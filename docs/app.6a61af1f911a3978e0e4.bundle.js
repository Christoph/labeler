/******/ (function(modules) { // webpackBootstrap
/******/ 	// install a JSONP callback for chunk loading
/******/ 	function webpackJsonpCallback(data) {
/******/ 		var chunkIds = data[0];
/******/ 		var moreModules = data[1];
/******/ 		var executeModules = data[2];
/******/
/******/ 		// add "moreModules" to the modules object,
/******/ 		// then flag all "chunkIds" as loaded and fire callback
/******/ 		var moduleId, chunkId, i = 0, resolves = [];
/******/ 		for(;i < chunkIds.length; i++) {
/******/ 			chunkId = chunkIds[i];
/******/ 			if(Object.prototype.hasOwnProperty.call(installedChunks, chunkId) && installedChunks[chunkId]) {
/******/ 				resolves.push(installedChunks[chunkId][0]);
/******/ 			}
/******/ 			installedChunks[chunkId] = 0;
/******/ 		}
/******/ 		for(moduleId in moreModules) {
/******/ 			if(Object.prototype.hasOwnProperty.call(moreModules, moduleId)) {
/******/ 				modules[moduleId] = moreModules[moduleId];
/******/ 			}
/******/ 		}
/******/ 		if(parentJsonpFunction) parentJsonpFunction(data);
/******/
/******/ 		while(resolves.length) {
/******/ 			resolves.shift()();
/******/ 		}
/******/
/******/ 		// add entry modules from loaded chunk to deferred list
/******/ 		deferredModules.push.apply(deferredModules, executeModules || []);
/******/
/******/ 		// run deferred modules when all chunks ready
/******/ 		return checkDeferredModules();
/******/ 	};
/******/ 	function checkDeferredModules() {
/******/ 		var result;
/******/ 		for(var i = 0; i < deferredModules.length; i++) {
/******/ 			var deferredModule = deferredModules[i];
/******/ 			var fulfilled = true;
/******/ 			for(var j = 1; j < deferredModule.length; j++) {
/******/ 				var depId = deferredModule[j];
/******/ 				if(installedChunks[depId] !== 0) fulfilled = false;
/******/ 			}
/******/ 			if(fulfilled) {
/******/ 				deferredModules.splice(i--, 1);
/******/ 				result = __webpack_require__(__webpack_require__.s = deferredModule[0]);
/******/ 			}
/******/ 		}
/******/
/******/ 		return result;
/******/ 	}
/******/
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// object to store loaded and loading chunks
/******/ 	// undefined = chunk not loaded, null = chunk preloaded/prefetched
/******/ 	// Promise = chunk loading, 0 = chunk loaded
/******/ 	var installedChunks = {
/******/ 		"app": 0
/******/ 	};
/******/
/******/ 	var deferredModules = [];
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/ 	var jsonpArray = window["webpackJsonp"] = window["webpackJsonp"] || [];
/******/ 	var oldJsonpFunction = jsonpArray.push.bind(jsonpArray);
/******/ 	jsonpArray.push = webpackJsonpCallback;
/******/ 	jsonpArray = jsonpArray.slice();
/******/ 	for(var i = 0; i < jsonpArray.length; i++) webpackJsonpCallback(jsonpArray[i]);
/******/ 	var parentJsonpFunction = oldJsonpFunction;
/******/
/******/
/******/ 	// add entry module to deferred list
/******/ 	deferredModules.push([0,"vendor.bluebird","vendor.aurelia-binding","vendor.aurelia-templating","vendor.aurelia","vendor"]);
/******/ 	// run deferred modules when ready
/******/ 	return checkDeferredModules();
/******/ })
/************************************************************************/
/******/ ({

/***/ "./datasets/classes.json":
/*!*******************************!*\
  !*** ./datasets/classes.json ***!
  \*******************************/
/*! exports provided: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, default */
/***/ (function(module) {

eval("module.exports = JSON.parse(\"{\\\"0\\\":{\\\"Cluster\\\":\\\"AbstractionSimplificationApproximation\\\",\\\"Vector\\\":[0.0015334019,0.019863158,0.1521609912,0.0021978864,0.0120034582,0.0208181969,0.0378633096,0.0187841235,0.0047198655,0.0008357566,0.0015557094,0.001217591,0.0066204518,0.0051874123,0.0061516665,0.0018922101,0.0039521899,0.0162639108,0.010512431,0.0027349221]},\\\"1\\\":{\\\"Cluster\\\":\\\"AcousticsSoundSonification\\\",\\\"Vector\\\":[0.0020473242,0.0056250335,0.0068788527,0.0014812197,0.0009429025,0.0102442232,0.0004076669,0.0029094343,0.0057184328,0.0410201604,0.0023674748,0.000917213,0.0446158128,0.0061344215,0.0006054849,0.023074986,0.0003778807,0.0034039961,0.0134302764,0.0082070695]},\\\"2\\\":{\\\"Cluster\\\":\\\"AdaptiveProcessingAndRefinement\\\",\\\"Vector\\\":[0.0016961511,0.0143497078,0.1140275872,0.004969509,0.0064916104,0.0008809851,0.0028844016,0.0458078818,0.0101219432,0.0007983763,0.0014364727,0.0002622595,0.0176362392,0.0035571865,0.0012368223,0.0116176018,0.0003405319,0.0077812843,0.0228371513,0.0011095437]},\\\"3\\\":{\\\"Cluster\\\":\\\"AlgorithmicPatternFeatureDetectionTracking\\\",\\\"Vector\\\":[0.0049829211,0.0040442182,0.0285322707,0.005799736,0.0163592609,0.1240094021,0.0082174356,0.0230039656,0.0104676347,0.0013686845,0.0007199293,0.0004302405,0.0042262081,0.0013153642,0.0038226753,0.031737175,0.001819152,0.0169532736,0.0091877833,0.0146282842]},\\\"4\\\":{\\\"Cluster\\\":\\\"AmbientVisualization\\\",\\\"Vector\\\":[0.0007835072,0,0.0001230737,0,0.0006868361,0.002784618,0.000128537,0.0001199655,0.0020923692,0.0002269553,0.0014348296,0.0101343771,0.0017178342,0.1419700787,0,0.0007427604,0.0179891172,0.0141100636,0.0018915677,0.0121049761]},\\\"5\\\":{\\\"Cluster\\\":\\\"AnalysisProcessGeneral\\\",\\\"Vector\\\":[0.0052449027,0.0085386886,0.0023921953,0.0003403683,0.0025449982,0.0037665026,0.0209213678,0.0131074154,0.00720207,0.0041449328,0.0020031097,0.0249716398,0.0027553354,0.0269885113,0.0008552911,0.0030899546,0.0248290461,0.0559709746,0.0041739797,0.0359254442]},\\\"6\\\":{\\\"Cluster\\\":\\\"AnimationAndMotion\\\",\\\"Vector\\\":[0.0099649088,0.0139408839,0.0136242233,0.0144228204,0.0220113153,0.0239499635,0.029578366,0.0080606143,0.0081531348,0.0099014949,0.0029572489,0.0099144595,0.0036617252,0.0224679868,0.001715865,0.0283788951,0.0076395518,0.0147208719,0.0072771644,0.0536556913]},\\\"7\\\":{\\\"Cluster\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"Vector\\\":[0.0069457431,0.0069129182,0.0166591488,0.0025623121,0.0072135836,0.017298958,0.0097565432,0.0055342698,0.0076794497,0.0038422834,0.0079147958,0.0116420327,0.0094466757,0.0183227915,0.0010046088,0.0120148595,0.0112200693,0.01577622,0.0250032903,0.0324679366]},\\\"8\\\":{\\\"Cluster\\\":\\\"ArtAndAestheticsInVisualization\\\",\\\"Vector\\\":[0.0008266312,0.0307900836,0.0296550477,0.0244359318,0.0249698658,0.0021919071,0.0025972731,0.0046381053,0.0112261924,0.0018081554,0.0030839163,0.0078339875,0.0081975214,0.0659477159,0.0092746293,0.0179725965,0.0033864129,0.0251516808,0.0022756332,0.0241477778]},\\\"9\\\":{\\\"Cluster\\\":\\\"AstronomyAstrophysics\\\",\\\"Vector\\\":[0.0029148079,0.00581263,0.0002563232,0.0009180552,0.0069846563,0.0009995688,0.0396380664,0.0171589913,0.0073493358,0.0349013429,0.0090710808,0.0039354548,0.0201892231,0.0141687331,0.0006969166,0.079982781,0.0013359675,0.0107129561,0.0093743418,0.0121882729]},\\\"10\\\":{\\\"Cluster\\\":\\\"AutomaticAnalysisVisualizationTechniques\\\",\\\"Vector\\\":[0.0009270781,0.0522683857,0.002685963,0.0011608529,0.0042558204,0.0023979212,0.0022181033,0.0044431188,0.0037590249,0.0011192282,0.0481466897,0.0044767151,0.0015358536,0.0431404706,0.000024938,0.0046818765,0.0028478197,0.0358900191,0.0011301685,0.0063025948]},\\\"11\\\":{\\\"Cluster\\\":\\\"BiologyAndBioinformatics\\\",\\\"Vector\\\":[0.0276778645,0.0272968617,0.0101271336,0.0063246989,0.0182890336,0.0087132805,0.0149318108,0.0253608441,0.0080963939,0.001220778,0.0027303982,0.002115343,0.0159843438,0.0130062225,0.0075976042,0.0039471501,0.0105563359,0.0212398791,0.0063930572,0.0129919311]},\\\"12\\\":{\\\"Cluster\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"Vector\\\":[0.0041998713,0.0063023693,0.0096005144,0.0169308882,0.0130763695,0.0122466721,0.0016022061,0.00770665,0.0426677521,0.0050488035,0.0041748375,0.0012594174,0.0285948379,0.0092403101,0.0200229579,0.0159262984,0.0032055484,0.0086949024,0.0093886581,0.009110967]},\\\"13\\\":{\\\"Cluster\\\":\\\"BusinessFinanceEconomyManufacturing\\\",\\\"Vector\\\":[0.0018312428,0.0642122276,0.0013975819,0.000257381,0.0007298879,0.000719681,0.021287262,0.0008840796,0.0012966058,0.0019513891,0.0025684462,0.0130593323,0.0016884971,0.0176324873,0.0006014241,0.0001515078,0.0106905616,0.0432877199,0.001043989,0.02240236]},\\\"14\\\":{\\\"Cluster\\\":\\\"CamerasCameraViewsAndProjections\\\",\\\"Vector\\\":[0.0022288307,0.007230781,0.0147364319,0.001076718,0.0186265692,0.0114486617,0.0033200576,0.002488773,0.0292320025,0.000245385,0.0520522431,0.0012056659,0.0333188879,0.0161075439,0.0009634977,0.0026500007,0.0021955587,0.0030131396,0.0240028973,0.0224909341]},\\\"15\\\":{\\\"Cluster\\\":\\\"CategoricalDataAndTechniques\\\",\\\"Vector\\\":[0,0.005560605,0.0001145044,0,0.0001657184,0,0.0113493852,0.0020716293,0.0017711326,0.0000903606,0,0.0173285637,0.000044693,0.0243415662,0,0,0.0101741802,0.1150299282,0.0160110157,0.0271450003]},\\\"16\\\":{\\\"Cluster\\\":\\\"ChartsDiagramsPlots\\\",\\\"Vector\\\":[0.0030357709,0.0170100021,0.0028090743,0.0005476423,0.0009545654,0.0066229248,0.011446231,0.0165729477,0.0049376394,0.0058931794,0.0005206331,0.0215884534,0.0009179033,0.0229080629,0.001398404,0.0026283425,0.0152236558,0.0734843749,0.0027842854,0.0094561308]},\\\"17\\\":{\\\"Cluster\\\":\\\"Cognition\\\",\\\"Vector\\\":[0.0004606333,0.0087792058,0.0010232375,0.0002070556,0.0162444893,0.0082612846,0.0065678321,0.0033293567,0.0060233491,0.001447562,0.0033939188,0.0308542304,0.0025687872,0.0764035319,0.0004512092,0.001433227,0.0158345897,0.0149108781,0.0054283873,0.0342019687]},\\\"18\\\":{\\\"Cluster\\\":\\\"CollaborativeVisualization\\\",\\\"Vector\\\":[0.0033020407,0.0118167353,0.0074490913,0.0009586013,0.0035751618,0.0025180383,0.0064852142,0.0031559757,0.0016236546,0.0023429883,0.0116776716,0.0404728339,0.0017996164,0.0593786287,0.0006824722,0.0023482032,0.0284956878,0.0235857823,0.0047200418,0.0223690623]},\\\"19\\\":{\\\"Cluster\\\":\\\"ColorColorPerception\\\",\\\"Vector\\\":[0.0020844467,0.0131610177,0.0027787456,0.004016099,0.0316640513,0.0167724017,0.0052265817,0.0093625283,0.0269178986,0.0018811271,0.0319811153,0.000898058,0.0100303324,0.0254156043,0.0143064281,0.0038121353,0.0003891801,0.009990661,0.0115315584,0.0086403655]},\\\"20\\\":{\\\"Cluster\\\":\\\"ComparisonComparativeVisualizationAndSimilarity\\\",\\\"Vector\\\":[0.0147558189,0.020892356,0.0061109462,0.0294638334,0.0094030346,0.0415784559,0.0044875078,0.0138903004,0.0117713593,0.0059538423,0.0016115758,0.0114423951,0.0126920426,0.0078358181,0.0013704217,0.0038973699,0.0154350688,0.0210664178,0.0048568275,0.0173329522]},\\\"21\\\":{\\\"Cluster\\\":\\\"CompressionTechniques\\\",\\\"Vector\\\":[0.0001812302,0.0055339922,0.1426127062,0.0019032765,0.0158839477,0.0049392733,0.0066412706,0.0365231784,0.0046230696,0.0005306012,0.0002139206,0.0000277703,0.0215842276,0.0005505604,0.000888349,0.0006943631,0.0015813022,0.001610756,0.1638177489,0.0021578644]},\\\"22\\\":{\\\"Cluster\\\":\\\"ComputerGraphicsTechniquesGeneral\\\",\\\"Vector\\\":[0.0097819551,0.0101342949,0.0354065335,0.003046007,0.0438806954,0.0133644415,0.0096546024,0.0187169758,0.0150938345,0.0017078308,0.0084729295,0.0116769139,0.0271355175,0.0065750553,0.001515737,0.0099703952,0.002047717,0.0125553216,0.0135673296,0.0095579402]},\\\"23\\\":{\\\"Cluster\\\":\\\"ComputerNetworksNetworkSecurity\\\",\\\"Vector\\\":[0.001061106,0.0116935268,0.0016479831,0.0002445007,0.003692866,0.00600353,0.0088050646,0.0010752433,0.0015054706,0.0008532125,0.0016040339,0.0031005812,0.0020070104,0.0119208048,0.0000134587,0.0038021231,0.0954277526,0.0218211876,0.0208672913,0.0470167294]},\\\"24\\\":{\\\"Cluster\\\":\\\"ContourCreasesRidgesValleys\\\",\\\"Vector\\\":[0.0004964073,0.0037514813,0.0344632051,0.0404128619,0.0107949184,0.0384743666,0.0012136168,0.0883898184,0.0146205303,0.0041684241,0.0033557627,0.0025947539,0.0076887253,0.0009807233,0.0062199488,0.0455443407,0.0008889895,0.0019936981,0.017252166,0.003086487]},\\\"25\\\":{\\\"Cluster\\\":\\\"CpuAndGpuClusters\\\",\\\"Vector\\\":[0,0.0308960103,0,0,0.0874743773,0,0.0739048563,0,0,0,0,0,0.0382907985,0,0,0,0.0738335836,0,0.0940992588,0]},\\\"26\\\":{\\\"Cluster\\\":\\\"CurvesAndCurvature\\\",\\\"Vector\\\":[0.0052121601,0.0187895314,0.0549058522,0.0140553245,0.0042069741,0.0131508021,0.0103421681,0.0316155069,0.0165938228,0.0010040512,0.0134683026,0.0137609963,0.0200584837,0.0028619193,0.0036884025,0.0071412969,0.0016533216,0.0115416862,0.0133895087,0.0021824357]},\\\"27\\\":{\\\"Cluster\\\":\\\"CuttingPlanes\\\",\\\"Vector\\\":[0.0007962891,0.0076430028,0.0988573314,0.0013307834,0.0120161329,0.1219004342,0.0016032953,0.0195061364,0.0118117499,0.0002049795,0.0021488739,0.0011961492,0.02115821,0.0024274039,0.000276452,0.0021965024,0.0026586432,0,0,0]},\\\"28\\\":{\\\"Cluster\\\":\\\"DataAcquisitionAndManagement\\\",\\\"Vector\\\":[0.0009883448,0.011134407,0.0152352562,0.0016440497,0.0048340879,0.0185219022,0.0145025902,0.0215551651,0.0142597495,0.0056390673,0.0043306211,0.0130808985,0.0124871216,0.0130115688,0.0018995947,0.0047438583,0.0193371007,0.0346995975,0.0098899894,0.0212157225]},\\\"29\\\":{\\\"Cluster\\\":\\\"DataAndAnalysisMetrics\\\",\\\"Vector\\\":[0.0036578712,0.0081280347,0.0140691201,0.0086386738,0.0044650369,0.0062190568,0.0334179479,0.0150345486,0.0211474019,0.0061397506,0.0070689448,0.0060034905,0.0064926929,0.0309546676,0.0000796563,0.0023824787,0.0011762842,0.0506196671,0.0204110486,0.0139023366]},\\\"30\\\":{\\\"Cluster\\\":\\\"DataCleaningAndSmoothing\\\",\\\"Vector\\\":[0.00053609,0.0013968879,0.0365472739,0.0012168932,0.0013229506,0,0.0063326109,0.010808998,0.004845989,0.0392140384,0.0012443325,0.0088205158,0.0021040031,0.0510861437,0.0004203709,0,0.0443044737,0.0512627147,0.0025289877,0.0014555664]},\\\"31\\\":{\\\"Cluster\\\":\\\"DataClusteringAndAggregation\\\",\\\"Vector\\\":[0.0027988757,0.0335608117,0.0096029827,0.0029563187,0.0076547127,0.0175975441,0.119784819,0.0059237613,0.0048976258,0.0022566127,0.0017873091,0.015630607,0.0021220994,0.0124658989,0.0221194008,0.0098054213,0.0308271361,0.0267313831,0.0130663335,0.0212448346]},\\\"32\\\":{\\\"Cluster\\\":\\\"DataEditing\\\",\\\"Vector\\\":[0.0000898956,0.0219713912,0.0043277515,0.0002542137,0,0.0193178128,0,0.0070224744,0.0111187898,0,0.0039298086,0.051570236,0.0019045558,0,0,0,0.0409394395,0.0981370728,0,0]},\\\"33\\\":{\\\"Cluster\\\":\\\"DataFacetsAndTechniques\\\",\\\"Vector\\\":[0,0.0161877066,0.0024746276,0,0.0000203063,0.0013658233,0.0192876835,0.002319652,0.0011348214,0,0.0002370371,0.1031851054,0.0003173677,0.0392852807,0.000977909,0,0.0174258236,0.0303630844,0,0.0050472209]},\\\"34\\\":{\\\"Cluster\\\":\\\"DataFeaturesAndAttributes\\\",\\\"Vector\\\":[0.0029807723,0.01868453,0.0369179583,0.029002138,0.0136554961,0.0568712762,0.0187055666,0.0097065448,0.0180863825,0.0013653477,0.0018706273,0.00466974,0.0058737147,0.00616349,0.011260593,0.006072499,0.0062914829,0.0226160235,0.0058867183,0.0021946209]},\\\"35\\\":{\\\"Cluster\\\":\\\"DataRegistrationFusionAndIntegration\\\",\\\"Vector\\\":[0.0014232723,0.0001777328,0.0053500175,0.0052365169,0.0143125742,0.0123565244,0.000484195,0.0245668196,0.0127011034,0.0104337003,0.0786691723,0.0137498554,0.040172258,0.0042365836,0.0009090297,0.0059930191,0.0004168466,0.0110966791,0.0050825763,0.0099913221]},\\\"36\\\":{\\\"Cluster\\\":\\\"DataTransformation\\\",\\\"Vector\\\":[0.00103966,0.0055744288,0.0235505967,0.0012197718,0.0169812372,0.021087123,0.0104728322,0.0117929492,0.0152448965,0.0401143911,0.0007465334,0.0046652804,0.0092846806,0.0198445656,0.0016243204,0.0017966463,0.0261516606,0.0544467195,0.0302554599,0.0116689744]},\\\"37\\\":{\\\"Cluster\\\":\\\"DataTypesGeneral\\\",\\\"Vector\\\":[0.0009054201,0.0050750811,0.0192230819,0.0004146076,0.0077525964,0.0005327334,0.0234919912,0.0046697841,0.0026747549,0.0022992525,0,0.0036713106,0.0093654548,0.0025493952,0.0024560155,0.0009514601,0.0052477349,0.0932707868,0.0067686701,0.0062780731]},\\\"38\\\":{\\\"Cluster\\\":\\\"DatabasesAndDataMining\\\",\\\"Vector\\\":[0.0025328022,0.016634561,0.0089868248,0.0014685556,0.0175332778,0.0062893326,0.0290218762,0.0037721846,0.0034715397,0.0012598394,0.0012067087,0.0508827335,0.002986917,0.0105421099,0.0009558283,0.0048288021,0.0210361376,0.0516422705,0.0113358338,0.020937265]},\\\"39\\\":{\\\"Cluster\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"Vector\\\":[0.0020456571,0.0257892762,0.0211930678,0.0024056381,0.0025580889,0.008764233,0.0300893247,0.0029264026,0.0037457176,0.0012201124,0.0225324588,0.030959816,0.0029855377,0.0199608507,0.0009170035,0.0034332346,0.0094621129,0.0320649431,0.0045926979,0.0423307889]},\\\"40\\\":{\\\"Cluster\\\":\\\"DesignStudiesAndCaseStudies\\\",\\\"Vector\\\":[0.0243984907,0.0313795463,0.00194952,0.0101425984,0.0000189993,0.0012767602,0.0068646046,0.0072812384,0.0001343202,0.001243339,0.0001414108,0.0290407316,0.000049435,0.0252678877,0.0007887408,0.0010797699,0.0129967363,0.011698126,0.0129473817,0.0246643454]},\\\"41\\\":{\\\"Cluster\\\":\\\"DiffusionRelatedTechniques\\\",\\\"Vector\\\":[0.000788148,0,0.0187169332,0.0383308856,0.0272093247,0.0610976126,0.0004714742,0.0067800494,0.0328709101,0.0100191185,0.0062401115,0.0007555734,0.0024814549,0.0034408344,0.0883861196,0.0237753423,0.0000079612,0.0043398079,0.0022482937,0.0036096673]},\\\"42\\\":{\\\"Cluster\\\":\\\"DimensionalityReduction\\\",\\\"Vector\\\":[0.0008804644,0.0207683712,0.0275574868,0.0092769924,0.0160343938,0.0088095837,0.0487081009,0.0066839034,0.0092516795,0.0145346252,0.019861266,0.013352478,0.0137515515,0.0053402741,0.009630507,0.0014382052,0.0063649927,0.0388312613,0.0052197167,0.008520495]},\\\"43\\\":{\\\"Cluster\\\":\\\"DisplaysGeneral\\\",\\\"Vector\\\":[0.0014952271,0.0113097795,0.0100660978,0.0026192373,0.0164804821,0.0041289269,0.0065878913,0.0051028678,0.0069801391,0.0018778388,0.1541859751,0.0015914873,0.0122115762,0.029274007,0.0028925591,0.0014726443,0.0070935111,0.0140641893,0.0078389744,0.0024310321]},\\\"44\\\":{\\\"Cluster\\\":\\\"DistributedSystemsAndGridEnvironments\\\",\\\"Vector\\\":[0.0037368864,0.0060437129,0.017008815,0,0.0282640021,0.0036893719,0.0135185449,0.0199124473,0.0057802327,0,0.0170698471,0.0038977994,0.0136031773,0.0219515424,0.0001864141,0.0150156067,0.0589452165,0.0028519057,0.0806752573,0.0099332656]},\\\"45\\\":{\\\"Cluster\\\":\\\"DynamicDataAndTechniques\\\",\\\"Vector\\\":[0.005522996,0.0461851067,0.0855278782,0.001870651,0.0027675038,0.0009781965,0.05702388,0.0070342238,0.0006881191,0.0001397462,0.0025096375,0.0014283197,0.0018516171,0.0062493311,0,0.0025909684,0.0063666267,0.0388953758,0.0032022569,0.0192537512]},\\\"46\\\":{\\\"Cluster\\\":\\\"DynamicVisualizationVisualizationOfChange\\\",\\\"Vector\\\":[0.0010637808,0.0189909513,0.0032691175,0.026723155,0.0059155671,0.0171302043,0.0031819306,0.0091371506,0.0138887873,0.0011726029,0.0040496889,0.0372040783,0.0137270646,0.0345297117,0.0154554372,0.0278132148,0.0029306133,0.0191198853,0.020688033,0.028845926]},\\\"47\\\":{\\\"Cluster\\\":\\\"EarthSpaceAndEnvironmentalSciences\\\",\\\"Vector\\\":[0.0018050169,0.0069160192,0.0110747755,0.0115001236,0.0246969213,0.0232263166,0.0131276924,0.0154814543,0.0085612035,0.0092957783,0.0030786581,0.0025273487,0.0058569633,0.0157500638,0.0010122734,0.0214008747,0.0040731488,0.0247514774,0.0158760018,0.0123584723]},\\\"48\\\":{\\\"Cluster\\\":\\\"Education\\\",\\\"Vector\\\":[0.0019854647,0.0027025324,0.0143613064,0,0.0020076039,0.0003974721,0,0,0.0004918911,0.002047768,0.0010560882,0.0523754518,0.0013840968,0.041055718,0,0.0010461146,0.0148275202,0.0038346247,0,0.0353910761]},\\\"49\\\":{\\\"Cluster\\\":\\\"EmergencyDisasterManagement\\\",\\\"Vector\\\":[0.0014392926,0.0028006071,0,0,0.0010103682,0.0441180708,0,0.0014096737,0,0.0326054333,0.0023502077,0.0222163859,0.0038572218,0.0305266618,0.000325564,0.0074249227,0.0263959445,0.0098944071,0.0136144253,0.0671282873]},\\\"50\\\":{\\\"Cluster\\\":\\\"Engineering\\\",\\\"Vector\\\":[0.0064193849,0.0009974392,0.0010294197,0.003619479,0.02859987,0.1235809856,0.0003588001,0.0021167905,0.0010333235,0.0028705997,0.0082235473,0.0007699089,0.0012234366,0.005514495,0.0000117368,0.0265946118,0.0036603108,0.0297689829,0.0224007583,0.0044173893]},\\\"51\\\":{\\\"Cluster\\\":\\\"EvaluationGeneral\\\",\\\"Vector\\\":[0.0011488503,0.0218312716,0.0060000541,0.0011572722,0.021088448,0.006516722,0.0081437984,0.0067796953,0.0107833935,0.0076063783,0.0085920661,0.0174772703,0.0040474652,0.0786543285,0.002347676,0.0039272718,0.0079728015,0.0246254457,0.0091188239,0.0157023085]},\\\"52\\\":{\\\"Cluster\\\":\\\"EvaluationMetricsAndBenchmarks\\\",\\\"Vector\\\":[0.0004564535,0.0399533591,0.0239768809,0.0074636431,0.0050751033,0.0087707256,0.02787147,0.0086365386,0.0073845731,0.0060610195,0.0015562881,0.0053478334,0.0021275356,0.017142019,0.0016691721,0.0021883753,0.0118068992,0.0344334702,0.0249560647,0.0207662859]},\\\"53\\\":{\\\"Cluster\\\":\\\"EventsTrendsOutlierDetectionAnalysisAndVisualization\\\",\\\"Vector\\\":[0.0007475632,0.0066787669,0.0025973061,0.0042892479,0.0035462583,0.0064317038,0.0186508139,0.0011779632,0.0028532232,0.0005216137,0.0013067902,0.0271473716,0.0009091232,0.0259387276,0.0002062674,0.0015551297,0.0142524978,0.0287299101,0.0080590914,0.1181814692]},\\\"54\\\":{\\\"Cluster\\\":\\\"FieldStudies\\\",\\\"Vector\\\":[0.0011394859,0,0.0000826325,0.0003334418,0,0.0000932504,0.002708317,0.0006704812,0.0171898605,0.0034861503,0.0027699319,0.0117463958,0.0001373469,0.0478178029,0.0000452954,0.0024409816,0.0027165668,0.0148552966,0.0028693166,0.0188294942]},\\\"55\\\":{\\\"Cluster\\\":\\\"FilteringTechniques\\\",\\\"Vector\\\":[0.0124379643,0.0162386294,0.0099394947,0.0243481426,0.0192371419,0.0362371646,0.0154594025,0.0200484737,0.0128658998,0.0004785716,0.0021849718,0.0012215581,0.0275193006,0.0009061842,0.035750885,0.0055719127,0.0174247031,0.0173459554,0.0137704926,0.0020762508]},\\\"56\\\":{\\\"Cluster\\\":\\\"FlowVisualizationDataAndTechniques\\\",\\\"Vector\\\":[0.0014894064,0.005610087,0.0170735265,0.0179041108,0.0410542211,0.1439155419,0.0091412133,0.0156950421,0.0074710702,0.0121918889,0.0021262481,0.0006964519,0.004982344,0.0051137215,0.0061834679,0.0429948023,0.0025877308,0.0056103707,0.0069579964,0.0096639028]},\\\"57\\\":{\\\"Cluster\\\":\\\"FocusContextTechniques\\\",\\\"Vector\\\":[0.0050749798,0.0560310805,0.0073951187,0.0018488253,0.007330146,0.0083772679,0.0067267176,0.0032875063,0.0115962235,0.000644936,0.0065079443,0.0080667616,0.0149199639,0.0149743214,0.0013258127,0.0051960385,0.0112976751,0.0303293168,0.0079722256,0.0172228467]},\\\"58\\\":{\\\"Cluster\\\":\\\"Genetics\\\",\\\"Vector\\\":[0.035444887,0.0046200564,0.0020956993,0.0010211735,0.0484391005,0.0029252824,0.0105240416,0.012780835,0.0024417115,0.0003268473,0.0021712558,0.001667376,0.0014998671,0.0248682343,0.0028132771,0.0004015987,0.0184904868,0.0350179519,0.0109597654,0.0060350891]},\\\"59\\\":{\\\"Cluster\\\":\\\"GeographyGeospatialVisCartographyTerrainVis\\\",\\\"Vector\\\":[0.0016170036,0.0179572517,0.0328463322,0.0009975461,0.0196635269,0.0088881965,0.016914067,0.0128258397,0.0028806788,0.0076136347,0.0059292567,0.0094617156,0.0093729098,0.0195151645,0.0005219718,0.0032945032,0.0117656817,0.0204923583,0.0128081514,0.0336543761]},\\\"60\\\":{\\\"Cluster\\\":\\\"GeometricModeling\\\",\\\"Vector\\\":[0.0018444928,0.0077465596,0.0799890391,0.0127993562,0.0140583065,0.0110688389,0.0052483773,0.0220613578,0.0146516607,0.0011077487,0.0227372717,0.0080522696,0.011396408,0.0037730911,0.0027643244,0.0076317011,0.0023980516,0.0075709213,0.0181966897,0.0029747584]},\\\"61\\\":{\\\"Cluster\\\":\\\"GeometryBasedTechniques\\\",\\\"Vector\\\":[0.0099270557,0.0117318481,0.080858279,0.0021589707,0.0043576306,0.0150684628,0.0026907398,0.018242638,0.0089282419,0.0193436148,0.0044702985,0.0021286788,0.0161764378,0.0020879018,0.0012953442,0.0110688665,0.0014246365,0.0082631361,0.0234626937,0.0062980206]},\\\"62\\\":{\\\"Cluster\\\":\\\"GlyphsGlyphBasedTechniques\\\",\\\"Vector\\\":[0.0140806,0.0006524875,0.0031416211,0.0905799958,0.0147532733,0.0373757082,0.0137547021,0.0091254253,0.0067970614,0.0455684139,0.0023222546,0.0012233745,0.0047359337,0.0240161508,0.0065079643,0.0093156089,0.011853052,0.019441239,0.0020711309,0.0021150368]},\\\"63\\\":{\\\"Cluster\\\":\\\"GpuBasedTechniques\\\",\\\"Vector\\\":[0.0107535299,0.008341848,0.0255389922,0.0171001395,0.0599939403,0.0175635229,0.0020126179,0.017230609,0.0204002144,0.0060401808,0.0026032753,0.0008239203,0.0524625615,0.0026100154,0.0091203557,0.0436406386,0.0030166731,0.0030207496,0.0227381186,0.0095421473]},\\\"64\\\":{\\\"Cluster\\\":\\\"GraphNetworkDataAndTechniques\\\",\\\"Vector\\\":[0.0040654826,0.0893396432,0.0182242672,0.0018647993,0.0020335676,0.003521698,0.0378539646,0.0071825155,0.0029252177,0.0007079471,0.0012452188,0.0089393666,0.0021914077,0.0202011042,0.0034601785,0.0020061135,0.0630826402,0.0154740709,0.0023188619,0.012276053]},\\\"65\\\":{\\\"Cluster\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"Vector\\\":[0.0074979002,0.0126982217,0.0276889728,0.0011237802,0.0669056209,0.0131687387,0.0163240119,0.017680407,0.0134074843,0.0005825042,0.0012650391,0.0106444805,0.0441561572,0.000972031,0.0017234566,0.0143464408,0.005468995,0.0068073551,0.0530803479,0.0059200761]},\\\"66\\\":{\\\"Cluster\\\":\\\"HierarchicalTreeDataAndTechniques\\\",\\\"Vector\\\":[0.0048199255,0.1075899603,0.0228044527,0.0005639452,0.0036308116,0.0041924394,0.0316097135,0.0134314831,0.0030915941,0.0006575236,0.0012184742,0.0179837261,0.0051297446,0.0131130757,0.001074222,0.0015784212,0.0077699581,0.0203056111,0.0062553426,0.0078890962]},\\\"67\\\":{\\\"Cluster\\\":\\\"HumanComputerInteractionHumanFactors\\\",\\\"Vector\\\":[0.0045533415,0.0100377437,0.0020920409,0.00185814,0.0109648516,0.0046789831,0.003836871,0.0022963995,0.0083527571,0.0019021449,0.0040582278,0.0418331106,0.0037237943,0.0537151803,0.0032230195,0.0028171737,0.0137156301,0.0274597828,0.0027556135,0.0367508236]},\\\"68\\\":{\\\"Cluster\\\":\\\"HypothesisFormingTestingAndVisualEvidence\\\",\\\"Vector\\\":[0.0022292209,0.0062420637,0.0049015577,0.0002617072,0.0023034513,0.0202760375,0.0029650541,0.0016693952,0.0060096011,0.000378927,0,0.0000661849,0.0007367942,0.0280217075,0,0.0034111981,0.0046902171,0.0707131552,0.0042448875,0.0260225239]},\\\"69\\\":{\\\"Cluster\\\":\\\"Illumination\\\",\\\"Vector\\\":[0.0026406249,0.0038078403,0.0178966262,0.0036600281,0.0227676846,0.0182320571,0.0025411274,0.0053802007,0.051301042,0.0017160894,0.0085146147,0.0003696276,0.021978818,0.0231890037,0.0068008003,0.0083586599,0.0053554129,0.0022957977,0.007127946,0.0019149368]},\\\"70\\\":{\\\"Cluster\\\":\\\"IllustrativeVisualization\\\",\\\"Vector\\\":[0.0023645347,0.0027689853,0.0128803508,0.0036445718,0.0453288771,0.0371491067,0.0024602994,0.0064813251,0.0517199435,0.0013791229,0.0036719417,0.0007945308,0.0164742057,0.0139661234,0.0119037766,0.0088094486,0.00037667,0.0058434285,0.0002608945,0.0175686848]},\\\"71\\\":{\\\"Cluster\\\":\\\"ImageBasedDataImageSignalProcessing\\\",\\\"Vector\\\":[0.0036476953,0.0077365587,0.0178499006,0.0035327886,0.0217671836,0.0179707172,0.0120939851,0.0139078507,0.0282757125,0.0050248301,0.018559363,0.0088318604,0.0247341195,0.0058799554,0.0078316222,0.0071524547,0.0048607251,0.0122100419,0.0263582456,0.0171160549]},\\\"72\\\":{\\\"Cluster\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"Vector\\\":[0.0122763521,0.011814133,0.0107160482,0.0065171693,0.0235062425,0.0174336389,0.0011100455,0.0064629961,0.006771792,0.0006449534,0.0452978245,0.0091126684,0.0132057807,0.0265699768,0.0076784095,0.0116193154,0.003181628,0.0058317638,0.0081356321,0.0253635532]},\\\"73\\\":{\\\"Cluster\\\":\\\"InformationProcessingAndHandling\\\",\\\"Vector\\\":[0.0018426098,0.0011553506,0,0,0.0231679509,0.035880676,0.0003133802,0.1269581663,0.0158276581,0.0004762272,0.0029471466,0.000865662,0.006011224,0.000197168,0,0.010308589,0.0000548244,0.0061426486,0.0799556025,0.0025105266]},\\\"74\\\":{\\\"Cluster\\\":\\\"InformationTheory\\\",\\\"Vector\\\":[0.0016527416,0.0011802243,0.0049531882,0.0007258476,0.0011250028,0.0429708256,0.0127727948,0.0117330235,0.0533920394,0.0106654926,0.0055246566,0.0005406132,0.003218195,0.00588271,0.0033727119,0.0015450747,0.0038455268,0.0319897883,0.06638037,0.011696833]},\\\"75\\\":{\\\"Cluster\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"Vector\\\":[0.0079094092,0.0043283126,0.0091402741,0.0075265722,0.0599702135,0.0179225696,0.0050056964,0.0097372003,0.019380748,0.0009019453,0.0058194141,0.0010065136,0.0218949156,0.0189852722,0.0070899239,0.0273513797,0.0115075279,0.0046159587,0.0330618745,0.0146660835]},\\\"76\\\":{\\\"Cluster\\\":\\\"IntegratingSpatialAndNonSpatialDataVisualization\\\",\\\"Vector\\\":[0.0013976186,0.001939395,0.0127491311,0.0031328136,0.007539294,0.0052615531,0.0152266648,0.0078083716,0.0201524474,0.0023619281,0.0032825227,0.000684822,0.0079269628,0.0077289762,0.0061215708,0.0256865213,0.0011966455,0.0577149712,0.0052735451,0.000972799]},\\\"77\\\":{\\\"Cluster\\\":\\\"InteractionTechniquesGeneral\\\",\\\"Vector\\\":[0.0054754861,0.0242407861,0.0109104117,0.0038275489,0.0142550262,0.0160281896,0.0097590413,0.0066174205,0.0145705911,0.0060092584,0.0061100538,0.0080975739,0.0108399542,0.0183659153,0.0072652107,0.0090003979,0.0138653431,0.0387543583,0.0116228127,0.0172121077]},\\\"78\\\":{\\\"Cluster\\\":\\\"InternetWebVisualizationForTheMasses\\\",\\\"Vector\\\":[0.0008284427,0.0170345408,0.0046759952,0.000294685,0.0117126847,0.0014084478,0.0078765666,0.0081596912,0.0077909639,0.0008385244,0.0029057621,0.0513083155,0.0041929392,0.015485788,0.0002951975,0.0004082471,0.0270213457,0.0262802634,0.0091146435,0.0304853239]},\\\"79\\\":{\\\"Cluster\\\":\\\"Interpolation\\\",\\\"Vector\\\":[0.0015846481,0.0060842398,0.0417687434,0.0091433754,0.0107846321,0.0085935146,0.0028095528,0.0575450093,0.0089207374,0.0109534398,0.0078175595,0.0008277555,0.0289571168,0.009609014,0.000426858,0.0207381598,0.0002574251,0.0139897183,0.0255909891,0.0097522512]},\\\"80\\\":{\\\"Cluster\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"Vector\\\":[0.0039355349,0.0102101872,0.0571946739,0.0054106974,0.0091682094,0.0100366785,0.0044513855,0.10731337,0.0174606957,0.001323137,0.0009135501,0.0009985654,0.027114348,0.0018700589,0.0013097165,0.018483411,0.0013418441,0.0034857592,0.0149964598,0.0047585817]},\\\"81\\\":{\\\"Cluster\\\":\\\"KnowledgeDiscovery\\\",\\\"Vector\\\":[0.0011072305,0.0134684976,0.002167178,0.0012970321,0.0003151946,0.0134455484,0.0304387702,0.0037200245,0.0020009516,0.0121538598,0.0005146521,0.0469220392,0.0014847956,0.022735742,0.001731769,0.0028254875,0.0382545121,0.0415501673,0.0027668117,0.045697593]},\\\"82\\\":{\\\"Cluster\\\":\\\"Labeling\\\",\\\"Vector\\\":[0.0140264828,0.0145824668,0.0284851797,0.0016567719,0.0259430034,0.0018435607,0.009314746,0.0012588755,0.0157091534,0.046762306,0.0039314478,0.0215684362,0.0077161256,0.0133853146,0.0000193845,0.0376882351,0.0015740864,0.0171123603,0.0015923049,0.0038523765]},\\\"83\\\":{\\\"Cluster\\\":\\\"LaboratoryStudies\\\",\\\"Vector\\\":[0,0.0016962671,0.0008757028,0,0.0001372013,0.0006726057,0.0140878422,0.0016182511,0,0.0000649679,0.0004979695,0.0184857456,0,0.1964872165,0,0.0009159033,0.001752177,0.019455697,0.0008549317,0]},\\\"84\\\":{\\\"Cluster\\\":\\\"LargeAndHighResDisplays\\\",\\\"Vector\\\":[0.0006861667,0.0047978317,0.0046200769,0.0000763293,0.0120023841,0.0001027306,0.0043231021,0.0002185886,0.0024983422,0.0000905716,0.2275933475,0.0018733769,0.0049861089,0.0357917378,0.0044153036,0.0023566074,0.0066061599,0.0055553959,0.0184369135,0.0021456649]},\\\"85\\\":{\\\"Cluster\\\":\\\"LargeScaleDataAndScalability\\\",\\\"Vector\\\":[0.0036264791,0.0185269231,0.0282896124,0.000331168,0.0141778828,0.0041533697,0.0267880063,0.017815702,0.0089367181,0.0096513248,0.0118535602,0.0061289015,0.0097433032,0.0115296001,0.000254742,0.0223984025,0.0082670798,0.0313354162,0.0430684431,0.0279323854]},\\\"86\\\":{\\\"Cluster\\\":\\\"LevelOfDetail\\\",\\\"Vector\\\":[0.0042470368,0.0218244733,0.1382580205,0.0012263354,0.0485059493,0.0016873466,0.0143189929,0.0141494156,0.0070154698,0.0005188571,0.0038028594,0.0006202251,0.0155584901,0.0022389708,0.0030763665,0.0024276204,0.0038142479,0.0053787641,0.0338979873,0.0078710104]},\\\"87\\\":{\\\"Cluster\\\":\\\"LineBasedTechniquesAndApproaches\\\",\\\"Vector\\\":[0.0036468551,0.0139649512,0.0092062145,0.0044302925,0.0264238736,0.070949769,0.0003538696,0.0102242306,0.0312082712,0.0001994578,0.0029215454,0.0023886389,0.0021313384,0.0353447803,0.0060877097,0.0139382088,0.0001432582,0.0020094495,0.0082528958,0]},\\\"88\\\":{\\\"Cluster\\\":\\\"MachineLearningAndStatistics\\\",\\\"Vector\\\":[0.0051035772,0.0096158903,0.0133401068,0.0028359169,0.0161333296,0.0204008345,0.0236891677,0.0080394432,0.0227150455,0.0232520704,0.0014292492,0.011675798,0.0014821402,0.0117194805,0.0061986519,0.003706694,0.0178589225,0.0506293826,0.0118625273,0.0055392557]},\\\"89\\\":{\\\"Cluster\\\":\\\"ManipulationAndDeformation\\\",\\\"Vector\\\":[0.0025730748,0.0083847297,0.018816725,0.0188380508,0.0265428918,0.1053300487,0.0006944542,0.0027566731,0.025256811,0,0.0149437935,0.0010879737,0.0220320161,0.0232497743,0.0070415389,0.0001905315,0.0007305632,0.0015949676,0.0026105379,0.0180233661]},\\\"90\\\":{\\\"Cluster\\\":\\\"Maps\\\",\\\"Vector\\\":[0.0019707785,0.0334591177,0.0359819426,0.0050767933,0.0085052165,0.0122209246,0.0089772861,0.0100275329,0.0071328178,0.0053721826,0.0088072707,0.0047323296,0.0071257288,0.0130211469,0.0026807733,0.0032136625,0.0113029008,0.0264859109,0.0050087853,0.0096758319]},\\\"91\\\":{\\\"Cluster\\\":\\\"MaterialScience\\\",\\\"Vector\\\":[0.0131330991,0.0042292813,0.0110632127,0.1116419513,0.0105724835,0.0121979953,0.0041281577,0.0213679169,0.0078109118,0.0013423169,0.0020917745,0.011466606,0.0108967168,0.0034402713,0.0003977879,0.015791377,0.0054080472,0.0055893701,0.0115776267,0.0009127795]},\\\"92\\\":{\\\"Cluster\\\":\\\"Mathematics\\\",\\\"Vector\\\":[0.0039419515,0.0010158019,0.0267329811,0.0035862787,0.0164776521,0.004642724,0.0016453407,0.0024738702,0.0194640694,0.0018543852,0.0112555091,0.0021115226,0.0451427511,0.0115985409,0.0000205394,0.005789818,0.0034841098,0.0045603861,0.0189274924,0.0109622383]},\\\"93\\\":{\\\"Cluster\\\":\\\"MatrixRelatedTechniques\\\",\\\"Vector\\\":[0,0.1012050186,0.0073774061,0.0024722383,0.0016103445,0.0004098086,0.0381229104,0.0078503524,0,0,0.0004571367,0.0052286643,0.0016054792,0.017847894,0,0.0012036689,0.1327971435,0.0244447357,0,0.0004636479]},\\\"94\\\":{\\\"Cluster\\\":\\\"MeshesGridsAndLattices\\\",\\\"Vector\\\":[0.0033233323,0.009420113,0.127490137,0.0039529881,0.0202289913,0.0122670353,0.0072925288,0.0416309268,0.0057990865,0.000691173,0.0020012135,0.0009352553,0.0318907648,0.0017549225,0.0014492273,0.0150361939,0.0032719309,0.0031795739,0.0234125563,0.0029629232]},\\\"95\\\":{\\\"Cluster\\\":\\\"Microscopy\\\",\\\"Vector\\\":[0.0173281041,0.0042133273,0.0016986748,0.001843437,0.0078311856,0.0096860255,0.0026078656,0.026425853,0.021275191,0.0009591484,0.0043373382,0.0009905371,0.0076310158,0.0101805285,0.0163270415,0.0073763344,0.0214012467,0.0110642969,0.0048776934,0.0110184148]},\\\"96\\\":{\\\"Cluster\\\":\\\"MolecularScienceAndChemistry\\\",\\\"Vector\\\":[0.1095838078,0.0092455549,0.0168181146,0.0056771046,0.0081446428,0.0034228616,0.0163599181,0.0110078223,0.0041062096,0.0029850479,0.0017354709,0.0008139108,0.0063625625,0.0034401124,0.0004552182,0.0069150023,0.0017269847,0.0054245633,0.0030799933,0.0041833692]},\\\"97\\\":{\\\"Cluster\\\":\\\"MultiCoreProcessing\\\",\\\"Vector\\\":[0.0003675453,0,0,0,0.0046814666,0.0085134066,0,0,0.0147599092,0,0,0,0.1236883555,0.0002148271,0.0022965705,0,0.0010640949,0,0.121551169,0]},\\\"98\\\":{\\\"Cluster\\\":\\\"MultiScaleDataTechniques\\\",\\\"Vector\\\":[0.0065102637,0.0322012186,0.0149843399,0.024153905,0.0104108611,0.053361283,0.008767902,0.0134255029,0.019532163,0.0017233252,0.0051935562,0.0022347296,0.0072132255,0.015228558,0.0137321284,0.0147597164,0.0207084349,0.0142023304,0.0135601752,0.0077410655]},\\\"99\\\":{\\\"Cluster\\\":\\\"MultidimensionalMultivariateMultifieldDataAndTechniques\\\",\\\"Vector\\\":[0.0026255782,0.0108391303,0.0035920818,0.008046399,0.0110670374,0.0174630988,0.0399855772,0.0124333275,0.0086621721,0.0074121937,0.0026660998,0.0117760996,0.0037640738,0.0112011275,0.0027459431,0.0120050503,0.005301753,0.0764965552,0.0094341405,0.0118882439]},\\\"100\\\":{\\\"Cluster\\\":\\\"MultimediaImageVideoMusic\\\",\\\"Vector\\\":[0.0023719102,0.0022955187,0.000680017,0.0007314149,0.0051134142,0.0091391117,0.0024779284,0.0018056298,0.0095597101,0.000936374,0.008575936,0.0141896922,0.003854135,0.0241870944,0.0004447323,0.0020281895,0.0042359363,0.011713395,0.0027628485,0.1758819995]},\\\"101\\\":{\\\"Cluster\\\":\\\"MultimodalDataTechniques\\\",\\\"Vector\\\":[0.0101923624,0.0021300533,0.0041927855,0.001621149,0.0045728883,0.0069271499,0.0065326211,0.0301219774,0.0388751779,0.0001739593,0.0074963663,0.0043115633,0.0168439588,0.0180247954,0.0057207252,0.0035253909,0.0039808785,0.0039920586,0.0042483037,0.0182874149]},\\\"102\\\":{\\\"Cluster\\\":\\\"MultipleLinkedCoordinatedViews\\\",\\\"Vector\\\":[0.007511595,0.0161622436,0.0012016397,0.0005469258,0.0039220863,0.0210809806,0.0139344559,0.0019703731,0.0036580575,0.0012888549,0.0017436455,0.0187148158,0.0027458782,0.0096021378,0.0005779194,0.0105627807,0.0188723618,0.0596753273,0.011876296,0.0272077302]},\\\"103\\\":{\\\"Cluster\\\":\\\"MultiresolutionTechniques\\\",\\\"Vector\\\":[0.0052691569,0.0162742163,0.1260081825,0.0011139381,0.0239793618,0.0167646883,0.0148253351,0.0243168162,0.0022535515,0.0003067185,0.0114000611,0.0080363539,0.0079672824,0.0058459087,0.0009668236,0.0022442204,0.0047527133,0.0106454017,0.0313927772,0.0059651615]},\\\"104\\\":{\\\"Cluster\\\":\\\"NeurosciencesAndBrainVisualization\\\",\\\"Vector\\\":[0.0048318807,0.0035190845,0.0152059672,0.018142547,0.0138653135,0.0016832082,0.0014482101,0.0187499206,0.0220039923,0.0010238807,0.0005405424,0.0022047131,0.0176226783,0.0016127219,0.122812256,0.0047951719,0.0055171505,0.0216243912,0.0163438505,0.0115733014]},\\\"105\\\":{\\\"Cluster\\\":\\\"NumericalMethodsMathematics\\\",\\\"Vector\\\":[0.0022646533,0.0076569946,0.0503476548,0.0252933432,0.0179887801,0.0225651344,0.0075672854,0.0235064301,0.0165121575,0.0021671285,0.004508256,0.0028560392,0.0156328019,0.0058678127,0.0124805779,0.0143947808,0.0018102858,0.0092248809,0.03382152,0.0058210279]},\\\"106\\\":{\\\"Cluster\\\":\\\"OcclusionProblemsTechniques\\\",\\\"Vector\\\":[0.0003033559,0.0116462011,0.0431696661,0.0012815201,0.0250209791,0.0012824633,0.0488548773,0.0174529368,0.0164202309,0.0008297706,0.0171719688,0.0018606851,0.0466475487,0.0064444152,0.0000074531,0.0108432469,0.0045262787,0.0228747447,0.0029005467,0.0143752756]},\\\"107\\\":{\\\"Cluster\\\":\\\"Optimization\\\",\\\"Vector\\\":[0.0021581868,0.0171731757,0.0456651805,0.0025488436,0.006697598,0.0066831768,0.0052166164,0.0020229643,0.0201794997,0.0006901522,0.009326013,0.0017453034,0.0042225339,0.0149846561,0.0000566069,0.0040751286,0.0215326967,0.02213074,0.0104525104,0.0154077676]},\\\"108\\\":{\\\"Cluster\\\":\\\"OutOfCoreProcessing\\\",\\\"Vector\\\":[0.0044663003,0.024855162,0.102863071,0.0007966853,0.0294965402,0.0062397683,0.0267403432,0.0498298754,0.0039709281,0.0001088312,0.0005035487,0.0010289696,0.0073916462,0.0014021144,0.0001143609,0.0222694509,0.0098048216,0.0036515555,0.0603086528,0.0043041032]},\\\"109\\\":{\\\"Cluster\\\":\\\"ParallelCoordinates\\\",\\\"Vector\\\":[0.0005921689,0.0193758305,0.0024365309,0.0025965167,0.0196420054,0.0041166819,0.0556140231,0.0068134946,0.0062936679,0.0085272129,0.0016034683,0.0016343826,0.0037170691,0.0070022572,0.0004084608,0.004943386,0.007478623,0.1050813703,0.0054237508,0.0022649978]},\\\"110\\\":{\\\"Cluster\\\":\\\"ParallelSystemsAndParallelProcessing\\\",\\\"Vector\\\":[0.0130598722,0.0151251307,0.0027246157,0,0.014440142,0.0081521138,0.0083541096,0.0234079933,0.0039032177,0.0001475311,0.0028723908,0.0016044057,0.0819966751,0.002469012,0.0014808265,0.0102845791,0.0090940639,0.0069186337,0.0414891543,0.0133902314]},\\\"111\\\":{\\\"Cluster\\\":\\\"Parameterization\\\",\\\"Vector\\\":[0.0008550449,0.0116513703,0.0508697527,0.0007876416,0.0206810819,0.02035427,0.0043578742,0.0045998512,0.0082012524,0.0175542569,0.008106648,0.0064953044,0.0086775828,0.0144130554,0.0540516679,0.0040281401,0.0035798271,0.0219834912,0.0205226027,0.0070176079]},\\\"112\\\":{\\\"Cluster\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"Vector\\\":[0.0005901223,0.0046195174,0.0132886444,0.0242416976,0.0160555966,0.0794660666,0.0169356635,0.011597293,0.0027583542,0.0021720359,0.003267557,0.0008565226,0.0075775505,0.0021248571,0.0081409876,0.2249204811,0.0028799319,0.0027244617,0.0138045302,0.0061266265]},\\\"113\\\":{\\\"Cluster\\\":\\\"PdeSForVisualization\\\",\\\"Vector\\\":[0,0.006226593,0.0253865327,0.0061049328,0.0028556231,0.0100142153,0.0033669222,0.1129740038,0.0312561707,0.0045501164,0.0020696381,0.0020714915,0,0.0024891476,0,0.0343629378,0,0,0,0]},\\\"114\\\":{\\\"Cluster\\\":\\\"Perception\\\",\\\"Vector\\\":[0.0036556396,0.0124571936,0.0054976672,0.0028354242,0.0488707849,0.0091197947,0.0116370628,0.0041852592,0.0168229255,0.0033613707,0.0156437297,0.0022986057,0.013135836,0.0492464946,0.0018036959,0.0127403607,0.0093152528,0.0200458712,0.0201763427,0.0097477708]},\\\"115\\\":{\\\"Cluster\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"Vector\\\":[0.0130464979,0.007069961,0.0157410991,0.0231693134,0.018529182,0.0257678957,0.0030171697,0.0189887184,0.0101383572,0.0017918575,0.0064252943,0.001693368,0.0215550456,0.0144740427,0.00257164,0.0252767853,0.0033258348,0.0122345296,0.0130236614,0.0119813224]},\\\"116\\\":{\\\"Cluster\\\":\\\"PixelOrientedEncodings\\\",\\\"Vector\\\":[0.0010964204,0.0112356032,0.015226284,0.0177050814,0.0314527639,0.0017597294,0.0246715,0.0003917679,0.0024596448,0.0056235206,0.0048494798,0.0053091861,0.0094845337,0.0296096583,0.0002275504,0.0031502076,0.0014058602,0.0417144376,0.0357238739,0.0101257339]},\\\"117\\\":{\\\"Cluster\\\":\\\"PointBasedDataAndTechniques\\\",\\\"Vector\\\":[0.0076596425,0.0204868267,0.0495529982,0.0032155435,0.0079524447,0.0371724037,0.0188619716,0.0460759914,0.0098187155,0.019192992,0.0032745348,0.0015629491,0.0211765887,0.0077842462,0.0024307296,0.0194502901,0.0029084699,0.0070606789,0.0115912142,0.002335577]},\\\"118\\\":{\\\"Cluster\\\":\\\"PresentationProductionAndDissemination\\\",\\\"Vector\\\":[0,0.0119266823,0,0,0,0,0,0,0,0,0,0.028264545,0,0.0313263062,0,0,0.0015059083,0.0426582698,0,0.0430466987]},\\\"119\\\":{\\\"Cluster\\\":\\\"PrivacySecurityIntelligenceAnalysis\\\",\\\"Vector\\\":[0.0001589502,0.0038292363,0.0000225009,0.0040589995,0.0009462282,0.0009170856,0.033682504,0.0017623078,0.0007154673,0.0029061215,0.0054017488,0.080659147,0.0001753681,0.0189107167,0.0003461235,0.0006611114,0.025345685,0.0107919917,0.0053250032,0.0912194748]},\\\"120\\\":{\\\"Cluster\\\":\\\"ProgrammingAlgorithmsAndDataStructures\\\",\\\"Vector\\\":[0.0047728292,0.0266949793,0.0374581446,0.006698568,0.0147231246,0.0145264344,0.0120641451,0.0198890538,0.0080805133,0.0114521941,0.004129293,0.0098477627,0.0120728543,0.0062181195,0.0075095301,0.006384584,0.0169610436,0.0208311294,0.0392935675,0.0068862644]},\\\"121\\\":{\\\"Cluster\\\":\\\"ProvenanceAndHistory\\\",\\\"Vector\\\":[0,0.0458159661,0.0006985969,0.0005032678,0.0044409828,0.0009118232,0.004186006,0.0041504184,0.0036566799,0.0009114736,0.0025766638,0.019234083,0.000049435,0.0668134573,0,0,0.0032812538,0.0214762401,0.0018110708,0.051344279]},\\\"122\\\":{\\\"Cluster\\\":\\\"QualitativeEvaluation\\\",\\\"Vector\\\":[0.0018845837,0.0040815719,0.0008505301,0.0001249661,0.0045763778,0.0029744998,0.0014145066,0.0035896838,0.0162083636,0.0310105189,0.0010926462,0.0327106389,0.0009293636,0.0849679415,0.0083361912,0.0006946891,0.0070810849,0.0039112653,0.001488855,0.0151687913]},\\\"123\\\":{\\\"Cluster\\\":\\\"QuantitativeEvaluation\\\",\\\"Vector\\\":[0.0012512813,0.0042424848,0.0103012781,0.0008379545,0.0008401608,0.0087606721,0.0040050664,0.0019480205,0.0305854795,0.0152863739,0.0036616124,0.0097379136,0.00211412,0.0664901105,0.0040795522,0.0002994439,0.0009475293,0.0397756434,0.0281583007,0.0120581703]},\\\"124\\\":{\\\"Cluster\\\":\\\"QueriesAndSearch\\\",\\\"Vector\\\":[0.0010776928,0.0165259467,0.0023666663,0.0001125249,0.0006130237,0.0005396313,0.0033996663,0.0233974149,0.0024553734,0.0004233957,0.0019969785,0.0217522148,0.003901196,0.0123884747,0.0015463993,0.0013200495,0.0150749043,0.0979155085,0.0095981993,0.0318483739]},\\\"125\\\":{\\\"Cluster\\\":\\\"Ranking\\\",\\\"Vector\\\":[0,0.0266734149,0.0002348834,0,0,0,0.0475720055,0,0,0,0,0,0,0.0003623843,0.0019066009,0,0.1688485144,0.0442165405,0,0]},\\\"126\\\":{\\\"Cluster\\\":\\\"RaytracingRaycasting\\\",\\\"Vector\\\":[0.0061334041,0.0054080054,0.0144098939,0.002833696,0.0324807834,0.0044144542,0.0003712558,0.021252532,0.0204018627,0.0015538721,0.004144734,0.0005511134,0.1325857346,0.0027095123,0.0011864181,0.0232267827,0.0002029841,0.0021593751,0.0063197443,0.0067720039]},\\\"127\\\":{\\\"Cluster\\\":\\\"RealtimeProcessingRenderingAndVisualizationGeneral\\\",\\\"Vector\\\":[0.0019983075,0.0418684227,0.0253130431,0.0094320989,0.0851781743,0.0171719155,0.0020849027,0.0189960312,0.0056507623,0.0008179647,0.0055576768,0.0293987493,0.0118048043,0.0119769177,0,0.0053571965,0.0022046021,0.0107775996,0.0158750454,0.0205818951]},\\\"128\\\":{\\\"Cluster\\\":\\\"ReasoningProblemSolvingAndDecisionMaking\\\",\\\"Vector\\\":[0.0014878596,0.0040848346,0.000454,0.000483069,0.0007681333,0.0055066177,0.0194059864,0.0017459402,0.0006799695,0.0062010017,0,0.0326540206,0.0002976181,0.088985982,0.0002078773,0.0111415918,0.0054596015,0.017036254,0.0030106914,0.0228881462]},\\\"129\\\":{\\\"Cluster\\\":\\\"Rendering\\\",\\\"Vector\\\":[0.0042312513,0.0162542928,0.0495144851,0.0129748162,0.0450474488,0.0088210045,0.0075861915,0.0065765731,0.025621511,0.0010321158,0.0225492749,0.0005733809,0.027816493,0.0038737445,0.0012086598,0.0029166371,0.0066187727,0.0042907908,0.0295942055,0.0042051326]},\\\"130\\\":{\\\"Cluster\\\":\\\"Sampling\\\",\\\"Vector\\\":[0.0025093453,0.0043149812,0.0120336425,0.021490689,0.0234623588,0.0008371269,0.0085894374,0.0246668645,0.017301689,0.0020574791,0.0032342559,0.0025051144,0.0518843362,0.0037625268,0.0047486963,0.0214687584,0.0014577989,0.0180786717,0.0256776413,0.0012616703]},\\\"131\\\":{\\\"Cluster\\\":\\\"ScalarFieldDataTechniques\\\",\\\"Vector\\\":[0.0048743314,0.0332639418,0.0233085703,0.0036366269,0.0012577258,0.0294622798,0.0190358639,0.1436846605,0.0081735688,0.000617837,0.000040938,0.0008413356,0.0155231239,0.0000856707,0,0.0019026849,0.0003844879,0.0013122823,0.0109855628,0.0057458435]},\\\"132\\\":{\\\"Cluster\\\":\\\"SegmentationAndClassification\\\",\\\"Vector\\\":[0.000811389,0.0076180817,0.0243917093,0.0029198008,0.0324009701,0.0061092774,0.0360354302,0.011474587,0.0449194627,0.0153109664,0.0016082945,0.0062405787,0.0180741318,0.0054144249,0.0060053226,0.0048038581,0.0098267552,0.0170101927,0.0093413234,0.0074889027]},\\\"133\\\":{\\\"Cluster\\\":\\\"SemanticsSemioticsRelatedTechniques\\\",\\\"Vector\\\":[0.0004694972,0.0234966707,0.0003208124,0.0010356648,0.0055972195,0.000164939,0.001471106,0.0009170011,0.0226678701,0.0065136147,0,0.046076032,0.0027595781,0.0418171753,0,0,0.0367229315,0.0285899373,0.0048385048,0.0264541892]},\\\"134\\\":{\\\"Cluster\\\":\\\"SensorNetworks\\\",\\\"Vector\\\":[0.0003380234,0,0,0,0.0032245389,0,0,0.0019636192,0.000391917,0,0.0534734751,0,0.0017055847,0.0122871928,0.0017399282,0,0.0214254034,0.0098359338,0,0.2573868104]},\\\"135\\\":{\\\"Cluster\\\":\\\"SetRelatedDataTechniques\\\",\\\"Vector\\\":[0,0.0139785892,0.0050846812,0.0001200873,0,0.0027316466,0.0087908366,0.0031182652,0,0,0,0.0001860106,0.0006040725,0.0987554596,0.0011268031,0,0.0344062087,0,0,0]},\\\"136\\\":{\\\"Cluster\\\":\\\"ShapeRelatedTechniques\\\",\\\"Vector\\\":[0.0036839244,0.0054244735,0.1101086028,0.0045566316,0.0042573253,0.0277119972,0.0072196773,0.0179705957,0.0108742781,0.0014062043,0.0068180533,0.0019558276,0.0053864168,0.0051926848,0.0105773269,0.002654559,0.0006414408,0.0097080192,0.0022500815,0.0030795615]},\\\"137\\\":{\\\"Cluster\\\":\\\"Simulation\\\",\\\"Vector\\\":[0.006463337,0.0065843232,0.0077988558,0.0184739473,0.0094691153,0.0153481506,0.0038039795,0.0076845052,0.0014427885,0.0069177993,0.0226161138,0.0062738065,0.0179860911,0.0224708693,0.0036117895,0.0171203697,0.0121941479,0.0259294626,0.0297955914,0.0094554653]},\\\"138\\\":{\\\"Cluster\\\":\\\"SmallMobileUbiquitousDevicesDisplays\\\",\\\"Vector\\\":[0.000778574,0,0.0003441831,0.0007984463,0.0028670993,0.0058703178,0.0159519031,0.0001037741,0.0008349385,0.0422838954,0.0560822501,0.0149629215,0.0022493445,0.0221846432,0.000467327,0.0030027149,0.0328069092,0.0065765709,0.0176277507,0.0677381389]},\\\"139\\\":{\\\"Cluster\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"Vector\\\":[0.0007620734,0.00745695,0.0012670243,0.0011955917,0.0023471005,0.0023392993,0.0072651682,0.0014279574,0.001952512,0.0013703269,0.0010541242,0.0321787632,0.0026142001,0.0363861152,0.0003523976,0.0015503692,0.0744479585,0.0185540723,0.0036340611,0.0363199029]},\\\"140\\\":{\\\"Cluster\\\":\\\"SocialScienceAndHumanities\\\",\\\"Vector\\\":[0.0002585911,0.0401663988,0.0128584695,0.0010564781,0.0139853681,0.0039108614,0.0047524527,0.0069535286,0.0079771059,0.0015305577,0.0015621262,0.0271340392,0.0043631217,0.0266053186,0.0001690279,0.0019753186,0.0393598164,0.0179051099,0.0040013639,0.0141749604]},\\\"141\\\":{\\\"Cluster\\\":\\\"SoftwareVisualization\\\",\\\"Vector\\\":[0.0020764692,0.0581552023,0.0281040696,0.0006509349,0.005680468,0.0002764307,0.0378243333,0.0060669492,0.0007217181,0.0005288808,0.0032776163,0.0152865585,0.0038021934,0.0215488485,0.000797353,0.0020596405,0.0167083623,0.0402873802,0.0059828885,0.0061536637]},\\\"142\\\":{\\\"Cluster\\\":\\\"SpaceRelatedSpatialDataAndTechniques\\\",\\\"Vector\\\":[0.006445012,0.030058176,0.0119890886,0.001996942,0.0048762223,0.0026300423,0.0212299043,0.0426495535,0.009735183,0.0008102748,0.0039632752,0.0051439742,0.008419868,0.0297073489,0.0004623164,0.0031991865,0.0027904943,0.0178545651,0.0055446274,0.0467096831]},\\\"143\\\":{\\\"Cluster\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"Vector\\\":[0.0011915685,0.0040810882,0.004559209,0.0040987645,0.0083162025,0.0037778049,0.0373101308,0.0047096546,0.0013319511,0.0003465917,0.0074067581,0.0249380199,0.0131253621,0.0250630088,0.0002754875,0.0056143875,0.011148496,0.0115476216,0.0027512456,0.1580682789]},\\\"144\\\":{\\\"Cluster\\\":\\\"SportsVisualization\\\",\\\"Vector\\\":[0.0054546391,0.0012122866,0,0,0.0015459597,0.000052518,0,0,0,0,0.0130130839,0,0.0005006932,0.0060901812,0.0021474192,0.0086401147,0,0,0,0.189785268]},\\\"145\\\":{\\\"Cluster\\\":\\\"StateRelatedDataTechniques\\\",\\\"Vector\\\":[0.0022359888,0.0903061787,0.0025472422,0.0005879124,0.0029518001,0.0024696966,0.0531574438,0,0.0054581378,0,0,0,0,0.0086694432,0.0027104267,0.0012568589,0.0086997304,0.0382647973,0.0297314092,0.0223442777]},\\\"146\\\":{\\\"Cluster\\\":\\\"Storytelling\\\",\\\"Vector\\\":[0.0000109699,0.0010939117,0.000141986,0.0014229635,0.0009439178,0.0035512003,0.0041440357,0.0001926785,0.0017654512,0.0115503597,0.0002828216,0.0472605687,0,0.0376341753,0,0.0007496446,0.0267630858,0.0148040576,0.003869962,0.0738559943]},\\\"147\\\":{\\\"Cluster\\\":\\\"StreamingDataAndTechniques\\\",\\\"Vector\\\":[0.0012826666,0.0011638661,0.0603368348,0.0048896329,0.0505074796,0.003489758,0.0091658878,0.0055971911,0.0307089477,0.002029366,0.002046905,0.0200748168,0.0165551422,0.0004947557,0.0089117615,0.0369176021,0.0024003319,0.0214663833,0.0562583189,0]},\\\"148\\\":{\\\"Cluster\\\":\\\"StreamlinesPathlinesStreaklines\\\",\\\"Vector\\\":[0.0061724951,0.0013792997,0.0094227467,0.0805348711,0.0198586845,0.1393761216,0.0008036218,0.0050665287,0.0046099622,0.0128717587,0.0016071004,0.0008596728,0.0051276876,0.0071965851,0.039371037,0.0188476105,0.0008745845,0.0026141795,0.007000061,0.0016275152]},\\\"149\\\":{\\\"Cluster\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"Vector\\\":[0.0044184933,0.0056633716,0.0773466404,0.0110399458,0.035613303,0.0308547959,0.0047141733,0.0265424207,0.0212082496,0.0016827161,0.0032977456,0.006999144,0.0130402814,0.0085557914,0.0041379046,0.0227038069,0.0017742301,0.0072289221,0.0072065558,0.0033838792]},\\\"150\\\":{\\\"Cluster\\\":\\\"TabularDataAndTechniques\\\",\\\"Vector\\\":[0.0005913567,0.0176122753,0.0010819379,0.0000635534,0.0001723811,0.0106419515,0.0016047849,0.0461676614,0.0045088754,0,0.0009824522,0.0409273278,0.0095988827,0.0042923795,0,0,0.0250914636,0.0581520917,0.0016836266,0]},\\\"151\\\":{\\\"Cluster\\\":\\\"TasksTaskRequirementsAnalysis\\\",\\\"Vector\\\":[0.0012517455,0.0113212988,0.002059197,0.0048002321,0.003521929,0.0037912537,0.0027642384,0.0028979782,0.0018293755,0.0127727216,0.0007832622,0.0350213117,0.0018299224,0.0334218959,0.0000871133,0.002087408,0.0070168956,0.0552720413,0.0038446078,0.0133606983]},\\\"152\\\":{\\\"Cluster\\\":\\\"Taxonomies\\\",\\\"Vector\\\":[0.0019781988,0.0185608582,0.0105794134,0.0046223336,0.0018426721,0.0052366712,0.0110857173,0.0178048498,0.0050148175,0.0027277747,0.0018865387,0.0261052567,0.0022363513,0.0354683929,0.0028220261,0.001502538,0.0139669219,0.0787609259,0.0026740912,0.0143942719]},\\\"153\\\":{\\\"Cluster\\\":\\\"TensorDataAndTechniques\\\",\\\"Vector\\\":[0.0026418927,0.0027998691,0.0059840438,0.1810608743,0.0134539797,0.0184928919,0.009610944,0.0028172331,0.0050755709,0.0032863427,0.0016304559,0.0007008614,0.0042016456,0.0050097647,0.1255004422,0.0270811921,0.0008946348,0.0026899405,0.0081472675,0.0037094363]},\\\"154\\\":{\\\"Cluster\\\":\\\"TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"Vector\\\":[0.000845845,0.0197435079,0.0036678517,0.000849673,0.0015567838,0.0025703941,0.0208907658,0.002744798,0.002337769,0.0029215711,0.0004154247,0.117312101,0.0008279929,0.0136185038,0.0005683184,0.0007200752,0.0236087046,0.0181612033,0.0057193006,0.0332989436]},\\\"155\\\":{\\\"Cluster\\\":\\\"Textures\\\",\\\"Vector\\\":[0.0057290999,0.00608412,0.0292751548,0.0025056344,0.1587516636,0.0361066041,0.0022040369,0.0104662588,0.0098389322,0.0062662786,0.0035996014,0.0010317596,0.0184317961,0.0065070099,0.0087064956,0.0318644068,0.0010832386,0.0043771314,0.0194979095,0.0034579172]},\\\"156\\\":{\\\"Cluster\\\":\\\"TimeCriticalApplications\\\",\\\"Vector\\\":[0.0010137987,0,0.1537502383,0.0003317013,0.0362774174,0,0.0016445782,0,0.0000630583,0.0002406663,0.0109532009,0.000769603,0.0071488246,0.0109209303,0,0,0,0.0036159249,0.2295771085,0.0133843999]},\\\"157\\\":{\\\"Cluster\\\":\\\"TimeseriesTimeVaryingDataAndTechniques\\\",\\\"Vector\\\":[0.0062132951,0.0175488241,0.012763308,0.0023641778,0.0078647665,0.0219714831,0.0158371064,0.0250129657,0.0062690476,0.0043008837,0.0048385847,0.0052818212,0.0088102049,0.0106878421,0.0015528542,0.0135013297,0.0109854223,0.0295721726,0.0238024672,0.0581931671]},\\\"158\\\":{\\\"Cluster\\\":\\\"TopologyBasedTechniques\\\",\\\"Vector\\\":[0.0053717858,0.0133973015,0.052318219,0.0250079132,0.0046126947,0.0586746566,0.0037151741,0.0640711601,0.012868572,0.0011196218,0.0012654447,0.0009654812,0.0025958917,0.0031539009,0.0026963382,0.0040580419,0.005370581,0.0072700267,0.0065776497,0.0025429657]},\\\"159\\\":{\\\"Cluster\\\":\\\"Tractography\\\",\\\"Vector\\\":[0.0003219204,0.0028587417,0.0049772326,0.1151251774,0.0097899883,0.0081997164,0.0248150607,0.0012932041,0.004940894,0.0073261022,0.0009740054,0.0002070343,0.002353163,0.0105173504,0.2786693123,0.0146400984,0.0007303443,0.0031914669,0.0011490955,0.0013947855]},\\\"160\\\":{\\\"Cluster\\\":\\\"Traffic\\\",\\\"Vector\\\":[0.0023196297,0.0078332975,0.0096806158,0.0057528124,0.0100696791,0.0078774867,0.0024803937,0.0005724431,0.0049599613,0.0012451961,0.0243459165,0.0008588465,0.0290630786,0.0402824584,0.0005081742,0.0002540421,0.0061374412,0.0107503649,0.0013321448,0.0560736275]},\\\"161\\\":{\\\"Cluster\\\":\\\"TransitionsAndMorphing\\\",\\\"Vector\\\":[0.0002744217,0.0285952234,0.0059069176,0.0002218258,0.0592263938,0.0057422926,0.0197157274,0.0031674166,0.0027142759,0.0011103513,0.0566577064,0.0018531843,0.0017399398,0.0174196131,0.0007541357,0.0010207971,0.0027386267,0.0265558137,0.0372515661,0.0064336549]},\\\"162\\\":{\\\"Cluster\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"Vector\\\":[0.0041394314,0.0042171258,0.0021168946,0.010234515,0.0071473694,0.0275921367,0.0104805377,0.004156809,0.0168923765,0.1692947697,0.0009113004,0.0032892944,0.0011737666,0.0081107697,0.023854348,0.0105032593,0.0085700438,0.0349271231,0.0030374941,0.0062900528]},\\\"163\\\":{\\\"Cluster\\\":\\\"UsabilityStudies\\\",\\\"Vector\\\":[0,0.0207109086,0.0407266531,0,0,0,0,0,0,0,0,0,0,0.1154222999,0,0,0.0189744242,0.1361084199,0,0]},\\\"164\\\":{\\\"Cluster\\\":\\\"UserInterfacesGeneral\\\",\\\"Vector\\\":[0.0028321368,0.0254067903,0.0069136422,0.0007853627,0.0054286248,0.0070951808,0.0049693713,0.0126612317,0.0103949487,0.000660737,0.0138016735,0.0253343421,0.0041850331,0.0205724578,0.0101303866,0.0023254951,0.0175452561,0.0376335129,0.0071801616,0.0218032778]},\\\"165\\\":{\\\"Cluster\\\":\\\"VectorFieldsDataAndTechniques\\\",\\\"Vector\\\":[0.0016708279,0.0042120018,0.0197545143,0.0168389483,0.0333834786,0.0955872634,0.0161536815,0.020294138,0.0120852378,0.002415338,0.001625671,0.0014668611,0.0078129097,0.0085696894,0.0098556461,0.027411639,0.0019208239,0.0091517494,0.015456535,0.0056014096]},\\\"166\\\":{\\\"Cluster\\\":\\\"ViewDependentVisualization\\\",\\\"Vector\\\":[0.007763829,0.0205865086,0.0991766433,0.0213468559,0.043852485,0.0215501966,0.0350757712,0.0267725521,0.014706968,0.0020747034,0.0118489746,0.0000663252,0.029845793,0.0023413411,0.0014694388,0.0004637095,0.000893943,0.0012005381,0.0070482619,0.0125442915]},\\\"167\\\":{\\\"Cluster\\\":\\\"VisualAnalysisModels\\\",\\\"Vector\\\":[0.0024519193,0.0231153395,0.0022054285,0.0011895138,0,0.0099156272,0.0025057521,0.0074293418,0.0040558471,0.0009828963,0,0.0248100908,0.0010762236,0.0186359227,0,0.0014725285,0.0139101478,0.0737328098,0,0.0175105807]},\\\"168\\\":{\\\"Cluster\\\":\\\"VisualClutterAndItsReduction\\\",\\\"Vector\\\":[0,0.0318169148,0.0433060161,0.0087201313,0.0032296957,0.0420525755,0.0601513215,0.0055742523,0.0092636158,0.0042168187,0.0065603267,0,0.018288361,0.0107866215,0.002379643,0.0015000415,0.0031358939,0.0784579171,0,0]},\\\"169\\\":{\\\"Cluster\\\":\\\"VisualDesignDesignGuidelines\\\",\\\"Vector\\\":[0.0024302443,0.01286327,0.0030865874,0.0005606078,0.0042686825,0.011248961,0.0047258456,0.0044562206,0.0022581198,0.0039659525,0.001865136,0.020772248,0.002422782,0.073896849,0.0014846937,0.0038917091,0.0130492887,0.042353945,0.0072035932,0.0180015551]},\\\"170\\\":{\\\"Cluster\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"Vector\\\":[0.0025933804,0.0510544591,0.0211427888,0.0097699888,0.0057573374,0.0086211956,0.0114008402,0.0086733608,0.0069503261,0.0030406305,0.0027594791,0.0084860709,0.0064193877,0.0371006611,0.0022643593,0.0013101819,0.0101506008,0.0307505288,0.0138939029,0.0150058347]},\\\"171\\\":{\\\"Cluster\\\":\\\"VisualKnowledgeRepresentationAndExternalization\\\",\\\"Vector\\\":[0.00046865,0.0259971255,0.0029482968,0.0007281183,0.0025028559,0.0081234857,0.0030289491,0.0078947294,0.0066371713,0.0012580069,0.0016711812,0.0430913218,0.0054979736,0.0236824913,0.000022192,0.0010562595,0.045099288,0.0229043047,0.0262110599,0.0457792822]},\\\"172\\\":{\\\"Cluster\\\":\\\"VisualPatternFeatureDetectionAndTracking\\\",\\\"Vector\\\":[0.0140797966,0.0055870136,0.0178357784,0.0043546279,0.0035246292,0.0525318395,0.0031168717,0.010609949,0.0085761756,0.0033980284,0.0020679807,0.0085384691,0.0061584228,0.004180864,0.0022138548,0.0105424387,0.0043503497,0.022078872,0.0411498945,0.0329877497]},\\\"173\\\":{\\\"Cluster\\\":\\\"VisualizationSystemsToolkitsAndEnvironments\\\",\\\"Vector\\\":[0.0033094985,0.0218802185,0.0075225483,0.0003915244,0.0104186418,0.021782298,0.0124942025,0.0089501878,0.003106942,0.0046717089,0.0034850981,0.0222160707,0.0059521504,0.0244632224,0.0003732931,0.0152557029,0.0224919955,0.0356676911,0.0110536711,0.0219981481]},\\\"174\\\":{\\\"Cluster\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"Vector\\\":[0.0039088592,0.0139195473,0.0140106592,0.0043865353,0.0137908078,0.0242920778,0.0104985499,0.015371491,0.0093713509,0.0022366737,0.0059208772,0.0143338641,0.0076861609,0.0246267711,0.0013113344,0.0149116353,0.0138758164,0.0265169186,0.0075559706,0.0235583045]},\\\"175\\\":{\\\"Cluster\\\":\\\"VisualizationTheoryModelsAndMethods\\\",\\\"Vector\\\":[0.0050256477,0.0118338371,0.0055730665,0.0024090781,0.0023299751,0.0080170794,0.0075492111,0.0074363451,0.005709771,0.0080946954,0.0023455122,0.0263921992,0.0022014384,0.0559293373,0.0002096684,0.0095653618,0.0150535492,0.0393099255,0.0164382148,0.0107210533]},\\\"176\\\":{\\\"Cluster\\\":\\\"VolumeRenderingModelingAndVisualization\\\",\\\"Vector\\\":[0.0032442173,0.0079047189,0.0180841516,0.0069784596,0.0347690972,0.0098777814,0.0059723325,0.0230101602,0.0417136979,0.0025374402,0.003707232,0.0011762814,0.0439562296,0.004679802,0.0028888422,0.0123578878,0.0039531382,0.0075565524,0.0285630907,0.0065644192]},\\\"177\\\":{\\\"Cluster\\\":\\\"VoronoiBasedTechniques\\\",\\\"Vector\\\":[0.0030527251,0.0313448262,0.0590719496,0.0047246837,0.0045371994,0.0581452093,0.0287899612,0.0297200422,0.0062319635,0.0008274019,0.0006724467,0.0014340124,0.0204230498,0.0007807244,0.0030210882,0.0052318432,0.00016671,0.001184649,0.0113022768,0]},\\\"178\\\":{\\\"Cluster\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"Vector\\\":[0.0072968571,0.0409238709,0.0060837351,0.0022457687,0.0108812014,0.0033287976,0.0120705381,0.0083258395,0.009454162,0.0001592853,0.0175511285,0.0024344628,0.0216476503,0.0267614005,0.0035281069,0.0021010935,0.0174742865,0.0269834985,0.0029864173,0.0208509549]}}\");//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoiLi9kYXRhc2V0cy9jbGFzc2VzLmpzb24uanMiLCJzb3VyY2VzIjpbXSwibWFwcGluZ3MiOiIiLCJzb3VyY2VSb290IjoiIn0=\n//# sourceURL=webpack-internal:///./datasets/classes.json\n");

/***/ }),

/***/ "./datasets/mapping.json":
/*!*******************************!*\
  !*** ./datasets/mapping.json ***!
  \*******************************/
/*! exports provided: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 588, 589, 590, 591, 592, 593, 594, 595, 597, 598, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 615, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 873, 874, 875, 876, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1108, 1109, 1110, 1111, 1112, 1113, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1544, 1545, 1546, 1547, 1548, 1549, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1755, 1756, 1757, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2160, 2161, 2162, 2163, 2164, 2165, 2166, 2167, 2168, 2169, 2170, 2171, 2172, 2174, 2175, 2176, 2177, 2178, 2179, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2187, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210, 2211, 2213, 2214, 2215, 2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2227, 2228, 2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2260, 2261, 2262, 2263, 2264, 2265, 2266, 2267, 2268, 2269, 2270, 2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2281, 2282, 2283, 2284, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407, 2408, 2409, 2410, 2411, 2412, 2413, 2414, 2415, 2416, 2417, 2418, 2419, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2432, 2434, 2435, 2436, 2437, 2438, 2439, 2440, 2441, 2442, 2443, 2444, 2445, 2446, 2447, 2448, 2449, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2460, 2461, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484, 2485, 2486, 2487, 2488, 2489, 2490, 2491, 2492, 2493, 2494, 2495, 2496, 2497, 2498, 2499, 2500, 2501, 2502, 2503, 2504, 2505, 2506, 2507, 2508, 2509, 2510, 2511, 2512, 2513, 2514, 2515, 2516, 2517, 2518, 2519, 2520, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2528, 2529, 2530, 2531, 2532, 2533, 2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2550, 2551, 2552, 2553, 2554, 2555, 2556, 2557, 2558, 2559, 2560, 2561, 2562, 2563, 2564, 2565, 2566, 2567, 2568, 2569, 2570, 2571, 2572, 2573, 2574, 2575, 2576, 2577, 2578, 2579, 2580, 2581, 2582, 2583, 2584, 2585, 2586, 2587, 2588, 2589, 2590, 2591, 2592, 2593, 2594, 2595, 2596, 2597, 2598, 2599, 2600, 2601, 2602, 2603, 2604, 2605, 2606, 2607, 2608, 2609, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2618, 2619, 2620, 2621, 2622, 2623, 2624, 2625, 2626, 2627, 2628, 2629, 2630, 2631, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641, 2642, 2643, 2644, 2645, 2647, 2648, 2649, 2650, 2651, 2652, 2653, 2654, 2655, 2656, 2657, 2658, 2659, 2660, 2661, 2662, 2663, 2664, 2665, 2666, 2667, 2668, 2669, 2670, 2671, 2672, 2673, 2674, 2675, 2676, 2678, 2679, 2680, 2681, 2682, 2683, 2684, 2685, 2686, 2687, 2688, 2689, 2690, 2691, 2692, 2693, 2694, 2695, 2696, 2697, 2698, 2699, 2700, 2701, 2702, 2703, 2704, 2705, 2707, 2708, 2709, 2710, 2711, 2712, 2713, 2714, 2715, 2716, 2717, 2718, 2719, 2720, 2721, 2722, 2723, 2724, 2725, 2726, 2727, 2728, 2729, 2730, 2731, 2732, 2733, 2734, 2735, 2736, 2737, 2738, 2739, 2740, 2741, 2742, 2743, 2744, 2745, 2746, 2747, 2748, 2749, 2750, 2751, 2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759, 2760, 2761, 2762, 2763, 2764, 2765, 2766, 2767, 2768, 2769, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2779, 2780, 2781, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801, 2802, 2803, 2804, 2805, 2806, 2807, 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2821, 2822, 2823, 2824, 2825, 2826, 2827, 2828, 2829, 2830, 2831, 2832, 2833, 2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2842, 2843, 2844, 2846, 2847, 2848, 2849, 2850, 2851, 2852, 2853, 2854, 2855, 2856, 2857, 2858, 2860, 2861, 2862, 2863, 2864, 2865, 2866, 2867, 2868, 2869, 2870, 2871, 2872, 2873, 2874, 2875, 2876, 2877, 2878, 2879, 2881, 2882, 2883, 2884, 2885, 2886, 2887, 2888, 2889, 2890, 2891, 2892, 2893, 2894, 2895, 2896, 2897, 2898, 2899, 2900, 2901, 2902, 2903, 2904, 2905, 2906, 2907, 2908, 2909, 2910, 2911, 2912, 2913, 2914, 2915, 2916, 2917, 2918, 2919, 2920, 2921, 2922, 2923, 2924, 2925, 2926, 2928, 2929, 2930, 2931, 2932, 2933, 2934, 2935, 2936, 2937, 2938, 2939, 2940, 2941, 2942, 2943, 2944, 2945, 2946, 2947, 2948, 2949, 2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2958, 2959, 2960, 2961, 2962, 2963, 2964, 2965, 2966, 2967, 2968, 2969, 2970, 2971, 2972, 2973, 2974, 2975, 2976, 2977, 2978, 2979, 2981, 2982, 2983, 2984, 2986, 2987, 2988, 2989, 2990, 2991, 2992, 2993, 2994, 2995, 2996, 2997, 2998, 2999, 3000, 3001, 3002, 3004, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3031, 3032, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3085, 3086, 3087, 3088, 3089, 3090, 3091, 3092, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100, 3101, 3103, 3104, 3105, 3106, 3107, 3108, 3109, 3111, 3112, 3113, 3114, 3115, 3116, 3117, 3118, 3119, 3121, 3122, 3123, 3124, 3125, 3126, 3127, 3128, 3129, 3130, 3131, 3132, 3133, 3134, 3135, 3136, 3137, 3138, 3139, 3140, 3141, 3142, 3143, 3144, 3145, 3146, 3147, 3148, 3149, 3150, 3151, 3152, 3153, 3154, 3155, 3156, 3157, 3158, 3159, 3160, 3161, 3162, 3163, 3164, 3165, 3166, 3167, 3168, 3169, 3170, 3171, 3172, 3173, 3174, 3175, 3176, 3177, 3178, 3179, 3180, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200, 3201, 3202, 3203, 3204, 3205, 3206, 3208, 3209, 3210, 3211, 3212, 3213, 3214, 3215, 3216, 3217, 3218, 3219, 3220, 3221, 3222, 3223, 3224, 3225, 3226, 3227, 3228, 3229, 3230, 3232, 3233, 3234, 3235, 3236, 3237, 3238, 3239, 3240, 3242, 3243, 3244, 3245, 3246, 3247, 3249, 3250, 3251, 3252, 3253, 3254, 3255, 3256, 3257, 3258, 3259, 3260, 3261, 3262, 3263, 3264, 3265, 3266, 3267, 3268, 3269, 3271, 3272, 3273, 3274, 3275, 3276, 3277, 3278, 3279, 3280, 3281, 3282, 3283, 3284, 3285, 3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294, 3295, 3296, 3297, 3298, 3299, 3300, 3301, 3302, 3303, 3304, 3305, 3306, 3307, 3308, 3309, 3310, 3311, 3313, 3314, 3315, 3316, 3317, 3318, 3319, 3320, 3321, 3322, 3323, 3324, 3325, 3326, 3327, 3328, 3329, 3330, 3331, 3332, 3333, 3334, 3335, 3336, 3337, 3338, 3339, 3340, 3341, 3342, 3343, 3344, 3345, 3346, 3347, 3348, 3349, 3350, 3351, 3352, 3353, 3354, 3355, 3356, 3357, 3358, 3359, 3360, 3361, 3362, 3363, 3364, 3365, 3366, 3367, 3368, 3369, 3370, 3371, 3372, 3373, 3374, 3375, 3376, 3377, 3378, 3379, 3380, 3381, 3382, 3383, 3384, 3385, 3386, 3387, 3388, 3389, 3390, 3391, 3392, 3393, 3394, 3395, 3396, 3397, 3398, 3399, 3400, 3401, 3402, 3403, 3404, 3405, 3406, 3407, 3408, 3409, 3410, 3411, 3412, 3413, 3414, 3415, 3417, 3418, 3419, 3420, 3421, 3422, 3423, 3424, 3425, 3426, 3427, 3428, 3429, 3430, 3431, 3432, 3433, 3434, 3435, 3436, 3437, 3438, 3439, 3440, 3441, 3442, 3443, 3444, 3445, 3446, 3447, 3448, 3449, 3450, 3451, 3452, 3454, 3455, 3456, 3457, 3458, 3459, 3460, 3461, 3462, 3463, 3464, 3465, 3466, 3467, 3468, 3469, 3470, 3471, 3472, 3473, 3475, 3476, 3477, 3479, 3480, 3481, 3483, 3484, 3485, 3486, 3487, 3488, 3489, 3490, 3491, 3492, 3493, 3494, 3495, 3496, 3497, 3498, 3499, 3500, 3501, 3502, 3503, 3504, 3505, 3506, 3507, 3508, 3509, 3510, 3511, 3512, 3513, 3514, 3515, 3516, 3517, 3518, 3519, 3520, 3521, 3522, 3523, 3524, 3525, 3526, 3527, 3528, 3530, 3531, 3532, 3533, 3534, 3535, 3536, 3537, 3538, 3539, 3540, 3541, 3542, 3543, 3544, 3545, 3546, 3547, 3548, 3549, 3550, 3551, 3552, 3553, 3554, 3555, 3556, 3557, 3558, 3559, 3560, 3561, 3562, 3563, 3564, 3565, 3566, 3567, 3568, 3569, 3570, 3571, 3572, 3573, 3574, 3575, 3576, 3577, 3578, 3579, 3580, 3581, 3582, 3584, 3585, 3586, 3587, 3588, 3589, 3590, 3591, 3592, 3593, 3594, 3595, 3596, 3597, 3598, 3599, 3600, 3601, 3602, 3603, 3604, 3605, 3606, 3607, 3608, 3609, 3610, 3611, 3612, 3613, 3614, 3615, 3616, 3617, 3618, 3619, 3620, 3621, 3622, 3623, 3624, 3625, 3626, 3627, 3629, 3630, 3631, 3632, 3633, 3634, 3635, 3636, 3637, 3638, 3639, 3640, 3641, 3642, 3643, 3644, 3645, 3646, 3647, 3648, 3649, 3650, 3651, 3652, 3653, 3654, 3655, 3656, 3657, 3658, 3659, 3660, 3661, 3662, 3663, 3664, 3665, 3666, 3667, 3668, 3669, 3670, 3671, 3672, 3673, 3674, 3675, 3676, 3677, 3678, 3679, 3680, 3681, 3682, 3683, 3684, 3685, 3686, 3687, 3688, 3689, 3690, 3691, 3692, 3693, 3694, 3695, 3696, 3697, 3698, 3699, 3700, 3701, 3702, 3703, 3704, 3705, 3706, 3707, 3708, 3709, 3710, 3711, 3712, 3713, 3714, 3715, 3716, 3717, 3718, 3719, 3720, 3721, 3722, 3723, 3724, 3725, 3726, 3727, 3728, 3729, 3730, 3731, 3732, 3733, 3734, 3735, 3736, 3737, 3738, 3739, 3740, 3741, 3742, 3743, 3744, 3745, 3746, 3747, 3748, 3749, 3750, 3751, 3752, 3753, 3754, 3755, 3756, 3757, 3758, 3759, 3760, 3761, 3762, 3763, 3764, 3765, 3766, 3767, 3768, 3769, 3770, 3771, 3772, 3773, 3774, 3775, 3776, 3777, 3778, 3779, 3780, 3781, 3782, 3783, 3784, 3785, 3786, 3787, 3788, 3789, 3790, 3791, 3792, 3793, 3794, 3795, 3796, 3797, 3798, 3799, 3800, 3801, 3802, 3803, 3804, 3805, 3806, 3807, 3808, 3809, 3810, 3811, 3812, 3813, 3815, 3816, 3817, 3818, 3819, 3820, 3821, 3822, 3823, 3824, 3825, 3826, 3827, 3828, 3829, 3830, 3831, 3832, 3833, 3834, 3835, 3836, 3837, 3839, 3840, 3841, 3842, 3843, 3844, 3845, 3846, 3847, 3848, 3849, 3850, 3851, 3852, 3853, 3854, 3855, 3856, 3857, 3858, 3859, 3860, 3861, 3862, 3863, 3864, 3865, 3866, 3868, 3869, 3870, 3871, 3872, 3873, 3874, 3875, 3876, 3877, 3878, 3879, 3880, 3881, 3882, 3883, 3884, 3885, 3886, 3887, 3888, 3890, 3891, 3892, 3893, 3894, 3895, 3896, 3897, 3898, 3899, 3900, 3901, 3902, 3903, 3904, 3905, 3906, 3907, 3908, 3909, 3910, 3911, 3912, 3913, 3914, 3915, 3916, 3917, 3918, 3919, 3920, 3921, 3922, 3923, 3924, 3925, 3926, 3927, 3928, 3929, 3930, 3931, 3932, 3933, 3934, 3935, 3936, 3937, 3938, 3939, 3940, 3941, 3942, 3943, 3944, 3945, 3946, 3947, 3948, 3949, 3950, 3951, default */
/***/ (function(module) {

eval("module.exports = JSON.parse(\"{\\\"0\\\":{\\\"AuthorKeyword\\\":\\\"2d\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"1\\\":{\\\"AuthorKeyword\\\":\\\"2d and 3d visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"2\\\":{\\\"AuthorKeyword\\\":\\\"2d graphic\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"3\\\":{\\\"AuthorKeyword\\\":\\\"2d projection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"4\\\":{\\\"AuthorKeyword\\\":\\\"2d vector field\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"5\\\":{\\\"AuthorKeyword\\\":\\\"2d visualization method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"6\\\":{\\\"AuthorKeyword\\\":\\\"3d\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"7\\\":{\\\"AuthorKeyword\\\":\\\"3d acquisition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"8\\\":{\\\"AuthorKeyword\\\":\\\"3d data exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"9\\\":{\\\"AuthorKeyword\\\":\\\"3d flow visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"10\\\":{\\\"AuthorKeyword\\\":\\\"3d freehand ultrasound\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"11\\\":{\\\"AuthorKeyword\\\":\\\"3d geometry compression\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"12\\\":{\\\"AuthorKeyword\\\":\\\"3d glyph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"13\\\":{\\\"AuthorKeyword\\\":\\\"3d graphic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"14\\\":{\\\"AuthorKeyword\\\":\\\"3d image processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"15\\\":{\\\"AuthorKeyword\\\":\\\"3d information visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"16\\\":{\\\"AuthorKeyword\\\":\\\"3d input device\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"17\\\":{\\\"AuthorKeyword\\\":\\\"3d interaction\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"18\\\":{\\\"AuthorKeyword\\\":\\\"3d map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"19\\\":{\\\"AuthorKeyword\\\":\\\"3d medical imaging\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"20\\\":{\\\"AuthorKeyword\\\":\\\"3d navigation and exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"21\\\":{\\\"AuthorKeyword\\\":\\\"3d painting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ArtAndAestheticsInVisualization\\\",\\\"ExpertKeywordCount\\\":16},\\\"22\\\":{\\\"AuthorKeyword\\\":\\\"3d reconstruction\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"23\\\":{\\\"AuthorKeyword\\\":\\\"3d scalar field\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ScalarFieldData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"24\\\":{\\\"AuthorKeyword\\\":\\\"3d shape analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ShapeRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"25\\\":{\\\"AuthorKeyword\\\":\\\"3d shape perception\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"26\\\":{\\\"AuthorKeyword\\\":\\\"3d texture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"27\\\":{\\\"AuthorKeyword\\\":\\\"3d texture base volume render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"28\\\":{\\\"AuthorKeyword\\\":\\\"3d texture mapping\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"29\\\":{\\\"AuthorKeyword\\\":\\\"3d ultrasound\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"30\\\":{\\\"AuthorKeyword\\\":\\\"3d user interface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"31\\\":{\\\"AuthorKeyword\\\":\\\"3d vector field datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"32\\\":{\\\"AuthorKeyword\\\":\\\"3d vector field visualization\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"33\\\":{\\\"AuthorKeyword\\\":\\\"3d vector field\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"34\\\":{\\\"AuthorKeyword\\\":\\\"3d virtual environment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"35\\\":{\\\"AuthorKeyword\\\":\\\"3d visualization\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"36\\\":{\\\"AuthorKeyword\\\":\\\"3d widget\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"37\\\":{\\\"AuthorKeyword\\\":\\\"3d ray compute tomography\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"38\\\":{\\\"AuthorKeyword\\\":\\\"4d\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"39\\\":{\\\"AuthorKeyword\\\":\\\"4d mri blood flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"40\\\":{\\\"AuthorKeyword\\\":\\\"4d pc mri\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"41\\\":{\\\"AuthorKeyword\\\":\\\"4d space time\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"42\\\":{\\\"AuthorKeyword\\\":\\\"4d visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"43\\\":{\\\"AuthorKeyword\\\":\\\"dof haptic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"44\\\":{\\\"AuthorKeyword\\\":\\\"aberration of light\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"46\\\":{\\\"AuthorKeyword\\\":\\\"acceleration technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"47\\\":{\\\"AuthorKeyword\\\":\\\"accessibility\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"48\\\":{\\\"AuthorKeyword\\\":\\\"accuracy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationMetricsAndBenchmarks\\\",\\\"ExpertKeywordCount\\\":19},\\\"49\\\":{\\\"AuthorKeyword\\\":\\\"acoustic imaging\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Acoustics,Sound,Sonification\\\",\\\"ExpertKeywordCount\\\":9},\\\"50\\\":{\\\"AuthorKeyword\\\":\\\"acoustic metric\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Acoustics,Sound,Sonification\\\",\\\"ExpertKeywordCount\\\":9},\\\"51\\\":{\\\"AuthorKeyword\\\":\\\"acoustic propagation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Acoustics,Sound,Sonification\\\",\\\"ExpertKeywordCount\\\":9},\\\"52\\\":{\\\"AuthorKeyword\\\":\\\"acoustic simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Acoustics,Sound,Sonification\\\",\\\"ExpertKeywordCount\\\":9},\\\"53\\\":{\\\"AuthorKeyword\\\":\\\"acoustic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Acoustics,Sound,Sonification\\\",\\\"ExpertKeywordCount\\\":9},\\\"54\\\":{\\\"AuthorKeyword\\\":\\\"active learning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"55\\\":{\\\"AuthorKeyword\\\":\\\"active network measurement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"56\\\":{\\\"AuthorKeyword\\\":\\\"active processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"57\\\":{\\\"AuthorKeyword\\\":\\\"activity sculpture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ArtAndAestheticsInVisualization\\\",\\\"ExpertKeywordCount\\\":16},\\\"58\\\":{\\\"AuthorKeyword\\\":\\\"adaptive fast forward\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"59\\\":{\\\"AuthorKeyword\\\":\\\"adaptive filtering\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"60\\\":{\\\"AuthorKeyword\\\":\\\"adaptive integration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataRegistration,Fusion,AndIntegration\\\",\\\"ExpertKeywordCount\\\":14},\\\"61\\\":{\\\"AuthorKeyword\\\":\\\"adaptive isosurface extraction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"62\\\":{\\\"AuthorKeyword\\\":\\\"adaptive mesh refinement\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"AdaptiveProcessingAndRefinement\\\",\\\"ExpertKeywordCount\\\":19},\\\"63\\\":{\\\"AuthorKeyword\\\":\\\"adaptive mesh refinement datum\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"64\\\":{\\\"AuthorKeyword\\\":\\\"adaptive mesh\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"65\\\":{\\\"AuthorKeyword\\\":\\\"adaptive refinement\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"AdaptiveProcessingAndRefinement\\\",\\\"ExpertKeywordCount\\\":19},\\\"66\\\":{\\\"AuthorKeyword\\\":\\\"adaptive rendering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"67\\\":{\\\"AuthorKeyword\\\":\\\"adaptive sampling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Sampling\\\",\\\"ExpertKeywordCount\\\":23},\\\"68\\\":{\\\"AuthorKeyword\\\":\\\"adaptive streamline\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"69\\\":{\\\"AuthorKeyword\\\":\\\"adaptive tessellation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AdaptiveProcessingAndRefinement\\\",\\\"ExpertKeywordCount\\\":19},\\\"70\\\":{\\\"AuthorKeyword\\\":\\\"adaptive texture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"71\\\":{\\\"AuthorKeyword\\\":\\\"adaptive tree visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"72\\\":{\\\"AuthorKeyword\\\":\\\"adaptive user interface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"73\\\":{\\\"AuthorKeyword\\\":\\\"adaptive wavelet\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AdaptiveProcessingAndRefinement\\\",\\\"ExpertKeywordCount\\\":19},\\\"74\\\":{\\\"AuthorKeyword\\\":\\\"adjacency matrix\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"MatrixRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":13},\\\"75\\\":{\\\"AuthorKeyword\\\":\\\"advanced illumination\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"76\\\":{\\\"AuthorKeyword\\\":\\\"advance front\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"77\\\":{\\\"AuthorKeyword\\\":\\\"advection\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"78\\\":{\\\"AuthorKeyword\\\":\\\"aesthetic\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ArtAndAestheticsInVisualization\\\",\\\"ExpertKeywordCount\\\":16},\\\"79\\\":{\\\"AuthorKeyword\\\":\\\"affective and mood modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"81\\\":{\\\"AuthorKeyword\\\":\\\"agent\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"82\\\":{\\\"AuthorKeyword\\\":\\\"aggregate\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"83\\\":{\\\"AuthorKeyword\\\":\\\"aggregate visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"84\\\":{\\\"AuthorKeyword\\\":\\\"aggregate datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"85\\\":{\\\"AuthorKeyword\\\":\\\"aggregation\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"86\\\":{\\\"AuthorKeyword\\\":\\\"air pollution\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"87\\\":{\\\"AuthorKeyword\\\":\\\"ajax\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"88\\\":{\\\"AuthorKeyword\\\":\\\"algebraic multigrid\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"89\\\":{\\\"AuthorKeyword\\\":\\\"algorithm\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"90\\\":{\\\"AuthorKeyword\\\":\\\"algorithm animation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"91\\\":{\\\"AuthorKeyword\\\":\\\"alignment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"92\\\":{\\\"AuthorKeyword\\\":\\\"alleviate occlusion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"OcclusionProblems/techniques\\\",\\\"ExpertKeywordCount\\\":15},\\\"93\\\":{\\\"AuthorKeyword\\\":\\\"alternative clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"94\\\":{\\\"AuthorKeyword\\\":\\\"ambient display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AmbientVisualization\\\",\\\"ExpertKeywordCount\\\":4},\\\"95\\\":{\\\"AuthorKeyword\\\":\\\"ambient information visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"AmbientVisualization\\\",\\\"ExpertKeywordCount\\\":4},\\\"96\\\":{\\\"AuthorKeyword\\\":\\\"ambient occlusion\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"97\\\":{\\\"AuthorKeyword\\\":\\\"ambient scattering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"98\\\":{\\\"AuthorKeyword\\\":\\\"ambient visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AmbientVisualization\\\",\\\"ExpertKeywordCount\\\":4},\\\"99\\\":{\\\"AuthorKeyword\\\":\\\"amino acid\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"100\\\":{\\\"AuthorKeyword\\\":\\\"analog method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataTransformation\\\",\\\"ExpertKeywordCount\\\":19},\\\"101\\\":{\\\"AuthorKeyword\\\":\\\"analogy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"102\\\":{\\\"AuthorKeyword\\\":\\\"analysis\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"103\\\":{\\\"AuthorKeyword\\\":\\\"analysis guide exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"104\\\":{\\\"AuthorKeyword\\\":\\\"analytic activity\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"105\\\":{\\\"AuthorKeyword\\\":\\\"analytic environment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"106\\\":{\\\"AuthorKeyword\\\":\\\"analytic function\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"107\\\":{\\\"AuthorKeyword\\\":\\\"analytic gap\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"108\\\":{\\\"AuthorKeyword\\\":\\\"analytic provenance\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"ProvenanceAndHistory\\\",\\\"ExpertKeywordCount\\\":15},\\\"109\\\":{\\\"AuthorKeyword\\\":\\\"analytic reasoning\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"110\\\":{\\\"AuthorKeyword\\\":\\\"anamorphosis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"111\\\":{\\\"AuthorKeyword\\\":\\\"anatomic structure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"112\\\":{\\\"AuthorKeyword\\\":\\\"anesthesia\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"113\\\":{\\\"AuthorKeyword\\\":\\\"aneurysm\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"114\\\":{\\\"AuthorKeyword\\\":\\\"angular histogram\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"115\\\":{\\\"AuthorKeyword\\\":\\\"animal behavior\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"116\\\":{\\\"AuthorKeyword\\\":\\\"animate graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"117\\\":{\\\"AuthorKeyword\\\":\\\"animate lic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"118\\\":{\\\"AuthorKeyword\\\":\\\"animate transition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TransitionsAndMorphing\\\",\\\"ExpertKeywordCount\\\":8},\\\"119\\\":{\\\"AuthorKeyword\\\":\\\"animation\\\",\\\"AuthorKeywordCount\\\":19,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"120\\\":{\\\"AuthorKeyword\\\":\\\"anisotropic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"121\\\":{\\\"AuthorKeyword\\\":\\\"anisotropic diffusion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DiffusionRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":11},\\\"122\\\":{\\\"AuthorKeyword\\\":\\\"anisotropic filtering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"123\\\":{\\\"AuthorKeyword\\\":\\\"anisotropic lighting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"124\\\":{\\\"AuthorKeyword\\\":\\\"anisotropic sampling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Sampling\\\",\\\"ExpertKeywordCount\\\":23},\\\"125\\\":{\\\"AuthorKeyword\\\":\\\"anisotropic shading\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"126\\\":{\\\"AuthorKeyword\\\":\\\"anisotropic tensor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"127\\\":{\\\"AuthorKeyword\\\":\\\"anisotropy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"128\\\":{\\\"AuthorKeyword\\\":\\\"annotation\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Labeling\\\",\\\"ExpertKeywordCount\\\":10},\\\"129\\\":{\\\"AuthorKeyword\\\":\\\"anomalous trichromacy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"130\\\":{\\\"AuthorKeyword\\\":\\\"anomaly detection\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"Events,Trends,OutlierDetection,Analysis,AndVisualization\\\",\\\"ExpertKeywordCount\\\":23},\\\"131\\\":{\\\"AuthorKeyword\\\":\\\"ant colony optimization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"132\\\":{\\\"AuthorKeyword\\\":\\\"antialiase\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"133\\\":{\\\"AuthorKeyword\\\":\\\"antisymmetric\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"134\\\":{\\\"AuthorKeyword\\\":\\\"antisymmetric tensor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"135\\\":{\\\"AuthorKeyword\\\":\\\"appearance preserve\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"136\\\":{\\\"AuthorKeyword\\\":\\\"application of information visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"137\\\":{\\\"AuthorKeyword\\\":\\\"application of visualization\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"138\\\":{\\\"AuthorKeyword\\\":\\\"application of volume graphic and volume visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"139\\\":{\\\"AuthorKeyword\\\":\\\"apply machine learning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"140\\\":{\\\"AuthorKeyword\\\":\\\"apply perception\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"141\\\":{\\\"AuthorKeyword\\\":\\\"approximation\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"AdaptiveProcessingAndRefinement\\\",\\\"ExpertKeywordCount\\\":19},\\\"142\\\":{\\\"AuthorKeyword\\\":\\\"arbitrary topology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"143\\\":{\\\"AuthorKeyword\\\":\\\"arc diagram\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"144\\\":{\\\"AuthorKeyword\\\":\\\"archaeological datum analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"145\\\":{\\\"AuthorKeyword\\\":\\\"archaeology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"146\\\":{\\\"AuthorKeyword\\\":\\\"architectural lighting design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"147\\\":{\\\"AuthorKeyword\\\":\\\"architectural walkthrough\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"148\\\":{\\\"AuthorKeyword\\\":\\\"architecture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"149\\\":{\\\"AuthorKeyword\\\":\\\"area preservation mapping\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"150\\\":{\\\"AuthorKeyword\\\":\\\"area preserve map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"151\\\":{\\\"AuthorKeyword\\\":\\\"area preserve surface parameterization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"152\\\":{\\\"AuthorKeyword\\\":\\\"argumentation marshalling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"153\\\":{\\\"AuthorKeyword\\\":\\\"art\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ArtAndAestheticsInVisualization\\\",\\\"ExpertKeywordCount\\\":16},\\\"154\\\":{\\\"AuthorKeyword\\\":\\\"artificial intelligence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"155\\\":{\\\"AuthorKeyword\\\":\\\"artificial life\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"156\\\":{\\\"AuthorKeyword\\\":\\\"artificial neural network\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"157\\\":{\\\"AuthorKeyword\\\":\\\"aspect ratio\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"159\\\":{\\\"AuthorKeyword\\\":\\\"assembly maintenance simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"160\\\":{\\\"AuthorKeyword\\\":\\\"association analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"161\\\":{\\\"AuthorKeyword\\\":\\\"astronomical datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Astronomy/Astrophysics\\\",\\\"ExpertKeywordCount\\\":17},\\\"162\\\":{\\\"AuthorKeyword\\\":\\\"astronomical visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Astronomy/Astrophysics\\\",\\\"ExpertKeywordCount\\\":17},\\\"163\\\":{\\\"AuthorKeyword\\\":\\\"astronomy\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"Astronomy/Astrophysics\\\",\\\"ExpertKeywordCount\\\":17},\\\"164\\\":{\\\"AuthorKeyword\\\":\\\"astrophysical visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Astronomy/Astrophysics\\\",\\\"ExpertKeywordCount\\\":17},\\\"165\\\":{\\\"AuthorKeyword\\\":\\\"astrophysic\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Astronomy/Astrophysics\\\",\\\"ExpertKeywordCount\\\":17},\\\"166\\\":{\\\"AuthorKeyword\\\":\\\"asymmetric tensor field\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"167\\\":{\\\"AuthorKeyword\\\":\\\"asynchronous collaboration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"168\\\":{\\\"AuthorKeyword\\\":\\\"atlas\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"169\\\":{\\\"AuthorKeyword\\\":\\\"atomic collision\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"170\\\":{\\\"AuthorKeyword\\\":\\\"atomic force microscopy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Microscopy\\\",\\\"ExpertKeywordCount\\\":11},\\\"171\\\":{\\\"AuthorKeyword\\\":\\\"atomistic simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"172\\\":{\\\"AuthorKeyword\\\":\\\"attention\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"173\\\":{\\\"AuthorKeyword\\\":\\\"attentionally ambient visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AmbientVisualization\\\",\\\"ExpertKeywordCount\\\":4},\\\"174\\\":{\\\"AuthorKeyword\\\":\\\"attribute drive layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"175\\\":{\\\"AuthorKeyword\\\":\\\"attribute calculation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"176\\\":{\\\"AuthorKeyword\\\":\\\"attribute curve\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"177\\\":{\\\"AuthorKeyword\\\":\\\"attribute extraction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"178\\\":{\\\"AuthorKeyword\\\":\\\"attribute filtering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"179\\\":{\\\"AuthorKeyword\\\":\\\"attribute inference\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"180\\\":{\\\"AuthorKeyword\\\":\\\"attribute ranking\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Ranking\\\",\\\"ExpertKeywordCount\\\":5},\\\"181\\\":{\\\"AuthorKeyword\\\":\\\"attribute relationship graphs\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"182\\\":{\\\"AuthorKeyword\\\":\\\"augmented reality\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"183\\\":{\\\"AuthorKeyword\\\":\\\"augment timeline\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"184\\\":{\\\"AuthorKeyword\\\":\\\"auralization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Acoustics,Sound,Sonification\\\",\\\"ExpertKeywordCount\\\":9},\\\"185\\\":{\\\"AuthorKeyword\\\":\\\"author environment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"186\\\":{\\\"AuthorKeyword\\\":\\\"autism\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NeurosciencesAndBrainVisualization\\\",\\\"ExpertKeywordCount\\\":17},\\\"187\\\":{\\\"AuthorKeyword\\\":\\\"auto calibration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"188\\\":{\\\"AuthorKeyword\\\":\\\"auto completion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"189\\\":{\\\"AuthorKeyword\\\":\\\"autoignition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"190\\\":{\\\"AuthorKeyword\\\":\\\"automate cartography\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"191\\\":{\\\"AuthorKeyword\\\":\\\"automate design of graphical display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AutomaticAnalysis/VisualizationTechniques\\\",\\\"ExpertKeywordCount\\\":10},\\\"192\\\":{\\\"AuthorKeyword\\\":\\\"automate generation of visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AutomaticAnalysis/VisualizationTechniques\\\",\\\"ExpertKeywordCount\\\":10},\\\"193\\\":{\\\"AuthorKeyword\\\":\\\"automate visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AutomaticAnalysis/VisualizationTechniques\\\",\\\"ExpertKeywordCount\\\":10},\\\"194\\\":{\\\"AuthorKeyword\\\":\\\"automatic alignment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AutomaticAnalysis/VisualizationTechniques\\\",\\\"ExpertKeywordCount\\\":10},\\\"195\\\":{\\\"AuthorKeyword\\\":\\\"automatic camera control\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"196\\\":{\\\"AuthorKeyword\\\":\\\"automatic expansion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AutomaticAnalysis/VisualizationTechniques\\\",\\\"ExpertKeywordCount\\\":10},\\\"197\\\":{\\\"AuthorKeyword\\\":\\\"automatic geometric alignment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"198\\\":{\\\"AuthorKeyword\\\":\\\"automatic label placement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Labeling\\\",\\\"ExpertKeywordCount\\\":10},\\\"199\\\":{\\\"AuthorKeyword\\\":\\\"automatic layout algorithm\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"AutomaticAnalysis/VisualizationTechniques\\\",\\\"ExpertKeywordCount\\\":10},\\\"200\\\":{\\\"AuthorKeyword\\\":\\\"automatic lighting design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"201\\\":{\\\"AuthorKeyword\\\":\\\"automatic optimization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Optimization\\\",\\\"ExpertKeywordCount\\\":19},\\\"202\\\":{\\\"AuthorKeyword\\\":\\\"automatic presentation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"AutomaticAnalysis/VisualizationTechniques\\\",\\\"ExpertKeywordCount\\\":10},\\\"203\\\":{\\\"AuthorKeyword\\\":\\\"automatic presentation system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AutomaticAnalysis/VisualizationTechniques\\\",\\\"ExpertKeywordCount\\\":10},\\\"204\\\":{\\\"AuthorKeyword\\\":\\\"automatic web service\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"205\\\":{\\\"AuthorKeyword\\\":\\\"automotive\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Engineering\\\",\\\"ExpertKeywordCount\\\":12},\\\"206\\\":{\\\"AuthorKeyword\\\":\\\"automotive industry\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Engineering\\\",\\\"ExpertKeywordCount\\\":12},\\\"207\\\":{\\\"AuthorKeyword\\\":\\\"autopsy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"208\\\":{\\\"AuthorKeyword\\\":\\\"autostereoscopic display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"209\\\":{\\\"AuthorKeyword\\\":\\\"autostereoscopy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"210\\\":{\\\"AuthorKeyword\\\":\\\"awareness\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"211\\\":{\\\"AuthorKeyword\\\":\\\"axis labeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Labeling\\\",\\\"ExpertKeywordCount\\\":10},\\\"212\\\":{\\\"AuthorKeyword\\\":\\\"backchannel\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"213\\\":{\\\"AuthorKeyword\\\":\\\"band depth\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"214\\\":{\\\"AuthorKeyword\\\":\\\"bandwidth limited resource\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"215\\\":{\\\"AuthorKeyword\\\":\\\"banking to 45 degree\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"216\\\":{\\\"AuthorKeyword\\\":\\\"bar chart\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"217\\\":{\\\"AuthorKeyword\\\":\\\"bard\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"218\\\":{\\\"AuthorKeyword\\\":\\\"barrier tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"219\\\":{\\\"AuthorKeyword\\\":\\\"barycentric coordinate\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"220\\\":{\\\"AuthorKeyword\\\":\\\"base rate fallacy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"221\\\":{\\\"AuthorKeyword\\\":\\\"baseball\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SportsVisualization\\\",\\\"ExpertKeywordCount\\\":5},\\\"222\\\":{\\\"AuthorKeyword\\\":\\\"baseball metric\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SportsVisualization\\\",\\\"ExpertKeywordCount\\\":5},\\\"223\\\":{\\\"AuthorKeyword\\\":\\\"basis function\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"224\\\":{\\\"AuthorKeyword\\\":\\\"bayesian method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"225\\\":{\\\"AuthorKeyword\\\":\\\"bayesian reasoning\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"226\\\":{\\\"AuthorKeyword\\\":\\\"behavioral change\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"227\\\":{\\\"AuthorKeyword\\\":\\\"bernstein bezi technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"228\\\":{\\\"AuthorKeyword\\\":\\\"bertin\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"229\\\":{\\\"AuthorKeyword\\\":\\\"good practice\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"230\\\":{\\\"AuthorKeyword\\\":\\\"betti number\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"231\\\":{\\\"AuthorKeyword\\\":\\\"betweenness centrality\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"232\\\":{\\\"AuthorKeyword\\\":\\\"bezi surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"233\\\":{\\\"AuthorKeyword\\\":\\\"bias\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"234\\\":{\\\"AuthorKeyword\\\":\\\"bias field\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"235\\\":{\\\"AuthorKeyword\\\":\\\"bibliographic datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"236\\\":{\\\"AuthorKeyword\\\":\\\"bicluster\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"237\\\":{\\\"AuthorKeyword\\\":\\\"bifurcation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"238\\\":{\\\"AuthorKeyword\\\":\\\"big datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"239\\\":{\\\"AuthorKeyword\\\":\\\"bikeshare\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"240\\\":{\\\"AuthorKeyword\\\":\\\"binary space partitioning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"241\\\":{\\\"AuthorKeyword\\\":\\\"binary space partitioning tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"242\\\":{\\\"AuthorKeyword\\\":\\\"binary triangle tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"243\\\":{\\\"AuthorKeyword\\\":\\\"bioinformatic\\\",\\\"AuthorKeywordCount\\\":9,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"244\\\":{\\\"AuthorKeyword\\\":\\\"bioinformatic visualization\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"245\\\":{\\\"AuthorKeyword\\\":\\\"biological datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"246\\\":{\\\"AuthorKeyword\\\":\\\"biological network\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"247\\\":{\\\"AuthorKeyword\\\":\\\"biological visualization\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"248\\\":{\\\"AuthorKeyword\\\":\\\"biology\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"249\\\":{\\\"AuthorKeyword\\\":\\\"biomechanic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"250\\\":{\\\"AuthorKeyword\\\":\\\"biomedical\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"251\\\":{\\\"AuthorKeyword\\\":\\\"biomedical and medical visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"252\\\":{\\\"AuthorKeyword\\\":\\\"biomedical image processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"253\\\":{\\\"AuthorKeyword\\\":\\\"biomedical image segmentation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"254\\\":{\\\"AuthorKeyword\\\":\\\"biomedical imaging\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"255\\\":{\\\"AuthorKeyword\\\":\\\"biomedical visualization\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"257\\\":{\\\"AuthorKeyword\\\":\\\"bitmap index\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"258\\\":{\\\"AuthorKeyword\\\":\\\"bivariate map\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"259\\\":{\\\"AuthorKeyword\\\":\\\"blend\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TransitionsAndMorphing\\\",\\\"ExpertKeywordCount\\\":8},\\\"260\\\":{\\\"AuthorKeyword\\\":\\\"blobby clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"261\\\":{\\\"AuthorKeyword\\\":\\\"blobby model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"262\\\":{\\\"AuthorKeyword\\\":\\\"blog\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"263\\\":{\\\"AuthorKeyword\\\":\\\"blood damage\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"264\\\":{\\\"AuthorKeyword\\\":\\\"blood flow\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"265\\\":{\\\"AuthorKeyword\\\":\\\"blood vessel detection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"266\\\":{\\\"AuthorKeyword\\\":\\\"blood vessel\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"267\\\":{\\\"AuthorKeyword\\\":\\\"blur\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"268\\\":{\\\"AuthorKeyword\\\":\\\"body center cubic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"269\\\":{\\\"AuthorKeyword\\\":\\\"body center cubic grid\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"270\\\":{\\\"AuthorKeyword\\\":\\\"body center cubic lattice\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"271\\\":{\\\"AuthorKeyword\\\":\\\"boid\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"272\\\":{\\\"AuthorKeyword\\\":\\\"book index\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"274\\\":{\\\"AuthorKeyword\\\":\\\"boolean operation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"275\\\":{\\\"AuthorKeyword\\\":\\\"boolean query\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"276\\\":{\\\"AuthorKeyword\\\":\\\"botanical tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"277\\\":{\\\"AuthorKeyword\\\":\\\"boundary change\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"278\\\":{\\\"AuthorKeyword\\\":\\\"boundary improvement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"279\\\":{\\\"AuthorKeyword\\\":\\\"bound uncertainty\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"280\\\":{\\\"AuthorKeyword\\\":\\\"bound space\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"281\\\":{\\\"AuthorKeyword\\\":\\\"box spline\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"282\\\":{\\\"AuthorKeyword\\\":\\\"boxplot\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"283\\\":{\\\"AuthorKeyword\\\":\\\"bracket\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"284\\\":{\\\"AuthorKeyword\\\":\\\"braid graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"285\\\":{\\\"AuthorKeyword\\\":\\\"brain\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"286\\\":{\\\"AuthorKeyword\\\":\\\"breast cancer\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"287\\\":{\\\"AuthorKeyword\\\":\\\"brightness matching\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"288\\\":{\\\"AuthorKeyword\\\":\\\"broadcast video analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"289\\\":{\\\"AuthorKeyword\\\":\\\"bronchial tube\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"290\\\":{\\\"AuthorKeyword\\\":\\\"browse\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"291\\\":{\\\"AuthorKeyword\\\":\\\"brush\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"292\\\":{\\\"AuthorKeyword\\\":\\\"brush and linking\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"293\\\":{\\\"AuthorKeyword\\\":\\\"bubble scale simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"294\\\":{\\\"AuthorKeyword\\\":\\\"bull eye plot\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"295\\\":{\\\"AuthorKeyword\\\":\\\"business ecosystem\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Business,Finance,Economy,Manufacturing\\\",\\\"ExpertKeywordCount\\\":12},\\\"296\\\":{\\\"AuthorKeyword\\\":\\\"business graphic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Business,Finance,Economy,Manufacturing\\\",\\\"ExpertKeywordCount\\\":12},\\\"297\\\":{\\\"AuthorKeyword\\\":\\\"business intelligence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Business,Finance,Economy,Manufacturing\\\",\\\"ExpertKeywordCount\\\":12},\\\"298\\\":{\\\"AuthorKeyword\\\":\\\"aperture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Microscopy\\\",\\\"ExpertKeywordCount\\\":11},\\\"299\\\":{\\\"AuthorKeyword\\\":\\\"\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"300\\\":{\\\"AuthorKeyword\\\":\\\"cache aware and cache oblivious layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"301\\\":{\\\"AuthorKeyword\\\":\\\"cache coherent layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"302\\\":{\\\"AuthorKeyword\\\":\\\"cache\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"303\\\":{\\\"AuthorKeyword\\\":\\\"cad\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"304\\\":{\\\"AuthorKeyword\\\":\\\"cad cam\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"305\\\":{\\\"AuthorKeyword\\\":\\\"calendar\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"306\\\":{\\\"AuthorKeyword\\\":\\\"calibration\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"307\\\":{\\\"AuthorKeyword\\\":\\\"call matrix\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MatrixRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":13},\\\"308\\\":{\\\"AuthorKeyword\\\":\\\"calm technology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"309\\\":{\\\"AuthorKeyword\\\":\\\"camera base registration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataRegistration,Fusion,AndIntegration\\\",\\\"ExpertKeywordCount\\\":14},\\\"310\\\":{\\\"AuthorKeyword\\\":\\\"camera base registration and calibration\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"311\\\":{\\\"AuthorKeyword\\\":\\\"camera projector system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"312\\\":{\\\"AuthorKeyword\\\":\\\"camera control\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"313\\\":{\\\"AuthorKeyword\\\":\\\"camera model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"314\\\":{\\\"AuthorKeyword\\\":\\\"camera motion planning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"315\\\":{\\\"AuthorKeyword\\\":\\\"camera planning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"316\\\":{\\\"AuthorKeyword\\\":\\\"cancer\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"317\\\":{\\\"AuthorKeyword\\\":\\\"cancer datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"318\\\":{\\\"AuthorKeyword\\\":\\\"capture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"319\\\":{\\\"AuthorKeyword\\\":\\\"car navigation system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"320\\\":{\\\"AuthorKeyword\\\":\\\"carbon fiber reinforce polymer\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"321\\\":{\\\"AuthorKeyword\\\":\\\"cardiac blood flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"322\\\":{\\\"AuthorKeyword\\\":\\\"cardiac mri\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"323\\\":{\\\"AuthorKeyword\\\":\\\"cardiac visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"324\\\":{\\\"AuthorKeyword\\\":\\\"cartesian grid\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"325\\\":{\\\"AuthorKeyword\\\":\\\"cartogram\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"326\\\":{\\\"AuthorKeyword\\\":\\\"cartographic labeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Labeling\\\",\\\"ExpertKeywordCount\\\":10},\\\"327\\\":{\\\"AuthorKeyword\\\":\\\"cartography\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"328\\\":{\\\"AuthorKeyword\\\":\\\"carve\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"329\\\":{\\\"AuthorKeyword\\\":\\\"case study\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"DesignStudiesAndCaseStudies\\\",\\\"ExpertKeywordCount\\\":28},\\\"330\\\":{\\\"AuthorKeyword\\\":\\\"casual information visualization\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"331\\\":{\\\"AuthorKeyword\\\":\\\"casual visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"332\\\":{\\\"AuthorKeyword\\\":\\\"categorial and time vary datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CategoricalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"333\\\":{\\\"AuthorKeyword\\\":\\\"categorical color\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"334\\\":{\\\"AuthorKeyword\\\":\\\"categorical datum\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"CategoricalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"335\\\":{\\\"AuthorKeyword\\\":\\\"categorical visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CategoricalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"336\\\":{\\\"AuthorKeyword\\\":\\\"categorization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"337\\\":{\\\"AuthorKeyword\\\":\\\"catmull clark\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"338\\\":{\\\"AuthorKeyword\\\":\\\"causal relation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HypothesisForming,Testing,AndVisualEvidence\\\",\\\"ExpertKeywordCount\\\":7},\\\"339\\\":{\\\"AuthorKeyword\\\":\\\"causality\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DynamicVisualization,VisualizationOfChange\\\",\\\"ExpertKeywordCount\\\":14},\\\"340\\\":{\\\"AuthorKeyword\\\":\\\"cave application\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"341\\\":{\\\"AuthorKeyword\\\":\\\"cavity analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"342\\\":{\\\"AuthorKeyword\\\":\\\"cell\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"343\\\":{\\\"AuthorKeyword\\\":\\\"cell image\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"344\\\":{\\\"AuthorKeyword\\\":\\\"cell location\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"345\\\":{\\\"AuthorKeyword\\\":\\\"cell migration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"346\\\":{\\\"AuthorKeyword\\\":\\\"cell projection\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"347\\\":{\\\"AuthorKeyword\\\":\\\"cell\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"348\\\":{\\\"AuthorKeyword\\\":\\\"censor regression\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"349\\\":{\\\"AuthorKeyword\\\":\\\"centerline\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"350\\\":{\\\"AuthorKeyword\\\":\\\"centerline base modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"351\\\":{\\\"AuthorKeyword\\\":\\\"centrality\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAndAnalysisMetrics\\\",\\\"ExpertKeywordCount\\\":11},\\\"352\\\":{\\\"AuthorKeyword\\\":\\\"centroidal voronoi tessellation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VoronoiBasedTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"353\\\":{\\\"AuthorKeyword\\\":\\\"cerebral aneurysm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"354\\\":{\\\"AuthorKeyword\\\":\\\"cerebral blood vessel\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"355\\\":{\\\"AuthorKeyword\\\":\\\"change detection\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DynamicVisualization,VisualizationOfChange\\\",\\\"ExpertKeywordCount\\\":14},\\\"356\\\":{\\\"AuthorKeyword\\\":\\\"change management\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DynamicVisualization,VisualizationOfChange\\\",\\\"ExpertKeywordCount\\\":14},\\\"357\\\":{\\\"AuthorKeyword\\\":\\\"chaos\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"358\\\":{\\\"AuthorKeyword\\\":\\\"characteristic viewpoint estimation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"359\\\":{\\\"AuthorKeyword\\\":\\\"cie lab\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"360\\\":{\\\"AuthorKeyword\\\":\\\"circular coordinate\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"361\\\":{\\\"AuthorKeyword\\\":\\\"city block\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"362\\\":{\\\"AuthorKeyword\\\":\\\"classification\\\",\\\"AuthorKeywordCount\\\":18,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"363\\\":{\\\"AuthorKeyword\\\":\\\"class\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"364\\\":{\\\"AuthorKeyword\\\":\\\"client server\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DistributedSystemsAndGridEnvironments\\\",\\\"ExpertKeywordCount\\\":16},\\\"365\\\":{\\\"AuthorKeyword\\\":\\\"climate change\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"366\\\":{\\\"AuthorKeyword\\\":\\\"climate impact research\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"367\\\":{\\\"AuthorKeyword\\\":\\\"climate model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"368\\\":{\\\"AuthorKeyword\\\":\\\"climate modeling\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"369\\\":{\\\"AuthorKeyword\\\":\\\"climate study\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"370\\\":{\\\"AuthorKeyword\\\":\\\"climate variability change visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"371\\\":{\\\"AuthorKeyword\\\":\\\"clinical diagnosis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"372\\\":{\\\"AuthorKeyword\\\":\\\"clinical evaluation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"373\\\":{\\\"AuthorKeyword\\\":\\\"clipping\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"374\\\":{\\\"AuthorKeyword\\\":\\\"close packing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"375\\\":{\\\"AuthorKeyword\\\":\\\"closed streamline\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"376\\\":{\\\"AuthorKeyword\\\":\\\"cloud\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"377\\\":{\\\"AuthorKeyword\\\":\\\"cluster base visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"378\\\":{\\\"AuthorKeyword\\\":\\\"cluster analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"379\\\":{\\\"AuthorKeyword\\\":\\\"cluster comparison\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"380\\\":{\\\"AuthorKeyword\\\":\\\"cluster detection analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"381\\\":{\\\"AuthorKeyword\\\":\\\"cluster ensemble\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"382\\\":{\\\"AuthorKeyword\\\":\\\"cluster glyph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"383\\\":{\\\"AuthorKeyword\\\":\\\"cluster render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"384\\\":{\\\"AuthorKeyword\\\":\\\"cluster visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"385\\\":{\\\"AuthorKeyword\\\":\\\"cluster datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"386\\\":{\\\"AuthorKeyword\\\":\\\"clustering\\\",\\\"AuthorKeywordCount\\\":32,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"387\\\":{\\\"AuthorKeyword\\\":\\\"cluster algorithm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"388\\\":{\\\"AuthorKeyword\\\":\\\"cluster high dimensional datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"389\\\":{\\\"AuthorKeyword\\\":\\\"cluster metric\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"390\\\":{\\\"AuthorKeyword\\\":\\\"clustering validation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"391\\\":{\\\"AuthorKeyword\\\":\\\"cluster\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"392\\\":{\\\"AuthorKeyword\\\":\\\"clutter\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualClutterAndItsReduction\\\",\\\"ExpertKeywordCount\\\":5},\\\"393\\\":{\\\"AuthorKeyword\\\":\\\"clutter reduction\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualClutterAndItsReduction\\\",\\\"ExpertKeywordCount\\\":5},\\\"394\\\":{\\\"AuthorKeyword\\\":\\\"co citation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"395\\\":{\\\"AuthorKeyword\\\":\\\"co citation network\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"396\\\":{\\\"AuthorKeyword\\\":\\\"co locate work\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"397\\\":{\\\"AuthorKeyword\\\":\\\"co occurrence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MatrixRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":13},\\\"398\\\":{\\\"AuthorKeyword\\\":\\\"coarea formula\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"399\\\":{\\\"AuthorKeyword\\\":\\\"coastal observatory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"400\\\":{\\\"AuthorKeyword\\\":\\\"coast\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"401\\\":{\\\"AuthorKeyword\\\":\\\"code\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"402\\\":{\\\"AuthorKeyword\\\":\\\"code\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"403\\\":{\\\"AuthorKeyword\\\":\\\"cognition\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"404\\\":{\\\"AuthorKeyword\\\":\\\"cognition and perception theory\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"405\\\":{\\\"AuthorKeyword\\\":\\\"cognition theory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"406\\\":{\\\"AuthorKeyword\\\":\\\"cognitive model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"407\\\":{\\\"AuthorKeyword\\\":\\\"cognitive efficiency\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"408\\\":{\\\"AuthorKeyword\\\":\\\"cognitive theory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"409\\\":{\\\"AuthorKeyword\\\":\\\"coherent structure\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"410\\\":{\\\"AuthorKeyword\\\":\\\"cohort definition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"411\\\":{\\\"AuthorKeyword\\\":\\\"collaboration\\\",\\\"AuthorKeywordCount\\\":14,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"412\\\":{\\\"AuthorKeyword\\\":\\\"collaborative and distribute visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"413\\\":{\\\"AuthorKeyword\\\":\\\"collaborative development\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"414\\\":{\\\"AuthorKeyword\\\":\\\"collaborative learning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"415\\\":{\\\"AuthorKeyword\\\":\\\"collaborative thinking space\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"416\\\":{\\\"AuthorKeyword\\\":\\\"collaborative visualization\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"417\\\":{\\\"AuthorKeyword\\\":\\\"collage\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ArtAndAestheticsInVisualization\\\",\\\"ExpertKeywordCount\\\":16},\\\"418\\\":{\\\"AuthorKeyword\\\":\\\"collective intelligence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"419\\\":{\\\"AuthorKeyword\\\":\\\"collective movement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"420\\\":{\\\"AuthorKeyword\\\":\\\"collision detection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"421\\\":{\\\"AuthorKeyword\\\":\\\"collision probability\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"422\\\":{\\\"AuthorKeyword\\\":\\\"colon flatten\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"423\\\":{\\\"AuthorKeyword\\\":\\\"color\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"424\\\":{\\\"AuthorKeyword\\\":\\\"color contrast enhancement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"425\\\":{\\\"AuthorKeyword\\\":\\\"color vision deficiency\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"426\\\":{\\\"AuthorKeyword\\\":\\\"color blending\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"427\\\":{\\\"AuthorKeyword\\\":\\\"color calibration\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"428\\\":{\\\"AuthorKeyword\\\":\\\"color design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"429\\\":{\\\"AuthorKeyword\\\":\\\"color map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"430\\\":{\\\"AuthorKeyword\\\":\\\"color matching\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"431\\\":{\\\"AuthorKeyword\\\":\\\"color mixing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"432\\\":{\\\"AuthorKeyword\\\":\\\"color mri\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"433\\\":{\\\"AuthorKeyword\\\":\\\"color name\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"434\\\":{\\\"AuthorKeyword\\\":\\\"color perception\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"435\\\":{\\\"AuthorKeyword\\\":\\\"color scale\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"436\\\":{\\\"AuthorKeyword\\\":\\\"color scheme\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"437\\\":{\\\"AuthorKeyword\\\":\\\"color transfer\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"438\\\":{\\\"AuthorKeyword\\\":\\\"color weaving\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"439\\\":{\\\"AuthorKeyword\\\":\\\"color\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"440\\\":{\\\"AuthorKeyword\\\":\\\"colorization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"441\\\":{\\\"AuthorKeyword\\\":\\\"colormappe\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"442\\\":{\\\"AuthorKeyword\\\":\\\"colormaps\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"443\\\":{\\\"AuthorKeyword\\\":\\\"columbia river\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"444\\\":{\\\"AuthorKeyword\\\":\\\"combination\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"445\\\":{\\\"AuthorKeyword\\\":\\\"combinatorial topology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"446\\\":{\\\"AuthorKeyword\\\":\\\"combustion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"447\\\":{\\\"AuthorKeyword\\\":\\\"common rail injection system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Engineering\\\",\\\"ExpertKeywordCount\\\":12},\\\"448\\\":{\\\"AuthorKeyword\\\":\\\"communication minded visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"449\\\":{\\\"AuthorKeyword\\\":\\\"community\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"450\\\":{\\\"AuthorKeyword\\\":\\\"community detection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AlgorithmicPattern/featureDetection/tracking\\\",\\\"ExpertKeywordCount\\\":49},\\\"451\\\":{\\\"AuthorKeyword\\\":\\\"compact disc tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"452\\\":{\\\"AuthorKeyword\\\":\\\"comparative\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"453\\\":{\\\"AuthorKeyword\\\":\\\"comparative analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"454\\\":{\\\"AuthorKeyword\\\":\\\"comparative genomic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"455\\\":{\\\"AuthorKeyword\\\":\\\"comparative visualization\\\",\\\"AuthorKeywordCount\\\":14,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"456\\\":{\\\"AuthorKeyword\\\":\\\"comparison\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"457\\\":{\\\"AuthorKeyword\\\":\\\"comparison measure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"458\\\":{\\\"AuthorKeyword\\\":\\\"compensate linear vector dipole\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"459\\\":{\\\"AuthorKeyword\\\":\\\"complex logarithm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"460\\\":{\\\"AuthorKeyword\\\":\\\"complexity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"461\\\":{\\\"AuthorKeyword\\\":\\\"composite indicator visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"462\\\":{\\\"AuthorKeyword\\\":\\\"composite material\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"463\\\":{\\\"AuthorKeyword\\\":\\\"composite visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"464\\\":{\\\"AuthorKeyword\\\":\\\"compositing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"465\\\":{\\\"AuthorKeyword\\\":\\\"compound graph\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"466\\\":{\\\"AuthorKeyword\\\":\\\"compress volume render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"467\\\":{\\\"AuthorKeyword\\\":\\\"compression\\\",\\\"AuthorKeywordCount\\\":9,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"468\\\":{\\\"AuthorKeyword\\\":\\\"compression algorithm\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"469\\\":{\\\"AuthorKeyword\\\":\\\"compression for visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"470\\\":{\\\"AuthorKeyword\\\":\\\"computational aesthetic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ArtAndAestheticsInVisualization\\\",\\\"ExpertKeywordCount\\\":16},\\\"471\\\":{\\\"AuthorKeyword\\\":\\\"computational biology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"472\\\":{\\\"AuthorKeyword\\\":\\\"computational cartography\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"473\\\":{\\\"AuthorKeyword\\\":\\\"computational fluid dynamic\\\",\\\"AuthorKeywordCount\\\":10,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"474\\\":{\\\"AuthorKeyword\\\":\\\"computational geography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"475\\\":{\\\"AuthorKeyword\\\":\\\"computational geometry\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"GeometryBasedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"476\\\":{\\\"AuthorKeyword\\\":\\\"computational geometry and object modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"477\\\":{\\\"AuthorKeyword\\\":\\\"computational journalism\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"478\\\":{\\\"AuthorKeyword\\\":\\\"computational linguisitic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"479\\\":{\\\"AuthorKeyword\\\":\\\"computational science\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"480\\\":{\\\"AuthorKeyword\\\":\\\"computational steering\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"481\\\":{\\\"AuthorKeyword\\\":\\\"computational topology\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"482\\\":{\\\"AuthorKeyword\\\":\\\"compute tomography\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"483\\\":{\\\"AuthorKeyword\\\":\\\"compute tomography angiography\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"484\\\":{\\\"AuthorKeyword\\\":\\\"compute tomography colonography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"485\\\":{\\\"AuthorKeyword\\\":\\\"computer aid design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"486\\\":{\\\"AuthorKeyword\\\":\\\"computer aid detection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"487\\\":{\\\"AuthorKeyword\\\":\\\"computer aid diagnosis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"488\\\":{\\\"AuthorKeyword\\\":\\\"computer aid surgery\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"489\\\":{\\\"AuthorKeyword\\\":\\\"computer assist medical illustration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IllustrativeVisualization\\\",\\\"ExpertKeywordCount\\\":40},\\\"490\\\":{\\\"AuthorKeyword\\\":\\\"computer assist multi variate datum exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"491\\\":{\\\"AuthorKeyword\\\":\\\"computer assist reporting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"492\\\":{\\\"AuthorKeyword\\\":\\\"computer generate hologram\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"493\\\":{\\\"AuthorKeyword\\\":\\\"computer human interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"494\\\":{\\\"AuthorKeyword\\\":\\\"computer support cooperative work\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"495\\\":{\\\"AuthorKeyword\\\":\\\"computer graphic\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"496\\\":{\\\"AuthorKeyword\\\":\\\"computer system visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"497\\\":{\\\"AuthorKeyword\\\":\\\"computer vision\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"498\\\":{\\\"AuthorKeyword\\\":\\\"computer vision and scene understanding\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"499\\\":{\\\"AuthorKeyword\\\":\\\"concept design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"500\\\":{\\\"AuthorKeyword\\\":\\\"concept map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualKnowledgeRepresentationAndExternalization\\\",\\\"ExpertKeywordCount\\\":13},\\\"501\\\":{\\\"AuthorKeyword\\\":\\\"conceptual model\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"502\\\":{\\\"AuthorKeyword\\\":\\\"concordance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"503\\\":{\\\"AuthorKeyword\\\":\\\"concrete scale\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiScaleData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"504\\\":{\\\"AuthorKeyword\\\":\\\"concurrent visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"505\\\":{\\\"AuthorKeyword\\\":\\\"conditional distribution\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"506\\\":{\\\"AuthorKeyword\\\":\\\"conditional entropy\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"InformationTheory\\\",\\\"ExpertKeywordCount\\\":12},\\\"507\\\":{\\\"AuthorKeyword\\\":\\\"conditional simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"508\\\":{\\\"AuthorKeyword\\\":\\\"conditioning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"509\\\":{\\\"AuthorKeyword\\\":\\\"confidence map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"510\\\":{\\\"AuthorKeyword\\\":\\\"confine magnetic fusion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"511\\\":{\\\"AuthorKeyword\\\":\\\"confocal microscopy\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Microscopy\\\",\\\"ExpertKeywordCount\\\":11},\\\"512\\\":{\\\"AuthorKeyword\\\":\\\"conformal\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"513\\\":{\\\"AuthorKeyword\\\":\\\"conformal mapping\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"514\\\":{\\\"AuthorKeyword\\\":\\\"confusion analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"515\\\":{\\\"AuthorKeyword\\\":\\\"confusion matrix\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"516\\\":{\\\"AuthorKeyword\\\":\\\"conjoint analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"517\\\":{\\\"AuthorKeyword\\\":\\\"conjunctive normal form\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"518\\\":{\\\"AuthorKeyword\\\":\\\"connected morphological operator\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"519\\\":{\\\"AuthorKeyword\\\":\\\"connectome\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NeurosciencesAndBrainVisualization\\\",\\\"ExpertKeywordCount\\\":17},\\\"520\\\":{\\\"AuthorKeyword\\\":\\\"connectomic\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"NeurosciencesAndBrainVisualization\\\",\\\"ExpertKeywordCount\\\":17},\\\"521\\\":{\\\"AuthorKeyword\\\":\\\"connotation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"522\\\":{\\\"AuthorKeyword\\\":\\\"consensus\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"523\\\":{\\\"AuthorKeyword\\\":\\\"constrain clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"524\\\":{\\\"AuthorKeyword\\\":\\\"constrain delaunay triangulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"525\\\":{\\\"AuthorKeyword\\\":\\\"constrain least square\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"526\\\":{\\\"AuthorKeyword\\\":\\\"constrain navigation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"527\\\":{\\\"AuthorKeyword\\\":\\\"constrain optimization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Optimization\\\",\\\"ExpertKeywordCount\\\":19},\\\"528\\\":{\\\"AuthorKeyword\\\":\\\"constraint\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"529\\\":{\\\"AuthorKeyword\\\":\\\"constructive solid geometry\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"530\\\":{\\\"AuthorKeyword\\\":\\\"constructive visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"531\\\":{\\\"AuthorKeyword\\\":\\\"consumer graphic hardware\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"532\\\":{\\\"AuthorKeyword\\\":\\\"contact\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"533\\\":{\\\"AuthorKeyword\\\":\\\"contagion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"534\\\":{\\\"AuthorKeyword\\\":\\\"content actor network datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"535\\\":{\\\"AuthorKeyword\\\":\\\"content aware\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"536\\\":{\\\"AuthorKeyword\\\":\\\"context\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"537\\\":{\\\"AuthorKeyword\\\":\\\"context aware selection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"538\\\":{\\\"AuthorKeyword\\\":\\\"context of use\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"539\\\":{\\\"AuthorKeyword\\\":\\\"contextualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"540\\\":{\\\"AuthorKeyword\\\":\\\"contextualized video\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"541\\\":{\\\"AuthorKeyword\\\":\\\"contiguity constraint\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"543\\\":{\\\"AuthorKeyword\\\":\\\"continuous frequency plot\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"544\\\":{\\\"AuthorKeyword\\\":\\\"continuous interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"545\\\":{\\\"AuthorKeyword\\\":\\\"continuous reconstruction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"546\\\":{\\\"AuthorKeyword\\\":\\\"continuum mechanic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Engineering\\\",\\\"ExpertKeywordCount\\\":12},\\\"547\\\":{\\\"AuthorKeyword\\\":\\\"contour datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Contour/Creases/Ridges/Valleys\\\",\\\"ExpertKeywordCount\\\":17},\\\"548\\\":{\\\"AuthorKeyword\\\":\\\"contour diagram\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Contour/Creases/Ridges/Valleys\\\",\\\"ExpertKeywordCount\\\":17},\\\"549\\\":{\\\"AuthorKeyword\\\":\\\"contour interpolation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"550\\\":{\\\"AuthorKeyword\\\":\\\"contour map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Contour/Creases/Ridges/Valleys\\\",\\\"ExpertKeywordCount\\\":17},\\\"551\\\":{\\\"AuthorKeyword\\\":\\\"contour surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"552\\\":{\\\"AuthorKeyword\\\":\\\"contour tree\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"553\\\":{\\\"AuthorKeyword\\\":\\\"contour\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"Contour/Creases/Ridges/Valleys\\\",\\\"ExpertKeywordCount\\\":17},\\\"554\\\":{\\\"AuthorKeyword\\\":\\\"contract base system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"555\\\":{\\\"AuthorKeyword\\\":\\\"control volume vaporization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"556\\\":{\\\"AuthorKeyword\\\":\\\"control density streamline\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"557\\\":{\\\"AuthorKeyword\\\":\\\"control laboratory user study\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LaboratoryStudies\\\",\\\"ExpertKeywordCount\\\":3},\\\"558\\\":{\\\"AuthorKeyword\\\":\\\"controversy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Storytelling\\\",\\\"ExpertKeywordCount\\\":10},\\\"560\\\":{\\\"AuthorKeyword\\\":\\\"conversation analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"561\\\":{\\\"AuthorKeyword\\\":\\\"conversation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"562\\\":{\\\"AuthorKeyword\\\":\\\"convolution\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"563\\\":{\\\"AuthorKeyword\\\":\\\"convolution base differentiation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"564\\\":{\\\"AuthorKeyword\\\":\\\"cool jacket\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"565\\\":{\\\"AuthorKeyword\\\":\\\"cooperative design and modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"566\\\":{\\\"AuthorKeyword\\\":\\\"coordinate multiple view\\\",\\\"AuthorKeywordCount\\\":18,\\\"ExpertKeyword\\\":\\\"MultipleLinked/coordinatedViews\\\",\\\"ExpertKeywordCount\\\":50},\\\"567\\\":{\\\"AuthorKeyword\\\":\\\"coordinate link view\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultipleLinked/coordinatedViews\\\",\\\"ExpertKeywordCount\\\":50},\\\"568\\\":{\\\"AuthorKeyword\\\":\\\"coordinated query\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"569\\\":{\\\"AuthorKeyword\\\":\\\"coordinated relationship\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"570\\\":{\\\"AuthorKeyword\\\":\\\"coordinated view\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"MultipleLinked/coordinatedViews\\\",\\\"ExpertKeywordCount\\\":50},\\\"571\\\":{\\\"AuthorKeyword\\\":\\\"coordination\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"572\\\":{\\\"AuthorKeyword\\\":\\\"coronal hole extraction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Astronomy/Astrophysics\\\",\\\"ExpertKeywordCount\\\":17},\\\"573\\\":{\\\"AuthorKeyword\\\":\\\"coronal mass ejection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"574\\\":{\\\"AuthorKeyword\\\":\\\"coronary artery territory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"575\\\":{\\\"AuthorKeyword\\\":\\\"corpus visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"576\\\":{\\\"AuthorKeyword\\\":\\\"correlation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"577\\\":{\\\"AuthorKeyword\\\":\\\"correlation analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"578\\\":{\\\"AuthorKeyword\\\":\\\"correlation measure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAndAnalysisMetrics\\\",\\\"ExpertKeywordCount\\\":11},\\\"579\\\":{\\\"AuthorKeyword\\\":\\\"correspondence analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"580\\\":{\\\"AuthorKeyword\\\":\\\"cortical feature\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"581\\\":{\\\"AuthorKeyword\\\":\\\"cosmology\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Astronomy/Astrophysics\\\",\\\"ExpertKeywordCount\\\":17},\\\"582\\\":{\\\"AuthorKeyword\\\":\\\"coverage tracking\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"583\\\":{\\\"AuthorKeyword\\\":\\\"crack propagation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"584\\\":{\\\"AuthorKeyword\\\":\\\"crease extraction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Contour/Creases/Ridges/Valleys\\\",\\\"ExpertKeywordCount\\\":17},\\\"585\\\":{\\\"AuthorKeyword\\\":\\\"crease feature\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Contour/Creases/Ridges/Valleys\\\",\\\"ExpertKeywordCount\\\":17},\\\"586\\\":{\\\"AuthorKeyword\\\":\\\"creativity technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"588\\\":{\\\"AuthorKeyword\\\":\\\"critical event\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Events,Trends,OutlierDetection,Analysis,AndVisualization\\\",\\\"ExpertKeywordCount\\\":23},\\\"589\\\":{\\\"AuthorKeyword\\\":\\\"critical infrastructure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"590\\\":{\\\"AuthorKeyword\\\":\\\"critical point theory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"591\\\":{\\\"AuthorKeyword\\\":\\\"critical point\\\",\\\"AuthorKeywordCount\\\":9,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"592\\\":{\\\"AuthorKeyword\\\":\\\"cross slit image\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"593\\\":{\\\"AuthorKeyword\\\":\\\"crosset\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SetRelatedData&Techniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"594\\\":{\\\"AuthorKeyword\\\":\\\"cross\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"595\\\":{\\\"AuthorKeyword\\\":\\\"crowdsourced study\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"597\\\":{\\\"AuthorKeyword\\\":\\\"cull\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"598\\\":{\\\"AuthorKeyword\\\":\\\"cultural collection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"600\\\":{\\\"AuthorKeyword\\\":\\\"curse of dimensionality\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"601\\\":{\\\"AuthorKeyword\\\":\\\"curvature\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"602\\\":{\\\"AuthorKeyword\\\":\\\"curvature estimation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"603\\\":{\\\"AuthorKeyword\\\":\\\"curve centric reformation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"604\\\":{\\\"AuthorKeyword\\\":\\\"curve skeleton\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"605\\\":{\\\"AuthorKeyword\\\":\\\"curve surface solid and object representation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"606\\\":{\\\"AuthorKeyword\\\":\\\"curve interpolation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"607\\\":{\\\"AuthorKeyword\\\":\\\"curve edge\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"608\\\":{\\\"AuthorKeyword\\\":\\\"curve planar reformation\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"609\\\":{\\\"AuthorKeyword\\\":\\\"curve ray\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Raytracing/raycasting\\\",\\\"ExpertKeywordCount\\\":32},\\\"610\\\":{\\\"AuthorKeyword\\\":\\\"curve section\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"611\\\":{\\\"AuthorKeyword\\\":\\\"curve\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"612\\\":{\\\"AuthorKeyword\\\":\\\"curve and surface\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"613\\\":{\\\"AuthorKeyword\\\":\\\"curvilinear grid\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"615\\\":{\\\"AuthorKeyword\\\":\\\"cut plane\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CuttingPlanes\\\",\\\"ExpertKeywordCount\\\":3},\\\"617\\\":{\\\"AuthorKeyword\\\":\\\"cut\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CuttingPlanes\\\",\\\"ExpertKeywordCount\\\":3},\\\"618\\\":{\\\"AuthorKeyword\\\":\\\"cut plane\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CuttingPlanes\\\",\\\"ExpertKeywordCount\\\":3},\\\"619\\\":{\\\"AuthorKeyword\\\":\\\"cybersecurity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Privacy,Security,IntelligenceAnalysis\\\",\\\"ExpertKeywordCount\\\":16},\\\"620\\\":{\\\"AuthorKeyword\\\":\\\"dark matter\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Astronomy/Astrophysics\\\",\\\"ExpertKeywordCount\\\":17},\\\"621\\\":{\\\"AuthorKeyword\\\":\\\"dashboard\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"622\\\":{\\\"AuthorKeyword\\\":\\\"datum drive magnification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"623\\\":{\\\"AuthorKeyword\\\":\\\"datum flow\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"624\\\":{\\\"AuthorKeyword\\\":\\\"datum flow paradigm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"625\\\":{\\\"AuthorKeyword\\\":\\\"datum parallel visualization pipeline\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"626\\\":{\\\"AuthorKeyword\\\":\\\"datum abstraction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"627\\\":{\\\"AuthorKeyword\\\":\\\"datum abstraction quality metric\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationMetricsAndBenchmarks\\\",\\\"ExpertKeywordCount\\\":19},\\\"628\\\":{\\\"AuthorKeyword\\\":\\\"datum acquisition and management\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"629\\\":{\\\"AuthorKeyword\\\":\\\"datum aggregation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"630\\\":{\\\"AuthorKeyword\\\":\\\"datum analysis\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"631\\\":{\\\"AuthorKeyword\\\":\\\"datum and knowledge visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualKnowledgeRepresentationAndExternalization\\\",\\\"ExpertKeywordCount\\\":13},\\\"632\\\":{\\\"AuthorKeyword\\\":\\\"datum and provenance tracking\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ProvenanceAndHistory\\\",\\\"ExpertKeywordCount\\\":15},\\\"633\\\":{\\\"AuthorKeyword\\\":\\\"datum assimilation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataRegistration,Fusion,AndIntegration\\\",\\\"ExpertKeywordCount\\\":14},\\\"634\\\":{\\\"AuthorKeyword\\\":\\\"datum cleaning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataCleaningAndSmoothing\\\",\\\"ExpertKeywordCount\\\":5},\\\"635\\\":{\\\"AuthorKeyword\\\":\\\"datum cleaning and integration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataCleaningAndSmoothing\\\",\\\"ExpertKeywordCount\\\":5},\\\"636\\\":{\\\"AuthorKeyword\\\":\\\"datum clustering\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"637\\\":{\\\"AuthorKeyword\\\":\\\"data compression\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"639\\\":{\\\"AuthorKeyword\\\":\\\"data density\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"640\\\":{\\\"AuthorKeyword\\\":\\\"data depth\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"641\\\":{\\\"AuthorKeyword\\\":\\\"datum editing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataEditing\\\",\\\"ExpertKeywordCount\\\":3},\\\"642\\\":{\\\"AuthorKeyword\\\":\\\"datum exploration\\\",\\\"AuthorKeywordCount\\\":11,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"643\\\":{\\\"AuthorKeyword\\\":\\\"datum filtering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"644\\\":{\\\"AuthorKeyword\\\":\\\"data flow network\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"645\\\":{\\\"AuthorKeyword\\\":\\\"datum fusion\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataRegistration,Fusion,AndIntegration\\\",\\\"ExpertKeywordCount\\\":14},\\\"646\\\":{\\\"AuthorKeyword\\\":\\\"datum integration\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"647\\\":{\\\"AuthorKeyword\\\":\\\"datum locality\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"648\\\":{\\\"AuthorKeyword\\\":\\\"data management\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"649\\\":{\\\"AuthorKeyword\\\":\\\"data management and knowledge representation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"650\\\":{\\\"AuthorKeyword\\\":\\\"datum mining\\\",\\\"AuthorKeywordCount\\\":10,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"651\\\":{\\\"AuthorKeyword\\\":\\\"datum model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"652\\\":{\\\"AuthorKeyword\\\":\\\"datum navigation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"653\\\":{\\\"AuthorKeyword\\\":\\\"datum overlay\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"654\\\":{\\\"AuthorKeyword\\\":\\\"datum partitioning\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"655\\\":{\\\"AuthorKeyword\\\":\\\"datum physicalization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"656\\\":{\\\"AuthorKeyword\\\":\\\"data plot\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"657\\\":{\\\"AuthorKeyword\\\":\\\"datum point\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"659\\\":{\\\"AuthorKeyword\\\":\\\"data quality\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataCleaningAndSmoothing\\\",\\\"ExpertKeywordCount\\\":5},\\\"660\\\":{\\\"AuthorKeyword\\\":\\\"datum readability\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"661\\\":{\\\"AuthorKeyword\\\":\\\"datum reduction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"662\\\":{\\\"AuthorKeyword\\\":\\\"datum reformation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"663\\\":{\\\"AuthorKeyword\\\":\\\"datum registration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataRegistration,Fusion,AndIntegration\\\",\\\"ExpertKeywordCount\\\":14},\\\"664\\\":{\\\"AuthorKeyword\\\":\\\"data regularization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"665\\\":{\\\"AuthorKeyword\\\":\\\"datum retrieval\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"666\\\":{\\\"AuthorKeyword\\\":\\\"datum sculpture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ArtAndAestheticsInVisualization\\\",\\\"ExpertKeywordCount\\\":16},\\\"667\\\":{\\\"AuthorKeyword\\\":\\\"data selection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"668\\\":{\\\"AuthorKeyword\\\":\\\"datum simplification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"669\\\":{\\\"AuthorKeyword\\\":\\\"data state model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"670\\\":{\\\"AuthorKeyword\\\":\\\"datum storytelling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Storytelling\\\",\\\"ExpertKeywordCount\\\":10},\\\"671\\\":{\\\"AuthorKeyword\\\":\\\"datum stream\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"StreamingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":9},\\\"672\\\":{\\\"AuthorKeyword\\\":\\\"datum stream\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"StreamingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":9},\\\"673\\\":{\\\"AuthorKeyword\\\":\\\"data structure\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"674\\\":{\\\"AuthorKeyword\\\":\\\"datum synthesis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"675\\\":{\\\"AuthorKeyword\\\":\\\"datum transformation\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"DataTransformation\\\",\\\"ExpertKeywordCount\\\":19},\\\"676\\\":{\\\"AuthorKeyword\\\":\\\"datum transformation and representation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataTransformation\\\",\\\"ExpertKeywordCount\\\":19},\\\"677\\\":{\\\"AuthorKeyword\\\":\\\"data variability\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"678\\\":{\\\"AuthorKeyword\\\":\\\"database\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"679\\\":{\\\"AuthorKeyword\\\":\\\"database and datum mining visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"680\\\":{\\\"AuthorKeyword\\\":\\\"database overview\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"681\\\":{\\\"AuthorKeyword\\\":\\\"database visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"682\\\":{\\\"AuthorKeyword\\\":\\\"dataframe mode\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"683\\\":{\\\"AuthorKeyword\\\":\\\"dataset management\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"684\\\":{\\\"AuthorKeyword\\\":\\\"dataset traversal\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"685\\\":{\\\"AuthorKeyword\\\":\\\"decision boundary visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"686\\\":{\\\"AuthorKeyword\\\":\\\"decision make\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Reasoning,ProblemSolving,AndDecisionMaking\\\",\\\"ExpertKeywordCount\\\":15},\\\"688\\\":{\\\"AuthorKeyword\\\":\\\"decision tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"689\\\":{\\\"AuthorKeyword\\\":\\\"decision\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Reasoning,ProblemSolving,AndDecisionMaking\\\",\\\"ExpertKeywordCount\\\":15},\\\"690\\\":{\\\"AuthorKeyword\\\":\\\"declarative language\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"691\\\":{\\\"AuthorKeyword\\\":\\\"declarative specification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"692\\\":{\\\"AuthorKeyword\\\":\\\"decomposition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"693\\\":{\\\"AuthorKeyword\\\":\\\"defect\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"694\\\":{\\\"AuthorKeyword\\\":\\\"defer interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"695\\\":{\\\"AuthorKeyword\\\":\\\"deformable model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"696\\\":{\\\"AuthorKeyword\\\":\\\"deformation\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"ManipulationAndDeformation\\\",\\\"ExpertKeywordCount\\\":7},\\\"697\\\":{\\\"AuthorKeyword\\\":\\\"degenerate tensor\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"699\\\":{\\\"AuthorKeyword\\\":\\\"degree of interest\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"700\\\":{\\\"AuthorKeyword\\\":\\\"delaunay\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"701\\\":{\\\"AuthorKeyword\\\":\\\"delaunay triangulation\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"702\\\":{\\\"AuthorKeyword\\\":\\\"demand drive evaluation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"703\\\":{\\\"AuthorKeyword\\\":\\\"democracy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"704\\\":{\\\"AuthorKeyword\\\":\\\"demographic analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"705\\\":{\\\"AuthorKeyword\\\":\\\"demographic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"706\\\":{\\\"AuthorKeyword\\\":\\\"dendrogram\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"707\\\":{\\\"AuthorKeyword\\\":\\\"denoise\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"708\\\":{\\\"AuthorKeyword\\\":\\\"denotation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"709\\\":{\\\"AuthorKeyword\\\":\\\"dense pixel display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PixelOrientedEncodings\\\",\\\"ExpertKeywordCount\\\":7},\\\"710\\\":{\\\"AuthorKeyword\\\":\\\"density base visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"711\\\":{\\\"AuthorKeyword\\\":\\\"density reduction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"712\\\":{\\\"AuthorKeyword\\\":\\\"depth\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"713\\\":{\\\"AuthorKeyword\\\":\\\"depth of field\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"714\\\":{\\\"AuthorKeyword\\\":\\\"derivative\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"715\\\":{\\\"AuthorKeyword\\\":\\\"derivative filter\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"716\\\":{\\\"AuthorKeyword\\\":\\\"descriptor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"717\\\":{\\\"AuthorKeyword\\\":\\\"design\\\",\\\"AuthorKeywordCount\\\":19,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"718\\\":{\\\"AuthorKeyword\\\":\\\"design analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"719\\\":{\\\"AuthorKeyword\\\":\\\"design automation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"720\\\":{\\\"AuthorKeyword\\\":\\\"design consideration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"721\\\":{\\\"AuthorKeyword\\\":\\\"design factor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"722\\\":{\\\"AuthorKeyword\\\":\\\"design framework\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"723\\\":{\\\"AuthorKeyword\\\":\\\"design guideline\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"724\\\":{\\\"AuthorKeyword\\\":\\\"design methodology\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"725\\\":{\\\"AuthorKeyword\\\":\\\"design methodology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"726\\\":{\\\"AuthorKeyword\\\":\\\"design method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"727\\\":{\\\"AuthorKeyword\\\":\\\"design model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"728\\\":{\\\"AuthorKeyword\\\":\\\"design pattern\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"729\\\":{\\\"AuthorKeyword\\\":\\\"design recommendation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"730\\\":{\\\"AuthorKeyword\\\":\\\"design review\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"731\\\":{\\\"AuthorKeyword\\\":\\\"design space\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"732\\\":{\\\"AuthorKeyword\\\":\\\"design steering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"733\\\":{\\\"AuthorKeyword\\\":\\\"design study\\\",\\\"AuthorKeywordCount\\\":23,\\\"ExpertKeyword\\\":\\\"DesignStudiesAndCaseStudies\\\",\\\"ExpertKeywordCount\\\":28},\\\"734\\\":{\\\"AuthorKeyword\\\":\\\"design theory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"735\\\":{\\\"AuthorKeyword\\\":\\\"design tradeoff\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"736\\\":{\\\"AuthorKeyword\\\":\\\"desirable difficulite\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"737\\\":{\\\"AuthorKeyword\\\":\\\"detail\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"738\\\":{\\\"AuthorKeyword\\\":\\\"detail in context\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"739\\\":{\\\"AuthorKeyword\\\":\\\"detail preservation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LevelOfDetail\\\",\\\"ExpertKeywordCount\\\":48},\\\"740\\\":{\\\"AuthorKeyword\\\":\\\"detail recovery\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AlgorithmicPattern/featureDetection/tracking\\\",\\\"ExpertKeywordCount\\\":49},\\\"741\\\":{\\\"AuthorKeyword\\\":\\\"deviator\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"742\\\":{\\\"AuthorKeyword\\\":\\\"deviatoric\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"743\\\":{\\\"AuthorKeyword\\\":\\\"device information base\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"744\\\":{\\\"AuthorKeyword\\\":\\\"device unify interface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"745\\\":{\\\"AuthorKeyword\\\":\\\"diagram recall\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"746\\\":{\\\"AuthorKeyword\\\":\\\"diagram\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"747\\\":{\\\"AuthorKeyword\\\":\\\"diamond\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"748\\\":{\\\"AuthorKeyword\\\":\\\"dichromacy\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"749\\\":{\\\"AuthorKeyword\\\":\\\"difference map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"750\\\":{\\\"AuthorKeyword\\\":\\\"difference visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"751\\\":{\\\"AuthorKeyword\\\":\\\"differential form\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"752\\\":{\\\"AuthorKeyword\\\":\\\"differential geometry\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometryBasedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"753\\\":{\\\"AuthorKeyword\\\":\\\"differential hierarchy comparison\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"754\\\":{\\\"AuthorKeyword\\\":\\\"differential proteomic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"755\\\":{\\\"AuthorKeyword\\\":\\\"diffuse illumination\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"756\\\":{\\\"AuthorKeyword\\\":\\\"diffuse interreflection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"757\\\":{\\\"AuthorKeyword\\\":\\\"diffusion\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DiffusionRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":11},\\\"758\\\":{\\\"AuthorKeyword\\\":\\\"diffusion kurtosis imaging\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DiffusionRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":11},\\\"759\\\":{\\\"AuthorKeyword\\\":\\\"diffusion tensor\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"760\\\":{\\\"AuthorKeyword\\\":\\\"diffusion tensor datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"761\\\":{\\\"AuthorKeyword\\\":\\\"diffusion tensor field\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"762\\\":{\\\"AuthorKeyword\\\":\\\"diffusion tensor imaging\\\",\\\"AuthorKeywordCount\\\":10,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"763\\\":{\\\"AuthorKeyword\\\":\\\"diffusion tensor image fiber tract\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"764\\\":{\\\"AuthorKeyword\\\":\\\"diffusion tensor mri\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"765\\\":{\\\"AuthorKeyword\\\":\\\"diffusion tensor visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"766\\\":{\\\"AuthorKeyword\\\":\\\"diffusion weight mri\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NeurosciencesAndBrainVisualization\\\",\\\"ExpertKeywordCount\\\":17},\\\"767\\\":{\\\"AuthorKeyword\\\":\\\"digimap service\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"768\\\":{\\\"AuthorKeyword\\\":\\\"digital geometry processing\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"769\\\":{\\\"AuthorKeyword\\\":\\\"digital humanity\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"770\\\":{\\\"AuthorKeyword\\\":\\\"digital library\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"771\\\":{\\\"AuthorKeyword\\\":\\\"digital radiograph reconstruction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"772\\\":{\\\"AuthorKeyword\\\":\\\"digital repository\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"773\\\":{\\\"AuthorKeyword\\\":\\\"digitally reconstruct radiograph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"774\\\":{\\\"AuthorKeyword\\\":\\\"dimension filtering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"775\\\":{\\\"AuthorKeyword\\\":\\\"dimension order\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"776\\\":{\\\"AuthorKeyword\\\":\\\"dimension ordering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"777\\\":{\\\"AuthorKeyword\\\":\\\"dimension reduction\\\",\\\"AuthorKeywordCount\\\":12,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"778\\\":{\\\"AuthorKeyword\\\":\\\"dimension spacing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"779\\\":{\\\"AuthorKeyword\\\":\\\"dimensional measurement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"780\\\":{\\\"AuthorKeyword\\\":\\\"dimensional stacking\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"781\\\":{\\\"AuthorKeyword\\\":\\\"direct touch interaction\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"782\\\":{\\\"AuthorKeyword\\\":\\\"direct manipulation\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"783\\\":{\\\"AuthorKeyword\\\":\\\"direct manipulation widget\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"784\\\":{\\\"AuthorKeyword\\\":\\\"direct surface extraction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"785\\\":{\\\"AuthorKeyword\\\":\\\"direct volume render\\\",\\\"AuthorKeywordCount\\\":30,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"786\\\":{\\\"AuthorKeyword\\\":\\\"direct acyclic graph\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"787\\\":{\\\"AuthorKeyword\\\":\\\"direct graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"788\\\":{\\\"AuthorKeyword\\\":\\\"direction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"789\\\":{\\\"AuthorKeyword\\\":\\\"direction encoding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"790\\\":{\\\"AuthorKeyword\\\":\\\"direction visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"791\\\":{\\\"AuthorKeyword\\\":\\\"directional\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"792\\\":{\\\"AuthorKeyword\\\":\\\"directional flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"793\\\":{\\\"AuthorKeyword\\\":\\\"directory tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"794\\\":{\\\"AuthorKeyword\\\":\\\"directx\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"795\\\":{\\\"AuthorKeyword\\\":\\\"disaster management\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Emergency/disasterManagement\\\",\\\"ExpertKeywordCount\\\":6},\\\"796\\\":{\\\"AuthorKeyword\\\":\\\"disc tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"797\\\":{\\\"AuthorKeyword\\\":\\\"disclination\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"798\\\":{\\\"AuthorKeyword\\\":\\\"discontinuity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"799\\\":{\\\"AuthorKeyword\\\":\\\"discontinuity preservation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"800\\\":{\\\"AuthorKeyword\\\":\\\"discontinuous galerkin method\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"801\\\":{\\\"AuthorKeyword\\\":\\\"discourse structure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"802\\\":{\\\"AuthorKeyword\\\":\\\"discoverage\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"KnowledgeDiscovery\\\",\\\"ExpertKeywordCount\\\":28},\\\"803\\\":{\\\"AuthorKeyword\\\":\\\"discovery management\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"KnowledgeDiscovery\\\",\\\"ExpertKeywordCount\\\":28},\\\"804\\\":{\\\"AuthorKeyword\\\":\\\"discovery search visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"805\\\":{\\\"AuthorKeyword\\\":\\\"discrete hartley transform\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"806\\\":{\\\"AuthorKeyword\\\":\\\"discrete morse theory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InformationTheory\\\",\\\"ExpertKeywordCount\\\":12},\\\"807\\\":{\\\"AuthorKeyword\\\":\\\"discrete raytracing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Raytracing/raycasting\\\",\\\"ExpertKeywordCount\\\":32},\\\"808\\\":{\\\"AuthorKeyword\\\":\\\"discrete wavelet transform\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"809\\\":{\\\"AuthorKeyword\\\":\\\"discussion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"810\\\":{\\\"AuthorKeyword\\\":\\\"displacement map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"811\\\":{\\\"AuthorKeyword\\\":\\\"display\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"812\\\":{\\\"AuthorKeyword\\\":\\\"display algorithm\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"813\\\":{\\\"AuthorKeyword\\\":\\\"display characteristic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"814\\\":{\\\"AuthorKeyword\\\":\\\"display optimization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"815\\\":{\\\"AuthorKeyword\\\":\\\"dissemination\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Presentation,Production,AndDissemination\\\",\\\"ExpertKeywordCount\\\":5},\\\"816\\\":{\\\"AuthorKeyword\\\":\\\"dissimilarity base classification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"817\\\":{\\\"AuthorKeyword\\\":\\\"dissimilarity base visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"818\\\":{\\\"AuthorKeyword\\\":\\\"distance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAndAnalysisMetrics\\\",\\\"ExpertKeywordCount\\\":11},\\\"819\\\":{\\\"AuthorKeyword\\\":\\\"distance similarity preservation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"820\\\":{\\\"AuthorKeyword\\\":\\\"distance field\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"821\\\":{\\\"AuthorKeyword\\\":\\\"distance map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"822\\\":{\\\"AuthorKeyword\\\":\\\"distance transform\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataTransformation\\\",\\\"ExpertKeywordCount\\\":19},\\\"823\\\":{\\\"AuthorKeyword\\\":\\\"distance visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"824\\\":{\\\"AuthorKeyword\\\":\\\"distant reading\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"825\\\":{\\\"AuthorKeyword\\\":\\\"distortion\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"826\\\":{\\\"AuthorKeyword\\\":\\\"distortion lens\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"827\\\":{\\\"AuthorKeyword\\\":\\\"distortion view\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"828\\\":{\\\"AuthorKeyword\\\":\\\"distribute algorithm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DistributedSystemsAndGridEnvironments\\\",\\\"ExpertKeywordCount\\\":16},\\\"829\\\":{\\\"AuthorKeyword\\\":\\\"distribute cognition\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"830\\\":{\\\"AuthorKeyword\\\":\\\"distribute file system visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DistributedSystemsAndGridEnvironments\\\",\\\"ExpertKeywordCount\\\":16},\\\"831\\\":{\\\"AuthorKeyword\\\":\\\"distribute heterogeneous system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DistributedSystemsAndGridEnvironments\\\",\\\"ExpertKeywordCount\\\":16},\\\"832\\\":{\\\"AuthorKeyword\\\":\\\"distribute render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DistributedSystemsAndGridEnvironments\\\",\\\"ExpertKeywordCount\\\":16},\\\"833\\\":{\\\"AuthorKeyword\\\":\\\"distribute share memory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DistributedSystemsAndGridEnvironments\\\",\\\"ExpertKeywordCount\\\":16},\\\"834\\\":{\\\"AuthorKeyword\\\":\\\"distribute storage\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DistributedSystemsAndGridEnvironments\\\",\\\"ExpertKeywordCount\\\":16},\\\"835\\\":{\\\"AuthorKeyword\\\":\\\"distribute synchronization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DistributedSystemsAndGridEnvironments\\\",\\\"ExpertKeywordCount\\\":16},\\\"836\\\":{\\\"AuthorKeyword\\\":\\\"distribute system\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DistributedSystemsAndGridEnvironments\\\",\\\"ExpertKeywordCount\\\":16},\\\"837\\\":{\\\"AuthorKeyword\\\":\\\"distribute visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DistributedSystemsAndGridEnvironments\\\",\\\"ExpertKeywordCount\\\":16},\\\"838\\\":{\\\"AuthorKeyword\\\":\\\"distribute volume reconstruction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"839\\\":{\\\"AuthorKeyword\\\":\\\"distribution\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"840\\\":{\\\"AuthorKeyword\\\":\\\"dither\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"841\\\":{\\\"AuthorKeyword\\\":\\\"divergence theorem\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"842\\\":{\\\"AuthorKeyword\\\":\\\"diversity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"843\\\":{\\\"AuthorKeyword\\\":\\\"dna design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"844\\\":{\\\"AuthorKeyword\\\":\\\"dna sequence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"845\\\":{\\\"AuthorKeyword\\\":\\\"document analysis\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"846\\\":{\\\"AuthorKeyword\\\":\\\"document categorization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"847\\\":{\\\"AuthorKeyword\\\":\\\"document clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"848\\\":{\\\"AuthorKeyword\\\":\\\"document processing and analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"849\\\":{\\\"AuthorKeyword\\\":\\\"document triage\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"850\\\":{\\\"AuthorKeyword\\\":\\\"document visualization\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"851\\\":{\\\"AuthorKeyword\\\":\\\"doi tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"852\\\":{\\\"AuthorKeyword\\\":\\\"domain specific language\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"853\\\":{\\\"AuthorKeyword\\\":\\\"domain analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"854\\\":{\\\"AuthorKeyword\\\":\\\"doppler effect\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"855\\\":{\\\"AuthorKeyword\\\":\\\"doppler radar\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"856\\\":{\\\"AuthorKeyword\\\":\\\"dot plot\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"857\\\":{\\\"AuthorKeyword\\\":\\\"double couple\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"858\\\":{\\\"AuthorKeyword\\\":\\\"drill down\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"859\\\":{\\\"AuthorKeyword\\\":\\\"drug design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"860\\\":{\\\"AuthorKeyword\\\":\\\"drug discovery\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"861\\\":{\\\"AuthorKeyword\\\":\\\"dual energy compute tomography image fusion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"862\\\":{\\\"AuthorKeyword\\\":\\\"dual energy ct\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"863\\\":{\\\"AuthorKeyword\\\":\\\"dual graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"864\\\":{\\\"AuthorKeyword\\\":\\\"dual mesh\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"865\\\":{\\\"AuthorKeyword\\\":\\\"dust\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"866\\\":{\\\"AuthorKeyword\\\":\\\"dynamic animation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"867\\\":{\\\"AuthorKeyword\\\":\\\"dynamic area of interest\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"868\\\":{\\\"AuthorKeyword\\\":\\\"dynamic datum\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"DynamicDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":11},\\\"869\\\":{\\\"AuthorKeyword\\\":\\\"dynamic graph\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DynamicDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":11},\\\"870\\\":{\\\"AuthorKeyword\\\":\\\"dynamic graph datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"871\\\":{\\\"AuthorKeyword\\\":\\\"dynamic graph layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"873\\\":{\\\"AuthorKeyword\\\":\\\"dynamic graphic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DynamicDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":11},\\\"874\\\":{\\\"AuthorKeyword\\\":\\\"dynamic labeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Labeling\\\",\\\"ExpertKeywordCount\\\":10},\\\"875\\\":{\\\"AuthorKeyword\\\":\\\"dynamic layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DynamicDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":11},\\\"876\\\":{\\\"AuthorKeyword\\\":\\\"dynamic map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"878\\\":{\\\"AuthorKeyword\\\":\\\"dynamic query\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"879\\\":{\\\"AuthorKeyword\\\":\\\"dynamic scene analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"880\\\":{\\\"AuthorKeyword\\\":\\\"dynamic simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"881\\\":{\\\"AuthorKeyword\\\":\\\"dynamic spect\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"882\\\":{\\\"AuthorKeyword\\\":\\\"dynamic surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"883\\\":{\\\"AuthorKeyword\\\":\\\"dynamic tessellation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"884\\\":{\\\"AuthorKeyword\\\":\\\"dynamic view selection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"885\\\":{\\\"AuthorKeyword\\\":\\\"dynamic visualization\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"DynamicVisualization,VisualizationOfChange\\\",\\\"ExpertKeywordCount\\\":14},\\\"886\\\":{\\\"AuthorKeyword\\\":\\\"dynamical system\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"DynamicVisualization,VisualizationOfChange\\\",\\\"ExpertKeywordCount\\\":14},\\\"887\\\":{\\\"AuthorKeyword\\\":\\\"dynamic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DynamicDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":11},\\\"888\\\":{\\\"AuthorKeyword\\\":\\\"transaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Business,Finance,Economy,Manufacturing\\\",\\\"ExpertKeywordCount\\\":12},\\\"889\\\":{\\\"AuthorKeyword\\\":\\\"earth space and environmental science visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"891\\\":{\\\"AuthorKeyword\\\":\\\"earth science visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"892\\\":{\\\"AuthorKeyword\\\":\\\"ebook\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"893\\\":{\\\"AuthorKeyword\\\":\\\"ecco\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"894\\\":{\\\"AuthorKeyword\\\":\\\"economic decision making\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Reasoning,ProblemSolving,AndDecisionMaking\\\",\\\"ExpertKeywordCount\\\":15},\\\"895\\\":{\\\"AuthorKeyword\\\":\\\"economic input output\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Business,Finance,Economy,Manufacturing\\\",\\\"ExpertKeywordCount\\\":12},\\\"896\\\":{\\\"AuthorKeyword\\\":\\\"ecosystem\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"897\\\":{\\\"AuthorKeyword\\\":\\\"eda\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"898\\\":{\\\"AuthorKeyword\\\":\\\"edge aggregation\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"899\\\":{\\\"AuthorKeyword\\\":\\\"edge bundling\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"900\\\":{\\\"AuthorKeyword\\\":\\\"edge clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"901\\\":{\\\"AuthorKeyword\\\":\\\"edge concentration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"902\\\":{\\\"AuthorKeyword\\\":\\\"edge congestion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"903\\\":{\\\"AuthorKeyword\\\":\\\"edge contraction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"904\\\":{\\\"AuthorKeyword\\\":\\\"edge feature\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"905\\\":{\\\"AuthorKeyword\\\":\\\"edge filtering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"907\\\":{\\\"AuthorKeyword\\\":\\\"editorial\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"908\\\":{\\\"AuthorKeyword\\\":\\\"education\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Education\\\",\\\"ExpertKeywordCount\\\":4},\\\"909\\\":{\\\"AuthorKeyword\\\":\\\"educational visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Education\\\",\\\"ExpertKeywordCount\\\":4},\\\"910\\\":{\\\"AuthorKeyword\\\":\\\"efficiency of display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"911\\\":{\\\"AuthorKeyword\\\":\\\"efficient volume render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"912\\\":{\\\"AuthorKeyword\\\":\\\"egocentric network\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"913\\\":{\\\"AuthorKeyword\\\":\\\"eigenprojection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"914\\\":{\\\"AuthorKeyword\\\":\\\"eigenvector analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"915\\\":{\\\"AuthorKeyword\\\":\\\"el nino\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"916\\\":{\\\"AuthorKeyword\\\":\\\"elaboration likelihood model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"917\\\":{\\\"AuthorKeyword\\\":\\\"elastic hierarchy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"918\\\":{\\\"AuthorKeyword\\\":\\\"election\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"919\\\":{\\\"AuthorKeyword\\\":\\\"electro holography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"920\\\":{\\\"AuthorKeyword\\\":\\\"electronic health record\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"921\\\":{\\\"AuthorKeyword\\\":\\\"electronic signal\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"922\\\":{\\\"AuthorKeyword\\\":\\\"electronic workspace\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"923\\\":{\\\"AuthorKeyword\\\":\\\"elliptical weight average filter\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"924\\\":{\\\"AuthorKeyword\\\":\\\"email\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"925\\\":{\\\"AuthorKeyword\\\":\\\"email correspondent\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"926\\\":{\\\"AuthorKeyword\\\":\\\"emailtime\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"927\\\":{\\\"AuthorKeyword\\\":\\\"embed coding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"928\\\":{\\\"AuthorKeyword\\\":\\\"embed vortex\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"929\\\":{\\\"AuthorKeyword\\\":\\\"embed\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"930\\\":{\\\"AuthorKeyword\\\":\\\"embody cognition\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"931\\\":{\\\"AuthorKeyword\\\":\\\"embodiment\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"932\\\":{\\\"AuthorKeyword\\\":\\\"emergency response\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Emergency/disasterManagement\\\",\\\"ExpertKeywordCount\\\":6},\\\"933\\\":{\\\"AuthorKeyword\\\":\\\"emergency disaster management\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Emergency/disasterManagement\\\",\\\"ExpertKeywordCount\\\":6},\\\"934\\\":{\\\"AuthorKeyword\\\":\\\"empirical evaluation\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"935\\\":{\\\"AuthorKeyword\\\":\\\"empirical study\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"936\\\":{\\\"AuthorKeyword\\\":\\\"empty space skipping\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"937\\\":{\\\"AuthorKeyword\\\":\\\"encode\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"939\\\":{\\\"AuthorKeyword\\\":\\\"endoscopy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"940\\\":{\\\"AuthorKeyword\\\":\\\"energy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"941\\\":{\\\"AuthorKeyword\\\":\\\"energy consumption\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"942\\\":{\\\"AuthorKeyword\\\":\\\"energy demand prediction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"943\\\":{\\\"AuthorKeyword\\\":\\\"energy efficiency\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"944\\\":{\\\"AuthorKeyword\\\":\\\"energy flow topology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"945\\\":{\\\"AuthorKeyword\\\":\\\"energy landscape\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"946\\\":{\\\"AuthorKeyword\\\":\\\"engagement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"947\\\":{\\\"AuthorKeyword\\\":\\\"engine simulation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Engineering\\\",\\\"ExpertKeywordCount\\\":12},\\\"948\\\":{\\\"AuthorKeyword\\\":\\\"engineering datum management\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"949\\\":{\\\"AuthorKeyword\\\":\\\"enron\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"950\\\":{\\\"AuthorKeyword\\\":\\\"ensemble\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"951\\\":{\\\"AuthorKeyword\\\":\\\"ensemble analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"952\\\":{\\\"AuthorKeyword\\\":\\\"ensemble datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"953\\\":{\\\"AuthorKeyword\\\":\\\"ensemble simulation steering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"954\\\":{\\\"AuthorKeyword\\\":\\\"ensemble visualization\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"955\\\":{\\\"AuthorKeyword\\\":\\\"entity base\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"956\\\":{\\\"AuthorKeyword\\\":\\\"entropy\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"InformationTheory\\\",\\\"ExpertKeywordCount\\\":12},\\\"957\\\":{\\\"AuthorKeyword\\\":\\\"environmental management\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"958\\\":{\\\"AuthorKeyword\\\":\\\"environmental observation and forecasting system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"959\\\":{\\\"AuthorKeyword\\\":\\\"enzo\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"960\\\":{\\\"AuthorKeyword\\\":\\\"epidemic visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"961\\\":{\\\"AuthorKeyword\\\":\\\"epidemiology\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"962\\\":{\\\"AuthorKeyword\\\":\\\"epipolar geometry\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"963\\\":{\\\"AuthorKeyword\\\":\\\"error base frame control\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"964\\\":{\\\"AuthorKeyword\\\":\\\"error ellipsoid\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"965\\\":{\\\"AuthorKeyword\\\":\\\"error metric\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"EvaluationMetricsAndBenchmarks\\\",\\\"ExpertKeywordCount\\\":19},\\\"966\\\":{\\\"AuthorKeyword\\\":\\\"essential dynamic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"967\\\":{\\\"AuthorKeyword\\\":\\\"estuary\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"968\\\":{\\\"AuthorKeyword\\\":\\\"ethnographic fieldwork\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FieldStudies\\\",\\\"ExpertKeywordCount\\\":2},\\\"969\\\":{\\\"AuthorKeyword\\\":\\\"euler diagram\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"970\\\":{\\\"AuthorKeyword\\\":\\\"eulerian flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"971\\\":{\\\"AuthorKeyword\\\":\\\"evaluation\\\",\\\"AuthorKeywordCount\\\":36,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"972\\\":{\\\"AuthorKeyword\\\":\\\"evaluation methodology\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"973\\\":{\\\"AuthorKeyword\\\":\\\"evaluation of visualization technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"974\\\":{\\\"AuthorKeyword\\\":\\\"evenly space streamline\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"975\\\":{\\\"AuthorKeyword\\\":\\\"event base datum\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Events,Trends,OutlierDetection,Analysis,AndVisualization\\\",\\\"ExpertKeywordCount\\\":23},\\\"976\\\":{\\\"AuthorKeyword\\\":\\\"event analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Events,Trends,OutlierDetection,Analysis,AndVisualization\\\",\\\"ExpertKeywordCount\\\":23},\\\"977\\\":{\\\"AuthorKeyword\\\":\\\"event datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Events,Trends,OutlierDetection,Analysis,AndVisualization\\\",\\\"ExpertKeywordCount\\\":23},\\\"978\\\":{\\\"AuthorKeyword\\\":\\\"event detection\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Events,Trends,OutlierDetection,Analysis,AndVisualization\\\",\\\"ExpertKeywordCount\\\":23},\\\"979\\\":{\\\"AuthorKeyword\\\":\\\"event sequence visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Events,Trends,OutlierDetection,Analysis,AndVisualization\\\",\\\"ExpertKeywordCount\\\":23},\\\"980\\\":{\\\"AuthorKeyword\\\":\\\"event sequence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Events,Trends,OutlierDetection,Analysis,AndVisualization\\\",\\\"ExpertKeywordCount\\\":23},\\\"981\\\":{\\\"AuthorKeyword\\\":\\\"event\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Events,Trends,OutlierDetection,Analysis,AndVisualization\\\",\\\"ExpertKeywordCount\\\":23},\\\"982\\\":{\\\"AuthorKeyword\\\":\\\"evidence base decision making\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Reasoning,ProblemSolving,AndDecisionMaking\\\",\\\"ExpertKeywordCount\\\":15},\\\"983\\\":{\\\"AuthorKeyword\\\":\\\"evolution\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"984\\\":{\\\"AuthorKeyword\\\":\\\"evolution graph view\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"985\\\":{\\\"AuthorKeyword\\\":\\\"evolutionary tree clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"986\\\":{\\\"AuthorKeyword\\\":\\\"example base render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"987\\\":{\\\"AuthorKeyword\\\":\\\"exemplar\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"988\\\":{\\\"AuthorKeyword\\\":\\\"expand ahead\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"989\\\":{\\\"AuthorKeyword\\\":\\\"expect time complexity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"990\\\":{\\\"AuthorKeyword\\\":\\\"experiment\\\",\\\"AuthorKeywordCount\\\":10,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"991\\\":{\\\"AuthorKeyword\\\":\\\"experimental comparison\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"992\\\":{\\\"AuthorKeyword\\\":\\\"experimental design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"993\\\":{\\\"AuthorKeyword\\\":\\\"experimental method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"994\\\":{\\\"AuthorKeyword\\\":\\\"experimental study\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"995\\\":{\\\"AuthorKeyword\\\":\\\"experimentation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"996\\\":{\\\"AuthorKeyword\\\":\\\"expert review\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"997\\\":{\\\"AuthorKeyword\\\":\\\"explanatory computer graphic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"998\\\":{\\\"AuthorKeyword\\\":\\\"explode view diagram\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"999\\\":{\\\"AuthorKeyword\\\":\\\"explode view\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"1000\\\":{\\\"AuthorKeyword\\\":\\\"exploration\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1001\\\":{\\\"AuthorKeyword\\\":\\\"exploratory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1002\\\":{\\\"AuthorKeyword\\\":\\\"exploratory datum analysis\\\",\\\"AuthorKeywordCount\\\":11,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1003\\\":{\\\"AuthorKeyword\\\":\\\"exploratory interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1004\\\":{\\\"AuthorKeyword\\\":\\\"exploratory process\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1005\\\":{\\\"AuthorKeyword\\\":\\\"exploratory search\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1006\\\":{\\\"AuthorKeyword\\\":\\\"exploratory visualization\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1007\\\":{\\\"AuthorKeyword\\\":\\\"exploratory visualization and analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1008\\\":{\\\"AuthorKeyword\\\":\\\"exponential extinction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"1009\\\":{\\\"AuthorKeyword\\\":\\\"exposure error\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1010\\\":{\\\"AuthorKeyword\\\":\\\"expressive cue\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"1011\\\":{\\\"AuthorKeyword\\\":\\\"expressiveness\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"1012\\\":{\\\"AuthorKeyword\\\":\\\"extensibility\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"1013\\\":{\\\"AuthorKeyword\\\":\\\"extensible\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"1014\\\":{\\\"AuthorKeyword\\\":\\\"external index\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1015\\\":{\\\"AuthorKeyword\\\":\\\"external memory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"1016\\\":{\\\"AuthorKeyword\\\":\\\"external memory algorithm\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"1017\\\":{\\\"AuthorKeyword\\\":\\\"external sorting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"OutOfCoreProcessing\\\",\\\"ExpertKeywordCount\\\":20},\\\"1018\\\":{\\\"AuthorKeyword\\\":\\\"externalization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualKnowledgeRepresentationAndExternalization\\\",\\\"ExpertKeywordCount\\\":13},\\\"1019\\\":{\\\"AuthorKeyword\\\":\\\"extremum graph\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1020\\\":{\\\"AuthorKeyword\\\":\\\"eye gaze analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"1022\\\":{\\\"AuthorKeyword\\\":\\\"eye tracking study\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"1023\\\":{\\\"AuthorKeyword\\\":\\\"face center cubic lattice\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1024\\\":{\\\"AuthorKeyword\\\":\\\"facete browsing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"1025\\\":{\\\"AuthorKeyword\\\":\\\"faceted metadata\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFacetsAndTechniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"1026\\\":{\\\"AuthorKeyword\\\":\\\"faceted visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFacetsAndTechniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"1027\\\":{\\\"AuthorKeyword\\\":\\\"fair\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"1028\\\":{\\\"AuthorKeyword\\\":\\\"family of surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"1029\\\":{\\\"AuthorKeyword\\\":\\\"family tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1030\\\":{\\\"AuthorKeyword\\\":\\\"farth point seeding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"1031\\\":{\\\"AuthorKeyword\\\":\\\"fast entropy coding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InformationTheory\\\",\\\"ExpertKeywordCount\\\":12},\\\"1032\\\":{\\\"AuthorKeyword\\\":\\\"fault simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"1033\\\":{\\\"AuthorKeyword\\\":\\\"feature base\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"1034\\\":{\\\"AuthorKeyword\\\":\\\"feature base visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"1035\\\":{\\\"AuthorKeyword\\\":\\\"feature analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AlgorithmicPattern/featureDetection/tracking\\\",\\\"ExpertKeywordCount\\\":49},\\\"1036\\\":{\\\"AuthorKeyword\\\":\\\"feature animation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"1037\\\":{\\\"AuthorKeyword\\\":\\\"feature classification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AlgorithmicPattern/featureDetection/tracking\\\",\\\"ExpertKeywordCount\\\":49},\\\"1038\\\":{\\\"AuthorKeyword\\\":\\\"feature curve extraction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"1039\\\":{\\\"AuthorKeyword\\\":\\\"feature detection\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"AlgorithmicPattern/featureDetection/tracking\\\",\\\"ExpertKeywordCount\\\":49},\\\"1040\\\":{\\\"AuthorKeyword\\\":\\\"feature evaluation and selection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AlgorithmicPattern/featureDetection/tracking\\\",\\\"ExpertKeywordCount\\\":49},\\\"1041\\\":{\\\"AuthorKeyword\\\":\\\"feature extraction\\\",\\\"AuthorKeywordCount\\\":21,\\\"ExpertKeyword\\\":\\\"AlgorithmicPattern/featureDetection/tracking\\\",\\\"ExpertKeywordCount\\\":49},\\\"1042\\\":{\\\"AuthorKeyword\\\":\\\"feature extraction and tracking\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"AlgorithmicPattern/featureDetection/tracking\\\",\\\"ExpertKeywordCount\\\":49},\\\"1044\\\":{\\\"AuthorKeyword\\\":\\\"feature mining\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AlgorithmicPattern/featureDetection/tracking\\\",\\\"ExpertKeywordCount\\\":49},\\\"1045\\\":{\\\"AuthorKeyword\\\":\\\"feature selection\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"AlgorithmicPattern/featureDetection/tracking\\\",\\\"ExpertKeywordCount\\\":49},\\\"1046\\\":{\\\"AuthorKeyword\\\":\\\"feature space\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"1047\\\":{\\\"AuthorKeyword\\\":\\\"feature tracking\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"AlgorithmicPattern/featureDetection/tracking\\\",\\\"ExpertKeywordCount\\\":49},\\\"1048\\\":{\\\"AuthorKeyword\\\":\\\"feature verification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AlgorithmicPattern/featureDetection/tracking\\\",\\\"ExpertKeywordCount\\\":49},\\\"1049\\\":{\\\"AuthorKeyword\\\":\\\"feature\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"1050\\\":{\\\"AuthorKeyword\\\":\\\"feature in volume datum set\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"1051\\\":{\\\"AuthorKeyword\\\":\\\"fiber clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"1052\\\":{\\\"AuthorKeyword\\\":\\\"fiber topology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tractography\\\",\\\"ExpertKeywordCount\\\":17},\\\"1053\\\":{\\\"AuthorKeyword\\\":\\\"fiber tracing\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Tractography\\\",\\\"ExpertKeywordCount\\\":17},\\\"1054\\\":{\\\"AuthorKeyword\\\":\\\"fiber tracking\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Tractography\\\",\\\"ExpertKeywordCount\\\":17},\\\"1055\\\":{\\\"AuthorKeyword\\\":\\\"fiber tractography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tractography\\\",\\\"ExpertKeywordCount\\\":17},\\\"1056\\\":{\\\"AuthorKeyword\\\":\\\"fiber\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tractography\\\",\\\"ExpertKeywordCount\\\":17},\\\"1057\\\":{\\\"AuthorKeyword\\\":\\\"fiedl vector\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"1058\\\":{\\\"AuthorKeyword\\\":\\\"field line advection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1059\\\":{\\\"AuthorKeyword\\\":\\\"field line\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LineBasedTechniquesAndApproaches\\\",\\\"ExpertKeywordCount\\\":8},\\\"1060\\\":{\\\"AuthorKeyword\\\":\\\"field study\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FieldStudies\\\",\\\"ExpertKeywordCount\\\":2},\\\"1061\\\":{\\\"AuthorKeyword\\\":\\\"file compaction for efficiency\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1062\\\":{\\\"AuthorKeyword\\\":\\\"filter construction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"1063\\\":{\\\"AuthorKeyword\\\":\\\"filter design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"1064\\\":{\\\"AuthorKeyword\\\":\\\"filter back projection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"1065\\\":{\\\"AuthorKeyword\\\":\\\"filter shadow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"1066\\\":{\\\"AuthorKeyword\\\":\\\"filter\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"1067\\\":{\\\"AuthorKeyword\\\":\\\"filter\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"1068\\\":{\\\"AuthorKeyword\\\":\\\"financial datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Business,Finance,Economy,Manufacturing\\\",\\\"ExpertKeywordCount\\\":12},\\\"1069\\\":{\\\"AuthorKeyword\\\":\\\"financial information visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Business,Finance,Economy,Manufacturing\\\",\\\"ExpertKeywordCount\\\":12},\\\"1070\\\":{\\\"AuthorKeyword\\\":\\\"financial visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Business,Finance,Economy,Manufacturing\\\",\\\"ExpertKeywordCount\\\":12},\\\"1071\\\":{\\\"AuthorKeyword\\\":\\\"fine detail\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LevelOfDetail\\\",\\\"ExpertKeywordCount\\\":48},\\\"1072\\\":{\\\"AuthorKeyword\\\":\\\"finite difference time domain fdtd\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1073\\\":{\\\"AuthorKeyword\\\":\\\"finite time lyapunov exponent\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1074\\\":{\\\"AuthorKeyword\\\":\\\"finite element code and simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"1075\\\":{\\\"AuthorKeyword\\\":\\\"finite element method\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1076\\\":{\\\"AuthorKeyword\\\":\\\"finite element modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1077\\\":{\\\"AuthorKeyword\\\":\\\"finite element visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1078\\\":{\\\"AuthorKeyword\\\":\\\"finite element\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1079\\\":{\\\"AuthorKeyword\\\":\\\"finite state machine\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"StateRelatedData&Techniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"1080\\\":{\\\"AuthorKeyword\\\":\\\"fire modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"1081\\\":{\\\"AuthorKeyword\\\":\\\"fire propagation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"1082\\\":{\\\"AuthorKeyword\\\":\\\"fisher linear discriminant analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"1083\\\":{\\\"AuthorKeyword\\\":\\\"fisheye\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"1084\\\":{\\\"AuthorKeyword\\\":\\\"fisheye view\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"1085\\\":{\\\"AuthorKeyword\\\":\\\"fitness landscape\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1086\\\":{\\\"AuthorKeyword\\\":\\\"flat map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"1087\\\":{\\\"AuthorKeyword\\\":\\\"flatten dataset\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"1088\\\":{\\\"AuthorKeyword\\\":\\\"flexibility usability tradeoff\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"1089\\\":{\\\"AuthorKeyword\\\":\\\"flexible model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"1090\\\":{\\\"AuthorKeyword\\\":\\\"flicker\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"1091\\\":{\\\"AuthorKeyword\\\":\\\"float point arrays\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataTypesGeneral\\\",\\\"ExpertKeywordCount\\\":12},\\\"1092\\\":{\\\"AuthorKeyword\\\":\\\"float point compression\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"1093\\\":{\\\"AuthorKeyword\\\":\\\"flood management\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Emergency/disasterManagement\\\",\\\"ExpertKeywordCount\\\":6},\\\"1094\\\":{\\\"AuthorKeyword\\\":\\\"flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1095\\\":{\\\"AuthorKeyword\\\":\\\"flow guide\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1096\\\":{\\\"AuthorKeyword\\\":\\\"flow diagram\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"1097\\\":{\\\"AuthorKeyword\\\":\\\"flow envelope\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1098\\\":{\\\"AuthorKeyword\\\":\\\"flow feature\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1099\\\":{\\\"AuthorKeyword\\\":\\\"flow field\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1100\\\":{\\\"AuthorKeyword\\\":\\\"flow field visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1101\\\":{\\\"AuthorKeyword\\\":\\\"flow map\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1102\\\":{\\\"AuthorKeyword\\\":\\\"flow mapping\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1103\\\":{\\\"AuthorKeyword\\\":\\\"flow reversal\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1104\\\":{\\\"AuthorKeyword\\\":\\\"flow surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1105\\\":{\\\"AuthorKeyword\\\":\\\"flow topology\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"1106\\\":{\\\"AuthorKeyword\\\":\\\"flow visualization\\\",\\\"AuthorKeywordCount\\\":77,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1108\\\":{\\\"AuthorKeyword\\\":\\\"flowline curvature\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"1109\\\":{\\\"AuthorKeyword\\\":\\\"flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1110\\\":{\\\"AuthorKeyword\\\":\\\"fluctuation diagram\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"1111\\\":{\\\"AuthorKeyword\\\":\\\"fluid dynamic\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"1112\\\":{\\\"AuthorKeyword\\\":\\\"fluid flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1113\\\":{\\\"AuthorKeyword\\\":\\\"fluid flow simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1115\\\":{\\\"AuthorKeyword\\\":\\\"focus stack\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1116\\\":{\\\"AuthorKeyword\\\":\\\"focus context\\\",\\\"AuthorKeywordCount\\\":25,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"1117\\\":{\\\"AuthorKeyword\\\":\\\"focus context technique\\\",\\\"AuthorKeywordCount\\\":12,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"1118\\\":{\\\"AuthorKeyword\\\":\\\"focus context visualization\\\",\\\"AuthorKeywordCount\\\":11,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"1119\\\":{\\\"AuthorKeyword\\\":\\\"focusse\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"1120\\\":{\\\"AuthorKeyword\\\":\\\"fold recognition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"1121\\\":{\\\"AuthorKeyword\\\":\\\"forage\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1122\\\":{\\\"AuthorKeyword\\\":\\\"force\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"1123\\\":{\\\"AuthorKeyword\\\":\\\"force direct algorithm\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1124\\\":{\\\"AuthorKeyword\\\":\\\"force direct approach\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1125\\\":{\\\"AuthorKeyword\\\":\\\"force direct drawing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1126\\\":{\\\"AuthorKeyword\\\":\\\"force direct layout\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1127\\\":{\\\"AuthorKeyword\\\":\\\"force direct placement\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1128\\\":{\\\"AuthorKeyword\\\":\\\"force feedback device\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"1129\\\":{\\\"AuthorKeyword\\\":\\\"forensic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1130\\\":{\\\"AuthorKeyword\\\":\\\"formal concept analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualAnalysisModels\\\",\\\"ExpertKeywordCount\\\":9},\\\"1131\\\":{\\\"AuthorKeyword\\\":\\\"formal method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1132\\\":{\\\"AuthorKeyword\\\":\\\"forward mapping\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"1133\\\":{\\\"AuthorKeyword\\\":\\\"fouri analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1134\\\":{\\\"AuthorKeyword\\\":\\\"fouri projection theorem\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1135\\\":{\\\"AuthorKeyword\\\":\\\"fouri transform\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1136\\\":{\\\"AuthorKeyword\\\":\\\"fp tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1137\\\":{\\\"AuthorKeyword\\\":\\\"fractal dimension\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1138\\\":{\\\"AuthorKeyword\\\":\\\"fragment program\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1139\\\":{\\\"AuthorKeyword\\\":\\\"frame to frame coherence\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"1140\\\":{\\\"AuthorKeyword\\\":\\\"frame buffer\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"1141\\\":{\\\"AuthorKeyword\\\":\\\"frame rate datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"1142\\\":{\\\"AuthorKeyword\\\":\\\"frame\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"1143\\\":{\\\"AuthorKeyword\\\":\\\"framework\\\",\\\"AuthorKeywordCount\\\":12,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"1144\\\":{\\\"AuthorKeyword\\\":\\\"frame effect\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Storytelling\\\",\\\"ExpertKeywordCount\\\":10},\\\"1145\\\":{\\\"AuthorKeyword\\\":\\\"fraud detection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Privacy,Security,IntelligenceAnalysis\\\",\\\"ExpertKeywordCount\\\":16},\\\"1146\\\":{\\\"AuthorKeyword\\\":\\\"frequency error kernel\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1147\\\":{\\\"AuthorKeyword\\\":\\\"function similarity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"1148\\\":{\\\"AuthorKeyword\\\":\\\"functional datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataTypesGeneral\\\",\\\"ExpertKeywordCount\\\":12},\\\"1149\\\":{\\\"AuthorKeyword\\\":\\\"functional programming\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1150\\\":{\\\"AuthorKeyword\\\":\\\"functional realism\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"1151\\\":{\\\"AuthorKeyword\\\":\\\"fundexplore\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"1152\\\":{\\\"AuthorKeyword\\\":\\\"funnel analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"1153\\\":{\\\"AuthorKeyword\\\":\\\"fuzzy clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"1154\\\":{\\\"AuthorKeyword\\\":\\\"fuzzy logic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1155\\\":{\\\"AuthorKeyword\\\":\\\"gabor filter\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"1156\\\":{\\\"AuthorKeyword\\\":\\\"gabriel graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1157\\\":{\\\"AuthorKeyword\\\":\\\"galilean invariance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Astronomy/Astrophysics\\\",\\\"ExpertKeywordCount\\\":17},\\\"1158\\\":{\\\"AuthorKeyword\\\":\\\"galois sub hierarchy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1159\\\":{\\\"AuthorKeyword\\\":\\\"game graphic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"1160\\\":{\\\"AuthorKeyword\\\":\\\"game performance evaluation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"1161\\\":{\\\"AuthorKeyword\\\":\\\"game reconstruction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1162\\\":{\\\"AuthorKeyword\\\":\\\"game\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1163\\\":{\\\"AuthorKeyword\\\":\\\"gauss map\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1164\\\":{\\\"AuthorKeyword\\\":\\\"gaussian mixture model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1165\\\":{\\\"AuthorKeyword\\\":\\\"gaussian process\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1166\\\":{\\\"AuthorKeyword\\\":\\\"gaussian process model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1167\\\":{\\\"AuthorKeyword\\\":\\\"gaussian scale mixture model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1168\\\":{\\\"AuthorKeyword\\\":\\\"gaussian type orbital\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"1169\\\":{\\\"AuthorKeyword\\\":\\\"gender difference\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"1170\\\":{\\\"AuthorKeyword\\\":\\\"gene expression\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"1171\\\":{\\\"AuthorKeyword\\\":\\\"gene expression experiment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"1172\\\":{\\\"AuthorKeyword\\\":\\\"gene expression profiling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"1174\\\":{\\\"AuthorKeyword\\\":\\\"gene regulatory network\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"1175\\\":{\\\"AuthorKeyword\\\":\\\"genealogy\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"1176\\\":{\\\"AuthorKeyword\\\":\\\"genealogy visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"1177\\\":{\\\"AuthorKeyword\\\":\\\"general relativity\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"1178\\\":{\\\"AuthorKeyword\\\":\\\"general tensor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1179\\\":{\\\"AuthorKeyword\\\":\\\"generalization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"1180\\\":{\\\"AuthorKeyword\\\":\\\"generalize coulomb potential\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"1181\\\":{\\\"AuthorKeyword\\\":\\\"generalize eigenvalue problem\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1182\\\":{\\\"AuthorKeyword\\\":\\\"generalized singular value decomposition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"1183\\\":{\\\"AuthorKeyword\\\":\\\"generalized streak line\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"1184\\\":{\\\"AuthorKeyword\\\":\\\"genetic algorithm\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"1185\\\":{\\\"AuthorKeyword\\\":\\\"genetic network\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"1186\\\":{\\\"AuthorKeyword\\\":\\\"genetic variant\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"1187\\\":{\\\"AuthorKeyword\\\":\\\"genome assembly\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"1188\\\":{\\\"AuthorKeyword\\\":\\\"genomic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"1189\\\":{\\\"AuthorKeyword\\\":\\\"genus\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Taxonomies\\\",\\\"ExpertKeywordCount\\\":18},\\\"1190\\\":{\\\"AuthorKeyword\\\":\\\"geo tag social medium\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"1191\\\":{\\\"AuthorKeyword\\\":\\\"geo temporal analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"1192\\\":{\\\"AuthorKeyword\\\":\\\"geo temporal visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"1193\\\":{\\\"AuthorKeyword\\\":\\\"geodemographic\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1194\\\":{\\\"AuthorKeyword\\\":\\\"geodesic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"1195\\\":{\\\"AuthorKeyword\\\":\\\"geographic database\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1196\\\":{\\\"AuthorKeyword\\\":\\\"geographic information\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1197\\\":{\\\"AuthorKeyword\\\":\\\"geographic information retrieval\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"1198\\\":{\\\"AuthorKeyword\\\":\\\"geographic information system\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1199\\\":{\\\"AuthorKeyword\\\":\\\"geographic visualization\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1200\\\":{\\\"AuthorKeyword\\\":\\\"geographic geospatial visualization\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1201\\\":{\\\"AuthorKeyword\\\":\\\"geographical information system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1202\\\":{\\\"AuthorKeyword\\\":\\\"geographical weighting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1203\\\":{\\\"AuthorKeyword\\\":\\\"geography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1204\\\":{\\\"AuthorKeyword\\\":\\\"geometric algebra\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"1205\\\":{\\\"AuthorKeyword\\\":\\\"geometric algorithm\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"1206\\\":{\\\"AuthorKeyword\\\":\\\"geometric and color calibration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"1207\\\":{\\\"AuthorKeyword\\\":\\\"geometric calibration\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"1208\\\":{\\\"AuthorKeyword\\\":\\\"geometric coding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"1209\\\":{\\\"AuthorKeyword\\\":\\\"geometric flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1210\\\":{\\\"AuthorKeyword\\\":\\\"geometric modeling\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"1211\\\":{\\\"AuthorKeyword\\\":\\\"geometric substitution\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"1212\\\":{\\\"AuthorKeyword\\\":\\\"geometric surface processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"1213\\\":{\\\"AuthorKeyword\\\":\\\"geometry\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"GeometryBasedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"1214\\\":{\\\"AuthorKeyword\\\":\\\"geometry base technique\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"GeometryBasedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"1215\\\":{\\\"AuthorKeyword\\\":\\\"geometry coding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometryBasedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"1216\\\":{\\\"AuthorKeyword\\\":\\\"geometry compression\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"1217\\\":{\\\"AuthorKeyword\\\":\\\"geometry tensor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1219\\\":{\\\"AuthorKeyword\\\":\\\"georegistration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataRegistration,Fusion,AndIntegration\\\",\\\"ExpertKeywordCount\\\":14},\\\"1220\\\":{\\\"AuthorKeyword\\\":\\\"geos4 global climate model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"1221\\\":{\\\"AuthorKeyword\\\":\\\"geospatial\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1222\\\":{\\\"AuthorKeyword\\\":\\\"geospatial analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1223\\\":{\\\"AuthorKeyword\\\":\\\"geospatial analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1224\\\":{\\\"AuthorKeyword\\\":\\\"geospatial datum\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1225\\\":{\\\"AuthorKeyword\\\":\\\"geospatial time series\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"1226\\\":{\\\"AuthorKeyword\\\":\\\"geospatial visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1227\\\":{\\\"AuthorKeyword\\\":\\\"geostatistic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1228\\\":{\\\"AuthorKeyword\\\":\\\"geovista studio\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"1229\\\":{\\\"AuthorKeyword\\\":\\\"geovisual analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1230\\\":{\\\"AuthorKeyword\\\":\\\"geovisualization\\\",\\\"AuthorKeywordCount\\\":15,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1231\\\":{\\\"AuthorKeyword\\\":\\\"gestalt principle\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"1232\\\":{\\\"AuthorKeyword\\\":\\\"gesture recognition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1233\\\":{\\\"AuthorKeyword\\\":\\\"gigapixel display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeAndHighResDisplays\\\",\\\"ExpertKeywordCount\\\":24},\\\"1234\\\":{\\\"AuthorKeyword\\\":\\\"gigapixel viewer\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeAndHighResDisplays\\\",\\\"ExpertKeywordCount\\\":24},\\\"1235\\\":{\\\"AuthorKeyword\\\":\\\"gigapixel visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeAndHighResDisplays\\\",\\\"ExpertKeywordCount\\\":24},\\\"1236\\\":{\\\"AuthorKeyword\\\":\\\"global illumination\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1237\\\":{\\\"AuthorKeyword\\\":\\\"glyph\\\",\\\"AuthorKeywordCount\\\":14,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"1238\\\":{\\\"AuthorKeyword\\\":\\\"glyph base design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"1239\\\":{\\\"AuthorKeyword\\\":\\\"glyph base technique\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"1240\\\":{\\\"AuthorKeyword\\\":\\\"glyph base visualization\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"1241\\\":{\\\"AuthorKeyword\\\":\\\"glyph design\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"1242\\\":{\\\"AuthorKeyword\\\":\\\"glyph generation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"1243\\\":{\\\"AuthorKeyword\\\":\\\"glyph packing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"1244\\\":{\\\"AuthorKeyword\\\":\\\"glyph render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"1245\\\":{\\\"AuthorKeyword\\\":\\\"goal orient design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"1246\\\":{\\\"AuthorKeyword\\\":\\\"godel universe\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"1247\\\":{\\\"AuthorKeyword\\\":\\\"google gram\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"1248\\\":{\\\"AuthorKeyword\\\":\\\"gouraud shade\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"1249\\\":{\\\"AuthorKeyword\\\":\\\"governance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1250\\\":{\\\"AuthorKeyword\\\":\\\"gpgpu\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1251\\\":{\\\"AuthorKeyword\\\":\\\"gpu\\\",\\\"AuthorKeywordCount\\\":14,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1253\\\":{\\\"AuthorKeyword\\\":\\\"gpu base visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1254\\\":{\\\"AuthorKeyword\\\":\\\"gpu acceleration\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1255\\\":{\\\"AuthorKeyword\\\":\\\"gpu computing\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1256\\\":{\\\"AuthorKeyword\\\":\\\"gpu method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1257\\\":{\\\"AuthorKeyword\\\":\\\"gpu particle tracing and streamline\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1258\\\":{\\\"AuthorKeyword\\\":\\\"gpu programming\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1259\\\":{\\\"AuthorKeyword\\\":\\\"gpu raycasting\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1260\\\":{\\\"AuthorKeyword\\\":\\\"gpu raytracing\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1261\\\":{\\\"AuthorKeyword\\\":\\\"gpu render\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1262\\\":{\\\"AuthorKeyword\\\":\\\"gpu resampling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1263\\\":{\\\"AuthorKeyword\\\":\\\"gpu technique\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1264\\\":{\\\"AuthorKeyword\\\":\\\"gpu cuda\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1265\\\":{\\\"AuthorKeyword\\\":\\\"gpus and multi core architecture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiCoreProcessing\\\",\\\"ExpertKeywordCount\\\":2},\\\"1266\\\":{\\\"AuthorKeyword\\\":\\\"gradient\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"1267\\\":{\\\"AuthorKeyword\\\":\\\"gradient free shading\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"1268\\\":{\\\"AuthorKeyword\\\":\\\"grammar direct design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"1269\\\":{\\\"AuthorKeyword\\\":\\\"grand tour\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"1270\\\":{\\\"AuthorKeyword\\\":\\\"graph\\\",\\\"AuthorKeywordCount\\\":9,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1271\\\":{\\\"AuthorKeyword\\\":\\\"graph base visual analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1272\\\":{\\\"AuthorKeyword\\\":\\\"graph level operation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1273\\\":{\\\"AuthorKeyword\\\":\\\"graph analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1274\\\":{\\\"AuthorKeyword\\\":\\\"graph analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1275\\\":{\\\"AuthorKeyword\\\":\\\"graph and network visualization\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1276\\\":{\\\"AuthorKeyword\\\":\\\"graph browsing and navigation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"1277\\\":{\\\"AuthorKeyword\\\":\\\"graph bundling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1278\\\":{\\\"AuthorKeyword\\\":\\\"graph clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"1279\\\":{\\\"AuthorKeyword\\\":\\\"graph comprehension\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"1280\\\":{\\\"AuthorKeyword\\\":\\\"graph cut\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1281\\\":{\\\"AuthorKeyword\\\":\\\"graph drawing\\\",\\\"AuthorKeywordCount\\\":20,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1282\\\":{\\\"AuthorKeyword\\\":\\\"graph drawing aesthetic\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ArtAndAestheticsInVisualization\\\",\\\"ExpertKeywordCount\\\":16},\\\"1283\\\":{\\\"AuthorKeyword\\\":\\\"graph label placement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1284\\\":{\\\"AuthorKeyword\\\":\\\"graph labeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Labeling\\\",\\\"ExpertKeywordCount\\\":10},\\\"1285\\\":{\\\"AuthorKeyword\\\":\\\"graph layout\\\",\\\"AuthorKeywordCount\\\":11,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1286\\\":{\\\"AuthorKeyword\\\":\\\"graph matching\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1287\\\":{\\\"AuthorKeyword\\\":\\\"graph navigation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"1288\\\":{\\\"AuthorKeyword\\\":\\\"graph partitioning\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"1289\\\":{\\\"AuthorKeyword\\\":\\\"graph product\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1290\\\":{\\\"AuthorKeyword\\\":\\\"graph query language\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"1291\\\":{\\\"AuthorKeyword\\\":\\\"graph search\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1292\\\":{\\\"AuthorKeyword\\\":\\\"graph semantic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1293\\\":{\\\"AuthorKeyword\\\":\\\"graph similarity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"1294\\\":{\\\"AuthorKeyword\\\":\\\"graph simplification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"1296\\\":{\\\"AuthorKeyword\\\":\\\"graph theory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1297\\\":{\\\"AuthorKeyword\\\":\\\"graph visualization\\\",\\\"AuthorKeywordCount\\\":27,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1298\\\":{\\\"AuthorKeyword\\\":\\\"graph wavelet\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1299\\\":{\\\"AuthorKeyword\\\":\\\"graph network datum\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1300\\\":{\\\"AuthorKeyword\\\":\\\"graphic composition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"1301\\\":{\\\"AuthorKeyword\\\":\\\"graphic design\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"1302\\\":{\\\"AuthorKeyword\\\":\\\"graphical browser\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"1303\\\":{\\\"AuthorKeyword\\\":\\\"graphical perception\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"1304\\\":{\\\"AuthorKeyword\\\":\\\"graphical user interface\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"1305\\\":{\\\"AuthorKeyword\\\":\\\"graphical visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"1306\\\":{\\\"AuthorKeyword\\\":\\\"graphic\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"1307\\\":{\\\"AuthorKeyword\\\":\\\"graphic architecture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"1308\\\":{\\\"AuthorKeyword\\\":\\\"graphic cluster\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CpuAndGpuClusters\\\",\\\"ExpertKeywordCount\\\":1},\\\"1309\\\":{\\\"AuthorKeyword\\\":\\\"graphic hardware\\\",\\\"AuthorKeywordCount\\\":18,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"1310\\\":{\\\"AuthorKeyword\\\":\\\"graphic processor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1311\\\":{\\\"AuthorKeyword\\\":\\\"greedy algorithm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Optimization\\\",\\\"ExpertKeywordCount\\\":19},\\\"1312\\\":{\\\"AuthorKeyword\\\":\\\"grey scale\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"1313\\\":{\\\"AuthorKeyword\\\":\\\"grid computing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DistributedSystemsAndGridEnvironments\\\",\\\"ExpertKeywordCount\\\":16},\\\"1314\\\":{\\\"AuthorKeyword\\\":\\\"grid\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1315\\\":{\\\"AuthorKeyword\\\":\\\"ground theory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QualitativeEvaluation\\\",\\\"ExpertKeywordCount\\\":15},\\\"1316\\\":{\\\"AuthorKeyword\\\":\\\"group action\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"1317\\\":{\\\"AuthorKeyword\\\":\\\"group work\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"1318\\\":{\\\"AuthorKeyword\\\":\\\"guarantee quality triangulation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1319\\\":{\\\"AuthorKeyword\\\":\\\"guide interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1320\\\":{\\\"AuthorKeyword\\\":\\\"guide visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"1321\\\":{\\\"AuthorKeyword\\\":\\\"guideline\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"1322\\\":{\\\"AuthorKeyword\\\":\\\"tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1323\\\":{\\\"AuthorKeyword\\\":\\\"hall energy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"1324\\\":{\\\"AuthorKeyword\\\":\\\"halo render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"1325\\\":{\\\"AuthorKeyword\\\":\\\"haloed line\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LineBasedTechniquesAndApproaches\\\",\\\"ExpertKeywordCount\\\":8},\\\"1326\\\":{\\\"AuthorKeyword\\\":\\\"halos\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"1327\\\":{\\\"AuthorKeyword\\\":\\\"hand draw\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ArtAndAestheticsInVisualization\\\",\\\"ExpertKeywordCount\\\":16},\\\"1328\\\":{\\\"AuthorKeyword\\\":\\\"haptic rendering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"1329\\\":{\\\"AuthorKeyword\\\":\\\"haptic\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"1330\\\":{\\\"AuthorKeyword\\\":\\\"hardware\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"1331\\\":{\\\"AuthorKeyword\\\":\\\"hardware accelerate volume render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"1332\\\":{\\\"AuthorKeyword\\\":\\\"hardware accelerate volume visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"1333\\\":{\\\"AuthorKeyword\\\":\\\"hardware acceleration\\\",\\\"AuthorKeywordCount\\\":11,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"1334\\\":{\\\"AuthorKeyword\\\":\\\"hardware acceleration render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"1335\\\":{\\\"AuthorKeyword\\\":\\\"hardware assist raycasting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"1336\\\":{\\\"AuthorKeyword\\\":\\\"hardware assist volume render\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"1337\\\":{\\\"AuthorKeyword\\\":\\\"hardware modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"1338\\\":{\\\"AuthorKeyword\\\":\\\"hardware texture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"1339\\\":{\\\"AuthorKeyword\\\":\\\"hardy multiquadric method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1340\\\":{\\\"AuthorKeyword\\\":\\\"harmonic color\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"1341\\\":{\\\"AuthorKeyword\\\":\\\"hash index\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1342\\\":{\\\"AuthorKeyword\\\":\\\"hasse diagram\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"1343\\\":{\\\"AuthorKeyword\\\":\\\"hatching\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IllustrativeVisualization\\\",\\\"ExpertKeywordCount\\\":40},\\\"1344\\\":{\\\"AuthorKeyword\\\":\\\"hazardous weather\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Emergency/disasterManagement\\\",\\\"ExpertKeywordCount\\\":6},\\\"1345\\\":{\\\"AuthorKeyword\\\":\\\"head mount display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"1346\\\":{\\\"AuthorKeyword\\\":\\\"health\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1347\\\":{\\\"AuthorKeyword\\\":\\\"healthcare\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1348\\\":{\\\"AuthorKeyword\\\":\\\"heart\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1349\\\":{\\\"AuthorKeyword\\\":\\\"heat diffusion\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"1350\\\":{\\\"AuthorKeyword\\\":\\\"heat transfer\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"1351\\\":{\\\"AuthorKeyword\\\":\\\"heatmap\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"1352\\\":{\\\"AuthorKeyword\\\":\\\"height field\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"GeometryBasedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"1353\\\":{\\\"AuthorKeyword\\\":\\\"hemodynamic\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1354\\\":{\\\"AuthorKeyword\\\":\\\"hepatic steatosis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1355\\\":{\\\"AuthorKeyword\\\":\\\"heterogeneous datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataTypesGeneral\\\",\\\"ExpertKeywordCount\\\":12},\\\"1356\\\":{\\\"AuthorKeyword\\\":\\\"heuristic base spatial clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"1357\\\":{\\\"AuthorKeyword\\\":\\\"hexagonal sampling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Sampling\\\",\\\"ExpertKeywordCount\\\":23},\\\"1358\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1359\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical approximation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"1360\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical caching\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1361\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical clustering\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"1362\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical cluster\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"1363\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical datum\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1364\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical datum comparison\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"1365\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical datum encoding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1366\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical datum exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1367\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical datum representation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1368\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical dirichlet process\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1369\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical multidimensional visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1370\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical representation\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1371\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical splatting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"1372\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical topic representation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"1373\\\":{\\\"AuthorKeyword\\\":\\\"hierarchical topic visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"1374\\\":{\\\"AuthorKeyword\\\":\\\"hierarchy\\\",\\\"AuthorKeywordCount\\\":13,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1375\\\":{\\\"AuthorKeyword\\\":\\\"hierarchy datum\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1376\\\":{\\\"AuthorKeyword\\\":\\\"hierarchy navigation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"1377\\\":{\\\"AuthorKeyword\\\":\\\"hierarchy of diamond\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1378\\\":{\\\"AuthorKeyword\\\":\\\"hierarchy tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1379\\\":{\\\"AuthorKeyword\\\":\\\"hierarchy visualization\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1380\\\":{\\\"AuthorKeyword\\\":\\\"high dimensional approximation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"1381\\\":{\\\"AuthorKeyword\\\":\\\"high dimensional datum\\\",\\\"AuthorKeywordCount\\\":18,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"1382\\\":{\\\"AuthorKeyword\\\":\\\"high dimensional datum analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"1383\\\":{\\\"AuthorKeyword\\\":\\\"high dimensional embedding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"1384\\\":{\\\"AuthorKeyword\\\":\\\"high dimensional isosurfacing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"1385\\\":{\\\"AuthorKeyword\\\":\\\"high dimensional space\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"1386\\\":{\\\"AuthorKeyword\\\":\\\"high dimensional visual analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"1387\\\":{\\\"AuthorKeyword\\\":\\\"high dimensional visualization\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"1389\\\":{\\\"AuthorKeyword\\\":\\\"high performance computing\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"1390\\\":{\\\"AuthorKeyword\\\":\\\"high performance visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"1391\\\":{\\\"AuthorKeyword\\\":\\\"high resolution microscopy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Microscopy\\\",\\\"ExpertKeywordCount\\\":11},\\\"1392\\\":{\\\"AuthorKeyword\\\":\\\"high throughput\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1393\\\":{\\\"AuthorKeyword\\\":\\\"high throughput experiment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1394\\\":{\\\"AuthorKeyword\\\":\\\"high throughput imaging\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1395\\\":{\\\"AuthorKeyword\\\":\\\"high dynamic range\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InformationProcessingAndHandling\\\",\\\"ExpertKeywordCount\\\":4},\\\"1396\\\":{\\\"AuthorKeyword\\\":\\\"high quality\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"1397\\\":{\\\"AuthorKeyword\\\":\\\"high temporal resolution visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"1398\\\":{\\\"AuthorKeyword\\\":\\\"high order conjunctive query\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"1399\\\":{\\\"AuthorKeyword\\\":\\\"high order element\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1400\\\":{\\\"AuthorKeyword\\\":\\\"high order singular value decomposition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"1401\\\":{\\\"AuthorKeyword\\\":\\\"high order singularity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"1402\\\":{\\\"AuthorKeyword\\\":\\\"high order tensor\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1403\\\":{\\\"AuthorKeyword\\\":\\\"high order volumetric function\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1404\\\":{\\\"AuthorKeyword\\\":\\\"highlight\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"1405\\\":{\\\"AuthorKeyword\\\":\\\"higraph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1406\\\":{\\\"AuthorKeyword\\\":\\\"histogram\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"1407\\\":{\\\"AuthorKeyword\\\":\\\"historical datum\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1408\\\":{\\\"AuthorKeyword\\\":\\\"historical geography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1409\\\":{\\\"AuthorKeyword\\\":\\\"history\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"ProvenanceAndHistory\\\",\\\"ExpertKeywordCount\\\":15},\\\"1410\\\":{\\\"AuthorKeyword\\\":\\\"holographic video\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"1411\\\":{\\\"AuthorKeyword\\\":\\\"homeland security\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Privacy,Security,IntelligenceAnalysis\\\",\\\"ExpertKeywordCount\\\":16},\\\"1412\\\":{\\\"AuthorKeyword\\\":\\\"homeomorphism\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"1413\\\":{\\\"AuthorKeyword\\\":\\\"homography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1414\\\":{\\\"AuthorKeyword\\\":\\\"horizon graphs\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"1415\\\":{\\\"AuthorKeyword\\\":\\\"hotbox\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1416\\\":{\\\"AuthorKeyword\\\":\\\"html5 canvas\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1417\\\":{\\\"AuthorKeyword\\\":\\\"hue\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"1419\\\":{\\\"AuthorKeyword\\\":\\\"huge dataset\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"1420\\\":{\\\"AuthorKeyword\\\":\\\"huge hierarchy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1421\\\":{\\\"AuthorKeyword\\\":\\\"human computer interaction\\\",\\\"AuthorKeywordCount\\\":16,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"1422\\\":{\\\"AuthorKeyword\\\":\\\"human computer interface\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"1423\\\":{\\\"AuthorKeyword\\\":\\\"human in the loop\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"1424\\\":{\\\"AuthorKeyword\\\":\\\"human information interaction\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"1425\\\":{\\\"AuthorKeyword\\\":\\\"human brain\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1426\\\":{\\\"AuthorKeyword\\\":\\\"human color vision\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"1427\\\":{\\\"AuthorKeyword\\\":\\\"human complexity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"1428\\\":{\\\"AuthorKeyword\\\":\\\"human computation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"1429\\\":{\\\"AuthorKeyword\\\":\\\"human facial modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"1430\\\":{\\\"AuthorKeyword\\\":\\\"human factor\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"1431\\\":{\\\"AuthorKeyword\\\":\\\"human mobility\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1432\\\":{\\\"AuthorKeyword\\\":\\\"human motion visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1433\\\":{\\\"AuthorKeyword\\\":\\\"human subject testing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"1435\\\":{\\\"AuthorKeyword\\\":\\\"human vision\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"1436\\\":{\\\"AuthorKeyword\\\":\\\"human visual perception\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"1437\\\":{\\\"AuthorKeyword\\\":\\\"human visual system\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"1438\\\":{\\\"AuthorKeyword\\\":\\\"hurricane visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"1439\\\":{\\\"AuthorKeyword\\\":\\\"hybrid\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"1440\\\":{\\\"AuthorKeyword\\\":\\\"hybrid algorithm\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1441\\\":{\\\"AuthorKeyword\\\":\\\"hybrid image\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1442\\\":{\\\"AuthorKeyword\\\":\\\"hybrid render\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"1443\\\":{\\\"AuthorKeyword\\\":\\\"hybrid render system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"1444\\\":{\\\"AuthorKeyword\\\":\\\"hybrid visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"1445\\\":{\\\"AuthorKeyword\\\":\\\"hyperbolic space\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"1446\\\":{\\\"AuthorKeyword\\\":\\\"hyperprojection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataTransformation\\\",\\\"ExpertKeywordCount\\\":19},\\\"1447\\\":{\\\"AuthorKeyword\\\":\\\"hyperslice\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1448\\\":{\\\"AuthorKeyword\\\":\\\"hyperspectral visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1449\\\":{\\\"AuthorKeyword\\\":\\\"hyperstreamline placement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"1450\\\":{\\\"AuthorKeyword\\\":\\\"hyperstreamline\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"1451\\\":{\\\"AuthorKeyword\\\":\\\"hypertext\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"1452\\\":{\\\"AuthorKeyword\\\":\\\"hypothesis testing\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"HypothesisForming,Testing,AndVisualEvidence\\\",\\\"ExpertKeywordCount\\\":7},\\\"1453\\\":{\\\"AuthorKeyword\\\":\\\"hysteroscopy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1454\\\":{\\\"AuthorKeyword\\\":\\\"iconic texture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"1455\\\":{\\\"AuthorKeyword\\\":\\\"iconic visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"1456\\\":{\\\"AuthorKeyword\\\":\\\"icon\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"1457\\\":{\\\"AuthorKeyword\\\":\\\"ideal knot\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1458\\\":{\\\"AuthorKeyword\\\":\\\"ideation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"1459\\\":{\\\"AuthorKeyword\\\":\\\"identifiable point\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"1460\\\":{\\\"AuthorKeyword\\\":\\\"illuminate line\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1461\\\":{\\\"AuthorKeyword\\\":\\\"illumination\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1462\\\":{\\\"AuthorKeyword\\\":\\\"illumination and shading\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1463\\\":{\\\"AuthorKeyword\\\":\\\"illumination model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1464\\\":{\\\"AuthorKeyword\\\":\\\"illustration\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"IllustrativeVisualization\\\",\\\"ExpertKeywordCount\\\":40},\\\"1465\\\":{\\\"AuthorKeyword\\\":\\\"illustrative manipulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IllustrativeVisualization\\\",\\\"ExpertKeywordCount\\\":40},\\\"1466\\\":{\\\"AuthorKeyword\\\":\\\"illustrative parallel coordinate\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParallelCoordinates\\\",\\\"ExpertKeywordCount\\\":29},\\\"1467\\\":{\\\"AuthorKeyword\\\":\\\"illustrative render\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"IllustrativeVisualization\\\",\\\"ExpertKeywordCount\\\":40},\\\"1468\\\":{\\\"AuthorKeyword\\\":\\\"illustrative visualization\\\",\\\"AuthorKeywordCount\\\":18,\\\"ExpertKeyword\\\":\\\"IllustrativeVisualization\\\",\\\"ExpertKeywordCount\\\":40},\\\"1469\\\":{\\\"AuthorKeyword\\\":\\\"image base information visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1470\\\":{\\\"AuthorKeyword\\\":\\\"image base method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1471\\\":{\\\"AuthorKeyword\\\":\\\"image base modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1472\\\":{\\\"AuthorKeyword\\\":\\\"image base modeling and render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1473\\\":{\\\"AuthorKeyword\\\":\\\"image base render\\\",\\\"AuthorKeywordCount\\\":10,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1474\\\":{\\\"AuthorKeyword\\\":\\\"image guide streamline\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"1475\\\":{\\\"AuthorKeyword\\\":\\\"image sweep volume\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1476\\\":{\\\"AuthorKeyword\\\":\\\"image analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1477\\\":{\\\"AuthorKeyword\\\":\\\"image browsing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"1479\\\":{\\\"AuthorKeyword\\\":\\\"image comparison\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"1480\\\":{\\\"AuthorKeyword\\\":\\\"image compositing\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1481\\\":{\\\"AuthorKeyword\\\":\\\"image contrast\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1482\\\":{\\\"AuthorKeyword\\\":\\\"image datum management\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"1483\\\":{\\\"AuthorKeyword\\\":\\\"image enhancement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1484\\\":{\\\"AuthorKeyword\\\":\\\"image fusion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataRegistration,Fusion,AndIntegration\\\",\\\"ExpertKeywordCount\\\":14},\\\"1485\\\":{\\\"AuthorKeyword\\\":\\\"image layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1486\\\":{\\\"AuthorKeyword\\\":\\\"image metric\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataAndAnalysisMetrics\\\",\\\"ExpertKeywordCount\\\":11},\\\"1487\\\":{\\\"AuthorKeyword\\\":\\\"image processing\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1488\\\":{\\\"AuthorKeyword\\\":\\\"image recoloring\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1489\\\":{\\\"AuthorKeyword\\\":\\\"image registration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataRegistration,Fusion,AndIntegration\\\",\\\"ExpertKeywordCount\\\":14},\\\"1490\\\":{\\\"AuthorKeyword\\\":\\\"image representation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1491\\\":{\\\"AuthorKeyword\\\":\\\"image retrieval\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"1492\\\":{\\\"AuthorKeyword\\\":\\\"image saliency\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1493\\\":{\\\"AuthorKeyword\\\":\\\"image segmentation\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"1494\\\":{\\\"AuthorKeyword\\\":\\\"image sequence analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1495\\\":{\\\"AuthorKeyword\\\":\\\"image set comparison\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"1496\\\":{\\\"AuthorKeyword\\\":\\\"image warp\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1497\\\":{\\\"AuthorKeyword\\\":\\\"image video analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"1498\\\":{\\\"AuthorKeyword\\\":\\\"immediate mode render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"1499\\\":{\\\"AuthorKeyword\\\":\\\"immersion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"1500\\\":{\\\"AuthorKeyword\\\":\\\"immersive display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"1501\\\":{\\\"AuthorKeyword\\\":\\\"immersive environment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"1502\\\":{\\\"AuthorKeyword\\\":\\\"immersive medium\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"1503\\\":{\\\"AuthorKeyword\\\":\\\"immersive virtual reality interface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"1504\\\":{\\\"AuthorKeyword\\\":\\\"immersive visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"1505\\\":{\\\"AuthorKeyword\\\":\\\"immunofluorescence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"1506\\\":{\\\"AuthorKeyword\\\":\\\"impact\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"1507\\\":{\\\"AuthorKeyword\\\":\\\"impingement zone\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1508\\\":{\\\"AuthorKeyword\\\":\\\"implant planning\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1509\\\":{\\\"AuthorKeyword\\\":\\\"implicit function\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1510\\\":{\\\"AuthorKeyword\\\":\\\"implicit geometry\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1511\\\":{\\\"AuthorKeyword\\\":\\\"implicit model\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"1512\\\":{\\\"AuthorKeyword\\\":\\\"implicit stream flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1513\\\":{\\\"AuthorKeyword\\\":\\\"implicit surface approximation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"1514\\\":{\\\"AuthorKeyword\\\":\\\"implicit surface curvature\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"1515\\\":{\\\"AuthorKeyword\\\":\\\"implicit surface model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"1516\\\":{\\\"AuthorKeyword\\\":\\\"implicit surface render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"1517\\\":{\\\"AuthorKeyword\\\":\\\"implicit surface\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"1518\\\":{\\\"AuthorKeyword\\\":\\\"importance sample\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Sampling\\\",\\\"ExpertKeywordCount\\\":23},\\\"1519\\\":{\\\"AuthorKeyword\\\":\\\"imposter render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"1520\\\":{\\\"AuthorKeyword\\\":\\\"in cylinder flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1521\\\":{\\\"AuthorKeyword\\\":\\\"in situ analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"1522\\\":{\\\"AuthorKeyword\\\":\\\"incomplete ranking\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Ranking\\\",\\\"ExpertKeywordCount\\\":5},\\\"1523\\\":{\\\"AuthorKeyword\\\":\\\"inconsistent lighting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1524\\\":{\\\"AuthorKeyword\\\":\\\"incremental datum exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1525\\\":{\\\"AuthorKeyword\\\":\\\"incremental learning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1526\\\":{\\\"AuthorKeyword\\\":\\\"incremental visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"1527\\\":{\\\"AuthorKeyword\\\":\\\"independent component analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1528\\\":{\\\"AuthorKeyword\\\":\\\"indexing\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"1529\\\":{\\\"AuthorKeyword\\\":\\\"indirect collaboration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"1530\\\":{\\\"AuthorKeyword\\\":\\\"indirect human computer interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"1531\\\":{\\\"AuthorKeyword\\\":\\\"indirect volume render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1532\\\":{\\\"AuthorKeyword\\\":\\\"individual difference\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"1533\\\":{\\\"AuthorKeyword\\\":\\\"inertial particle\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"ExpertKeywordCount\\\":21},\\\"1534\\\":{\\\"AuthorKeyword\\\":\\\"inflow jet\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Engineering\\\",\\\"ExpertKeywordCount\\\":12},\\\"1535\\\":{\\\"AuthorKeyword\\\":\\\"influence estimation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1536\\\":{\\\"AuthorKeyword\\\":\\\"informal learning environment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1537\\\":{\\\"AuthorKeyword\\\":\\\"informal science education\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Education\\\",\\\"ExpertKeywordCount\\\":4},\\\"1538\\\":{\\\"AuthorKeyword\\\":\\\"information guide exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1539\\\":{\\\"AuthorKeyword\\\":\\\"information analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1540\\\":{\\\"AuthorKeyword\\\":\\\"information analytic\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1541\\\":{\\\"AuthorKeyword\\\":\\\"information and scientific visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"IntegratingSpatialAndNonSpatialDataVisualization\\\",\\\"ExpertKeywordCount\\\":7},\\\"1542\\\":{\\\"AuthorKeyword\\\":\\\"information art\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ArtAndAestheticsInVisualization\\\",\\\"ExpertKeywordCount\\\":16},\\\"1544\\\":{\\\"AuthorKeyword\\\":\\\"information discovery\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"KnowledgeDiscovery\\\",\\\"ExpertKeywordCount\\\":28},\\\"1545\\\":{\\\"AuthorKeyword\\\":\\\"information ecology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"1546\\\":{\\\"AuthorKeyword\\\":\\\"information entropy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InformationTheory\\\",\\\"ExpertKeywordCount\\\":12},\\\"1547\\\":{\\\"AuthorKeyword\\\":\\\"information forage\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1548\\\":{\\\"AuthorKeyword\\\":\\\"information interface and presentation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"1549\\\":{\\\"AuthorKeyword\\\":\\\"information landscape\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"1551\\\":{\\\"AuthorKeyword\\\":\\\"information retrieval\\\",\\\"AuthorKeywordCount\\\":11,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"1552\\\":{\\\"AuthorKeyword\\\":\\\"information scent\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"1553\\\":{\\\"AuthorKeyword\\\":\\\"information seek\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1554\\\":{\\\"AuthorKeyword\\\":\\\"information theory\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"InformationTheory\\\",\\\"ExpertKeywordCount\\\":12},\\\"1555\\\":{\\\"AuthorKeyword\\\":\\\"information visualization\\\",\\\"AuthorKeywordCount\\\":160,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"1556\\\":{\\\"AuthorKeyword\\\":\\\"information visualization and exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1557\\\":{\\\"AuthorKeyword\\\":\\\"information visualization and geography base solution\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1558\\\":{\\\"AuthorKeyword\\\":\\\"information visualization architecture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"1559\\\":{\\\"AuthorKeyword\\\":\\\"information visualization for the people\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"1560\\\":{\\\"AuthorKeyword\\\":\\\"information workspace\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"1561\\\":{\\\"AuthorKeyword\\\":\\\"informational divergence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InformationTheory\\\",\\\"ExpertKeywordCount\\\":12},\\\"1562\\\":{\\\"AuthorKeyword\\\":\\\"informative art\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ArtAndAestheticsInVisualization\\\",\\\"ExpertKeywordCount\\\":16},\\\"1563\\\":{\\\"AuthorKeyword\\\":\\\"inhomogeneous datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataTypesGeneral\\\",\\\"ExpertKeywordCount\\\":12},\\\"1564\\\":{\\\"AuthorKeyword\\\":\\\"injection system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Engineering\\\",\\\"ExpertKeywordCount\\\":12},\\\"1565\\\":{\\\"AuthorKeyword\\\":\\\"input output model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"1567\\\":{\\\"AuthorKeyword\\\":\\\"inside removal\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"1568\\\":{\\\"AuthorKeyword\\\":\\\"insight\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1569\\\":{\\\"AuthorKeyword\\\":\\\"insight base evaluation\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"1570\\\":{\\\"AuthorKeyword\\\":\\\"insight management\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1571\\\":{\\\"AuthorKeyword\\\":\\\"insight provenance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ProvenanceAndHistory\\\",\\\"ExpertKeywordCount\\\":15},\\\"1572\\\":{\\\"AuthorKeyword\\\":\\\"instant messaging\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"1573\\\":{\\\"AuthorKeyword\\\":\\\"integral histogram\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"1574\\\":{\\\"AuthorKeyword\\\":\\\"integral surface\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"1576\\\":{\\\"AuthorKeyword\\\":\\\"integrate design environment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"1577\\\":{\\\"AuthorKeyword\\\":\\\"integrate visualization system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"1578\\\":{\\\"AuthorKeyword\\\":\\\"integrate infovis scivi\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IntegratingSpatialAndNonSpatialDataVisualization\\\",\\\"ExpertKeywordCount\\\":7},\\\"1579\\\":{\\\"AuthorKeyword\\\":\\\"integrate spatial and non spatial visualization\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"IntegratingSpatialAndNonSpatialDataVisualization\\\",\\\"ExpertKeywordCount\\\":7},\\\"1580\\\":{\\\"AuthorKeyword\\\":\\\"integration\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"1581\\\":{\\\"AuthorKeyword\\\":\\\"integration operator\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1582\\\":{\\\"AuthorKeyword\\\":\\\"intellectual structure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"1583\\\":{\\\"AuthorKeyword\\\":\\\"intelligence analysis\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"Privacy,Security,IntelligenceAnalysis\\\",\\\"ExpertKeywordCount\\\":16},\\\"1584\\\":{\\\"AuthorKeyword\\\":\\\"intelligent multimodal interface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"1585\\\":{\\\"AuthorKeyword\\\":\\\"intensity blending\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"1586\\\":{\\\"AuthorKeyword\\\":\\\"intent discernment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"1587\\\":{\\\"AuthorKeyword\\\":\\\"inter cell dependency\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"1588\\\":{\\\"AuthorKeyword\\\":\\\"interact with volumetric dataset\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1589\\\":{\\\"AuthorKeyword\\\":\\\"interaction\\\",\\\"AuthorKeywordCount\\\":58,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1590\\\":{\\\"AuthorKeyword\\\":\\\"interaction animation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"1591\\\":{\\\"AuthorKeyword\\\":\\\"interaction design\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"1592\\\":{\\\"AuthorKeyword\\\":\\\"interaction log\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"1593\\\":{\\\"AuthorKeyword\\\":\\\"interaction primitive\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1594\\\":{\\\"AuthorKeyword\\\":\\\"interactive\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1595\\\":{\\\"AuthorKeyword\\\":\\\"interactive algorithm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1596\\\":{\\\"AuthorKeyword\\\":\\\"interactive animation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"1597\\\":{\\\"AuthorKeyword\\\":\\\"interactive classification\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"1598\\\":{\\\"AuthorKeyword\\\":\\\"interactive clustering\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"1599\\\":{\\\"AuthorKeyword\\\":\\\"interactive computational steering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1600\\\":{\\\"AuthorKeyword\\\":\\\"interactive computer graphic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"1601\\\":{\\\"AuthorKeyword\\\":\\\"interactive datum analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1602\\\":{\\\"AuthorKeyword\\\":\\\"interactive design\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"1603\\\":{\\\"AuthorKeyword\\\":\\\"interactive detection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1604\\\":{\\\"AuthorKeyword\\\":\\\"interactive display\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"1605\\\":{\\\"AuthorKeyword\\\":\\\"interactive exploration\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1606\\\":{\\\"AuthorKeyword\\\":\\\"interactive flattening\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"1607\\\":{\\\"AuthorKeyword\\\":\\\"interactive gpu centric rendering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1608\\\":{\\\"AuthorKeyword\\\":\\\"interactive graph drawing\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1609\\\":{\\\"AuthorKeyword\\\":\\\"interactive graph visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1610\\\":{\\\"AuthorKeyword\\\":\\\"interactive graphic\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1611\\\":{\\\"AuthorKeyword\\\":\\\"interactive histogram\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"1612\\\":{\\\"AuthorKeyword\\\":\\\"interactive illumination\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1613\\\":{\\\"AuthorKeyword\\\":\\\"interactive information retrieval\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"1615\\\":{\\\"AuthorKeyword\\\":\\\"interactive labeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Labeling\\\",\\\"ExpertKeywordCount\\\":10},\\\"1616\\\":{\\\"AuthorKeyword\\\":\\\"interactive large scale visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"1617\\\":{\\\"AuthorKeyword\\\":\\\"interactive large high order tetrahedral volume visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1618\\\":{\\\"AuthorKeyword\\\":\\\"interactive machine learning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1619\\\":{\\\"AuthorKeyword\\\":\\\"interactive manipulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ManipulationAndDeformation\\\",\\\"ExpertKeywordCount\\\":7},\\\"1620\\\":{\\\"AuthorKeyword\\\":\\\"interactive map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"1621\\\":{\\\"AuthorKeyword\\\":\\\"interactive navigation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"1622\\\":{\\\"AuthorKeyword\\\":\\\"interactive query\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"1623\\\":{\\\"AuthorKeyword\\\":\\\"interactive re light\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1625\\\":{\\\"AuthorKeyword\\\":\\\"interactive selection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1626\\\":{\\\"AuthorKeyword\\\":\\\"interactive system\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1627\\\":{\\\"AuthorKeyword\\\":\\\"interactive technique\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1628\\\":{\\\"AuthorKeyword\\\":\\\"interactive tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1629\\\":{\\\"AuthorKeyword\\\":\\\"interactive visual analysis\\\",\\\"AuthorKeywordCount\\\":12,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1630\\\":{\\\"AuthorKeyword\\\":\\\"interactive visual analysis of scientific datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1631\\\":{\\\"AuthorKeyword\\\":\\\"interactive visual analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"1632\\\":{\\\"AuthorKeyword\\\":\\\"interactive visual clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"1633\\\":{\\\"AuthorKeyword\\\":\\\"interactive visual computing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1634\\\":{\\\"AuthorKeyword\\\":\\\"interactive visual exploration\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1635\\\":{\\\"AuthorKeyword\\\":\\\"interactive visual exploration and analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1636\\\":{\\\"AuthorKeyword\\\":\\\"interactive visual hypothesis generation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HypothesisForming,Testing,AndVisualEvidence\\\",\\\"ExpertKeywordCount\\\":7},\\\"1637\\\":{\\\"AuthorKeyword\\\":\\\"interactive visualization\\\",\\\"AuthorKeywordCount\\\":15,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1638\\\":{\\\"AuthorKeyword\\\":\\\"interactive volume exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1639\\\":{\\\"AuthorKeyword\\\":\\\"interactive volume illustration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1640\\\":{\\\"AuthorKeyword\\\":\\\"interactive volume raycasting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Raytracing/raycasting\\\",\\\"ExpertKeywordCount\\\":32},\\\"1641\\\":{\\\"AuthorKeyword\\\":\\\"interactive volume render\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1642\\\":{\\\"AuthorKeyword\\\":\\\"interactive volume visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1643\\\":{\\\"AuthorKeyword\\\":\\\"interactive zoom\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"1644\\\":{\\\"AuthorKeyword\\\":\\\"interactivity\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1645\\\":{\\\"AuthorKeyword\\\":\\\"interactome\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"1646\\\":{\\\"AuthorKeyword\\\":\\\"interdomain route\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"1647\\\":{\\\"AuthorKeyword\\\":\\\"interesting view problem\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ViewDependentVisualization\\\",\\\"ExpertKeywordCount\\\":19},\\\"1648\\\":{\\\"AuthorKeyword\\\":\\\"interface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"1649\\\":{\\\"AuthorKeyword\\\":\\\"interface design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"1650\\\":{\\\"AuthorKeyword\\\":\\\"interface design issue\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"1651\\\":{\\\"AuthorKeyword\\\":\\\"interface evaluation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"1652\\\":{\\\"AuthorKeyword\\\":\\\"interface metaphor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"1653\\\":{\\\"AuthorKeyword\\\":\\\"interface to database\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"1654\\\":{\\\"AuthorKeyword\\\":\\\"interior surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"1655\\\":{\\\"AuthorKeyword\\\":\\\"interior exterior classification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"1656\\\":{\\\"AuthorKeyword\\\":\\\"interlink visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultipleLinked/coordinatedViews\\\",\\\"ExpertKeywordCount\\\":50},\\\"1657\\\":{\\\"AuthorKeyword\\\":\\\"internet base visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"1658\\\":{\\\"AuthorKeyword\\\":\\\"internet color\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"1659\\\":{\\\"AuthorKeyword\\\":\\\"internet stability\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"1660\\\":{\\\"AuthorKeyword\\\":\\\"internet visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"1661\\\":{\\\"AuthorKeyword\\\":\\\"interpolation\\\",\\\"AuthorKeywordCount\\\":11,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"1662\\\":{\\\"AuthorKeyword\\\":\\\"interpolation filter\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"1663\\\":{\\\"AuthorKeyword\\\":\\\"interpretation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"1664\\\":{\\\"AuthorKeyword\\\":\\\"interpret system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1665\\\":{\\\"AuthorKeyword\\\":\\\"interrogative visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"1666\\\":{\\\"AuthorKeyword\\\":\\\"intersect surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"1667\\\":{\\\"AuthorKeyword\\\":\\\"interstellar datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Astronomy/Astrophysics\\\",\\\"ExpertKeywordCount\\\":17},\\\"1668\\\":{\\\"AuthorKeyword\\\":\\\"interval tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1669\\\":{\\\"AuthorKeyword\\\":\\\"interval volume\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1670\\\":{\\\"AuthorKeyword\\\":\\\"interval volume render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1671\\\":{\\\"AuthorKeyword\\\":\\\"intravascular ultrasound\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1672\\\":{\\\"AuthorKeyword\\\":\\\"intrinsic laplacian of curvature\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"1673\\\":{\\\"AuthorKeyword\\\":\\\"intrusion detection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"1674\\\":{\\\"AuthorKeyword\\\":\\\"invariant manifold\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"1675\\\":{\\\"AuthorKeyword\\\":\\\"invariant\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1676\\\":{\\\"AuthorKeyword\\\":\\\"inverse kinematic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"1677\\\":{\\\"AuthorKeyword\\\":\\\"inverse render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"1678\\\":{\\\"AuthorKeyword\\\":\\\"investigative analysis\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1679\\\":{\\\"AuthorKeyword\\\":\\\"investigative journalism\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1680\\\":{\\\"AuthorKeyword\\\":\\\"irregular cropping\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"1681\\\":{\\\"AuthorKeyword\\\":\\\"irregular grid\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1682\\\":{\\\"AuthorKeyword\\\":\\\"irregular sampling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Sampling\\\",\\\"ExpertKeywordCount\\\":23},\\\"1683\\\":{\\\"AuthorKeyword\\\":\\\"iso value\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"1684\\\":{\\\"AuthorKeyword\\\":\\\"isocline surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"1685\\\":{\\\"AuthorKeyword\\\":\\\"isocontour\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Contour/Creases/Ridges/Valleys\\\",\\\"ExpertKeywordCount\\\":17},\\\"1686\\\":{\\\"AuthorKeyword\\\":\\\"isoluminance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1687\\\":{\\\"AuthorKeyword\\\":\\\"isometric embed\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"1688\\\":{\\\"AuthorKeyword\\\":\\\"isosurface\\\",\\\"AuthorKeywordCount\\\":46,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"1689\\\":{\\\"AuthorKeyword\\\":\\\"isosurface extraction\\\",\\\"AuthorKeywordCount\\\":17,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"1690\\\":{\\\"AuthorKeyword\\\":\\\"isosurface reconstruction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"1691\\\":{\\\"AuthorKeyword\\\":\\\"isosurface render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"1692\\\":{\\\"AuthorKeyword\\\":\\\"isosurface statistic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"1693\\\":{\\\"AuthorKeyword\\\":\\\"isosurface and surface extraction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"1694\\\":{\\\"AuthorKeyword\\\":\\\"isotropic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1695\\\":{\\\"AuthorKeyword\\\":\\\"item response theory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"1696\\\":{\\\"AuthorKeyword\\\":\\\"iterative analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1697\\\":{\\\"AuthorKeyword\\\":\\\"iterative exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1698\\\":{\\\"AuthorKeyword\\\":\\\"iterative query refinement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"1699\\\":{\\\"AuthorKeyword\\\":\\\"java\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1700\\\":{\\\"AuthorKeyword\\\":\\\"javascript\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1701\\\":{\\\"AuthorKeyword\\\":\\\"jitter\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"1702\\\":{\\\"AuthorKeyword\\\":\\\"jittered grid icon\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"1703\\\":{\\\"AuthorKeyword\\\":\\\"join tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1704\\\":{\\\"AuthorKeyword\\\":\\\"joint distribution\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1705\\\":{\\\"AuthorKeyword\\\":\\\"joint feature temporal space\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"1706\\\":{\\\"AuthorKeyword\\\":\\\"journalism\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1708\\\":{\\\"AuthorKeyword\\\":\\\"juxtaposition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"1709\\\":{\\\"AuthorKeyword\\\":\\\"tree\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1710\\\":{\\\"AuthorKeyword\\\":\\\"mean\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"1711\\\":{\\\"AuthorKeyword\\\":\\\"order alpha shape\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"1712\\\":{\\\"AuthorKeyword\\\":\\\"kernel density estimation\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1713\\\":{\\\"AuthorKeyword\\\":\\\"kernel regression\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1714\\\":{\\\"AuthorKeyword\\\":\\\"kernel smoothing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataCleaningAndSmoothing\\\",\\\"ExpertKeywordCount\\\":5},\\\"1715\\\":{\\\"AuthorKeyword\\\":\\\"key value store\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"1716\\\":{\\\"AuthorKeyword\\\":\\\"kinship\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"1717\\\":{\\\"AuthorKeyword\\\":\\\"knot theory\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1719\\\":{\\\"AuthorKeyword\\\":\\\"knowledge base\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualKnowledgeRepresentationAndExternalization\\\",\\\"ExpertKeywordCount\\\":13},\\\"1720\\\":{\\\"AuthorKeyword\\\":\\\"knowledge discovery\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"KnowledgeDiscovery\\\",\\\"ExpertKeywordCount\\\":28},\\\"1721\\\":{\\\"AuthorKeyword\\\":\\\"knowledge generation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"KnowledgeDiscovery\\\",\\\"ExpertKeywordCount\\\":28},\\\"1722\\\":{\\\"AuthorKeyword\\\":\\\"knowledge management\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualKnowledgeRepresentationAndExternalization\\\",\\\"ExpertKeywordCount\\\":13},\\\"1723\\\":{\\\"AuthorKeyword\\\":\\\"knowledge representation\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"VisualKnowledgeRepresentationAndExternalization\\\",\\\"ExpertKeywordCount\\\":13},\\\"1724\\\":{\\\"AuthorKeyword\\\":\\\"knowledge sharing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualKnowledgeRepresentationAndExternalization\\\",\\\"ExpertKeywordCount\\\":13},\\\"1725\\\":{\\\"AuthorKeyword\\\":\\\"knowledge task\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"1726\\\":{\\\"AuthorKeyword\\\":\\\"knowledge visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualKnowledgeRepresentationAndExternalization\\\",\\\"ExpertKeywordCount\\\":13},\\\"1727\\\":{\\\"AuthorKeyword\\\":\\\"kullback leibler decomposition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InformationTheory\\\",\\\"ExpertKeywordCount\\\":12},\\\"1728\\\":{\\\"AuthorKeyword\\\":\\\"kullback leibler distance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InformationTheory\\\",\\\"ExpertKeywordCount\\\":12},\\\"1729\\\":{\\\"AuthorKeyword\\\":\\\"label consistency\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Labeling\\\",\\\"ExpertKeywordCount\\\":10},\\\"1730\\\":{\\\"AuthorKeyword\\\":\\\"label filtering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Labeling\\\",\\\"ExpertKeywordCount\\\":10},\\\"1731\\\":{\\\"AuthorKeyword\\\":\\\"label placement\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Labeling\\\",\\\"ExpertKeywordCount\\\":10},\\\"1732\\\":{\\\"AuthorKeyword\\\":\\\"label selection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Labeling\\\",\\\"ExpertKeywordCount\\\":10},\\\"1733\\\":{\\\"AuthorKeyword\\\":\\\"laboratory study\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"LaboratoryStudies\\\",\\\"ExpertKeywordCount\\\":3},\\\"1734\\\":{\\\"AuthorKeyword\\\":\\\"lagrangian\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1735\\\":{\\\"AuthorKeyword\\\":\\\"lagrangian flow visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1736\\\":{\\\"AuthorKeyword\\\":\\\"landing gear\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Engineering\\\",\\\"ExpertKeywordCount\\\":12},\\\"1737\\\":{\\\"AuthorKeyword\\\":\\\"landscape visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"1739\\\":{\\\"AuthorKeyword\\\":\\\"large format projection display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeAndHighResDisplays\\\",\\\"ExpertKeywordCount\\\":24},\\\"1740\\\":{\\\"AuthorKeyword\\\":\\\"large format tile projection display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeAndHighResDisplays\\\",\\\"ExpertKeywordCount\\\":24},\\\"1741\\\":{\\\"AuthorKeyword\\\":\\\"large neighborhood search\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Optimization\\\",\\\"ExpertKeywordCount\\\":19},\\\"1742\\\":{\\\"AuthorKeyword\\\":\\\"large scale datum\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"1743\\\":{\\\"AuthorKeyword\\\":\\\"large scale display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeAndHighResDisplays\\\",\\\"ExpertKeywordCount\\\":24},\\\"1744\\\":{\\\"AuthorKeyword\\\":\\\"large scale document visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"1745\\\":{\\\"AuthorKeyword\\\":\\\"large scale exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"1746\\\":{\\\"AuthorKeyword\\\":\\\"large scale microarray\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"1747\\\":{\\\"AuthorKeyword\\\":\\\"large scale multivariate visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"1748\\\":{\\\"AuthorKeyword\\\":\\\"large scale simulation and visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"1749\\\":{\\\"AuthorKeyword\\\":\\\"large scale visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"1750\\\":{\\\"AuthorKeyword\\\":\\\"large scale volume render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1751\\\":{\\\"AuthorKeyword\\\":\\\"large and high resolution display\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"LargeAndHighResDisplays\\\",\\\"ExpertKeywordCount\\\":24},\\\"1752\\\":{\\\"AuthorKeyword\\\":\\\"large area display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeAndHighResDisplays\\\",\\\"ExpertKeywordCount\\\":24},\\\"1753\\\":{\\\"AuthorKeyword\\\":\\\"large benign prostatic hyperplasia simulator\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1755\\\":{\\\"AuthorKeyword\\\":\\\"large datum\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"1756\\\":{\\\"AuthorKeyword\\\":\\\"large datum exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"1757\\\":{\\\"AuthorKeyword\\\":\\\"large datum set visualization\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"1759\\\":{\\\"AuthorKeyword\\\":\\\"large datum visualization\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"1760\\\":{\\\"AuthorKeyword\\\":\\\"large display\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"LargeAndHighResDisplays\\\",\\\"ExpertKeywordCount\\\":24},\\\"1761\\\":{\\\"AuthorKeyword\\\":\\\"large format display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeAndHighResDisplays\\\",\\\"ExpertKeywordCount\\\":24},\\\"1762\\\":{\\\"AuthorKeyword\\\":\\\"large graph visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1763\\\":{\\\"AuthorKeyword\\\":\\\"large mesh\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1764\\\":{\\\"AuthorKeyword\\\":\\\"large network visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1765\\\":{\\\"AuthorKeyword\\\":\\\"large spatial scale\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"1766\\\":{\\\"AuthorKeyword\\\":\\\"large tree visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1767\\\":{\\\"AuthorKeyword\\\":\\\"large unstructured grid\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1768\\\":{\\\"AuthorKeyword\\\":\\\"large volume visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1769\\\":{\\\"AuthorKeyword\\\":\\\"large volume\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1770\\\":{\\\"AuthorKeyword\\\":\\\"large volumetric datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1771\\\":{\\\"AuthorKeyword\\\":\\\"large contour\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Contour/Creases/Ridges/Valleys\\\",\\\"ExpertKeywordCount\\\":17},\\\"1772\\\":{\\\"AuthorKeyword\\\":\\\"last fm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"1773\\\":{\\\"AuthorKeyword\\\":\\\"late enhancement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"1774\\\":{\\\"AuthorKeyword\\\":\\\"latency\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"RealtimeProcessing,Rendering,AndVisualizationGeneral\\\",\\\"ExpertKeywordCount\\\":14},\\\"1775\\\":{\\\"AuthorKeyword\\\":\\\"latent dirichlet allocation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1776\\\":{\\\"AuthorKeyword\\\":\\\"lattice\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1777\\\":{\\\"AuthorKeyword\\\":\\\"lattice boltzmann model\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1778\\\":{\\\"AuthorKeyword\\\":\\\"law enforcement\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1779\\\":{\\\"AuthorKeyword\\\":\\\"layer\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"1780\\\":{\\\"AuthorKeyword\\\":\\\"layer classification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"1781\\\":{\\\"AuthorKeyword\\\":\\\"layer perception\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"1782\\\":{\\\"AuthorKeyword\\\":\\\"layer depth image\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"1784\\\":{\\\"AuthorKeyword\\\":\\\"layer surface\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"1785\\\":{\\\"AuthorKeyword\\\":\\\"layout\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"1786\\\":{\\\"AuthorKeyword\\\":\\\"layout algorithm\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"1787\\\":{\\\"AuthorKeyword\\\":\\\"layout management\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"1788\\\":{\\\"AuthorKeyword\\\":\\\"laziness\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1789\\\":{\\\"AuthorKeyword\\\":\\\"lazy evaluation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1790\\\":{\\\"AuthorKeyword\\\":\\\"least square approximation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1791\\\":{\\\"AuthorKeyword\\\":\\\"leave ventricle diagnosis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1792\\\":{\\\"AuthorKeyword\\\":\\\"legal citation network\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1793\\\":{\\\"AuthorKeyword\\\":\\\"legend\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"1794\\\":{\\\"AuthorKeyword\\\":\\\"legibility\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationMetricsAndBenchmarks\\\",\\\"ExpertKeywordCount\\\":19},\\\"1795\\\":{\\\"AuthorKeyword\\\":\\\"lens\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"1796\\\":{\\\"AuthorKeyword\\\":\\\"lens distortion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"1797\\\":{\\\"AuthorKeyword\\\":\\\"level of detail\\\",\\\"AuthorKeywordCount\\\":38,\\\"ExpertKeyword\\\":\\\"LevelOfDetail\\\",\\\"ExpertKeywordCount\\\":48},\\\"1798\\\":{\\\"AuthorKeyword\\\":\\\"level of detail algorithm\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"LevelOfDetail\\\",\\\"ExpertKeywordCount\\\":48},\\\"1799\\\":{\\\"AuthorKeyword\\\":\\\"level of detail generation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LevelOfDetail\\\",\\\"ExpertKeywordCount\\\":48},\\\"1800\\\":{\\\"AuthorKeyword\\\":\\\"level of detail map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LevelOfDetail\\\",\\\"ExpertKeywordCount\\\":48},\\\"1801\\\":{\\\"AuthorKeyword\\\":\\\"level of detail representation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LevelOfDetail\\\",\\\"ExpertKeywordCount\\\":48},\\\"1802\\\":{\\\"AuthorKeyword\\\":\\\"level of detail technique\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"LevelOfDetail\\\",\\\"ExpertKeywordCount\\\":48},\\\"1803\\\":{\\\"AuthorKeyword\\\":\\\"level set graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1804\\\":{\\\"AuthorKeyword\\\":\\\"level set method\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1805\\\":{\\\"AuthorKeyword\\\":\\\"level set model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1806\\\":{\\\"AuthorKeyword\\\":\\\"level set topology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"1807\\\":{\\\"AuthorKeyword\\\":\\\"level set\\\",\\\"AuthorKeywordCount\\\":9,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1808\\\":{\\\"AuthorKeyword\\\":\\\"lie advection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1809\\\":{\\\"AuthorKeyword\\\":\\\"life cycle assessment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1810\\\":{\\\"AuthorKeyword\\\":\\\"life science and engineering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1811\\\":{\\\"AuthorKeyword\\\":\\\"lifelogge\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"1812\\\":{\\\"AuthorKeyword\\\":\\\"lift up operation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1813\\\":{\\\"AuthorKeyword\\\":\\\"ligand exclude surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"1814\\\":{\\\"AuthorKeyword\\\":\\\"light\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1815\\\":{\\\"AuthorKeyword\\\":\\\"light color\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"1816\\\":{\\\"AuthorKeyword\\\":\\\"light placement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1817\\\":{\\\"AuthorKeyword\\\":\\\"light transport\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1818\\\":{\\\"AuthorKeyword\\\":\\\"lighting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1819\\\":{\\\"AuthorKeyword\\\":\\\"lighting design\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1820\\\":{\\\"AuthorKeyword\\\":\\\"lighting model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1821\\\":{\\\"AuthorKeyword\\\":\\\"lighting similarity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1822\\\":{\\\"AuthorKeyword\\\":\\\"light stability\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1824\\\":{\\\"AuthorKeyword\\\":\\\"line chart\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"1825\\\":{\\\"AuthorKeyword\\\":\\\"line datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LineBasedTechniquesAndApproaches\\\",\\\"ExpertKeywordCount\\\":8},\\\"1826\\\":{\\\"AuthorKeyword\\\":\\\"line field\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"1827\\\":{\\\"AuthorKeyword\\\":\\\"line integral convolution\\\",\\\"AuthorKeywordCount\\\":12,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1828\\\":{\\\"AuthorKeyword\\\":\\\"line of curvature\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"1829\\\":{\\\"AuthorKeyword\\\":\\\"line placement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LineBasedTechniquesAndApproaches\\\",\\\"ExpertKeywordCount\\\":8},\\\"1830\\\":{\\\"AuthorKeyword\\\":\\\"line predicate\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LineBasedTechniquesAndApproaches\\\",\\\"ExpertKeywordCount\\\":8},\\\"1831\\\":{\\\"AuthorKeyword\\\":\\\"linear correlation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1832\\\":{\\\"AuthorKeyword\\\":\\\"linear discriminant analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"1833\\\":{\\\"AuthorKeyword\\\":\\\"linear interpolation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"1834\\\":{\\\"AuthorKeyword\\\":\\\"linear prediction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1835\\\":{\\\"AuthorKeyword\\\":\\\"linear programming\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1836\\\":{\\\"AuthorKeyword\\\":\\\"line\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LineBasedTechniquesAndApproaches\\\",\\\"ExpertKeywordCount\\\":8},\\\"1837\\\":{\\\"AuthorKeyword\\\":\\\"lineup\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"1838\\\":{\\\"AuthorKeyword\\\":\\\"linguistic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"1839\\\":{\\\"AuthorKeyword\\\":\\\"link analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1840\\\":{\\\"AuthorKeyword\\\":\\\"linkage analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"1841\\\":{\\\"AuthorKeyword\\\":\\\"linkage disequilibrium\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"1842\\\":{\\\"AuthorKeyword\\\":\\\"linkage disequilibrium analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"1843\\\":{\\\"AuthorKeyword\\\":\\\"link common work\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"1844\\\":{\\\"AuthorKeyword\\\":\\\"link related view\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultipleLinked/coordinatedViews\\\",\\\"ExpertKeywordCount\\\":50},\\\"1845\\\":{\\\"AuthorKeyword\\\":\\\"link view visual analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultipleLinked/coordinatedViews\\\",\\\"ExpertKeywordCount\\\":50},\\\"1846\\\":{\\\"AuthorKeyword\\\":\\\"link view\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"MultipleLinked/coordinatedViews\\\",\\\"ExpertKeywordCount\\\":50},\\\"1847\\\":{\\\"AuthorKeyword\\\":\\\"lipschitz exponent\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1848\\\":{\\\"AuthorKeyword\\\":\\\"liquid crystal\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"1849\\\":{\\\"AuthorKeyword\\\":\\\"listen history\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ProvenanceAndHistory\\\",\\\"ExpertKeywordCount\\\":15},\\\"1850\\\":{\\\"AuthorKeyword\\\":\\\"literacy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"1851\\\":{\\\"AuthorKeyword\\\":\\\"literary analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"1852\\\":{\\\"AuthorKeyword\\\":\\\"literary study\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"1853\\\":{\\\"AuthorKeyword\\\":\\\"literature analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"1854\\\":{\\\"AuthorKeyword\\\":\\\"literature browser\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"1855\\\":{\\\"AuthorKeyword\\\":\\\"literature fingerprint\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"1856\\\":{\\\"AuthorKeyword\\\":\\\"live monitoring\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TimeCriticalApplications\\\",\\\"ExpertKeywordCount\\\":3},\\\"1857\\\":{\\\"AuthorKeyword\\\":\\\"local fitting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1858\\\":{\\\"AuthorKeyword\\\":\\\"local illumination\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"1860\\\":{\\\"AuthorKeyword\\\":\\\"local statistical complexity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1861\\\":{\\\"AuthorKeyword\\\":\\\"local statistic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1862\\\":{\\\"AuthorKeyword\\\":\\\"local surface extraction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"1863\\\":{\\\"AuthorKeyword\\\":\\\"locomotion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"1864\\\":{\\\"AuthorKeyword\\\":\\\"log file analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"1865\\\":{\\\"AuthorKeyword\\\":\\\"log transformation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataTransformation\\\",\\\"ExpertKeywordCount\\\":19},\\\"1866\\\":{\\\"AuthorKeyword\\\":\\\"log visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"1867\\\":{\\\"AuthorKeyword\\\":\\\"logarithmic scale\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataTransformation\\\",\\\"ExpertKeywordCount\\\":19},\\\"1868\\\":{\\\"AuthorKeyword\\\":\\\"logical operation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1869\\\":{\\\"AuthorKeyword\\\":\\\"logical tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"1870\\\":{\\\"AuthorKeyword\\\":\\\"logistical networking\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1871\\\":{\\\"AuthorKeyword\\\":\\\"long term memory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"1872\\\":{\\\"AuthorKeyword\\\":\\\"long edge bisection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"1873\\\":{\\\"AuthorKeyword\\\":\\\"loop scheme\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1874\\\":{\\\"AuthorKeyword\\\":\\\"lossless compression\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"1875\\\":{\\\"AuthorKeyword\\\":\\\"low dimensional embedding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"1876\\\":{\\\"AuthorKeyword\\\":\\\"low fidelity prototyping\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"1877\\\":{\\\"AuthorKeyword\\\":\\\"luminance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"1878\\\":{\\\"AuthorKeyword\\\":\\\"lung ct\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1879\\\":{\\\"AuthorKeyword\\\":\\\"machine learning\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1881\\\":{\\\"AuthorKeyword\\\":\\\"magic lens\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1882\\\":{\\\"AuthorKeyword\\\":\\\"magnetic field\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"1883\\\":{\\\"AuthorKeyword\\\":\\\"magnetic field visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"1884\\\":{\\\"AuthorKeyword\\\":\\\"magnetic resonance imaging\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1885\\\":{\\\"AuthorKeyword\\\":\\\"magnification\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"1886\\\":{\\\"AuthorKeyword\\\":\\\"magnification brushing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"1887\\\":{\\\"AuthorKeyword\\\":\\\"majority voting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"1888\\\":{\\\"AuthorKeyword\\\":\\\"manifold\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"1889\\\":{\\\"AuthorKeyword\\\":\\\"manifold learning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1890\\\":{\\\"AuthorKeyword\\\":\\\"manipulator\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"1891\\\":{\\\"AuthorKeyword\\\":\\\"mantle convection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"1892\\\":{\\\"AuthorKeyword\\\":\\\"many core computing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiCoreProcessing\\\",\\\"ExpertKeywordCount\\\":2},\\\"1893\\\":{\\\"AuthorKeyword\\\":\\\"many eye\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"1894\\\":{\\\"AuthorKeyword\\\":\\\"map labeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Labeling\\\",\\\"ExpertKeywordCount\\\":10},\\\"1895\\\":{\\\"AuthorKeyword\\\":\\\"map transformation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataTransformation\\\",\\\"ExpertKeywordCount\\\":19},\\\"1896\\\":{\\\"AuthorKeyword\\\":\\\"mapping\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"1897\\\":{\\\"AuthorKeyword\\\":\\\"map\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"1898\\\":{\\\"AuthorKeyword\\\":\\\"march cube\\\",\\\"AuthorKeywordCount\\\":15,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"1899\\\":{\\\"AuthorKeyword\\\":\\\"market research\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Business,Finance,Economy,Manufacturing\\\",\\\"ExpertKeywordCount\\\":12},\\\"1900\\\":{\\\"AuthorKeyword\\\":\\\"mark menu\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"1901\\\":{\\\"AuthorKeyword\\\":\\\"mass spectrometry\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"1902\\\":{\\\"AuthorKeyword\\\":\\\"mass spectrometry datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"1903\\\":{\\\"AuthorKeyword\\\":\\\"massive data set\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"1904\\\":{\\\"AuthorKeyword\\\":\\\"massive mesh\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1905\\\":{\\\"AuthorKeyword\\\":\\\"match mismatch measure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationMetricsAndBenchmarks\\\",\\\"ExpertKeywordCount\\\":19},\\\"1906\\\":{\\\"AuthorKeyword\\\":\\\"material boundary surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"1907\\\":{\\\"AuthorKeyword\\\":\\\"material science\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"1908\\\":{\\\"AuthorKeyword\\\":\\\"mathematical foundation for visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"1909\\\":{\\\"AuthorKeyword\\\":\\\"mathematical visualization\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"Mathematics\\\",\\\"ExpertKeywordCount\\\":8},\\\"1910\\\":{\\\"AuthorKeyword\\\":\\\"matrix\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"MatrixRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":13},\\\"1912\\\":{\\\"AuthorKeyword\\\":\\\"matrix base representation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MatrixRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":13},\\\"1913\\\":{\\\"AuthorKeyword\\\":\\\"matrix factorization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MatrixRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":13},\\\"1914\\\":{\\\"AuthorKeyword\\\":\\\"matrix ordering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MatrixRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":13},\\\"1915\\\":{\\\"AuthorKeyword\\\":\\\"matrix visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MatrixRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":13},\\\"1916\\\":{\\\"AuthorKeyword\\\":\\\"maximum entropy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAndAnalysisMetrics\\\",\\\"ExpertKeywordCount\\\":11},\\\"1917\\\":{\\\"AuthorKeyword\\\":\\\"mean shift\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1918\\\":{\\\"AuthorKeyword\\\":\\\"mechanical turk\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"1919\\\":{\\\"AuthorKeyword\\\":\\\"medium analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"1920\\\":{\\\"AuthorKeyword\\\":\\\"medial axis transform\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"1921\\\":{\\\"AuthorKeyword\\\":\\\"medial surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"1922\\\":{\\\"AuthorKeyword\\\":\\\"medical\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1923\\\":{\\\"AuthorKeyword\\\":\\\"medical application\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1924\\\":{\\\"AuthorKeyword\\\":\\\"medical decision support system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1925\\\":{\\\"AuthorKeyword\\\":\\\"medical imaging\\\",\\\"AuthorKeywordCount\\\":9,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1926\\\":{\\\"AuthorKeyword\\\":\\\"medical informatic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1927\\\":{\\\"AuthorKeyword\\\":\\\"medical record\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1928\\\":{\\\"AuthorKeyword\\\":\\\"medical simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1929\\\":{\\\"AuthorKeyword\\\":\\\"medical visualization\\\",\\\"AuthorKeywordCount\\\":18,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"1930\\\":{\\\"AuthorKeyword\\\":\\\"memorability\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"1931\\\":{\\\"AuthorKeyword\\\":\\\"memory\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"1932\\\":{\\\"AuthorKeyword\\\":\\\"mental map\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"1933\\\":{\\\"AuthorKeyword\\\":\\\"mental model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"1934\\\":{\\\"AuthorKeyword\\\":\\\"mental registration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"1936\\\":{\\\"AuthorKeyword\\\":\\\"mesh\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1937\\\":{\\\"AuthorKeyword\\\":\\\"mesh and graph layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"1938\\\":{\\\"AuthorKeyword\\\":\\\"mesh comparison\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1939\\\":{\\\"AuthorKeyword\\\":\\\"mesh compression\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"1940\\\":{\\\"AuthorKeyword\\\":\\\"mesh connectivity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1941\\\":{\\\"AuthorKeyword\\\":\\\"mesh data structure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"1942\\\":{\\\"AuthorKeyword\\\":\\\"mesh decimation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1943\\\":{\\\"AuthorKeyword\\\":\\\"mesh deformation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1944\\\":{\\\"AuthorKeyword\\\":\\\"mesh generation\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1946\\\":{\\\"AuthorKeyword\\\":\\\"mesh partition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1947\\\":{\\\"AuthorKeyword\\\":\\\"mesh simplification\\\",\\\"AuthorKeywordCount\\\":9,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"1948\\\":{\\\"AuthorKeyword\\\":\\\"mesh subdivision\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1949\\\":{\\\"AuthorKeyword\\\":\\\"mesh\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"1950\\\":{\\\"AuthorKeyword\\\":\\\"mesoscale eddy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"1951\\\":{\\\"AuthorKeyword\\\":\\\"meta datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataTypesGeneral\\\",\\\"ExpertKeywordCount\\\":12},\\\"1952\\\":{\\\"AuthorKeyword\\\":\\\"meta flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"1953\\\":{\\\"AuthorKeyword\\\":\\\"meta visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"1954\\\":{\\\"AuthorKeyword\\\":\\\"meta information\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataTypesGeneral\\\",\\\"ExpertKeywordCount\\\":12},\\\"1955\\\":{\\\"AuthorKeyword\\\":\\\"metal artifact reduction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"1956\\\":{\\\"AuthorKeyword\\\":\\\"metaphor\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"1957\\\":{\\\"AuthorKeyword\\\":\\\"meteorology\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"1958\\\":{\\\"AuthorKeyword\\\":\\\"methodology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"1959\\\":{\\\"AuthorKeyword\\\":\\\"methodology design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"1960\\\":{\\\"AuthorKeyword\\\":\\\"metric tensor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"1961\\\":{\\\"AuthorKeyword\\\":\\\"metric\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"EvaluationMetricsAndBenchmarks\\\",\\\"ExpertKeywordCount\\\":19},\\\"1962\\\":{\\\"AuthorKeyword\\\":\\\"metric for cache coherence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationMetricsAndBenchmarks\\\",\\\"ExpertKeywordCount\\\":19},\\\"1963\\\":{\\\"AuthorKeyword\\\":\\\"metro map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"1964\\\":{\\\"AuthorKeyword\\\":\\\"metrology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"1965\\\":{\\\"AuthorKeyword\\\":\\\"microarray datum\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"1966\\\":{\\\"AuthorKeyword\\\":\\\"microarray\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"1967\\\":{\\\"AuthorKeyword\\\":\\\"microblog analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"1968\\\":{\\\"AuthorKeyword\\\":\\\"microblog datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"1969\\\":{\\\"AuthorKeyword\\\":\\\"microblogge\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"1970\\\":{\\\"AuthorKeyword\\\":\\\"microscopy\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Microscopy\\\",\\\"ExpertKeywordCount\\\":11},\\\"1971\\\":{\\\"AuthorKeyword\\\":\\\"microscopy visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Microscopy\\\",\\\"ExpertKeywordCount\\\":11},\\\"1972\\\":{\\\"AuthorKeyword\\\":\\\"midi\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Acoustics,Sound,Sonification\\\",\\\"ExpertKeywordCount\\\":9},\\\"1973\\\":{\\\"AuthorKeyword\\\":\\\"minimum area triangulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"1974\\\":{\\\"AuthorKeyword\\\":\\\"minimum spanning tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"1975\\\":{\\\"AuthorKeyword\\\":\\\"mix effect\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1976\\\":{\\\"AuthorKeyword\\\":\\\"mixed initiative system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualAnalysisModels\\\",\\\"ExpertKeywordCount\\\":9},\\\"1977\\\":{\\\"AuthorKeyword\\\":\\\"mixed initiative visual analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualAnalysisModels\\\",\\\"ExpertKeywordCount\\\":9},\\\"1978\\\":{\\\"AuthorKeyword\\\":\\\"mix polygon and volume\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"1979\\\":{\\\"AuthorKeyword\\\":\\\"mobile and ubiquitous visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Small,Mobile,UbiquitousDevices/Displays\\\",\\\"ExpertKeywordCount\\\":8},\\\"1980\\\":{\\\"AuthorKeyword\\\":\\\"mobile object\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"1981\\\":{\\\"AuthorKeyword\\\":\\\"mobile visualization\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Small,Mobile,UbiquitousDevices/Displays\\\",\\\"ExpertKeywordCount\\\":8},\\\"1982\\\":{\\\"AuthorKeyword\\\":\\\"mobility\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"1983\\\":{\\\"AuthorKeyword\\\":\\\"mobject\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"1984\\\":{\\\"AuthorKeyword\\\":\\\"model\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"1985\\\":{\\\"AuthorKeyword\\\":\\\"model base reasoning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Reasoning,ProblemSolving,AndDecisionMaking\\\",\\\"ExpertKeywordCount\\\":15},\\\"1986\\\":{\\\"AuthorKeyword\\\":\\\"model assessment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1987\\\":{\\\"AuthorKeyword\\\":\\\"model building\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1988\\\":{\\\"AuthorKeyword\\\":\\\"model comparison\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1989\\\":{\\\"AuthorKeyword\\\":\\\"model fit\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1990\\\":{\\\"AuthorKeyword\\\":\\\"model selection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1991\\\":{\\\"AuthorKeyword\\\":\\\"model simplification\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"1992\\\":{\\\"AuthorKeyword\\\":\\\"model space visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1993\\\":{\\\"AuthorKeyword\\\":\\\"model steering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"1996\\\":{\\\"AuthorKeyword\\\":\\\"model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"1997\\\":{\\\"AuthorKeyword\\\":\\\"model from image sequence\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"1998\\\":{\\\"AuthorKeyword\\\":\\\"model of color vision\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"1999\\\":{\\\"AuthorKeyword\\\":\\\"modify shepard method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"2000\\\":{\\\"AuthorKeyword\\\":\\\"modular\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2001\\\":{\\\"AuthorKeyword\\\":\\\"modular decomposition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2002\\\":{\\\"AuthorKeyword\\\":\\\"modular visualization environment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"2003\\\":{\\\"AuthorKeyword\\\":\\\"mohr circle\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"2004\\\":{\\\"AuthorKeyword\\\":\\\"molecular chemistry\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"2005\\\":{\\\"AuthorKeyword\\\":\\\"molecular conformation analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"2006\\\":{\\\"AuthorKeyword\\\":\\\"molecular dynamic\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"2007\\\":{\\\"AuthorKeyword\\\":\\\"molecular dynamic visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"2008\\\":{\\\"AuthorKeyword\\\":\\\"molecular graphic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"2009\\\":{\\\"AuthorKeyword\\\":\\\"molecular modeling\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"2010\\\":{\\\"AuthorKeyword\\\":\\\"molecular surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"2011\\\":{\\\"AuthorKeyword\\\":\\\"molecular visualization\\\",\\\"AuthorKeywordCount\\\":11,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"2012\\\":{\\\"AuthorKeyword\\\":\\\"monge brenier theory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"2013\\\":{\\\"AuthorKeyword\\\":\\\"monte carlo integration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2014\\\":{\\\"AuthorKeyword\\\":\\\"morphable model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TransitionsAndMorphing\\\",\\\"ExpertKeywordCount\\\":8},\\\"2015\\\":{\\\"AuthorKeyword\\\":\\\"morph\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"TransitionsAndMorphing\\\",\\\"ExpertKeywordCount\\\":8},\\\"2016\\\":{\\\"AuthorKeyword\\\":\\\"morphological analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"2017\\\":{\\\"AuthorKeyword\\\":\\\"morphological segmentation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"2018\\\":{\\\"AuthorKeyword\\\":\\\"morse smale\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"2019\\\":{\\\"AuthorKeyword\\\":\\\"morse smale complex\\\",\\\"AuthorKeywordCount\\\":11,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"2020\\\":{\\\"AuthorKeyword\\\":\\\"morse connection graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"2021\\\":{\\\"AuthorKeyword\\\":\\\"morse decomposition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"2022\\\":{\\\"AuthorKeyword\\\":\\\"morse theory\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"2023\\\":{\\\"AuthorKeyword\\\":\\\"mosaic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"2024\\\":{\\\"AuthorKeyword\\\":\\\"mosaic plot\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"2025\\\":{\\\"AuthorKeyword\\\":\\\"motif detection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"2026\\\":{\\\"AuthorKeyword\\\":\\\"motif search\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"2027\\\":{\\\"AuthorKeyword\\\":\\\"motif visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"2028\\\":{\\\"AuthorKeyword\\\":\\\"motion\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"2029\\\":{\\\"AuthorKeyword\\\":\\\"motion compensate heatmap\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"2030\\\":{\\\"AuthorKeyword\\\":\\\"motion capture datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"2031\\\":{\\\"AuthorKeyword\\\":\\\"motion detection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2032\\\":{\\\"AuthorKeyword\\\":\\\"motion estimation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"2033\\\":{\\\"AuthorKeyword\\\":\\\"motion synchronization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"2034\\\":{\\\"AuthorKeyword\\\":\\\"motion tracking datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"2035\\\":{\\\"AuthorKeyword\\\":\\\"motion visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"2036\\\":{\\\"AuthorKeyword\\\":\\\"movement\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"2037\\\":{\\\"AuthorKeyword\\\":\\\"movement datum\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"2038\\\":{\\\"AuthorKeyword\\\":\\\"movement pattern\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2039\\\":{\\\"AuthorKeyword\\\":\\\"movement visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"2040\\\":{\\\"AuthorKeyword\\\":\\\"movie\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"2041\\\":{\\\"AuthorKeyword\\\":\\\"move least square\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2042\\\":{\\\"AuthorKeyword\\\":\\\"move least square reconstruction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"2043\\\":{\\\"AuthorKeyword\\\":\\\"move object visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"2044\\\":{\\\"AuthorKeyword\\\":\\\"mpi profiling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2045\\\":{\\\"AuthorKeyword\\\":\\\"mpu implicit\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"2046\\\":{\\\"AuthorKeyword\\\":\\\"mr angiography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2047\\\":{\\\"AuthorKeyword\\\":\\\"mr spectroscopy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2048\\\":{\\\"AuthorKeyword\\\":\\\"mr tractography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tractography\\\",\\\"ExpertKeywordCount\\\":17},\\\"2049\\\":{\\\"AuthorKeyword\\\":\\\"mrna sequencing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"2050\\\":{\\\"AuthorKeyword\\\":\\\"multi attribute\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2051\\\":{\\\"AuthorKeyword\\\":\\\"multi attribute visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2052\\\":{\\\"AuthorKeyword\\\":\\\"multi camera tracking\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"2053\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2054\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional approximation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"2055\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional datum\\\",\\\"AuthorKeywordCount\\\":10,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2056\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional datum set\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2057\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional function\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2058\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional geometry\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometryBasedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2059\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional information modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"2060\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional information space\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2061\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional information visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2062\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional multi variate\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2063\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional multi variate datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2064\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional multi variate visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2065\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional projection\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"2066\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional range search\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2067\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional scaling\\\",\\\"AuthorKeywordCount\\\":12,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"2068\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional space\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2069\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional transfer function\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"2070\\\":{\\\"AuthorKeyword\\\":\\\"multi dimensional visualization\\\",\\\"AuthorKeywordCount\\\":16,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2071\\\":{\\\"AuthorKeyword\\\":\\\"multi facet visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFacetsAndTechniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"2072\\\":{\\\"AuthorKeyword\\\":\\\"multi faceted\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFacetsAndTechniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"2073\\\":{\\\"AuthorKeyword\\\":\\\"multi faceted visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFacetsAndTechniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"2074\\\":{\\\"AuthorKeyword\\\":\\\"multi factorial\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"2075\\\":{\\\"AuthorKeyword\\\":\\\"multi field\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2076\\\":{\\\"AuthorKeyword\\\":\\\"multi field and multi variate visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2077\\\":{\\\"AuthorKeyword\\\":\\\"multi field visualization\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2078\\\":{\\\"AuthorKeyword\\\":\\\"multi focus\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"2079\\\":{\\\"AuthorKeyword\\\":\\\"multi focus distortion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"2080\\\":{\\\"AuthorKeyword\\\":\\\"multi focus context\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"2081\\\":{\\\"AuthorKeyword\\\":\\\"multi layer\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"2082\\\":{\\\"AuthorKeyword\\\":\\\"multi level parallelism\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParallelSystemsAndParallelProcessing\\\",\\\"ExpertKeywordCount\\\":17},\\\"2083\\\":{\\\"AuthorKeyword\\\":\\\"multi level visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiScaleData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2084\\\":{\\\"AuthorKeyword\\\":\\\"multi level visualization technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiScaleData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2085\\\":{\\\"AuthorKeyword\\\":\\\"multi linear interpolation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"2086\\\":{\\\"AuthorKeyword\\\":\\\"multi material component\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"2087\\\":{\\\"AuthorKeyword\\\":\\\"multi modality datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultimodalData&Techniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"2088\\\":{\\\"AuthorKeyword\\\":\\\"multi perspective image\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2089\\\":{\\\"AuthorKeyword\\\":\\\"multi projector\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"2090\\\":{\\\"AuthorKeyword\\\":\\\"multi projector display\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"2091\\\":{\\\"AuthorKeyword\\\":\\\"multi relational datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2092\\\":{\\\"AuthorKeyword\\\":\\\"multi relational graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2093\\\":{\\\"AuthorKeyword\\\":\\\"multi representation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"2094\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution\\\",\\\"AuthorKeywordCount\\\":20,\\\"ExpertKeyword\\\":\\\"MultiresolutionTechniques\\\",\\\"ExpertKeywordCount\\\":45},\\\"2095\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiresolutionTechniques\\\",\\\"ExpertKeywordCount\\\":45},\\\"2096\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution datum structure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiresolutionTechniques\\\",\\\"ExpertKeywordCount\\\":45},\\\"2097\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution hierarchy\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"2098\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution isosurface extraction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"2099\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution mapping\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiresolutionTechniques\\\",\\\"ExpertKeywordCount\\\":45},\\\"2100\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution method\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"MultiresolutionTechniques\\\",\\\"ExpertKeywordCount\\\":45},\\\"2101\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution model\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"MultiresolutionTechniques\\\",\\\"ExpertKeywordCount\\\":45},\\\"2102\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution modeling\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"MultiresolutionTechniques\\\",\\\"ExpertKeywordCount\\\":45},\\\"2103\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution render\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2104\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution representation\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"MultiresolutionTechniques\\\",\\\"ExpertKeywordCount\\\":45},\\\"2105\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"2106\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution surface\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"2107\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiresolutionTechniques\\\",\\\"ExpertKeywordCount\\\":45},\\\"2108\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution tetrahedal mesh\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"2109\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution texture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"2110\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution triangulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"2111\\\":{\\\"AuthorKeyword\\\":\\\"multi resolution volume\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"2112\\\":{\\\"AuthorKeyword\\\":\\\"multi resoution visualization\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"MultiresolutionTechniques\\\",\\\"ExpertKeywordCount\\\":45},\\\"2113\\\":{\\\"AuthorKeyword\\\":\\\"multi scale\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"MultiScaleData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2115\\\":{\\\"AuthorKeyword\\\":\\\"multi scale diffusion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DiffusionRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":11},\\\"2116\\\":{\\\"AuthorKeyword\\\":\\\"multi scale graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2117\\\":{\\\"AuthorKeyword\\\":\\\"multi scale image processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2118\\\":{\\\"AuthorKeyword\\\":\\\"multi scale interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"2119\\\":{\\\"AuthorKeyword\\\":\\\"multi scale interface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"2120\\\":{\\\"AuthorKeyword\\\":\\\"multi scale map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"2121\\\":{\\\"AuthorKeyword\\\":\\\"multi scale model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiScaleData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2122\\\":{\\\"AuthorKeyword\\\":\\\"multi scale navigation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiScaleData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2123\\\":{\\\"AuthorKeyword\\\":\\\"multi scale perceptual organization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2124\\\":{\\\"AuthorKeyword\\\":\\\"multi scale representation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiScaleData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2125\\\":{\\\"AuthorKeyword\\\":\\\"multi scale viewing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiScaleData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2126\\\":{\\\"AuthorKeyword\\\":\\\"multi scale visualization\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"MultiScaleData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2127\\\":{\\\"AuthorKeyword\\\":\\\"multi scale multi level optimization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiScaleData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2128\\\":{\\\"AuthorKeyword\\\":\\\"multi slice ct\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2129\\\":{\\\"AuthorKeyword\\\":\\\"multi temporal visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"2130\\\":{\\\"AuthorKeyword\\\":\\\"multi threading\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParallelSystemsAndParallelProcessing\\\",\\\"ExpertKeywordCount\\\":17},\\\"2131\\\":{\\\"AuthorKeyword\\\":\\\"multi touch\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2132\\\":{\\\"AuthorKeyword\\\":\\\"multi touch interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2133\\\":{\\\"AuthorKeyword\\\":\\\"multi tree\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"2134\\\":{\\\"AuthorKeyword\\\":\\\"multi value attribute\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2135\\\":{\\\"AuthorKeyword\\\":\\\"multi value visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2136\\\":{\\\"AuthorKeyword\\\":\\\"multi volume render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"2137\\\":{\\\"AuthorKeyword\\\":\\\"multi volume visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"2138\\\":{\\\"AuthorKeyword\\\":\\\"multiform visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"2139\\\":{\\\"AuthorKeyword\\\":\\\"multimedia datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"2140\\\":{\\\"AuthorKeyword\\\":\\\"multimedia database system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"2141\\\":{\\\"AuthorKeyword\\\":\\\"multimedia indexing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"2143\\\":{\\\"AuthorKeyword\\\":\\\"multimodal\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultimodalData&Techniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"2144\\\":{\\\"AuthorKeyword\\\":\\\"multimodal and multi dimensional visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2145\\\":{\\\"AuthorKeyword\\\":\\\"multimodal curve planar reformation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultimodalData&Techniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"2146\\\":{\\\"AuthorKeyword\\\":\\\"multimodal datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultimodalData&Techniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"2147\\\":{\\\"AuthorKeyword\\\":\\\"multimodal graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2148\\\":{\\\"AuthorKeyword\\\":\\\"multimodal interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"2149\\\":{\\\"AuthorKeyword\\\":\\\"multimodal render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2150\\\":{\\\"AuthorKeyword\\\":\\\"multimodal visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultimodalData&Techniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"2151\\\":{\\\"AuthorKeyword\\\":\\\"multimodal volume render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"2152\\\":{\\\"AuthorKeyword\\\":\\\"multiperspective visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ViewDependentVisualization\\\",\\\"ExpertKeywordCount\\\":19},\\\"2153\\\":{\\\"AuthorKeyword\\\":\\\"multiphase simplification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"2154\\\":{\\\"AuthorKeyword\\\":\\\"multiple view technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultipleLinked/coordinatedViews\\\",\\\"ExpertKeywordCount\\\":50},\\\"2155\\\":{\\\"AuthorKeyword\\\":\\\"multiple attribute\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2156\\\":{\\\"AuthorKeyword\\\":\\\"multiple clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"2157\\\":{\\\"AuthorKeyword\\\":\\\"multiple compete hypothesis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HypothesisForming,Testing,AndVisualEvidence\\\",\\\"ExpertKeywordCount\\\":7},\\\"2158\\\":{\\\"AuthorKeyword\\\":\\\"multiple line graphs\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2159\\\":{\\\"AuthorKeyword\\\":\\\"multiple link view\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultipleLinked/coordinatedViews\\\",\\\"ExpertKeywordCount\\\":50},\\\"2160\\\":{\\\"AuthorKeyword\\\":\\\"multiple resolution\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiresolutionTechniques\\\",\\\"ExpertKeywordCount\\\":45},\\\"2161\\\":{\\\"AuthorKeyword\\\":\\\"multiple scattering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"2162\\\":{\\\"AuthorKeyword\\\":\\\"multiple tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"2163\\\":{\\\"AuthorKeyword\\\":\\\"multiple view\\\",\\\"AuthorKeywordCount\\\":13,\\\"ExpertKeyword\\\":\\\"MultipleLinked/coordinatedViews\\\",\\\"ExpertKeywordCount\\\":50},\\\"2164\\\":{\\\"AuthorKeyword\\\":\\\"multivalue image\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2165\\\":{\\\"AuthorKeyword\\\":\\\"multivariate\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2166\\\":{\\\"AuthorKeyword\\\":\\\"multivariate analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2167\\\":{\\\"AuthorKeyword\\\":\\\"multivariate datum\\\",\\\"AuthorKeywordCount\\\":18,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2168\\\":{\\\"AuthorKeyword\\\":\\\"multivariate datum analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2169\\\":{\\\"AuthorKeyword\\\":\\\"multivariate linear model construction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2170\\\":{\\\"AuthorKeyword\\\":\\\"multivariate model construction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2171\\\":{\\\"AuthorKeyword\\\":\\\"multivariate network\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2172\\\":{\\\"AuthorKeyword\\\":\\\"multivariate projection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"2174\\\":{\\\"AuthorKeyword\\\":\\\"multivariate time series\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"2175\\\":{\\\"AuthorKeyword\\\":\\\"multivariate topology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"2176\\\":{\\\"AuthorKeyword\\\":\\\"multivariate visualization\\\",\\\"AuthorKeywordCount\\\":17,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"2177\\\":{\\\"AuthorKeyword\\\":\\\"multiwavelength datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiScaleData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2178\\\":{\\\"AuthorKeyword\\\":\\\"muscle\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2179\\\":{\\\"AuthorKeyword\\\":\\\"music\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"2180\\\":{\\\"AuthorKeyword\\\":\\\"music performance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"2181\\\":{\\\"AuthorKeyword\\\":\\\"musician database visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"2182\\\":{\\\"AuthorKeyword\\\":\\\"musicology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Acoustics,Sound,Sonification\\\",\\\"ExpertKeywordCount\\\":9},\\\"2183\\\":{\\\"AuthorKeyword\\\":\\\"mutation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"2184\\\":{\\\"AuthorKeyword\\\":\\\"mutual reinforcement model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"2185\\\":{\\\"AuthorKeyword\\\":\\\"myocardial perfusion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2186\\\":{\\\"AuthorKeyword\\\":\\\"myocardial perfusion imaging\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2187\\\":{\\\"AuthorKeyword\\\":\\\"body simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Astronomy/Astrophysics\\\",\\\"ExpertKeywordCount\\\":17},\\\"2188\\\":{\\\"AuthorKeyword\\\":\\\"navigation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"2189\\\":{\\\"AuthorKeyword\\\":\\\"nanotechnology simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"2190\\\":{\\\"AuthorKeyword\\\":\\\"narrative\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Storytelling\\\",\\\"ExpertKeywordCount\\\":10},\\\"2191\\\":{\\\"AuthorKeyword\\\":\\\"narrative structure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Storytelling\\\",\\\"ExpertKeywordCount\\\":10},\\\"2192\\\":{\\\"AuthorKeyword\\\":\\\"narrative visualization\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Storytelling\\\",\\\"ExpertKeywordCount\\\":10},\\\"2193\\\":{\\\"AuthorKeyword\\\":\\\"natto view\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"2194\\\":{\\\"AuthorKeyword\\\":\\\"natural embedding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2195\\\":{\\\"AuthorKeyword\\\":\\\"natural interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2196\\\":{\\\"AuthorKeyword\\\":\\\"natural language interface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"2197\\\":{\\\"AuthorKeyword\\\":\\\"natural language processing\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"2198\\\":{\\\"AuthorKeyword\\\":\\\"natural scale\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiScaleData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2199\\\":{\\\"AuthorKeyword\\\":\\\"natural user interface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"2200\\\":{\\\"AuthorKeyword\\\":\\\"navigation\\\",\\\"AuthorKeywordCount\\\":11,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"2201\\\":{\\\"AuthorKeyword\\\":\\\"near neighbour search\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2202\\\":{\\\"AuthorKeyword\\\":\\\"near common ancestor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"2203\\\":{\\\"AuthorKeyword\\\":\\\"nebula\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Astronomy/Astrophysics\\\",\\\"ExpertKeywordCount\\\":17},\\\"2204\\\":{\\\"AuthorKeyword\\\":\\\"necklace map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"2205\\\":{\\\"AuthorKeyword\\\":\\\"neighborhood graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2206\\\":{\\\"AuthorKeyword\\\":\\\"neighborhood meta datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2207\\\":{\\\"AuthorKeyword\\\":\\\"nematic liquid crystal\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"2208\\\":{\\\"AuthorKeyword\\\":\\\"nest graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2209\\\":{\\\"AuthorKeyword\\\":\\\"nest model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"2210\\\":{\\\"AuthorKeyword\\\":\\\"nested relation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"2211\\\":{\\\"AuthorKeyword\\\":\\\"nested surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"2213\\\":{\\\"AuthorKeyword\\\":\\\"network diagnosis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"2214\\\":{\\\"AuthorKeyword\\\":\\\"network diagram\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2215\\\":{\\\"AuthorKeyword\\\":\\\"network evolution\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2216\\\":{\\\"AuthorKeyword\\\":\\\"network exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2217\\\":{\\\"AuthorKeyword\\\":\\\"network intrusion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"2218\\\":{\\\"AuthorKeyword\\\":\\\"network latency\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"2219\\\":{\\\"AuthorKeyword\\\":\\\"network layout\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2220\\\":{\\\"AuthorKeyword\\\":\\\"network layout visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2221\\\":{\\\"AuthorKeyword\\\":\\\"network monitoring\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"2222\\\":{\\\"AuthorKeyword\\\":\\\"network sampling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2223\\\":{\\\"AuthorKeyword\\\":\\\"network schematic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2224\\\":{\\\"AuthorKeyword\\\":\\\"network security\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"2225\\\":{\\\"AuthorKeyword\\\":\\\"network security and intrusion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"2226\\\":{\\\"AuthorKeyword\\\":\\\"network traffic monitoring\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"2227\\\":{\\\"AuthorKeyword\\\":\\\"network traffic visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"2228\\\":{\\\"AuthorKeyword\\\":\\\"network visualization\\\",\\\"AuthorKeywordCount\\\":15,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2230\\\":{\\\"AuthorKeyword\\\":\\\"neural network\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"2231\\\":{\\\"AuthorKeyword\\\":\\\"neurobiology\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"NeurosciencesAndBrainVisualization\\\",\\\"ExpertKeywordCount\\\":17},\\\"2232\\\":{\\\"AuthorKeyword\\\":\\\"neuron visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NeurosciencesAndBrainVisualization\\\",\\\"ExpertKeywordCount\\\":17},\\\"2233\\\":{\\\"AuthorKeyword\\\":\\\"neuronal fiber pathway\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NeurosciencesAndBrainVisualization\\\",\\\"ExpertKeywordCount\\\":17},\\\"2234\\\":{\\\"AuthorKeyword\\\":\\\"neuronal pathway\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NeurosciencesAndBrainVisualization\\\",\\\"ExpertKeywordCount\\\":17},\\\"2235\\\":{\\\"AuthorKeyword\\\":\\\"neuroscience\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"NeurosciencesAndBrainVisualization\\\",\\\"ExpertKeywordCount\\\":17},\\\"2236\\\":{\\\"AuthorKeyword\\\":\\\"neurovascular structure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NeurosciencesAndBrainVisualization\\\",\\\"ExpertKeywordCount\\\":17},\\\"2237\\\":{\\\"AuthorKeyword\\\":\\\"news visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"2238\\\":{\\\"AuthorKeyword\\\":\\\"newspaper\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"2239\\\":{\\\"AuthorKeyword\\\":\\\"nice number\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2240\\\":{\\\"AuthorKeyword\\\":\\\"node link diagram\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2241\\\":{\\\"AuthorKeyword\\\":\\\"node link diagram\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2242\\\":{\\\"AuthorKeyword\\\":\\\"node link layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2243\\\":{\\\"AuthorKeyword\\\":\\\"node link representation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2244\\\":{\\\"AuthorKeyword\\\":\\\"node link visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2245\\\":{\\\"AuthorKeyword\\\":\\\"node duplication\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"2246\\\":{\\\"AuthorKeyword\\\":\\\"node group\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"2247\\\":{\\\"AuthorKeyword\\\":\\\"node similarity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"2248\\\":{\\\"AuthorKeyword\\\":\\\"node splatte\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2249\\\":{\\\"AuthorKeyword\\\":\\\"nominal axis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"2250\\\":{\\\"AuthorKeyword\\\":\\\"nominal datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataTypesGeneral\\\",\\\"ExpertKeywordCount\\\":12},\\\"2251\\\":{\\\"AuthorKeyword\\\":\\\"non destructive testing\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"2252\\\":{\\\"AuthorKeyword\\\":\\\"non euclidean geometry\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometryBasedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2253\\\":{\\\"AuthorKeyword\\\":\\\"non linear diffusion\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DiffusionRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":11},\\\"2254\\\":{\\\"AuthorKeyword\\\":\\\"non linear dimensionality reduction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"2255\\\":{\\\"AuthorKeyword\\\":\\\"non linear filtering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"2256\\\":{\\\"AuthorKeyword\\\":\\\"non linear magnification\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"2257\\\":{\\\"AuthorKeyword\\\":\\\"non linear optimization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Optimization\\\",\\\"ExpertKeywordCount\\\":19},\\\"2258\\\":{\\\"AuthorKeyword\\\":\\\"non linear raytracing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Raytracing/raycasting\\\",\\\"ExpertKeywordCount\\\":32},\\\"2259\\\":{\\\"AuthorKeyword\\\":\\\"non manifold\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"2260\\\":{\\\"AuthorKeyword\\\":\\\"non manifold surface\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"2261\\\":{\\\"AuthorKeyword\\\":\\\"non photorealistic rendering\\\",\\\"AuthorKeywordCount\\\":11,\\\"ExpertKeyword\\\":\\\"IllustrativeVisualization\\\",\\\"ExpertKeywordCount\\\":40},\\\"2262\\\":{\\\"AuthorKeyword\\\":\\\"non photorealistic technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IllustrativeVisualization\\\",\\\"ExpertKeywordCount\\\":40},\\\"2263\\\":{\\\"AuthorKeyword\\\":\\\"non rectilinear mesh\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"2264\\\":{\\\"AuthorKeyword\\\":\\\"non regular triangulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"2265\\\":{\\\"AuthorKeyword\\\":\\\"non rigid motion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"2266\\\":{\\\"AuthorKeyword\\\":\\\"nondestructive testing and evaluation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"2267\\\":{\\\"AuthorKeyword\\\":\\\"nonnegative matrix factorization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2268\\\":{\\\"AuthorKeyword\\\":\\\"nonparametric statistic\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"2269\\\":{\\\"AuthorKeyword\\\":\\\"nonperspective projection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"2270\\\":{\\\"AuthorKeyword\\\":\\\"normal\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"2271\\\":{\\\"AuthorKeyword\\\":\\\"normal estimation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"2272\\\":{\\\"AuthorKeyword\\\":\\\"normal mapping\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"2273\\\":{\\\"AuthorKeyword\\\":\\\"normal orientation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"2274\\\":{\\\"AuthorKeyword\\\":\\\"normal vector\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"2275\\\":{\\\"AuthorKeyword\\\":\\\"normalize cut\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2276\\\":{\\\"AuthorKeyword\\\":\\\"notation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"2277\\\":{\\\"AuthorKeyword\\\":\\\"note take\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"2278\\\":{\\\"AuthorKeyword\\\":\\\"novice user\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"2279\\\":{\\\"AuthorKeyword\\\":\\\"novice\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"2280\\\":{\\\"AuthorKeyword\\\":\\\"null hypothesis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QuantitativeEvaluation\\\",\\\"ExpertKeywordCount\\\":10},\\\"2281\\\":{\\\"AuthorKeyword\\\":\\\"numerical analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2282\\\":{\\\"AuthorKeyword\\\":\\\"numerical ensemble\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"2283\\\":{\\\"AuthorKeyword\\\":\\\"numerical optimization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Optimization\\\",\\\"ExpertKeywordCount\\\":19},\\\"2284\\\":{\\\"AuthorKeyword\\\":\\\"numerosity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2285\\\":{\\\"AuthorKeyword\\\":\\\"oac\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"2286\\\":{\\\"AuthorKeyword\\\":\\\"object orient\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2287\\\":{\\\"AuthorKeyword\\\":\\\"object orient design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2288\\\":{\\\"AuthorKeyword\\\":\\\"object orient programming\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2289\\\":{\\\"AuthorKeyword\\\":\\\"object orient visualization toolkit\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"2290\\\":{\\\"AuthorKeyword\\\":\\\"object modeling\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"2291\\\":{\\\"AuthorKeyword\\\":\\\"observation level interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2292\\\":{\\\"AuthorKeyword\\\":\\\"observational study\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QualitativeEvaluation\\\",\\\"ExpertKeywordCount\\\":15},\\\"2293\\\":{\\\"AuthorKeyword\\\":\\\"occlusion\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"OcclusionProblems/techniques\\\",\\\"ExpertKeywordCount\\\":15},\\\"2294\\\":{\\\"AuthorKeyword\\\":\\\"occlusion free\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"OcclusionProblems/techniques\\\",\\\"ExpertKeywordCount\\\":15},\\\"2295\\\":{\\\"AuthorKeyword\\\":\\\"occlusion free animation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"OcclusionProblems/techniques\\\",\\\"ExpertKeywordCount\\\":15},\\\"2296\\\":{\\\"AuthorKeyword\\\":\\\"occlusion clipping\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"OcclusionProblems/techniques\\\",\\\"ExpertKeywordCount\\\":15},\\\"2297\\\":{\\\"AuthorKeyword\\\":\\\"occlusion compatible ordering for discrete image\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2298\\\":{\\\"AuthorKeyword\\\":\\\"occlusion cull\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"OcclusionProblems/techniques\\\",\\\"ExpertKeywordCount\\\":15},\\\"2299\\\":{\\\"AuthorKeyword\\\":\\\"ocean current\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"2300\\\":{\\\"AuthorKeyword\\\":\\\"ocean modeling\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"2301\\\":{\\\"AuthorKeyword\\\":\\\"oceanographic visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"2302\\\":{\\\"AuthorKeyword\\\":\\\"oceanography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"2303\\\":{\\\"AuthorKeyword\\\":\\\"octilinear layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"2304\\\":{\\\"AuthorKeyword\\\":\\\"octree\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2305\\\":{\\\"AuthorKeyword\\\":\\\"offset\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"2306\\\":{\\\"AuthorKeyword\\\":\\\"oil and gas exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"2307\\\":{\\\"AuthorKeyword\\\":\\\"oil flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Engineering\\\",\\\"ExpertKeywordCount\\\":12},\\\"2308\\\":{\\\"AuthorKeyword\\\":\\\"oil painting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ArtAndAestheticsInVisualization\\\",\\\"ExpertKeywordCount\\\":16},\\\"2309\\\":{\\\"AuthorKeyword\\\":\\\"omit variable bias\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"2310\\\":{\\\"AuthorKeyword\\\":\\\"online analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"2311\\\":{\\\"AuthorKeyword\\\":\\\"online analytic processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"2312\\\":{\\\"AuthorKeyword\\\":\\\"online fantasy sport\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2313\\\":{\\\"AuthorKeyword\\\":\\\"online health community\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2314\\\":{\\\"AuthorKeyword\\\":\\\"online mapping system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"2315\\\":{\\\"AuthorKeyword\\\":\\\"online study\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"2316\\\":{\\\"AuthorKeyword\\\":\\\"online visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"2317\\\":{\\\"AuthorKeyword\\\":\\\"online web mapping\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"2318\\\":{\\\"AuthorKeyword\\\":\\\"ontology\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Taxonomies\\\",\\\"ExpertKeywordCount\\\":18},\\\"2319\\\":{\\\"AuthorKeyword\\\":\\\"opacity function\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"OcclusionProblems/techniques\\\",\\\"ExpertKeywordCount\\\":15},\\\"2320\\\":{\\\"AuthorKeyword\\\":\\\"opengl\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"2321\\\":{\\\"AuthorKeyword\\\":\\\"operation planning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2322\\\":{\\\"AuthorKeyword\\\":\\\"operator\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"2323\\\":{\\\"AuthorKeyword\\\":\\\"opinion diffusion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"2324\\\":{\\\"AuthorKeyword\\\":\\\"opinion flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"2325\\\":{\\\"AuthorKeyword\\\":\\\"opinion visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"2326\\\":{\\\"AuthorKeyword\\\":\\\"optical coherence tomography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2327\\\":{\\\"AuthorKeyword\\\":\\\"optical flow\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2328\\\":{\\\"AuthorKeyword\\\":\\\"optimal regular sampling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Sampling\\\",\\\"ExpertKeywordCount\\\":23},\\\"2329\\\":{\\\"AuthorKeyword\\\":\\\"optimal regular volume sample\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Sampling\\\",\\\"ExpertKeywordCount\\\":23},\\\"2330\\\":{\\\"AuthorKeyword\\\":\\\"optimal transport map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"2331\\\":{\\\"AuthorKeyword\\\":\\\"optimal visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"2332\\\":{\\\"AuthorKeyword\\\":\\\"optimization\\\",\\\"AuthorKeywordCount\\\":10,\\\"ExpertKeyword\\\":\\\"Optimization\\\",\\\"ExpertKeywordCount\\\":19},\\\"2333\\\":{\\\"AuthorKeyword\\\":\\\"oracle\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2334\\\":{\\\"AuthorKeyword\\\":\\\"orbit\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"2335\\\":{\\\"AuthorKeyword\\\":\\\"order optimization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Optimization\\\",\\\"ExpertKeywordCount\\\":19},\\\"2336\\\":{\\\"AuthorKeyword\\\":\\\"order selection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Ranking\\\",\\\"ExpertKeywordCount\\\":5},\\\"2337\\\":{\\\"AuthorKeyword\\\":\\\"order statistic\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"2338\\\":{\\\"AuthorKeyword\\\":\\\"order treemap\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"2339\\\":{\\\"AuthorKeyword\\\":\\\"order of magnitude\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"2340\\\":{\\\"AuthorKeyword\\\":\\\"organizational chart\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"2341\\\":{\\\"AuthorKeyword\\\":\\\"orientation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"2342\\\":{\\\"AuthorKeyword\\\":\\\"orientation enhance brushing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2343\\\":{\\\"AuthorKeyword\\\":\\\"orientation enhance parallel coordinate\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParallelCoordinates\\\",\\\"ExpertKeywordCount\\\":29},\\\"2344\\\":{\\\"AuthorKeyword\\\":\\\"orientation filtering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"2346\\\":{\\\"AuthorKeyword\\\":\\\"origin destination\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"2347\\\":{\\\"AuthorKeyword\\\":\\\"orthogonal block transform\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2348\\\":{\\\"AuthorKeyword\\\":\\\"orthogonal centroid method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"2349\\\":{\\\"AuthorKeyword\\\":\\\"orthogonal drawing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"2350\\\":{\\\"AuthorKeyword\\\":\\\"orthogonal layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"2351\\\":{\\\"AuthorKeyword\\\":\\\"orthogonal opacity map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2352\\\":{\\\"AuthorKeyword\\\":\\\"orthogonal projection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"2353\\\":{\\\"AuthorKeyword\\\":\\\"orthogonality\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"2354\\\":{\\\"AuthorKeyword\\\":\\\"orthographic projection\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"2355\\\":{\\\"AuthorKeyword\\\":\\\"out of core\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"OutOfCoreProcessing\\\",\\\"ExpertKeywordCount\\\":20},\\\"2356\\\":{\\\"AuthorKeyword\\\":\\\"out of core algorithm\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"OutOfCoreProcessing\\\",\\\"ExpertKeywordCount\\\":20},\\\"2357\\\":{\\\"AuthorKeyword\\\":\\\"out of core computation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"OutOfCoreProcessing\\\",\\\"ExpertKeywordCount\\\":20},\\\"2358\\\":{\\\"AuthorKeyword\\\":\\\"out of core method\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"OutOfCoreProcessing\\\",\\\"ExpertKeywordCount\\\":20},\\\"2359\\\":{\\\"AuthorKeyword\\\":\\\"out of core processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"OutOfCoreProcessing\\\",\\\"ExpertKeywordCount\\\":20},\\\"2360\\\":{\\\"AuthorKeyword\\\":\\\"out of core render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"OutOfCoreProcessing\\\",\\\"ExpertKeywordCount\\\":20},\\\"2361\\\":{\\\"AuthorKeyword\\\":\\\"out of core simplification\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"OutOfCoreProcessing\\\",\\\"ExpertKeywordCount\\\":20},\\\"2362\\\":{\\\"AuthorKeyword\\\":\\\"out of core technique\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"OutOfCoreProcessing\\\",\\\"ExpertKeywordCount\\\":20},\\\"2363\\\":{\\\"AuthorKeyword\\\":\\\"out of core visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"OutOfCoreProcessing\\\",\\\"ExpertKeywordCount\\\":20},\\\"2364\\\":{\\\"AuthorKeyword\\\":\\\"outflow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2365\\\":{\\\"AuthorKeyword\\\":\\\"outli detection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Events,Trends,OutlierDetection,Analysis,AndVisualization\\\",\\\"ExpertKeywordCount\\\":23},\\\"2366\\\":{\\\"AuthorKeyword\\\":\\\"outlier trend\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Events,Trends,OutlierDetection,Analysis,AndVisualization\\\",\\\"ExpertKeywordCount\\\":23},\\\"2367\\\":{\\\"AuthorKeyword\\\":\\\"over blend\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataRegistration,Fusion,AndIntegration\\\",\\\"ExpertKeywordCount\\\":14},\\\"2368\\\":{\\\"AuthorKeyword\\\":\\\"overdraw reduction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"2369\\\":{\\\"AuthorKeyword\\\":\\\"overlap community visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"2370\\\":{\\\"AuthorKeyword\\\":\\\"overlap set\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SetRelatedData&Techniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"2371\\\":{\\\"AuthorKeyword\\\":\\\"overlay\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"2372\\\":{\\\"AuthorKeyword\\\":\\\"overplotte\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualClutterAndItsReduction\\\",\\\"ExpertKeywordCount\\\":5},\\\"2373\\\":{\\\"AuthorKeyword\\\":\\\"overview\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"2374\\\":{\\\"AuthorKeyword\\\":\\\"overview use\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"2375\\\":{\\\"AuthorKeyword\\\":\\\"overview detail\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"2376\\\":{\\\"AuthorKeyword\\\":\\\"p2p file sharing network visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"2377\\\":{\\\"AuthorKeyword\\\":\\\"pad\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"2378\\\":{\\\"AuthorKeyword\\\":\\\"page\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2379\\\":{\\\"AuthorKeyword\\\":\\\"painting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ArtAndAestheticsInVisualization\\\",\\\"ExpertKeywordCount\\\":16},\\\"2380\\\":{\\\"AuthorKeyword\\\":\\\"pan and zoom\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"2381\\\":{\\\"AuthorKeyword\\\":\\\"pan\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"2382\\\":{\\\"AuthorKeyword\\\":\\\"panoramic image display\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"LargeAndHighResDisplays\\\",\\\"ExpertKeywordCount\\\":24},\\\"2383\\\":{\\\"AuthorKeyword\\\":\\\"paper reference matrix\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MatrixRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":13},\\\"2384\\\":{\\\"AuthorKeyword\\\":\\\"parallel and distribute volume visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"2385\\\":{\\\"AuthorKeyword\\\":\\\"parallel computing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParallelSystemsAndParallelProcessing\\\",\\\"ExpertKeywordCount\\\":17},\\\"2386\\\":{\\\"AuthorKeyword\\\":\\\"parallel coordinate plot\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ParallelCoordinates\\\",\\\"ExpertKeywordCount\\\":29},\\\"2387\\\":{\\\"AuthorKeyword\\\":\\\"parallel coordinate\\\",\\\"AuthorKeywordCount\\\":25,\\\"ExpertKeyword\\\":\\\"ParallelCoordinates\\\",\\\"ExpertKeywordCount\\\":29},\\\"2388\\\":{\\\"AuthorKeyword\\\":\\\"parallel coordinate plot\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParallelCoordinates\\\",\\\"ExpertKeywordCount\\\":29},\\\"2389\\\":{\\\"AuthorKeyword\\\":\\\"parallel finite element code and simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2390\\\":{\\\"AuthorKeyword\\\":\\\"parallel glyph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"2391\\\":{\\\"AuthorKeyword\\\":\\\"parallel image compositing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2392\\\":{\\\"AuthorKeyword\\\":\\\"parallel processing\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"ParallelSystemsAndParallelProcessing\\\",\\\"ExpertKeywordCount\\\":17},\\\"2393\\\":{\\\"AuthorKeyword\\\":\\\"parallel reconstruction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParallelSystemsAndParallelProcessing\\\",\\\"ExpertKeywordCount\\\":17},\\\"2394\\\":{\\\"AuthorKeyword\\\":\\\"parallel rendering\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"ParallelSystemsAndParallelProcessing\\\",\\\"ExpertKeywordCount\\\":17},\\\"2395\\\":{\\\"AuthorKeyword\\\":\\\"parallel vector\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"2396\\\":{\\\"AuthorKeyword\\\":\\\"parallel warping\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParallelSystemsAndParallelProcessing\\\",\\\"ExpertKeywordCount\\\":17},\\\"2397\\\":{\\\"AuthorKeyword\\\":\\\"parallel world\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2398\\\":{\\\"AuthorKeyword\\\":\\\"parallelogram rule\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2399\\\":{\\\"AuthorKeyword\\\":\\\"parameter exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"2400\\\":{\\\"AuthorKeyword\\\":\\\"paramet sensitivity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Parameterization\\\",\\\"ExpertKeywordCount\\\":10},\\\"2401\\\":{\\\"AuthorKeyword\\\":\\\"paramet space\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Parameterization\\\",\\\"ExpertKeywordCount\\\":10},\\\"2402\\\":{\\\"AuthorKeyword\\\":\\\"paramet space analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Parameterization\\\",\\\"ExpertKeywordCount\\\":10},\\\"2403\\\":{\\\"AuthorKeyword\\\":\\\"paramet study\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Parameterization\\\",\\\"ExpertKeywordCount\\\":10},\\\"2404\\\":{\\\"AuthorKeyword\\\":\\\"parameterization\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Parameterization\\\",\\\"ExpertKeywordCount\\\":10},\\\"2405\\\":{\\\"AuthorKeyword\\\":\\\"parameterize algorithm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Parameterization\\\",\\\"ExpertKeywordCount\\\":10},\\\"2406\\\":{\\\"AuthorKeyword\\\":\\\"parametric curve\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"2407\\\":{\\\"AuthorKeyword\\\":\\\"parametric topology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"2408\\\":{\\\"AuthorKeyword\\\":\\\"pareto set\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Optimization\\\",\\\"ExpertKeywordCount\\\":19},\\\"2409\\\":{\\\"AuthorKeyword\\\":\\\"parity test\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2410\\\":{\\\"AuthorKeyword\\\":\\\"partial differential equation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Pde'sForVisualization\\\",\\\"ExpertKeywordCount\\\":2},\\\"2411\\\":{\\\"AuthorKeyword\\\":\\\"partial differential equation surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Pde'sForVisualization\\\",\\\"ExpertKeywordCount\\\":2},\\\"2412\\\":{\\\"AuthorKeyword\\\":\\\"partial ranking\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Ranking\\\",\\\"ExpertKeywordCount\\\":5},\\\"2413\\\":{\\\"AuthorKeyword\\\":\\\"partial volume effect\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"2414\\\":{\\\"AuthorKeyword\\\":\\\"partial volume voxel\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"2415\\\":{\\\"AuthorKeyword\\\":\\\"participate medium\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"2416\\\":{\\\"AuthorKeyword\\\":\\\"participatory culture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"2417\\\":{\\\"AuthorKeyword\\\":\\\"participatory visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"2418\\\":{\\\"AuthorKeyword\\\":\\\"particle datum\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"ExpertKeywordCount\\\":21},\\\"2419\\\":{\\\"AuthorKeyword\\\":\\\"particle image velocimetry\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"ExpertKeywordCount\\\":21},\\\"2420\\\":{\\\"AuthorKeyword\\\":\\\"particle motion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"ExpertKeywordCount\\\":21},\\\"2421\\\":{\\\"AuthorKeyword\\\":\\\"particle simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"ExpertKeywordCount\\\":21},\\\"2422\\\":{\\\"AuthorKeyword\\\":\\\"particle system\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"ExpertKeywordCount\\\":21},\\\"2423\\\":{\\\"AuthorKeyword\\\":\\\"particle tracing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"ExpertKeywordCount\\\":21},\\\"2424\\\":{\\\"AuthorKeyword\\\":\\\"particle trajectorie\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"ExpertKeywordCount\\\":21},\\\"2425\\\":{\\\"AuthorKeyword\\\":\\\"particle trajectory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"ExpertKeywordCount\\\":21},\\\"2426\\\":{\\\"AuthorKeyword\\\":\\\"particle visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"ExpertKeywordCount\\\":21},\\\"2427\\\":{\\\"AuthorKeyword\\\":\\\"partition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"2428\\\":{\\\"AuthorKeyword\\\":\\\"patent retrieval\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2429\\\":{\\\"AuthorKeyword\\\":\\\"path planning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"2430\\\":{\\\"AuthorKeyword\\\":\\\"path reconstruction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"2431\\\":{\\\"AuthorKeyword\\\":\\\"pathfinder network\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2432\\\":{\\\"AuthorKeyword\\\":\\\"pathline\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"2434\\\":{\\\"AuthorKeyword\\\":\\\"pathway\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"2435\\\":{\\\"AuthorKeyword\\\":\\\"patient vital sign monitor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2436\\\":{\\\"AuthorKeyword\\\":\\\"pattern detection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"2437\\\":{\\\"AuthorKeyword\\\":\\\"pattern extraction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"2438\\\":{\\\"AuthorKeyword\\\":\\\"pattern formation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"2439\\\":{\\\"AuthorKeyword\\\":\\\"pattern matching\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"2440\\\":{\\\"AuthorKeyword\\\":\\\"pattern recognition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"2441\\\":{\\\"AuthorKeyword\\\":\\\"pattern visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"2442\\\":{\\\"AuthorKeyword\\\":\\\"pc\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"2443\\\":{\\\"AuthorKeyword\\\":\\\"pc base volume graphic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"2444\\\":{\\\"AuthorKeyword\\\":\\\"pc graphic card\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"2445\\\":{\\\"AuthorKeyword\\\":\\\"pc hardware\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"2446\\\":{\\\"AuthorKeyword\\\":\\\"pda\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"2447\\\":{\\\"AuthorKeyword\\\":\\\"pdm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Business,Finance,Economy,Manufacturing\\\",\\\"ExpertKeywordCount\\\":12},\\\"2448\\\":{\\\"AuthorKeyword\\\":\\\"pedigree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ProvenanceAndHistory\\\",\\\"ExpertKeywordCount\\\":15},\\\"2449\\\":{\\\"AuthorKeyword\\\":\\\"pen and ink render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IllustrativeVisualization\\\",\\\"ExpertKeywordCount\\\":40},\\\"2451\\\":{\\\"AuthorKeyword\\\":\\\"perceive affordance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"2452\\\":{\\\"AuthorKeyword\\\":\\\"perception\\\",\\\"AuthorKeywordCount\\\":23,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2453\\\":{\\\"AuthorKeyword\\\":\\\"perception model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2454\\\":{\\\"AuthorKeyword\\\":\\\"perception of correlation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2455\\\":{\\\"AuthorKeyword\\\":\\\"perception theory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2456\\\":{\\\"AuthorKeyword\\\":\\\"perceptual cognition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"2457\\\":{\\\"AuthorKeyword\\\":\\\"perceptual color scale\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"2458\\\":{\\\"AuthorKeyword\\\":\\\"perceptual cue\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2459\\\":{\\\"AuthorKeyword\\\":\\\"perceptual enhancement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"2460\\\":{\\\"AuthorKeyword\\\":\\\"perceptual interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2461\\\":{\\\"AuthorKeyword\\\":\\\"perceptual organization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2462\\\":{\\\"AuthorKeyword\\\":\\\"perceptual reasoning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2463\\\":{\\\"AuthorKeyword\\\":\\\"perceptual study\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2464\\\":{\\\"AuthorKeyword\\\":\\\"perceptual theory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2465\\\":{\\\"AuthorKeyword\\\":\\\"perceptual transparency\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2466\\\":{\\\"AuthorKeyword\\\":\\\"perceptually base visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2467\\\":{\\\"AuthorKeyword\\\":\\\"performance analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"2468\\\":{\\\"AuthorKeyword\\\":\\\"performance optimization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Optimization\\\",\\\"ExpertKeywordCount\\\":19},\\\"2469\\\":{\\\"AuthorKeyword\\\":\\\"performance visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2470\\\":{\\\"AuthorKeyword\\\":\\\"periodic magnetic fieldline\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"2472\\\":{\\\"AuthorKeyword\\\":\\\"permutation test\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"2473\\\":{\\\"AuthorKeyword\\\":\\\"persistence\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"2474\\\":{\\\"AuthorKeyword\\\":\\\"persistence diagram\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"2475\\\":{\\\"AuthorKeyword\\\":\\\"persistent datum structure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2476\\\":{\\\"AuthorKeyword\\\":\\\"persistent homology\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"2477\\\":{\\\"AuthorKeyword\\\":\\\"personal emotion analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2478\\\":{\\\"AuthorKeyword\\\":\\\"personal finance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Business,Finance,Economy,Manufacturing\\\",\\\"ExpertKeywordCount\\\":12},\\\"2479\\\":{\\\"AuthorKeyword\\\":\\\"personal visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2480\\\":{\\\"AuthorKeyword\\\":\\\"personalized information access\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"2481\\\":{\\\"AuthorKeyword\\\":\\\"perspective interpolation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"2482\\\":{\\\"AuthorKeyword\\\":\\\"perspective projection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"2483\\\":{\\\"AuthorKeyword\\\":\\\"perspective shear warp\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"2484\\\":{\\\"AuthorKeyword\\\":\\\"persuasive visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Presentation,Production,AndDissemination\\\",\\\"ExpertKeywordCount\\\":5},\\\"2485\\\":{\\\"AuthorKeyword\\\":\\\"petascale volume analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"2486\\\":{\\\"AuthorKeyword\\\":\\\"petascale volume exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"2487\\\":{\\\"AuthorKeyword\\\":\\\"phase contrast cine mri\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2488\\\":{\\\"AuthorKeyword\\\":\\\"phenomic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"2489\\\":{\\\"AuthorKeyword\\\":\\\"phenotype\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"2490\\\":{\\\"AuthorKeyword\\\":\\\"phone traffic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2491\\\":{\\\"AuthorKeyword\\\":\\\"phong shading\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2492\\\":{\\\"AuthorKeyword\\\":\\\"phonon map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Acoustics,Sound,Sonification\\\",\\\"ExpertKeywordCount\\\":9},\\\"2493\\\":{\\\"AuthorKeyword\\\":\\\"phonon tracing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Acoustics,Sound,Sonification\\\",\\\"ExpertKeywordCount\\\":9},\\\"2494\\\":{\\\"AuthorKeyword\\\":\\\"photic extremum line\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LineBasedTechniquesAndApproaches\\\",\\\"ExpertKeywordCount\\\":8},\\\"2495\\\":{\\\"AuthorKeyword\\\":\\\"photogrammetry\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2496\\\":{\\\"AuthorKeyword\\\":\\\"photographic technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2497\\\":{\\\"AuthorKeyword\\\":\\\"photometric calibration\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"2498\\\":{\\\"AuthorKeyword\\\":\\\"photometric correction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"2499\\\":{\\\"AuthorKeyword\\\":\\\"photon mapping\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"2500\\\":{\\\"AuthorKeyword\\\":\\\"photo\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"2501\\\":{\\\"AuthorKeyword\\\":\\\"phyllotaxis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"2502\\\":{\\\"AuthorKeyword\\\":\\\"phylogenetic tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"2503\\\":{\\\"AuthorKeyword\\\":\\\"physical activity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2504\\\":{\\\"AuthorKeyword\\\":\\\"physical model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"2505\\\":{\\\"AuthorKeyword\\\":\\\"physical navigation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"2506\\\":{\\\"AuthorKeyword\\\":\\\"physical simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"2507\\\":{\\\"AuthorKeyword\\\":\\\"physical variable\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"2508\\\":{\\\"AuthorKeyword\\\":\\\"physical visualization\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"2509\\\":{\\\"AuthorKeyword\\\":\\\"physically base illumination\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"2510\\\":{\\\"AuthorKeyword\\\":\\\"physically base modeling\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"2511\\\":{\\\"AuthorKeyword\\\":\\\"physically base system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"2512\\\":{\\\"AuthorKeyword\\\":\\\"physics base graph layout\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2513\\\":{\\\"AuthorKeyword\\\":\\\"piccolo\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"2514\\\":{\\\"AuthorKeyword\\\":\\\"pick\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2515\\\":{\\\"AuthorKeyword\\\":\\\"pick\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2516\\\":{\\\"AuthorKeyword\\\":\\\"pipeline model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"2517\\\":{\\\"AuthorKeyword\\\":\\\"pituitary surgery\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2518\\\":{\\\"AuthorKeyword\\\":\\\"pivot\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2519\\\":{\\\"AuthorKeyword\\\":\\\"pixel base visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PixelOrientedEncodings\\\",\\\"ExpertKeywordCount\\\":7},\\\"2520\\\":{\\\"AuthorKeyword\\\":\\\"pixel exact visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PixelOrientedEncodings\\\",\\\"ExpertKeywordCount\\\":7},\\\"2521\\\":{\\\"AuthorKeyword\\\":\\\"pixel filling display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PixelOrientedEncodings\\\",\\\"ExpertKeywordCount\\\":7},\\\"2522\\\":{\\\"AuthorKeyword\\\":\\\"pixel orient technique\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"PixelOrientedEncodings\\\",\\\"ExpertKeywordCount\\\":7},\\\"2523\\\":{\\\"AuthorKeyword\\\":\\\"pixel shader\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"2524\\\":{\\\"AuthorKeyword\\\":\\\"pixel visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PixelOrientedEncodings\\\",\\\"ExpertKeywordCount\\\":7},\\\"2525\\\":{\\\"AuthorKeyword\\\":\\\"planar contour\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Contour/Creases/Ridges/Valleys\\\",\\\"ExpertKeywordCount\\\":17},\\\"2526\\\":{\\\"AuthorKeyword\\\":\\\"plane disc tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2527\\\":{\\\"AuthorKeyword\\\":\\\"planetary nebulae\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Astronomy/Astrophysics\\\",\\\"ExpertKeywordCount\\\":17},\\\"2528\\\":{\\\"AuthorKeyword\\\":\\\"plant biology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"2529\\\":{\\\"AuthorKeyword\\\":\\\"plant root\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"2530\\\":{\\\"AuthorKeyword\\\":\\\"plaque growth\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2531\\\":{\\\"AuthorKeyword\\\":\\\"plasma physics\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"2532\\\":{\\\"AuthorKeyword\\\":\\\"play\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2533\\\":{\\\"AuthorKeyword\\\":\\\"plenoptic function\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"2534\\\":{\\\"AuthorKeyword\\\":\\\"plenoptic opacity function\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"2535\\\":{\\\"AuthorKeyword\\\":\\\"plume\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2536\\\":{\\\"AuthorKeyword\\\":\\\"poincare map\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2537\\\":{\\\"AuthorKeyword\\\":\\\"poincare transformation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2538\\\":{\\\"AuthorKeyword\\\":\\\"point base\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"2539\\\":{\\\"AuthorKeyword\\\":\\\"point base datum\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"2540\\\":{\\\"AuthorKeyword\\\":\\\"point base model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"2541\\\":{\\\"AuthorKeyword\\\":\\\"point base render\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"2542\\\":{\\\"AuthorKeyword\\\":\\\"point base visualization\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"2543\\\":{\\\"AuthorKeyword\\\":\\\"point cloud\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"2544\\\":{\\\"AuthorKeyword\\\":\\\"point processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"2545\\\":{\\\"AuthorKeyword\\\":\\\"point sample render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"2546\\\":{\\\"AuthorKeyword\\\":\\\"point sample datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"2547\\\":{\\\"AuthorKeyword\\\":\\\"point\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"2548\\\":{\\\"AuthorKeyword\\\":\\\"point as display primitive\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"2549\\\":{\\\"AuthorKeyword\\\":\\\"poisson disk distribution\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"2550\\\":{\\\"AuthorKeyword\\\":\\\"polar system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"2551\\\":{\\\"AuthorKeyword\\\":\\\"polygon render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2552\\\":{\\\"AuthorKeyword\\\":\\\"polygon simplification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"2553\\\":{\\\"AuthorKeyword\\\":\\\"polygonal mesh reduction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"2554\\\":{\\\"AuthorKeyword\\\":\\\"polygonal mesh\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"2555\\\":{\\\"AuthorKeyword\\\":\\\"polygonal modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"2556\\\":{\\\"AuthorKeyword\\\":\\\"polygonal path\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"2557\\\":{\\\"AuthorKeyword\\\":\\\"polygonal surface simplification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"2558\\\":{\\\"AuthorKeyword\\\":\\\"polygonal surface\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"2559\\\":{\\\"AuthorKeyword\\\":\\\"polygonization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"2560\\\":{\\\"AuthorKeyword\\\":\\\"polyhedral grid\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"2561\\\":{\\\"AuthorKeyword\\\":\\\"polyp detection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2562\\\":{\\\"AuthorKeyword\\\":\\\"porosity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"2563\\\":{\\\"AuthorKeyword\\\":\\\"porous solid\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"2564\\\":{\\\"AuthorKeyword\\\":\\\"portable\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Small,Mobile,UbiquitousDevices/Displays\\\",\\\"ExpertKeywordCount\\\":8},\\\"2565\\\":{\\\"AuthorKeyword\\\":\\\"portable parallel programming\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParallelSystemsAndParallelProcessing\\\",\\\"ExpertKeywordCount\\\":17},\\\"2566\\\":{\\\"AuthorKeyword\\\":\\\"portal\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"2567\\\":{\\\"AuthorKeyword\\\":\\\"portfolio mining\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"2568\\\":{\\\"AuthorKeyword\\\":\\\"post illumination\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"2569\\\":{\\\"AuthorKeyword\\\":\\\"post wimp\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"2570\\\":{\\\"AuthorKeyword\\\":\\\"posterior probability of linkage\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"2571\\\":{\\\"AuthorKeyword\\\":\\\"posterior probability of linkage disequilibrium\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"2572\\\":{\\\"AuthorKeyword\\\":\\\"power comparison\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"2573\\\":{\\\"AuthorKeyword\\\":\\\"power graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2574\\\":{\\\"AuthorKeyword\\\":\\\"power graph analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2575\\\":{\\\"AuthorKeyword\\\":\\\"pre integrated volume render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"2576\\\":{\\\"AuthorKeyword\\\":\\\"pre integration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"2577\\\":{\\\"AuthorKeyword\\\":\\\"preattentive processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"2578\\\":{\\\"AuthorKeyword\\\":\\\"predicate function\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2579\\\":{\\\"AuthorKeyword\\\":\\\"predictive analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualAnalysisModels\\\",\\\"ExpertKeywordCount\\\":9},\\\"2580\\\":{\\\"AuthorKeyword\\\":\\\"predictive analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualAnalysisModels\\\",\\\"ExpertKeywordCount\\\":9},\\\"2581\\\":{\\\"AuthorKeyword\\\":\\\"predictive coding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"2582\\\":{\\\"AuthorKeyword\\\":\\\"predictive modeling\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualAnalysisModels\\\",\\\"ExpertKeywordCount\\\":9},\\\"2583\\\":{\\\"AuthorKeyword\\\":\\\"prefetche\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2584\\\":{\\\"AuthorKeyword\\\":\\\"preintegrate light transport\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Illumination\\\",\\\"ExpertKeywordCount\\\":35},\\\"2585\\\":{\\\"AuthorKeyword\\\":\\\"preintegration\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataRegistration,Fusion,AndIntegration\\\",\\\"ExpertKeywordCount\\\":14},\\\"2586\\\":{\\\"AuthorKeyword\\\":\\\"preloade\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2587\\\":{\\\"AuthorKeyword\\\":\\\"preprocesse\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"2588\\\":{\\\"AuthorKeyword\\\":\\\"presence acceleration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"2589\\\":{\\\"AuthorKeyword\\\":\\\"presentation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Presentation,Production,AndDissemination\\\",\\\"ExpertKeywordCount\\\":5},\\\"2590\\\":{\\\"AuthorKeyword\\\":\\\"preview\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2591\\\":{\\\"AuthorKeyword\\\":\\\"principal component analysis\\\",\\\"AuthorKeywordCount\\\":10,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"2592\\\":{\\\"AuthorKeyword\\\":\\\"principal direction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2593\\\":{\\\"AuthorKeyword\\\":\\\"privacy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Privacy,Security,IntelligenceAnalysis\\\",\\\"ExpertKeywordCount\\\":16},\\\"2594\\\":{\\\"AuthorKeyword\\\":\\\"probabilistic algorithm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2595\\\":{\\\"AuthorKeyword\\\":\\\"probabilistic classification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"2596\\\":{\\\"AuthorKeyword\\\":\\\"probabilistic fiber tracking\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tractography\\\",\\\"ExpertKeywordCount\\\":17},\\\"2597\\\":{\\\"AuthorKeyword\\\":\\\"probabilistic judgment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"2598\\\":{\\\"AuthorKeyword\\\":\\\"probabilistic segmentation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"2599\\\":{\\\"AuthorKeyword\\\":\\\"probability\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"2600\\\":{\\\"AuthorKeyword\\\":\\\"probability density function\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"2601\\\":{\\\"AuthorKeyword\\\":\\\"probe\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2602\\\":{\\\"AuthorKeyword\\\":\\\"probe\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2603\\\":{\\\"AuthorKeyword\\\":\\\"problem diagnosis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Reasoning,ProblemSolving,AndDecisionMaking\\\",\\\"ExpertKeywordCount\\\":15},\\\"2604\\\":{\\\"AuthorKeyword\\\":\\\"problem solve\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Reasoning,ProblemSolving,AndDecisionMaking\\\",\\\"ExpertKeywordCount\\\":15},\\\"2605\\\":{\\\"AuthorKeyword\\\":\\\"problem solve environment\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Reasoning,ProblemSolving,AndDecisionMaking\\\",\\\"ExpertKeywordCount\\\":15},\\\"2606\\\":{\\\"AuthorKeyword\\\":\\\"problem subdivision\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"2607\\\":{\\\"AuthorKeyword\\\":\\\"procedural modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"2608\\\":{\\\"AuthorKeyword\\\":\\\"procedural visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"2609\\\":{\\\"AuthorKeyword\\\":\\\"procedure generation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2610\\\":{\\\"AuthorKeyword\\\":\\\"process\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"2611\\\":{\\\"AuthorKeyword\\\":\\\"process visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"2612\\\":{\\\"AuthorKeyword\\\":\\\"processing sequence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"2613\\\":{\\\"AuthorKeyword\\\":\\\"product attribute\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2614\\\":{\\\"AuthorKeyword\\\":\\\"product configuration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2615\\\":{\\\"AuthorKeyword\\\":\\\"product structure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2616\\\":{\\\"AuthorKeyword\\\":\\\"profiling system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2618\\\":{\\\"AuthorKeyword\\\":\\\"program understanding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SoftwareVisualization\\\",\\\"ExpertKeywordCount\\\":13},\\\"2619\\\":{\\\"AuthorKeyword\\\":\\\"program visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SoftwareVisualization\\\",\\\"ExpertKeywordCount\\\":13},\\\"2620\\\":{\\\"AuthorKeyword\\\":\\\"programmable graphic hardware\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"2621\\\":{\\\"AuthorKeyword\\\":\\\"programmable shader\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"2622\\\":{\\\"AuthorKeyword\\\":\\\"programming with example\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2623\\\":{\\\"AuthorKeyword\\\":\\\"progressive compression\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"2624\\\":{\\\"AuthorKeyword\\\":\\\"progressive incremental reconstruction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AdaptiveProcessingAndRefinement\\\",\\\"ExpertKeywordCount\\\":19},\\\"2625\\\":{\\\"AuthorKeyword\\\":\\\"progressive mesh\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"2626\\\":{\\\"AuthorKeyword\\\":\\\"progressive refinement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AdaptiveProcessingAndRefinement\\\",\\\"ExpertKeywordCount\\\":19},\\\"2627\\\":{\\\"AuthorKeyword\\\":\\\"progressive rendering\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2628\\\":{\\\"AuthorKeyword\\\":\\\"progressive transmission\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2629\\\":{\\\"AuthorKeyword\\\":\\\"progressive visual analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"2630\\\":{\\\"AuthorKeyword\\\":\\\"progressive visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"2631\\\":{\\\"AuthorKeyword\\\":\\\"project graph layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2632\\\":{\\\"AuthorKeyword\\\":\\\"project tetrahedra\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"2633\\\":{\\\"AuthorKeyword\\\":\\\"projection\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"2634\\\":{\\\"AuthorKeyword\\\":\\\"projection method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"2635\\\":{\\\"AuthorKeyword\\\":\\\"projection template\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"2636\\\":{\\\"AuthorKeyword\\\":\\\"projective invariant\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"2637\\\":{\\\"AuthorKeyword\\\":\\\"projector camera system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"2638\\\":{\\\"AuthorKeyword\\\":\\\"projector graphic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"2639\\\":{\\\"AuthorKeyword\\\":\\\"projector\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"2640\\\":{\\\"AuthorKeyword\\\":\\\"proofread\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"2641\\\":{\\\"AuthorKeyword\\\":\\\"proportional symbol map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"2642\\\":{\\\"AuthorKeyword\\\":\\\"prop\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"2643\\\":{\\\"AuthorKeyword\\\":\\\"prosthetic heart valve\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2644\\\":{\\\"AuthorKeyword\\\":\\\"protein\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"2645\\\":{\\\"AuthorKeyword\\\":\\\"protein dynamic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"2647\\\":{\\\"AuthorKeyword\\\":\\\"protein isoform\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"2648\\\":{\\\"AuthorKeyword\\\":\\\"protein manipulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"2649\\\":{\\\"AuthorKeyword\\\":\\\"protein structure prediction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"2650\\\":{\\\"AuthorKeyword\\\":\\\"proteomic\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"2651\\\":{\\\"AuthorKeyword\\\":\\\"prototype\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"2652\\\":{\\\"AuthorKeyword\\\":\\\"provenance\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"ProvenanceAndHistory\\\",\\\"ExpertKeywordCount\\\":15},\\\"2653\\\":{\\\"AuthorKeyword\\\":\\\"provenance datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ProvenanceAndHistory\\\",\\\"ExpertKeywordCount\\\":15},\\\"2654\\\":{\\\"AuthorKeyword\\\":\\\"proxemic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2655\\\":{\\\"AuthorKeyword\\\":\\\"proximity\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataAndAnalysisMetrics\\\",\\\"ExpertKeywordCount\\\":11},\\\"2656\\\":{\\\"AuthorKeyword\\\":\\\"proximity shadow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"2657\\\":{\\\"AuthorKeyword\\\":\\\"pseudo color\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"2658\\\":{\\\"AuthorKeyword\\\":\\\"psychophysical scaling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"2659\\\":{\\\"AuthorKeyword\\\":\\\"psychophysic\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2660\\\":{\\\"AuthorKeyword\\\":\\\"public space\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2661\\\":{\\\"AuthorKeyword\\\":\\\"public transportation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"2662\\\":{\\\"AuthorKeyword\\\":\\\"pursuit algorithm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2663\\\":{\\\"AuthorKeyword\\\":\\\"python\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2664\\\":{\\\"AuthorKeyword\\\":\\\"ball\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tractography\\\",\\\"ExpertKeywordCount\\\":17},\\\"2665\\\":{\\\"AuthorKeyword\\\":\\\"qton\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"2666\\\":{\\\"AuthorKeyword\\\":\\\"quadratic programming\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2667\\\":{\\\"AuthorKeyword\\\":\\\"quadratic super spline\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"2668\\\":{\\\"AuthorKeyword\\\":\\\"quadric error metric\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"2669\\\":{\\\"AuthorKeyword\\\":\\\"qualitative analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"QualitativeEvaluation\\\",\\\"ExpertKeywordCount\\\":15},\\\"2670\\\":{\\\"AuthorKeyword\\\":\\\"qualitative evaluation\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"QualitativeEvaluation\\\",\\\"ExpertKeywordCount\\\":15},\\\"2671\\\":{\\\"AuthorKeyword\\\":\\\"qualitative experiment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QualitativeEvaluation\\\",\\\"ExpertKeywordCount\\\":15},\\\"2672\\\":{\\\"AuthorKeyword\\\":\\\"qualitative research\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QualitativeEvaluation\\\",\\\"ExpertKeywordCount\\\":15},\\\"2673\\\":{\\\"AuthorKeyword\\\":\\\"qualitative study\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"QualitativeEvaluation\\\",\\\"ExpertKeywordCount\\\":15},\\\"2674\\\":{\\\"AuthorKeyword\\\":\\\"quality metric\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataAndAnalysisMetrics\\\",\\\"ExpertKeywordCount\\\":11},\\\"2675\\\":{\\\"AuthorKeyword\\\":\\\"quantification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"2676\\\":{\\\"AuthorKeyword\\\":\\\"quantitative analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QuantitativeEvaluation\\\",\\\"ExpertKeywordCount\\\":10},\\\"2678\\\":{\\\"AuthorKeyword\\\":\\\"quantitative evaluation\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"QuantitativeEvaluation\\\",\\\"ExpertKeywordCount\\\":10},\\\"2679\\\":{\\\"AuthorKeyword\\\":\\\"quantitative study\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QuantitativeEvaluation\\\",\\\"ExpertKeywordCount\\\":10},\\\"2680\\\":{\\\"AuthorKeyword\\\":\\\"quantitative texton sequence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"2681\\\":{\\\"AuthorKeyword\\\":\\\"quantization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InformationProcessingAndHandling\\\",\\\"ExpertKeywordCount\\\":4},\\\"2682\\\":{\\\"AuthorKeyword\\\":\\\"quantum chemistry\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"2683\\\":{\\\"AuthorKeyword\\\":\\\"quantum dot\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"2684\\\":{\\\"AuthorKeyword\\\":\\\"quasi static approximation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AdaptiveProcessingAndRefinement\\\",\\\"ExpertKeywordCount\\\":19},\\\"2685\\\":{\\\"AuthorKeyword\\\":\\\"quasi tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2686\\\":{\\\"AuthorKeyword\\\":\\\"quasi interpolation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"2687\\\":{\\\"AuthorKeyword\\\":\\\"quaternion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2688\\\":{\\\"AuthorKeyword\\\":\\\"query\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2689\\\":{\\\"AuthorKeyword\\\":\\\"query by example\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2690\\\":{\\\"AuthorKeyword\\\":\\\"query drive visualization\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2691\\\":{\\\"AuthorKeyword\\\":\\\"query algebra\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2692\\\":{\\\"AuthorKeyword\\\":\\\"query construction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2693\\\":{\\\"AuthorKeyword\\\":\\\"query processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2694\\\":{\\\"AuthorKeyword\\\":\\\"radial basis function interpolation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"2695\\\":{\\\"AuthorKeyword\\\":\\\"radial basis function\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2696\\\":{\\\"AuthorKeyword\\\":\\\"radial graph layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2697\\\":{\\\"AuthorKeyword\\\":\\\"radial layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"2698\\\":{\\\"AuthorKeyword\\\":\\\"radial layout design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"2699\\\":{\\\"AuthorKeyword\\\":\\\"radial menu\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"2700\\\":{\\\"AuthorKeyword\\\":\\\"radial raycasting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Raytracing/raycasting\\\",\\\"ExpertKeywordCount\\\":32},\\\"2701\\\":{\\\"AuthorKeyword\\\":\\\"radial space fill hierarchy visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"2702\\\":{\\\"AuthorKeyword\\\":\\\"radial tree layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"2703\\\":{\\\"AuthorKeyword\\\":\\\"radial tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"2704\\\":{\\\"AuthorKeyword\\\":\\\"radial visualization\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"2705\\\":{\\\"AuthorKeyword\\\":\\\"radio\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"2707\\\":{\\\"AuthorKeyword\\\":\\\"radiograph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2708\\\":{\\\"AuthorKeyword\\\":\\\"radiotherapy planning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2709\\\":{\\\"AuthorKeyword\\\":\\\"radviz\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"2710\\\":{\\\"AuthorKeyword\\\":\\\"rake\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"2711\\\":{\\\"AuthorKeyword\\\":\\\"random access\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"2712\\\":{\\\"AuthorKeyword\\\":\\\"random projection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"2713\\\":{\\\"AuthorKeyword\\\":\\\"random sampling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Sampling\\\",\\\"ExpertKeywordCount\\\":23},\\\"2714\\\":{\\\"AuthorKeyword\\\":\\\"random walker\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2715\\\":{\\\"AuthorKeyword\\\":\\\"range coder\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"2716\\\":{\\\"AuthorKeyword\\\":\\\"rank\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Ranking\\\",\\\"ExpertKeywordCount\\\":5},\\\"2717\\\":{\\\"AuthorKeyword\\\":\\\"rank change\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Ranking\\\",\\\"ExpertKeywordCount\\\":5},\\\"2718\\\":{\\\"AuthorKeyword\\\":\\\"rank visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Ranking\\\",\\\"ExpertKeywordCount\\\":5},\\\"2719\\\":{\\\"AuthorKeyword\\\":\\\"rasch model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CategoricalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"2720\\\":{\\\"AuthorKeyword\\\":\\\"raster map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2721\\\":{\\\"AuthorKeyword\\\":\\\"rate of deformation tensor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"2722\\\":{\\\"AuthorKeyword\\\":\\\"ray coherence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Raytracing/raycasting\\\",\\\"ExpertKeywordCount\\\":32},\\\"2723\\\":{\\\"AuthorKeyword\\\":\\\"ray differential\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Raytracing/raycasting\\\",\\\"ExpertKeywordCount\\\":32},\\\"2724\\\":{\\\"AuthorKeyword\\\":\\\"raycaste\\\",\\\"AuthorKeywordCount\\\":18,\\\"ExpertKeyword\\\":\\\"Raytracing/raycasting\\\",\\\"ExpertKeywordCount\\\":32},\\\"2725\\\":{\\\"AuthorKeyword\\\":\\\"raycaste optimization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Raytracing/raycasting\\\",\\\"ExpertKeywordCount\\\":32},\\\"2726\\\":{\\\"AuthorKeyword\\\":\\\"raytrace\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"Raytracing/raycasting\\\",\\\"ExpertKeywordCount\\\":32},\\\"2727\\\":{\\\"AuthorKeyword\\\":\\\"rdf\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"2728\\\":{\\\"AuthorKeyword\\\":\\\"reaction diffusion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DiffusionRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":11},\\\"2729\\\":{\\\"AuthorKeyword\\\":\\\"readability\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationMetricsAndBenchmarks\\\",\\\"ExpertKeywordCount\\\":19},\\\"2730\\\":{\\\"AuthorKeyword\\\":\\\"real projective plane\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2731\\\":{\\\"AuthorKeyword\\\":\\\"real symmetric tensor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"2732\\\":{\\\"AuthorKeyword\\\":\\\"reality deck\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeAndHighResDisplays\\\",\\\"ExpertKeywordCount\\\":24},\\\"2733\\\":{\\\"AuthorKeyword\\\":\\\"realtime\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"RealtimeProcessing,Rendering,AndVisualizationGeneral\\\",\\\"ExpertKeywordCount\\\":14},\\\"2734\\\":{\\\"AuthorKeyword\\\":\\\"realtime computer graphic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"RealtimeProcessing,Rendering,AndVisualizationGeneral\\\",\\\"ExpertKeywordCount\\\":14},\\\"2735\\\":{\\\"AuthorKeyword\\\":\\\"realtime display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"RealtimeProcessing,Rendering,AndVisualizationGeneral\\\",\\\"ExpertKeywordCount\\\":14},\\\"2736\\\":{\\\"AuthorKeyword\\\":\\\"realtime processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"RealtimeProcessing,Rendering,AndVisualizationGeneral\\\",\\\"ExpertKeywordCount\\\":14},\\\"2737\\\":{\\\"AuthorKeyword\\\":\\\"realtime quantitative query\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2738\\\":{\\\"AuthorKeyword\\\":\\\"realtime render\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"RealtimeProcessing,Rendering,AndVisualizationGeneral\\\",\\\"ExpertKeywordCount\\\":14},\\\"2739\\\":{\\\"AuthorKeyword\\\":\\\"realtime television monitoring\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2740\\\":{\\\"AuthorKeyword\\\":\\\"realtime terrain visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"2741\\\":{\\\"AuthorKeyword\\\":\\\"realtime updating\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"RealtimeProcessing,Rendering,AndVisualizationGeneral\\\",\\\"ExpertKeywordCount\\\":14},\\\"2742\\\":{\\\"AuthorKeyword\\\":\\\"realtime video analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"2743\\\":{\\\"AuthorKeyword\\\":\\\"realtime visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"RealtimeProcessing,Rendering,AndVisualizationGeneral\\\",\\\"ExpertKeywordCount\\\":14},\\\"2744\\\":{\\\"AuthorKeyword\\\":\\\"reason\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"2745\\\":{\\\"AuthorKeyword\\\":\\\"reason process\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Reasoning,ProblemSolving,AndDecisionMaking\\\",\\\"ExpertKeywordCount\\\":15},\\\"2746\\\":{\\\"AuthorKeyword\\\":\\\"recall\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"2747\\\":{\\\"AuthorKeyword\\\":\\\"recognition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2748\\\":{\\\"AuthorKeyword\\\":\\\"recolore algorithm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"2749\\\":{\\\"AuthorKeyword\\\":\\\"recommender system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2750\\\":{\\\"AuthorKeyword\\\":\\\"reconstruction\\\",\\\"AuthorKeywordCount\\\":11,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"2751\\\":{\\\"AuthorKeyword\\\":\\\"reconstruction filter\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"2752\\\":{\\\"AuthorKeyword\\\":\\\"recording\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"2753\\\":{\\\"AuthorKeyword\\\":\\\"rectangular area\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"2754\\\":{\\\"AuthorKeyword\\\":\\\"rectilinear grid\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"2755\\\":{\\\"AuthorKeyword\\\":\\\"recurrent pattern\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"2756\\\":{\\\"AuthorKeyword\\\":\\\"recursive partitioning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"2757\\\":{\\\"AuthorKeyword\\\":\\\"recursive visualization technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"2758\\\":{\\\"AuthorKeyword\\\":\\\"reeb graph\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"2759\\\":{\\\"AuthorKeyword\\\":\\\"reference model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualAnalysisModels\\\",\\\"ExpertKeywordCount\\\":9},\\\"2760\\\":{\\\"AuthorKeyword\\\":\\\"refinement and simplification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AdaptiveProcessingAndRefinement\\\",\\\"ExpertKeywordCount\\\":19},\\\"2761\\\":{\\\"AuthorKeyword\\\":\\\"reformation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"2762\\\":{\\\"AuthorKeyword\\\":\\\"region growing\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2763\\\":{\\\"AuthorKeyword\\\":\\\"region selection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2764\\\":{\\\"AuthorKeyword\\\":\\\"registration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataRegistration,Fusion,AndIntegration\\\",\\\"ExpertKeywordCount\\\":14},\\\"2765\\\":{\\\"AuthorKeyword\\\":\\\"regression\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"2766\\\":{\\\"AuthorKeyword\\\":\\\"regression analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"2767\\\":{\\\"AuthorKeyword\\\":\\\"regular map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"2768\\\":{\\\"AuthorKeyword\\\":\\\"regularity finding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"2769\\\":{\\\"AuthorKeyword\\\":\\\"regularization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2770\\\":{\\\"AuthorKeyword\\\":\\\"reidemeister theorem\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2771\\\":{\\\"AuthorKeyword\\\":\\\"relation base visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"2772\\\":{\\\"AuthorKeyword\\\":\\\"relational datum\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataTypesGeneral\\\",\\\"ExpertKeywordCount\\\":12},\\\"2773\\\":{\\\"AuthorKeyword\\\":\\\"relationship\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"2774\\\":{\\\"AuthorKeyword\\\":\\\"relevance feedback\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2775\\\":{\\\"AuthorKeyword\\\":\\\"remote sensing\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"2776\\\":{\\\"AuthorKeyword\\\":\\\"remote sensing imagery\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2777\\\":{\\\"AuthorKeyword\\\":\\\"remote visualization\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"DistributedSystemsAndGridEnvironments\\\",\\\"ExpertKeywordCount\\\":16},\\\"2778\\\":{\\\"AuthorKeyword\\\":\\\"render\\\",\\\"AuthorKeywordCount\\\":9,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2779\\\":{\\\"AuthorKeyword\\\":\\\"render algorithm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2780\\\":{\\\"AuthorKeyword\\\":\\\"render system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2781\\\":{\\\"AuthorKeyword\\\":\\\"renderman\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"2782\\\":{\\\"AuthorKeyword\\\":\\\"reorderable matrix\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MatrixRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":13},\\\"2783\\\":{\\\"AuthorKeyword\\\":\\\"requirement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"2784\\\":{\\\"AuthorKeyword\\\":\\\"resample\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Sampling\\\",\\\"ExpertKeywordCount\\\":23},\\\"2785\\\":{\\\"AuthorKeyword\\\":\\\"residue flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"2786\\\":{\\\"AuthorKeyword\\\":\\\"resource allocation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2787\\\":{\\\"AuthorKeyword\\\":\\\"responsive workbench\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"2788\\\":{\\\"AuthorKeyword\\\":\\\"restrict union of ball\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"2789\\\":{\\\"AuthorKeyword\\\":\\\"retinal\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2790\\\":{\\\"AuthorKeyword\\\":\\\"retweete thread\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"2791\\\":{\\\"AuthorKeyword\\\":\\\"revert\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"2792\\\":{\\\"AuthorKeyword\\\":\\\"revision control\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SoftwareVisualization\\\",\\\"ExpertKeywordCount\\\":13},\\\"2793\\\":{\\\"AuthorKeyword\\\":\\\"rfid visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2794\\\":{\\\"AuthorKeyword\\\":\\\"rheology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"2795\\\":{\\\"AuthorKeyword\\\":\\\"rheoscopic fluid\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"2796\\\":{\\\"AuthorKeyword\\\":\\\"rhetoric\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Storytelling\\\",\\\"ExpertKeywordCount\\\":10},\\\"2797\\\":{\\\"AuthorKeyword\\\":\\\"ribbon\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"2798\\\":{\\\"AuthorKeyword\\\":\\\"ridge and valley detection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Contour/Creases/Ridges/Valleys\\\",\\\"ExpertKeywordCount\\\":17},\\\"2799\\\":{\\\"AuthorKeyword\\\":\\\"ridge extraction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Contour/Creases/Ridges/Valleys\\\",\\\"ExpertKeywordCount\\\":17},\\\"2800\\\":{\\\"AuthorKeyword\\\":\\\"ridge line\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Contour/Creases/Ridges/Valleys\\\",\\\"ExpertKeywordCount\\\":17},\\\"2801\\\":{\\\"AuthorKeyword\\\":\\\"ridge and valley\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Contour/Creases/Ridges/Valleys\\\",\\\"ExpertKeywordCount\\\":17},\\\"2802\\\":{\\\"AuthorKeyword\\\":\\\"riemannian manifold\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2803\\\":{\\\"AuthorKeyword\\\":\\\"riemannian surface structure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"2804\\\":{\\\"AuthorKeyword\\\":\\\"rigid body dynamic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"2805\\\":{\\\"AuthorKeyword\\\":\\\"rigid body simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"2806\\\":{\\\"AuthorKeyword\\\":\\\"risk analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"2807\\\":{\\\"AuthorKeyword\\\":\\\"rna fold\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MolecularScienceAndChemistry\\\",\\\"ExpertKeywordCount\\\":29},\\\"2808\\\":{\\\"AuthorKeyword\\\":\\\"road base query\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2809\\\":{\\\"AuthorKeyword\\\":\\\"roadblock\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"2810\\\":{\\\"AuthorKeyword\\\":\\\"robustness\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationMetricsAndBenchmarks\\\",\\\"ExpertKeywordCount\\\":19},\\\"2811\\\":{\\\"AuthorKeyword\\\":\\\"roc curve\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"2812\\\":{\\\"AuthorKeyword\\\":\\\"room acoustic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Acoustics,Sound,Sonification\\\",\\\"ExpertKeywordCount\\\":9},\\\"2813\\\":{\\\"AuthorKeyword\\\":\\\"ropelength\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2814\\\":{\\\"AuthorKeyword\\\":\\\"rise tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"2815\\\":{\\\"AuthorKeyword\\\":\\\"rotation invariance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2816\\\":{\\\"AuthorKeyword\\\":\\\"rough surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"2817\\\":{\\\"AuthorKeyword\\\":\\\"route visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"2818\\\":{\\\"AuthorKeyword\\\":\\\"rsvp\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"2819\\\":{\\\"AuthorKeyword\\\":\\\"run length encoding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"2820\\\":{\\\"AuthorKeyword\\\":\\\"ryb\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"2821\\\":{\\\"AuthorKeyword\\\":\\\"saliency\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"2822\\\":{\\\"AuthorKeyword\\\":\\\"salient feature\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"2823\\\":{\\\"AuthorKeyword\\\":\\\"sample base render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2824\\\":{\\\"AuthorKeyword\\\":\\\"sample point\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Sampling\\\",\\\"ExpertKeywordCount\\\":23},\\\"2825\\\":{\\\"AuthorKeyword\\\":\\\"sample\\\",\\\"AuthorKeywordCount\\\":9,\\\"ExpertKeyword\\\":\\\"Sampling\\\",\\\"ExpertKeywordCount\\\":23},\\\"2826\\\":{\\\"AuthorKeyword\\\":\\\"sankey diagram\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"2827\\\":{\\\"AuthorKeyword\\\":\\\"satellite image\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"2828\\\":{\\\"AuthorKeyword\\\":\\\"satisfaction survey\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"2829\\\":{\\\"AuthorKeyword\\\":\\\"scagnostic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"2830\\\":{\\\"AuthorKeyword\\\":\\\"scalability\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"2831\\\":{\\\"AuthorKeyword\\\":\\\"scalability issue\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"2832\\\":{\\\"AuthorKeyword\\\":\\\"scalable graphic hardware\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"2833\\\":{\\\"AuthorKeyword\\\":\\\"scalable rendering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2834\\\":{\\\"AuthorKeyword\\\":\\\"scalable visualization\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"2835\\\":{\\\"AuthorKeyword\\\":\\\"scalar and vector field visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"2836\\\":{\\\"AuthorKeyword\\\":\\\"scalar datum\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ScalarFieldData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2837\\\":{\\\"AuthorKeyword\\\":\\\"scalar field design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ScalarFieldData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2838\\\":{\\\"AuthorKeyword\\\":\\\"scalar field simplification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ScalarFieldData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2839\\\":{\\\"AuthorKeyword\\\":\\\"scalar field symmetry\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ScalarFieldData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2840\\\":{\\\"AuthorKeyword\\\":\\\"scalar field topology\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"ScalarFieldData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2841\\\":{\\\"AuthorKeyword\\\":\\\"scalar field visualization\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"ScalarFieldData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2842\\\":{\\\"AuthorKeyword\\\":\\\"scalar field\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"ScalarFieldData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2843\\\":{\\\"AuthorKeyword\\\":\\\"scalar topology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ScalarFieldData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2844\\\":{\\\"AuthorKeyword\\\":\\\"scale\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"2846\\\":{\\\"AuthorKeyword\\\":\\\"scale free network\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2847\\\":{\\\"AuthorKeyword\\\":\\\"scale invariant opacity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"2848\\\":{\\\"AuthorKeyword\\\":\\\"scale cognition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"2849\\\":{\\\"AuthorKeyword\\\":\\\"scale space\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"MultiScaleData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"2850\\\":{\\\"AuthorKeyword\\\":\\\"scan conversion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"2851\\\":{\\\"AuthorKeyword\\\":\\\"scanline\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2852\\\":{\\\"AuthorKeyword\\\":\\\"scan tunneling microscopy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Microscopy\\\",\\\"ExpertKeywordCount\\\":11},\\\"2853\\\":{\\\"AuthorKeyword\\\":\\\"scatter gather clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"2854\\\":{\\\"AuthorKeyword\\\":\\\"scatter datum\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"2855\\\":{\\\"AuthorKeyword\\\":\\\"scatter datum approximation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AdaptiveProcessingAndRefinement\\\",\\\"ExpertKeywordCount\\\":19},\\\"2856\\\":{\\\"AuthorKeyword\\\":\\\"scatter datum interpolation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"2857\\\":{\\\"AuthorKeyword\\\":\\\"scatterplot\\\",\\\"AuthorKeywordCount\\\":15,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"2858\\\":{\\\"AuthorKeyword\\\":\\\"scatterplot matrix\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"2860\\\":{\\\"AuthorKeyword\\\":\\\"scene graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"2861\\\":{\\\"AuthorKeyword\\\":\\\"scene perception\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2862\\\":{\\\"AuthorKeyword\\\":\\\"schedule visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"2863\\\":{\\\"AuthorKeyword\\\":\\\"schedule\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"2864\\\":{\\\"AuthorKeyword\\\":\\\"schematic map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"2865\\\":{\\\"AuthorKeyword\\\":\\\"schematisation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"2866\\\":{\\\"AuthorKeyword\\\":\\\"science fiction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2867\\\":{\\\"AuthorKeyword\\\":\\\"science museum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2868\\\":{\\\"AuthorKeyword\\\":\\\"science of interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2869\\\":{\\\"AuthorKeyword\\\":\\\"scientific analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"2870\\\":{\\\"AuthorKeyword\\\":\\\"scientific data management\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"2871\\\":{\\\"AuthorKeyword\\\":\\\"scientific illustration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IllustrativeVisualization\\\",\\\"ExpertKeywordCount\\\":40},\\\"2872\\\":{\\\"AuthorKeyword\\\":\\\"scientific literature\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"2873\\\":{\\\"AuthorKeyword\\\":\\\"scientific visualization\\\",\\\"AuthorKeywordCount\\\":56,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"2874\\\":{\\\"AuthorKeyword\\\":\\\"scientific workflow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"2875\\\":{\\\"AuthorKeyword\\\":\\\"score\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2876\\\":{\\\"AuthorKeyword\\\":\\\"screen door transparency\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"2877\\\":{\\\"AuthorKeyword\\\":\\\"screen design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"2878\\\":{\\\"AuthorKeyword\\\":\\\"screen layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"2879\\\":{\\\"AuthorKeyword\\\":\\\"scroll\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"2881\\\":{\\\"AuthorKeyword\\\":\\\"seabed visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"2882\\\":{\\\"AuthorKeyword\\\":\\\"seam carving\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2883\\\":{\\\"AuthorKeyword\\\":\\\"search\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2884\\\":{\\\"AuthorKeyword\\\":\\\"search engine\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2885\\\":{\\\"AuthorKeyword\\\":\\\"search interface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2886\\\":{\\\"AuthorKeyword\\\":\\\"search result\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2887\\\":{\\\"AuthorKeyword\\\":\\\"search user interface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2888\\\":{\\\"AuthorKeyword\\\":\\\"search visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2889\\\":{\\\"AuthorKeyword\\\":\\\"searchlight effect\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2890\\\":{\\\"AuthorKeyword\\\":\\\"seasonal trend decomposition base on loess\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"2891\\\":{\\\"AuthorKeyword\\\":\\\"seed fill\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"2892\\\":{\\\"AuthorKeyword\\\":\\\"seed placement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"ExpertKeywordCount\\\":21},\\\"2893\\\":{\\\"AuthorKeyword\\\":\\\"seed strategy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"ExpertKeywordCount\\\":21},\\\"2894\\\":{\\\"AuthorKeyword\\\":\\\"segmentation\\\",\\\"AuthorKeywordCount\\\":16,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"2895\\\":{\\\"AuthorKeyword\\\":\\\"segmentation ray\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"2896\\\":{\\\"AuthorKeyword\\\":\\\"segmented datum\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"2897\\\":{\\\"AuthorKeyword\\\":\\\"seifert surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2898\\\":{\\\"AuthorKeyword\\\":\\\"seismic attribute\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"2899\\\":{\\\"AuthorKeyword\\\":\\\"seismic datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"2900\\\":{\\\"AuthorKeyword\\\":\\\"seismic interpretation\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"2901\\\":{\\\"AuthorKeyword\\\":\\\"seismic moment tensor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"2902\\\":{\\\"AuthorKeyword\\\":\\\"seismic visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"2903\\\":{\\\"AuthorKeyword\\\":\\\"selection\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2904\\\":{\\\"AuthorKeyword\\\":\\\"selection of interest\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2905\\\":{\\\"AuthorKeyword\\\":\\\"selective refinement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AdaptiveProcessingAndRefinement\\\",\\\"ExpertKeywordCount\\\":19},\\\"2906\\\":{\\\"AuthorKeyword\\\":\\\"self interference\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2907\\\":{\\\"AuthorKeyword\\\":\\\"self organizing network\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2908\\\":{\\\"AuthorKeyword\\\":\\\"semantic edge bundling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2909\\\":{\\\"AuthorKeyword\\\":\\\"semantic graph layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"2910\\\":{\\\"AuthorKeyword\\\":\\\"semantic image classification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"2911\\\":{\\\"AuthorKeyword\\\":\\\"semantic interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"2912\\\":{\\\"AuthorKeyword\\\":\\\"semantic lense\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"2913\\\":{\\\"AuthorKeyword\\\":\\\"semantic meta datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Semantics/semioticsRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"2914\\\":{\\\"AuthorKeyword\\\":\\\"semantic model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Semantics/semioticsRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"2915\\\":{\\\"AuthorKeyword\\\":\\\"semantic net\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualKnowledgeRepresentationAndExternalization\\\",\\\"ExpertKeywordCount\\\":13},\\\"2916\\\":{\\\"AuthorKeyword\\\":\\\"semantic notebook\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Semantics/semioticsRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"2917\\\":{\\\"AuthorKeyword\\\":\\\"semantic substrate\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Semantics/semioticsRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"2918\\\":{\\\"AuthorKeyword\\\":\\\"semantic video classification\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"2919\\\":{\\\"AuthorKeyword\\\":\\\"semantic web\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"2920\\\":{\\\"AuthorKeyword\\\":\\\"semantic zoom\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"2921\\\":{\\\"AuthorKeyword\\\":\\\"semantic\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Semantics/semioticsRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"2922\\\":{\\\"AuthorKeyword\\\":\\\"semi regular mesh\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"2923\\\":{\\\"AuthorKeyword\\\":\\\"semi regular remeshing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"2924\\\":{\\\"AuthorKeyword\\\":\\\"semiotic\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Semantics/semioticsRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"2925\\\":{\\\"AuthorKeyword\\\":\\\"sensemake\\\",\\\"AuthorKeywordCount\\\":16,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"2926\\\":{\\\"AuthorKeyword\\\":\\\"sensemake model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualAnalysisModels\\\",\\\"ExpertKeywordCount\\\":9},\\\"2928\\\":{\\\"AuthorKeyword\\\":\\\"sensor analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"2929\\\":{\\\"AuthorKeyword\\\":\\\"sensor network\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SensorNetworks\\\",\\\"ExpertKeywordCount\\\":1},\\\"2930\\\":{\\\"AuthorKeyword\\\":\\\"separate surface\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"2931\\\":{\\\"AuthorKeyword\\\":\\\"separatrix\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2932\\\":{\\\"AuthorKeyword\\\":\\\"sequence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"2933\\\":{\\\"AuthorKeyword\\\":\\\"sequence analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"2934\\\":{\\\"AuthorKeyword\\\":\\\"sequence identification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"2935\\\":{\\\"AuthorKeyword\\\":\\\"sequential processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"2936\\\":{\\\"AuthorKeyword\\\":\\\"seriation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"2937\\\":{\\\"AuthorKeyword\\\":\\\"server log analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"2938\\\":{\\\"AuthorKeyword\\\":\\\"session analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"2939\\\":{\\\"AuthorKeyword\\\":\\\"set\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SetRelatedData&Techniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"2940\\\":{\\\"AuthorKeyword\\\":\\\"set cover problem\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2941\\\":{\\\"AuthorKeyword\\\":\\\"set type datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SetRelatedData&Techniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"2942\\\":{\\\"AuthorKeyword\\\":\\\"set attribute\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SetRelatedData&Techniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"2943\\\":{\\\"AuthorKeyword\\\":\\\"set intersection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SetRelatedData&Techniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"2944\\\":{\\\"AuthorKeyword\\\":\\\"set relationship\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SetRelatedData&Techniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"2945\\\":{\\\"AuthorKeyword\\\":\\\"set visualization\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"SetRelatedData&Techniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"2946\\\":{\\\"AuthorKeyword\\\":\\\"shader\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"2947\\\":{\\\"AuthorKeyword\\\":\\\"shader programming\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GpuBasedTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"2948\\\":{\\\"AuthorKeyword\\\":\\\"shade\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2949\\\":{\\\"AuthorKeyword\\\":\\\"shade language\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2950\\\":{\\\"AuthorKeyword\\\":\\\"shade model\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2951\\\":{\\\"AuthorKeyword\\\":\\\"shadow removal\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2952\\\":{\\\"AuthorKeyword\\\":\\\"shadow\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"2953\\\":{\\\"AuthorKeyword\\\":\\\"shape base volume analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ShapeRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2954\\\":{\\\"AuthorKeyword\\\":\\\"shape plending\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ShapeRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2955\\\":{\\\"AuthorKeyword\\\":\\\"shape preserve mapping\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ShapeRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2956\\\":{\\\"AuthorKeyword\\\":\\\"shape approximation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ShapeRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2957\\\":{\\\"AuthorKeyword\\\":\\\"shape compression\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"2958\\\":{\\\"AuthorKeyword\\\":\\\"shape interpolation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ShapeRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2959\\\":{\\\"AuthorKeyword\\\":\\\"shape matching\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ShapeRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2960\\\":{\\\"AuthorKeyword\\\":\\\"shape morphing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ShapeRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2961\\\":{\\\"AuthorKeyword\\\":\\\"shape perception\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"2962\\\":{\\\"AuthorKeyword\\\":\\\"shape recognition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ShapeRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2963\\\":{\\\"AuthorKeyword\\\":\\\"shape reconstruction\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ShapeRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2964\\\":{\\\"AuthorKeyword\\\":\\\"shape representation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ShapeRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2965\\\":{\\\"AuthorKeyword\\\":\\\"shape simplification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ShapeRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2966\\\":{\\\"AuthorKeyword\\\":\\\"shape space\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ShapeRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2967\\\":{\\\"AuthorKeyword\\\":\\\"shape transformation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ShapeRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2968\\\":{\\\"AuthorKeyword\\\":\\\"shape vector image\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ShapeRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":18},\\\"2969\\\":{\\\"AuthorKeyword\\\":\\\"shear\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"2970\\\":{\\\"AuthorKeyword\\\":\\\"shear warp algorithm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"2971\\\":{\\\"AuthorKeyword\\\":\\\"shepard method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"2972\\\":{\\\"AuthorKeyword\\\":\\\"shock\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"2973\\\":{\\\"AuthorKeyword\\\":\\\"shock filter\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"2974\\\":{\\\"AuthorKeyword\\\":\\\"signal processing\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"2975\\\":{\\\"AuthorKeyword\\\":\\\"significance map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AlgorithmicPattern/featureDetection/tracking\\\",\\\"ExpertKeywordCount\\\":49},\\\"2976\\\":{\\\"AuthorKeyword\\\":\\\"silhouette enhancement\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"IllustrativeVisualization\\\",\\\"ExpertKeywordCount\\\":40},\\\"2977\\\":{\\\"AuthorKeyword\\\":\\\"silhouette\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"IllustrativeVisualization\\\",\\\"ExpertKeywordCount\\\":40},\\\"2978\\\":{\\\"AuthorKeyword\\\":\\\"similan\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"2979\\\":{\\\"AuthorKeyword\\\":\\\"similarity\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"2981\\\":{\\\"AuthorKeyword\\\":\\\"similarity detection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"2982\\\":{\\\"AuthorKeyword\\\":\\\"similarity measure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAndAnalysisMetrics\\\",\\\"ExpertKeywordCount\\\":11},\\\"2983\\\":{\\\"AuthorKeyword\\\":\\\"similarity query\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"2984\\\":{\\\"AuthorKeyword\\\":\\\"similarity search\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"2986\\\":{\\\"AuthorKeyword\\\":\\\"simplicial complex\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"2987\\\":{\\\"AuthorKeyword\\\":\\\"simplification\\\",\\\"AuthorKeywordCount\\\":14,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"2988\\\":{\\\"AuthorKeyword\\\":\\\"simpson paradox\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"2989\\\":{\\\"AuthorKeyword\\\":\\\"simulation\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"2990\\\":{\\\"AuthorKeyword\\\":\\\"simulation ensemble steering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"2991\\\":{\\\"AuthorKeyword\\\":\\\"simulation control\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"2992\\\":{\\\"AuthorKeyword\\\":\\\"simulation of color vision deficiency\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"2993\\\":{\\\"AuthorKeyword\\\":\\\"simulation steering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"2994\\\":{\\\"AuthorKeyword\\\":\\\"singular fiber\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tractography\\\",\\\"ExpertKeywordCount\\\":17},\\\"2995\\\":{\\\"AuthorKeyword\\\":\\\"singularity\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"2996\\\":{\\\"AuthorKeyword\\\":\\\"singularity tracking\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AlgorithmicPattern/featureDetection/tracking\\\",\\\"ExpertKeywordCount\\\":49},\\\"2997\\\":{\\\"AuthorKeyword\\\":\\\"sinus surgery\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"2998\\\":{\\\"AuthorKeyword\\\":\\\"sitemap\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"2999\\\":{\\\"AuthorKeyword\\\":\\\"situation awareness\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"3000\\\":{\\\"AuthorKeyword\\\":\\\"size\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"3001\\\":{\\\"AuthorKeyword\\\":\\\"skeleton\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3002\\\":{\\\"AuthorKeyword\\\":\\\"skeletonization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"3004\\\":{\\\"AuthorKeyword\\\":\\\"sketch base steering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3005\\\":{\\\"AuthorKeyword\\\":\\\"sketch for visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3006\\\":{\\\"AuthorKeyword\\\":\\\"sketch input\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3007\\\":{\\\"AuthorKeyword\\\":\\\"skin friction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3008\\\":{\\\"AuthorKeyword\\\":\\\"slice\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3009\\\":{\\\"AuthorKeyword\\\":\\\"slider\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"3010\\\":{\\\"AuthorKeyword\\\":\\\"slope perception\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"3011\\\":{\\\"AuthorKeyword\\\":\\\"small display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Small,Mobile,UbiquitousDevices/Displays\\\",\\\"ExpertKeywordCount\\\":8},\\\"3012\\\":{\\\"AuthorKeyword\\\":\\\"small multiple\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3013\\\":{\\\"AuthorKeyword\\\":\\\"small screen\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"3014\\\":{\\\"AuthorKeyword\\\":\\\"small world graph\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"3015\\\":{\\\"AuthorKeyword\\\":\\\"smart aggregation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"3016\\\":{\\\"AuthorKeyword\\\":\\\"smart card datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"3017\\\":{\\\"AuthorKeyword\\\":\\\"smart home\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"3018\\\":{\\\"AuthorKeyword\\\":\\\"smart particle\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"ExpertKeywordCount\\\":21},\\\"3019\\\":{\\\"AuthorKeyword\\\":\\\"smoke visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"ExpertKeywordCount\\\":21},\\\"3020\\\":{\\\"AuthorKeyword\\\":\\\"smooth function\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"3021\\\":{\\\"AuthorKeyword\\\":\\\"smooth surface\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3022\\\":{\\\"AuthorKeyword\\\":\\\"smoothed particle hydrodynamic\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ParticleVisualizationAndTechniques\\\",\\\"ExpertKeywordCount\\\":21},\\\"3023\\\":{\\\"AuthorKeyword\\\":\\\"smooth\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataCleaningAndSmoothing\\\",\\\"ExpertKeywordCount\\\":5},\\\"3024\\\":{\\\"AuthorKeyword\\\":\\\"soar\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"3025\\\":{\\\"AuthorKeyword\\\":\\\"soccer analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SportsVisualization\\\",\\\"ExpertKeywordCount\\\":5},\\\"3026\\\":{\\\"AuthorKeyword\\\":\\\"social datum analysis\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"3027\\\":{\\\"AuthorKeyword\\\":\\\"social datum mining\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"3028\\\":{\\\"AuthorKeyword\\\":\\\"social infovi\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"3029\\\":{\\\"AuthorKeyword\\\":\\\"social medium\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"3031\\\":{\\\"AuthorKeyword\\\":\\\"social medium monitoring\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"3032\\\":{\\\"AuthorKeyword\\\":\\\"social medium text\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"3034\\\":{\\\"AuthorKeyword\\\":\\\"social navigation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"3035\\\":{\\\"AuthorKeyword\\\":\\\"social network analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"3036\\\":{\\\"AuthorKeyword\\\":\\\"social network\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"3037\\\":{\\\"AuthorKeyword\\\":\\\"social network visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"3038\\\":{\\\"AuthorKeyword\\\":\\\"social photo\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"3039\\\":{\\\"AuthorKeyword\\\":\\\"social software\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3040\\\":{\\\"AuthorKeyword\\\":\\\"social visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"3041\\\":{\\\"AuthorKeyword\\\":\\\"socialnetsense\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3042\\\":{\\\"AuthorKeyword\\\":\\\"soft shadow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"3043\\\":{\\\"AuthorKeyword\\\":\\\"software define radio\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Engineering\\\",\\\"ExpertKeywordCount\\\":12},\\\"3044\\\":{\\\"AuthorKeyword\\\":\\\"software engineering\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SoftwareVisualization\\\",\\\"ExpertKeywordCount\\\":13},\\\"3046\\\":{\\\"AuthorKeyword\\\":\\\"software infrastructure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3047\\\":{\\\"AuthorKeyword\\\":\\\"software psychology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SoftwareVisualization\\\",\\\"ExpertKeywordCount\\\":13},\\\"3048\\\":{\\\"AuthorKeyword\\\":\\\"software tool\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3049\\\":{\\\"AuthorKeyword\\\":\\\"software visualization\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"SoftwareVisualization\\\",\\\"ExpertKeywordCount\\\":13},\\\"3050\\\":{\\\"AuthorKeyword\\\":\\\"solid modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"3051\\\":{\\\"AuthorKeyword\\\":\\\"solid texture synthesis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3052\\\":{\\\"AuthorKeyword\\\":\\\"solvent exclude surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3053\\\":{\\\"AuthorKeyword\\\":\\\"sonar technology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Acoustics,Sound,Sonification\\\",\\\"ExpertKeywordCount\\\":9},\\\"3054\\\":{\\\"AuthorKeyword\\\":\\\"sonification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Acoustics,Sound,Sonification\\\",\\\"ExpertKeywordCount\\\":9},\\\"3055\\\":{\\\"AuthorKeyword\\\":\\\"sort last rendering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"3056\\\":{\\\"AuthorKeyword\\\":\\\"sort middle\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"3057\\\":{\\\"AuthorKeyword\\\":\\\"sound analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Acoustics,Sound,Sonification\\\",\\\"ExpertKeywordCount\\\":9},\\\"3058\\\":{\\\"AuthorKeyword\\\":\\\"sound propagation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Acoustics,Sound,Sonification\\\",\\\"ExpertKeywordCount\\\":9},\\\"3059\\\":{\\\"AuthorKeyword\\\":\\\"source code analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SoftwareVisualization\\\",\\\"ExpertKeywordCount\\\":13},\\\"3060\\\":{\\\"AuthorKeyword\\\":\\\"source code visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SoftwareVisualization\\\",\\\"ExpertKeywordCount\\\":13},\\\"3061\\\":{\\\"AuthorKeyword\\\":\\\"space\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"3062\\\":{\\\"AuthorKeyword\\\":\\\"space filling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3063\\\":{\\\"AuthorKeyword\\\":\\\"space filling curve\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"3064\\\":{\\\"AuthorKeyword\\\":\\\"space fill layout generation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3065\\\":{\\\"AuthorKeyword\\\":\\\"space filling technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3066\\\":{\\\"AuthorKeyword\\\":\\\"space fill visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3067\\\":{\\\"AuthorKeyword\\\":\\\"space time cube\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"3068\\\":{\\\"AuthorKeyword\\\":\\\"space time finite element\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"3069\\\":{\\\"AuthorKeyword\\\":\\\"space deformation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ManipulationAndDeformation\\\",\\\"ExpertKeywordCount\\\":7},\\\"3070\\\":{\\\"AuthorKeyword\\\":\\\"space leap\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Raytracing/raycasting\\\",\\\"ExpertKeywordCount\\\":32},\\\"3071\\\":{\\\"AuthorKeyword\\\":\\\"space weather\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"3072\\\":{\\\"AuthorKeyword\\\":\\\"span space\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"3073\\\":{\\\"AuthorKeyword\\\":\\\"sparkline\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"3074\\\":{\\\"AuthorKeyword\\\":\\\"sparse approximation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"3075\\\":{\\\"AuthorKeyword\\\":\\\"sparse point visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PointBasedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":26},\\\"3076\\\":{\\\"AuthorKeyword\\\":\\\"sparse sampling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Sampling\\\",\\\"ExpertKeywordCount\\\":23},\\\"3077\\\":{\\\"AuthorKeyword\\\":\\\"sparse traffic trajectory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"3078\\\":{\\\"AuthorKeyword\\\":\\\"sparsely sample datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"3079\\\":{\\\"AuthorKeyword\\\":\\\"sparsely sampling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Sampling\\\",\\\"ExpertKeywordCount\\\":23},\\\"3080\\\":{\\\"AuthorKeyword\\\":\\\"spatial ability\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"3081\\\":{\\\"AuthorKeyword\\\":\\\"spatial aggregation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"3082\\\":{\\\"AuthorKeyword\\\":\\\"spatial clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"3083\\\":{\\\"AuthorKeyword\\\":\\\"spatial cognition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"3085\\\":{\\\"AuthorKeyword\\\":\\\"spatial conditioning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"3086\\\":{\\\"AuthorKeyword\\\":\\\"spatial construction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"3087\\\":{\\\"AuthorKeyword\\\":\\\"spatial context\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"3088\\\":{\\\"AuthorKeyword\\\":\\\"spatial datum\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"3089\\\":{\\\"AuthorKeyword\\\":\\\"spatial datum mining\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"3090\\\":{\\\"AuthorKeyword\\\":\\\"spatial data structure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"3091\\\":{\\\"AuthorKeyword\\\":\\\"spatial event\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"3092\\\":{\\\"AuthorKeyword\\\":\\\"spatial frequency\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"3093\\\":{\\\"AuthorKeyword\\\":\\\"spatial information organization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"3094\\\":{\\\"AuthorKeyword\\\":\\\"spatial interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3095\\\":{\\\"AuthorKeyword\\\":\\\"spatial layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3096\\\":{\\\"AuthorKeyword\\\":\\\"spatial perception\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"3097\\\":{\\\"AuthorKeyword\\\":\\\"spatial selection\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3098\\\":{\\\"AuthorKeyword\\\":\\\"spatialization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"3099\\\":{\\\"AuthorKeyword\\\":\\\"spatially immersive display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"3100\\\":{\\\"AuthorKeyword\\\":\\\"spatio angular field\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"3101\\\":{\\\"AuthorKeyword\\\":\\\"spatio temporal\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"3103\\\":{\\\"AuthorKeyword\\\":\\\"spatio temporal clustering\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"3104\\\":{\\\"AuthorKeyword\\\":\\\"spatio temporal datum\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"3105\\\":{\\\"AuthorKeyword\\\":\\\"spatio temporal datum mining and visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"3106\\\":{\\\"AuthorKeyword\\\":\\\"spatio temporal index\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"3107\\\":{\\\"AuthorKeyword\\\":\\\"spatio temporal order\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"3108\\\":{\\\"AuthorKeyword\\\":\\\"spatio temporal pattern\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"3109\\\":{\\\"AuthorKeyword\\\":\\\"spatio temporal predicate\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"3111\\\":{\\\"AuthorKeyword\\\":\\\"spatio temporal system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"3112\\\":{\\\"AuthorKeyword\\\":\\\"spatio temporal visual analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"3113\\\":{\\\"AuthorKeyword\\\":\\\"spatio temporal visualization\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"SpatiotemporalDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"3114\\\":{\\\"AuthorKeyword\\\":\\\"special relativity\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"3115\\\":{\\\"AuthorKeyword\\\":\\\"specie distribution model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"3116\\\":{\\\"AuthorKeyword\\\":\\\"spect\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3117\\\":{\\\"AuthorKeyword\\\":\\\"spectate\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"3118\\\":{\\\"AuthorKeyword\\\":\\\"spectral clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"3119\\\":{\\\"AuthorKeyword\\\":\\\"spectral volume render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3121\\\":{\\\"AuthorKeyword\\\":\\\"speech recognition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"3122\\\":{\\\"AuthorKeyword\\\":\\\"speed\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"3123\\\":{\\\"AuthorKeyword\\\":\\\"sphere tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"3124\\\":{\\\"AuthorKeyword\\\":\\\"spherical deconvolution\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3125\\\":{\\\"AuthorKeyword\\\":\\\"spherical harmonic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"3126\\\":{\\\"AuthorKeyword\\\":\\\"spherical harmonic field\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"3127\\\":{\\\"AuthorKeyword\\\":\\\"spherical space\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"3128\\\":{\\\"AuthorKeyword\\\":\\\"spidere\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"3129\\\":{\\\"AuthorKeyword\\\":\\\"spine\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"3130\\\":{\\\"AuthorKeyword\\\":\\\"spiral tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"3131\\\":{\\\"AuthorKeyword\\\":\\\"splatte\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"3132\\\":{\\\"AuthorKeyword\\\":\\\"splatte method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"3133\\\":{\\\"AuthorKeyword\\\":\\\"spline\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"3134\\\":{\\\"AuthorKeyword\\\":\\\"spline patch\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CurvesAndCurvature\\\",\\\"ExpertKeywordCount\\\":27},\\\"3135\\\":{\\\"AuthorKeyword\\\":\\\"sport analytic\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"SportsVisualization\\\",\\\"ExpertKeywordCount\\\":5},\\\"3136\\\":{\\\"AuthorKeyword\\\":\\\"sport visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SportsVisualization\\\",\\\"ExpertKeywordCount\\\":5},\\\"3137\\\":{\\\"AuthorKeyword\\\":\\\"spray render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"3138\\\":{\\\"AuthorKeyword\\\":\\\"spreadsheet\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"TabularDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"3139\\\":{\\\"AuthorKeyword\\\":\\\"spring embedder\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3140\\\":{\\\"AuthorKeyword\\\":\\\"spring model\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3141\\\":{\\\"AuthorKeyword\\\":\\\"stack bar chart\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"3142\\\":{\\\"AuthorKeyword\\\":\\\"stack graph visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"3143\\\":{\\\"AuthorKeyword\\\":\\\"stack graph\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"3144\\\":{\\\"AuthorKeyword\\\":\\\"stagger animation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"3145\\\":{\\\"AuthorKeyword\\\":\\\"standardized testing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3146\\\":{\\\"AuthorKeyword\\\":\\\"star coordinate\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"3147\\\":{\\\"AuthorKeyword\\\":\\\"star glyph\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"3148\\\":{\\\"AuthorKeyword\\\":\\\"star plot\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"3149\\\":{\\\"AuthorKeyword\\\":\\\"state transition base algorithm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"StateRelatedData&Techniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"3150\\\":{\\\"AuthorKeyword\\\":\\\"state diagram\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"StateRelatedData&Techniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"3151\\\":{\\\"AuthorKeyword\\\":\\\"state space\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"StateRelatedData&Techniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"3152\\\":{\\\"AuthorKeyword\\\":\\\"state transition\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"StateRelatedData&Techniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"3153\\\":{\\\"AuthorKeyword\\\":\\\"state\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"StateRelatedData&Techniques\\\",\\\"ExpertKeywordCount\\\":5},\\\"3154\\\":{\\\"AuthorKeyword\\\":\\\"static view selection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"3155\\\":{\\\"AuthorKeyword\\\":\\\"station base observation datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"3156\\\":{\\\"AuthorKeyword\\\":\\\"stationary velocity field\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"3157\\\":{\\\"AuthorKeyword\\\":\\\"statistical analysis\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"3158\\\":{\\\"AuthorKeyword\\\":\\\"statistical computing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"3159\\\":{\\\"AuthorKeyword\\\":\\\"statistical deformation model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"3160\\\":{\\\"AuthorKeyword\\\":\\\"statistical graphic\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"3161\\\":{\\\"AuthorKeyword\\\":\\\"statistical modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"3162\\\":{\\\"AuthorKeyword\\\":\\\"statistical model\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"3163\\\":{\\\"AuthorKeyword\\\":\\\"statistical shape and intensity model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"3164\\\":{\\\"AuthorKeyword\\\":\\\"statistical visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"3165\\\":{\\\"AuthorKeyword\\\":\\\"statistic\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"3166\\\":{\\\"AuthorKeyword\\\":\\\"steer\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3167\\\":{\\\"AuthorKeyword\\\":\\\"stem cell segmentation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"3168\\\":{\\\"AuthorKeyword\\\":\\\"stereo\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"3169\\\":{\\\"AuthorKeyword\\\":\\\"stereo display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"3170\\\":{\\\"AuthorKeyword\\\":\\\"stereo graphic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"3171\\\":{\\\"AuthorKeyword\\\":\\\"stereopsis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"3172\\\":{\\\"AuthorKeyword\\\":\\\"stereoscopic and monoscopic viewing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"3173\\\":{\\\"AuthorKeyword\\\":\\\"stereoscopic field analyzer sfa\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"3174\\\":{\\\"AuthorKeyword\\\":\\\"stitch\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"3175\\\":{\\\"AuthorKeyword\\\":\\\"stitching cell\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"3176\\\":{\\\"AuthorKeyword\\\":\\\"stochastic algorithm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"3177\\\":{\\\"AuthorKeyword\\\":\\\"stochastic tractography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tractography\\\",\\\"ExpertKeywordCount\\\":17},\\\"3178\\\":{\\\"AuthorKeyword\\\":\\\"stock market\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Business,Finance,Economy,Manufacturing\\\",\\\"ExpertKeywordCount\\\":12},\\\"3179\\\":{\\\"AuthorKeyword\\\":\\\"stop criterion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"3180\\\":{\\\"AuthorKeyword\\\":\\\"story make\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Storytelling\\\",\\\"ExpertKeywordCount\\\":10},\\\"3181\\\":{\\\"AuthorKeyword\\\":\\\"storyline visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Storytelling\\\",\\\"ExpertKeywordCount\\\":10},\\\"3182\\\":{\\\"AuthorKeyword\\\":\\\"storyline\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Storytelling\\\",\\\"ExpertKeywordCount\\\":10},\\\"3183\\\":{\\\"AuthorKeyword\\\":\\\"storytelle\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Storytelling\\\",\\\"ExpertKeywordCount\\\":10},\\\"3184\\\":{\\\"AuthorKeyword\\\":\\\"strain\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"3185\\\":{\\\"AuthorKeyword\\\":\\\"strain rate\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"3186\\\":{\\\"AuthorKeyword\\\":\\\"strain tensor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3187\\\":{\\\"AuthorKeyword\\\":\\\"strand\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LineBasedTechniquesAndApproaches\\\",\\\"ExpertKeywordCount\\\":8},\\\"3188\\\":{\\\"AuthorKeyword\\\":\\\"strategic analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"3189\\\":{\\\"AuthorKeyword\\\":\\\"streak surface generation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3190\\\":{\\\"AuthorKeyword\\\":\\\"streak surface\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3191\\\":{\\\"AuthorKeyword\\\":\\\"streakline\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"3192\\\":{\\\"AuthorKeyword\\\":\\\"streakline\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"3193\\\":{\\\"AuthorKeyword\\\":\\\"stream surface\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3194\\\":{\\\"AuthorKeyword\\\":\\\"streamgraph\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"3195\\\":{\\\"AuthorKeyword\\\":\\\"stream\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"StreamingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":9},\\\"3196\\\":{\\\"AuthorKeyword\\\":\\\"stream computation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"StreamingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":9},\\\"3197\\\":{\\\"AuthorKeyword\\\":\\\"stream datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"StreamingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":9},\\\"3198\\\":{\\\"AuthorKeyword\\\":\\\"stream technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"StreamingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":9},\\\"3199\\\":{\\\"AuthorKeyword\\\":\\\"streamline behavior\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"3200\\\":{\\\"AuthorKeyword\\\":\\\"streamline generation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"3201\\\":{\\\"AuthorKeyword\\\":\\\"streamline placement\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"3202\\\":{\\\"AuthorKeyword\\\":\\\"streamline visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"3203\\\":{\\\"AuthorKeyword\\\":\\\"streamline\\\",\\\"AuthorKeywordCount\\\":17,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"3204\\\":{\\\"AuthorKeyword\\\":\\\"streamtube\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Streamlines,Pathlines,Streaklines\\\",\\\"ExpertKeywordCount\\\":33},\\\"3205\\\":{\\\"AuthorKeyword\\\":\\\"stress\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"3206\\\":{\\\"AuthorKeyword\\\":\\\"stress majorization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3208\\\":{\\\"AuthorKeyword\\\":\\\"stress tensor\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3209\\\":{\\\"AuthorKeyword\\\":\\\"stress tensor field\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3210\\\":{\\\"AuthorKeyword\\\":\\\"string\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"3211\\\":{\\\"AuthorKeyword\\\":\\\"structural analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3212\\\":{\\\"AuthorKeyword\\\":\\\"structural comparison\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"3213\\\":{\\\"AuthorKeyword\\\":\\\"structural dissimilarity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"3214\\\":{\\\"AuthorKeyword\\\":\\\"structural mechanic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Engineering\\\",\\\"ExpertKeywordCount\\\":12},\\\"3215\\\":{\\\"AuthorKeyword\\\":\\\"structure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"3216\\\":{\\\"AuthorKeyword\\\":\\\"structure aware navigation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"3217\\\":{\\\"AuthorKeyword\\\":\\\"structure aware selection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3218\\\":{\\\"AuthorKeyword\\\":\\\"structure base brushing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3219\\\":{\\\"AuthorKeyword\\\":\\\"structure detection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"3220\\\":{\\\"AuthorKeyword\\\":\\\"structure tensor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3221\\\":{\\\"AuthorKeyword\\\":\\\"structured light\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Rendering\\\",\\\"ExpertKeywordCount\\\":58},\\\"3222\\\":{\\\"AuthorKeyword\\\":\\\"structured texture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3223\\\":{\\\"AuthorKeyword\\\":\\\"student performance analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3224\\\":{\\\"AuthorKeyword\\\":\\\"style\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IllustrativeVisualization\\\",\\\"ExpertKeywordCount\\\":40},\\\"3225\\\":{\\\"AuthorKeyword\\\":\\\"stylize render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IllustrativeVisualization\\\",\\\"ExpertKeywordCount\\\":40},\\\"3226\\\":{\\\"AuthorKeyword\\\":\\\"sub dimensional space\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"3227\\\":{\\\"AuthorKeyword\\\":\\\"subdivision\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"3228\\\":{\\\"AuthorKeyword\\\":\\\"subdivision scheme\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"3229\\\":{\\\"AuthorKeyword\\\":\\\"subdivision surface\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"3230\\\":{\\\"AuthorKeyword\\\":\\\"subdtw\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3232\\\":{\\\"AuthorKeyword\\\":\\\"subspace\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"3233\\\":{\\\"AuthorKeyword\\\":\\\"subspace finding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"3234\\\":{\\\"AuthorKeyword\\\":\\\"substitope\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"3235\\\":{\\\"AuthorKeyword\\\":\\\"suggest interactivity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3236\\\":{\\\"AuthorKeyword\\\":\\\"suggestive contour\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Contour/Creases/Ridges/Valleys\\\",\\\"ExpertKeywordCount\\\":17},\\\"3237\\\":{\\\"AuthorKeyword\\\":\\\"sum area table\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"3238\\\":{\\\"AuthorKeyword\\\":\\\"super resolution\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultiresolutionTechniques\\\",\\\"ExpertKeywordCount\\\":45},\\\"3239\\\":{\\\"AuthorKeyword\\\":\\\"supercompute\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"3240\\\":{\\\"AuthorKeyword\\\":\\\"superconductor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"3242\\\":{\\\"AuthorKeyword\\\":\\\"superimpose projection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DisplaysGeneral\\\",\\\"ExpertKeywordCount\\\":26},\\\"3243\\\":{\\\"AuthorKeyword\\\":\\\"superscalar processor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"3244\\\":{\\\"AuthorKeyword\\\":\\\"support vector machine\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"3245\\\":{\\\"AuthorKeyword\\\":\\\"surface and curve extremality\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3246\\\":{\\\"AuthorKeyword\\\":\\\"surface and volume illustration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3247\\\":{\\\"AuthorKeyword\\\":\\\"surface approximation\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3249\\\":{\\\"AuthorKeyword\\\":\\\"surface classification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3250\\\":{\\\"AuthorKeyword\\\":\\\"surface construction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3251\\\":{\\\"AuthorKeyword\\\":\\\"surface cross probability\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3252\\\":{\\\"AuthorKeyword\\\":\\\"surface evolver\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3253\\\":{\\\"AuthorKeyword\\\":\\\"surface extraction\\\",\\\"AuthorKeywordCount\\\":9,\\\"ExpertKeyword\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"ExpertKeywordCount\\\":81},\\\"3254\\\":{\\\"AuthorKeyword\\\":\\\"surface fair\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3255\\\":{\\\"AuthorKeyword\\\":\\\"surface fit\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3256\\\":{\\\"AuthorKeyword\\\":\\\"surface flattening\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3257\\\":{\\\"AuthorKeyword\\\":\\\"surface labeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3258\\\":{\\\"AuthorKeyword\\\":\\\"surface matching\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3259\\\":{\\\"AuthorKeyword\\\":\\\"surface model\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3260\\\":{\\\"AuthorKeyword\\\":\\\"surface parameterization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3261\\\":{\\\"AuthorKeyword\\\":\\\"surface processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3262\\\":{\\\"AuthorKeyword\\\":\\\"surface property\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3263\\\":{\\\"AuthorKeyword\\\":\\\"surface reconstruction\\\",\\\"AuthorKeywordCount\\\":10,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3264\\\":{\\\"AuthorKeyword\\\":\\\"surface render\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3265\\\":{\\\"AuthorKeyword\\\":\\\"surface representation\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3266\\\":{\\\"AuthorKeyword\\\":\\\"surface representation and reconstruction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3267\\\":{\\\"AuthorKeyword\\\":\\\"surface similarity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3268\\\":{\\\"AuthorKeyword\\\":\\\"surface simplification\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3269\\\":{\\\"AuthorKeyword\\\":\\\"surface slant\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3271\\\":{\\\"AuthorKeyword\\\":\\\"surface topology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3272\\\":{\\\"AuthorKeyword\\\":\\\"surface visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3273\\\":{\\\"AuthorKeyword\\\":\\\"surface\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3274\\\":{\\\"AuthorKeyword\\\":\\\"surgery planning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3275\\\":{\\\"AuthorKeyword\\\":\\\"surgery planning and simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3276\\\":{\\\"AuthorKeyword\\\":\\\"surgical simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3277\\\":{\\\"AuthorKeyword\\\":\\\"surveillance\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Privacy,Security,IntelligenceAnalysis\\\",\\\"ExpertKeywordCount\\\":16},\\\"3278\\\":{\\\"AuthorKeyword\\\":\\\"surveillance video\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Privacy,Security,IntelligenceAnalysis\\\",\\\"ExpertKeywordCount\\\":16},\\\"3279\\\":{\\\"AuthorKeyword\\\":\\\"survey\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3280\\\":{\\\"AuthorKeyword\\\":\\\"sustainability\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"3281\\\":{\\\"AuthorKeyword\\\":\\\"svg\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"3282\\\":{\\\"AuthorKeyword\\\":\\\"sweep\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3283\\\":{\\\"AuthorKeyword\\\":\\\"swirl flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3284\\\":{\\\"AuthorKeyword\\\":\\\"symmetric\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3285\\\":{\\\"AuthorKeyword\\\":\\\"symmetric tensor\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3286\\\":{\\\"AuthorKeyword\\\":\\\"symmetric traceless tensor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3287\\\":{\\\"AuthorKeyword\\\":\\\"symmetry\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3288\\\":{\\\"AuthorKeyword\\\":\\\"symmetry detection\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualPattern/featureDetectionAndTracking\\\",\\\"ExpertKeywordCount\\\":18},\\\"3289\\\":{\\\"AuthorKeyword\\\":\\\"synchronous situated collaboration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"3290\\\":{\\\"AuthorKeyword\\\":\\\"synchronous view\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultipleLinked/coordinatedViews\\\",\\\"ExpertKeywordCount\\\":50},\\\"3291\\\":{\\\"AuthorKeyword\\\":\\\"synteny\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Genetics\\\",\\\"ExpertKeywordCount\\\":17},\\\"3292\\\":{\\\"AuthorKeyword\\\":\\\"synthetic datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"3293\\\":{\\\"AuthorKeyword\\\":\\\"synthetic datum generation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"3294\\\":{\\\"AuthorKeyword\\\":\\\"synthetic plant\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"3295\\\":{\\\"AuthorKeyword\\\":\\\"system\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3296\\\":{\\\"AuthorKeyword\\\":\\\"system architecture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3297\\\":{\\\"AuthorKeyword\\\":\\\"systematic review\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3298\\\":{\\\"AuthorKeyword\\\":\\\"system biology visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"3299\\\":{\\\"AuthorKeyword\\\":\\\"table lens\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"3300\\\":{\\\"AuthorKeyword\\\":\\\"table tree layout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"3301\\\":{\\\"AuthorKeyword\\\":\\\"tabletop\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"LargeAndHighResDisplays\\\",\\\"ExpertKeywordCount\\\":24},\\\"3302\\\":{\\\"AuthorKeyword\\\":\\\"tabular datum\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"TabularDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"3303\\\":{\\\"AuthorKeyword\\\":\\\"tag cloud\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Charts,Diagrams,Plots\\\",\\\"ExpertKeywordCount\\\":62},\\\"3304\\\":{\\\"AuthorKeyword\\\":\\\"tangible interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3305\\\":{\\\"AuthorKeyword\\\":\\\"tangible user interface\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"3306\\\":{\\\"AuthorKeyword\\\":\\\"task center design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"3307\\\":{\\\"AuthorKeyword\\\":\\\"task and requirement analysis\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"3308\\\":{\\\"AuthorKeyword\\\":\\\"task characterization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"3309\\\":{\\\"AuthorKeyword\\\":\\\"task model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"3310\\\":{\\\"AuthorKeyword\\\":\\\"task performance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"3311\\\":{\\\"AuthorKeyword\\\":\\\"task taxonomy\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Taxonomies\\\",\\\"ExpertKeywordCount\\\":18},\\\"3313\\\":{\\\"AuthorKeyword\\\":\\\"taxi trajectory\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"3314\\\":{\\\"AuthorKeyword\\\":\\\"taxonomy\\\",\\\"AuthorKeywordCount\\\":10,\\\"ExpertKeyword\\\":\\\"Taxonomies\\\",\\\"ExpertKeywordCount\\\":18},\\\"3315\\\":{\\\"AuthorKeyword\\\":\\\"taxonomy of visualization technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Taxonomies\\\",\\\"ExpertKeywordCount\\\":18},\\\"3316\\\":{\\\"AuthorKeyword\\\":\\\"taylor series expansion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"3317\\\":{\\\"AuthorKeyword\\\":\\\"technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"3318\\\":{\\\"AuthorKeyword\\\":\\\"telco datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"3319\\\":{\\\"AuthorKeyword\\\":\\\"tele immersion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"3320\\\":{\\\"AuthorKeyword\\\":\\\"teleoperation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3321\\\":{\\\"AuthorKeyword\\\":\\\"telepresence\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"3322\\\":{\\\"AuthorKeyword\\\":\\\"template\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"3323\\\":{\\\"AuthorKeyword\\\":\\\"temporal aggregation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3324\\\":{\\\"AuthorKeyword\\\":\\\"temporal bone dissection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3325\\\":{\\\"AuthorKeyword\\\":\\\"temporal categorical record\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3326\\\":{\\\"AuthorKeyword\\\":\\\"temporal categorical visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3327\\\":{\\\"AuthorKeyword\\\":\\\"temporal coherence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3328\\\":{\\\"AuthorKeyword\\\":\\\"temporal datum\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3329\\\":{\\\"AuthorKeyword\\\":\\\"temporal event sequence\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3330\\\":{\\\"AuthorKeyword\\\":\\\"temporal interval\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3331\\\":{\\\"AuthorKeyword\\\":\\\"temporal query\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"3332\\\":{\\\"AuthorKeyword\\\":\\\"temporal trajectory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"3333\\\":{\\\"AuthorKeyword\\\":\\\"temporal visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3334\\\":{\\\"AuthorKeyword\\\":\\\"temporal volume render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3335\\\":{\\\"AuthorKeyword\\\":\\\"tennis visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SportsVisualization\\\",\\\"ExpertKeywordCount\\\":5},\\\"3336\\\":{\\\"AuthorKeyword\\\":\\\"tensor\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3337\\\":{\\\"AuthorKeyword\\\":\\\"tensor decomposition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3338\\\":{\\\"AuthorKeyword\\\":\\\"tensor field\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3339\\\":{\\\"AuthorKeyword\\\":\\\"tensor field topology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3340\\\":{\\\"AuthorKeyword\\\":\\\"tensor field visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3341\\\":{\\\"AuthorKeyword\\\":\\\"tensor glyph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"3342\\\":{\\\"AuthorKeyword\\\":\\\"tensor invariant\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3343\\\":{\\\"AuthorKeyword\\\":\\\"tensor line\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3344\\\":{\\\"AuthorKeyword\\\":\\\"tensor reconstruction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3345\\\":{\\\"AuthorKeyword\\\":\\\"tensor topology\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3346\\\":{\\\"AuthorKeyword\\\":\\\"tensor visualization\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3347\\\":{\\\"AuthorKeyword\\\":\\\"terascale visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"3348\\\":{\\\"AuthorKeyword\\\":\\\"terrain\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"3349\\\":{\\\"AuthorKeyword\\\":\\\"terrain modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"3350\\\":{\\\"AuthorKeyword\\\":\\\"terrain model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"3351\\\":{\\\"AuthorKeyword\\\":\\\"terrain render\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"3352\\\":{\\\"AuthorKeyword\\\":\\\"terrain visualization\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"3353\\\":{\\\"AuthorKeyword\\\":\\\"tessellation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3354\\\":{\\\"AuthorKeyword\\\":\\\"test and measurement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3355\\\":{\\\"AuthorKeyword\\\":\\\"testbed design and evaluation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3356\\\":{\\\"AuthorKeyword\\\":\\\"tetrahedra\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3357\\\":{\\\"AuthorKeyword\\\":\\\"tetrahedral compression\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"3358\\\":{\\\"AuthorKeyword\\\":\\\"tetrahedral grid\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3359\\\":{\\\"AuthorKeyword\\\":\\\"tetrahedral grid refinement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3360\\\":{\\\"AuthorKeyword\\\":\\\"tetrahedral mesh\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3361\\\":{\\\"AuthorKeyword\\\":\\\"tetrahedral partition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3362\\\":{\\\"AuthorKeyword\\\":\\\"tetrahedralization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3363\\\":{\\\"AuthorKeyword\\\":\\\"text\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3364\\\":{\\\"AuthorKeyword\\\":\\\"text analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3365\\\":{\\\"AuthorKeyword\\\":\\\"text analytic\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3366\\\":{\\\"AuthorKeyword\\\":\\\"text and document datum\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3367\\\":{\\\"AuthorKeyword\\\":\\\"text and document visualization\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3368\\\":{\\\"AuthorKeyword\\\":\\\"text annotation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3369\\\":{\\\"AuthorKeyword\\\":\\\"text author\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3370\\\":{\\\"AuthorKeyword\\\":\\\"text classification\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3371\\\":{\\\"AuthorKeyword\\\":\\\"text highlighting technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3372\\\":{\\\"AuthorKeyword\\\":\\\"text mining\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3373\\\":{\\\"AuthorKeyword\\\":\\\"text processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3374\\\":{\\\"AuthorKeyword\\\":\\\"text visualization\\\",\\\"AuthorKeywordCount\\\":16,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3375\\\":{\\\"AuthorKeyword\\\":\\\"texton\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"3376\\\":{\\\"AuthorKeyword\\\":\\\"textual information\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3377\\\":{\\\"AuthorKeyword\\\":\\\"texture\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3378\\\":{\\\"AuthorKeyword\\\":\\\"texture base analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3379\\\":{\\\"AuthorKeyword\\\":\\\"texture base render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3380\\\":{\\\"AuthorKeyword\\\":\\\"texture base visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3381\\\":{\\\"AuthorKeyword\\\":\\\"texture base volume render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3382\\\":{\\\"AuthorKeyword\\\":\\\"texture base volume visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3383\\\":{\\\"AuthorKeyword\\\":\\\"texture advection\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3384\\\":{\\\"AuthorKeyword\\\":\\\"texture analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3385\\\":{\\\"AuthorKeyword\\\":\\\"texture cache\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3386\\\":{\\\"AuthorKeyword\\\":\\\"texture compression\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3387\\\":{\\\"AuthorKeyword\\\":\\\"texture for geometry\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3388\\\":{\\\"AuthorKeyword\\\":\\\"texture hardware\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"3389\\\":{\\\"AuthorKeyword\\\":\\\"texture level of detail\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3390\\\":{\\\"AuthorKeyword\\\":\\\"texture mapping\\\",\\\"AuthorKeywordCount\\\":20,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3391\\\":{\\\"AuthorKeyword\\\":\\\"texture map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3392\\\":{\\\"AuthorKeyword\\\":\\\"texture method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3393\\\":{\\\"AuthorKeyword\\\":\\\"texture synthesis\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3394\\\":{\\\"AuthorKeyword\\\":\\\"texture splatting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3395\\\":{\\\"AuthorKeyword\\\":\\\"texture\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3396\\\":{\\\"AuthorKeyword\\\":\\\"thematic cartography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"3397\\\":{\\\"AuthorKeyword\\\":\\\"themeriver\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"3398\\\":{\\\"AuthorKeyword\\\":\\\"theory\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"3399\\\":{\\\"AuthorKeyword\\\":\\\"theory of visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"3400\\\":{\\\"AuthorKeyword\\\":\\\"thin client\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"3401\\\":{\\\"AuthorKeyword\\\":\\\"think aloud\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QualitativeEvaluation\\\",\\\"ExpertKeywordCount\\\":15},\\\"3402\\\":{\\\"AuthorKeyword\\\":\\\"thin\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"3403\\\":{\\\"AuthorKeyword\\\":\\\"thread visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SoftwareVisualization\\\",\\\"ExpertKeywordCount\\\":13},\\\"3404\\\":{\\\"AuthorKeyword\\\":\\\"thread\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParallelSystemsAndParallelProcessing\\\",\\\"ExpertKeywordCount\\\":17},\\\"3405\\\":{\\\"AuthorKeyword\\\":\\\"thread\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ParallelSystemsAndParallelProcessing\\\",\\\"ExpertKeywordCount\\\":17},\\\"3406\\\":{\\\"AuthorKeyword\\\":\\\"tight knot\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"3407\\\":{\\\"AuthorKeyword\\\":\\\"tile display\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"LargeAndHighResDisplays\\\",\\\"ExpertKeywordCount\\\":24},\\\"3408\\\":{\\\"AuthorKeyword\\\":\\\"tile\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ComputerGraphicsTechniques,General\\\",\\\"ExpertKeywordCount\\\":46},\\\"3409\\\":{\\\"AuthorKeyword\\\":\\\"time\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3410\\\":{\\\"AuthorKeyword\\\":\\\"time base visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3411\\\":{\\\"AuthorKeyword\\\":\\\"time critical graphic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TimeCriticalApplications\\\",\\\"ExpertKeywordCount\\\":3},\\\"3412\\\":{\\\"AuthorKeyword\\\":\\\"time critical visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TimeCriticalApplications\\\",\\\"ExpertKeywordCount\\\":3},\\\"3413\\\":{\\\"AuthorKeyword\\\":\\\"time dependent\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3414\\\":{\\\"AuthorKeyword\\\":\\\"time dependent attribute\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3415\\\":{\\\"AuthorKeyword\\\":\\\"time dependent datum\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3417\\\":{\\\"AuthorKeyword\\\":\\\"time dependent flow field\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3418\\\":{\\\"AuthorKeyword\\\":\\\"time dependent scalar field visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ScalarFieldData&Techniques\\\",\\\"ExpertKeywordCount\\\":22},\\\"3419\\\":{\\\"AuthorKeyword\\\":\\\"time dependent scatter datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3420\\\":{\\\"AuthorKeyword\\\":\\\"time dependent vector field\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"3421\\\":{\\\"AuthorKeyword\\\":\\\"time dependent visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3422\\\":{\\\"AuthorKeyword\\\":\\\"time dependent volume datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3423\\\":{\\\"AuthorKeyword\\\":\\\"time orient datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3424\\\":{\\\"AuthorKeyword\\\":\\\"time series\\\",\\\"AuthorKeywordCount\\\":9,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3425\\\":{\\\"AuthorKeyword\\\":\\\"time series analysis\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3426\\\":{\\\"AuthorKeyword\\\":\\\"time series clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3427\\\":{\\\"AuthorKeyword\\\":\\\"time series datum\\\",\\\"AuthorKeywordCount\\\":12,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3428\\\":{\\\"AuthorKeyword\\\":\\\"time series exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3429\\\":{\\\"AuthorKeyword\\\":\\\"time series visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3430\\\":{\\\"AuthorKeyword\\\":\\\"time vary\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3431\\\":{\\\"AuthorKeyword\\\":\\\"time varying and time series visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3432\\\":{\\\"AuthorKeyword\\\":\\\"time vary datum\\\",\\\"AuthorKeywordCount\\\":15,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3433\\\":{\\\"AuthorKeyword\\\":\\\"time vary datum analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3434\\\":{\\\"AuthorKeyword\\\":\\\"time vary field\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3435\\\":{\\\"AuthorKeyword\\\":\\\"time vary information visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3436\\\":{\\\"AuthorKeyword\\\":\\\"time vary visualization\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3437\\\":{\\\"AuthorKeyword\\\":\\\"time vary volume\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3438\\\":{\\\"AuthorKeyword\\\":\\\"time and streak surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3439\\\":{\\\"AuthorKeyword\\\":\\\"time filter\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3440\\\":{\\\"AuthorKeyword\\\":\\\"time navigation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"3441\\\":{\\\"AuthorKeyword\\\":\\\"time surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3442\\\":{\\\"AuthorKeyword\\\":\\\"time travel\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"3443\\\":{\\\"AuthorKeyword\\\":\\\"timeline\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3444\\\":{\\\"AuthorKeyword\\\":\\\"timeline visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3445\\\":{\\\"AuthorKeyword\\\":\\\"timetree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3446\\\":{\\\"AuthorKeyword\\\":\\\"tokamak\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"3447\\\":{\\\"AuthorKeyword\\\":\\\"token\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"3448\\\":{\\\"AuthorKeyword\\\":\\\"tomographic datum\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3449\\\":{\\\"AuthorKeyword\\\":\\\"tone mapping\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"3450\\\":{\\\"AuthorKeyword\\\":\\\"toolkit design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3451\\\":{\\\"AuthorKeyword\\\":\\\"toolkit\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3452\\\":{\\\"AuthorKeyword\\\":\\\"top down interpretation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"3454\\\":{\\\"AuthorKeyword\\\":\\\"topic coopetition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3455\\\":{\\\"AuthorKeyword\\\":\\\"topic detection and tracking\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3456\\\":{\\\"AuthorKeyword\\\":\\\"topic evolution\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3457\\\":{\\\"AuthorKeyword\\\":\\\"topic graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3458\\\":{\\\"AuthorKeyword\\\":\\\"topic model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3459\\\":{\\\"AuthorKeyword\\\":\\\"topic modeling\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3460\\\":{\\\"AuthorKeyword\\\":\\\"topolayout\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3461\\\":{\\\"AuthorKeyword\\\":\\\"topological analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3462\\\":{\\\"AuthorKeyword\\\":\\\"topological datum analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3463\\\":{\\\"AuthorKeyword\\\":\\\"topological fisheye\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Focus+ContextTechniques\\\",\\\"ExpertKeywordCount\\\":68},\\\"3464\\\":{\\\"AuthorKeyword\\\":\\\"topological genus\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3465\\\":{\\\"AuthorKeyword\\\":\\\"topological line\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3466\\\":{\\\"AuthorKeyword\\\":\\\"topological method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3467\\\":{\\\"AuthorKeyword\\\":\\\"topological noise\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3468\\\":{\\\"AuthorKeyword\\\":\\\"topological persistence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3469\\\":{\\\"AuthorKeyword\\\":\\\"topological simplification\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3470\\\":{\\\"AuthorKeyword\\\":\\\"topological spine\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3471\\\":{\\\"AuthorKeyword\\\":\\\"topological thinning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3472\\\":{\\\"AuthorKeyword\\\":\\\"topology\\\",\\\"AuthorKeywordCount\\\":18,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3473\\\":{\\\"AuthorKeyword\\\":\\\"topology base analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3475\\\":{\\\"AuthorKeyword\\\":\\\"topology preservation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3476\\\":{\\\"AuthorKeyword\\\":\\\"topology tracking\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3477\\\":{\\\"AuthorKeyword\\\":\\\"topology visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3479\\\":{\\\"AuthorKeyword\\\":\\\"total variation preserve\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataAcquisitionAndManagement\\\",\\\"ExpertKeywordCount\\\":36},\\\"3480\\\":{\\\"AuthorKeyword\\\":\\\"touch interaction\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3481\\\":{\\\"AuthorKeyword\\\":\\\"tournament\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"3483\\\":{\\\"AuthorKeyword\\\":\\\"trace\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Timeseries,TimeVaryingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":114},\\\"3484\\\":{\\\"AuthorKeyword\\\":\\\"tracheo bronchial tree\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3485\\\":{\\\"AuthorKeyword\\\":\\\"tracking\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"3486\\\":{\\\"AuthorKeyword\\\":\\\"tractography\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Tractography\\\",\\\"ExpertKeywordCount\\\":17},\\\"3487\\\":{\\\"AuthorKeyword\\\":\\\"tradeoff\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"3488\\\":{\\\"AuthorKeyword\\\":\\\"traffic congestion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"3489\\\":{\\\"AuthorKeyword\\\":\\\"traffic flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"3490\\\":{\\\"AuthorKeyword\\\":\\\"traffic jam propagation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"3491\\\":{\\\"AuthorKeyword\\\":\\\"traffic optimization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"3492\\\":{\\\"AuthorKeyword\\\":\\\"traffic routing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"3493\\\":{\\\"AuthorKeyword\\\":\\\"traffic visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"3494\\\":{\\\"AuthorKeyword\\\":\\\"training\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3495\\\":{\\\"AuthorKeyword\\\":\\\"trajectory\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"3496\\\":{\\\"AuthorKeyword\\\":\\\"trajectory analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"3497\\\":{\\\"AuthorKeyword\\\":\\\"trajectory attribute datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"3498\\\":{\\\"AuthorKeyword\\\":\\\"trajectory visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tractography\\\",\\\"ExpertKeywordCount\\\":17},\\\"3499\\\":{\\\"AuthorKeyword\\\":\\\"transaction analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Business,Finance,Economy,Manufacturing\\\",\\\"ExpertKeywordCount\\\":12},\\\"3500\\\":{\\\"AuthorKeyword\\\":\\\"transcatheter aortic valve implantation tavi\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3501\\\":{\\\"AuthorKeyword\\\":\\\"transcription\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3502\\\":{\\\"AuthorKeyword\\\":\\\"transfer function\\\",\\\"AuthorKeywordCount\\\":24,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3503\\\":{\\\"AuthorKeyword\\\":\\\"transfer function design\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3504\\\":{\\\"AuthorKeyword\\\":\\\"transform coding\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"3505\\\":{\\\"AuthorKeyword\\\":\\\"transform encoding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataTransformation\\\",\\\"ExpertKeywordCount\\\":19},\\\"3506\\\":{\\\"AuthorKeyword\\\":\\\"transformation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataTransformation\\\",\\\"ExpertKeywordCount\\\":19},\\\"3507\\\":{\\\"AuthorKeyword\\\":\\\"transient datum stream\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"StreamingDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":9},\\\"3508\\\":{\\\"AuthorKeyword\\\":\\\"transition relationship\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TransitionsAndMorphing\\\",\\\"ExpertKeywordCount\\\":8},\\\"3509\\\":{\\\"AuthorKeyword\\\":\\\"transition system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TransitionsAndMorphing\\\",\\\"ExpertKeywordCount\\\":8},\\\"3510\\\":{\\\"AuthorKeyword\\\":\\\"transitional flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3511\\\":{\\\"AuthorKeyword\\\":\\\"transition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TransitionsAndMorphing\\\",\\\"ExpertKeywordCount\\\":8},\\\"3512\\\":{\\\"AuthorKeyword\\\":\\\"translucence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"OcclusionProblems/techniques\\\",\\\"ExpertKeywordCount\\\":15},\\\"3513\\\":{\\\"AuthorKeyword\\\":\\\"translucent polygon render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"OcclusionProblems/techniques\\\",\\\"ExpertKeywordCount\\\":15},\\\"3514\\\":{\\\"AuthorKeyword\\\":\\\"transparency\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Color&ColorPerception\\\",\\\"ExpertKeywordCount\\\":36},\\\"3515\\\":{\\\"AuthorKeyword\\\":\\\"transparent surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3516\\\":{\\\"AuthorKeyword\\\":\\\"transport diffusion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DiffusionRelatedTechniques\\\",\\\"ExpertKeywordCount\\\":11},\\\"3517\\\":{\\\"AuthorKeyword\\\":\\\"transportation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"3518\\\":{\\\"AuthorKeyword\\\":\\\"transportation assessment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"3519\\\":{\\\"AuthorKeyword\\\":\\\"transportation planning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"3520\\\":{\\\"AuthorKeyword\\\":\\\"travel pattern analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"3521\\\":{\\\"AuthorKeyword\\\":\\\"treatment planning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3522\\\":{\\\"AuthorKeyword\\\":\\\"tree\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"3523\\\":{\\\"AuthorKeyword\\\":\\\"tree browsing and navigation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"3524\\\":{\\\"AuthorKeyword\\\":\\\"tree comparison\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"3525\\\":{\\\"AuthorKeyword\\\":\\\"tree structure\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"3526\\\":{\\\"AuthorKeyword\\\":\\\"tree visualization\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"3527\\\":{\\\"AuthorKeyword\\\":\\\"treemap\\\",\\\"AuthorKeywordCount\\\":19,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"3528\\\":{\\\"AuthorKeyword\\\":\\\"treemap layout algorithm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"3530\\\":{\\\"AuthorKeyword\\\":\\\"tree and network visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"3531\\\":{\\\"AuthorKeyword\\\":\\\"trelli display\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"3532\\\":{\\\"AuthorKeyword\\\":\\\"trend sequence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Events,Trends,OutlierDetection,Analysis,AndVisualization\\\",\\\"ExpertKeywordCount\\\":23},\\\"3533\\\":{\\\"AuthorKeyword\\\":\\\"trend sequence clustering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Events,Trends,OutlierDetection,Analysis,AndVisualization\\\",\\\"ExpertKeywordCount\\\":23},\\\"3534\\\":{\\\"AuthorKeyword\\\":\\\"trend visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Events,Trends,OutlierDetection,Analysis,AndVisualization\\\",\\\"ExpertKeywordCount\\\":23},\\\"3535\\\":{\\\"AuthorKeyword\\\":\\\"trend\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Events,Trends,OutlierDetection,Analysis,AndVisualization\\\",\\\"ExpertKeywordCount\\\":23},\\\"3536\\\":{\\\"AuthorKeyword\\\":\\\"triangle bintree\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3537\\\":{\\\"AuthorKeyword\\\":\\\"triangle decimation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"3538\\\":{\\\"AuthorKeyword\\\":\\\"triangular and tetrahedral grid refinement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3539\\\":{\\\"AuthorKeyword\\\":\\\"triangular mesh\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3540\\\":{\\\"AuthorKeyword\\\":\\\"triangulate irregular network\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"3541\\\":{\\\"AuthorKeyword\\\":\\\"triangulate surface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3542\\\":{\\\"AuthorKeyword\\\":\\\"triangulation\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"3543\\\":{\\\"AuthorKeyword\\\":\\\"triangle\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3544\\\":{\\\"AuthorKeyword\\\":\\\"trisector\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3545\\\":{\\\"AuthorKeyword\\\":\\\"trust building\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"3546\\\":{\\\"AuthorKeyword\\\":\\\"tube\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3547\\\":{\\\"AuthorKeyword\\\":\\\"tubing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3548\\\":{\\\"AuthorKeyword\\\":\\\"tuboid\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3549\\\":{\\\"AuthorKeyword\\\":\\\"tuft\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"3550\\\":{\\\"AuthorKeyword\\\":\\\"tumble flow\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3551\\\":{\\\"AuthorKeyword\\\":\\\"tunnel\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"3552\\\":{\\\"AuthorKeyword\\\":\\\"turbine flow visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3553\\\":{\\\"AuthorKeyword\\\":\\\"turbulence\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3554\\\":{\\\"AuthorKeyword\\\":\\\"twitter\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"3555\\\":{\\\"AuthorKeyword\\\":\\\"two handed interface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3556\\\":{\\\"AuthorKeyword\\\":\\\"two surface visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SurfaceRelatedDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":87},\\\"3557\\\":{\\\"AuthorKeyword\\\":\\\"typhoon\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"3558\\\":{\\\"AuthorKeyword\\\":\\\"typology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"3559\\\":{\\\"AuthorKeyword\\\":\\\"ultrasound\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3560\\\":{\\\"AuthorKeyword\\\":\\\"ultrasound echography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3561\\\":{\\\"AuthorKeyword\\\":\\\"uncertain graph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"3562\\\":{\\\"AuthorKeyword\\\":\\\"uncertainty\\\",\\\"AuthorKeywordCount\\\":18,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"3563\\\":{\\\"AuthorKeyword\\\":\\\"uncertainty category\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"3564\\\":{\\\"AuthorKeyword\\\":\\\"uncertainty fusion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"3565\\\":{\\\"AuthorKeyword\\\":\\\"uncertainty glyph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"3566\\\":{\\\"AuthorKeyword\\\":\\\"uncertainty measure and propagation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"3567\\\":{\\\"AuthorKeyword\\\":\\\"uncertainty modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"3568\\\":{\\\"AuthorKeyword\\\":\\\"uncertainty propagation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"3569\\\":{\\\"AuthorKeyword\\\":\\\"uncertainty quantification\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"3570\\\":{\\\"AuthorKeyword\\\":\\\"uncertainty visualization\\\",\\\"AuthorKeywordCount\\\":28,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"3571\\\":{\\\"AuthorKeyword\\\":\\\"understanding performance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationMetricsAndBenchmarks\\\",\\\"ExpertKeywordCount\\\":19},\\\"3572\\\":{\\\"AuthorKeyword\\\":\\\"undo\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3573\\\":{\\\"AuthorKeyword\\\":\\\"undo redo\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3574\\\":{\\\"AuthorKeyword\\\":\\\"unsteady\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3575\\\":{\\\"AuthorKeyword\\\":\\\"unsteady flow\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3576\\\":{\\\"AuthorKeyword\\\":\\\"unsteady flow visualization\\\",\\\"AuthorKeywordCount\\\":9,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3577\\\":{\\\"AuthorKeyword\\\":\\\"unsteady vector field\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"3578\\\":{\\\"AuthorKeyword\\\":\\\"unstructured datum\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataTypesGeneral\\\",\\\"ExpertKeywordCount\\\":12},\\\"3579\\\":{\\\"AuthorKeyword\\\":\\\"unstructured grid\\\",\\\"AuthorKeywordCount\\\":11,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3580\\\":{\\\"AuthorKeyword\\\":\\\"unstructured mesh\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3581\\\":{\\\"AuthorKeyword\\\":\\\"unstructured mesh\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3582\\\":{\\\"AuthorKeyword\\\":\\\"upwind method\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"3584\\\":{\\\"AuthorKeyword\\\":\\\"urban model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"3585\\\":{\\\"AuthorKeyword\\\":\\\"urban network\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Graph/networkDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":137},\\\"3586\\\":{\\\"AuthorKeyword\\\":\\\"usability experiment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UsabilityStudies\\\",\\\"ExpertKeywordCount\\\":2},\\\"3587\\\":{\\\"AuthorKeyword\\\":\\\"usability study\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UsabilityStudies\\\",\\\"ExpertKeywordCount\\\":2},\\\"3588\\\":{\\\"AuthorKeyword\\\":\\\"user center design\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"3589\\\":{\\\"AuthorKeyword\\\":\\\"user generate layout\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3590\\\":{\\\"AuthorKeyword\\\":\\\"user machine system\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"3591\\\":{\\\"AuthorKeyword\\\":\\\"user evaluation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3592\\\":{\\\"AuthorKeyword\\\":\\\"user experience\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3593\\\":{\\\"AuthorKeyword\\\":\\\"user interaction\\\",\\\"AuthorKeywordCount\\\":12,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3594\\\":{\\\"AuthorKeyword\\\":\\\"user interaction design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"3595\\\":{\\\"AuthorKeyword\\\":\\\"user interface\\\",\\\"AuthorKeywordCount\\\":29,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"3596\\\":{\\\"AuthorKeyword\\\":\\\"user interface component\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"3597\\\":{\\\"AuthorKeyword\\\":\\\"user interface design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"3598\\\":{\\\"AuthorKeyword\\\":\\\"user interface environment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"3599\\\":{\\\"AuthorKeyword\\\":\\\"user interface toolkit\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3600\\\":{\\\"AuthorKeyword\\\":\\\"user involvement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3601\\\":{\\\"AuthorKeyword\\\":\\\"user model\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"3602\\\":{\\\"AuthorKeyword\\\":\\\"user model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"3603\\\":{\\\"AuthorKeyword\\\":\\\"user performance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationMetricsAndBenchmarks\\\",\\\"ExpertKeywordCount\\\":19},\\\"3604\\\":{\\\"AuthorKeyword\\\":\\\"user preference model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QualitativeEvaluation\\\",\\\"ExpertKeywordCount\\\":15},\\\"3605\\\":{\\\"AuthorKeyword\\\":\\\"user satisfaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3606\\\":{\\\"AuthorKeyword\\\":\\\"user scenario\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"3607\\\":{\\\"AuthorKeyword\\\":\\\"user study\\\",\\\"AuthorKeywordCount\\\":27,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3608\\\":{\\\"AuthorKeyword\\\":\\\"user study evaluation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3609\\\":{\\\"AuthorKeyword\\\":\\\"user task\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"3610\\\":{\\\"AuthorKeyword\\\":\\\"user tracking\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3611\\\":{\\\"AuthorKeyword\\\":\\\"utility service\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"3612\\\":{\\\"AuthorKeyword\\\":\\\"validation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3613\\\":{\\\"AuthorKeyword\\\":\\\"value\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"3614\\\":{\\\"AuthorKeyword\\\":\\\"value by area map\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"3615\\\":{\\\"AuthorKeyword\\\":\\\"variable density\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"3616\\\":{\\\"AuthorKeyword\\\":\\\"variable ordering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"3617\\\":{\\\"AuthorKeyword\\\":\\\"variable selection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"3618\\\":{\\\"AuthorKeyword\\\":\\\"variable speed animation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"3619\\\":{\\\"AuthorKeyword\\\":\\\"variable template\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"3620\\\":{\\\"AuthorKeyword\\\":\\\"variance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MachineLearningAndStatistics\\\",\\\"ExpertKeywordCount\\\":86},\\\"3621\\\":{\\\"AuthorKeyword\\\":\\\"variance comparison\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"3622\\\":{\\\"AuthorKeyword\\\":\\\"variational modeling\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"GeometricModeling\\\",\\\"ExpertKeywordCount\\\":61},\\\"3623\\\":{\\\"AuthorKeyword\\\":\\\"variational principle\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"3624\\\":{\\\"AuthorKeyword\\\":\\\"vascular visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3625\\\":{\\\"AuthorKeyword\\\":\\\"vector scale\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"3626\\\":{\\\"AuthorKeyword\\\":\\\"vector datum fusion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"3627\\\":{\\\"AuthorKeyword\\\":\\\"vector field\\\",\\\"AuthorKeywordCount\\\":14,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"3629\\\":{\\\"AuthorKeyword\\\":\\\"vector field reconstruction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"3630\\\":{\\\"AuthorKeyword\\\":\\\"vector field topology\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"3631\\\":{\\\"AuthorKeyword\\\":\\\"vector field visualization\\\",\\\"AuthorKeywordCount\\\":12,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"3632\\\":{\\\"AuthorKeyword\\\":\\\"vector quantization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VectorFields,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":62},\\\"3633\\\":{\\\"AuthorKeyword\\\":\\\"vector topology\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3634\\\":{\\\"AuthorKeyword\\\":\\\"vector tensor visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"TensorDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":54},\\\"3635\\\":{\\\"AuthorKeyword\\\":\\\"vectorize radviz\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multidimensional/Multivariate/MultifieldDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":118},\\\"3636\\\":{\\\"AuthorKeyword\\\":\\\"vehicle scheduling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Traffic\\\",\\\"ExpertKeywordCount\\\":13},\\\"3637\\\":{\\\"AuthorKeyword\\\":\\\"velocity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"3638\\\":{\\\"AuthorKeyword\\\":\\\"velocity gradient\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"3639\\\":{\\\"AuthorKeyword\\\":\\\"ventricular assist device\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3640\\\":{\\\"AuthorKeyword\\\":\\\"verbal analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3641\\\":{\\\"AuthorKeyword\\\":\\\"verifiable visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3642\\\":{\\\"AuthorKeyword\\\":\\\"verification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3643\\\":{\\\"AuthorKeyword\\\":\\\"verification and validation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3644\\\":{\\\"AuthorKeyword\\\":\\\"vertical velocity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"3645\\\":{\\\"AuthorKeyword\\\":\\\"very large scale image\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"3646\\\":{\\\"AuthorKeyword\\\":\\\"vessel analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3647\\\":{\\\"AuthorKeyword\\\":\\\"vessel flattening\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3648\\\":{\\\"AuthorKeyword\\\":\\\"vessel identification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3649\\\":{\\\"AuthorKeyword\\\":\\\"vessel visualization\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3650\\\":{\\\"AuthorKeyword\\\":\\\"viability\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationMetricsAndBenchmarks\\\",\\\"ExpertKeywordCount\\\":19},\\\"3651\\\":{\\\"AuthorKeyword\\\":\\\"video analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"3652\\\":{\\\"AuthorKeyword\\\":\\\"video browsing and exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"3653\\\":{\\\"AuthorKeyword\\\":\\\"video generation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"3654\\\":{\\\"AuthorKeyword\\\":\\\"video placement\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"3655\\\":{\\\"AuthorKeyword\\\":\\\"video processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"3656\\\":{\\\"AuthorKeyword\\\":\\\"video summarization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"3657\\\":{\\\"AuthorKeyword\\\":\\\"video surveillance\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"3658\\\":{\\\"AuthorKeyword\\\":\\\"video visual analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"3659\\\":{\\\"AuthorKeyword\\\":\\\"video visualization\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"3660\\\":{\\\"AuthorKeyword\\\":\\\"video\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Multimedia(image/video/music)\\\",\\\"ExpertKeywordCount\\\":23},\\\"3661\\\":{\\\"AuthorKeyword\\\":\\\"view dependent\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"ViewDependentVisualization\\\",\\\"ExpertKeywordCount\\\":19},\\\"3662\\\":{\\\"AuthorKeyword\\\":\\\"view dependent filtering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FilteringTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"3663\\\":{\\\"AuthorKeyword\\\":\\\"view dependent mesh\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ViewDependentVisualization\\\",\\\"ExpertKeywordCount\\\":19},\\\"3664\\\":{\\\"AuthorKeyword\\\":\\\"view dependent rendering\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"ViewDependentVisualization\\\",\\\"ExpertKeywordCount\\\":19},\\\"3665\\\":{\\\"AuthorKeyword\\\":\\\"view dependent visualization\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"ViewDependentVisualization\\\",\\\"ExpertKeywordCount\\\":19},\\\"3666\\\":{\\\"AuthorKeyword\\\":\\\"view space exploration framework\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3667\\\":{\\\"AuthorKeyword\\\":\\\"view space partitioning\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"3668\\\":{\\\"AuthorKeyword\\\":\\\"view suggestion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ViewDependentVisualization\\\",\\\"ExpertKeywordCount\\\":19},\\\"3669\\\":{\\\"AuthorKeyword\\\":\\\"view synthesis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"3670\\\":{\\\"AuthorKeyword\\\":\\\"view value\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataEditing\\\",\\\"ExpertKeywordCount\\\":3},\\\"3671\\\":{\\\"AuthorKeyword\\\":\\\"view algorithm\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"3672\\\":{\\\"AuthorKeyword\\\":\\\"view control\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ViewDependentVisualization\\\",\\\"ExpertKeywordCount\\\":19},\\\"3673\\\":{\\\"AuthorKeyword\\\":\\\"viewpoint entropy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"3674\\\":{\\\"AuthorKeyword\\\":\\\"viewpoint selection\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"3675\\\":{\\\"AuthorKeyword\\\":\\\"virtual colonoscopy\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3676\\\":{\\\"AuthorKeyword\\\":\\\"virtual coupling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"3677\\\":{\\\"AuthorKeyword\\\":\\\"virtual endoscopy\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3678\\\":{\\\"AuthorKeyword\\\":\\\"virtual environment\\\",\\\"AuthorKeywordCount\\\":15,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"3679\\\":{\\\"AuthorKeyword\\\":\\\"virtual environment model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"3680\\\":{\\\"AuthorKeyword\\\":\\\"virtual input device\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InputAndOutputDevicesGeneral\\\",\\\"ExpertKeywordCount\\\":45},\\\"3681\\\":{\\\"AuthorKeyword\\\":\\\"virtual navigation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"3682\\\":{\\\"AuthorKeyword\\\":\\\"virtual prototyping\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"3683\\\":{\\\"AuthorKeyword\\\":\\\"virtual reality\\\",\\\"AuthorKeywordCount\\\":20,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"3684\\\":{\\\"AuthorKeyword\\\":\\\"virtual world\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"ImmersiveAndVirtualEnvironments\\\",\\\"ExpertKeywordCount\\\":44},\\\"3685\\\":{\\\"AuthorKeyword\\\":\\\"visad\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3686\\\":{\\\"AuthorKeyword\\\":\\\"visibility\\\",\\\"AuthorKeywordCount\\\":6,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"3687\\\":{\\\"AuthorKeyword\\\":\\\"visibility classification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"3688\\\":{\\\"AuthorKeyword\\\":\\\"visibility cull\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"3689\\\":{\\\"AuthorKeyword\\\":\\\"visibility ordering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"OcclusionProblems/techniques\\\",\\\"ExpertKeywordCount\\\":15},\\\"3690\\\":{\\\"AuthorKeyword\\\":\\\"visible human project\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3691\\\":{\\\"AuthorKeyword\\\":\\\"visiblity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"3692\\\":{\\\"AuthorKeyword\\\":\\\"visineer heuristic and expertise\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3693\\\":{\\\"AuthorKeyword\\\":\\\"visual abstraction\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"3694\\\":{\\\"AuthorKeyword\\\":\\\"visual abstraction language\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Abstraction,Simplification,Approximation\\\",\\\"ExpertKeywordCount\\\":50},\\\"3695\\\":{\\\"AuthorKeyword\\\":\\\"visual acuity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"3696\\\":{\\\"AuthorKeyword\\\":\\\"visual aggregation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"3697\\\":{\\\"AuthorKeyword\\\":\\\"visual ambiguity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"3698\\\":{\\\"AuthorKeyword\\\":\\\"visual analysis\\\",\\\"AuthorKeywordCount\\\":13,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"3699\\\":{\\\"AuthorKeyword\\\":\\\"visual analytic\\\",\\\"AuthorKeywordCount\\\":121,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"3700\\\":{\\\"AuthorKeyword\\\":\\\"visual analytic infrastructure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3701\\\":{\\\"AuthorKeyword\\\":\\\"visual analytic of document\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3702\\\":{\\\"AuthorKeyword\\\":\\\"visual analytic process\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"3703\\\":{\\\"AuthorKeyword\\\":\\\"visual analytic query\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"3704\\\":{\\\"AuthorKeyword\\\":\\\"visual artifact in visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3705\\\":{\\\"AuthorKeyword\\\":\\\"visual attention\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"3706\\\":{\\\"AuthorKeyword\\\":\\\"visual citation analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3707\\\":{\\\"AuthorKeyword\\\":\\\"visual clustering\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"DataClusteringAndAggregation\\\",\\\"ExpertKeywordCount\\\":88},\\\"3708\\\":{\\\"AuthorKeyword\\\":\\\"visual clutter\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualClutterAndItsReduction\\\",\\\"ExpertKeywordCount\\\":5},\\\"3709\\\":{\\\"AuthorKeyword\\\":\\\"visual communication\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Presentation,Production,AndDissemination\\\",\\\"ExpertKeywordCount\\\":5},\\\"3710\\\":{\\\"AuthorKeyword\\\":\\\"visual comparison\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Comparison,ComparativeVisualizationAndSimilarity\\\",\\\"ExpertKeywordCount\\\":44},\\\"3711\\\":{\\\"AuthorKeyword\\\":\\\"visual context management\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"3712\\\":{\\\"AuthorKeyword\\\":\\\"visual continuity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3713\\\":{\\\"AuthorKeyword\\\":\\\"visual cue\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"3714\\\":{\\\"AuthorKeyword\\\":\\\"visual datum analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"3715\\\":{\\\"AuthorKeyword\\\":\\\"visual datum exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"3716\\\":{\\\"AuthorKeyword\\\":\\\"visual datum mining\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"3717\\\":{\\\"AuthorKeyword\\\":\\\"visual database exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DatabasesAndDataMining\\\",\\\"ExpertKeywordCount\\\":44},\\\"3718\\\":{\\\"AuthorKeyword\\\":\\\"visual debugging\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"3719\\\":{\\\"AuthorKeyword\\\":\\\"visual design\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"3720\\\":{\\\"AuthorKeyword\\\":\\\"visual document analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3721\\\":{\\\"AuthorKeyword\\\":\\\"visual document analytic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3722\\\":{\\\"AuthorKeyword\\\":\\\"visual effect\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"3723\\\":{\\\"AuthorKeyword\\\":\\\"visual embedding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DimensionalityReduction\\\",\\\"ExpertKeywordCount\\\":56},\\\"3724\\\":{\\\"AuthorKeyword\\\":\\\"visual embellishment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"3725\\\":{\\\"AuthorKeyword\\\":\\\"visual encoding\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3726\\\":{\\\"AuthorKeyword\\\":\\\"visual encoding of numerical error metric\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3727\\\":{\\\"AuthorKeyword\\\":\\\"visual evidence\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"HypothesisForming,Testing,AndVisualEvidence\\\",\\\"ExpertKeywordCount\\\":7},\\\"3728\\\":{\\\"AuthorKeyword\\\":\\\"visual exploration\\\",\\\"AuthorKeywordCount\\\":8,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"3729\\\":{\\\"AuthorKeyword\\\":\\\"visual exploratory datum analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"3730\\\":{\\\"AuthorKeyword\\\":\\\"visual feature\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"3731\\\":{\\\"AuthorKeyword\\\":\\\"visual grouping\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"3732\\\":{\\\"AuthorKeyword\\\":\\\"visual hierarchy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"3733\\\":{\\\"AuthorKeyword\\\":\\\"visual inference\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HypothesisForming,Testing,AndVisualEvidence\\\",\\\"ExpertKeywordCount\\\":7},\\\"3734\\\":{\\\"AuthorKeyword\\\":\\\"visual information seek\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"3735\\\":{\\\"AuthorKeyword\\\":\\\"visual inspection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3736\\\":{\\\"AuthorKeyword\\\":\\\"visual interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3737\\\":{\\\"AuthorKeyword\\\":\\\"visual isomorph\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnalysisProcessGeneral\\\",\\\"ExpertKeywordCount\\\":117},\\\"3738\\\":{\\\"AuthorKeyword\\\":\\\"visual knowledge discovery\\\",\\\"AuthorKeywordCount\\\":15,\\\"ExpertKeyword\\\":\\\"KnowledgeDiscovery\\\",\\\"ExpertKeywordCount\\\":28},\\\"3739\\\":{\\\"AuthorKeyword\\\":\\\"visual knowledge discovery and representation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"KnowledgeDiscovery\\\",\\\"ExpertKeywordCount\\\":28},\\\"3740\\\":{\\\"AuthorKeyword\\\":\\\"visual knowledge representation\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"VisualKnowledgeRepresentationAndExternalization\\\",\\\"ExpertKeywordCount\\\":13},\\\"3741\\\":{\\\"AuthorKeyword\\\":\\\"visual linking\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MultipleLinked/coordinatedViews\\\",\\\"ExpertKeywordCount\\\":50},\\\"3742\\\":{\\\"AuthorKeyword\\\":\\\"visual literature analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3743\\\":{\\\"AuthorKeyword\\\":\\\"visual mapping\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3744\\\":{\\\"AuthorKeyword\\\":\\\"visual memento\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"3745\\\":{\\\"AuthorKeyword\\\":\\\"visual memory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"3746\\\":{\\\"AuthorKeyword\\\":\\\"visual momentum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"AnimationAndMotion\\\",\\\"ExpertKeywordCount\\\":60},\\\"3747\\\":{\\\"AuthorKeyword\\\":\\\"visual notation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3748\\\":{\\\"AuthorKeyword\\\":\\\"visual opinion analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialNetworksAndSocialMedia\\\",\\\"ExpertKeywordCount\\\":47},\\\"3749\\\":{\\\"AuthorKeyword\\\":\\\"visual optimization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Optimization\\\",\\\"ExpertKeywordCount\\\":19},\\\"3750\\\":{\\\"AuthorKeyword\\\":\\\"visual perception\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"3751\\\":{\\\"AuthorKeyword\\\":\\\"visual processing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"3752\\\":{\\\"AuthorKeyword\\\":\\\"visual programming\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"3753\\\":{\\\"AuthorKeyword\\\":\\\"visual programming language\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"3754\\\":{\\\"AuthorKeyword\\\":\\\"visual query\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"3755\\\":{\\\"AuthorKeyword\\\":\\\"visual query language\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"3756\\\":{\\\"AuthorKeyword\\\":\\\"visual query specification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"3757\\\":{\\\"AuthorKeyword\\\":\\\"visual recommendation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"3758\\\":{\\\"AuthorKeyword\\\":\\\"visual search\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"3759\\\":{\\\"AuthorKeyword\\\":\\\"visual sentiment analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3760\\\":{\\\"AuthorKeyword\\\":\\\"visual signature\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3761\\\":{\\\"AuthorKeyword\\\":\\\"visual simulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Simulation\\\",\\\"ExpertKeywordCount\\\":38},\\\"3762\\\":{\\\"AuthorKeyword\\\":\\\"visual steering\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3763\\\":{\\\"AuthorKeyword\\\":\\\"visual structure\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3764\\\":{\\\"AuthorKeyword\\\":\\\"visual task design\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tasks,Task&RequirementsAnalysis\\\",\\\"ExpertKeywordCount\\\":22},\\\"3765\\\":{\\\"AuthorKeyword\\\":\\\"visual temporal query\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"3766\\\":{\\\"AuthorKeyword\\\":\\\"visual testing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3767\\\":{\\\"AuthorKeyword\\\":\\\"visual text analysis\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3768\\\":{\\\"AuthorKeyword\\\":\\\"visual to parametric interaction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3769\\\":{\\\"AuthorKeyword\\\":\\\"visual tracking\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"3770\\\":{\\\"AuthorKeyword\\\":\\\"visual variable\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualEncodingAndLayoutGeneral\\\",\\\"ExpertKeywordCount\\\":82},\\\"3771\\\":{\\\"AuthorKeyword\\\":\\\"visual verification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3772\\\":{\\\"AuthorKeyword\\\":\\\"visualization\\\",\\\"AuthorKeywordCount\\\":153,\\\"ExpertKeyword\\\":\\\"Unclear\\\",\\\"ExpertKeywordCount\\\":479},\\\"3773\\\":{\\\"AuthorKeyword\\\":\\\"visualization and graphic application\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"3774\\\":{\\\"AuthorKeyword\\\":\\\"visualization application\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"3775\\\":{\\\"AuthorKeyword\\\":\\\"visualization author\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"3776\\\":{\\\"AuthorKeyword\\\":\\\"visualization component\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"3777\\\":{\\\"AuthorKeyword\\\":\\\"visualization composition\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"3778\\\":{\\\"AuthorKeyword\\\":\\\"visualization construction\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"3779\\\":{\\\"AuthorKeyword\\\":\\\"visualization design\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"3780\\\":{\\\"AuthorKeyword\\\":\\\"visualization environment\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3781\\\":{\\\"AuthorKeyword\\\":\\\"visualization evaluation\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3782\\\":{\\\"AuthorKeyword\\\":\\\"visualization feature\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DataFeaturesAndAttributes\\\",\\\"ExpertKeywordCount\\\":30},\\\"3783\\\":{\\\"AuthorKeyword\\\":\\\"visualization for climate research\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"3784\\\":{\\\"AuthorKeyword\\\":\\\"visualization framework\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3785\\\":{\\\"AuthorKeyword\\\":\\\"visualization in astrophysic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Astronomy/Astrophysics\\\",\\\"ExpertKeywordCount\\\":17},\\\"3786\\\":{\\\"AuthorKeyword\\\":\\\"visualization in bioinformatic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiologyAndBioinformatics\\\",\\\"ExpertKeywordCount\\\":55},\\\"3787\\\":{\\\"AuthorKeyword\\\":\\\"visualization in earth space and environmental science\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"3788\\\":{\\\"AuthorKeyword\\\":\\\"visualization in education\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Education\\\",\\\"ExpertKeywordCount\\\":4},\\\"3789\\\":{\\\"AuthorKeyword\\\":\\\"visualization in medicine\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3790\\\":{\\\"AuthorKeyword\\\":\\\"visualization in physical science\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"3791\\\":{\\\"AuthorKeyword\\\":\\\"visualization in physical science and engineering\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"3792\\\":{\\\"AuthorKeyword\\\":\\\"visualization in the humanity\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SocialScienceAndHumanities\\\",\\\"ExpertKeywordCount\\\":20},\\\"3793\\\":{\\\"AuthorKeyword\\\":\\\"visualization interface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"3794\\\":{\\\"AuthorKeyword\\\":\\\"visualization literacy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"3795\\\":{\\\"AuthorKeyword\\\":\\\"visualization metaphor\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"3796\\\":{\\\"AuthorKeyword\\\":\\\"visualization model\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"3797\\\":{\\\"AuthorKeyword\\\":\\\"visualization of control\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"3798\\\":{\\\"AuthorKeyword\\\":\\\"visualization of risk\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"3799\\\":{\\\"AuthorKeyword\\\":\\\"visualization on network security\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"3800\\\":{\\\"AuthorKeyword\\\":\\\"visualization over network\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DistributedSystemsAndGridEnvironments\\\",\\\"ExpertKeywordCount\\\":16},\\\"3801\\\":{\\\"AuthorKeyword\\\":\\\"visualization pipeline\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"3802\\\":{\\\"AuthorKeyword\\\":\\\"visualization process\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"3803\\\":{\\\"AuthorKeyword\\\":\\\"visualization recommendation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"3804\\\":{\\\"AuthorKeyword\\\":\\\"visualization reference model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"3805\\\":{\\\"AuthorKeyword\\\":\\\"visualization selection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3806\\\":{\\\"AuthorKeyword\\\":\\\"visualization system and toolkit design\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3807\\\":{\\\"AuthorKeyword\\\":\\\"visualization system\\\",\\\"AuthorKeywordCount\\\":15,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3808\\\":{\\\"AuthorKeyword\\\":\\\"visualization taxonomy and model\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"3809\\\":{\\\"AuthorKeyword\\\":\\\"visualization taxonomy\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Taxonomies\\\",\\\"ExpertKeywordCount\\\":18},\\\"3810\\\":{\\\"AuthorKeyword\\\":\\\"visualization technique\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"3811\\\":{\\\"AuthorKeyword\\\":\\\"visualization technique specification\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"3812\\\":{\\\"AuthorKeyword\\\":\\\"visualization theory\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VisualizationTheory,Models,AndMethods\\\",\\\"ExpertKeywordCount\\\":36},\\\"3813\\\":{\\\"AuthorKeyword\\\":\\\"visualize change\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DynamicVisualization,VisualizationOfChange\\\",\\\"ExpertKeywordCount\\\":14},\\\"3815\\\":{\\\"AuthorKeyword\\\":\\\"visualize cause and effect\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DynamicVisualization,VisualizationOfChange\\\",\\\"ExpertKeywordCount\\\":14},\\\"3816\\\":{\\\"AuthorKeyword\\\":\\\"visualize large sequential data set\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"LargeScaleDataAndScalability\\\",\\\"ExpertKeywordCount\\\":54},\\\"3817\\\":{\\\"AuthorKeyword\\\":\\\"visualize query result\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"QueriesAndSearch\\\",\\\"ExpertKeywordCount\\\":43},\\\"3818\\\":{\\\"AuthorKeyword\\\":\\\"visualize spatially reference datum\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"SpaceRelated,SpatialDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":20},\\\"3819\\\":{\\\"AuthorKeyword\\\":\\\"visualize surface uncertainty\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"ExpertKeywordCount\\\":54},\\\"3820\\\":{\\\"AuthorKeyword\\\":\\\"visualize the web\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"3821\\\":{\\\"AuthorKeyword\\\":\\\"visually accurate visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualDesign,DesignGuidelines\\\",\\\"ExpertKeywordCount\\\":48},\\\"3822\\\":{\\\"AuthorKeyword\\\":\\\"volume preserve mapping\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3823\\\":{\\\"AuthorKeyword\\\":\\\"volume bricke\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3824\\\":{\\\"AuthorKeyword\\\":\\\"volume classification\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"3825\\\":{\\\"AuthorKeyword\\\":\\\"volume completion\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3826\\\":{\\\"AuthorKeyword\\\":\\\"volume compositing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3827\\\":{\\\"AuthorKeyword\\\":\\\"volume compression\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"CompressionTechniques\\\",\\\"ExpertKeywordCount\\\":29},\\\"3828\\\":{\\\"AuthorKeyword\\\":\\\"volume csg\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3829\\\":{\\\"AuthorKeyword\\\":\\\"volume datum\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3830\\\":{\\\"AuthorKeyword\\\":\\\"volume deformation\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3831\\\":{\\\"AuthorKeyword\\\":\\\"volume distortion camera\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cameras,CameraViews,AndProjections\\\",\\\"ExpertKeywordCount\\\":33},\\\"3832\\\":{\\\"AuthorKeyword\\\":\\\"volume edit\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3833\\\":{\\\"AuthorKeyword\\\":\\\"volume exploration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3834\\\":{\\\"AuthorKeyword\\\":\\\"volume fair\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3835\\\":{\\\"AuthorKeyword\\\":\\\"volume fraction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3836\\\":{\\\"AuthorKeyword\\\":\\\"volume gradient operator\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3837\\\":{\\\"AuthorKeyword\\\":\\\"volume graphic\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3839\\\":{\\\"AuthorKeyword\\\":\\\"volume illustration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"IllustrativeVisualization\\\",\\\"ExpertKeywordCount\\\":40},\\\"3840\\\":{\\\"AuthorKeyword\\\":\\\"volume manipulation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3841\\\":{\\\"AuthorKeyword\\\":\\\"volume model\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3842\\\":{\\\"AuthorKeyword\\\":\\\"volume model and render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3843\\\":{\\\"AuthorKeyword\\\":\\\"volume navigation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"3844\\\":{\\\"AuthorKeyword\\\":\\\"volume raycasting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3845\\\":{\\\"AuthorKeyword\\\":\\\"volume reconstruction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3846\\\":{\\\"AuthorKeyword\\\":\\\"volume reformation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3847\\\":{\\\"AuthorKeyword\\\":\\\"volume render\\\",\\\"AuthorKeywordCount\\\":137,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3848\\\":{\\\"AuthorKeyword\\\":\\\"volume render acceleration\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"HardwareAccellerationAndComputationGeneral\\\",\\\"ExpertKeywordCount\\\":35},\\\"3849\\\":{\\\"AuthorKeyword\\\":\\\"volume render of unstructured grid\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3850\\\":{\\\"AuthorKeyword\\\":\\\"volume roam\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3851\\\":{\\\"AuthorKeyword\\\":\\\"volume sample\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Sampling\\\",\\\"ExpertKeywordCount\\\":23},\\\"3852\\\":{\\\"AuthorKeyword\\\":\\\"volume segmentation\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"SegmentationAndClassification\\\",\\\"ExpertKeywordCount\\\":59},\\\"3853\\\":{\\\"AuthorKeyword\\\":\\\"volume shade\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3854\\\":{\\\"AuthorKeyword\\\":\\\"volume splatte\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3855\\\":{\\\"AuthorKeyword\\\":\\\"volume subdivision\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3856\\\":{\\\"AuthorKeyword\\\":\\\"volume texture\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Textures\\\",\\\"ExpertKeywordCount\\\":59},\\\"3857\\\":{\\\"AuthorKeyword\\\":\\\"volume visualization\\\",\\\"AuthorKeywordCount\\\":51,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3858\\\":{\\\"AuthorKeyword\\\":\\\"volume visualization framework\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationSystems,Toolkits,AndEnvironments\\\",\\\"ExpertKeywordCount\\\":72},\\\"3859\\\":{\\\"AuthorKeyword\\\":\\\"volume warp\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3860\\\":{\\\"AuthorKeyword\\\":\\\"volume\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3861\\\":{\\\"AuthorKeyword\\\":\\\"volumetric collision\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3862\\\":{\\\"AuthorKeyword\\\":\\\"volumetric datum\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3863\\\":{\\\"AuthorKeyword\\\":\\\"volumetric datum interpolation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Interpolation\\\",\\\"ExpertKeywordCount\\\":36},\\\"3864\\\":{\\\"AuthorKeyword\\\":\\\"volumetric datum reconstruction\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3865\\\":{\\\"AuthorKeyword\\\":\\\"volumetric environment\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3866\\\":{\\\"AuthorKeyword\\\":\\\"voronoi diagram\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"VoronoiBasedTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"3868\\\":{\\\"AuthorKeyword\\\":\\\"voronoi tessellation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VoronoiBasedTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"3869\\\":{\\\"AuthorKeyword\\\":\\\"voronoi treemap\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VoronoiBasedTechniques\\\",\\\"ExpertKeywordCount\\\":8},\\\"3870\\\":{\\\"AuthorKeyword\\\":\\\"vortex\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3871\\\":{\\\"AuthorKeyword\\\":\\\"vortex analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3872\\\":{\\\"AuthorKeyword\\\":\\\"vortex breakdown\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3873\\\":{\\\"AuthorKeyword\\\":\\\"vortex core line\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3874\\\":{\\\"AuthorKeyword\\\":\\\"vortex core\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3875\\\":{\\\"AuthorKeyword\\\":\\\"vortex detection\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3876\\\":{\\\"AuthorKeyword\\\":\\\"vortex dynamic\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3877\\\":{\\\"AuthorKeyword\\\":\\\"vortex extraction\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3878\\\":{\\\"AuthorKeyword\\\":\\\"vortex region\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3879\\\":{\\\"AuthorKeyword\\\":\\\"vortex visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3880\\\":{\\\"AuthorKeyword\\\":\\\"vorticity transport\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3881\\\":{\\\"AuthorKeyword\\\":\\\"voting\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"3882\\\":{\\\"AuthorKeyword\\\":\\\"voxel base modeling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3883\\\":{\\\"AuthorKeyword\\\":\\\"voxel array\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3884\\\":{\\\"AuthorKeyword\\\":\\\"voxel sampling\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Sampling\\\",\\\"ExpertKeywordCount\\\":23},\\\"3885\\\":{\\\"AuthorKeyword\\\":\\\"voxelization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3886\\\":{\\\"AuthorKeyword\\\":\\\"vrml\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"3887\\\":{\\\"AuthorKeyword\\\":\\\"walkthrough\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3888\\\":{\\\"AuthorKeyword\\\":\\\"wall display\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"LargeAndHighResDisplays\\\",\\\"ExpertKeywordCount\\\":24},\\\"3890\\\":{\\\"AuthorKeyword\\\":\\\"wall shear stress\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"3891\\\":{\\\"AuthorKeyword\\\":\\\"wall thickness\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3892\\\":{\\\"AuthorKeyword\\\":\\\"wang cube\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"3893\\\":{\\\"AuthorKeyword\\\":\\\"water quality\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"3894\\\":{\\\"AuthorKeyword\\\":\\\"watershe transformation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"3895\\\":{\\\"AuthorKeyword\\\":\\\"wave subspace\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"3896\\\":{\\\"AuthorKeyword\\\":\\\"wavefront\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3897\\\":{\\\"AuthorKeyword\\\":\\\"wavelet analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"3898\\\":{\\\"AuthorKeyword\\\":\\\"wavelet transform\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"ImageBasedData,Image/signalProcessing\\\",\\\"ExpertKeywordCount\\\":71},\\\"3899\\\":{\\\"AuthorKeyword\\\":\\\"wavelet\\\",\\\"AuthorKeywordCount\\\":7,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"3900\\\":{\\\"AuthorKeyword\\\":\\\"waveletsat\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NumericalMethods/Mathematics\\\",\\\"ExpertKeywordCount\\\":108},\\\"3901\\\":{\\\"AuthorKeyword\\\":\\\"wave\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"PhysicsAndPhysicalSciences\\\",\\\"ExpertKeywordCount\\\":50},\\\"3902\\\":{\\\"AuthorKeyword\\\":\\\"wayfinde\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"3903\\\":{\\\"AuthorKeyword\\\":\\\"weather\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"3904\\\":{\\\"AuthorKeyword\\\":\\\"weather ensemble\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"3905\\\":{\\\"AuthorKeyword\\\":\\\"weather forecast\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"3906\\\":{\\\"AuthorKeyword\\\":\\\"weather forecasting\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"3907\\\":{\\\"AuthorKeyword\\\":\\\"weather visualization\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"3908\\\":{\\\"AuthorKeyword\\\":\\\"web base application\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"3909\\\":{\\\"AuthorKeyword\\\":\\\"web\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"3910\\\":{\\\"AuthorKeyword\\\":\\\"web browsing\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"3911\\\":{\\\"AuthorKeyword\\\":\\\"web cartography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"3912\\\":{\\\"AuthorKeyword\\\":\\\"web map projection\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"3913\\\":{\\\"AuthorKeyword\\\":\\\"web mapping\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"3914\\\":{\\\"AuthorKeyword\\\":\\\"web mercator\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Maps\\\",\\\"ExpertKeywordCount\\\":23},\\\"3915\\\":{\\\"AuthorKeyword\\\":\\\"web navigation\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"3916\\\":{\\\"AuthorKeyword\\\":\\\"web search result\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"3917\\\":{\\\"AuthorKeyword\\\":\\\"web session log analysis\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"3918\\\":{\\\"AuthorKeyword\\\":\\\"web visualization\\\",\\\"AuthorKeywordCount\\\":5,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"3919\\\":{\\\"AuthorKeyword\\\":\\\"weber law\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Perception\\\",\\\"ExpertKeywordCount\\\":68},\\\"3920\\\":{\\\"AuthorKeyword\\\":\\\"wedge\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"TopologyBasedTechniques\\\",\\\"ExpertKeywordCount\\\":77},\\\"3921\\\":{\\\"AuthorKeyword\\\":\\\"what see be what get\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"DesignMethodologiesAndInteractionDesign\\\",\\\"ExpertKeywordCount\\\":40},\\\"3922\\\":{\\\"AuthorKeyword\\\":\\\"white matter\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"NeurosciencesAndBrainVisualization\\\",\\\"ExpertKeywordCount\\\":17},\\\"3923\\\":{\\\"AuthorKeyword\\\":\\\"white matter tractography\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tractography\\\",\\\"ExpertKeywordCount\\\":17},\\\"3924\\\":{\\\"AuthorKeyword\\\":\\\"white matter tract\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Tractography\\\",\\\"ExpertKeywordCount\\\":17},\\\"3925\\\":{\\\"AuthorKeyword\\\":\\\"whiteboard\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"HumanComputerInteraction,HumanFactors\\\",\\\"ExpertKeywordCount\\\":49},\\\"3926\\\":{\\\"AuthorKeyword\\\":\\\"whole field model\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3927\\\":{\\\"AuthorKeyword\\\":\\\"wiki\\\",\\\"AuthorKeywordCount\\\":2,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"3928\\\":{\\\"AuthorKeyword\\\":\\\"wikipedia\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"3929\\\":{\\\"AuthorKeyword\\\":\\\"wind\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Earth,Space,AndEnvironmentalSciences\\\",\\\"ExpertKeywordCount\\\":49},\\\"3930\\\":{\\\"AuthorKeyword\\\":\\\"wind tunnel\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"FlowVisualization,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":135},\\\"3931\\\":{\\\"AuthorKeyword\\\":\\\"wireless network\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"3932\\\":{\\\"AuthorKeyword\\\":\\\"wizard of oz\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"EvaluationGeneral\\\",\\\"ExpertKeywordCount\\\":133},\\\"3933\\\":{\\\"AuthorKeyword\\\":\\\"word scale visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Glyphs,GlyphBasedTechniques\\\",\\\"ExpertKeywordCount\\\":36},\\\"3934\\\":{\\\"AuthorKeyword\\\":\\\"wordnet\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Text,Document,TopicAnalysis,Data,AndTechniques\\\",\\\"ExpertKeywordCount\\\":76},\\\"3935\\\":{\\\"AuthorKeyword\\\":\\\"work material\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"MaterialScience\\\",\\\"ExpertKeywordCount\\\":18},\\\"3936\\\":{\\\"AuthorKeyword\\\":\\\"workflow visualization\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VisualizationTechniquesAndToolsGeneral\\\",\\\"ExpertKeywordCount\\\":86},\\\"3937\\\":{\\\"AuthorKeyword\\\":\\\"work memory\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Cognition\\\",\\\"ExpertKeywordCount\\\":60},\\\"3938\\\":{\\\"AuthorKeyword\\\":\\\"workspace awareness\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"CollaborativeVisualization\\\",\\\"ExpertKeywordCount\\\":33},\\\"3939\\\":{\\\"AuthorKeyword\\\":\\\"world in miniature wim\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"InteractionTechniquesGeneral\\\",\\\"ExpertKeywordCount\\\":198},\\\"3940\\\":{\\\"AuthorKeyword\\\":\\\"world wide web\\\",\\\"AuthorKeywordCount\\\":9,\\\"ExpertKeyword\\\":\\\"Internet,Web,VisualizationForTheMasses\\\",\\\"ExpertKeywordCount\\\":38},\\\"3941\\\":{\\\"AuthorKeyword\\\":\\\"worldmapper\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Geography,GeospatialVis,Cartography,TerrainVis\\\",\\\"ExpertKeywordCount\\\":72},\\\"3942\\\":{\\\"AuthorKeyword\\\":\\\"wormhole attack\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ComputerNetworks&NetworkSecurity\\\",\\\"ExpertKeywordCount\\\":18},\\\"3943\\\":{\\\"AuthorKeyword\\\":\\\"ray\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"ExpertKeywordCount\\\":134},\\\"3944\\\":{\\\"AuthorKeyword\\\":\\\"ray volume render\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"VolumeRendering,Modeling,AndVisualization\\\",\\\"ExpertKeywordCount\\\":267},\\\"3945\\\":{\\\"AuthorKeyword\\\":\\\"xkcd\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"ExpertKeywordCount\\\":86},\\\"3946\\\":{\\\"AuthorKeyword\\\":\\\"xml\\\",\\\"AuthorKeywordCount\\\":3,\\\"ExpertKeyword\\\":\\\"Programming,Algorithms,AndDataStructures\\\",\\\"ExpertKeywordCount\\\":89},\\\"3947\\\":{\\\"AuthorKeyword\\\":\\\"zoomable grid\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Meshes,Grids,AndLattices\\\",\\\"ExpertKeywordCount\\\":105},\\\"3948\\\":{\\\"AuthorKeyword\\\":\\\"zoomable treemap\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"Hierarchical/treeDataAndTechniques\\\",\\\"ExpertKeywordCount\\\":80},\\\"3949\\\":{\\\"AuthorKeyword\\\":\\\"zoomable user interface\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"UserInterfacesGeneral\\\",\\\"ExpertKeywordCount\\\":60},\\\"3950\\\":{\\\"AuthorKeyword\\\":\\\"zooming\\\",\\\"AuthorKeywordCount\\\":4,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35},\\\"3951\\\":{\\\"AuthorKeyword\\\":\\\"zooming and navigation technique\\\",\\\"AuthorKeywordCount\\\":1,\\\"ExpertKeyword\\\":\\\"ZoomingAndNavigationTechniques\\\",\\\"ExpertKeywordCount\\\":35}}\");//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoiLi9kYXRhc2V0cy9tYXBwaW5nLmpzb24uanMiLCJzb3VyY2VzIjpbXSwibWFwcGluZ3MiOiIiLCJzb3VyY2VSb290IjoiIn0=\n//# sourceURL=webpack-internal:///./datasets/mapping.json\n");

/***/ }),

/***/ "./datasets/new_data.json":
/*!********************************!*\
  !*** ./datasets/new_data.json ***!
  \********************************/
/*! exports provided: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, default */
/***/ (function(module) {

eval("module.exports = JSON.parse(\"{\\\"0\\\":{\\\"Abstract\\\":\\\"We describe and demonstrate an extensible framework that supports data exploration and provenance in the context of Human Terrain Analysis (HTA). Working closely with defence analysts we extract requirements and a list of features that characterise data analysed at the end of the HTA chain. From these, we select an appropriate non-classified data source with analogous features, and model it as a set of facets. We develop ProveML, an XML-based extension of the Open Provenance Model, using these facets and augment it with the structures necessary to record the provenance of data, analytical process and interpretations. Through an iterative process, we develop and refine a prototype system for Human Terrain Visual Analytics (HTVA), and demonstrate means of storing, browsing and recalling analytical provenance and process through analytic bookmarks in ProveML. We show how these bookmarks can be combined to form narratives that link back to the live data. Throughout the process, we demonstrate that through structured workshops, rapid prototyping and structured communication with intelligence analysts we are able to establish requirements, and design schema, techniques and tools that meet the requirements of the intelligence community. We use the needs and reactions of defence analysts in defining and steering the methods to validate the framework.\\\",\\\"Authors\\\":\\\"Walker, R.;Slingsby, A.;Dykes, J.;Kai Xu;Wood, J.;Nguyen, P.H.;Stephens, D.;Wong, B.L.W.;Yongjun Zheng\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;InternetWebVisualizationForTheMasses;ProvenanceAndHistory;Storytelling;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2013.132\\\",\\\"Keywords\\\":\\\"human terrain analysis;provenance;bookmarks;framework;narrative\\\",\\\"Keywords_Processed\\\":\\\"human terrain analysis;framework;narrative;bookmark;provenance\\\",\\\"Title\\\":\\\"An Extensible Framework for Provenance in Human Terrain Visual Analytics\\\"},\\\"1\\\":{\\\"Abstract\\\":\\\"We present a novel dynamic graph visualization technique based on node-link diagrams. The graphs are drawn side-byside from left to right as a sequence of narrow stripes that are placed perpendicular to the horizontal time line. The hierarchically organized vertices of the graphs are arranged on vertical, parallel lines that bound the stripes; directed edges connect these vertices from left to right. To address massive overplotting of edges in huge graphs, we employ a splatting approach that transforms the edges to a pixel-based scalar field. This field represents the edge densities in a scalable way and is depicted by non-linear color mapping. The visualization method is complemented by interaction techniques that support data exploration by aggregation, filtering, brushing, and selective data zooming. Furthermore, we formalize graph patterns so that they can be interactively highlighted on demand. A case study on software releases explores the evolution of call graphs extracted from the JUnit open source software project. In a second application, we demonstrate the scalability of our approach by applying it to a bibliography dataset containing more than 1.5 million paper titles from 60 years of research history producing a vast amount of relations between title words.\\\",\\\"Authors\\\":\\\"Burch, M.;Vehlow, C.;Beck, F.;Diehl, S.;Weiskopf, D.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;ProgrammingAlgorithmsAndDataStructures;SoftwareVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2011.226\\\",\\\"Keywords\\\":\\\"software visualization;graph splatting;dynamic graph visualization;software evolution\\\",\\\"Keywords_Processed\\\":\\\"dynamic graph visualization;software visualization;software evolution;graph splatte\\\",\\\"Title\\\":\\\"Parallel Edge Splatting for Scalable Dynamic Graph Visualization\\\"},\\\"2\\\":{\\\"Abstract\\\":\\\"Percutaneous radiofrequency ablation (RFA) is becoming a standard minimally invasive clinical procedure for the treatment of liver tumors. However, planning the applicator placement such that the malignant tissue is completely destroyed, is a demanding task that requires considerable experience. In this work, we present a fast GPU-based real-time approximation of the ablation zone incorporating the cooling effect of liver vessels. Weighted distance fields of varying RF applicator types are derived from complex numerical simulations to allow a fast estimation of the ablation zone. Furthermore, the heat-sink effect of the cooling blood flow close to the applicator's electrode is estimated by means of a preprocessed thermal equilibrium representation of the liver parenchyma and blood vessels. Utilizing the graphics card, the weighted distance field incorporating the cooling blood flow is calculated using a modular shader framework, which facilitates the real-time visualization of the ablation zone in projected slice views and in volume rendering. The proposed methods are integrated in our software assistant prototype for planning RFA therapy. The software allows the physician to interactively place virtual RF applicator models. The real-time visualization of the corresponding approximated ablation zone facilitates interactive evaluation of the tumor coverage in order to optimize the applicator's placement such that all cancer cells are destroyed by the ablation.\\\",\\\"Authors\\\":\\\"Rieder, C.;Kroeger, T.;Schumann, C.;Hahn, H.K.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;EarthSpaceAndEnvironmentalSciences;GpuBasedTechniques;InteractionTechniquesGeneral;VisualizationTechniquesAndToolsGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2011.207\\\",\\\"Keywords\\\":\\\"volume rendering;distance field;ablation zone visualization;gpu;radiofrequency ablation;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;volume render;distance field;radiofrequency ablation;ablation zone visualization;gpu\\\",\\\"Title\\\":\\\"GPU-based Real-Time Approximation of the Ablation Zone for Radiofrequency Ablation\\\"},\\\"3\\\":{\\\"Abstract\\\":\\\"We present a novel technique-Compressed Adjacency Matrices-for visualizing gene regulatory networks. These directed networks have strong structural characteristics: out-degrees with a scale-free distribution, in-degrees bound by a low maximum, and few and small cycles. Standard visualization techniques, such as node-link diagrams and adjacency matrices, are impeded by these network characteristics. The scale-free distribution of out-degrees causes a high number of intersecting edges in node-link diagrams. Adjacency matrices become space-inefficient due to the low in-degrees and the resulting sparse network. Compressed adjacency matrices, however, exploit these structural characteristics. By cutting open and rearranging an adjacency matrix, we achieve a compact and neatly-arranged visualization. Compressed adjacency matrices allow for easy detection of subnetworks with a specific structure, so-called motifs, which provide important knowledge about gene regulatory networks to domain experts. We summarize motifs commonly referred to in the literature, and relate them to network analysis tasks common to the visualization domain. We show that a user can easily find the important motifs in compressed adjacency matrices, and that this is hard in standard adjacency matrix and node-link diagrams. We also demonstrate that interaction techniques for standard adjacency matrices can be used for our compressed variant. These techniques include rearrangement clustering, highlighting, and filtering.\\\",\\\"Authors\\\":\\\"Dinkla, K.;Westenberg, M.A.;van Wijk, J.J.\\\",\\\"Clusters\\\":\\\"Genetics;GraphNetworkDataAndTechniques;MatrixRelatedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2012.208\\\",\\\"Keywords\\\":\\\"scale-free;adjacency matrix;networks;gene regulation\\\",\\\"Keywords_Processed\\\":\\\"network;scale free;gene regulation;adjacency matrix\\\",\\\"Title\\\":\\\"Compressed Adjacency Matrices: Untangling Gene Regulatory Networks\\\"},\\\"4\\\":{\\\"Abstract\\\":\\\"The visual analysis of dynamic networks is a challenging task. In this paper, we introduce a new approach supporting the discovery of substructures sharing a similar trend over time by combining computation, visualization and interaction. With existing techniques, their discovery would be a tedious endeavor because of the number of nodes, edges as well as time points to be compared. First, on the basis of the supergraph, we therefore group nodes and edges according to their associated attributes that are changing over time. Second, the supergraph is visualized to provide an overview of the groups of nodes and edges with similar behavior over time in terms of their associated attributes. Third, we provide specific interactions to explore and refine the temporal clustering, allowing the user to further steer the analysis of the dynamic network. We demonstrate our approach by the visual analysis of a large wireless mesh network.\\\",\\\"Authors\\\":\\\"Hadlak, S.;Schumann, H.;Cap, C.H.;Wollenberg, T.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;DynamicDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2013.198\\\",\\\"Keywords\\\":\\\"visualization;supergraph clustering;dynamic networks\\\",\\\"Keywords_Processed\\\":\\\"visualization;dynamic network;supergraph clustering\\\",\\\"Title\\\":\\\"Supporting the Visual Analysis of Dynamic Networks by Clustering associated Temporal Attributes\\\"},\\\"5\\\":{\\\"Abstract\\\":\\\"In this paper, we propose a new strategy for graph drawing utilizing layouts of many sub-graphs supplied by a large group of people in a crowd sourcing manner. We developed an algorithm based on Laplacian constrained distance embedding to merge subgraphs submitted by different users, while attempting to maintain the topological information of the individual input layouts. To facilitate collection of layouts from many people, a light-weight interactive system has been designed to enable convenient dynamic viewing, modification and traversing between layouts. Compared with other existing graph layout algorithms, our approach can achieve more aesthetic and meaningful layouts with high user preference.\\\",\\\"Authors\\\":\\\"Xiaoru Yuan;Limei Che;Yifan Hu;Xin Zhang\\\",\\\"Clusters\\\":\\\"DataEditing;DataRegistrationFusionAndIntegration;Engineering;EvaluationGeneral;GraphNetworkDataAndTechniques;MatrixRelatedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2012.236\\\",\\\"Keywords\\\":\\\"merging;stress model;graph layout;laplacian matrix;editing;force-directed layout;crowdsourcing\\\",\\\"Keywords_Processed\\\":\\\"graph layout;laplacian matrix;stress model;merge;edit;force direct layout;crowdsource\\\",\\\"Title\\\":\\\"Intelligent Graph Layout Using Many Users' Input\\\"},\\\"6\\\":{\\\"Abstract\\\":\\\"Sensitivity analysis is a powerful method for discovering the significant factors that contribute to targets and understanding the interaction between variables in multivariate datasets. A number of sensitivity analysis methods fall into the class of local analysis, in which the sensitivity is defined as the partial derivatives of a target variable with respect to a group of independent variables. Incorporating sensitivity analysis in visual analytic tools is essential for multivariate phenomena analysis. However, most current multivariate visualization techniques do not allow users to explore local patterns individually for understanding the sensitivity from a pointwise view. In this paper, we present a novel pointwise local pattern exploration system for visual sensitivity analysis. Using this system, analysts are able to explore local patterns and the sensitivity at individual data points, which reveals the relationships between a focal point and its neighbors. During exploration, users are able to interactively change the derivative coefficients to perform sensitivity analysis based on different requirements as well as their domain knowledge. Each local pattern is assigned an outlier factor, so that users can quickly identify anomalous local patterns that do not conform with the global pattern. Users can also compare the local pattern with the global pattern both visually and statistically. Finally, the local pattern is integrated into the original attribute space using color mapping and jittering, which reveals the distribution of the partial derivatives. Case studies with real datasets are used to investigate the effectiveness of the visualizations and interactions.\\\",\\\"Authors\\\":\\\"Zhenyu Guo;Ward, M.O.;Rundensteiner, E.A.;Ruiz, C.\\\",\\\"Clusters\\\":\\\"KnowledgeDiscovery;UncertaintyTechniquesAndVisualization;VisualPatternFeatureDetectionAndTracking\\\",\\\"DOI\\\":\\\"10.1109/VAST.2011.6102450\\\",\\\"Keywords\\\":\\\"sensitivity analysis;knowledge discovery;local pattern visualizations\\\",\\\"Keywords_Processed\\\":\\\"local pattern visualization;knowledge discovery;sensitivity analysis\\\",\\\"Title\\\":\\\"Pointwise local pattern exploration for sensitivity analysis\\\"},\\\"7\\\":{\\\"Abstract\\\":\\\"A fundamental characteristic of fluid flow is that it causes mixing: introduce a dye into a flow, and it will disperse. Mixing can be used as a method to visualize and characterize flow. Because mixing is a process that occurs over time, it is a 4D problem that presents a challenge for computation, visualization, and analysis. Motivated by a mixing problem in geophysics, we introduce a combination of methods to analyze, transform, and finally visualize mixing in simulations of convection in a self-gravitating 3D spherical shell representing convection in the Earth's mantle. Geophysicists use tools such as the finite element model CitcomS to simulate convection, and introduce massless, passive tracers to model mixing. The output of geophysical flow simulation is hard to analyze for domain experts because of overall data size and complexity. In addition, information overload and occlusion are problems when visualizing a whole-earth model. To address the large size of the data, we rearrange the simulation data using intelligent indexing for fast file access and efficient caching. To address information overload and interpret mixing, we compute tracer concentration statistics, which are used to characterize mixing in mantle convection models. Our visualization uses a specially tailored version of Direct Volume Rendering. The most important adjustment is the use of constant opacity. Because of this special area of application, i. e. the rendering of a spherical shell, many computations for volume rendering can be optimized. These optimizations are essential to a smooth animation of the time-dependent simulation data. Our results show how our system can be used to quickly assess the simulation output and test hypotheses regarding Earth's mantle convection. The integrated processing pipeline helps geoscientists to focus on their main task of analyzing mantle homogenization.\\\",\\\"Authors\\\":\\\"Schroder, S.;Peterson, J.A.;Obermaier, H.;Kellogg, L.H.;Joy, K.I.;Hagen, H.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;EarthSpaceAndEnvironmentalSciences;FlowVisualizationDataAndTechniques;LargeScaleDataAndScalability;PhysicsAndPhysicalSciences\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2012.283\\\",\\\"Keywords\\\":\\\"flow visualization;tracer concentration;earth mantle;convection;large data system;geophysics\\\",\\\"Keywords_Processed\\\":\\\"earth mantle;large datum system;tracer concentration;geophysic;convection;flow visualization\\\",\\\"Title\\\":\\\"Visualization of Flow Behavior in Earth Mantle Convection\\\"},\\\"8\\\":{\\\"Abstract\\\":\\\"In this paper, we present a user study in which we have investigated the influence of seven state-of-the-art volumetric illumination models on the spatial perception of volume rendered images. Within the study, we have compared gradient-based shading with half angle slicing, directional occlusion shading, multidirectional occlusion shading, shadow volume propagation, spherical harmonic lighting as well as dynamic ambient occlusion. To evaluate these models, users had to solve three tasks relying on correct depth as well as size perception. Our motivation for these three tasks was to find relations between the used illumination model, user accuracy and the elapsed time. In an additional task, users had to subjectively judge the output of the tested models. After first reviewing the models and their features, we will introduce the individual tasks and discuss their results. We discovered statistically significant differences in the testing performance of the techniques. Based on these findings, we have analyzed the models and extracted those features which are possibly relevant for the improved spatial comprehension in a relational task. We believe that a combination of these distinctive features could pave the way for a novel illumination model, which would be optimized based on our findings.\\\",\\\"Authors\\\":\\\"Lindemann, F.;Ropinski, T.\\\",\\\"Clusters\\\":\\\"Cognition;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2011.161\\\",\\\"Keywords\\\":\\\"volume illumination;volume rendering;spatial comprehension\\\",\\\"Keywords_Processed\\\":\\\"volume render;volume illumination;spatial comprehension\\\",\\\"Title\\\":\\\"About the Influence of Illumination Models on Image Comprehension in Direct Volume Rendering\\\"},\\\"9\\\":{\\\"Abstract\\\":\\\"For information visualization researchers, eye tracking has been a useful tool to investigate research participants' underlying cognitive processes by tracking their eye movements while they interact with visual techniques. We used an eye tracker to better understand why participants with a variant of a tabular visualization called `SimulSort' outperformed ones with a conventional table and typical one-column sorting feature (i.e., Typical Sorting). The collected eye-tracking data certainly shed light on the detailed cognitive processes of the participants; SimulSort helped with decision-making tasks by promoting efficient browsing behavior and compensatory decision-making strategies. However, more interestingly, we also found unexpected eye-tracking patterns with Simul- Sort. We investigated the cause of the unexpected patterns through a crowdsourcing-based study (i.e., Experiment 2), which elicited an important limitation of the eye tracking method: incapability of capturing peripheral vision. This particular result would be a caveat for other visualization researchers who plan to use an eye tracker in their studies. In addition, the method to use a testing stimulus (i.e., influential column) in Experiment 2 to verify the existence of such limitations would be useful for researchers who would like to verify their eye tracking results.\\\",\\\"Authors\\\":\\\"Sung-Hee Kim;Zhihua Dong;Hanjun Xian;Upatising, B.;Ji Soo Yi\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;Perception;QuantitativeEvaluation;ReasoningProblemSolvingAndDecisionMaking;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2012.215\\\",\\\"Keywords\\\":\\\"visualized decision making;limitations;crowdsourcing;peripheral vision;eye tracking;quantitative empirical study\\\",\\\"Keywords_Processed\\\":\\\"visualize decision making;limitation;quantitative empirical study;eye tracking;peripheral vision;crowdsource\\\",\\\"Title\\\":\\\"Does an Eye Tracker Tell the Truth about Visualizations?: findings while Investigating Visualizations for Decision Making\\\"},\\\"10\\\":{\\\"Abstract\\\":\\\"We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to qua- wing insects.\\\",\\\"Authors\\\":\\\"Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;FlowVisualizationDataAndTechniques;StreamlinesPathlinesStreaklines\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2011.260\\\",\\\"Keywords\\\":\\\"flow visualization;vortex visualization;unsteady flow;streamlines;flowing seed points;streaklines;insect flight\\\",\\\"Keywords_Processed\\\":\\\"flow seed point;streamline;unsteady flow;insect flight;vortex visualization;streakline;flow visualization\\\",\\\"Title\\\":\\\"Vortex Visualization in Ultra Low Reynolds Number Insect Flight\\\"},\\\"11\\\":{\\\"Abstract\\\":\\\"We introduce Visual Sedimentation, a novel design metaphor for visualizing data streams directly inspired by the physical process of sedimentation. Visualizing data streams (e. g., Tweets, RSS, Emails) is challenging as incoming data arrive at unpredictable rates and have to remain readable. For data streams, clearly expressing chronological order while avoiding clutter, and keeping aging data visible, are important. The metaphor is drawn from the real-world sedimentation processes: objects fall due to gravity, and aggregate into strata over time. Inspired by this metaphor, data is visually depicted as falling objects using a force model to land on a surface, aggregating into strata over time. In this paper, we discuss how this metaphor addresses the specific challenge of smoothing the transition between incoming and aging data. We describe the metaphor's design space, a toolkit developed to facilitate its implementation, and example applications to a range of case studies. We then explore the generative capabilities of the design space through our toolkit. We finally illustrate creative extensions of the metaphor when applied to real streams of data.\\\",\\\"Authors\\\":\\\"Huron, S.;Vuillemot, R.;Fekete, J.\\\",\\\"Clusters\\\":\\\"DynamicDataAndTechniques;DynamicVisualizationVisualizationOfChange;RealtimeProcessingRenderingAndVisualizationGeneral;StreamingDataAndTechniques;VisualDesignDesignGuidelines;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2013.227\\\",\\\"Keywords\\\":\\\"information visualization;dynamic data;realtime;data stream;design;metaphors;dynamic visualization\\\",\\\"Keywords_Processed\\\":\\\"realtime;information visualization;dynamic datum;dynamic visualization;datum stream;design;metaphor\\\",\\\"Title\\\":\\\"Visual Sedimentation\\\"},\\\"12\\\":{\\\"Abstract\\\":\\\"Biological pathway maps are highly relevant tools for many tasks in molecular biology. They reduce the complexity of the overall biological network by partitioning it into smaller manageable parts. While this reduction of complexity is their biggest strength, it is, at the same time, their biggest weakness. By removing what is deemed not important for the primary function of the pathway, biologists lose the ability to follow and understand cross-talks between pathways. Considering these cross-talks is, however, critical in many analysis scenarios, such as judging effects of drugs. In this paper we introduce Entourage, a novel visualization technique that provides contextual information lost due to the artificial partitioning of the biological network, but at the same time limits the presented information to what is relevant to the analyst's task. We use one pathway map as the focus of an analysis and allow a larger set of contextual pathways. For these context pathways we only show the contextual subsets, i.e., the parts of the graph that are relevant to a selection. Entourage suggests related pathways based on similarities and highlights parts of a pathway that are interesting in terms of mapped experimental data. We visualize interdependencies between pathways using stubs of visual links, which we found effective yet not obtrusive. By combining this approach with visualization of experimental data, we can provide domain experts with a highly valuable tool. We demonstrate the utility of Entourage with case studies conducted with a biochemist who researches the effects of drugs on pathways. We show that the technique is well suited to investigate interdependencies between pathways and to analyze, understand, and predict the effect that drugs have on different cell types.\\\",\\\"Authors\\\":\\\"Lex, A.;Partl, C.;Kalkofen, D.;Streit, M.;Gratzl, S.;Wassermann, A.M.;Schmalstieg, D.;Pfister, H.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;GraphNetworkDataAndTechniques;MolecularScienceAndChemistry;SetRelatedDataTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2013.154\\\",\\\"Keywords\\\":\\\"pathway visualization;subsets;biomolecular data;graph;biological networks\\\",\\\"Keywords_Processed\\\":\\\"pathway visualization;biological network;graph;subset;biomolecular datum\\\",\\\"Title\\\":\\\"Entourage: Visualizing Relationships between Biological Pathways using Contextual Subsets\\\"},\\\"13\\\":{\\\"Abstract\\\":\\\"In Toponomics, the function protein pattern in cells or tissue (the toponome) is imaged and analyzed for applications in toxicology, new drug development and patient-drug-interaction. The most advanced imaging technique is robot-driven multi-parameter fluorescence microscopy. This technique is capable of co-mapping hundreds of proteins and their distribution and assembly in protein clusters across a cell or tissue sample by running cycles of fluorescence tagging with monoclonal antibodies or other affinity reagents, imaging, and bleaching in situ. The imaging results in complex multi-parameter data composed of one slice or a 3D volume per affinity reagent. Biologists are particularly interested in the localization of co-occurring proteins, the frequency of co-occurrence and the distribution of co-occurring proteins across the cell. We present an interactive visual analysis approach for the evaluation of multi-parameter fluorescence microscopy data in toponomics. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The feature specification result is linked to all views establishing a focus+context visualization in 3D. In a new attribute view, we integrate techniques from graph visualization. Each node in the graph represents an affinity reagent while each edge represents two co-occurring affinity reagent bindings. The graph visualization is enhanced by glyphs which encode specific properties of the binding. The graph view is equipped with brushing facilities. By brushing in the spatial and attribute domain, the biologist achieves a better understanding of the function protein patterns of a cell. Furthermore, an interactive table view is integrated which summarizes unique fluorescence patterns. We discuss our approach with respect to a cell probe containing lymphocytes and a prostate tissue section.\\\",\\\"Authors\\\":\\\"Oeltze, S.;Freiler, W.;Hillert, R.;Doleisch, H.;Preim, B.;Schubert, W.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;GraphNetworkDataAndTechniques;Microscopy;MolecularScienceAndChemistry;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2011.217\\\",\\\"Keywords\\\":\\\"protein interaction;toponomics;fluorescence microscopy;graph visualization;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"fluorescence microscopy;toponomic;visual analytic;protein interaction;graph visualization\\\",\\\"Title\\\":\\\"Interactive, Graph-based Visual Analysis of High-dimensional, Multi-parameter Fluorescence Microscopy Data in Toponomics\\\"},\\\"14\\\":{\\\"Abstract\\\":\\\"We present a GPU-based ray-tracing system for the accurate and interactive visualization of cut-surfaces through 3D simulations of physical processes created from spectral/hp high-order finite element methods. When used by the numerical analyst to debug the solver, the ability for the imagery to precisely reflect the data is critical. In practice, the investigator interactively selects from a palette of visualization tools to construct a scene that can answer a query of the data. This is effective as long as the implicit contract of image quality between the individual and the visualization system is upheld. OpenGL rendering of scientific visualizations has worked remarkably well for exploratory visualization for most solver results. This is due to the consistency between the use of first-order representations in the simulation and the linear assumptions inherent in OpenGL (planar fragments and color-space interpolation). Unfortunately, the contract is broken when the solver discretization is of higher-order. There have been attempts to mitigate this through the use of spatial adaptation and/or texture mapping. These methods do a better job of approximating what the imagery should be but are not exact and tend to be view-dependent. This paper introduces new rendering mechanisms that specifically deal with the kinds of native data generated by high-order finite element solvers. The exploratory visualization tools are reassessed and cast in this system with the focus on image accuracy. This is accomplished in a GPU setting to ensure interactivity.\\\",\\\"Authors\\\":\\\"Nelson, B.;Haimes, R.;Kirby, R.M.\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;IsosurfaceAndSurfaceExtractionTechniques;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2011.206\\\",\\\"Keywords\\\":\\\"gpu raytracing;high-order finite elements;gpu-based root-finding;cut-surface extraction;spectral/hp elements;cut-plane extraction\\\",\\\"Keywords_Processed\\\":\\\"spectral hp element;gpu base root finding;cut plane extraction;high order finite element;gpu raytracing;cut surface extraction\\\",\\\"Title\\\":\\\"GPU-Based Interactive Cut-Surface Extraction From High-Order finite Element fields\\\"},\\\"15\\\":{\\\"Abstract\\\":\\\"We present a quasi interpolation framework that attains the optimal approximation-order of Voronoi splines for reconstruction of volumetric data sampled on general lattices. The quasi interpolation framework of Voronoi splines provides an unbiased reconstruction method across various lattices. Therefore this framework allows us to analyze and contrast the sampling-theoretic performance of general lattices, using signal reconstruction, in an unbiased manner. Our quasi interpolation methodology is implemented as an efficient FIR filter that can be applied online or as a preprocessing step. We present visual and numerical experiments that demonstrate the improved accuracy of reconstruction across lattices, using the quasi interpolation framework.\\\",\\\"Authors\\\":\\\"Mirzargar, M.;Entezari, A.\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;Interpolation;VolumeRenderingModelingAndVisualization;VoronoiBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2011.230\\\",\\\"Keywords\\\":\\\"quasi interpolation;volume visualization;box spline;voronoi spline\\\",\\\"Keywords_Processed\\\":\\\"box spline;voronoi spline;quasi interpolation;volume visualization\\\",\\\"Title\\\":\\\"Quasi Interpolation With Voronoi Splines\\\"},\\\"16\\\":{\\\"Abstract\\\":\\\"The aspect ratio of a plot has a dramatic impact on our ability to perceive trends and patterns in the data. Previous approaches for automatically selecting the aspect ratio have been based on adjusting the orientations or angles of the line segments in the plot. In contrast, we recommend a simple, effective method for selecting the aspect ratio: minimize the arc length of the data curve while keeping the area of the plot constant. The approach is parameterization invariant, robust to a wide range of inputs, preserves visual symmetries in the data, and is a compromise between previously proposed techniques. Further, we demonstrate that it can be effectively used to select the aspect ratio of contour plots. We believe arc length should become the default aspect ratio selection method.\\\",\\\"Authors\\\":\\\"Talbot, J.;Gerth, J.;Hanrahan, P.\\\",\\\"Clusters\\\":\\\"VectorFieldsDataAndTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2011.167\\\",\\\"Keywords\\\":\\\"orientation resolution;aspect ratio selection;banking to 45 degrees\\\",\\\"Keywords_Processed\\\":\\\"orientation resolution;banking to 45 degree;aspect ratio selection\\\",\\\"Title\\\":\\\"Arc Length-Based Aspect Ratio Selection\\\"},\\\"17\\\":{\\\"Abstract\\\":\\\"We present a visual analytics solution designed to address prevalent issues in the area of Operational Decision Management (ODM). In ODM, which has its roots in Artificial Intelligence (Expert Systems) and Management Science, it is increasingly important to align business decisions with business goals. In our work, we consider decision models (executable models of the business domain) as ontologies that describe the business domain, and production rules that describe the business logic of decisions to be made over this ontology. Executing a decision model produces an accumulation of decisions made over time for individual cases. We are interested, first, to get insight in the decision logic and the accumulated facts by themselves. Secondly and more importantly, we want to see how the accumulated facts reveal potential divergences between the reality as captured by the decision model, and the reality as captured by the executed decisions. We illustrate the motivation, added value for visual analytics, and our proposed solution and tooling through a business case from the car insurance industry.\\\",\\\"Authors\\\":\\\"Broeksema, B.;Baudel, T.;Telea, A.;Crisafulli, P.\\\",\\\"Clusters\\\":\\\"MachineLearningAndStatistics;SoftwareVisualization;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2013.146\\\",\\\"Keywords\\\":\\\"program analysis;decision support systems;model validation and analysis;multivariate statistics\\\",\\\"Keywords_Processed\\\":\\\"decision support system;multivariate statistic;model validation and analysis;program analysis\\\",\\\"Title\\\":\\\"Decision Exploration Lab: A Visual Analytics Solution for Decision Management\\\"},\\\"18\\\":{\\\"Abstract\\\":\\\"Network data often contain important attributes from various dimensions such as social affiliations and areas of expertise in a social network. If such attributes exhibit a tree structure, visualizing a compound graph consisting of tree and network structures becomes complicated. How to visually reveal patterns of a network over a tree has not been fully studied. In this paper, we propose a compound graph model, TreeNet, to support visualization and analysis of a network at multiple levels of aggregation over a tree. We also present a visualization design, TreeNetViz, to offer the multiscale and cross-scale exploration and interaction of a TreeNet graph. TreeNetViz uses a Radial, Space-Filling (RSF) visualization to represent the tree structure, a circle layout with novel optimization to show aggregated networks derived from TreeNet, and an edge bundling technique to reduce visual complexity. Our circular layout algorithm reduces both total edge-crossings and edge length and also considers hierarchical structure constraints and edge weight in a TreeNet graph. These experiments illustrate that the algorithm can reduce visual cluttering in TreeNet graphs. Our case study also shows that TreeNetViz has the potential to support the analysis of a compound graph by revealing multiscale and cross-scale network patterns.\\\",\\\"Authors\\\":\\\"Liang Gou;Xiaolong Zhang\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;MultiScaleDataTechniques;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2011.247\\\",\\\"Keywords\\\":\\\"network and tree;multi-scale and cross-scale;visualization;treenetviz;compound graphs\\\",\\\"Keywords_Processed\\\":\\\"visualization;treenetviz;network and tree;multi scale and cross scale;compound graph\\\",\\\"Title\\\":\\\"TreeNetViz: Revealing Patterns of Networks over Tree Structures\\\"},\\\"19\\\":{\\\"Abstract\\\":\\\"For preserving the grotto wall paintings and protecting these historic cultural icons from the damage and deterioration in nature environment, a visual analytics framework and a set of tools are proposed for the discovery of degradation patterns. In comparison with the traditional analysis methods that used restricted scales, our method provides users with multi-scale analytic support to study the problems on site, cave, wall and particular degradation area scales, through the application of multidimensional visualization techniques. Several case studies have been carried out using real-world wall painting data collected from a renowned World Heritage site, to verify the usability and effectiveness of the proposed method. User studies and expert reviews were also conducted through by domain experts ranging from scientists such as microenvironment researchers, archivists, geologists, chemists, to practitioners such as conservators, restorers and curators.\\\",\\\"Authors\\\":\\\"Jiawan Zhang;Kai Kang;Dajian Liu;Ye Yuan;Yanli, E.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;ArtAndAestheticsInVisualization;SocialScienceAndHumanities;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2013.219\\\",\\\"Keywords\\\":\\\"wall paintings;cultural heritage;visual analytics;degradation\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;cultural heritage;wall painting;degradation\\\",\\\"Title\\\":\\\"Vis4Heritage: Visual Analytics Approach on Grotto Wall Painting Degradations\\\"},\\\"20\\\":{\\\"Abstract\\\":\\\"As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them.\\\",\\\"Authors\\\":\\\"Ferreira, N.;Poco, J.;Vo, H.T.;Freire, J.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;ApplicationsGeneralAndOther;QueriesAndSearch;Traffic\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2013.226\\\",\\\"Keywords\\\":\\\"urban data;spatio-temporal queries;visual exploration;taxi movement data\\\",\\\"Keywords_Processed\\\":\\\"spatio temporal query;taxi movement datum;urban datum;visual exploration\\\",\\\"Title\\\":\\\"Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips\\\"},\\\"21\\\":{\\\"Abstract\\\":\\\"Contingency tables summarize the relations between categorical variables and arise in both scientific and business domains. Asymmetrically large two-way contingency tables pose a problem for common visualization methods. The Contingency Wheel has been recently proposed as an interactive visual method to explore and analyze such tables. However, the scalability and readability of this method are limited when dealing with large and dense tables. In this paper we present Contingency Wheel++, new visual analytics methods that overcome these major shortcomings: (1) regarding automated methods, a measure of association based on Pearson's residuals alleviates the bias of the raw residuals originally used, (2) regarding visualization methods, a frequency-based abstraction of the visual elements eliminates overlapping and makes analyzing both positive and negative associations possible, and (3) regarding the interactive exploration environment, a multi-level overview+detail interface enables exploring individual data items that are aggregated in the visualization or in the table using coordinated views. We illustrate the applicability of these new methods with a use case and show how they enable discovering and analyzing nontrivial patterns and associations in large categorical data.\\\",\\\"Authors\\\":\\\"Alsallakh, B.;Aigner, W.;Miksch, S.;Groller, E.\\\",\\\"Clusters\\\":\\\"LargeScaleDataAndScalability;TabularDataAndTechniques;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2012.254\\\",\\\"Keywords\\\":\\\"information interfaces and presentation;contingency table analysis;large categorical data;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"contingency table analysis;visual analytic;information interface and presentation;large categorical datum\\\",\\\"Title\\\":\\\"Reinventing the Contingency Wheel: Scalable Visual Analytics of Large Categorical Data\\\"},\\\"22\\\":{\\\"Abstract\\\":\\\"How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.\\\",\\\"Authors\\\":\\\"Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;DiffusionRelatedTechniques;InformationProcessingAndHandling;SocialNetworksAndSocialMedia;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2013.221\\\",\\\"Keywords\\\":\\\"information propagation;agenda-setting;topic competition;social media visualization;information diffusion\\\",\\\"Keywords_Processed\\\":\\\"information diffusion;social medium visualization;information propagation;agenda setting;topic competition\\\",\\\"Title\\\":\\\"Visual Analysis of Topic Competition on Social Media\\\"},\\\"23\\\":{\\\"Abstract\\\":\\\"The study of complex activities such as scientific production and software development often require modeling connections among heterogeneous entities including people, institutions and artifacts. Despite numerous advances in algorithms and visualization techniques for understanding such social networks, the process of constructing network models and performing exploratory analysis remains difficult and time-consuming. In this paper we present Orion, a system for interactive modeling, transformation and visualization of network data. Orion's interface enables the rapid manipulation of large graphs-including the specification of complex linking relationships-using simple drag-and-drop operations with desired node types. Orion maps these user interactions to statements in a declarative workflow language that incorporates both relational operators (e.g., selection, aggregation and joins) and network analytics (e.g., centrality measures). We demonstrate how these features enable analysts to flexibly construct and compare networks in domains such as online health communities, academic collaboration and distributed software development.\\\",\\\"Authors\\\":\\\"Heer, J.;Perer, A.\\\",\\\"Clusters\\\":\\\"DataAcquisitionAndManagement;DataTransformation;GraphNetworkDataAndTechniques;ProgrammingAlgorithmsAndDataStructures;SocialNetworksAndSocialMedia;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2011.6102441\\\",\\\"Keywords\\\":\\\"visualization;social network analysis;graph;data management;data transformation;end-user programming\\\",\\\"Keywords_Processed\\\":\\\"visualization;end user programming;datum transformation;graph;social network analysis;data management\\\",\\\"Title\\\":\\\"Orion: A system for modeling, transformation and visualization of multidimensional heterogeneous networks\\\"},\\\"24\\\":{\\\"Abstract\\\":\\\"This paper introduces a new feature analysis and visualization method for multifield datasets. Our approach applies a surface-centric model to characterize salient features and form an effective, schematic representation of the data. We propose a simple, geometrically motivated, multifield feature definition. This definition relies on an iterative algorithm that applies existing theory of skeleton derivation to fuse the structures from the constitutive fields into a coherent data description, while addressing noise and spurious details. This paper also presents a new method for non-rigid surface registration between the surfaces of consecutive time steps. This matching is used in conjunction with clustering to discover the interaction patterns between the different fields and their evolution over time. We document the unified visual analysis achieved by our method in the context of several multifield problems from large-scale time-varying simulations.\\\",\\\"Authors\\\":\\\"Barakat, S.S.;Rutten, M.;Tricoche, X.\\\",\\\"Clusters\\\":\\\"MultidimensionalMultivariateMultifieldDataAndTechniques;SurfaceRelatedDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2012.269\\\",\\\"Keywords\\\":\\\"time-varying;surface structures;multi-field\\\",\\\"Keywords_Processed\\\":\\\"surface structure;time vary;multi field\\\",\\\"Title\\\":\\\"Surface-Based Structure Analysis and Visualization for Multifield Time-Varying Datasets\\\"},\\\"25\\\":{\\\"Abstract\\\":\\\"An alternative form to multidimensional projections for the visual analysis of data represented in multidimensional spaces is the deployment of similarity trees, such as Neighbor Joining trees. They organize data objects on the visual plane emphasizing their levels of similarity with high capability of detecting and separating groups and subgroups of objects. Besides this similarity-based hierarchical data organization, some of their advantages include the ability to decrease point clutter; high precision; and a consistent view of the data set during focusing, offering a very intuitive way to view the general structure of the data set as well as to drill down to groups and subgroups of interest. Disadvantages of similarity trees based on neighbor joining strategies include their computational cost and the presence of virtual nodes that utilize too much of the visual space. This paper presents a highly improved version of the similarity tree technique. The improvements in the technique are given by two procedures. The first is a strategy that replaces virtual nodes by promoting real leaf nodes to their place, saving large portions of space in the display and maintaining the expressiveness and precision of the technique. The second improvement is an implementation that significantly accelerates the algorithm, impacting its use for larger data sets. We also illustrate the applicability of the technique in visual data mining, showing its advantages to support visual classification of data sets, with special attention to the case of image classification. We demonstrate the capabilities of the tree for analysis and iterative manipulation and employ those capabilities to support evolving to a satisfactory data organization and classification.\\\",\\\"Authors\\\":\\\"Paiva, J.G.;Florian, L.;Pedrini, H.;Telles, G.P.;Minghim, R.\\\",\\\"Clusters\\\":\\\"DimensionalityReduction;HierarchicalTreeDataAndTechniques;SegmentationAndClassification\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2011.212\\\",\\\"Keywords\\\":\\\"image classification;multi-dimensional projection;similarity trees\\\",\\\"Keywords_Processed\\\":\\\"multi dimensional projection;image classification;similarity tree\\\",\\\"Title\\\":\\\"Improved Similarity Trees and their Application to Visual Data Classification\\\"},\\\"26\\\":{\\\"Abstract\\\":\\\"Geoscientific modeling and simulation helps to improve our understanding of the complex Earth system. During the modeling process, validation of the geoscientific model is an essential step. In validation, it is determined whether the model output shows sufficient agreement with observation data. Measures for this agreement are called goodness of fit. In the geosciences, analyzing the goodness of fit is challenging due to its manifold dependencies: 1) The goodness of fit depends on the model parameterization, whose precise values are not known. 2) The goodness of fit varies in space and time due to the spatio-temporal dimension of geoscientific models. 3) The significance of the goodness of fit is affected by resolution and preciseness of available observational data. 4) The correlation between goodness of fit and underlying modeled and observed values is ambiguous. In this paper, we introduce a visual analysis concept that targets these challenges in the validation of geoscientific models - specifically focusing on applications where observation data is sparse, unevenly distributed in space and time, and imprecise, which hinders a rigorous analytical approach. Our concept, developed in close cooperation with Earth system modelers, addresses the four challenges by four tailored visualization components. The tight linking of these components supports a twofold interactive drill-down in model parameter space and in the set of data samples, which facilitates the exploration of the numerous dependencies of the goodness of fit. We exemplify our visualization concept for geoscientific modeling of glacial isostatic adjustments in the last 100,000 years, validated against sea levels indicators - a prominent example for sparse and imprecise observation data. An initial use case and feedback from Earth system modelers indicate that our visualization concept is a valuable complement to the range of validation methods.\\\",\\\"Authors\\\":\\\"Unger, A.;Schulte, S.;Klemann, V.;Dransch, D.\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;MachineLearningAndStatistics;MultipleLinkedCoordinatedViews;SpatiotemporalDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2012.190\\\",\\\"Keywords\\\":\\\"spatio-temporal visualization;earth science visualization;model validation;sea level indicators;coordinated & multiple views\\\",\\\"Keywords_Processed\\\":\\\"spatio temporal visualization;earth science visualization;model validation;sea level indicator;coordinate multiple view\\\",\\\"Title\\\":\\\"A Visual Analysis Concept for the Validation of Geoscientific Simulation Models\\\"},\\\"27\\\":{\\\"Abstract\\\":\\\"Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop's main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.\\\",\\\"Authors\\\":\\\"Lins, L.;Klosowski, J.T.;Scheidegger, C.E.\\\",\\\"Clusters\\\":\\\"DataTypesGeneral;InteractionTechniquesGeneral;ProgrammingAlgorithmsAndDataStructures\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2013.179\\\",\\\"Keywords\\\":\\\"data cube;interactive exploration;data structures\\\",\\\"Keywords_Processed\\\":\\\"interactive exploration;data cube;data structure\\\",\\\"Title\\\":\\\"Nanocubes for Real-Time Exploration of Spatiotemporal Datasets\\\"},\\\"28\\\":{\\\"Abstract\\\":\\\"Geographically-grounded situational awareness (SA) is critical to crisis management and is essential in many other decision making domains that range from infectious disease monitoring, through regional planning, to political campaigning. Social media are becoming an important information input to support situational assessment (to produce awareness) in all domains. Here, we present a geovisual analytics approach to supporting SA for crisis events using one source of social media, Twitter. Specifically, we focus on leveraging explicit and implicit geographic information for tweets, on developing place-time-theme indexing schemes that support overview+detail methods and that scale analytical capabilities to relatively large tweet volumes, and on providing visual interface methods to enable understanding of place, time, and theme components of evolving situations. Our approach is user-centered, using scenario-based design methods that include formal scenarios to guide design and validate implementation as well as a systematic claims analysis to justify design choices and provide a framework for future testing. The work is informed by a structured survey of practitioners and the end product of Phase-I development is demonstrated / validated through implementation in SensePlace2, a map-based, web application initially focused on tweets but extensible to other media.\\\",\\\"Authors\\\":\\\"MacEachren, A.M.;Jaiswal, A.;Robinson, A.;Pezanowski, S.;Savelyev, A.;Mitra, P.;Zhang, X.;Blanford, J.\\\",\\\"Clusters\\\":\\\"Cognition;DesignMethodologiesAndInteractionDesign;EmergencyDisasterManagement;GeographyGeospatialVisCartographyTerrainVis;SocialNetworksAndSocialMedia;SpatiotemporalDataAndTechniques;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2011.6102456\\\",\\\"Keywords\\\":\\\"crisis management;text analytics;social media analytics;situation awareness;spatio-temporal analysis;scenario-based design;geovisualization\\\",\\\"Keywords_Processed\\\":\\\"scenario base design;spatio temporal analysis;geovisualization;situation awareness;crisis management;text analytic;social medium analytic\\\",\\\"Title\\\":\\\"SensePlace2: GeoTwitter analytics support for situational awareness\\\"},\\\"29\\\":{\\\"Abstract\\\":\\\"As the visualization field matures, an increasing number of general toolkits are developed to cover a broad range of applications. However, no general tool can incorporate the latest capabilities for all possible applications, nor can the user interfaces and workflows be easily adjusted to accommodate all user communities. As a result, users will often chose either substandard solutions presented in familiar, customized tools or assemble a patchwork of individual applications glued through ad-hoc scripts and extensive, manual intervention. Instead, we need the ability to easily and rapidly assemble the best-in-task tools into custom interfaces and workflows to optimally serve any given application community. Unfortunately, creating such meta-applications at the API or SDK level is difficult, time consuming, and often infeasible due to the sheer variety of data models, design philosophies, limits in functionality, and the use of closed commercial systems. In this paper, we present the ManyVis framework which enables custom solutions to be built both rapidly and simply by allowing coordination and communication across existing unrelated applications. ManyVis allows users to combine software tools with complementary characteristics into one virtual application driven by a single, custom-designed interface.\\\",\\\"Authors\\\":\\\"Rungta, A.;Summa, B.;Demir, D.;Bremer, P.-T.;Pascucci, V.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;MultipleLinkedCoordinatedViews;ProgrammingAlgorithmsAndDataStructures;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2013.174\\\",\\\"Keywords\\\":\\\"integrated applications;linked views;visualization environment;macros\\\",\\\"Keywords_Processed\\\":\\\"macro;link view;integrate application;visualization environment\\\",\\\"Title\\\":\\\"ManyVis: Multiple Applications in an Integrated Visualization Environment\\\"},\\\"30\\\":{\\\"Abstract\\\":\\\"Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.\\\",\\\"Authors\\\":\\\"Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.;Griffiths, I.W.;Chen, M.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;KnowledgeDiscovery;MachineLearningAndStatistics;MultimediaImageVideoMusic\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2013.207\\\",\\\"Keywords\\\":\\\"multimedia visualization;visual knowledge discovery;data clustering;machine learning\\\",\\\"Keywords_Processed\\\":\\\"machine learning;multimedia visualization;visual knowledge discovery;datum clustering\\\",\\\"Title\\\":\\\"Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop\\\"},\\\"31\\\":{\\\"Abstract\\\":\\\"Traditional layered graph depictions such as flow charts are in wide use. Yet as graphs grow more complex, these depictions can become difficult to understand. Quilts are matrix-based depictions for layered graphs designed to address this problem. In this research, we first improve Quilts by developing three design alternatives, and then compare the best of these alternatives to better-known node-link and matrix depictions. A primary weakness in Quilts is their depiction of skip links, links that do not simply connect to a succeeding layer. Therefore in our first study, we compare Quilts using color-only, text-only, and mixed (color and text) skip link depictions, finding that path finding with the color-only depiction is significantly slower and less accurate, and that in certain cases, the mixed depiction offers an advantage over the text-only depiction. In our second study, we compare Quilts using the mixed depiction to node-link diagrams and centered matrices. Overall results show that users can find paths through graphs significantly faster with Quilts (46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams. This speed advantage is still greater in large graphs (e.g. in 200 node graphs, 55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).\\\",\\\"Authors\\\":\\\"Juhee Bae;Watson, B.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;MatrixRelatedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2011.187\\\",\\\"Keywords\\\":\\\"matrix-based depiction;graph drawing;layered graphs;node-link diagram\\\",\\\"Keywords_Processed\\\":\\\"graph drawing;matrix base depiction;layer graph;node link diagram\\\",\\\"Title\\\":\\\"Developing and Evaluating Quilts for the Depiction of Large Layered Graphs\\\"},\\\"32\\\":{\\\"Abstract\\\":\\\"Room air flow and air exchange are important aspects for the design of energy-efficient buildings. As a result, simulations are increasingly used prior to construction to achieve an energy-efficient design. We present a visual analysis of air flow generated at building entrances, which uses a combination of revolving doors and air curtains. The resulting flow pattern is challenging because of two interacting flow patterns: On the one hand, the revolving door acts as a pump, on the other hand, the air curtain creates a layer of uniformly moving warm air between the interior of the building and the revolving door. Lagrangian coherent structures (LCS), which by definition are flow barriers, are the method of choice for visualizing the separation and recirculation behavior of warm and cold air flow. The extraction of LCS is based on the finite-time Lyapunov exponent (FTLE) and makes use of a ridge definition which is consistent with the concept of weak LCS. Both FTLE computation and ridge extraction are done in a robust and efficient way by making use of the fast Fourier transform for computing scale-space derivatives.\\\",\\\"Authors\\\":\\\"Schindler, B.;Fuchs, R.;Barp, S.;Waser, J.;Pobitzer, A.;Carnecky, R.;Matkovic, K.;Peikert, R.\\\",\\\"Clusters\\\":\\\"PhysicsAndPhysicalSciences;TopologyBasedTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2012.243\\\",\\\"Keywords\\\":\\\"visualization in physical sciences and engineering;topology-based techniques;vector field data\\\",\\\"Keywords_Processed\\\":\\\"topology base technique;visualization in physical science and engineering;vector field datum\\\",\\\"Title\\\":\\\"Lagrangian Coherent Structures for Design Analysis of Revolving Doors\\\"},\\\"33\\\":{\\\"Abstract\\\":\\\"Analyzing either high-frequency shape detail or any other 2D fields (scalar or vector) embedded over a 3D geometry is a complex task, since detaching the detail from the overall shape can be tricky. An alternative approach is to move to the 2D space, resolving shape reasoning to easier image processing techniques. In this paper we propose a novel framework for the analysis of 2D information distributed over 3D geometry, based on a locally smooth parametrization technique that allows us to treat local 3D data in terms of image content. The proposed approach has been implemented as a sketch-based system that allows to design with a few gestures a set of (possibly overlapping) parameterizations of rectangular portions of the surface. We demonstrate that, due to the locality of the parametrization, the distortion is under an acceptable threshold, while discontinuities can be avoided since the parametrized geometry is always homeomorphic to a disk. We show the effectiveness of the proposed technique to solve specific Cultural Heritage (CH) tasks: the analysis of chisel marks over the surface of a unfinished sculpture and the local comparison of multiple photographs mapped over the surface of an artwork. For this very difficult task, we believe that our framework and the corresponding tool are the first steps toward a computer-based shape reasoning system, able to support CH scholars with a medium they are more used to.\\\",\\\"Authors\\\":\\\"Pietroni, N.;Massimiliano, C.;Cignoni, P.;Scopigno, R.\\\",\\\"Clusters\\\":\\\"ImageBasedDataImageSignalProcessing;InteractionTechniquesGeneral;Parameterization;SocialScienceAndHumanities;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2011.165\\\",\\\"Keywords\\\":\\\"interactive inspection;surface characterization;image processing;cultural heritage;mesh parameterization\\\",\\\"Keywords_Processed\\\":\\\"image processing;cultural heritage;surface characterization;mesh parameterization;interactive inspection\\\",\\\"Title\\\":\\\"An Interactive Local Flattening Operator to Support Digital Investigations on Artwork Surfaces\\\"},\\\"34\\\":{\\\"Abstract\\\":\\\"This paper presents a visualization approach for detecting and exploring similarity in the temporal variation of field data. We provide an interactive technique for extracting correlations from similarity matrices which capture temporal similarity of univariate functions. We make use of the concept to extract periodic and quasiperiodic behavior at single (spatial) points as well as similarity between different locations within a field and also between different data sets. The obtained correlations are utilized for visual exploration of both temporal and spatial relationships in terms of temporal similarity. Our entire pipeline offers visual interaction and inspection, allowing for the flexibility that in particular time-dependent data analysis techniques require. We demonstrate the utility and versatility of our approach by applying our implementation to data from both simulation and measurement.\\\",\\\"Authors\\\":\\\"Frey, S.;Sadlo, F.;Ertl, T.\\\",\\\"Clusters\\\":\\\"ComparisonComparativeVisualizationAndSimilarity;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2012.284\\\",\\\"Keywords\\\":\\\"comparative visualization;time-dependent fields;similarity analysis;interactive recurrence analysis\\\",\\\"Keywords_Processed\\\":\\\"time dependent field;similarity analysis;comparative visualization;interactive recurrence analysis\\\",\\\"Title\\\":\\\"Visualization of Temporal Similarity in field Data\\\"},\\\"35\\\":{\\\"Abstract\\\":\\\"Color mapping and semitransparent layering play an important role in many visualization scenarios, such as information visualization and volume rendering. The combination of color and transparency is still dominated by standard alpha-compositing using the Porter-Duff over operator which can result in false colors with deceiving impact on the visualization. Other more advanced methods have also been proposed, but the problem is still far from being solved. Here we present an alternative to these existing methods specifically devised to avoid false colors and preserve visual depth ordering. Our approach is data driven and follows the recently formulated knowledge-assisted visualization (KAV) paradigm. Preference data, that have been gathered in web-based user surveys, are used to train a support-vector machine model for automatically predicting an optimized hue-preserving blending. We have applied the resulting model to both volume rendering and a specific information visualization technique, illustrative parallel coordinate plots. Comparative renderings show a significant improvement over previous approaches in the sense that false colors are completely removed and important properties such as depth ordering and blending vividness are better preserved. Due to the generality of the defined data-driven blending operator, it can be easily integrated also into other visualization frameworks.\\\",\\\"Authors\\\":\\\"Kuhne, L.;Giesen, J.;Zhiyuan Zhang;Sungsoo Ha;Mueller, K.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;ParallelCoordinates;VisualizationTechniquesAndToolsGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2012.186\\\",\\\"Keywords\\\":\\\"knowledge-assisted visualization;volume rendering;color blending;hue preservation;parallel coordinates\\\",\\\"Keywords_Processed\\\":\\\"volume render;parallel coordinate;knowledge assist visualization;color blending;hue preservation\\\",\\\"Title\\\":\\\"A Data-Driven Approach to Hue-Preserving Color-Blending\\\"},\\\"36\\\":{\\\"Abstract\\\":\\\"Presenting and communicating insights to an audience-telling a story-is one of the main goals of data exploration. Even though visualization as a storytelling medium has recently begun to gain attention, storytelling is still underexplored in information visualization and little research has been done to help people tell their stories with data. To create a new, more engaging form of storytelling with data, we leverage and extend the narrative storytelling attributes of whiteboard animation with pen and touch interactions. We present SketchStory, a data-enabled digital whiteboard that facilitates the creation of personalized and expressive data charts quickly and easily. SketchStory recognizes a small set of sketch gestures for chart invocation, and automatically completes charts by synthesizing the visuals from the presenter-provided example icon and binding them to the underlying data. Furthermore, SketchStory allows the presenter to move and resize the completed data charts with touch, and filter the underlying data to facilitate interactive exploration. We conducted a controlled experiment for both audiences and presenters to compare SketchStory with a traditional presentation system, Microsoft PowerPoint. Results show that the audience is more engaged by presentations done with SketchStory than PowerPoint. Eighteen out of 24 audience participants preferred SketchStory to PowerPoint. Four out of five presenter participants also favored SketchStory despite the extra effort required for presentation.\\\",\\\"Authors\\\":\\\"Bongshin Lee;Kazi, R.H.;Smith, G.\\\",\\\"Clusters\\\":\\\"InteractionTechniquesGeneral;Storytelling;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2013.191\\\",\\\"Keywords\\\":\\\"data presentation;sketch;visualization;pen and touch;storytelling;interaction\\\",\\\"Keywords_Processed\\\":\\\"visualization;interaction;pen and touch;storytelle;sketch;datum presentation\\\",\\\"Title\\\":\\\"SketchStory: Telling More Engaging Stories with Data through Freeform Sketching\\\"},\\\"37\\\":{\\\"Abstract\\\":\\\"We introduce the concept of just-in-time descriptive analytics as a novel application of computational and statistical techniques performed at interaction-time to help users easily understand the structure of data as seen in visualizations. Fundamental to just-intime descriptive analytics is (a) identifying visual features, such as clusters, outliers, and trends, user might observe in visualizations automatically, (b) determining the semantics of such features by performing statistical analysis as the user is interacting, and (c) enriching visualizations with annotations that not only describe semantics of visual features but also facilitate interaction to support high-level understanding of data. In this paper, we demonstrate just-in-time descriptive analytics applied to a point-based multi-dimensional visualization technique to identify and describe clusters, outliers, and trends. We argue that it provides a novel user experience of computational techniques working alongside of users allowing them to build faster qualitative mental models of data by demonstrating its application on a few use-cases. Techniques used to facilitate just-in-time descriptive analytics are described in detail along with their runtime performance characteristics. We believe this is just a starting point and much remains to be researched, as we discuss open issues and opportunities in improving accessibility and collaboration.\\\",\\\"Authors\\\":\\\"Kandogan, E.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;AnalysisProcessGeneral;PointBasedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2012.6400487\\\",\\\"Keywords\\\":\\\"feature identification and characterization;point-based visualization;just-in-time descriptive analytics\\\",\\\"Keywords_Processed\\\":\\\"feature identification and characterization;just in time descriptive analytic;point base visualization\\\",\\\"Title\\\":\\\"Just-in-time annotation of clusters, outliers, and trends in point-based data visualizations\\\"}}\");//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoiLi9kYXRhc2V0cy9uZXdfZGF0YS5qc29uLmpzIiwic291cmNlcyI6W10sIm1hcHBpbmdzIjoiIiwic291cmNlUm9vdCI6IiJ9\n//# sourceURL=webpack-internal:///./datasets/new_data.json\n");

/***/ }),

/***/ "./datasets/old_data.json":
/*!********************************!*\
  !*** ./datasets/old_data.json ***!
  \********************************/
/*! exports provided: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, default */
/***/ (function(module) {

eval("module.exports = JSON.parse(\"{\\\"0\\\":{\\\"abstract\\\":\\\"we propose an interpolating refinement method for two- and three-dimensional scalar fields defined on hexahedral grids. Iterative fairing of the underlying contours (isosurfaces) provides the function values of new grid points. Our method can be considered as a nonlinear variational subdivision scheme for volumes. It can be applied locally for adaptive mesh refinement in regions of high geometric complexity. We use our scheme to increase the quality of low-resolution data sets and to reduce interpolation artifacts in texture-based volume rendering.\\\",\\\"Authors\\\":\\\"Bertram, M.\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;GeometricModeling;IsosurfaceAndSurfaceExtractionTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.127\\\",\\\"Keywords\\\":\\\"subdivision;variational modeling;isosurface;adaptive mesh refinement;volume fairing\\\",\\\"Keywords_Processed\\\":\\\"adaptive mesh refinement;variational modeling;isosurface;volume fair;subdivision\\\",\\\"Title\\\":\\\"Volume refinement fairing isosurfaces\\\"},\\\"1\\\":{\\\"Abstract\\\":\\\"Vorticity is the quantity used to describe the creation, transformation and extinction of vortices. It is present not only in vortices but also in shear flow. Especially in ducted flows, most of the overall vorticity is usually contained in the boundary layer. When a vortex develops from the boundary layer, this can be described by transport of vorticity. For a better understanding of a flow it is therefore of interest to examine vorticity in all of its different roles. The goal of this application study was not primarily the visualization of vortices but of vorticity distribution and its role in vortex phenomena. The underlying industrial case is a design optimization for a Pelton turbine. An important industrial objective is to improve the quality of the water jets driving the runner. Jet quality is affected mostly by vortices originating in the distributor ring. For a better understanding of this interrelation, it is crucial to not only visualize these vortices but also to analyze the mechanisms of their creation. We used various techniques for the visualization of vorticity, including field lines and modified isosurfaces. For field line based visualization, we extended the image-guided streamline placement algorithm of Turk and Banks to data-guided field line placement on three-dimensional unstructured grids.\\\",\\\"Authors\\\":\\\"Sadlo, F.;Peikert, R.;Parkinson, E.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;LineBasedTechniquesAndApproaches\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.128\\\",\\\"Keywords\\\":\\\"flow visualization;feature extraction;line placement\\\",\\\"Keywords_Processed\\\":\\\"line placement;feature extraction;flow visualization\\\",\\\"Title\\\":\\\"Vorticity based flow analysis and visualization for Pelton turbine design optimization\\\"},\\\"2\\\":{\\\"Abstract\\\":\\\"We present a hardware-accelerated method for visualizing 3D flow fields. The method is based on insertion, advection, and decay of dye. To this aim, we extend the texture-based IBFV technique presented by van Wijk (2001) for 2D flow visualization in two main directions. First, we decompose the 3D flow visualization problem in a series of 2D instances of the mentioned IBFV technique. This makes our method benefit from the hardware acceleration the original IBFV technique introduced. Secondly, we extend the concept of advected gray value (or color) noise by introducing opacity (or matter) noise. This allows us to produce sparse 3D noise pattern advections, thus address the occlusion problem inherent to 3D flow visualization. Overall, the presented method delivers interactively animated 3D flow, uses only standard OpenGL 1.1 calls and 2D textures, and is simple to understand and implement.\\\",\\\"Authors\\\":\\\"Telea, A.;van Wijk, J.J.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;FlowVisualizationDataAndTechniques;HardwareAccellerationAndComputationGeneral;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250377\\\",\\\"Keywords\\\":\\\"flow visualization;opengl;texture advection;hardware acceleration\\\",\\\"Keywords_Processed\\\":\\\"texture advection;opengl;hardware acceleration;flow visualization\\\",\\\"Title\\\":\\\"3D IBFV: hardware-accelerated 3D flow visualization\\\"},\\\"3\\\":{\\\"Abstract\\\":\\\"We present a haptic rendering technique that uses directional constraints to facilitate enhanced exploration modes for volumetric datasets. The algorithm restricts user motion in certain directions by incrementally moving a proxy point along the axes of a local reference frame. Reaction forces are generated by a spring coupler between the proxy and the data probe, which can be tuned to the capabilities of the haptic interface. Secondary haptic effects including field forces, friction, and texture can be easily incorporated to convey information about additional characteristics of the data. We illustrate the technique with two examples: displaying fiber orientation in heart muscle layers and exploring diffusion tensor fiber tracts in brain white matter tissue. Initial evaluation of the approach indicates that haptic constraints provide an intuitive means or displaying directional information in volume data.\\\",\\\"Authors\\\":\\\"Ikits, M.;Brederson, J.D.;Hansen, C.;Johnson, C.R.\\\",\\\"Clusters\\\":\\\"HumanComputerInteractionHumanFactors;ImmersiveAndVirtualEnvironments;InputAndOutputDevicesGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250381\\\",\\\"Keywords\\\":\\\"haptic rendering;immersive visualization;human-computer interaction\\\",\\\"Keywords_Processed\\\":\\\"haptic rendering;immersive visualization;human computer interaction\\\",\\\"Title\\\":\\\"A constraint-based technique for haptic volume exploration\\\"},\\\"4\\\":{\\\"Abstract\\\":\\\"We present an innovative modeling and rendering primitive, called the O-buffer, for sample-based graphics, such as images, volumes and points. The 2D or 3D O-buffer is in essence a conventional image or a volume, respectively, except that samples are not restricted to a regular grid. A sample position in the O-buffer is recorded as an offset to the nearest grid point of a regular base grid (hence the name O-buffer). The offset is typically quantized for compact representation and efficient rendering. The O-buffer emancipates pixels and voxels from the regular grids and can greatly improve the modeling power of images and volumes. It is a semi-regular structure which lends itself to efficient construction and rendering. Image quality can be improved by storing more spatial information with samples and by avoiding multiple resamplings and delaying reconstruction to the final rendering stage. Using O-buffers, more accurate multi-resolution representations can be developed for images and volumes. It can also be exploited to represent and render unstructured primitives, such as points, particles, curvilinear or irregular volumes. The O-buffer is therefore a uniform representation for a variety of graphics primitives and supports mixing them in the same scene. We demonstrate the effectiveness of the O-buffer with hierarchical O-buffers, layered depth O-buffers, and hybrid volume rendering with O-buffers.\\\",\\\"Authors\\\":\\\"Huamin Qu;Kaufman, A.;Ran Shao;Kumar, A.\\\",\\\"Clusters\\\":\\\"HierarchicalTreeDataAndTechniques;ImageBasedDataImageSignalProcessing;Rendering;Sampling;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250405\\\",\\\"Keywords\\\":\\\"hierarchy;hybrid rendering;frame buffer;sample-based rendering;irregular sampling;offset;image-based rendering;layered depth image\\\",\\\"Keywords_Processed\\\":\\\"image base render;hierarchy;irregular sampling;hybrid render;sample base render;offset;frame buffer;layer depth image\\\",\\\"Title\\\":\\\"A framework for sample-based rendering with O-buffers\\\"},\\\"5\\\":{\\\"Abstract\\\":\\\"This paper introduces a method for converting an image or volume sampled on a regular grid into a space-efficient irregular point hierarchy. The conversion process retains the original frequency characteristics of the dataset by matching the spatial distribution of sample points with the required frequency. To achieve good blending, the spherical points commonly used in volume rendering are generalized to ellipsoidal point primitives. A family of multiresolution, oriented Gabor wavelets provide the frequency-space analysis of the dataset. The outcome of this frequency analysis is the reduced set of points, in which the sampling rate is decreased in originally oversampled areas. During rendering, the traversal of the hierarchy can be controlled by any suitable error metric or quality criteria. The local level of refinement is also sensitive to the transfer function. Areas with density ranges mapped to high transfer function variability are rendered at higher point resolution than others. Our decomposition is flexible and can be used for iso-surface rendering, alpha compositing and X-ray rendering of volumes. We demonstrate our hierarchy with an interactive splatting volume renderer, in which the traversal of the point hierarchy for rendering is modulated by a user-specified frame rate.\\\",\\\"Authors\\\":\\\"Welsh, T.;Mueller, K.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;PointBasedDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250403\\\",\\\"Keywords\\\":\\\"splatting;point-based rendering;volume rendering\\\",\\\"Keywords_Processed\\\":\\\"point base render;volume render;splatte\\\",\\\"Title\\\":\\\"A frequency-sensitive point hierarchy for images and volumes\\\"},\\\"6\\\":{\\\"Abstract\\\":\\\"We propose a new method for assessing the perceptual organization of information graphics, based on the premise that the visual structure of an image should match the structure of the data it is intended to convey. The core of our method is a new formal model of one type of perceptual structure, based on classical machine vision techniques for analyzing an image at multiple resolutions. The model takes as input an arbitrary grayscale image and returns a lattice structure describing the visual organization of the image. We show how this model captures several aspects of traditional design aesthetics, and we describe a software tool that implements the model to help designers analyze and refine visual displays. Our emphasis here is on demonstrating the model's potential as a design aid rather than as a description of human perception, but given its initial promise we propose a variety of ways in which the model could be extended and validated.\\\",\\\"Authors\\\":\\\"Wattenberg, M.;Fisher, D.\\\",\\\"Clusters\\\":\\\"DesignMethodologiesAndInteractionDesign;MultiScaleDataTechniques;Perception;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249005\\\",\\\"Keywords\\\":\\\"visualization;design methodology;perceptual organization;scale space\\\",\\\"Keywords_Processed\\\":\\\"visualization;perceptual organization;design methodology;scale space\\\",\\\"Title\\\":\\\"A model of multi-scale perceptual organization in information graphics\\\"},\\\"7\\\":{\\\"Abstract\\\":\\\"We combine topological and geometric methods to construct a multi-resolution data structure for functions over two-dimensional domains. Starting with the Morse-Smale complex, we construct a topological hierarchy by progressively canceling critical points in pairs. Concurrently, we create a geometric hierarchy by adapting the geometry to the changes in topology. The data structure supports mesh traversal operations similarly to traditional multi-resolution representations.\\\",\\\"Authors\\\":\\\"Bremer, P.-T.;Edelsbrunner, H.;Hamann, B.;Pascucci, V.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;GeographyGeospatialVisCartographyTerrainVis;MultiresolutionTechniques;NumericalMethodsMathematics;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250365\\\",\\\"Keywords\\\":\\\"multi-resolution data structure;critical point theory;morse-smale complex;simplification;terrain\\\",\\\"Keywords_Processed\\\":\\\"terrain;morse smale complex;multi resolution datum structure;simplification;critical point theory\\\",\\\"Title\\\":\\\"A multi-resolution data structure for two-dimensional Morse-Smale functions\\\"},\\\"8\\\":{\\\"Abstract\\\":\\\"In the traditional volume visualization paradigm, the user specifies a transfer function that assigns each scalar value to a color and opacity by defining an opacity and a color map function. The transfer function has two limitations. First, the user must define curves based on histogram and value rather than seeing and working with the volume itself. Second, the transfer function is inflexible in classifying regions of interest, where values at a voxel such as intensity and gradient are used to differentiate material, not talking into account additional properties such as texture and position. We describe an intuitive user interface for specifying the classification functions that consists of the users painting directly on sample slices of the volume. These painted regions are used to automatically define high-dimensional classification functions that can be implemented in hardware for interactive rendering. The classification of the volume is iteratively improved as the user paints samples, allowing intuitive and efficient viewing of materials of interest.\\\",\\\"Authors\\\":\\\"Tzeng, F.-Y.;Lum, E.B.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"InputAndOutputDevicesGeneral;InteractionTechniquesGeneral;MachineLearningAndStatistics;SegmentationAndClassification;UserInterfacesGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250413\\\",\\\"Keywords\\\":\\\"interactive visualization;graphics hardware;neural networks;multi-dimensional transfer function;classification;volume visualization;user interface design\\\",\\\"Keywords_Processed\\\":\\\"graphic hardware;multi dimensional transfer function;neural network;user interface design;classification;volume visualization;interactive visualization\\\",\\\"Title\\\":\\\"A novel interface for higher-dimensional classification of volume data\\\"},\\\"9\\\":{\\\"Abstract\\\":\\\"We propose unsteady flow advection-convolution (UFAC) as a novel visualization approach for unsteady flows. It performs time evolution governed by pathlines, but builds spatial correlation according to instantaneous streamlines whose spatial extent is controlled by the flow unsteadiness. UFAC is derived from a generic framework that provides spacetime-coherent dense representations of time dependent-vector fields by a two-step process: 1) construction of continuous trajectories in spacetime for temporal coherence; and 2) convolution along another set of paths through the above spacetime for spatially correlated patterns. Within the framework, known visualization techniques-such as Lagrangian-Eulerian advection, image-based flow visualization, unsteady flow LIC, and dynamic LIC-can be reproduced, often with better image quality, higher performance, or increased flexibility of the visualization style. Finally, we present a texture-based discretization of the framework and its interactive implementation on graphics hardware, which allows the user to gradually balance visualization speed against quality.\\\",\\\"Authors\\\":\\\"Weiskopf, D.;Erlebacher, G.;Ertl, T.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;HardwareAccellerationAndComputationGeneral;Textures;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250361\\\",\\\"Keywords\\\":\\\"unsteady flow visualization;hardware acceleration;line integral convolution;time-dependent vector fields;texture advection\\\",\\\"Keywords_Processed\\\":\\\"time dependent vector field;line integral convolution;texture advection;hardware acceleration;unsteady flow visualization\\\",\\\"Title\\\":\\\"A texture-based framework for spacetime-coherent visualization of time-dependent vector fields\\\"},\\\"10\\\":{\\\"Abstract\\\":\\\"In visualising multidimensional data, it is well known that different types of algorithms to process them. Data sets might be distinguished according to volume, variable types and distribution, and each of these characteristics imposes constraints upon the choice of applicable algorithms for their visualization. Previous work has shown that a hybrid algorithmic approach can be successful in addressing the impact of data volume on the feasibility of multidimensional scaling (MDS). This suggests that hybrid combinations of appropriate algorithms might also successfully address other characteristics of data. This paper presents a system and framework in which a user can easily explore hybrid algorithms and the data flowing through them. Visual programming and a novel algorithmic architecture let the user semi-automatically define data flows and the co-ordination of multiple views.\\\",\\\"Authors\\\":\\\"Ross, G.;Chalmers, M.\\\",\\\"Clusters\\\":\\\"Cognition;DataAcquisitionAndManagement;DimensionalityReduction;MultipleLinkedCoordinatedViews;ProgrammingAlgorithmsAndDataStructures\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249013\\\",\\\"Keywords\\\":\\\"multi-dimensional scaling;multiple views;hybrid algorithms;visual programming;data-flow;complexity\\\",\\\"Keywords_Processed\\\":\\\"datum flow;multiple view;multi dimensional scaling;hybrid algorithm;complexity;visual programming\\\",\\\"Title\\\":\\\"A virtual workspace for hybrid multidimensional scaling algorithms\\\"},\\\"11\\\":{\\\"Abstract\\\":\\\"The Internet pervades many aspects of our lives and is becoming indispensable to critical functions in areas such as commerce, government, production and general information dissemination. To maintain the stability and efficiency of the Internet, every effort must be made to protect it against various forms of attacks, malicious users, and errors. A key component in the Internet security effort is the routine examination of Internet routing data, which unfortunately can be too large and complicated to browse directly. We have developed an interactive visualization process which proves to be very effective for the analysis of Internet routing data. In this application paper, we show how each step in the visualization process helps direct the analysis and glean insights from the data. These insights include the discovery of patterns, detection of faults and abnormal events, understanding of event correlations, formation of causation hypotheses, and classification of anomalies. We also discuss lessons learned in our visual analysis study.\\\",\\\"Authors\\\":\\\"Soon Tee Teoh;Kwan-Liu Ma;Wu, S.F.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;InternetWebVisualizationForTheMasses;PrivacySecurityIntelligenceAnalysis;TextDocumentTopicAnalysisDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250415\\\",\\\"Keywords\\\":\\\"information visualization;homeland security;text visualization;internet stability;network visualization\\\",\\\"Keywords_Processed\\\":\\\"internet stability;text visualization;network visualization;information visualization;homeland security\\\",\\\"Title\\\":\\\"A visual exploration process for the analysis of Internet routing data\\\"},\\\"12\\\":{\\\"Abstract\\\":\\\"We present techniques for discovering and exploiting regularity in large curvilinear data sets. The data can be based on a single mesh or a mesh composed of multiple submeshes (also known as zones). Multi-zone data are typical in Computational Fluid Dynamics (CFD) simulations. Regularities include axis-aligned rectilinear and cylindrical meshes as well as cases where one zone is equivalent to a rigid body transformation of another. Our algorithms can also discover rigid-body motion of meshes in time-series data. Next, we describe a data model where we can utilize the results from the discovery process in order to accelerate large data visualizations. Where possible, we replace general curvilinear zones with rectilinear or cylindrical zones. In rigid-body motion cases, we replace a time-series of meshes with a transformed mesh object where a reference mesh is dynamically transformed based on a given time value in order to satisfy geometry requests, on demand. The data model enables us to make these substitutions and dynamic transformations transparently with respect to the visualization algorithms. We present results with large data sets where we combine our mesh replacement and transformation techniques with out-of-core paging in order to achieve analysis speedups ranging from 1.5 to 2.\\\",\\\"Authors\\\":\\\"Ellsworth, D.;Moran, P.J.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;ProgrammingAlgorithmsAndDataStructures;VisualPatternFeatureDetectionAndTracking\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250420\\\",\\\"Keywords\\\":\\\"data models;c++;paging;scientific visualization;demand-driven evaluation;template;object-oriented;regularity finding\\\",\\\"Keywords_Processed\\\":\\\"template;datum model;page;object orient;scientific visualization;regularity finding;demand drive evaluation\\\",\\\"Title\\\":\\\"Accelerating large data analysis by exploiting regularities\\\"},\\\"13\\\":{\\\"Abstract\\\":\\\"Nowadays, direct volume rendering via 3D textures has positioned itself as an efficient tool for the display and visual analysis of volumetric scalar fields. It is commonly accepted, that for reasonably sized data sets appropriate quality at interactive rates can be achieved by means of this technique. However, despite these benefits one important issue has received little attention throughout the ongoing discussion of texture based volume rendering: the integration of acceleration techniques to reduce per-fragment operations. In this paper, we address the integration of early ray termination and empty-space skipping into texture based volume rendering on graphical processing units (GPU). Therefore, we describe volume ray-casting on programmable graphics hardware as an alternative to object-order approaches. We exploit the early z-test to terminate fragment processing once sufficient opacity has been accumulated, and to skip empty space along the rays of sight. We demonstrate performance gains up to a factor of 3 for typical renditions of volumetric data sets on the ATI 9700 graphics card.\\\",\\\"Authors\\\":\\\"Kruger, J.;Westermann, R.\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;RaytracingRaycasting;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250384\\\",\\\"Keywords\\\":\\\"raycasting;volume rendering;programmable graphics hardware\\\",\\\"Keywords_Processed\\\":\\\"volume render;programmable graphic hardware;raycaste\\\",\\\"Title\\\":\\\"Acceleration techniques for GPU-based volume rendering\\\"},\\\"14\\\":{\\\"Abstract\\\":\\\"While there are a couple of transfer function design approaches for CT and MRI (magnetic resonance imaging) data, direct volume rendering of ultrasound data still relies on manual adjustment of an inflexible piecewise linear opacity transfer function (OTF) on a trial-and-error basis. The main challenge of automatically designing an OTF for visualization of sonographic data is the low signal-to-noise ratio in combination with real time data acquisition at frame rates up to 25 volumes per second. In this paper, we present an efficient solution of this task. Our approach is based on the evaluation of tube cores, i.e., collections of voxels gathered by traversing the volume in rendering directions. We use information about the probable position of an interface between tissues of different echogenicity to adaptively design an OTF in a multiplicative way. We show the appropriateness of our approach by examples, deliberately on data sets of moderate quality arising frequently in clinical settings.\\\",\\\"Authors\\\":\\\"Honigmann, D.;Ruisz, J.;Haider, C.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250411\\\",\\\"Keywords\\\":\\\"3d ultrasound;transfer function;direct volume rendering\\\",\\\"Keywords_Processed\\\":\\\"transfer function;3d ultrasound;direct volume render\\\",\\\"Title\\\":\\\"Adaptive design of a global opacity transfer function for direct volume rendering of ultrasound data\\\"},\\\"15\\\":{\\\"Abstract\\\":\\\"Traditional volume visualization techniques may provide incomplete clinical information needed for applications in medical visualization. In the area of vascular visualization important features such as the lumen of a diseased vessel segment may not be visible. Curved planar reformation (CPR) has proven to be an acceptable practical solution. Existing CPR techniques, however, still have diagnostically relevant limitations. In this paper, we introduce two advances methods for efficient vessel visualization, based on the concept of CPR. Both methods benefit from relaxation of spatial coherence in favor of improved feature perception. We present a new technique to visualize the interior of a vessel in a single image. A vessel is resampled along a spiral around its central axis. The helical spiral depicts the vessel volume. Furthermore, a method to display an entire vascular tree without mutually occluding vessels is presented. Minimal rotations at the bifurcations avoid occlusions. For each viewing direction the entire vessel structure is visible.\\\",\\\"Authors\\\":\\\"Kanitsar, A.;Wegenkittl, R.;Fleischmann, D.;Groller, E.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DimensionalityReduction\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250353\\\",\\\"Keywords\\\":\\\"curved planar reformation;computed tomography angiography;vessel analysis\\\",\\\"Keywords_Processed\\\":\\\"curve planar reformation;compute tomography angiography;vessel analysis\\\",\\\"Title\\\":\\\"Advanced curved planar reformation: flattening of vascular structures\\\"},\\\"16\\\":{\\\"Abstract\\\":\\\"This paper presents the results of an experiment aimed at investigating how different methods of viewing visual programs affect users' understanding. The first two methods used traditional flat and semantic zooming models of program representation; the third is a new representation that uses semantic zooming combined with blending and proximity. The results of several search tasks performed by approximately 80 participants showed that the new method resulted in both faster and more accurate searches than the other methods.\\\",\\\"Authors\\\":\\\"Summers, K.L.;Goldsmith, T.E.;Kubica, S.;Caudell, T.P.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;ProgrammingAlgorithmsAndDataStructures;SoftwareVisualization\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249021\\\",\\\"Keywords\\\":\\\"visual programming languages;human subjects testing;program visualization\\\",\\\"Keywords_Processed\\\":\\\"visual programming language;human subject testing;program visualization\\\",\\\"Title\\\":\\\"An experimental evaluation of continuous semantic zooming in program visualization\\\"},\\\"17\\\":{\\\"Abstract\\\":\\\"In this paper a new quadric-based view-dependent simplification scheme is presented. The scheme provides a method to connect mesh simplification controlled by a quadric error metric with a level-of-detail hierarchy that is accessed continuously and efficiently based on current view parameters. A variety of methods for determining the screen-space metric for the view calculation are implemented and evaluated, including an appearance-preserving method that has both geometry- and texture-preserving aspects. Results are presented and compared for a variety of models.\\\",\\\"Authors\\\":\\\"Jang, J.;Ribarsky, W.;Shaw, C.;Wonka, P.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;LevelOfDetail;MultiresolutionTechniques;ViewDependentVisualization;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250409\\\",\\\"Keywords\\\":\\\"multi-resolution model;level-of-detail;mesh simplification;appearance-preserving;view-dependent\\\",\\\"Keywords_Processed\\\":\\\"appearance preserve;level of detail;view dependent;mesh simplification;multi resolution model\\\",\\\"Title\\\":\\\"Appearance-preserving view-dependent visualization\\\"},\\\"18\\\":{\\\"Abstract\\\":\\\"We present BARD (biological arc diagrams), a visualization tool for biological sequence analysis. The development of BARD began with the application of Wattenberg's arc diagrams [Wattenberg 2002] to results from sequence analysis programs, such as BLAST [Altschul et al. 1990]. In this paper, we extend the initial arc diagram concept in two ways: 1) by separating the visualization method from the underlying matching algorithm and 2) by expanding the types of matches to include inexact matches, complemented palindrome matches, and inter-sequence matches. BARD renders each type of match distinctly, resulting in a powerful tool to quickly understand sequence similarities and differences. We illustrate the power of BARD by applying the technique to a comparative sequence analysis of the human pathogenic fungi Cryptococcus neoformans.\\\",\\\"Authors\\\":\\\"Spell, R.;Brady, R.;Dietrich, F.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;ChartsDiagramsPlots;Genetics;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249029\\\",\\\"Keywords\\\":\\\"sequence analysis;arc diagram;visualization;comparative genomics;bard\\\",\\\"Keywords_Processed\\\":\\\"visualization;bard;arc diagram;sequence analysis;comparative genomic\\\",\\\"Title\\\":\\\"BARD: A visualization tool for biological sequence analysis\\\"},\\\"19\\\":{\\\"Abstract\\\":\\\"Unlike traditional information visualization, ambient information visualizations reside in the environment of the user rather than on the screen of a desktop computer. Currently, most dynamic information that is displayed in public places consists of text and numbers. We argue that information visualization can be employed to make such dynamic data more useful and appealing. However, visualizations intended for non-desktop spaces will have to both provide valuable information and present an attractive addition to the environment - they must strike a balance between aesthetical appeal and usefulness. To explore this, we designed a real-time visualization of bus departure times and deployed it in a public space, with about 300 potential users. To make the presentation more visually appealing, we took inspiration from a modern abstract artist. The visualization was designed in two passes. First, we did a preliminary version that was presented to and discussed with prospective users. Based on their input, we did a final design. We discuss the lessons learned in designing this and previous ambient information visualizations, including how visual art can be used as a design constraint, and how the choice of information and the placement of the display affect the visualization.\\\",\\\"Authors\\\":\\\"Skog, T.;Ljungblad, S.;Holmquist, L.E.\\\",\\\"Clusters\\\":\\\"AmbientVisualization;ArtAndAestheticsInVisualization;InputAndOutputDevicesGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249031\\\",\\\"Keywords\\\":\\\"ambient displays;informative art;calm technology;ambient information visualization\\\",\\\"Keywords_Processed\\\":\\\"calm technology;informative art;ambient display;ambient information visualization\\\",\\\"Title\\\":\\\"Between aesthetics and utility: designing ambient information visualizations\\\"},\\\"20\\\":{\\\"Abstract\\\":\\\"We present Growing Polygons, a novel visualization technique for the graphical representation of causal relations and information flow in a system of interacting processes. Using this method, individual processes are displayed as partitioned polygons with color-coded segments showing dependencies to other processes. The entire visualization is also animated to communicate the dynamic execution of the system to the user. The results from a comparative user study of the method show that the Growing Polygons technique is significantly more efficient than the traditional Hasse diagram visualization for analysis tasks related to deducing information flow in a system for both small and large executions. Furthermore, our findings indicate that the correctness when solving causality tasks is significantly improved using our method. In addition, the subjective ratings of the users rank the method as superior in all regards, including usability, efficiency, and enjoyability.\\\",\\\"Authors\\\":\\\"Elmqvist, N.;Tsigas, P.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;HypothesisFormingTestingAndVisualEvidence;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249025\\\",\\\"Keywords\\\":\\\"causal relations;information visualization;interactive animation\\\",\\\"Keywords_Processed\\\":\\\"causal relation;information visualization;interactive animation\\\",\\\"Title\\\":\\\"Causality visualization using animated growing polygons\\\"},\\\"21\\\":{\\\"Abstract\\\":\\\"The goal of this paper is to define a convolution operation which transfers image processing and pattern matching to vector fields from flow visualization. For this, a multiplication of vectors is necessary. Clifford algebra provides such a multiplication of vectors. We define a Clifford convolution on vector fields with uniform grids. The Clifford convolution works with multivector filter masks. Scalar and vector masks can be easily converted to multivector fields. So, filter masks from image processing on scalar fields can be applied as well as vector and scalar masks. Furthermore, a method for pattern matching with Clifford convolution on vector fields is described. The method is independent of the direction of the structures. This provides an automatic approach to feature detection. The features can be visualized using any known method like glyphs, isosurfaces or streamlines. The features are defined by filter masks instead of analytical properties and thus the approach is more intuitive.\\\",\\\"Authors\\\":\\\"Ebling, J.;Scheuermann, G.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;NumericalMethodsMathematics;VisualPatternFeatureDetectionAndTracking\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250372\\\",\\\"Keywords\\\":\\\"convolution;pattern matching;flow visualization\\\",\\\"Keywords_Processed\\\":\\\"convolution;flow visualization;pattern matching\\\",\\\"Title\\\":\\\"Clifford convolution and pattern matching on vector fields\\\"},\\\"22\\\":{\\\"Abstract\\\":\\\"This paper proposes a conceptual model called compound brushing for modeling the brushing techniques used in dynamic data visualization. In this approach, brushing techniques are modeled as higraphs with five types of basic entities: data, selection, device, renderer, and transformation. Using this model, a flexible visual programming tool is designed not only to configure/control various common types of brushing techniques currently used in dynamic data visualization, but also to investigate new brushing techniques.\\\",\\\"Authors\\\":\\\"Hong Chen\\\",\\\"Clusters\\\":\\\"DynamicDataAndTechniques;GraphNetworkDataAndTechniques;InteractionTechniquesGeneral;ProgrammingAlgorithmsAndDataStructures;QueriesAndSearch;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249024\\\",\\\"Keywords\\\":\\\"dynamic graphics;brushing;dynamic query;visualization;higraph;visual programming;selection\\\",\\\"Keywords_Processed\\\":\\\"visualization;brush;selection;higraph;dynamic query;dynamic graphic;visual programming\\\",\\\"Title\\\":\\\"Compound brushing\\\"},\\\"23\\\":{\\\"Abstract\\\":\\\"A survey of graphics developers on the issue of texture mapping hardware for volume rendering would most likely find that the vast majority of them view limited texture memory as one of the most serious drawbacks of an otherwise fine technology. In this paper, we propose a compression scheme for static and time-varying volumetric data sets based on vector quantization that allows us to circumvent this limitation. We describe a hierarchical quantization scheme that is based on a multiresolution covariance analysis of the original field. This allows for the efficient encoding of large-scale data sets, yet providing a mechanism to exploit temporal coherence in non-stationary fields. We show, that decoding and rendering the compressed data stream can be done on the graphics chip using programmable hardware. In this way, data transfer between the CPU and the graphics processing unit (GPU) can be minimized thus enabling flexible and memory efficient real-time rendering options. We demonstrate the effectiveness of our approach by demonstrating interactive renditions of Gigabyte data sets at reasonable fidelity on commodity graphics hardware.\\\",\\\"Authors\\\":\\\"Schneider, J.;Westermann, R.\\\",\\\"Clusters\\\":\\\"InputAndOutputDevicesGeneral;Textures;VectorFieldsDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250385\\\",\\\"Keywords\\\":\\\"texture compression;vector quantization;volume rendering;graphics hardware\\\",\\\"Keywords_Processed\\\":\\\"texture compression;vector quantization;volume render;graphic hardware\\\",\\\"Title\\\":\\\"Compression domain volume rendering\\\"},\\\"24\\\":{\\\"Abstract\\\":\\\"The Informedia Digital Video Library user interface summarizes query results with a collage of representative keyframes. We present a user study in which keyframe occlusion caused difficulties. To use the screen space most efficiently to display images, both occlusion and wasted whitespace should be minimized. Thus optimal choices will tend toward constant density displays. However, previous constant density algorithms are based on global density, which leads to occlusion and empty space if the density is not uniform. We introduce an algorithm that considers the layout of individual objects and avoids occlusion altogether. Efficiency concerns are important for dynamic summaries of the Informedia Digital Video Library, which has hundreds of thousands of shots. Posting multiple queries that take into account parameters of the visualization as well as the original query reduces the amount of work required. This greedy algorithm is then compared to an optimal one. The approach is also applicable to visualizations containing complex graphical objects other than images, such as text, icons, or trees.\\\",\\\"Authors\\\":\\\"Derthick, M.;Christel, M.G.;Hauptmann, A.G.;Wactlar, H.D.\\\",\\\"Clusters\\\":\\\"ArtAndAestheticsInVisualization;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249019\\\",\\\"Keywords\\\":\\\"information visualization;collage\\\",\\\"Keywords_Processed\\\":\\\"information visualization;collage\\\",\\\"Title\\\":\\\"Constant density displays using diversity sampling\\\"},\\\"25\\\":{\\\"Abstract\\\":\\\"As visualization researchers, we are interested in gaining a better understanding of how to effectively use texture to facilitate shape perception. If we could design the ideal texture pattern to apply to an arbitrary smoothly curving shape to be most accurately and effectively perceived, what would the characteristics of that texture pattern be? In this paper we describe the results of a comprehensive controlled observer experiment intended to yield insight into that question. Here, we report the results of a new study comparing the relative accuracy of observers' judgments of shape type (elliptical, cylindrical, hyperbolic or flat) and shape orientation (convex, concave, both, or neither) for local views of boundary masked quadric surface patches under six different principal direction texture pattern conditions plus two texture conditions (an isotropic pattern and a non-principal direction oriented anisotropic pattern), under both perspective and orthographic projection conditions and from both head-on and oblique viewpoints. Our results confirm the hypothesis that accurate shape perception is facilitated to a statistically significantly greater extent by some principal direction texture patterns than by others. Specifically, we found that, for both views, under conditions of perspective projection, participants more often correctly identified the shape category and the shape orientation when the surface was textured with the pattern that contained oriented energy along both the first and second principal directions only than in the case of any other texture condition. Patterns containing markings following only one of the principal directions, or containing information along other directions in addition to the principal directions yielded poorer performance overall.\\\",\\\"Authors\\\":\\\"Kim, S.;Hagh-Shenas, H.;Interrante, V.\\\",\\\"Clusters\\\":\\\"NumericalMethodsMathematics;Perception;Textures\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249022\\\",\\\"Keywords\\\":\\\"shape perception;texture;principal directions\\\",\\\"Keywords_Processed\\\":\\\"texture;principal direction;shape perception\\\",\\\"Title\\\":\\\"Conveying shape with texture: an experimental investigation of the impact of texture type on shape categorization judgments\\\"},\\\"26\\\":{\\\"Abstract\\\":\\\"Microarrays are relatively new, high-throughput data acquisition technology for investigating biological phenomena at the micro-level. One of the more common procedures for microarray experimentation is that of the microarray time-course experiment. The product of microarray time-course experiment is time-series data, which subject to proper analysis has the potential to have significant impact on the diagnosis, treatment, and prevention of diseases. While existing information visualization techniques go some way to making microarray time-series data more manageable, requirements analysis has revealed significant limitations. The main finding was that users were unable to uncover and quantify common changes in value over a specified time-period. This paper describes a novel technique that provides this functionality by allowing the user to visually formulate and modify measurable queries with separate time-period and condition components. These visual queries are supported by the combination of a traditional value against time graph representation of the data with a complementary scatter-plot representation of a specified time-period. The multiple views of the visualization are coordinated so that the user can formulate and modify queries with rapid reversible display of query results in the traditional value against time graph format.\\\",\\\"Authors\\\":\\\"Craig, P.;Kennedy, J.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;MultipleLinkedCoordinatedViews;TimeseriesTimeVaryingDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249023\\\",\\\"Keywords\\\":\\\"information visualization;bioinformatics;time-series;microarrays;multiple views\\\",\\\"Keywords_Processed\\\":\\\"microarray;time series;information visualization;multiple view;bioinformatic\\\",\\\"Title\\\":\\\"Coordinated graph and scatter-plot views for the visual exploration of microarray time-series data\\\"},\\\"27\\\":{\\\"Abstract\\\":\\\"We describe how to count the cases that arise in a family of visualization techniques, including marching cubes, sweeping simplices, contour meshing, interval volumes, and separating surfaces. Counting the cases is the first step toward developing a generic visualization algorithm to produce substitopes (geometric substitution of polytopes). We demonstrate the method using a software system (\\\\\\\"GAP\\\\\\\") for computational group theory. The case-counts are organized into a table that provides taxonomy of members of the family; numbers in the table are derived from actual lists of cases, which are computed by our methods. The calculation confirms previously reported case-counts for large dimensions that are too large to check by hand, and predicts the number of cases that will arise in algorithms that have not yet been invented.\\\",\\\"Authors\\\":\\\"Banks, D.C.;Linton, S.\\\",\\\"Clusters\\\":\\\"CollaborativeVisualization;EarthSpaceAndEnvironmentalSciences;GeometricModeling;IsosurfaceAndSurfaceExtractionTechniques;NumericalMethodsMathematics;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250354\\\",\\\"Keywords\\\":\\\"substitope;group action;level sets;orbit;geometric substitution;marching cubes;isosurface;separating surfaces\\\",\\\"Keywords_Processed\\\":\\\"march cube;substitope;orbit;level set;separate surface;group action;isosurface;geometric substitution\\\",\\\"Title\\\":\\\"Counting cases in marching cubes: toward a generic algorithm for producing substitopes\\\"},\\\"28\\\":{\\\"Abstract\\\":\\\"Direct volume rendering of scalar fields uses a transfer function to map locally measured data properties to opacities and colors. The domain of the transfer function is typically the one-dimensional space of scalar data values. This paper advances the use of curvature information in multi-dimensional transfer functions, with a methodology for computing high-quality curvature measurements. The proposed methodology combines an implicit formulation of curvature with convolution-based reconstruction of the field. We give concrete guidelines for implementing the methodology, and illustrate the importance of choosing accurate filters for computing derivatives with convolution. Curvature-based transfer functions are shown to extend the expressivity and utility of volume rendering through contributions in three different application areas: nonphotorealistic volume rendering, surface smoothing via anisotropic diffusion, and visualization of isosurface uncertainty.\\\",\\\"Authors\\\":\\\"Kindlmann, G.;Whitaker, R.T.;Tasdizen, T.;Moller, T.\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;IllustrativeVisualization;NumericalMethodsMathematics;SurfaceRelatedDataAndTechniques;UncertaintyTechniquesAndVisualization;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250414\\\",\\\"Keywords\\\":\\\"volume rendering;non-photorealistic rendering;uncertainty visualization;convolution-based differentiation;flowline curvature;implicit surface curvature;surface processing\\\",\\\"Keywords_Processed\\\":\\\"volume render;non photorealistic rendering;implicit surface curvature;convolution base differentiation;flowline curvature;uncertainty visualization;surface processing\\\",\\\"Title\\\":\\\"Curvature-based transfer functions for direct volume rendering: methods and applications\\\"},\\\"29\\\":{\\\"Abstract\\\":\\\"In this paper, we focus on some of the key design decisions we faced during the process of architecting a visualization system and present some possible choices, with their associated advantages and disadvantages. We frame this discussion within the context of Rivet, our general visualization environment designed for rapidly prototyping interactive, exploratory visualization tools for analysis. As we designed increasingly sophisticated visualizations, we needed to refine Rivet in order to be able to create these richer displays for larger and more complex data sets. The design decisions we discuss in this paper include: the internal data model, data access, semantic meta-data information the visualization can use to create effective visual decodings, the need for data transformations in a visualization tool, modular objects for flexibility, and the tradeoff between simplicity and expressiveness when providing methods for creating visualizations.\\\",\\\"Authors\\\":\\\"Tang, D.;Stolte, C.;Bosche, R.\\\",\\\"Clusters\\\":\\\"DataTransformation;SemanticsSemioticsRelatedTechniques;VisualDesignDesignGuidelines;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249007\\\",\\\"Keywords\\\":\\\"information visualization;design tradeoffs;semantic meta-data;system architecture;data transformation\\\",\\\"Keywords_Processed\\\":\\\"semantic meta datum;design tradeoff;datum transformation;information visualization;system architecture\\\",\\\"Title\\\":\\\"Design choices when architecting visualizations\\\"},\\\"30\\\":{\\\"Abstract\\\":\\\"This paper reports on the development of a visualization system for architectural lighting designers. It starts by motivating the problem as both complex in its physics and social organization. Three iterations of prototypes for displaying time and space varying phenomena are discussed. Fieldwork is presented to identify where in practice they will be most effective. A set of user studies, one of which is analyzed in fine-grained detail, show how building designers incorporate visualization on hypothetical design problems. This has positive implications for both energy efficiency and lighting quality in buildings.\\\",\\\"Authors\\\":\\\"Glaser, D. C.;Tan, R.;Canny, J.;Do, E.Y.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;EarthSpaceAndEnvironmentalSciences;FieldStudies;QualitativeEvaluation;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249032\\\",\\\"Keywords\\\":\\\"information visualization;architectural lighting design;qualitative analysis;energy efficiency;ethnographic fieldwork\\\",\\\"Keywords_Processed\\\":\\\"energy efficiency;information visualization;architectural lighting design;ethnographic fieldwork;qualitative analysis\\\",\\\"Title\\\":\\\"Developing architectural lighting representations\\\"},\\\"31\\\":{\\\"Abstract\\\":\\\"We introduce two dynamic visualization techniques using multidimensional scaling to analyze transient data streams such as newswires and remote sensing imagery. While the time-sensitive nature of these data streams requires immediate attention in many applications, the unpredictable and unbounded characteristics of this information can potentially overwhelm many scaling algorithms that require a full re-computation for every update. We present an adaptive visualization technique based on data stratification to ingest stream information adaptively when influx rate exceeds processing rate. We also describe an incremental visualization technique based on data fusion to project new information directly onto a visualization subspace spanned by the singular vectors of the previously processed neighboring data. The ultimate goal is to leverage the value of legacy and new information and minimize re-processing of the entire dataset in full resolution. We demonstrate these dynamic visualization results using a newswire corpus and a remote sensing imagery sequence.\\\",\\\"Authors\\\":\\\"Pak Chung Wong;Foote, H.;Adams, D.;Cowley, W.;Thomas, J.\\\",\\\"Clusters\\\":\\\"DynamicVisualizationVisualizationOfChange;ImageBasedDataImageSignalProcessing;StreamingDataAndTechniques;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249014\\\",\\\"Keywords\\\":\\\"remote sensing imagery;transient data stream;text visualization;dynamic visualization\\\",\\\"Keywords_Processed\\\":\\\"dynamic visualization;text visualization;remote sensing imagery;transient datum stream\\\",\\\"Title\\\":\\\"Dynamic visualization of transient data streams\\\"},\\\"32\\\":{\\\"Abstract\\\":\\\"An increasing number of tasks require people to explore, navigate and search extremely complex data sets visualized as graphs. Examples include electrical and telecommunication networks, Web structures, and airline routes. The problem is that graphs of these real world data sets have many interconnected nodes, ultimately leading to edge congestion: the density of edges is so great that they obscure nodes, individual edges, and even the visual information beneath the graph. To address this problem we developed an interactive technique called EdgeLens. An EdgeLens interactively curves graph edges away for a person's focus attention without changing the node positions. This opens up sufficient space to disambiguate node and edge relationships and to see underlying information while still preserving node layout. Initially two methods of creating this interaction were developed and compared in a user study. The results of this study were used in the selection of a basic approach and the subsequent development of the EdgeLens. We then improved the EdgeLens through use of transparency and colour and by allowing multiple lenses to appear on the graph.\\\",\\\"Authors\\\":\\\"Wong, N.;Carpendale, S.;Greenberg, S.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;FocusContextTechniques;GraphNetworkDataAndTechniques;InteractionTechniquesGeneral;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249008\\\",\\\"Keywords\\\":\\\"interactive visualization;information visualization;graph layout;navigation;edge congestion;distortion lens\\\",\\\"Keywords_Processed\\\":\\\"graph layout;edge congestion;navigation;information visualization;distortion lens;interactive visualization\\\",\\\"Title\\\":\\\"Edgelens: an interactive method for managing edge congestion in graphs\\\"},\\\"33\\\":{\\\"Abstract\\\":\\\"In this paper we offer several new insights and techniques for effectively using color and texture to simultaneously convey information about multiple 2D scalar and vector distributions, in a way that facilitates allowing each distribution to be understood both individually and in the context of one or more of the other distributions. Specifically, we introduce the concepts of: color weaving for simultaneously representing information about multiple co-located color encoded distributions; and texture stitching for achieving more spatially accurate multi-frequency line integral convolution representations of combined scalar and vector distributions. The target application for our research is the definition, detection and visualization of regions of interest in a turbulent boundary layer flow at moderate Reynolds number. In this work, we examine and analyze streamwise-spanwise planes of three-component velocity vectors with the goal of identifying and characterizing spatially organized packets of hairpin vortices.\\\",\\\"Authors\\\":\\\"Urness, T.;Interrante, V.;Marusic, I.;Longmire, E.;Ganapathisubramani, B.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;FlowVisualizationDataAndTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250362\\\",\\\"Keywords\\\":\\\"color;flow visualization;multivariate visualization;line integral convolution;texture\\\",\\\"Keywords_Processed\\\":\\\"line integral convolution;texture;color;multivariate visualization;flow visualization\\\",\\\"Title\\\":\\\"Effectively visualizing multi-valued flow data using color and texture\\\"},\\\"34\\\":{\\\"Abstract\\\":\\\"Dynamic queries facilitate rapid exploration of information by real-time visual display of both query formulation and results. Dynamic query sliders are linked to the main visualization to filter data. A common alternative to dynamic queries is to link several simple visualizations, such as histograms, to the main visualization with a brushing interaction strategy. Selecting data in the histograms highlights that data in the main visualization. We compare these two approaches in an empirical experiment on DataMaps, a geographic data visualization tool. Dynamic query sliders resulted in better performance for simple range tasks, while brushing histograms was better for complex trend evaluation and attribute relation tasks. Participants preferred brushing histograms for understanding relationships between attributes and the rich information they provided.\\\",\\\"Authors\\\":\\\"Qing Li;North, C.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;MultidimensionalMultivariateMultifieldDataAndTechniques;QueriesAndSearch;UsabilityStudies;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249020\\\",\\\"Keywords\\\":\\\"information visualization;multi-dimensional visualization;dynamic query;slider;usability study;histogram\\\",\\\"Keywords_Processed\\\":\\\"multi dimensional visualization;dynamic query;information visualization;histogram;usability study;slider\\\",\\\"Title\\\":\\\"Empirical comparison of dynamic query sliders and brushing histograms\\\"},\\\"35\\\":{\\\"Abstract\\\":\\\"The extraction of planar sections from volume images is the most commonly used technique for inspecting and visualizing anatomic structures. We propose to generalize the concept of planar section to the extraction of curved cross-sections (free form surfaces). Compared with planar slices, curved cross-sections may easily follow the trajectory of tubular structures and organs such as the aorta or the colon. They may be extracted from a 3D volume, displayed as a 3D view and possibly flattened. Flattening of curved cross-sections allows to inspect spatially complex relationship between anatomic structures and their neighborhood. They also allow to carry out measurements along a specific orientation. For the purpose of facilitating the interactive specification of free form surfaces, users may navigate in real time within the body and select the slices on which the surface control points will be positioned. Immediate feedback is provided by displaying boundary curves as cylindrical markers within a 3D view composed of anatomic organs, planar slices and possibly free form surface sections. Extraction of curved surface sections is an additional service that is available online as a Java applet (http://visiblehuman.epfl.ch). It may be used as an advanced tool for exploring and teaching anatomy.\\\",\\\"Authors\\\":\\\"Saroul, L.;Gerlach, S.;Herch, R.D.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;CurvesAndCurvature;IsosurfaceAndSurfaceExtractionTechniques;SurfaceRelatedDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250351\\\",\\\"Keywords\\\":\\\"surface extraction;anatomic structures;interactive flattening;visualization;curved sections\\\",\\\"Keywords_Processed\\\":\\\"visualization;anatomic structure;curve section;interactive flattening;surface extraction\\\",\\\"Title\\\":\\\"Exploring curved anatomic structures with surface sections\\\"},\\\"36\\\":{\\\"Abstract\\\":\\\"We introduce an approach to visual analysis of multivariate data that integrates several methods from information visualization, exploratory data analysis (EDA), and geovisualization. The approach leverages the component-based architecture implemented in GeoVISTA Studio to construct a flexible, multiview, tightly (but generically) coordinated, EDA toolkit. This toolkit builds upon traditional ideas behind both small multiples and scatterplot matrices in three fundamental ways. First, we develop a general, multiform, bivariate matrix and a complementary multiform, bivariate small multiple plot in which different bivariate representation forms can be used in combination. We demonstrate the flexibility of this approach with matrices and small multiples that depict multivariate data through combinations of: scatterplots, bivariate maps, and space-filling displays. Second, we apply a measure of conditional entropy to (a) identify variables from a high-dimensional data set that are likely to display interesting relationships and (b) generate a default order of these variables in the matrix or small multiple display. Third, we add conditioning, a kind of dynamic query/filtering in which supplementary (undisplayed) variables are used to constrain the view onto variables that are displayed. Conditioning allows the effects of one or more well understood variables to be removed form the analysis, making relationships among remaining variables easier to explore. We illustrate the individual and combined functionality enabled by this approach through application to analysis of cancer diagnosis and mortality data and their associated covariates and risk factors.\\\",\\\"Authors\\\":\\\"MacEachren, A.M.;Xiping, D.;Hardisty, F.;Diansheng Guo;Lengerich, G.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;ChartsDiagramsPlots;GeographyGeospatialVisCartographyTerrainVis;InformationTheory;InteractionTechniquesGeneral;Maps;VisualEncodingAndLayoutGeneral;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249006\\\",\\\"Keywords\\\":\\\"space-filling visualization;conditioning;geovista studio;bivariate maps;conditional entropy;small multiples;scatterplot matrix;eda;geovisualization\\\",\\\"Keywords_Processed\\\":\\\"bivariate map;conditional entropy;geovisualization;scatterplot matrix;conditioning;small multiple;space fill visualization;geovista studio;eda\\\",\\\"Title\\\":\\\"Exploring high-D spaces with multiform matrices and small multiples\\\"},\\\"37\\\":{\\\"Abstract\\\":\\\"There are numerous algorithms in graphics and visualization whose performance is known to decay as the topological complexity of the input increases. On the other hand, the standard pipeline for 3D geometry acquisition often produces 3D models that are topologically more complex than their real forms. We present a simple and efficient algorithm that allows us to simplify the topology of an isosurface by alternating the values of some number of voxels. Its utility and performance are demonstrated on several examples, including signed distance functions from polygonal models and CT scans.\\\",\\\"Authors\\\":\\\"Szymczak, A.;Vanderhyde, J.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;Taxonomies;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250356\\\",\\\"Keywords\\\":\\\"isosurface;genus;topology\\\",\\\"Keywords_Processed\\\":\\\"genus;isosurface;topology\\\",\\\"Title\\\":\\\"Extraction of topologically simple isosurfaces from volume datasets\\\"},\\\"38\\\":{\\\"Abstract\\\":\\\"Volume rendering and isosurface extraction from three-dimensional scalar fields are mostly based on piecewise trilinear representations. In regions of high geometric complexity such visualization methods often exhibit artifacts, due to trilinear interpolation. In this work, we present an iterative fairing method for scalar fields interpolating function values associated with grid points while smoothing the contours inside the grid cells based on variational principles. We present a local fairing method providing a piecewise bicubic representation of two-dimensional scalar fields. Our algorithm generalizes to the trivariate case and can be used to increase the resolution of data sets either locally or globally, reducing interpolation artifacts. In contrast to filtering methods, our algorithm does not reduce geometric detail supported by the data.\\\",\\\"Authors\\\":\\\"Bertram, M.\\\",\\\"Clusters\\\":\\\"ContourCreasesRidgesValleys;GeometricModeling;Interpolation\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250398\\\",\\\"Keywords\\\":\\\"fairing;variational modeling;contours\\\",\\\"Keywords_Processed\\\":\\\"fair;contour;variational modeling\\\",\\\"Title\\\":\\\"Fairing scalar fields by variational modeling of contours\\\"},\\\"39\\\":{\\\"Abstract\\\":\\\"Segmentation of structures from measured volume data, such as anatomy in medical imaging, is a challenging data-dependent task. In this paper, we present a segmentation method that leverages the parallel processing capabilities of modern programmable graphics hardware in order to run significantly faster than previous methods. In addition, collocating the algorithm computation with the visualization on the graphics hardware circumvents the need to transfer data across the system bus, allowing for faster visualization and interaction. This algorithm is unique in that it utilizes sophisticated graphics hardware functionality (i.e., floating point precision, render to texture, computational masking, and fragment programs) to enable fast segmentation and interactive visualization.\\\",\\\"Authors\\\":\\\"Sherbondy, A.;Houston, M.;Napel, S.\\\",\\\"Clusters\\\":\\\"DiffusionRelatedTechniques;GpuBasedTechniques;ImageBasedDataImageSignalProcessing;SegmentationAndClassification;StreamingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250369\\\",\\\"Keywords\\\":\\\"streaming computation;segmentation;graphics processor;diffusion;region growing\\\",\\\"Keywords_Processed\\\":\\\"graphic processor;segmentation;region growing;stream computation;diffusion\\\",\\\"Title\\\":\\\"Fast volume segmentation with simultaneous visualization using programmable graphics hardware\\\"},\\\"40\\\":{\\\"Abstract\\\":\\\"We present improved subdivision and isosurface reconstruction algorithms for polygonizing implicit surfaces and performing accurate geometric operations. Our improved reconstruction algorithm uses directed distance fields (Kobbelt et al., 2001) to detect multiple intersections along an edge, separates them into components and reconstructs an isosurface locally within each components using the dual contouring algorithm (Ju et al., 2002). It can reconstruct thin features without creating handles and results in improved surface extraction from volumetric data. Our subdivision algorithm takes into account sharp features that arise from intersecting surfaces or Boolean operations and generates an adaptive grid such that each voxel has at most one sharp feature. The subdivision algorithm is combined with our improved reconstruction algorithm to compute accurate polygonization of Boolean combinations or offsets of complex primitives that faithfully reconstruct the sharp features. We have applied these algorithms to polygonize complex CAD models designed using thousands of Boolean operations on curved primitives.\\\",\\\"Authors\\\":\\\"Varadhan, G.;Shankar Krishnan;Kim, Y.J.;Manocha, D.\\\",\\\"Clusters\\\":\\\"GeometricModeling;IsosurfaceAndSurfaceExtractionTechniques;NumericalMethodsMathematics;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250360\\\",\\\"Keywords\\\":\\\"distance field;implicit modeling;subdivision;marching cubes;boolean operations\\\",\\\"Keywords_Processed\\\":\\\"march cube;distance field;boolean operation;implicit model;subdivision\\\",\\\"Title\\\":\\\"Feature-sensitive subdivision and isosurface reconstruction\\\"},\\\"41\\\":{\\\"Abstract\\\":\\\"Unstructured meshes are often used in simulations and imaging applications. They provide advanced flexibility in modeling abilities but are more difficult to manipulate and analyze than regular data. This work provides a novel approach for the analysis of unstructured meshes using feature-space clustering and feature-detection. Analyzing and revealing underlying structures in data involve operators on both spatial and functional domains. Slicing concentrates more on the spatial domain, while iso-surfacing or volume rendering concentrate more on the functional domain. Nevertheless, many times it is the combination of the two domains which provides real insight on the structure of the data. In this work, a combined feature-space is defined on top of unstructured meshes in order to search for structure in the data. A point in feature-space includes the spatial coordinates of the point in the mesh domain and all chosen attributes defined on the mesh. A distance measures between points in feature-space is defined enabling the utilization of clustering using the mean shift procedure (previously used for images) on unstructured meshes. Feature space analysis is shown to be useful for feature-extraction, for data exploration and partitioning.\\\",\\\"Authors\\\":\\\"Shamir, A.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;DataClusteringAndAggregation;ImageBasedDataImageSignalProcessing;MeshesGridsAndLattices;SegmentationAndClassification\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250371\\\",\\\"Keywords\\\":\\\"clustering;mean-shift;segmentation;unstructured meshes;feature extraction\\\",\\\"Keywords_Processed\\\":\\\"feature extraction;unstructured mesh;segmentation;mean shift;clustering\\\",\\\"Title\\\":\\\"Feature-space analysis of unstructured meshes\\\"},\\\"42\\\":{\\\"Abstract\\\":\\\"An equity mutual fund is a financial instrument that invests in a set of stocks. Any two different funds may partially invest in some of the same stocks, thus overlap is common. Portfolio diversification aims at spreading an investment over many different stocks in search of greater returns. Helping people with portfolio diversification is challenging because it requires informing them about both their current portfolio of stocks held through funds and the other stocks in the market not invested in yet. Current stock/fund visualization systems either waste screen real estate and visualization of all data points. We have developed a system called FundExplorer that implements a distorted treemap to visualize both the amount of money invested in a person's fund portfolio and the context of remaining market stocks. The FundExplorer system enables people to interactively explore diversification possibilities with their portfolios.\\\",\\\"Authors\\\":\\\"Csallner, C.;Handte, M.;Lehmann, O.;Stasko, J.\\\",\\\"Clusters\\\":\\\"BusinessFinanceEconomyManufacturing;FocusContextTechniques;HierarchicalTreeDataAndTechniques;QueriesAndSearch;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249027\\\",\\\"Keywords\\\":\\\"information visualization;context;query;treemap;financial data;distortion;fundexplore;stock market\\\",\\\"Keywords_Processed\\\":\\\"stock market;financial datum;treemap;fundexplore;information visualization;query;distortion;context\\\",\\\"Title\\\":\\\"FundExplorer: supporting the diversification of mutual fund portfolios using context treemaps\\\"},\\\"43\\\":{\\\"Abstract\\\":\\\"Volume rendering is a flexible technique for visualizing dense 3D volumetric datasets. A central element of volume rendering is the conversion between data values and observable quantities such as color and opacity. This process is usually realized through the use of transfer functions that are precomputed and stored in lookup tables. For multidimensional transfer functions applied to multivariate data, these lookup tables become prohibitively large. We propose the direct evaluation of a particular type of transfer functions based on a sum of Gaussians. Because of their simple form (in terms of number of parameters), these functions and their analytic integrals along line segments can be evaluated efficiently on current graphics hardware, obviating the need for precomputed lookup tables. We have adopted these transfer functions because they are well suited for classification based on a unique combination of multiple data values that localize features in the transfer function domain. We apply this technique to the visualization of several multivariate datasets (CT, cryosection) that are difficult to classify and render accurately at interactive rates using traditional approaches.\\\",\\\"Authors\\\":\\\"Kniss, J.;Premoze, S.;Ikits, M.;Lefohn, A.;Hansen, C.;Praun, E.\\\",\\\"Clusters\\\":\\\"MultidimensionalMultivariateMultifieldDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250412\\\",\\\"Keywords\\\":\\\"volume rendering;transfer function;multi-field visualization\\\",\\\"Keywords_Processed\\\":\\\"volume render;multi field visualization;transfer function\\\",\\\"Title\\\":\\\"Gaussian transfer functions for multi-field volume visualization\\\"},\\\"44\\\":{\\\"Abstract\\\":\\\"Non-linear filtering is an important task for volume analysis. This paper presents hardware-based implementations of various non-linear filters for volume smoothing with edge preservation. The Cg high-level shading language is used in combination with latest PC consumer graphics hardware. Filtering is divided into pervertex and per-fragment stages. In both stages we propose techniques to increase the filtering performance. The vertex program pre-computes texture coordinates in order to address all contributing input samples of the operator mask. Thus additional computations are avoided in the fragment program. The presented fragment programs preserve cache coherence, exploit 4D vector arithmetic, and internal fixed point arithmetic to increase performance. We show the applicability of non-linear filters as part of a GPU-based segmentation pipeline. The resulting binary mask is compressed and decompressed in the graphics memory on-the-fly.\\\",\\\"Authors\\\":\\\"Viola, I.;Kanitsar, A.;Groller, E.\\\",\\\"Clusters\\\":\\\"FilteringTechniques;HardwareAccellerationAndComputationGeneral;SegmentationAndClassification\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250387\\\",\\\"Keywords\\\":\\\"non-linear filtering;hardware acceleration;segmentation\\\",\\\"Keywords_Processed\\\":\\\"non linear filtering;segmentation;hardware acceleration\\\",\\\"Title\\\":\\\"Hardware-based nonlinear filtering and segmentation using high-level shading languages\\\"},\\\"45\\\":{\\\"Abstract\\\":\\\"We present the first implementation of a volume ray casting algorithm for tetrahedral meshes running on off-the-shelf programmable graphics hardware. Our implementation avoids the memory transfer bottleneck of the graphics bus since the complete mesh data is stored in the local memory of the graphics adapter and all computations, in particular ray traversal and ray integration, are performed by the graphics processing unit. Analogously to other ray casting algorithms, our algorithm does not require an expensive cell sorting. Provided that the graphics adapter offers enough texture memory, our implementation performs comparable to the fastest published volume rendering algorithms for unstructured meshes. Our approach works with cyclic and/or non-convex meshes and supports early ray termination. Accurate ray integration is guaranteed by applying pre-integrated volume rendering. In order to achieve almost interactive modifications of transfer functions, we propose a new method for computing three-dimensional pre-integration tables.\\\",\\\"Authors\\\":\\\"Weiler, M.;Kraus, M.;Merz, M.;Ertl, T.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;GpuBasedTechniques;MeshesGridsAndLattices;RaytracingRaycasting;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250390\\\",\\\"Keywords\\\":\\\"cell projection;tetrahedral meshes;volume visualization;raycasting;programmable graphics hardware;pixel shader;unstructured meshes;pre-integrated volume rendering\\\",\\\"Keywords_Processed\\\":\\\"tetrahedral mesh;programmable graphic hardware;pre integrated volume render;unstructured mesh;raycaste;pixel shader;volume visualization;cell projection\\\",\\\"Title\\\":\\\"Hardware-based ray casting for tetrahedral meshes\\\"},\\\"46\\\":{\\\"Abstract\\\":\\\"In this paper we use advanced tensor visualization techniques to study 3D diffusion tensor MRI data of a heart. We use scalar and tensor glyph visualization methods to investigate the data and apply a moving least squares (MLS) fiber tracing method to recover and visualize the helical structure and the orientation of the heart muscle fibers.\\\",\\\"Authors\\\":\\\"Zhukov, L.;Barr, A.\\\",\\\"Clusters\\\":\\\"FilteringTechniques;NumericalMethodsMathematics;StreamlinesPathlinesStreaklines;TensorDataAndTechniques;Tractography\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250425\\\",\\\"Keywords\\\":\\\"moving least squares;diffusion tensor mri;adaptive filtering;streamlines;diffusion tensor;fiber tracing\\\",\\\"Keywords_Processed\\\":\\\"diffusion tensor;streamline;adaptive filtering;fiber tracing;diffusion tensor mri;move least square\\\",\\\"Title\\\":\\\"Heart-muscle fiber reconstruction from diffusion tensor MRI\\\"},\\\"47\\\":{\\\"Abstract\\\":\\\"Numerical particle simulations and astronomical observations create huge data sets containing uncorrelated 3D points of varying size. These data sets cannot be visualized interactively by simply rendering millions of colored points for each frame. Therefore, in many visualization applications a scalar density corresponding to the point distribution is resampled on a regular grid for direct volume rendering. However, many fine details are usually lost for voxel resolutions which still allow interactive visualization on standard workstations. Since no surface geometry is associated with our data sets, the recently introduced point-based rendering algorithms cannot be applied as well. In this paper we propose to accelerate the visualization of scattered point data by a hierarchical data structure based on a PCA clustering procedure. By traversing this structure for each frame we can trade-off rendering speed vs. image quality. Our scheme also reduces memory consumption by using quantized relative coordinates and it allows for fast sorting of semi-transparent clusters. We analyze various software and hardware implementations of our renderer and demonstrate that we can now visualize data sets with tens of millions of points interactively with sub-pixel screen space error on current PC graphics hardware employing advanced vertex shader functionality.\\\",\\\"Authors\\\":\\\"Hopf, M.;Ertl, T.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;DataFeaturesAndAttributes;HierarchicalTreeDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250404\\\",\\\"Keywords\\\":\\\"splatting;hierarchy visualization;volume rendering;scattered data\\\",\\\"Keywords_Processed\\\":\\\"volume render;hierarchy visualization;splatte;scatter datum\\\",\\\"Title\\\":\\\"Herarchical splatting of scattered data\\\"},\\\"48\\\":{\\\"Abstract\\\":\\\"We present a method to represent unstructured scalar fields at multiple levels of detail. Using a parallelizable classification algorithm to build a cluster hierarchy, we generate a multiresolution representation of a given volumetric scalar data set. The method uses principal component analysis (PCA) for cluster generation and a fitting technique based on radial basis functions (RBFs). Once the cluster hierarchy has been generated, we utilize a variety of techniques for extracting different levels of detail. The main strength of this work is its generality. Regardless of grid type, this method can be applied to any discrete scalar field representation, even one given as a \\\\\\\"point cloud\\\\\\\".\\\",\\\"Authors\\\":\\\"Co, C.S.;Heckel, B.;Hagen, H.;Hamann, B.;Joy, K.I.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;DimensionalityReduction;MultiresolutionTechniques;NumericalMethodsMathematics;ScalarFieldDataTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250389\\\",\\\"Keywords\\\":\\\"hierarchical clustering;multi-resolution representation;scalar field simplification;principal component analysis;radial basis functions\\\",\\\"Keywords_Processed\\\":\\\"multi resolution representation;principal component analysis;hierarchical clustering;radial basis function;scalar field simplification\\\",\\\"Title\\\":\\\"Hierarchical clustering for unstructured volumetric scalar fields\\\"},\\\"49\\\":{\\\"Abstract\\\":\\\"We present an alternative method for viewing time-varying volumetric data. We consider such data as a four-dimensional data field, rather than considering space and time as separate entities. If we treat the data in this manner, we can apply high dimensional slicing and projection techniques to generate an image hyperplane. The user is provided with an intuitive user interface to specify arbitrary hyperplanes in 4D, which can be displayed with standard volume rendering techniques. From the volume specification, we are able to extract arbitrary hyperslices, combine slices together into a hyperprojection volume, or apply a 4D raycasting method to generate the same results. In combination with appropriate integration operators and transfer functions, we are able to extract and present different space-time features to the user.\\\",\\\"Authors\\\":\\\"Woodring, J.;Chaoli Wang;Han-Wei Shen\\\",\\\"Clusters\\\":\\\"DataTransformation;InteractionTechniquesGeneral;NumericalMethodsMathematics;RaytracingRaycasting;TimeseriesTimeVaryingDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250402\\\",\\\"Keywords\\\":\\\"volume rendering;time-varying data;integration operator;transfer function;hyperslice;hyperprojection;raycasting\\\",\\\"Keywords_Processed\\\":\\\"volume render;time vary datum;hyperslice;raycaste;integration operator;transfer function;hyperprojection\\\",\\\"Title\\\":\\\"High dimensional direct rendering of time-varying volumetric data\\\"},\\\"50\\\":{\\\"Abstract\\\":\\\"One of the most important goals in volume rendering is to be able to visually separate and selectively enable specific objects of interest contained in a single volumetric data set, which can be approached by using explicit segmentation information. We show how segmented data sets can be rendered interactively on current consumer graphics hardware with high image quality and pixel-resolution filtering of object boundaries. In order to enhance object perception, we employ different levels of object distinction. First, each object can be assigned an individual transfer function, multiple of which can be applied in a single rendering pass. Second, different rendering modes such as direct volume rendering, iso-surfacing, and non-photorealistic techniques can be selected for each object. A minimal number of rendering passes is achieved by processing sets of objects that share the same rendering mode in a single pass. Third, local compositing modes such as alpha blending and MIP can be selected for each object in addition to a single global mode, thus enabling high-quality two-level volume rendering on GPUs.\\\",\\\"Authors\\\":\\\"Hadwiger, M.;Berger, C.;Hauser, H.\\\",\\\"Clusters\\\":\\\"IllustrativeVisualization;InputAndOutputDevicesGeneral;SegmentationAndClassification;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250386\\\",\\\"Keywords\\\":\\\"consumer graphics hardware;volume rendering;segmentation;non-photorealistic rendering\\\",\\\"Keywords_Processed\\\":\\\"volume render;non photorealistic rendering;consumer graphic hardware;segmentation\\\",\\\"Title\\\":\\\"High-quality two-level volume rendering of segmented data sets on consumer graphics hardware\\\"},\\\"51\\\":{\\\"Abstract\\\":\\\"We describe an animated electro-holographic visualization of brain lesions due to the progression of multiple sclerosis. A research case study is used which documents the expression of visible brain lesions in a series of magnetic resonance imaging (MRI) volumes collected over the interval of one year. Some of the salient information resident within this data is described, and the motivation for using a dynamic spatial display to explore its spatial and temporal characteristics is stated. We provide a brief overview of spatial displays in medical imaging applications, and then describe our experimental visualization pipeline, from the processing of MRI datasets, through model construction, computer graphic rendering, and hologram encoding. The utility, strengths and shortcomings of the electro-holographic visualization are described and future improvements are suggested.\\\",\\\"Authors\\\":\\\"Plesniak, W.;Halle, M.;Pieper, S.D.;Wells, W.;Jakab, M.;Meier, D.S.;Benton, S.A.;Guttmann, R.G.;Kikinis, R.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DisplaysGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250424\\\",\\\"Keywords\\\":\\\"computer-generated holograms;holographic video;autostereoscopic display;electro-holography;medical imaging\\\",\\\"Keywords_Processed\\\":\\\"holographic video;autostereoscopic display;medical imaging;computer generate hologram;electro holography\\\",\\\"Title\\\":\\\"Holographic video display of time-series volumetric medical data\\\"},\\\"52\\\":{\\\"Abstract\\\":\\\"Segmentation of the tracheo-bronchial tree of the lungs is notoriously difficult. This is due to the fact that the small size of some of the anatomical structures is subject to partial volume effects. Furthermore, the limited intensity contrast between the participating materials (air, blood, and tissue) increases the segmentation of difficulties. In this paper, we propose a hybrid segmentation method which is based on a pipeline of three segmentation stages to extract the lower airways down to the seventh generation of the bronchi. User interaction is limited to the specification of a seed point inside the easily detectable trachea at the upper end of the lower airways. Similarly, the complementary vascular tree of the lungs can be segmented. Furthermore, we modified our virtual endoscopy system to visualize the vascular and airway system of the lungs along with other features, such as lung tumors.\\\",\\\"Authors\\\":\\\"Bartz, D.;Mayer, D.;Fischer, J.;Ley, S.;del Rio, A.;Thust, S.;Heussel, C.P.;Kauczor, H.-U.;Strasser, W.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;SegmentationAndClassification\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250370\\\",\\\"Keywords\\\":\\\"multi-slice ct;tracheo-bronchial tree;virtual endoscopy;segmentation\\\",\\\"Keywords_Processed\\\":\\\"virtual endoscopy;segmentation;tracheo bronchial tree;multi slice ct\\\",\\\"Title\\\":\\\"Hybrid segmentation and exploration of the human lungs\\\"},\\\"53\\\":{\\\"Abstract\\\":\\\"We introduce a new method for visualizing symmetric tensor fields. The technique produces images and animations reminiscent of line integral convolution (LIC). The technique is also slightly related to hyperstreamlines in that it is used to visualize tensor fields. However, the similarity ends there. HyperLIC uses a multi-pass approach to show the anisotropic properties in a 2D or 3D tensor field. We demonstrate this technique using data sets from computational fluid dynamics as well as diffusion-tensor MRI.\\\",\\\"Authors\\\":\\\"Zheng, X.;Pang, A.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;FlowVisualizationDataAndTechniques;StreamlinesPathlinesStreaklines;TensorDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250379\\\",\\\"Keywords\\\":\\\"hyperstreamlines;symmetric tensors;anisotropy;direct volume rendering;line integral convolution;animation\\\",\\\"Keywords_Processed\\\":\\\"line integral convolution;hyperstreamline;animation;direct volume render;anisotropy;symmetric tensor\\\",\\\"Title\\\":\\\"HyperLIC\\\"},\\\"54\\\":{\\\"Abstract\\\":\\\"A new method for the synthesis of dense, vector-field aligned textures on curved surfaces is presented, called IBFVS. The method is based on image based flow visualization (IBFV). In IBFV two-dimensional animated textures are produced by defining each frame of a flow animation as a blend between a warped version of the previous image and a number of filtered white noise images. We produce flow aligned texture on arbitrary three-dimensional triangular meshes in the same spirit as the original method: texture is generated directly in image space. We show that IBFVS is efficient and effective. High performance (typically fifty frames or more per second) is achieved by exploiting graphics hardware. Also, IBFVS can easily be implemented and a variety of effects can be achieved. Applications are flow visualization and surface rendering. Specifically, we show how to visualize the wind field on the earth and how to render a dirty bronze bunny.\\\",\\\"Authors\\\":\\\"van Wijk, J.J.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;SurfaceRelatedDataAndTechniques;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250363\\\",\\\"Keywords\\\":\\\"flow visualization;surface rendering;line integral convolution;texture mapping\\\",\\\"Keywords_Processed\\\":\\\"surface render;line integral convolution;texture mapping;flow visualization\\\",\\\"Title\\\":\\\"Image based flow visualization for curved surfaces\\\"},\\\"55\\\":{\\\"Abstract\\\":\\\"We present a technique for direct visualization of unsteady flow on surfaces from computational fluid dynamics. The method generates dense representations of time-dependent vector fields with high spatio-temporal correlation using both Lagrangian-Eulerian advection and image based flow visualization as its foundation. While the 3D vector fields are associated with arbitrary triangular surface meshes, the generation and advection of texture properties is confined to image space. Frame rates of up to 20 frames per second are realized by exploiting graphics card hardware. We apply this algorithm to unsteady flow on boundary surfaces of, large, complex meshes from computational fluid dynamics composed of more than 250,000 polygons, dynamic meshes with time-dependent geometry and topology, as well as medical data.\\\",\\\"Authors\\\":\\\"Laramee, R.S.;Jobard, B.;Hauser, H.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;SurfaceRelatedDataAndTechniques;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250364\\\",\\\"Keywords\\\":\\\"texture mapping;computational fluid dynamics;surface representation;unsteady flow visualization\\\",\\\"Keywords_Processed\\\":\\\"unsteady flow visualization;computational fluid dynamic;texture mapping;surface representation\\\",\\\"Title\\\":\\\"Image space based visualization of unsteady flow on surfaces\\\"},\\\"56\\\":{\\\"Abstract\\\":\\\"An algorithm is presented for the visualisation of multidimensional abstract data, building on a hybrid model introduced at InfoVis 2002. The most computationally complex stage of the original model involved performing a nearest-neighbour search for every data item. The complexity of this phase has been reduced by treating all high-dimensional relationships as a set of discretised distances to a constant number of randomly selected pivot items. In improving this computational bottleneck, the complexity is reduced from O(N v N) to O(N 5 4 ). As well as documenting this improvement, the paper describes evaluation with a data set of 108000 14-dimensional items; a considerable increase on the size of data previously tested. Results illustrate that the reduction in complexity is reflected in significantly improved run times and that no negative impact is made upon the quality of layout produced\\\",\\\"Authors\\\":\\\"Morrison, A.;Chalmers, M.\\\",\\\"Clusters\\\":\\\"DimensionalityReduction;GraphNetworkDataAndTechniques;InteractionTechniquesGeneral;ProgrammingAlgorithmsAndDataStructures;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249012\\\",\\\"Keywords\\\":\\\"multi-dimensional scaling;pivots;force-directed placement;hybrid algorithms;near-neighbour search;spring models\\\",\\\"Keywords_Processed\\\":\\\"pivot;spring model;near neighbour search;hybrid algorithm;multi dimensional scaling;force direct placement\\\",\\\"Title\\\":\\\"Improving Hybrid MDS with Pivot-Based Searching\\\"},\\\"57\\\":{\\\"Abstract\\\":\\\"Large and high-dimensional data sets mapped to low-dimensional visualizations often result in perceptual ambiguities. One such ambiguity is overlap or occlusion that occurs when the number of records exceeds the number of unique locations in the presentation or when there exist two or more records that map to the same location. To lessen the affect of occlusion, non-standard visual attributes (i.e. shading and/or transparency) are applied, or such records may be remapped to a corresponding jittered location. The resulting mapping efficiently portrays the crowding of records but fails to provide the insight into the relationship between the neighboring records. We introduce a new interactive technique that intelligibly organizes overlapped points, a neural network-based smart jittering algorithm. We demonstrate this technique on a scatter plot, the most widely used visualization. The algorithm can be applied to other one, two, and multi-dimensional visualizations which represent data as points, including 3-dimensional scatter plots, RadViz, polar coordinates.\\\",\\\"Authors\\\":\\\"Trutschl, M.;Grinstein, G.;Cvek, U.\\\",\\\"Clusters\\\":\\\"DataAcquisitionAndManagement;MachineLearningAndStatistics;OcclusionProblemsTechniques;Perception;PointBasedDataAndTechniques;VisualDesignDesignGuidelines\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249018\\\",\\\"Keywords\\\":\\\"information visualization;data density;data points;jitter;neural networks;occlusion;visualization;identifiable points;design\\\",\\\"Keywords_Processed\\\":\\\"visualization;datum point;information visualization;identifiable point;neural network;design;jitter;occlusion;data density\\\",\\\"Title\\\":\\\"Intelligently resolving point occlusion\\\"},\\\"58\\\":{\\\"Abstract\\\":\\\"Simulation of rigid body dynamics has been a field of active research for quite some time. However, the presentation of simulation results has received far less attention so far. We present an interactive and intuitive 3D visualization framework for rigid body simulation data. We introduce various glyphs representing vector attributes such as force and velocity as well as angular attributes including angular velocity and torque. We have integrated our visualization method into an application developed at one of the leading companies in automotive engine design and simulation. We apply our principles to visualization of chain and belt driven timing drives in engines.\\\",\\\"Authors\\\":\\\"Konyha, Z.;Matkovic, K.;Hauser, H.\\\",\\\"Clusters\\\":\\\"Engineering;GlyphsGlyphBasedTechniques;PhysicsAndPhysicalSciences;Simulation\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250417\\\",\\\"Keywords\\\":\\\"automotive industry;glyph-based visualization;rigid body simulation;iconic visualization;rigid body dynamics\\\",\\\"Keywords_Processed\\\":\\\"automotive industry;rigid body dynamic;iconic visualization;glyph base visualization;rigid body simulation\\\",\\\"Title\\\":\\\"Interactive 3D visualization of rigid body systems\\\"},\\\"59\\\":{\\\"Abstract\\\":\\\"Deformable isosurfaces, implemented with level-set methods, have demonstrated a great potential in visualization for applications such as segmentation, surface processing, and surface reconstruction. Their usefulness has been limited, however, by their high computational cost and reliance on significant parameter tuning. This paper presents a solution to these challenges by describing graphics processor (GPU) based on algorithms for solving and visualizing level-set solutions at interactive rates. Our efficient GPU-based solution relies on packing the level-set isosurface data into a dynamic, sparse texture format. As the level set moves, this sparse data structure is updated via a novel GPU to CPU message passing scheme. When the level-set solver is integrated with a real-time volume renderer operating on the same packed format, a user can visualize and steer the deformable level-set surface as it evolves. In addition, the resulting isosurface can serve as a region-of-interest specifier for the volume renderer. This paper demonstrates the capabilities of this technology for interactive volume visualization and segmentation.\\\",\\\"Authors\\\":\\\"Lefohn, A.;Kniss, J.;Hansen, C.;Whitaker, R.T.\\\",\\\"Clusters\\\":\\\"GeometricModeling;GpuBasedTechniques;NumericalMethodsMathematics;SegmentationAndClassification;StreamingDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250357\\\",\\\"Keywords\\\":\\\"streaming computation;level sets;deformable models;volume visualization;gpu;image segmentation\\\",\\\"Keywords_Processed\\\":\\\"level set;stream computation;image segmentation;deformable model;volume visualization;gpu\\\",\\\"Title\\\":\\\"Interactive deformation and visualization of level set surfaces using graphics hardware\\\"},\\\"60\\\":{\\\"Abstract\\\":\\\"Large number of dimensions not only cause clutter in multi-dimensional visualizations, but also make it difficult for users to navigate the data space. Effective dimension management, such as dimension ordering, spacing and filtering, is critical for visual exploration of such datasets. Dimension ordering and spacing explicitly reveal dimension relationships in arrangement-sensitive multidimensional visualization techniques, such as parallel coordinates, star glyphs, and pixel-oriented techniques. They facilitate the visual discovery of patterns within the data. Dimension filtering hides some of the dimensions to reduce clutter while preserving the major information of the dataset. In this paper, we propose an interactive hierarchical dimension ordering, spacing and filtering approach, called DOSFA. DOSFA is based on dimension hierarchies derived from similarities among dimensions. It is scalable multi-resolution approach making dimensional management a tractable task. On the one hand, it automatically generates default settings for dimension ordering, spacing and filtering. On the other hand, it allows users to efficiently control all aspects of this dimension management process via visual interaction tools for dimension hierarchy manipulation. A case study visualizing a dataset containing over 200 dimensions reveals high dimensional visualization techniques.\\\",\\\"Authors\\\":\\\"Jing Yang;Wei Peng;Ward, M.O.;Rundensteiner, E.A.\\\",\\\"Clusters\\\":\\\"FilteringTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249015\\\",\\\"Keywords\\\":\\\"dimension filtering;high-dimensional data;dimension ordering;multi-dimensional visualization;dimension spacing\\\",\\\"Keywords_Processed\\\":\\\"multi dimensional visualization;dimension filtering;high dimensional datum;dimension spacing;dimension ordering\\\",\\\"Title\\\":\\\"Interactive hierarchical dimension ordering, spacing and filtering for exploration of high dimensional datasets\\\"},\\\"61\\\":{\\\"Abstract\\\":\\\"We describe an interactive visualization and modeling program for the creation of protein structures \\\\\\\"from scratch.\\\\\\\" The input to our program is an amino acid sequence - decoded from a gene - and a sequence of predicted secondary structure types for each amino acid - provided by external structure prediction programs. Our program can be used in the set-up phase of a protein structure prediction process; the structures created with it serve as input for a subsequent global internal energy minimization, or another method of protein structure prediction. Our program supports basic visualization methods for protein structures, interactive manipulation based on inverse kinematics, and visualization guides to aid a user in creating \\\\\\\"good\\\\\\\" initial structures.\\\",\\\"Authors\\\":\\\"Kreylos, O.;Max, N.;Hamann, B.;Crivelli, S.N.;Bethel, E.W.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;ApplicationsGeneralAndOther;InteractionTechniquesGeneral;MolecularScienceAndChemistry\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250423\\\",\\\"Keywords\\\":\\\"interactive visualization;inverse kinematics;computational science;molecular visualization;protein manipulation;molecular modeling;protein structure prediction\\\",\\\"Keywords_Processed\\\":\\\"inverse kinematic;molecular visualization;protein manipulation;molecular modeling;protein structure prediction;interactive visualization;computational science\\\",\\\"Title\\\":\\\"Interactive protein manipulation\\\"},\\\"62\\\":{\\\"Abstract\\\":\\\"This paper presents an algorithm combining view-dependent rendering and conservative occlusion culling for interactive display of complex environments. A vertex hierarchy of the entire scene is decomposed into a cluster hierarchy through a novel clustering and partitioning algorithm. The cluster hierarchy is then used for view-frustum and occlusion culling. Using hardware accelerated occlusion queries and frame-to-frame coherence, a potentially visible set of clusters is computed. An active vertex front and face list is computed from the visible clusters and rendered using vertex arrays. The integrated algorithm has been implemented on a Pentium IV PC with a NVIDIA GeForce 4 graphics card and applied in two complex environments composed of millions of triangles. The resulting system can render these environments at interactive rates with little loss in image quality and minimal popping artifacts.\\\",\\\"Authors\\\":\\\"Yoon, S.-E.;Salomon, B.;Manocha, D.\\\",\\\"Clusters\\\":\\\"DesignMethodologiesAndInteractionDesign;HierarchicalTreeDataAndTechniques;LevelOfDetail;OcclusionProblemsTechniques;ViewDependentVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250368\\\",\\\"Keywords\\\":\\\"level-of-detail;multi-resolution hierarchies;view-dependent rendering;occlusion culling;interactive display\\\",\\\"Keywords_Processed\\\":\\\"occlusion cull;multi resolution hierarchy;view dependent rendering;interactive display;level of detail\\\",\\\"Title\\\":\\\"Interactive view-dependent rendering with conservative occlusion culling in complex environments\\\"},\\\"63\\\":{\\\"Abstract\\\":\\\"In this paper we show how out-of-core mesh processing techniques can be adapted to perform their computations based on the new processing sequence paradigm (Isenburg, et al., 2003), using mesh simplification as an example. We believe that this processing concept will also prove useful for other tasks, such a parameterization, remeshing, or smoothing, for which currently only in-core solutions exist. A processing sequence represents a mesh as a particular interleaved ordering of indexed triangles and vertices. This representation allows streaming very large meshes through main memory while maintaining information about the visitation status of edges and vertices. At any time, only a small portion of the mesh is kept in-core, with the bulk of the mesh data residing on disk. Mesh access is restricted to a fixed traversal order, but full connectivity and geometry information is available for the active elements of the traversal. This provides seamless and highly efficient out-of-core access to very large meshes for algorithms that can adapt their computations to this fixed ordering. The two abstractions that are naturally supported by this representation are boundary-based and buffer-based processing. We illustrate both abstractions by adapting two different simplification methods to perform their computation using a prototype of our mesh processing sequence API. Both algorithms benefit from using processing sequences in terms of improved quality, more efficient execution, and smaller memory footprints.\\\",\\\"Authors\\\":\\\"Isenburg, M.;Lindstrom, P.;Gumhold, S.;Snoeyink, J.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;MeshesGridsAndLattices;OutOfCoreProcessing;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250408\\\",\\\"Keywords\\\":\\\"large meshes;mesh simplification;out-of-core algorithm;processing sequences\\\",\\\"Keywords_Processed\\\":\\\"processing sequence;out of core algorithm;mesh simplification;large mesh\\\",\\\"Title\\\":\\\"Large mesh simplification using processing sequences\\\"},\\\"64\\\":{\\\"Abstract\\\":\\\"LightKit is a system for lighting three-dimensional synthetic scenes. LightKit simplifies the task of producing visually pleasing, easily interpretable images for visualization while making it harder to produce results where the scene illumination distracts from the visualization process. LightKit is based on lighting designs developed by artists and photographers and shown in previous studies to enhance shape perception. A key light provides natural overhead illumination of the scene, augmented by fill, head, and back lights. By default, lights are attached to a normalized, subject-centric, camera-relative coordinate frame to ensure consistent lighting independent of camera location or orientation. This system allows all lights to be positioned by specifying just six parameters. The intensity of each light is specified as a ratio to the key light intensity, allowing the scene's brightness to be adjusted using a single parameter. The color of each light is specified by a single normalized color parameter called warmth that is based on color temperature of natural sources. LightKit's default values for light position, intensity, and color are chosen to produce good results for a variety of scenes. LightKit is designed to work with both hardware graphics systems and, potentially, higher quality off-line rendering systems. We provide examples of images created using a LightKit implementation within the VTK visualization toolkit software framework.\\\",\\\"Authors\\\":\\\"Halle, M.;Meng, J.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;Illumination;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250395\\\",\\\"Keywords\\\":\\\"visualization;light color;lighting design\\\",\\\"Keywords_Processed\\\":\\\"visualization;lighting design;light color\\\",\\\"Title\\\":\\\"LightKit: a lighting system for effective visualization\\\"},\\\"65\\\":{\\\"Abstract\\\":\\\"Data sets with a large number of nominal variables, some with high cardinality, are becoming increasingly common and need to be explored. Unfortunately, most existing visual exploration displays are designed to handle numeric variables only. When importing data sets with nominal values into such visualization tools, most solutions to date are rather simplistic. Often, techniques that map nominal values to numbers do not assign order or spacing among the values in a manner that conveys semantic relationships. Moreover, displays designed for nominal variables usually cannot handle high cardinality variables well. This paper addresses the problem of how to display nominal variables in general-purpose visual exploration tools designed for numeric variables. Specifically, we investigate (1) how to assign order and spacing among the nominal values, and (2) how to reduce the number of distinct values to display. We propose that nominal variables be pre-processed using a distance-quantification-classing (DQC) approach before being imported into a visual exploration tool. In the distance step, we identify a set of independent dimensions that can be used to calculate the distance between nominal values. In the quantification step, we use the independent dimensions and the distance information to assign order and spacing among the nominal values. In the classing step, we use results from the previous steps to determine which values within a variable are similar to each other and thus can be grouped together. Each step in the DQC approach can be accomplished by a variety of techniques. We extended the XmdvTool package to incorporate this approach. We evaluated our approach on several data sets using a variety of evaluation measures.\\\",\\\"Authors\\\":\\\"Rosario, G.E.;Rundensteiner, E.A.;Brown, D.C.;Ward, M.O.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;DataTypesGeneral;DimensionalityReduction;EvaluationGeneral;SegmentationAndClassification;TasksTaskRequirementsAnalysis;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249016\\\",\\\"Keywords\\\":\\\"quantification;clustering;dimension reduction;visualization;correspondence analysis;nominal data;classing\\\",\\\"Keywords_Processed\\\":\\\"visualization;quantification;class;correspondence analysis;nominal datum;clustering;dimension reduction\\\",\\\"Title\\\":\\\"Mapping nominal values to numbers for effective visualization\\\"},\\\"66\\\":{\\\"Abstract\\\":\\\"We describe a modification of the widely used marching cubes method that leads to the useful property that the resulting isosurfaces are locally single valued functions. This implies that conventional interpolation and approximation methods can be used to locally represent the surface. These representations can be used for computing approximations for local surface properties. We utilize this possibility in order to develop algorithms for locally approximating Gaussian and mean curvature, methods for constrained smoothing of isosurface, and techniques for the parameterization of isosurfaces.\\\",\\\"Authors\\\":\\\"Nielson, G.M.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250355\\\",\\\"Keywords\\\":\\\"isosurface;triangular mesh;marching cubes\\\",\\\"Keywords_Processed\\\":\\\"march cube;isosurface;triangular mesh\\\",\\\"Title\\\":\\\"MC<sup>*</sup>: star functions for marching cubes\\\"},\\\"67\\\":{\\\"Abstract\\\":\\\"2D and 3D views are used together in many visualization domains, such as medical imaging, flow visualization, oceanographic visualization, and computer aided design (CAD). Combining these views into one display can be done by: (1) orientation icon (i.e., separate windows), (2) in-place methods (e.g., clip and cutting planes), and (3) a new method called ExoVis. How 2D and 3D views are displayed affects ease of mental registration (understanding the spatial relationship between views), an important factor influencing user performance. This paper compares the above methods in terms of their ability to support mental registration. Empirical results show that mental registration is significantly easier with in-place displays than with ExoVis, and significantly easier with ExoVis than with orientation icons. Different mental transformation strategies can explain this result. The results suggest that ExoVis may be a better alternative to orientation icons when in-place displays are not appropriate (e.g., when in-place methods hide data or cut the 3D view into several pieces).\\\",\\\"Authors\\\":\\\"Tory, M.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;Cognition;EvaluationGeneral;InteractionTechniquesGeneral;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250396\\\",\\\"Keywords\\\":\\\"2d and 3d visualization;orthographic projection;empirical study;slice;experiment;mental registration\\\",\\\"Keywords_Processed\\\":\\\"mental registration;experiment;empirical study;slice;2d and 3d visualization;orthographic projection\\\",\\\"Title\\\":\\\"Mental registration of 2D and 3D visualizations (an empirical study)\\\"},\\\"68\\\":{\\\"Abstract\\\":\\\"Graph and tree visualization techniques enable interactive exploration of complex relations while communicating topology. However, most existing techniques have not been designed for situations where visual information such as images is also present at each node and must be displayed. This paper presents MoireGraphs to address this need. MoireGraphs combine a new focus+context radial graph layout with a suite of interaction techniques (focus strength changing, radial rotation, level highlighting, secondary foci, animated transitions and node information) to assist in the exploration of graphs with visual nodes. The method is scalable to hundreds of displayed visual nodes.\\\",\\\"Authors\\\":\\\"Jankun-Kelly, T.J.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;GraphNetworkDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249009\\\",\\\"Keywords\\\":\\\"radial graph layout;information visualization;graph drawing;focus+context\\\",\\\"Keywords_Processed\\\":\\\"radial graph layout;graph drawing;information visualization;focus context\\\",\\\"Title\\\":\\\"MoireGraphs: radial focus+context visualization and interaction for graphs with visual nodes\\\"},\\\"69\\\":{\\\"Abstract\\\":\\\"In this paper a novel volume-rendering technique based on Monte Carlo integration is presented. As a result of a preprocessing, a point cloud of random samples is generated using a normalized continuous reconstruction of the volume as a probability density function. This point cloud is projected onto the image plane, and to each pixel an intensity value is assigned which is proportional to the number of samples projected onto the corresponding pixel area. In such a way a simulated X-ray image of the volume can be obtained. Theoretically, for a fixed image resolution, there exists an M number of samples such that the average standard deviation of the estimated pixel intensities us under the level of quantization error regardless of the number of voxels. Therefore Monte Carlo Volume Rendering (MCVR) is mainly proposed to efficiently visualize large volume data sets. Furthermore, network applications are also supported, since the trade-off between image quality and interactivity can be adapted to the bandwidth of the client/server connection by using progressive refinement.\\\",\\\"Authors\\\":\\\"Csebfalvi, B.;Szirmay-Kalos, L.\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;NumericalMethodsMathematics;Sampling;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250406\\\",\\\"Keywords\\\":\\\"x-ray volume rendering;importance sampling;progressive refinement;monte carlo integration\\\",\\\"Keywords_Processed\\\":\\\"ray volume render;progressive refinement;monte carlo integration;importance sample\\\",\\\"Title\\\":\\\"Monte Carlo volume rendering\\\"},\\\"70\\\":{\\\"Abstract\\\":\\\"Many networks under study in Information Visualization are \\\\\\\"small world\\\\\\\" networks. These networks first appeared in the study social networks and were shown to be relevant models in other application domains such as software reverse engineering and biology. Furthermore, many of these networks actually have a multiscale nature: they can be viewed as a network of groups that are themselves small world networks. We describe a metric that has been designed in order to identify the weakest edges in a small world network leading to an easy and low cost filtering procedure that breaks up a graph into smaller and highly connected components. We show how this metric can be exploited through an interactive navigation of the network based on semantic zooming. Once the network is decomposed into a hierarchy of sub-networks, a user can easily find groups and subgroups of actors and understand their dynamics.\\\",\\\"Authors\\\":\\\"Aubert, D.;Chiricota, Y.;Jourdan, F.;Melanon, G.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;GraphNetworkDataAndTechniques;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249011\\\",\\\"Keywords\\\":\\\"clustering metric;small world graphs;semantic zoom;multi-scale graphs\\\",\\\"Keywords_Processed\\\":\\\"small world graph;cluster metric;multi scale graph;semantic zoom\\\",\\\"Title\\\":\\\"Multiscale Visualization of Small World Networks\\\"},\\\"71\\\":{\\\"Abstract\\\":\\\"In this paper, we propose a novel out-of-core isosurface extraction technique for large time-varying fields over irregular grids. We employ our meta-cell technique to explore the spatial coherence of the data, and our time tree algorithm to consider the temporal coherence as well. Our one-time preprocessing phase first partitions the dataset into meta-cells that cluster spatially neighboring cells together and are stored in disk. We then build a time tree to index the meta-cells for fast isosurface extraction. The time tree takes advantage of the temporal coherence among the scalar values at different time steps, and uses BBIO trees as secondary structures, which are stored in disk and support I/O-optimal interval searches. The time tree algorithm employs a novel meta-interval collapsing scheme and the buffer technique, to take care of the temporal coherence in an I/O-efficient way. We further make the time tree cache-oblivious, so that searching on it automatically performs optimal number of block transfers between any two consecutive levels of memory hierarchy (such as between cache and main memory and between main memory and disk) simultaneously. At run-time, we perform optimal cache-oblivious searches in the time tree, together with I/O-optimal searches in the BBIO trees, to read the active meta-cells from disk and generate the queried isosurface efficiently. The experiments demonstrate the effectiveness of our new technique. In particular, compared with the query-optimal main-memory algorithm by Cignoni et al. (1997) (extended for time-varying fields) when there is not enough main memory, our technique can speed up the isosurface queries from more than 18 hours to less than 4 minutes.\\\",\\\"Authors\\\":\\\"Yi-Jen Chiang\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices;OutOfCoreProcessing;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250375\\\",\\\"Keywords\\\":\\\"isosurface extraction;irregular grids;time-varying fields;out-of-core techniques\\\",\\\"Keywords_Processed\\\":\\\"irregular grid;out of core technique;time vary field;isosurface extraction\\\",\\\"Title\\\":\\\"Out-of-core isosurface extraction of time-varying fields over irregular grids\\\"},\\\"72\\\":{\\\"Abstract\\\":\\\"This paper addresses the problem of surface reconstruction of highly noisy point clouds. The surfaces to be reconstructed are assumed to be 2-manifolds of piecewise C1 continuity, with isolated small irregular regions of high curvature, sophisticated local topology or abrupt burst of noise. At each sample point, a quadric field is locally fitted via a modified moving least squares method. These locally fitted quadric fields are then blended together to produce a pseudo-signed distance field using Shepard's method. We introduce a prioritized front growing scheme in the process of local quadrics fitting. Flatter surface areas tend to grow faster. The already fitted regions will subsequently guide the fitting of those irregular regions in their neighborhood.\\\",\\\"Authors\\\":\\\"Hui Xie;Wang, J.;Jing Hua;Hong Qin;Kaufman, A.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;GeometricModeling;Interpolation;NumericalMethodsMathematics;PointBasedDataAndTechniques;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250359\\\",\\\"Keywords\\\":\\\"solid modeling;moving least squares;computer graphics;point clouds;surface representation;surface reconstruction;shepard's method\\\",\\\"Keywords_Processed\\\":\\\"computer graphic;surface representation;shepard method;move least square;surface reconstruction;solid modeling;point cloud\\\",\\\"Title\\\":\\\"Piecewise C<sup>1</sup> continuous surface reconstruction of noisy point clouds via local implicit quadric regression\\\"},\\\"73\\\":{\\\"Abstract\\\":\\\"We describe an efficient technique for out-of-core management and interactive rendering of planet sized textured terrain surfaces. The technique, called planet-sized batched dynamic adaptive meshes (P-BDAM), extends the BDAM approach by using as basic primitive a general triangulation of points on a displaced triangle. The proposed framework introduces several advances with respect to the state of the art: thanks to a batched host-to-graphics communication model, we outperform current adaptive tessellation solutions in terms of rendering speed; we guarantee overall geometric continuity, exploiting programmable graphics hardware to cope with the accuracy issues introduced by single precision floating points; we exploit a compressed out of core representation and speculative prefetching for hiding disk latency during rendering of out-of-core data; we efficiently construct high quality simplified representations with a novel distributed out of core simplification algorithm working on a standard PC network.\\\",\\\"Authors\\\":\\\"Cignoni, P.;Ganovelli, F.;Gobbetti, E.;Marton, F.;Ponchio, F.;Scopigno, R.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;LargeScaleDataAndScalability;MultiresolutionTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250366\\\",\\\"Keywords\\\":\\\"multi-resolution;terrain;huge dataset\\\",\\\"Keywords_Processed\\\":\\\"terrain;multi resolution;huge dataset\\\",\\\"Title\\\":\\\"Planet-sized batched dynamic adaptive meshes (P-BDAM)\\\"},\\\"74\\\":{\\\"Abstract\\\":\\\"A new method was developed to increase the saliency of changing variables in a cardiovascular visualization for use by anesthesiologists in the operating room (OR). Clinically meaningful changes in patient physiology were identified and then mapped to the inherent psychophysical properties of the visualization. A long history of psychophysical research has provided an understanding of the parameters within which the human information processing system is able to detect changes in the size, shape and color of visual objects (Gescheider, 1976, Spence, 1990, and Baird, 1970). These detection thresholds are known as just noticeable differences (JNDs) which characterize the amount of change in an object's attribute that is recognizable 50% of the time. A prototype version of the display has been demonstrated to facilitate anesthesiologist's performance while reducing cognitive workload during simulated cardiac events (Agutter et al., 2002). In order to further improve the utility of the new cardiovascular visualization, the clinically relevant changes in cardiovascular variables are mapped to noticeable perceptual changes in the representational elements of the display. The results of the method described in this paper are used to merge information from the psychophysical properties of the cardiovascular visualization, with clinically relevant changes in the patient's cardiovascular physiology as measured by the clinical meaningfulness questionnaire. The result of this combination will create a visualization that is sensitive to changes in the cardiovascular health of the patient and communicates this information to the user in a meaningful, salient and intuitive manner.\\\",\\\"Authors\\\":\\\"Albert, R.;Syroid, N.;Zhang, Y.;Agutter, J.;Drews, F.;Strayer, D.;Hutchinson, G.;Westenskow, D.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;Cognition\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250352\\\",\\\"Keywords\\\":\\\"patient vital sign monitor;psychophysical scaling;anesthesia\\\",\\\"Keywords_Processed\\\":\\\"anesthesia;patient vital sign monitor;psychophysical scaling\\\",\\\"Title\\\":\\\"Psychophysical scaling of a cardiovascular information display\\\"},\\\"75\\\":{\\\"Abstract\\\":\\\"In this paper, we propose a quasi-static approximation (QSA) approach to simulate the movement of the movable object in 6-degrees-of-freedom (DOF) haptic rendering. In our QSA approach, we solve for static equilibrium during each haptic time step, ignoring any dynamical properties such as inertia. The major contribution of this approach is to overcome the computational instability problem in overly stiff systems arising from numerical integration of second-order differential equations in previous dynamic models. Our primary experimental results on both simulated aircraft geometry and a large-scale real-world aircraft engine showed that our QSA approach was capable of maintaining the 1000Hz haptic refresh rate with more robust collision avoidance and more reliable force and torque feedback.\\\",\\\"Authors\\\":\\\"Ming Wan;McNeely, W.A.\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;InputAndOutputDevicesGeneral;PhysicsAndPhysicalSciences;Sampling\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250380\\\",\\\"Keywords\\\":\\\"6 dof haptics;physically-based modeling;quasi-static approximation;voxel sampling;virtual coupling\\\",\\\"Keywords_Processed\\\":\\\"voxel sampling;virtual coupling;quasi static approximation;dof haptic;physically base modeling\\\",\\\"Title\\\":\\\"Quasi-static approach approximation for 6 degrees-of-freedom haptic rendering\\\"},\\\"76\\\":{\\\"Abstract\\\":\\\"In this paper we present a generic method for incremental mesh adaptation based on hierarchy of semi-regular meshes. Our method supports any refinement rule mapping vertices onto vertices such as 1-to-4 split or 3-subdivision. Resulting adaptive mesh has subdivision connectivity and hence good aspect ratio of triangles. Hierarchic representation of the mesh allows incremental local refinement and simplification operations exploiting frame-to-frame coherence. We also present an out-of-core storage layout scheme designed for semi-regular meshes of arbitrary subdivision connectivity. It provides high cache coherency in the data retrieval and relies on the interleaved storage of resolution levels and maintaining good geometrical proximity within each level. The efficiency of the proposed method is demonstrated with applications in physically-based cloth simulation, real-time terrain visualization and procedural modeling.\\\",\\\"Authors\\\":\\\"Volkov, V.;Ling Li\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;GeometricModeling;LevelOfDetail;MeshesGridsAndLattices;MultiresolutionTechniques;OutOfCoreProcessing;Rendering\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250367\\\",\\\"Keywords\\\":\\\"multi-resolution;level-of-detail;subdivision;adaptive meshes;out-of-core visualization;refinement and simplification;frame-to-frame coherence\\\",\\\"Keywords_Processed\\\":\\\"multi resolution;refinement and simplification;frame to frame coherence;out of core visualization;level of detail;subdivision;adaptive mesh\\\",\\\"Title\\\":\\\"Real-time refinement and simplification of adaptive triangular meshes\\\"},\\\"77\\\":{\\\"Abstract\\\":\\\"One of the reasons that topological methods have a limited popularity for the visualization of complex 3D flow fields is the fact that such topological structures contain a number of separating stream surfaces. Since these stream surfaces tend to hide each other as well as other topological features, for complex 3D topologies the visualizations become cluttered and hardly interpretable. This paper proposes to use particular stream lines called saddle connectors instead of separating stream surfaces and to depict single surfaces only on user demand. We discuss properties and computational issues of saddle connectors and apply these methods to complex flow data. We show that the use of saddle connectors makes topological skeletons available as a valuable visualization tool even for topologically complex 3D flow data.\\\",\\\"Authors\\\":\\\"Theisel, H.;Weinkauf, T.;Hege, H.-C.;Seidel, H.-P.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;NumericalMethodsMathematics;TopologyBasedTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250376\\\",\\\"Keywords\\\":\\\"vector field topology;critical points;separatrices;3d flow visualization\\\",\\\"Keywords_Processed\\\":\\\"vector field topology;separatrix;3d flow visualization;critical point\\\",\\\"Title\\\":\\\"Saddle connectors - an approach to visualizing the topological skeleton of complex 3D vector fields\\\"},\\\"78\\\":{\\\"Abstract\\\":\\\"We present a new algorithm for simplifying the shape of 3D objects by manipulating their medial axis transform (MAT). From an unorganized set of boundary points, our algorithm computes the MAT, decomposes the axis into parts, then selectively removes a subset of these parts in order to reduce the complexity of the overall shape. The result is simplified MAT that can be used for a variety of shape operations. In addition, a polygonal surface of the resulting shape can be directly generated from the filtered MAT using a robust surface reconstruction method. The algorithm presented is shown to have a number of advantages over other existing approaches.\\\",\\\"Authors\\\":\\\"Tam, R.;Heidrich, W.\\\",\\\"Clusters\\\":\\\"ShapeRelatedTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250410\\\",\\\"Keywords\\\":\\\"topology preservation;medial axis transform;shape simplification\\\",\\\"Keywords_Processed\\\":\\\"medial axis transform;shape simplification;topology preservation\\\",\\\"Title\\\":\\\"Shape simplification based on the medial axis transform\\\"},\\\"79\\\":{\\\"Abstract\\\":\\\"This paper presents a signed distance transform algorithm using graphics hardware, which computes the scalar valued function of the Euclidean distance to a given manifold of co-dimension one. If the manifold is closed and orientable, the distance has a negative sign on one side of the manifold and a positive sign on the other. Triangle meshes are considered for the representation of a two-dimensional manifold and the distance function is sampled on a regular Cartesian grid. In order to achieve linear complexity in the number of grid points, to each primitive we assign a simple polyhedron enclosing its Voronoi cell. Voronoi cells are known to contain exactly all points that lay closest to its corresponding primitive. Thus, the distance to the primitive only has to be computed for grid points inside its polyhedron. Although Voronoi cells partition space, the polyhedrons enclosing these cells do overlap. In regions where these overlaps occur, the minimum of all computed distances is assigned to a grid point. In order to speed up computations, points inside each polyhedron are determined by scan conversion of grid slices using graphics hardware. For this task, a fragment program is used to perform the nonlinear interpolation and minimization of distance values.\\\",\\\"Authors\\\":\\\"Sigg, C.;Peikert, R.;Gross, M.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;DataTransformation;ProgrammingAlgorithmsAndDataStructures;VisualizationTechniquesAndToolsGeneral;VoronoiBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250358\\\",\\\"Keywords\\\":\\\"distance field;distance transform;voronoi diagram;scan conversion;fragment program\\\",\\\"Keywords_Processed\\\":\\\"fragment program;distance field;distance transform;scan conversion;voronoi diagram\\\",\\\"Title\\\":\\\"Signed distance transform using graphics hardware\\\"},\\\"80\\\":{\\\"Abstract\\\":\\\"Large 2D information spaces, such as maps, images, or abstract visualizations, require views at various level of detail: close ups to inspect details, overviews to maintain (literally) an overview. Users often switch between these views. We discuss how smooth animations from one view to another can be defined. To this end, a metric on the effect of simultaneous zooming and panning is defined, based on an estimate of the perceived velocity. Optimal is defined as smooth and efficient. Given the metric, these terms can be translated into a computational model, which is used to calculate an analytic solution for optimal animations. The model has two free parameters: animation speed and zoom/pan trade off. A user experiment to find good values for these is described.\\\",\\\"Authors\\\":\\\"van Wijk, J.J.;Nuij, W.A.A.\\\",\\\"Clusters\\\":\\\"MultiScaleDataTechniques;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249004\\\",\\\"Keywords\\\":\\\"navigation;panning;zooming;scrolling;scale space\\\",\\\"Keywords_Processed\\\":\\\"zooming;scroll;navigation;pan;scale space\\\",\\\"Title\\\":\\\"Smooth and efficient zooming and panning\\\"},\\\"81\\\":{\\\"Abstract\\\":\\\"In this paper, we present a space efficient algorithm for speeding up isosurface extraction. Even though there exist algorithms that can achieve optimal search performance to identify isosurface cells, they prove impractical for large datasets due to a high storage overhead. With the dual goals of achieving fast isosurface extraction and simultaneously reducing the space requirement, we introduce an algorithm based on transform coding to compress the interval information of the cells in a dataset. Compression is achieved by first transforming the cell intervals (minima, maxima) into a form which allows more efficient compaction. It is followed by a dataset optimized non-uniform quantization stage. The compressed data is stored in a data structure that allows fast searches in the compression domain, thus eliminating the need to retrieve the original representation of the intervals at run-time. The space requirement of our search data structure is the mandatory cost of storing every cell ID once, plus an overhead for quantization information. The overhead is typically in the order of a few hundredths of the dataset size.\\\",\\\"Authors\\\":\\\"Bordoloi, U.D.;Han-Wei Shen\\\",\\\"Clusters\\\":\\\"CompressionTechniques;InformationProcessingAndHandling;IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250373\\\",\\\"Keywords\\\":\\\"isosurface;compression;transform coding;quantization\\\",\\\"Keywords_Processed\\\":\\\"quantization;transform coding;isosurface;compression\\\",\\\"Title\\\":\\\"Space efficient fast isosurface extraction for large datasets\\\"},\\\"82\\\":{\\\"Abstract\\\":\\\"This paper describes Thread Arcs, a novel interactive visualization technique designed to help people use threads found in email. Thread Arcs combine the chronology of messages with the branching tree structure of a conversational thread in a mixed-model visualization by Venolia and Neustaedter (2003) that is stable and compact. By quickly scanning and interacting with Thread Arcs, people can see various attributes of conversations and find relevant messages in them easily. We tested this technique against other visualization techniques with users' own email in a functional prototype email client. Thread Arcs proved an excellent match for the types of threads found in users' email for the qualities users wanted in small-scale visualizations.\\\",\\\"Authors\\\":\\\"Kerr, B.\\\",\\\"Clusters\\\":\\\"CollaborativeVisualization;HierarchicalTreeDataAndTechniques;ParallelSystemsAndParallelProcessing;SocialNetworksAndSocialMedia;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249028\\\",\\\"Keywords\\\":\\\"information visualization;user interface;tree structure;threads;discussions;conversations;email\\\",\\\"Keywords_Processed\\\":\\\"user interface;conversation;thread;information visualization;email;discussion;tree structure\\\",\\\"Title\\\":\\\"Thread Arcs: an email thread visualization\\\"},\\\"83\\\":{\\\"Abstract\\\":\\\"Many traditional techniques for \\\\\\\"looking inside\\\\\\\" volumetric data involve removing portions of the data, for example using various cutting tools, to reveal the interior. This allows the user to see hidden parts of the data, but has the disadvantage of removing potentially important surrounding contextual information. We explore an alternate strategy for browsing that uses deformations, where the user can cut into and open up, spread apart, or peel away parts of the volume in real time, making the interior visible while still retaining surrounding context. We consider various deformation strategies and present a number of interaction techniques based on different metaphors. Our designs pay special attention to the semantic layers that might compose a volume (e.g. the skin, muscle, bone in a scan of a human). Users can apply deformations to only selected layers, or apply a given deformation to a different degree to each layer, making browsing more flexible and facilitating the visualization of relationships between layers. Our interaction techniques are controlled with direct, \\\\\\\"in place\\\\\\\" manipulation, using pop-up menus and 3D widgets, to avoid the divided attention and awkwardness that would come with panels of traditional widgets. Initial user feedback indicates that our techniques are valuable, especially for showing portions of the data spatially situated in context with surrounding data.\\\",\\\"Authors\\\":\\\"McGuffin, M.J.;Tancau, L.;Balakrishnan, R.\\\",\\\"Clusters\\\":\\\"InteractionTechniquesGeneral;ManipulationAndDeformation;UserInterfacesGeneral;VisualEncodingAndLayoutGeneral;VolumeRenderingModelingAndVisualization;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250400\\\",\\\"Keywords\\\":\\\"browsing;3d widgets;layer;volumetric data;deformation;volume data;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;deformation;3d widget;browse;layer;volume datum;volumetric datum\\\",\\\"Title\\\":\\\"Using deformations for browsing volumetric data\\\"},\\\"84\\\":{\\\"Abstract\\\":\\\"Traditionally, node link diagrams are the prime choice when it comes to visualizing software architectures. However, node link diagrams often fall short when used to visualize large graph structures. In this paper we investigate the use of call matrices as visual aids in the management of large software projects. We argue that call matrices have a number of advantages over traditional node link diagrams when the main object of interest is the link instead of the node. Matrix visualizations can provide stable and crisp layouts of large graphs and are inherently well suited for large multilevel visualizations because of their recursive structure. We discuss a number of visualization issues, using a very large software project currently under development at Philips Medical Systems as a running example.\\\",\\\"Authors\\\":\\\"van Ham, F.\\\",\\\"Clusters\\\":\\\"MatrixRelatedTechniques;MultiScaleDataTechniques;SoftwareVisualization\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249030\\\",\\\"Keywords\\\":\\\"software visualization;multi-level visualization;call matrix\\\",\\\"Keywords_Processed\\\":\\\"multi level visualization;call matrix;software visualization\\\",\\\"Title\\\":\\\"Using multilevel call matrices in large software projects\\\"},\\\"85\\\":{\\\"Abstract\\\":\\\"This paper presents a shading model for volumetric data which enhances the perception of surfaces within the volume. The model incorporates uniform diffuse illumination, which arrives equally from all directions at each surface point in the volume. This illumination is attenuated by occlusions in the local vicinity of the surface point, resulting in shadows in depressions and crevices. Experiments by other authors have shown that perception of a surface is superior under uniform diffuse lighting, compared to illumination from point source lighting.\\\",\\\"Authors\\\":\\\"Stewart, A.J.\\\",\\\"Clusters\\\":\\\"Illumination;Perception;Rendering;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250394\\\",\\\"Keywords\\\":\\\"perceptual cues;volume rendering;shading model;diffuse illumination\\\",\\\"Keywords_Processed\\\":\\\"volume render;shade model;perceptual cue;diffuse illumination\\\",\\\"Title\\\":\\\"Vicinity shading for enhanced perception of volumetric data\\\"},\\\"86\\\":{\\\"Abstract\\\":\\\"Video data, generated by the entertainment industry, security and traffic cameras, video conferencing systems, video emails, and so on, is perhaps most time-consuming to process by human beings. In this paper, we present a novel methodology for \\\\\\\"summarizing\\\\\\\" video sequences using volume visualization techniques. We outline a system pipeline for capturing videos, extracting features, volume rendering video and feature data, and creating video visualization. We discuss a collection of image comparison metrics, including the linear dependence detector, for constructing \\\\\\\"relative\\\\\\\" and \\\\\\\"absolute\\\\\\\" difference volumes that represent the magnitude of variation between video frames. We describe the use of a few volume visualization techniques, including volume scene graphs and spatial transfer functions, for creating video visualization. In particular, we present a stream-based technique for processing and directly rendering video data in real time. With the aid of several examples, we demonstrate the effectiveness of using video visualization to convey meaningful information contained in video sequences.\\\",\\\"Authors\\\":\\\"Daniel, G.;Chen, M.\\\",\\\"Clusters\\\":\\\"DynamicVisualizationVisualizationOfChange;MultimediaImageVideoMusic;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250401\\\",\\\"Keywords\\\":\\\"image-swept volume;volume rendering;video visualization;video surveillance;change detection\\\",\\\"Keywords_Processed\\\":\\\"volume render;change detection;image sweep volume;video surveillance;video visualization\\\",\\\"Title\\\":\\\"Video visualization\\\"},\\\"87\\\":{\\\"Abstract\\\":\\\"In this paper we propose a new method for the creation of normal maps for recovering the detail on simplified meshes and a set of objective techniques to metrically evaluate the quality of different recovering techniques. The proposed techniques, that automatically produces a normal-map texture for a simple 3D model that \\\\\\\"imitates\\\\\\\" the high frequency detail originally present in a second, much higher resolution one, is based on the computation of per-texel visibility and self-occlusion information. This information is used to define a point-to-point correspondence between simplified and hires meshes. Moreover, we introduce a number of criteria for measuring the quality (visual or otherwise) of a given mapping method, and provide efficient algorithms to implement them. Lastly, we apply them to rate different mapping methods, including the widely used ones and the new one proposed here.\\\",\\\"Authors\\\":\\\"Tarini, M.;Cignoni, P.;Scopigno, R.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;AlgorithmicPatternFeatureDetectionTracking;GeometricModeling;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250407\\\",\\\"Keywords\\\":\\\"texture for geometry;detail recovery;normal mapping;texture mapping;simplification\\\",\\\"Keywords_Processed\\\":\\\"texture for geometry;simplification;texture mapping;normal mapping;detail recovery\\\",\\\"Title\\\":\\\"Visibility based methods and assessment for detail-recovery\\\"},\\\"88\\\":{\\\"Abstract\\\":\\\"Visibility culling has the potential to accelerate large data visualization in significant ways. Unfortunately, existing algorithms do not scale well when parallelized, and require full re-computation whenever the opacity transfer function is modified. To address these issues, we have designed a Plenoptic Opacity Function (POF) scheme to encode the view-dependent opacity of a volume block. POFs are computed off-line during a pre-processing stage, only once for each block. We show that using POFs is (i) an efficient, conservative and effective way to encode the opacity variations of a volume block for a range of views, (ii) flexible for re-use by a family of opacity transfer functions without the need for additional off-line processing, and (iii) highly scalable for use in massively parallel implementations. Our results confirm the efficacy of POFs for visibility culling in large-scale parallel volume rendering; we can interactively render the Visible Woman dataset using software ray-casting on 32 processors, with interactive modification of the opacity transfer function on-the-fly.\\\",\\\"Authors\\\":\\\"Gao, J.;Huang, J.;Han-Wei Shen;Kohl, J.A.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;ColorColorPerception;LargeScaleDataAndScalability;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250391\\\",\\\"Keywords\\\":\\\"plenoptic opacity function;visibility culling;volume rendering;large data visualization\\\",\\\"Keywords_Processed\\\":\\\"plenoptic opacity function;volume render;large datum visualization;visibility cull\\\",\\\"Title\\\":\\\"Visibility culling using plenoptic opacity functions for large volume visualization\\\"},\\\"89\\\":{\\\"Abstract\\\":\\\"We present a novel family of data-driven linear transformations, aimed at visualizing multivariate data in a low-dimensional space in a way that optimally preserves the structure of the data. The well-studied PCA and Fisher's LDA are shown to be special members in this family of transformations, and we demonstrate how to generalize these two methods such as to enhance their performance. Furthermore, our technique is the only one, to the best of our knowledge, that reflects in the resulting embedding both the data coordi-nates and pairwise similarities and/or dissimilarities between the data elements. Even more so, when information on the clustering (labeling) decomposition of the data is known, this information can be integrated in the linear transformation, resulting in embeddings that clearly show the separation between the clusters, as well as their intra-structure. All this makes our technique very flexible and powerful, and lets us cope with kinds of data that other techniques fail to describe properly.\\\",\\\"Authors\\\":\\\"Koren, Y.;Carmel, L.\\\",\\\"Clusters\\\":\\\"DimensionalityReduction;SegmentationAndClassification;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249017\\\",\\\"Keywords\\\":\\\"eigenprojection;dimension reduction;projection;visualization;classification;fisher's linear discriminant analysis;principal component analysis\\\",\\\"Keywords_Processed\\\":\\\"visualization;principal component analysis;classification;fisher linear discriminant analysis;eigenprojection;dimension reduction;projection\\\",\\\"Title\\\":\\\"Visualization of Labeled Data Using Linear Transformation\\\"},\\\"90\\\":{\\\"Abstract\\\":\\\"Satisfaction surveys are an important measurement tool in fields such as market research or human resources management. Serious studies consist of numerous questions and contain answers from large population samples. Aggregation on both sides, the questions asked as well as the answers received, turns the multidimensional problem into a complex system of interleaved hierarchies. Traditional ways of presenting the results are limited to one-dimensional charts and cross-tables. We developed a visualization method called the Parallel Coordinate Tree that combines multidimensional analysis with a tree structure representation. Distortion-oriented focus+context techniques are used to facilitate interaction with the visualization. In this paper we present a design study of a commercial application that we built, using this method to analyze and communicate results from large-scale customer satisfaction surveys.\\\",\\\"Authors\\\":\\\"Brodbeck, D.;Girardin, L.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;FocusContextTechniques;HierarchicalTreeDataAndTechniques;ParallelCoordinates\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249026\\\",\\\"Keywords\\\":\\\"satisfaction survey;parallel coordinates;focus+context;hierarchical data\\\",\\\"Keywords_Processed\\\":\\\"satisfaction survey;parallel coordinate;hierarchical datum;focus context\\\",\\\"Title\\\":\\\"Visualization of large-scale customer satisfaction surveys using a parallel coordinate tree\\\"},\\\"91\\\":{\\\"Abstract\\\":\\\"The quality of volume visualization depends strongly on the quality of the underlying data. In virtual colonoscopy, CT data should be acquired at a low radiation dose that results in a low signal-to-noise ratio. Alternatively, MRI data is acquired without ionizing radiation, but suffers from noise and bias (global signal fluctuations). Current volume visualization techniques often do not produce good results with noisy or biased data. This paper describes methods for volume visualization that deal with these imperfections. The techniques are based on specially adapted edge detectors using first and second order derivative filters. The filtering is integrated into the visualization process. The first order derivative method results in good quality images but suffers from localization bias. The second order method has better surface localization, especially in highly curved areas. It guarantees minimal detail smoothing resulting in a better visualization of polyps.\\\",\\\"Authors\\\":\\\"Persoon, M.P.;Serlie, I.W.O.;Post, F.H.;Truyen, R.;Vos, F.M.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;IsosurfaceAndSurfaceExtractionTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250397\\\",\\\"Keywords\\\":\\\"surface extraction;bias field;virtual colonoscopy;direct volume rendering;medical imaging\\\",\\\"Keywords_Processed\\\":\\\"virtual colonoscopy;medical imaging;direct volume render;bias field;surface extraction\\\",\\\"Title\\\":\\\"Visualization of noisy and biased volume data using first and second order derivative techniques\\\"},\\\"92\\\":{\\\"Abstract\\\":\\\"The simulation of breaking of waves, the formation of thin spray sheets, and the entertainment of air around the next generation of naval surface combatants is an ongoing 3-year Department of Defense (DoD) Challenge Project. The goal of this project is a validated computation capability to model the full hydrodynamics around a surface combatant including all of the processes that affect mission and performance. Visualization of these large-scale simulations is paramount to understanding the complex physics involved. These simulations produce enormous data sets with both surface and volumetric qualities. Wave breaking, spray sheets, and air entertainment can be visualized using isosurfaces of scalar data. Visualization of quantities such as the vorticity field also provides insight into the dynamics of droplet and bubble formation. This paper documents the techniques used, results obtained, and lessons learned from the visualization of the hydrodynamics of naval vessels.\\\",\\\"Authors\\\":\\\"Adams, P.;Dommermuth, D.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;ParallelSystemsAndParallelProcessing\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250419\\\",\\\"Keywords\\\":\\\"isosurface;multi-level parallelism;marching cubes\\\",\\\"Keywords_Processed\\\":\\\"multi level parallelism;march cube;isosurface\\\",\\\"Title\\\":\\\"Visualization of steep breaking waves and thin spray sheets around a ship\\\"},\\\"93\\\":{\\\"Abstract\\\":\\\"We develop a new approach to reconstruct non-discrete models from gridded volume samples. As a model, we use quadratic trivariate super splines on a uniform tetrahedral partition . The approximating splines are determined in a natural and completely symmetric way by averaging local data samples, such that appropriate smoothness conditions are automatically satisfied. On each tetra-hedron of  , the quasi-interpolating spline is a polynomial of total degree two which provides several advantages including efficient computation, evaluation and visualization of the model. We apply Bernstein-Bezier techniques well-known in CAGD to compute and evaluate the trivariate spline and its gradient. With this approach the volume data can be visualized efficiently e.g., with isosurface ray-casting. Along an arbitrary ray the splines are univariate, piecewise quadratics and thus the exact intersection for a prescribed isovalue can be easily determined in an analytic and exact way. Our results confirm the efficiency of the quasi-interpolating method and demonstrate high visual quality for rendered isosurfaces.\\\",\\\"Authors\\\":\\\"Rossl, C.;Zeilfelder, F.;Nurnberger, G.;Seidel, H.-P.\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;Interpolation;IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices;RaytracingRaycasting;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250399\\\",\\\"Keywords\\\":\\\"isosurface rendering;volume rendering;reconstruction;bernstein-bezier techniques;quadratic super-splines;raycasting;tetrahedral partition\\\",\\\"Keywords_Processed\\\":\\\"volume render;reconstruction;raycaste;isosurface render;tetrahedral partition;quadratic super spline;bernstein bezi technique\\\",\\\"Title\\\":\\\"Visualization of volume data with quadratic super splines\\\"},\\\"94\\\":{\\\"Abstract\\\":\\\"We describe a visualization application intended for operational use in formulating business strategy in the customer service arena. The visualization capability provided in this application implicitly allows the user to better formulate the objective function for large optimization runs which act to minimize costs based on certain input parameters. Visualization is necessary because many of the inputs to the optimization runs are themselves strategic business decisions which are not pre-ordained. Both information visualization presentations and three-dimensional visualizations are included to help users better understand the cost/benefit tradeoffs of these strategic business decisions. Here, visualization explicitly provides value not possible algorithmically, as the perceived benefit of different combinations of service level does not have an a priori mathematical formulation. Thus, we take advantage of the fundamental power of visualization, bringing the user's intuition and pattern recognition skills into the solution, while simultaneously taking advantage of the strength of algorithmic approaches to quickly and accurately find an optimal solution to a well-defined problem.\\\",\\\"Authors\\\":\\\"Gresh, D.L.;Kelton, E.I.\\\",\\\"Clusters\\\":\\\"Optimization;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250416\\\",\\\"Keywords\\\":\\\"optimization;information visualization;visad;visualization\\\",\\\"Keywords_Processed\\\":\\\"optimization;visualization;information visualization;visad\\\",\\\"Title\\\":\\\"Visualization, optimization, business strategy: a case study\\\"},\\\"95\\\":{\\\"Abstract\\\":\\\"Network evolution is an ubiquitous phenomenon in a wide variety of complex systems. There is an increasing interest in statistically modeling the evolution of complex networks such as small-world networks and scale-free networks. In this article, we address a practical issue concerning the visualizations of co-citation networks of scientific publications derived by two widely known link reduction algorithms, namely minimum spanning trees (MSTs) and pathfinder networks (PFNETs). Our primary goal is to identify the strengths and weaknesses of the two methods in fulfilling the need for visualizing evolving networks. Two criteria are derived for assessing visualizations of evolving networks in terms of topological properties and dynamical properties. We examine the animated visualization models of the evolution of botulinum toxin research in terms of its co-citation structure across a 58-year span (1945-2002). The results suggest that although high-degree nodes dominate the structure of MST models, such structures can be inadequate in depicting the essence of how the network evolves because MST removes potentially significant links from high-order shortest paths. In contrast, PFNET models clearly demonstrate their superiority in maintaining the cohesiveness of some of the most pivotal paths, which in turn make the growth animation more predictable and interpretable. We suggest that the design of visualization and modeling tools for network evolution should take the cohesiveness of critical paths into account.\\\",\\\"Authors\\\":\\\"Chen, C.;Morris, S.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2003.1249010\\\",\\\"Keywords\\\":\\\"network evolution;pathfinder networks;co-citation networks;minimum spanning trees;network visualization\\\",\\\"Keywords_Processed\\\":\\\"pathfinder network;network visualization;co citation network;network evolution;minimum spanning tree\\\",\\\"Title\\\":\\\"Visualizing evolving networks: minimum spanning trees versus pathfinder networks\\\"},\\\"96\\\":{\\\"Abstract\\\":\\\"This paper describes a set of techniques developed for the visualization of high-resolution volume data generated from industrial computed tomography for nondestructive testing (NDT) applications. Because the data are typically noisy and contain fine features, direct volume rendering methods do not always give us satisfactory results. We have coupled region growing techniques and a 2D histogram interface to facilitate volumetric feature extraction. The new interface allows the user to conveniently identify, separate or composite, and compare features in the data. To lower the cost of segmentation, we show how partial region growing results can suggest a reasonably good classification function for the rendering of the whole volume. The NDT applications that we work on demand visualization tasks including not only feature extraction and visual inspection, but also modeling and measurement of concealed structures in volumetric objects. An efficient filtering and modeling process for generating surface representation of extracted features is also introduced. Four CT data sets for preliminary NDT are used to demonstrate the effectiveness of the new visualization strategy that we have developed.\\\",\\\"Authors\\\":\\\"Huang, R.;Kwan-Liu Ma;McCormick, P.;Ward, W.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;BiomedicalScienceAndMedicine;EvaluationGeneral;HardwareAccellerationAndComputationGeneral;ImageBasedDataImageSignalProcessing;InteractionTechniquesGeneral;SurfaceRelatedDataAndTechniques;UserInterfacesGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250418\\\",\\\"Keywords\\\":\\\"interactive visualization;volume rendering;user interface;surface modeling;computed tomography;nondestructive testing and evaluation;scientific visualization;image processing;hardware acceleration rendering;feature extraction\\\",\\\"Keywords_Processed\\\":\\\"volume render;surface model;nondestructive testing and evaluation;compute tomography;user interface;image processing;feature extraction;scientific visualization;hardware acceleration render;interactive visualization\\\",\\\"Title\\\":\\\"Visualizing industrial CT volume data for nondestructive testing applications\\\"},\\\"97\\\":{\\\"Abstract\\\":\\\"In this paper, we describe a set of 3D and 4D visualization tools and techniques for CORIE, a complex environmental observation and forecasting system (EOFS) for the Columbia River. The Columbia River, a complex and highly variable estuary, is the target of numerous cross-disciplinary ecosystem research projects and is at the heart of multiple sustainable development issues with long reaching implications for the Pacific Northwest. However, there has been until recently no comprehensive and objective system available for modeling this environment, and as a consequence, researchers and agencies have had inadequate tools for evaluating the effects of natural resource management decisions. CORIE was designed to address this gap and is a major step towards the vision of a scalable, multi-use, real-time EOFS. Although CORIE already had a rich set of visualization tools, most of them produced 2D visualizations and did not allow for interactive visualization. Our work adds advanced interactive 3D tools to CORIE, which can be used for further inspection of the simulated and measured data.\\\",\\\"Authors\\\":\\\"Jimenez, W.H.;Correa, W.T.;Silva, C.T.;Baptista, A.M.\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;GeographyGeospatialVisCartographyTerrainVis\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250421\\\",\\\"Keywords\\\":\\\"columbia river;estuaries;environmental observation and forecasting systems;coastal observatories;coasts\\\",\\\"Keywords_Processed\\\":\\\"coast;environmental observation and forecasting system;coastal observatory;estuary;columbia river\\\",\\\"Title\\\":\\\"Visualizing spatial and temporal variability in coastal observatories\\\"},\\\"98\\\":{\\\"Abstract\\\":\\\"Weather visualization is a difficult problem because it comprises volumetric multi-field data and traditional surface-based approaches obscure details of the complex three-dimensional structure of cloud dynamics. Therefore, visually accurate volumetric multi-field visualization of storm scale and cloud scale data is needed to effectively and efficiently communicate vital information to weather forecasters, improving storm forecasting, atmospheric dynamics models, and weather spotter training. We have developed a new approach to multi-field visualization that uses field specific, physically-based opacity, transmission, and lighting calculations per-field for the accurate visualization of storm and cloud scale weather data. Our approach extends traditional transfer function approaches to multi-field data and to volumetric illumination and scattering.\\\",\\\"Authors\\\":\\\"Riley, K.;Ebert, D.S.;Hansen, C.;Levit, J.\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;MultidimensionalMultivariateMultifieldDataAndTechniques;VisualDesignDesignGuidelines\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250383\\\",\\\"Keywords\\\":\\\"visually accurate visualization;weather visualization;multi-field visualization\\\",\\\"Keywords_Processed\\\":\\\"multi field visualization;weather visualization;visually accurate visualization\\\",\\\"Title\\\":\\\"Visually accurate multi-field weather visualization\\\"},\\\"99\\\":{\\\"Abstract\\\":\\\"Tracking and visualizing local features from a time-varying volumetric data allows the user to focus on selected regions of interest, both in space and time, which can lead to a better understanding of the underlying dynamics. In this paper, we present an efficient algorithm to track time-varying isosurfaces and interval volumes using isosurfacing in higher dimensions. Instead of extracting the data features such as isosurfaces or interval volumes separately from multiple time steps and computing the spatial correspondence between those features, our algorithm extracts the correspondence directly from the higher dimensional geometry and thus can more efficiently follow the user selected local features in time. In addition, by analyzing the resulting higher dimensional geometry, it becomes easier to detect important topological events and the corresponding critical time steps for the selected features. With our algorithm, the user can interact with the underlying time-varying data more easily. The computation cost for performing time-varying volume tracking is also minimized.\\\",\\\"Authors\\\":\\\"Guangfeng Ji;Han-Wei Shen;Wenger, R.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;IsosurfaceAndSurfaceExtractionTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250374\\\",\\\"Keywords\\\":\\\"isosurface;high-dimensional isosurfacing;interval volume;tracking\\\",\\\"Keywords_Processed\\\":\\\"tracking;interval volume;isosurface;high dimensional isosurfacing\\\",\\\"Title\\\":\\\"Volume tracking using higher dimensional isosurfacing\\\"},\\\"100\\\":{\\\"Abstract\\\":\\\"We introduce a method for the animation of fire propagation and the burning consumption of objects represented as volumetric data sets. Our method uses a volumetric fire propagation model based on an enhanced distance field. It can simulate the spreading of multiple fire fronts over a specified isosurface without actually having to create that isosurface. The distance field is generated from a specific shell volume that rapidly creates narrow spatial bands around the virtual surface of any given isovalue. The complete distance field is then obtained by propagation from the initial bands. At each step multiple fire fronts can evolve simultaneously on the volumetric object. The flames of the fire are constructed from streams of particles whose movement is regulated by a velocity field generated with the hardware-accelerated Lattice Boltzmann Model (LBM). The LBM provides a physically-based simulation of the air flow around the burning object. The object voxels and the splats associated with the flame particles are rendered in the same pipeline so that the volume data with its external and internal structures can be displayed along with the fire.\\\",\\\"Authors\\\":\\\"Ye Zhao;Wei, X.;Zhe Fan;Kaufman, A.;Hong Qin\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;GpuBasedTechniques;MeshesGridsAndLattices;PhysicsAndPhysicalSciences;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2003.1250382\\\",\\\"Keywords\\\":\\\"splatting;lattice boltzmann model;distance field;fire propagation;gpu acceleration\\\",\\\"Keywords_Processed\\\":\\\"distance field;lattice boltzmann model;splatte;fire propagation;gpu acceleration\\\",\\\"Title\\\":\\\"Voxels on fire\\\"},\\\"101\\\":{\\\"Abstract\\\":\\\"In this paper, we address the problem of automatic camera positioning and automatic camera path generation in the context of historical data visualization. After short description of the given data, we elaborate on the constraints for the positioning of a virtual camera in such a way that not only the projected area is maximized, but also the depth of the displayed scene. This is especially important when displaying terrain models, which do not provide good 3D impression when only the projected area is maximized. Based on this concept, we present a method for computing an optimal camera position for each instant of time. Since the explored data are not static, but change depending on the explored scene time, we also discuss a method for animation generation. In order to avoid sudden changes of the camera position, when the previous method is applied for each frame (point in time), we introduce pseudo-events in time, which expand the bounding box defined by the currently active events of interest. In particular, this technique allows events happening in a future point in time to be taken into account such that when this time becomes current, all events of interest are already within the current viewing frustum of the camera.\\\",\\\"Authors\\\":\\\"Stoev, S.L.;Strasser, W.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;CamerasCameraViewsAndProjections;TimeseriesTimeVaryingDataAndTechniques;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183826\\\",\\\"Keywords\\\":\\\"visualization technique;historical data;time-dependent data;visualization;automatic camera control\\\",\\\"Keywords_Processed\\\":\\\"visualization;automatic camera control;time dependent datum;visualization technique;historical datum\\\",\\\"Title\\\":\\\"A case study on automatic camera placement and motion for visualizing historical data\\\"},\\\"102\\\":{\\\"Abstract\\\":\\\"Weather radars can measure the backscatter from rain drops in the atmosphere. A complete radar scan provides three-dimensional precipitation information. For the understanding of the underlying atmospheric processes interactive visualization of these data sets is necessary. This is a challenging task due to the size, structure and required context of the data. In this case study, a multiresolution approach for real-time simultaneous visualization of radar measurements together with the corresponding terrain data is illustrated.\\\",\\\"Authors\\\":\\\"Gerstner, T.;Meetschen, D.;Crewel, S.;Griebel, M.;Simmer, C.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;LevelOfDetail;MeshesGridsAndLattices\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183823\\\",\\\"Keywords\\\":\\\"triangular and tetrahedral grid refinement;level-of-detail;multi-resolution isosurface extraction\\\",\\\"Keywords_Processed\\\":\\\"triangular and tetrahedral grid refinement;multi resolution isosurface extraction;level of detail\\\",\\\"Title\\\":\\\"A case study on multiresolution visualization of local rainfall from weather radar measurements\\\"},\\\"103\\\":{\\\"Abstract\\\":\\\"Active stereo has been used by engineers and industrial designers for several years to enhance the perception of computer generated three-dimensional images. Unfortunately, active stereo requires specialized hardware. Therefore, as ubiquitous computing and teleworking gain importance, using active stereo becomes a problem. The goal of this case study is to examine the concept of a generic library for polychromatic passive stereo to make stereo vision available everywhere.\\\",\\\"Authors\\\":\\\"Stegmaier, S.;Rose, D.;Ertl, T.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;DisplaysGeneral;ProgrammingAlgorithmsAndDataStructures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183829\\\",\\\"Keywords\\\":\\\"opengl;preloading;stereo graphics\\\",\\\"Keywords_Processed\\\":\\\"preloade;stereo graphic;opengl\\\",\\\"Title\\\":\\\"A case study on the applications of a generic library for low-cost polychromatic passive stereo\\\"},\\\"104\\\":{\\\"Abstract\\\":\\\"We present a new multiphase method for efficiently simplifying polygonal surface models of arbitrary size. It operates by combining an initial out-of-core uniform clustering phase with a subsequent in-core iterative edge contraction phase. These two phases are both driven by quadric error metrics, and quadrics are used to pass information about the original surface between phases. The result is a method that produces approximations of a quality comparable to quadric-based iterative edge contraction, but at a fraction of the cost in terms of running time and memory consumption.\\\",\\\"Authors\\\":\\\"Garland, M.;Shaffer, E.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;MeshesGridsAndLattices;OutOfCoreProcessing\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183765\\\",\\\"Keywords\\\":\\\"quadric error metrics;out-of-core simplification;multiphase simplification;massive meshes\\\",\\\"Keywords_Processed\\\":\\\"massive mesh;quadric error metric;multiphase simplification;out of core simplification\\\",\\\"Title\\\":\\\"A multiphase approach to efficient surface simplification\\\"},\\\"105\\\":{\\\"Abstract\\\":\\\"Many direct volume rendering algorithms have been proposed during the last decade to render 2563 voxels interactively. However a lot of limitations are inherent to all of them, like low-quality images, a small viewport size or a fixed classification. In contrast, interactive high quality algorithms are still a challenge nowadays. We introduce here an efficient and accurate technique called object-order ray-casting that can achieve up to 10 fps on current workstations. Like usual ray-casting, colors and opacities are evenly sampled along the ray, but now within a new object-order algorithm. Thus, it allows to combine the main advantages of both worlds in term of speed and quality. We also describe an efficient hidden volume removal technique to compensate for the loss of early ray termination.\\\",\\\"Authors\\\":\\\"Mora, B.;Jessel, J.-P.;Caubet, R.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;RaytracingRaycasting;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183776\\\",\\\"Keywords\\\":\\\"scientific visualization;raytracing;volume rendering;medical imaging\\\",\\\"Keywords_Processed\\\":\\\"scientific visualization;volume render;medical imaging;raytrace\\\",\\\"Title\\\":\\\"A new object-order ray-casting algorithm\\\"},\\\"106\\\":{\\\"Abstract\\\":\\\"The analysis of multidimensional functions is important in many engineering disciplines, and poses a major problem as the number of dimensions increases. Previous visualization approaches focus on representing three or fewer dimensions at a time. This paper presents a new focus+context visualization that provides an integrated overview of an entire multidimensional function space, with uniform treatment of all dimensions. The overview is displayed with respect to a user-controlled polar focal point in the function's parameter space. Function value patterns are viewed along rays that emanate from the focal point in all directions in the parameter space, and represented radially around the focal point in the visualization. Data near the focal point receives proportionally more screen space than distant data. This approach scales smoothly from two dimensions to 10-20, with a 1000 pixel range on each dimension.\\\",\\\"Authors\\\":\\\"Jayaraman, S.;North, C.\\\",\\\"Clusters\\\":\\\"NumericalMethodsMathematics;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183806\\\",\\\"Keywords\\\":\\\"visualization;multi-dimensional functions\\\",\\\"Keywords_Processed\\\":\\\"visualization;multi dimensional function\\\",\\\"Title\\\":\\\"A radial focus+context visualization for multi-dimensional functions\\\"},\\\"107\\\":{\\\"Abstract\\\":\\\"We present an extremely fast graph drawing algorithm for very large graphs, which we term ACE (for Algebraic multigrid Computation of Eigenvectors). ACE exhibits an improvement of something like two orders of magnitude over the fastest algorithms we are aware of; it draws graphs of millions of nodes in less than a minute. ACE finds an optimal drawing by minimizing a quadratic energy function. The minimization problem is expressed as a generalized eigenvalue problem, which is rapidly solved using a novel algebraic multigrid technique. The same generalized eigenvalue problem seems to come up also in other fields, hence ACE appears to be applicable outside of graph drawing too.\\\",\\\"Authors\\\":\\\"Koren, Y.;Carmel, L.;Harel, D.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;MeshesGridsAndLattices;MultiScaleDataTechniques;NumericalMethodsMathematics;PhysicsAndPhysicalSciences;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2002.1173159\\\",\\\"Keywords\\\":\\\"graph drawing;fiedler vector;hall energy;algebraic multigrid;force-directed layout;generalized eigenvalue problem;multi-scale/multi-level optimization\\\",\\\"Keywords_Processed\\\":\\\"graph drawing;generalize eigenvalue problem;multi scale multi level optimization;hall energy;fiedl vector;force direct layout;algebraic multigrid\\\",\\\"Title\\\":\\\"ACE: a fast multiscale eigenvectors computation for drawing huge graphs\\\"},\\\"108\\\":{\\\"Abstract\\\":\\\"In this paper we present angular brushing for parallel coordinates (PC) as a new approach to highlighting rational data-properties, i.e., features which - in a non-separable way - depend on two data dimensions. We also demonstrate smooth brushing as an intuitive tool for specifying nonbinary degree-of-interest functions (for focus+context visualization). We also briefly describe our implementation as well as its application to the visualization of CFD data.\\\",\\\"Authors\\\":\\\"Hauser, H.;Ledermann, F.;Doleisch, H.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;InteractionTechniquesGeneral;MachineLearningAndStatistics;ParallelCoordinates;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2002.1173157\\\",\\\"Keywords\\\":\\\"information visualization;brushing;focus+context visualization;parallel coordinates;linear correlations\\\",\\\"Keywords_Processed\\\":\\\"parallel coordinate;brush;linear correlation;information visualization;focus context visualization\\\",\\\"Title\\\":\\\"Angular brushing of extended parallel coordinates\\\"},\\\"109\\\":{\\\"Abstract\\\":\\\"We present some new methods for computing estimates of normal vectors at the vertices of a triangular mesh surface approximation to an isosurface which has been computed by the marching cube algorithm. These estimates are required for the smooth rendering of triangular mesh surfaces. The conventional method of computing estimates based upon divided difference approximations of the gradient can lead to poor estimates in some applications. This is particularly true for isosurfaces obtained from a field function, which is defined only for values near to the isosurface. We describe some efficient methods for computing the topology of the triangular mesh surface, which is used for obtaining local estimates of the normals. In addition, a new, one pass, approach for these types of applications is described and compared to existing methods.\\\",\\\"Authors\\\":\\\"Nielson, G.M.;Huang, A.;Sylvester, S.\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;GeometricModeling;IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices;Rendering;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183808\\\",\\\"Keywords\\\":\\\"isosurface;normal vectors;approximation;triangular mesh;marching cubes;gouraud shading;topology\\\",\\\"Keywords_Processed\\\":\\\"march cube;gouraud shade;topology;normal vector;triangular mesh;approximation;isosurface\\\",\\\"Title\\\":\\\"Approximating normals for marching cubes applied to locally supported isosurfaces\\\"},\\\"110\\\":{\\\"Abstract\\\":\\\"This paper introduces a new visualization method, the arc diagram, which is capable of representing complex patterns of repetition in string data. Arc diagrams improve over previous methods such as dotplots because they scale efficiently for strings that contain many instances of the same subsequence. This paper describes design and implementation issues related to arc diagrams and shows how they may be applied to visualize such diverse data as music, text, and compiled code.\\\",\\\"Authors\\\":\\\"Wattenberg, M.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;MultimediaImageVideoMusic;ProgrammingAlgorithmsAndDataStructures;TextDocumentTopicAnalysisDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2002.1173155\\\",\\\"Keywords\\\":\\\"sequence;code;music;arc diagram;visualization;string;text\\\",\\\"Keywords_Processed\\\":\\\"visualization;sequence;arc diagram;code;string;text;music\\\",\\\"Title\\\":\\\"Arc diagrams: visualizing structure in strings\\\"},\\\"111\\\":{\\\"Abstract\\\":\\\"This paper presents a new technique for visualizing large, complex collections of data. The size and dimensionality of these datasets make them challenging to display in an effective manner. The images must show the global structure of spatial relationships within the dataset, yet at the same time accurately represent the local detail of each data element being visualized. We propose combining ideas from information and scientific visualization together with a navigation assistant, a software system designed to help users identify and explore areas of interest within their data. The assistant locates data elements of potential importance to the user, clusters them into spatial regions, and builds underlying graph structures to connect the regions and the elements they contain. Graph traversal algorithms, constraint-based viewpoint construction, and intelligent camera planning techniques can then be used to design animated tours of these regions. In this way, the navigation assistant can help users to explore any of the areas of interest within their data. We conclude by demonstrating how our assistant is being used to visualize a multidimensional weather dataset.\\\",\\\"Authors\\\":\\\"Dennis, B.M.;Healey, C.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;MultidimensionalMultivariateMultifieldDataAndTechniques;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183803\\\",\\\"Keywords\\\":\\\"navigation;information visualization;scientific visualization;multi-dimensional visualization;camera planning\\\",\\\"Keywords_Processed\\\":\\\"multi dimensional visualization;navigation;information visualization;scientific visualization;camera planning\\\",\\\"Title\\\":\\\"Assisted navigation for large information spaces\\\"},\\\"112\\\":{\\\"Abstract\\\":\\\"In this paper we introduce a new and simple algorithm to compress isosurface data. This is the data extracted by isosurface algorithms from scalar functions defined on volume grids, and used to generate polygon meshes or alternative representations. In this algorithm the mesh connectivity and a substantial proportion of the geometric information are encoded to a fraction of a bit per marching cubes vertex with a context based arithmetic coder closely related to the JBIG binary image compression standard. The remaining optional geometric information that specifies the location of each marching cubes vertex more precisely along its supporting intersecting grid edge, is efficiently encoded in scan-order with the same mechanism. Vertex normals can optionally be computed as normalized gradient vectors by the encoder and included in the bitstream after quantization and entropy encoding, or computed by the decoder in a postprocessing smoothing step. These choices are determined by trade-offs associated with an in-core vs. out-of-core decoder structure. The main features of our algorithm are its extreme simplicity and high compression rates.\\\",\\\"Authors\\\":\\\"Taubin, G.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;ComputerGraphicsTechniquesGeneral;ProgrammingAlgorithmsAndDataStructures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183807\\\",\\\"Keywords\\\":\\\"algorithm;3d geometry compression;graphics\\\",\\\"Keywords_Processed\\\":\\\"graphic;3d geometry compression;algorithm\\\",\\\"Title\\\":\\\"BLIC: Bi-Level Isosurface Compression\\\"},\\\"113\\\":{\\\"Abstract\\\":\\\"This paper describes BM3D: a method for the analysis of motion in time dependent volume data. From a sequence of volume data sets a sequence of vector data sets representing the movement of the data is computed. A block matching technique is used for the reconstruction of data movement. The derived vector field can be used for the visualization of time dependent volume data. The method is illustrated in two applications.\\\",\\\"Authors\\\":\\\"de Leeuw, W.;van Liere, R.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;BiomedicalScienceAndMedicine;VectorFieldsDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183804\\\",\\\"Keywords\\\":\\\"biomedical imaging;feature tracking;volume visualization;vector field\\\",\\\"Keywords_Processed\\\":\\\"vector field;feature tracking;biomedical imaging;volume visualization\\\",\\\"Title\\\":\\\"BM3D: motion estimation in time dependent volume data\\\"},\\\"114\\\":{\\\"Abstract\\\":\\\"Many computer graphics operations, such as texture mapping, 3D painting, remeshing, mesh compression, and digital geometry processing, require finding a low-distortion parameterization for irregular connectivity triangulations of arbitrary genus 2-manifolds. This paper presents a simple and fast method for computing parameterizations with strictly bounded distortion. The new method operates by flattening the mesh onto a region of the 2D plane. To comply with the distortion bound, the mesh is automatically cut and partitioned on-the-fly. The method guarantees avoiding global and local self-intersections, while attempting to minimize the total length of the introduced seams. To our knowledge, this is the first method to compute the mesh partitioning and the parameterization simultaneously and entirely automatically, while providing guaranteed distortion bounds. Our results on a variety of objects demonstrate that the method is fast enough to work with large complex irregular meshes in interactive applications.\\\",\\\"Authors\\\":\\\"Sorkine, O.;Cohen-Or, D.;Goldenthal, R.;Lischinski, D.\\\",\\\"Clusters\\\":\\\"ArtAndAestheticsInVisualization;Maps;MeshesGridsAndLattices;Parameterization;SurfaceRelatedDataAndTechniques;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183795\\\",\\\"Keywords\\\":\\\"mesh partitioning;parameterization;atlas;surface flattening;texture mapping;3d painting\\\",\\\"Keywords_Processed\\\":\\\"surface flattening;mesh partition;3d painting;texture mapping;atlas;parameterization\\\",\\\"Title\\\":\\\"Bounded-distortion piecewise mesh parameterization\\\"},\\\"115\\\":{\\\"Abstract\\\":\\\"Visualization is required for the effective utilization of data from a weather simulation. Appropriate mapping of user goals to the design of pictorial content has been useful in the development of interactive applications with sufficient bandwidth for timely access to the model data. When remote access to the model visualizations is required the limited bandwidth becomes the primary bottleneck. To help address these problems, visualizations are presented on a Web page as a meta-representation of the model output and serve as an index to simplify finding other visualizations of relevance. To provide consistency with extant interactive products and to leverage their cost of development, the aforementioned applications are adapted to automatically populate a Web site with images and interactions for an operational weather forecasting system.\\\",\\\"Authors\\\":\\\"Treinish, L.A.\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;InternetWebVisualizationForTheMasses;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183827\\\",\\\"Keywords\\\":\\\"visualization;meteorology;world wide web\\\",\\\"Keywords_Processed\\\":\\\"visualization;meteorology;world wide web\\\",\\\"Title\\\":\\\"Case study on the adaptation of interactive visualization applications to Web-based production for operational mesoscale weather models\\\"},\\\"116\\\":{\\\"Abstract\\\":\\\"For most of the time, we enjoy and appreciate music performances as they are. Once we try to understand the performance not in subjective terms but in an objective way and share it with other people, visualizing the performance parameters is indispensable. In this paper, a figure for visualizing performance expressions is described. This figure helps people understand the cause and position of the performance expression as it has expressive cues, which coincide with the cognitive meaning of musical performance, and not by using only MIDI parameter values. The differences we hear between performances are clarified by visualized figures.\\\",\\\"Authors\\\":\\\"Hiraga, R.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;EvaluationMetricsAndBenchmarks;MultimediaImageVideoMusic;Perception\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183815\\\",\\\"Keywords\\\":\\\"expressive cue;performance visualization;understanding performance;music performance\\\",\\\"Keywords_Processed\\\":\\\"performance visualization;expressive cue;understanding performance;music performance\\\",\\\"Title\\\":\\\"Case study: A look of performance expression\\\"},\\\"117\\\":{\\\"Abstract\\\":\\\"With the completion of the human genome sequence, and with the proliferation of genome-related annotation data, the need for scalable and more intuitive means for analysis becomes critical, At Variagenics and Small Design Firm, we have addressed this problem with a coherent three-dimensional space in which all data can be seen in a single context. This tool aids in integrating information at vastly divergent scales while maintaining accurate spatial and size relationships. Our visualization was successful in communicating to project teams with diverse backgrounds the magnitude and biological implication of genetic variation.\\\",\\\"Authors\\\":\\\"Adams, R.M.;Stancampiano, B.;McKenna, M.;Small, D.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;HumanComputerInteractionHumanFactors;ImmersiveAndVirtualEnvironments;InteractionTechniquesGeneral;MultiScaleDataTechniques;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183818\\\",\\\"Keywords\\\":\\\"virtual environment;multi-scale model;data navigation;bioinformatics;3d interaction;human factors\\\",\\\"Keywords_Processed\\\":\\\"virtual environment;3d interaction;human factor;multi scale model;bioinformatic;datum navigation\\\",\\\"Title\\\":\\\"Case study: A virtual environment for genomic data visualization\\\"},\\\"118\\\":{\\\"Abstract\\\":\\\"Line Integral Convolution (LIC) is a promising method for visualizing 2D dense flow fields. Direct extensions of the LIC method to 3D have not been considered very effective, because optical integration in viewing directions tends to spoil the coherent structures along 3D local streamlines. In our previous reports, we have proposed a selective approach to volume rendering of LIC solid texture using 3D significance map (S-map), derived from the characteristics of flow structures, and a specific illumination model for 3D streamlines. In this paper, we take full advantage of scalar volume rendering hardware, such as VolumePro, to realize a realtime 3D flow field visualization environment with the LIC volume rendering method.\\\",\\\"Authors\\\":\\\"Suzuki, Y.;Fujishiro, I.;Chen, L.;Nakamura, H.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;Illumination;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183811\\\",\\\"Keywords\\\":\\\"flow visualization;illumination model;flow topology;significance map\\\",\\\"Keywords_Processed\\\":\\\"flow topology;illumination model;significance map;flow visualization\\\",\\\"Title\\\":\\\"Case study: hardware-accelerated selective LIC volume rendering\\\"},\\\"119\\\":{\\\"Abstract\\\":\\\"Adaptive mesh refinement (AMR) is a popular computational simulation technique used in various scientific and engineering fields. Although AMR data is organized in a hierarchical multi-resolution data structure, the traditional volume visualization algorithms such as ray-casting and splatting cannot handle the form without converting it to a sophisticated data structure. In this paper, we present a hierarchical multi-resolution splatting technique using k-d trees and octrees for AMR data that is suitable for implementation on the latest consumer PC graphics hardware. We describe a graphical user interface to set transfer function and viewing/rendering parameters interactively. Experimental results obtained on a general purpose PC equipped with NVIDIA GeForce card are presented to demonstrate that the technique can interactively render AMR data (over 20 frames per second). Our scheme can easily be applied to parallel rendering of time-varying AMR data.\\\",\\\"Authors\\\":\\\"Sanghun Park;Bajaj, C.L.;Siddavanahalli, V.\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;ComputerGraphicsTechniquesGeneral;ProgrammingAlgorithmsAndDataStructures;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183820\\\",\\\"Keywords\\\":\\\"octree;k-d tree;hierarchical splatting;texture mapping;adaptive mesh refinement\\\",\\\"Keywords_Processed\\\":\\\"adaptive mesh refinement;hierarchical splatting;octree;texture mapping;tree\\\",\\\"Title\\\":\\\"Case study: Interactive rendering of adaptive mesh refinement data\\\"},\\\"120\\\":{\\\"Abstract\\\":\\\"Internet connectivity is defined by a set of routing protocols which let the routers that comprise the Internet backbone choose the best route for a packet to reach its destination. One way to improve the security and performance of Internet is to routinely examine the routing data. In this case study, we show how interactive visualization of Border Gateway Protocol (BGP) data helps characterize routing behavior, identify weaknesses in connectivity which could potentially cripple the Internet, as well as detect and explain actual anomalous events.\\\",\\\"Authors\\\":\\\"Soon Tee Teoh;Kwan-Liu Ma;Wu, S.F.;Xiaoliang Zhao\\\",\\\"Clusters\\\":\\\"ComputerNetworksNetworkSecurity;EventsTrendsOutlierDetectionAnalysisAndVisualization;GraphNetworkDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183816\\\",\\\"Keywords\\\":\\\"information visualization;network security;graph drawing;anomaly detection\\\",\\\"Keywords_Processed\\\":\\\"graph drawing;network security;information visualization;anomaly detection\\\",\\\"Title\\\":\\\"Case study: Interactive visualization for Internet security\\\"},\\\"121\\\":{\\\"Abstract\\\":\\\"As part of a larger effort exploring alternative display systems, Lawrence Livermore National Laboratory has installed systems in two offices that extend and update the previously described \\\\\\\"Office of Real Soon Now\\\\\\\" project to improve the value for visualization tasks. These new systems use higher resolution projectors driven by workstations that run Unix-based applications via Linux and support hardware-accelerated 3D graphics, even across the boundary between displays.\\\",\\\"Authors\\\":\\\"Uselton, S.\\\",\\\"Clusters\\\":\\\"DimensionalityReduction;DisplaysGeneral;LargeAndHighResDisplays\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183830\\\",\\\"Keywords\\\":\\\"display;projection;panoramic image display\\\",\\\"Keywords_Processed\\\":\\\"display;panoramic image display;projection\\\",\\\"Title\\\":\\\"Case study: the \\\\\\\"Office of Real Soon Now\\\\\\\" for visualization\\\"},\\\"122\\\":{\\\"Abstract\\\":\\\"We present an innovative application developed at Sandia National Laboratories for visual debugging of unstructured finite element physics codes. Our tool automatically locates anomalous regions, such as inverted elements or nodes whose variable values lie outside a prescribed range, then extracts mesh subsets around these features for detailed examination. The subsets are viewed using color coding of variable values superimposed on the mesh structure. This allows the values and their relative spatial locations within the mesh to be correlated at a glance. Both topological irregularities and hot spots within the data stand out visually, allowing the user to explore the exact numeric values of the grid at surrounding points over time. We demonstrate the utility of this approach by debugging a cell inversion in a simulation of an exploding wire.\\\",\\\"Authors\\\":\\\"Crossno, P.;Rogers, D.H.;Garasi, C.J.\\\",\\\"Clusters\\\":\\\"NumericalMethodsMathematics;ProgrammingAlgorithmsAndDataStructures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183819\\\",\\\"Keywords\\\":\\\"visual debugging;parallel finite element codes and simulations\\\",\\\"Keywords_Processed\\\":\\\"visual debugging;parallel finite element code and simulation\\\",\\\"Title\\\":\\\"Case study: Visual debugging of finite element codes\\\"},\\\"123\\\":{\\\"Abstract\\\":\\\"Data sets from large-scale simulations (up to 5013 grid points) of mantle convection are analyzed with volume rendering of the temperature field and a new critical point analysis of the velocity field. As the Rayleigh number Ra is increased the thermal field develops increasingly thin plume-like structures along which heat is convected. These eventually break down and become turbulent. Visualization methods are used to distinguish between various models of heat conductivity and to develop an intuitive understanding of the structure of the flow.\\\",\\\"Authors\\\":\\\"Erlebacher, G.;Yuen, D.A.;Dubuffet, F.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;ApplicationsGeneralAndOther;EarthSpaceAndEnvironmentalSciences;FlowVisualizationDataAndTechniques;TopologyBasedTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183813\\\",\\\"Keywords\\\":\\\"volume rendering;plumes;critical points;unsteady flow;mantle convection;feature extraction\\\",\\\"Keywords_Processed\\\":\\\"volume render;unsteady flow;mantle convection;feature extraction;plume;critical point\\\",\\\"Title\\\":\\\"Case study: Visualization and analysis of high Rayleigh number - 3D convection in the Earth's mantle\\\"},\\\"124\\\":{\\\"Abstract\\\":\\\"Ocean model simulations commonly assume the ocean is hydrostatic, resulting in near zero vertical motion. The vertical motion found is typically associated with the variations of the thermocline depth over time, which are mainly a result of the development and movement of ocean fronts, eddies, and internal waves. A new technique, extended from Lagrangian-Eulerian Advection, is presented to help understand the variation of vertical motion associated with the change in thermocline depth over time. A time surface is correctly deformed in a single direction according to the flow. The evolution of the time surface is computed via a mixture of Eulerian and Lagrangian techniques. The dominant horizontal motion is textured onto the surface using texture advection, while both the horizontal and vertical motions are used to displace the surface. The resulting surface is shaded for enhanced contrast. Timings indicate that the overhead over standard 2D texture advection is no more than 12%.\\\",\\\"Authors\\\":\\\"Grant, J.;Erlebacher, G.;O'Brien, J.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;EarthSpaceAndEnvironmentalSciences;SurfaceRelatedDataAndTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183822\\\",\\\"Keywords\\\":\\\"time surfaces;ocean currents;unsteady vector fields;vertical velocity\\\",\\\"Keywords_Processed\\\":\\\"ocean current;unsteady vector field;vertical velocity;time surface\\\",\\\"Title\\\":\\\"Case study: Visualizing ocean flow vertical motions using Lagrangian-Eulerian time surfaces\\\"},\\\"125\\\":{\\\"Abstract\\\":\\\"We report on using computed tomography (CT) as a model acquisition tool for complex objects in computer graphics. Unlike other modeling and scanning techniques the complexity of the object is irrelevant in CT, which naturally enables to model objects with, for example, concavities, holes, twists or fine surface details. Once the data is scanned, one can apply post-processing techniques for data enhancement, modification or presentation. For demonstration purposes we chose to scan a Christmas tree which exhibits high complexity which is difficult or even impossible to handle with other techniques. However, care has to be taken to achieve good scanning results with CT. Further, we illustrate post-processing by means of data segmentation and photorealistic as well as non-photorealistic surface and volume rendering techniques.\\\",\\\"Authors\\\":\\\"Kanitsar, A.;Theussl, T.;Mroz, L.;Sramek, M.;Bartroli, A.V.;Csebfalvi, B.;Hladuvka, J.;Fleischmann, D.;Knapp, M.;Wegenkittl, R.;Felkel, P.;Rottger, S.;Guthe, S.;Purgathofer, W.;Groller, E.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183812\\\",\\\"Keywords\\\":\\\"computed tomography;volume visualization;modeling\\\",\\\"Keywords_Processed\\\":\\\"model;volume visualization;compute tomography\\\",\\\"Title\\\":\\\"Christmas tree case study: computed tomography as a tool for mastering complex real world objects with applications in computer graphics\\\"},\\\"126\\\":{\\\"Abstract\\\":\\\"Comparative evaluation of visualization and experimental results is a critical step in computational steering. In this paper, we present a study of image comparison metrics for quantifying the magnitude of difference between visualization of a computer simulation and a photographic image captured from an experiment. We examined eleven metrics, including three spatial domain, four spatial-frequency domain and four HVS (human-vision system) metrics. Among these metrics, a spatial-frequency domain metric called 2nd-order Fourier comparison was proposed specifically for this work. Our study consisted of two stages: base cases and field trials. The former is a general study on a controlled comparison space using purposely selected data, and the latter involves imagery results from computational fluid dynamics and a rheological experiment. This study has introduced a methodological framework for analyzing image-level methods used in comparative visualization. For the eleven metrics considered, it has offered a set of informative indicators as to the strengths and weaknesses of each metric. In particular, we have identified three image comparison metrics that are effective in separating \\\\\\\"similar\\\\\\\" and \\\\\\\"different\\\\\\\" image groups. Our 2nd-order Fourier comparison metric has compared favorably with others in two of the three tests, and has shown its potential to be used for steering computer simulation quantitatively.\\\",\\\"Authors\\\":\\\"Hualin Zhou;Chen, M.;Webster, M.F.\\\",\\\"Clusters\\\":\\\"ComparisonComparativeVisualizationAndSimilarity;EvaluationMetricsAndBenchmarks;MaterialScience;Perception;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183790\\\",\\\"Keywords\\\":\\\"human visual system;scientific visualization;error metrics;comparative visualization;rheology;image comparison\\\",\\\"Keywords_Processed\\\":\\\"rheology;human visual system;error metric;comparative visualization;scientific visualization;image comparison\\\",\\\"Title\\\":\\\"Comparative evaluation of visualization and experimental results using image comparison metrics\\\"},\\\"127\\\":{\\\"Abstract\\\":\\\"We present a generalization of the geometry coder by Touma and Gotsman (1998) to polygon meshes. We let the polygon information dictate where to apply the parallelogram rule that they use to predict vertex positions. Since polygons tend to be fairly planar and fairly convex, it is beneficial to make predictions within a polygon rather than across polygons. This, for example, avoids poor predictions due to a crease angle between polygons. Up to 90 percent of the vertices can be predicted this way. Our strategy improves geometry compression by 10 to 40 percent depending on (a) how polygonal the mesh is and (b) on the quality (planarity/convexity) of the polygons.\\\",\\\"Authors\\\":\\\"Isenburg, M.;Alliez, P.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;GeometricModeling;MachineLearningAndStatistics;MeshesGridsAndLattices;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183768\\\",\\\"Keywords\\\":\\\"parallelogram rule;polygonal meshes;mesh compression;linear prediction;geometric coding\\\",\\\"Keywords_Processed\\\":\\\"geometric coding;mesh compression;polygonal mesh;parallelogram rule;linear prediction\\\",\\\"Title\\\":\\\"Compressing polygon mesh geometry with parallelogram prediction\\\"},\\\"128\\\":{\\\"Abstract\\\":\\\"Critical points of a vector field are key to their characterization. Their positions as well as their indexes are crucial for understanding vector fields. Considerable work exists in 2D, but less is available for 3D or higher dimensions. Geometric algebra is a derivative of Clifford algebra that not only enables a succinct definition of the index of a critical point in higher dimension; it also provides insight and computational pathways for calculating the index. We describe the problems in terms of geometric algebra and present an octree based solution using the algebra for finding critical points and their index in a 3D vector field.\\\",\\\"Authors\\\":\\\"Mann, S.;Rockwood, A.\\\",\\\"Clusters\\\":\\\"GeometricModeling;NumericalMethodsMathematics;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183786\\\",\\\"Keywords\\\":\\\"singularities;geometric algebra;3d vector fields\\\",\\\"Keywords_Processed\\\":\\\"singularity;geometric algebra;3d vector field\\\",\\\"Title\\\":\\\"Computing singularities of 3D vector fields with geometric algebra\\\"},\\\"129\\\":{\\\"Abstract\\\":\\\"Visualization of tubular structures such as blood vessels is an important topic in medical imaging. One way to display tubular structures for diagnostic purposes is to generate longitudinal cross-sections in order to show their lumen, wall, and surrounding tissue in a curved plane. This process is called curved planar reformation (CPR). We present three different methods to generate CPR images. A tube-phantom was scanned with computed tomography (CT) to illustrate the properties of the different CPR methods. Furthermore we introduce enhancements to these methods: thick-CPR, rotating-CPR and multi-path-CPR.\\\",\\\"Authors\\\":\\\"Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, E.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DimensionalityReduction\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183754\\\",\\\"Keywords\\\":\\\"curved planar reformation;computed tomography angiography;vessel analysis\\\",\\\"Keywords_Processed\\\":\\\"curve planar reformation;compute tomography angiography;vessel analysis\\\",\\\"Title\\\":\\\"CPR - curved planar reformation\\\"},\\\"130\\\":{\\\"Abstract\\\":\\\"We present a method to code the multiresolution structure of a 3D triangle mesh in a manner that allows progressive decoding and efficient rendering at a client machine. The code is based on a special ordering of the mesh vertices which has good locality and continuity properties, inducing a natural multiresolution structure. This ordering also incorporates information allowing efficient rendering of the mesh at all resolutions using the contemporary vertex buffer mechanism. The performance of our code is shown to be competitive with existing progressive mesh compression methods, while achieving superior rendering speed.\\\",\\\"Authors\\\":\\\"Karni, Z.;Bogomjakov, A.;Gotsman, C.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;GeometryBasedTechniques;NumericalMethodsMathematics;Rendering\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183794\\\",\\\"Keywords\\\":\\\"rendering;progressive compression;wavelets;geometry coding\\\",\\\"Keywords_Processed\\\":\\\"render;progressive compression;geometry coding;wavelet\\\",\\\"Title\\\":\\\"Efficient compression and rendering of multi-resolution meshes\\\"},\\\"131\\\":{\\\"Abstract\\\":\\\"This paper introduces two efficient algorithms that compute the Contour Tree of a 3D scalar field  and its augmented version with the Betti numbers of each isosurface. The Contour Tree is a fundamental data structure in scientific visualization that is used to preprocess the domain mesh to allow optimal computation of isosurfaces with minimal overhead storage. The Contour Tree can also be used to build user interfaces reporting the complete topological characterization of a scalar field. The first part of the paper presents a new scheme that augments the Contour Tree with the Betti numbers of each isocontour in linear time. We show how to extend the scheme with the Betti number computation without increasing its complexity. Thus, we improve on the time complexity from our previous approach from O(m log m) to O(n log n+m), where m is the number of tetrahedra and n is the number of vertices in the domain of . The second part of the paper introduces a new divide-and-conquer algorithm that computes the Augmented Contour Tree with improved efficiency. The central part of the scheme computes the output Contour Tree by merging two intermediate Contour Trees and is independent of the interpolant. In this way we confine any knowledge regarding a specific interpolant to an oracle that computes the tree for a single cell. We have implemented this oracle for the trilinear interpolant and plan to replace it with higher order interpolants when needed. The complexity of the scheme is O(n+t log n), where t is the number of critical points of . For the first time we can compute the Contour Tree in linear time in many practical cases when t=O(n1-). Lastly, we report the running times for a parallel implementation of our algorithm, showing good scalability with the number of processors.\\\",\\\"Authors\\\":\\\"Pascucci, V.;Cole-McLaughlin, K.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183774\\\",\\\"Keywords\\\":\\\"isosurface;level set topology;betti numbers\\\",\\\"Keywords_Processed\\\":\\\"level set topology;isosurface;betti number\\\",\\\"Title\\\":\\\"Efficient computation of the topology of level sets\\\"},\\\"132\\\":{\\\"Abstract\\\":\\\"Novel speech and/or gesture interfaces are candidates for use in future mobile or ubiquitous applications. This paper describes an evaluation of various interfaces for visual navigation of a whole Earth 3D terrain model. A mouse driven interface, a speech interface, a gesture interface, and a multimodal speech and gesture interface were used to navigate to targets placed at various points on the Earth. This study measured each participant's recall of target identity, order, and location as a measure of cognitive load. Timing information as well as a variety of subjective measures including discomfort and user preference were taken. While the familiar and mature mouse interface scored best by most measures, the speech interface also performed well. The gesture and multimodal interface suffered from weaknesses in the gesture modality. Weaknesses in the speech and multimodal modalities are identified and areas for improvement are discussed.\\\",\\\"Authors\\\":\\\"Krum, D.;Omoteso, O.;Ribarsky, W.;Starner, T.;Hodges, L.F.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;GeographyGeospatialVisCartographyTerrainVis;ImmersiveAndVirtualEnvironments;InputAndOutputDevicesGeneral;InteractionTechniquesGeneral;ProgrammingAlgorithmsAndDataStructures;SmallMobileUbiquitousDevicesDisplays;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183802\\\",\\\"Keywords\\\":\\\"navigation;mobile visualization;virtual reality;geographic information systems;speech recognition;gesture recognition;multimodal interaction;evaluation\\\",\\\"Keywords_Processed\\\":\\\"navigation;mobile visualization;geographic information system;speech recognition;multimodal interaction;virtual reality;gesture recognition;evaluation\\\",\\\"Title\\\":\\\"Evaluation of a multimodal interface for 3D terrain visualization\\\"},\\\"133\\\":{\\\"Abstract\\\":\\\"Isosurfaces are commonly used to visualize scalar fields. Critical isovalues indicate isosurface topology changes: the creation of new surface components, merging of surface components or the formation of holes in a surface component. Therefore, they highlight interesting isosurface behavior and are helpful in exploration of large trivariate data sets. We present a method that detects critical isovalues in a scalar field defined by piecewise trilinear interpolation over a rectilinear grid and describe how to use them when examining volume data. We further review varieties of the marching cubes (MC) algorithm, with the intention of preserving topology of the trilinear interpolant when extracting an isosurface. We combine and extend two approaches in such a way that it is possible to extract meaningful isosurfaces even when a critical value is chosen as the isovalue.\\\",\\\"Authors\\\":\\\"Weber, G.H.;Scheuermann, G.;Hagen, H.;Hamann, B.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;IsosurfaceAndSurfaceExtractionTechniques;ScalarFieldDataTechniques;TopologyBasedTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183772\\\",\\\"Keywords\\\":\\\"data exploration;scalar field topology;critical points;volume visualization;marching cubes;isosurface\\\",\\\"Keywords_Processed\\\":\\\"march cube;scalar field topology;critical point;isosurface;volume visualization;datum exploration\\\",\\\"Title\\\":\\\"Exploring scalar fields using critical isovalues\\\"},\\\"134\\\":{\\\"Abstract\\\":\\\"The Gauss map projects surface normals to a unit sphere, providing a powerful visualization of the geometry of a graphical object. it can be used to predict visual events caused by changes in lighting, shading, and camera control. We present an interactive technique for portraying the Gauss map of polygonal models, mapping surface normals and the magnitudes of surface curvature using a spherical projection. Unlike other visualizations of surface curvature, we create our Gauss map directly from polygonal meshes without requiring any complex intermediate calculations of differential geometry. For anything other than simple shapes, surface information is densely mapped into the Gaussian normal image, inviting the use of visualization techniques to amplify and emphasize details hidden within the wealth of data. We present the use of interactive visualization tools such as brushing and linking to explore the surface properties of solid shapes. The Gauss map is shown to be simple to compute, easy to view dynamically, and effective at portraying important features of polygonal models.\\\",\\\"Authors\\\":\\\"Lowekamp, B.;Rheingans, P.;Yoo, T.S.\\\",\\\"Clusters\\\":\\\"GeometryBasedTechniques;Illumination;InteractionTechniquesGeneral;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183828\\\",\\\"Keywords\\\":\\\"interactive visualization;gauss map;computational geometry;illumination and shading\\\",\\\"Keywords_Processed\\\":\\\"interactive visualization;illumination and shading;gauss map;computational geometry\\\",\\\"Title\\\":\\\"Exploring surface characteristics with interactive Gaussian images (a case study)\\\"},\\\"135\\\":{\\\"Abstract\\\":\\\"Most systems used for creating and displaying colormap-based visualizations are not photometrically calibrated. That is, the relationship between RGB input levels and perceived luminance is usually not known, due to variations in the monitor, hardware configuration, and the viewing environment. However, the luminance component of perceptually based colormaps should be controlled, due to the central role that luminance plays in our visual processing. We address this problem with a simple and effective method for performing luminance matching on an uncalibrated monitor. The method is akin to the minimally distinct border technique (a previous method of luminance matching used for measuring luminous efficiency), but our method relies on the brain's highly developed ability to distinguish human faces. We present a user study showing that our method produces equivalent results to the minimally distinct border technique, but with significantly improved precision. We demonstrate how results from our luminance matching method can be directly applied to create new univariate colormaps.\\\",\\\"Authors\\\":\\\"Kindlmann, G.;Reinhard, E.;Creem, S.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;Illumination;Perception\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183788\\\",\\\"Keywords\\\":\\\"color scales;isoluminance;brightness matching;perceptually-based visualization;colormaps\\\",\\\"Keywords_Processed\\\":\\\"colormaps;perceptually base visualization;color scale;isoluminance;brightness matching\\\",\\\"Title\\\":\\\"Face-based luminance matching for perceptual colormap generation\\\"},\\\"136\\\":{\\\"Abstract\\\":\\\"We present a fast and reliable space-leaping scheme to accelerate ray casting during interactive navigation in a complex volumetric scene, where we combine innovative space-leaping techniques in a number of ways. First, we derive most of the pixel depths at the current frame by exploiting the temporal coherence during navigation, where we employ a novel fast cell-based reprojection scheme that is more reliable than the traditional intersection-point based reprojection. Next, we exploit the object space coherence to quickly detect the remaining pixel depths, by using a precomputed accurate distance field that stores the Euclidean distance from each empty (background) voxel toward its nearest object boundary. In addition, we propose an effective solution to the challenging new-incoming-objects problem during navigation. Our algorithm has been implemented on a 16-processor SGI Power Challenge and reached interactive rendering rates at more than 10 Hz during the navigation inside 5123 volume data sets acquired from both a simulation phantom and actual patients.\\\",\\\"Authors\\\":\\\"Wan, M.;Sadiq, A.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"RaytracingRaycasting;VolumeRenderingModelingAndVisualization;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183775\\\",\\\"Keywords\\\":\\\"raycasting optimization;space leaping;volume visualization;virtual navigation\\\",\\\"Keywords_Processed\\\":\\\"space leap;volume visualization;raycaste optimization;virtual navigation\\\",\\\"Title\\\":\\\"Fast and reliable space leaping for interactive volume rendering\\\"},\\\"137\\\":{\\\"Abstract\\\":\\\"Level-of-detail rendering is essential for rendering very large, detailed worlds in real-time. Unfortunately, level-of-detail computations can be expensive, creating a bottleneck at the CPU. This paper presents the CABTT algorithm, an extension to existing binary-triangle-tree-based level-of-detail algorithms. Instead of manipulating triangles, the CABTT algorithm instead operates on clusters of geometry called aggregate triangles. This reduces CPU overhead, eliminating a bottleneck common to level-of-detail algorithms. Since aggregate triangles stay fixed over several frames, they may be cached on the video card. This further reduces CPU load and fully utilizes the hardware accelerated rendering pipeline on modern video cards. These improvements result in a fourfold increase in frame rate over ROAM at high detail levels. Our implementation renders an approximation of an 8 million triangle height field at 42 frames per second with an maximum error of 1 pixel on consumer hardware.\\\",\\\"Authors\\\":\\\"Levenberg, J.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;GeographyGeospatialVisCartographyTerrainVis;GeometryBasedTechniques;HierarchicalTreeDataAndTechniques;LevelOfDetail;MeshesGridsAndLattices;MultiresolutionTechniques;Rendering;ViewDependentVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183783\\\",\\\"Keywords\\\":\\\"binary triangle trees;multi-resolution;level-of-detail;view-dependent mesh;height fields;triangle bintree;displacement maps;terrain;frame-to-frame coherence\\\",\\\"Keywords_Processed\\\":\\\"displacement map;terrain;multi resolution;frame to frame coherence;triangle bintree;view dependent mesh;binary triangle tree;height field;level of detail\\\",\\\"Title\\\":\\\"Fast view-dependent level-of-detail rendering using cached geometry\\\"},\\\"138\\\":{\\\"Abstract\\\":\\\"We present a robust, noise-resistant criterion characterizing plane-like skeletons in binary voxel objects. It is based on a distance map and the geodesic distance along the object's boundary. A parameter allows us to control the noise sensitivity. If needed, homotopy with the original object might be reconstructed in a second step, using an improved distance ordered thinning algorithm. The skeleton is analyzed to create a geometric representation for rendering. Plane-like parts are transformed into an triangulated surface not enclosing a volume by a suitable triangulation scheme. The resulting surfaces have lower triangle count than those created with standard methods and tend to maintain the original geometry, even after simplification with a high decimation rate. Our algorithm allows us to interactively render expressive images of complex 3D structures, emphasizing independently plane-like and rod-like structures. The methods are applied for visualization of the microstructure of bone biopsies.\\\",\\\"Authors\\\":\\\"Prohaska, S.;Hege, H.-C.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;DataTransformation;GeometricModeling;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183753\\\",\\\"Keywords\\\":\\\"triangulation;distance transform;thinning;visualization;skeletonization\\\",\\\"Keywords_Processed\\\":\\\"visualization;triangulation;distance transform;thin;skeletonization\\\",\\\"Title\\\":\\\"Fast visualization of plane-like structures in voxel data\\\"},\\\"139\\\":{\\\"Abstract\\\":\\\"GeneVis provides a visual environment for exploring the dynamics of genetic regulatory networks. At present time, genetic regulation is the focus of intensive research worldwide, and computational aids are being called for to help in the research of factors that are difficult to observe directly. GeneVis provides a particle-based simulation of genetic networks and visualizes the process of this simulation as it occurs. Two dynamic visualization techniques are provided, a visualization of the movement of the regulatory proteins and a visualization of the relative concentrations of these proteins. Several interactive tools relate the dynamic visualizations to the underlying genetic network structure.\\\",\\\"Authors\\\":\\\"Baker, C.;Carpendale, S.;Prusinkiewicz, P.;Surette, M.G.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;FocusContextTechniques;Genetics;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183781\\\",\\\"Keywords\\\":\\\"lens;biological visualization;focus+context;multi-representation;visualization;genetic networks\\\",\\\"Keywords_Processed\\\":\\\"visualization;genetic network;lens;biological visualization;focus context;multi representation\\\",\\\"Title\\\":\\\"GeneVis: visualization tools for genetic regulatory network dynamics\\\"},\\\"140\\\":{\\\"Abstract\\\":\\\"This paper introduces a method for smoothing complex, noisy surfaces, while preserving (and enhancing) sharp, geometric features. It has two main advantages over previous approaches to feature preserving surface smoothing. First is the use of level set surface models, which allows us to process very complex shapes of arbitrary and changing topology. This generality makes it well suited for processing surfaces that are derived directly from measured data. The second advantage is that the proposed method derives from a well-founded formulation, which is a natural generalization of anisotropic diffusion, as used in image processing. This formulation is based on the proposition that the generalization of image filtering entails filtering the normals of the surface, rather than processing the positions of points on a mesh.\\\",\\\"Authors\\\":\\\"Tasdizen, T.;Whitaker, R.T.;Burchard, P.;Osher, S.\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;DiffusionRelatedTechniques;NumericalMethodsMathematics;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183766\\\",\\\"Keywords\\\":\\\"geometric surface processing;anisotropic diffusion;surface fairing;level sets;intrinsic laplacian of curvature\\\",\\\"Keywords_Processed\\\":\\\"level set;geometric surface processing;intrinsic laplacian of curvature;anisotropic diffusion;surface fair\\\",\\\"Title\\\":\\\"Geometric surface smoothing via anisotropic diffusion of normals\\\"},\\\"141\\\":{\\\"Abstract\\\":\\\"In this paper, we present a verification algorithm for swirling features in flow fields, based on the geometry of streamlines. The features of interest in this case are vortices. Without a formal definition, existing detection algorithms lack the ability to accurately identify these features, and the current method for verifying the accuracy of their results is by human visual inspection. Our verification algorithm addresses this issue by automating the visual inspection process. It is based on identifying the swirling streamlines that surround the candidate vortex cores. We apply our algorithm to both numerically simulated and procedurally generated datasets to illustrate the efficacy of our approach.\\\",\\\"Authors\\\":\\\"Jiang, M.;Machiraju, R.;Thompson, D.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183789\\\",\\\"Keywords\\\":\\\"flow field visualization;feature verification;vortex detection\\\",\\\"Keywords_Processed\\\":\\\"flow field visualization;vortex detection;feature verification\\\",\\\"Title\\\":\\\"Geometric verification of swirling features in flow fields\\\"},\\\"142\\\":{\\\"Abstract\\\":\\\"We present a technique to perform occlusion culling for hierarchical terrains at run-time. The algorithm is simple to implement and requires minimal pre-processing and additional storage, yet leads to 2-4 times improvement in framerate for views with high degrees of occlusion. Our method is based on the well-known occlusion horizon algorithm. We show how to adapt the algorithm for use with hierarchical terrains. The occlusion horizon is constructed as the terrain is traversed in an approximate front to back ordering. Regions of the terrain are compared to the horizon to determine when they are completely occluded from the viewpoint. Culling these regions leads to significant savings in rendering.\\\",\\\"Authors\\\":\\\"Lloyd, B.;Egbert, P.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;OcclusionProblemsTechniques;Rendering\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183801\\\",\\\"Keywords\\\":\\\"occlusion culling;visibility;rendering algorithms\\\",\\\"Keywords_Processed\\\":\\\"render algorithm;occlusion cull;visibility\\\",\\\"Title\\\":\\\"Horizon occlusion culling for real-time rendering of hierarchical terrains\\\"},\\\"143\\\":{\\\"Abstract\\\":\\\"This paper is a documentation of techniques invented, results obtained and lessons learned while creating visualization algorithms to render outputs of large-scale seismic simulations. The objective is the development of techniques for a collaborative simulation and visualization shared between structural engineers, seismologists, and computer scientists. The computer graphics research community has been witnessing a large number of exemplary publications addressing the challenges faced while trying to visualize both large-scale surface and volumetric datasets lately. From a visualization perspective, issues like data preprocessing (simplification, sampling, filtering, etc.); rendering algorithms (surface and volume), and interaction paradigms (large-scale, highly interactive, highly immersive, etc.) have been areas of study. In this light, we outline and describe the milestones achieved in a large-scale simulation and visualization project, which opened the scope for combining existing techniques with new methods, especially in those cases where no existing methods were suitable. We elucidate the data simplification and reorganization schemes that we used, and discuss the problems we encountered and the solutions we found. We describe both desktop (high-end local as well as remote) interfaces and immersive visualization systems that we developed to employ interactive surface and volume rendering algorithms. Finally, we describe the results obtained, challenges that still need to be addressed, and ongoing efforts to meet the challenges of large-scale visualization.\\\",\\\"Authors\\\":\\\"Chopra, P.;Meyer, J.;Fernandez, A.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;LevelOfDetail;MeshesGridsAndLattices;MultiresolutionTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183814\\\",\\\"Keywords\\\":\\\"multi-resolution;mesh simplification;level-of-detail;unstructured meshes\\\",\\\"Keywords_Processed\\\":\\\"unstructured mesh;mesh simplification;multi resolution;level of detail\\\",\\\"Title\\\":\\\"Immersive volume visualization of seismic simulations: A case study of techniques invented and lessons learned\\\"},\\\"144\\\":{\\\"Abstract\\\":\\\"We discuss 3d interaction techniques for the quantitative analysis of spatial relations in medical visualizations. We describe the design and implementation of measurement tools to measure distances, angles and volumes in 3d visualizations. The visualization of measurement tools as recognizable 3d objects and a 3d interaction, which is both intuitive and precise, determines the usability of such facilities. Measurements may be carried out in 2d visualizations of the original radiological data and in 3d visualizations. The result of a measurement carried out in one view is also displayed in the other view appropriately. We discuss the validation of the obtained measures. Finally, we describe how some important measurement tasks may be solved automatically.\\\",\\\"Authors\\\":\\\"Preim, B.;Tietjen, C.;Spindler, W.;Peitgen, H.-O.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;InteractionTechniquesGeneral;QuantitativeEvaluation\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183752\\\",\\\"Keywords\\\":\\\"computer-aided surgery;quantitative analysis;medical visualization;interaction\\\",\\\"Keywords_Processed\\\":\\\"medical visualization;quantitative analysis;computer aid surgery;interaction\\\",\\\"Title\\\":\\\"Integration of measurement tools in medical 3d visualizations\\\"},\\\"145\\\":{\\\"Abstract\\\":\\\"We present a new algorithm for rendering very large volume data sets at interactive frame rates on standard PC hardware. The algorithm accepts scalar data sampled on a regular grid as input. The input data is converted into a compressed hierarchical wavelet representation in a preprocessing step. During rendering, the wavelet representation is decompressed on-the-fly and rendered using hardware texture mapping. The level of detail used for rendering is adapted to the local frequency spectrum of the data and its position relative to the viewer. Using a prototype implementation of the algorithm we were able to perform an interactive walkthrough of large data sets such as the visible human on a single off-the-shelf PC.\\\",\\\"Authors\\\":\\\"Guthe, S.;Wand, M.;Gonser, J.;Strasser, W.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;LevelOfDetail;NumericalMethodsMathematics;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183757\\\",\\\"Keywords\\\":\\\"level-of-detail algorithms;volume rendering;scientific visualization;compression algorithms;wavelets\\\",\\\"Keywords_Processed\\\":\\\"volume render;level of detail algorithm;scientific visualization;wavelet;compression algorithm\\\",\\\"Title\\\":\\\"Interactive rendering of large volume data sets\\\"},\\\"146\\\":{\\\"Abstract\\\":\\\"We describe a method for volume rendering using a spectral representation of colour instead of the traditional RGB model. It is shown how to use this framework for a novel exploration of datasets through enhanced transfer function design. Furthermore, our framework is extended to allow real-time re-lighting of the scene created with any rendering method. The technique of post-illumination is introduced to generate new spectral images for arbitrary light colours in real-time. Also a tool is described to design a palette of lights and materials having certain properties such as selective metamerism or colour constancy. Applied to spectral transfer functions, different light colours can accentuate or hide specific qualities of the data. In connection with post-illumination this provides a new degree of freedom for guided exploration of volumetric data, which cannot be achieved using the RGB model.\\\",\\\"Authors\\\":\\\"Bergner, S.;Moller, T.;Drew, M.S.;Finlayson, G.D.\\\",\\\"Clusters\\\":\\\"Illumination;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183763\\\",\\\"Keywords\\\":\\\"spectral volume rendering;post-illumination;interactive re-lighting\\\",\\\"Keywords_Processed\\\":\\\"spectral volume render;post illumination;interactive re light\\\",\\\"Title\\\":\\\"Interactive spectral volume rendering\\\"},\\\"147\\\":{\\\"Abstract\\\":\\\"Direct volume rendering is a commonly used technique in visualization applications. Many of these applications require sophisticated shading models to capture subtle lighting effects and characteristics of volumetric data and materials. Many common objects and natural phenomena exhibit visual quality that cannot be captured using simple lighting models or cannot be solved at interactive rates using more sophisticated methods. We present a simple yet effective interactive shading model which captures volumetric light attenuation effects to produce volumetric shadows and the subtle appearance of translucency. We also present a technique for volume displacement or perturbation that allows realistic interactive modeling of high frequency detail for real and synthetic volumetric data.\\\",\\\"Authors\\\":\\\"Kniss, J.;Premoze, S.;Hansen, C.;Ebert, D.S.\\\",\\\"Clusters\\\":\\\"GeometricModeling;Rendering;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183764\\\",\\\"Keywords\\\":\\\"volume rendering;procedural modeling;shading model;volume modeling\\\",\\\"Keywords_Processed\\\":\\\"volume render;shade model;procedural modeling;volume model\\\",\\\"Title\\\":\\\"Interactive translucent volume rendering and procedural modeling\\\"},\\\"148\\\":{\\\"Abstract\\\":\\\"We present an algorithm for interactively extracting and rendering isosurfaces of large volume datasets in a view-dependent fashion. A recursive tetrahedral mesh refinement scheme, based on longest edge bisection, is used to hierarchically decompose the data into a multiresolution structure. This data structure allows fast extraction of arbitrary isosurfaces to within user specified view-dependent error bounds. A data layout scheme based on hierarchical space filling curves provides access to the data in a cache coherent manner that follows the data access pattern indicated by the mesh refinement.\\\",\\\"Authors\\\":\\\"Gregorski, B.;Duchaineau, M.;Lindstrom, P.;Pascucci, V.;Joy, K.I.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices;MultiresolutionTechniques;ViewDependentVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183810\\\",\\\"Keywords\\\":\\\"isosurface;multi-resolution tetrahedal meshes;multi-resolution techniques;view-dependent rendering\\\",\\\"Keywords_Processed\\\":\\\"multi resolution tetrahedal mesh;view dependent rendering;multi resolution technique;isosurface\\\",\\\"Title\\\":\\\"Interactive view-dependent rendering of large isosurfaces\\\"},\\\"149\\\":{\\\"Abstract\\\":\\\"We present a method for interactive rendering of large outdoor scenes. Complex polygonal plant models and whole plant populations are represented by relatively small sets of point and line primitives. This enables us to show landscapes faithfully using only a limited percentage of primitives. In addition, a hierarchical data structure allows us to smoothly reduce the geometrical representation to any desired number of primitives. The scene is hierarchically divided into local portions of geometry to achieve large reduction factors for distant regions. Additionally, the data reduction is adapted to the visual importance of geometric objects. This allows us to maintain the visual fidelity of the representation while reducing most of the geometry drastically. With our system, we are able to interactively render very complex landscapes with good visual quality.\\\",\\\"Authors\\\":\\\"Deussen, O.;Colditz, C.;Stamminger, M.;Drettakis, G.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;LevelOfDetail;PointBasedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183778\\\",\\\"Keywords\\\":\\\"level-of-detail algorithms;ecosystems;point-based rendering;synthetic plants\\\",\\\"Keywords_Processed\\\":\\\"point base render;level of detail algorithm;synthetic plant;ecosystem\\\",\\\"Title\\\":\\\"Interactive visualization of complex plant ecosystems\\\"},\\\"150\\\":{\\\"Abstract\\\":\\\"Radial, space-filling (RSF) techniques for hierarchy visualization have several advantages over traditional node-link diagrams, including the ability to efficiently use the display space while effectively conveying the hierarchy structure. Several RSF systems and tools have been developed to date, each with varying degrees of support for interactive operations such as selection and navigation. We describe what we believe to be a complete set of desirable operations on hierarchical structures. We then present InterRing, an RSF hierarchy visualization system that supports a significantly more extensive set of these operations than prior systems. In particular, InterRing supports multi-focus distortions, interactive hierarchy reconfiguration, and both semi-automated and manual selection. We show the power and utility of these and other operations, and describe our on-going efforts to evaluate their effectiveness and usability.\\\",\\\"Authors\\\":\\\"Jing Yang;Ward, M.O.;Rundensteiner, E.A.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;HierarchicalTreeDataAndTechniques;InteractionTechniquesGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2002.1173151\\\",\\\"Keywords\\\":\\\"multi-focus distortion;structure-based brushing;radial space-filling hierarchy visualizations\\\",\\\"Keywords_Processed\\\":\\\"radial space fill hierarchy visualization;multi focus distortion;structure base brushing\\\",\\\"Title\\\":\\\"InterRing: an interactive tool for visually navigating and manipulating hierarchical structures\\\"},\\\"151\\\":{\\\"Abstract\\\":\\\"To display the intuitive meaning of an abstract metric it is helpful to look on an embedded surface with the same inner geometry as the given metric. The resulting partial differential equations have no standard solution. Only for some special cases satisfactory methods are known. I present a new algorithmic approach which is not based on differential equations. In contrast to other methods this technique also works if the embedding exists only locally. The fundamental idea is to estimate Euclidean distances, from which the surface is built up. In this paper I focus on the reconstruction of a surface from these estimated distances. Particular the influence of a perturbation of the distances on the shape of the resulting surface is investigated.\\\",\\\"Authors\\\":\\\"Hotz, I.\\\",\\\"Clusters\\\":\\\"DimensionalityReduction;EvaluationMetricsAndBenchmarks;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183782\\\",\\\"Keywords\\\":\\\"tensor field;metrics;isometric embedding\\\",\\\"Keywords_Processed\\\":\\\"isometric embed;metric;tensor field\\\",\\\"Title\\\":\\\"Isometric embedding by surface reconstruction from distances\\\"},\\\"152\\\":{\\\"Abstract\\\":\\\"Motion provides strong visual cues for the perception of shape and depth, as demonstrated by cognitive scientists and visual artists. This paper presents a novel visualization technique-kinetic visualization -that uses particle systems to add supplemental motion cues which can aid in the perception of shape and spatial relationships of static objects. Based on a set of rules following perceptual and physical principles, particles flowing over the surface of an object not only bring out, but also attract attention to, essential information on the shape of the object that might not be readily visible with conventional rendering that uses lighting and view changes. Replacing still images with animations in this fashion, we demonstrate with both surface and volumetric models in the accompanying videos that in many cases the resulting visualizations effectively enhance the perception of three-dimensional shape and structure. The results of a preliminary user study that we have conducted also show evidence that the supplemental motion cues help.\\\",\\\"Authors\\\":\\\"Lum, E.B.;Stompel, A.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;ParticleVisualizationAndTechniques;Perception;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183805\\\",\\\"Keywords\\\":\\\"volume rendering;visual perception;scientific visualization;animation;particle systems\\\",\\\"Keywords_Processed\\\":\\\"volume render;particle system;visual perception;animation;scientific visualization\\\",\\\"Title\\\":\\\"Kinetic visualization: a technique for illustrating 3D shape and structure\\\"},\\\"153\\\":{\\\"Abstract\\\":\\\"Typically 3-D MR and CT scans have a relatively high resolution in the scanning X-Y plane, but much lower resolution in the axial Z direction. This non-uniform sampling of an object can miss small or thin structures. One way to address this problem is to scan the same object from multiple directions. In this paper we describe a method for deforming a level set model using velocity information derived from multiple volume datasets with non-uniform resolution in order to produce a single high-resolution 3D model. The method locally approximates the values of the multiple datasets by fitting a distance-weighted polynomial using moving least-squares. The proposed method has several advantageous properties: its computational cost is proportional to the object surface area, it is stable with respect to noise, imperfect registrations and abrupt changes in the data, it provides gain-correction, and it employs a distance-based weighting to ensures that the contributions from each scan are properly merged into the final result. We have demonstrated the effectiveness of our approach on four multi-scan datasets, a Griffin laser scan reconstruction, a CT scan of a teapot and MR scans of a mouse embryo and a zucchini.\\\",\\\"Authors\\\":\\\"Museth, K.;Breen, D.;Zhukov, L.;Whitaker, R.T.\\\",\\\"Clusters\\\":\\\"NumericalMethodsMathematics;SegmentationAndClassification;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183773\\\",\\\"Keywords\\\":\\\"level set models;visualization;segmentation;3d reconstruction\\\",\\\"Keywords_Processed\\\":\\\"visualization;3d reconstruction;level set model;segmentation\\\",\\\"Title\\\":\\\"Level set segmentation from multiple non-uniform volume datasets\\\"},\\\"154\\\":{\\\"Abstract\\\":\\\"Finding the \\\\\\\"best\\\\\\\" viewing parameters for a scene is a difficult but very important problem. Fully automatic procedures seem to be impossible as the notion of \\\\\\\"best\\\\\\\" strongly depends on human judgment as well as on the application. In this paper a solution to the sub-problem of placing light sources for given camera parameters is proposed. A light position is defined to be optimal, when the resulting illumination reveals more about the scene than illuminations from all other light positions, i.e. the light position maximizes information that is added to the image through the illumination. With the help of an experiment with several subjects we could adapt the information measure to the actually perceived information content. We present fast global optimization procedures and solutions for two and more light sources.\\\",\\\"Authors\\\":\\\"Gumhold, S.\\\",\\\"Clusters\\\":\\\"DataAndAnalysisMetrics;EvaluationGeneral;Illumination;Optimization;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183785\\\",\\\"Keywords\\\":\\\"illumination;user study;optimization;maximum entropy;visualization;lighting design\\\",\\\"Keywords_Processed\\\":\\\"optimization;visualization;user study;illumination;lighting design;maximum entropy\\\",\\\"Title\\\":\\\"Maximum entropy light source placement\\\"},\\\"155\\\":{\\\"Abstract\\\":\\\"This paper examines a series of NASA outreach visualizations created using several layers of remote sensing satellite data ranging from 4-kilometers per pixel to I-meter per pixel. The viewer is taken on a seamless, cloud free journey from a global view of the Earth down to ground level where buildings, streets, and cars are visible. The visualizations were produced using a procedural shader that takes advantage of accurate georegistration and color matching between images. The shader accurately and efficiently maps the data sets to geometry allowing for animations with few perceptual transitions among data sets. We developed a pipeline to facilitate the production of over twenty zoom visualizations. Millions of people have seen these visualizations through national and international media coverage.\\\",\\\"Authors\\\":\\\"Shirah, G.W.;Mitchell, H.G.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;DataRegistrationFusionAndIntegration;EarthSpaceAndEnvironmentalSciences;GpuBasedTechniques;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183825\\\",\\\"Keywords\\\":\\\"renderman;visualization;georegistration;remote sensing;shader;color matching\\\",\\\"Keywords_Processed\\\":\\\"visualization;color matching;georegistration;remote sensing;shader;renderman\\\",\\\"Title\\\":\\\"NASA's great zooms: a case study\\\"},\\\"156\\\":{\\\"Abstract\\\":\\\"Simulating hand-drawn illustration techniques can succinctly express information in a manner that is communicative and informative. We present a framework for an interactive direct volume illustration system that simulates traditional stipple drawing. By combining the principles of artistic and scientific illustration, we explore several feature enhancement techniques to create effective, interactive visualizations of scientific and medical datasets. We also introduce a rendering mechanism that generates appropriate point lists at all resolutions during an automatic preprocess, and modifies rendering styles through different combinations of these feature enhancements. The new system is an effective way to interactively preview large, complex volume datasets in a concise, meaningful, and illustrative manner. Volume stippling is effective for many applications and provides a quick and efficient method to investigate volume models.\\\",\\\"Authors\\\":\\\"Aidong Lu;Morris, C.J.;Ebert, D.S.;Rheingans, P.;Hansen, C.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;IllustrativeVisualization;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183777\\\",\\\"Keywords\\\":\\\"scientific visualization;volume rendering;non-photorealistic rendering;medical imaging\\\",\\\"Keywords_Processed\\\":\\\"scientific visualization;volume render;non photorealistic rendering;medical imaging\\\",\\\"Title\\\":\\\"Non-photorealistic volume rendering using stippling techniques\\\"},\\\"157\\\":{\\\"Abstract\\\":\\\"In this paper we are presenting a novel approach for rendering large datasets in a view-dependent manner. In a typical view-dependent rendering framework, an appropriate level of detail is selected and sent to the graphics hardware for rendering at each frame. In our approach, we have successfully managed to speed up the selection of the level of detail as well as the rendering of the selected levels. We have accelerated the selection of the appropriate level of detail by not scanning active nodes that do not contribute to the incremental update of the selected level of detail. Our idea is based on imposing a spatial subdivision over the view-dependence trees data-structure, which allows spatial tree cells to refine and merge in real-time rendering to comply with the changes in the active nodes list. The rendering of the selected level of detail is accelerated by using vertex arrays. To overcome the dynamic changes in the selected levels of detail we use multiple small vertex arrays whose sizes depend on the memory on the graphics hardware. These multiple vertex arrays are attached to the active cells of the spatial tree and represent the active nodes of these cells. These vertex arrays, which are sent to the graphics hardware at each frame, merge and split with respect to the changes in the cells of the spatial tree.\\\",\\\"Authors\\\":\\\"El-Sana, J.;Bachmat, E.\\\",\\\"Clusters\\\":\\\"HierarchicalTreeDataAndTechniques;LevelOfDetail;SurfaceRelatedDataAndTechniques;ViewDependentVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183760\\\",\\\"Keywords\\\":\\\"view-dependent rendering;level-of-detail;surface simplification;multi-resolution hierarchies\\\",\\\"Keywords_Processed\\\":\\\"view dependent rendering;multi resolution hierarchy;level of detail;surface simplification\\\",\\\"Title\\\":\\\"Optimized view-dependent rendering for large polygonal datasets\\\"},\\\"158\\\":{\\\"Abstract\\\":\\\"In this paper we develop a new technique for tracing anatomical fibers from 3D tensor fields. The technique extracts salient tensor features using a local regularization technique that allows the algorithm to cross noisy regions and bridge gaps in the data. We applied the method to human brain DT-MRI data and recovered identifiable anatomical structures that correspond to the white matter brain-fiber pathways. The images in this paper are derived from a dataset having 1218860 resolution. We were able to recover fibers with less than the voxel size resolution by applying the regularization technique, i.e., using a priori assumptions about fiber smoothness. The regularization procedure is done through a moving least squares filter directly incorporated in the tracing algorithm.\\\",\\\"Authors\\\":\\\"Zhukov, L.;Barr, A.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;DataFeaturesAndAttributes;FilteringTechniques;NumericalMethodsMathematics;StreamlinesPathlinesStreaklines;TensorDataAndTechniques;Tractography\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183799\\\",\\\"Keywords\\\":\\\"pathways;moving least squares;adaptive filtering;streamlines;salient features;diffusion tensor;fiber tracing\\\",\\\"Keywords_Processed\\\":\\\"diffusion tensor;streamline;adaptive filtering;fiber tracing;move least square;salient feature;pathway\\\",\\\"Title\\\":\\\"Oriented tensor reconstruction: tracing neural pathways from diffusion tensor MRI\\\"},\\\"159\\\":{\\\"Abstract\\\":\\\"We present an external memory algorithm for fast display of very large and complex geometric environments. We represent the model using a scene graph and employ different culling techniques for rendering acceleration. Our algorithm uses a parallel approach to render the scene as well as fetch objects from the disk in a synchronous manner. We present a novel prioritized prefetching technique that takes into account LOD-switching and visibility-based events between successive frames. We have applied our algorithm to large gigabyte-sized environments that are composed of thousands of objects and tens of millions of polygons. The memory overhead of our algorithm is output sensitive and is typically tens of megabytes. In practice, our approach scales with the model sizes, and its rendering performance is comparable to that of an in-core algorithm.\\\",\\\"Authors\\\":\\\"Varadhan, G.;Manocha, D.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;EvaluationGeneral;HardwareAccellerationAndComputationGeneral;LargeScaleDataAndScalability;LevelOfDetail;ProgrammingAlgorithmsAndDataStructures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183759\\\",\\\"Keywords\\\":\\\"large data;visibility;walkthrough;level-of-detail;external memory;prefetching\\\",\\\"Keywords_Processed\\\":\\\"walkthrough;external memory;prefetche;visibility;level of detail;large datum\\\",\\\"Title\\\":\\\"Out-of-core rendering of massive geometric environments\\\"},\\\"160\\\":{\\\"Abstract\\\":\\\"Within the field of computer graphics and visualization, it is often necessary to visualize polygonal models with large number of polygons. Display quality is mandatory, but it is also desirable to have the ability to rapidly update the display in order to facilitate interactive use. Point based rendering methods have been shown effective for this task. Building on this paradigm we introduce the PMR system which uses a hierarchy both in points and triangles for rendering. This hierarchy is fundamentally different from the ones used in existing methods. It is based on the feature geometry in the object space rather than its projection in the screen space. This provides certain advantages over the existing methods.\\\",\\\"Authors\\\":\\\"Dey, T.K.;Hudson, J.\\\",\\\"Clusters\\\":\\\"DataFeaturesAndAttributes;LevelOfDetail;MultiresolutionTechniques;Rendering;VoronoiBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183770\\\",\\\"Keywords\\\":\\\"multi-resolution;voronoi diagram;level-of-detail;features;rendering\\\",\\\"Keywords_Processed\\\":\\\"render;multi resolution;feature;level of detail;voronoi diagram\\\",\\\"Title\\\":\\\"PMR: point to mesh rendering, a feature-based approach\\\"},\\\"161\\\":{\\\"Abstract\\\":\\\"We have created an application, called PRIMA (Patient Record intelligent Monitoring and Analysis), which can be used to visualize and understand patient record data. It was developed to better understand a large collection of patient records of bone marrow transplants at Hadassah Hospital in Jerusalem, Israel. It is based on an information visualization toolkit, Opal, which has been developed at the IBM T.J. Watson Research Center. Opal allows intelligent, interactive visualization of a wide variety of different types of data. The PRIMA application is generally applicable to a wide range of patient record data, as the underlying toolkit is flexible with regard to the form of the input data. This application is a good example of the usefulness of information visualization techniques in the bioinformatics domain, as these techniques have been developed specifically to deal with diverse sets of often unfamiliar data. We illustrate several unanticipated findings which resulted from the use of a flexible and interactive information visualization environment.\\\",\\\"Authors\\\":\\\"Gresh, D.L.;Rabenhorst, D.A.;Shabo, A.;Slavin, S.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;BiomedicalScienceAndMedicine;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183817\\\",\\\"Keywords\\\":\\\"medical records;information visualization;visualization;bioinformatics\\\",\\\"Keywords_Processed\\\":\\\"visualization;information visualization;medical record;bioinformatic\\\",\\\"Title\\\":\\\"PRIMA: A case study of using information visualization techniques for patient record analysis\\\"},\\\"162\\\":{\\\"Abstract\\\":\\\"Efficient and informative visualization of surfaces with uncertainties is an important topic with many applications in science and engineering. Examples include environmental pollution borderline identification, identification of the limits of an oil basin, or discrimination between contaminated and healthy tissue in medicine. This paper presents an approach for such visualization using points as display primitives. The approach is to render each polygon as a collection of points and to displace each point from the surface in the direction of the surface normal by an amount proportional to some random number multiplied by the uncertainty level at that point. This approach can be used in combination with other techniques such as pseudo-coloring and shading to give rise to efficient and revealing visualizations. The method is used to visualize real and simulated tumor formations with uncertainty of tumor boundaries.\\\",\\\"Authors\\\":\\\"Grigoryan, G.;Rheingans, P.\\\",\\\"Clusters\\\":\\\"PointBasedDataAndTechniques;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183769\\\",\\\"Keywords\\\":\\\"points as display primitives;uncertainty;visualizing surface uncertainty\\\",\\\"Keywords_Processed\\\":\\\"visualize surface uncertainty;uncertainty;point as display primitive\\\",\\\"Title\\\":\\\"Probabilistic surfaces: point based primitives to show surface uncertainty\\\"},\\\"163\\\":{\\\"Abstract\\\":\\\"We demonstrate how we apply information visualization techniques to process monitoring. Virtual instruments are enhanced using history encoding instruments are capable of displaying the current value and the value from the near past. Multi-instruments are capable of displaying several data sources simultaneously. Levels of detail for virtual instruments are introduced where the screen area is inversely proportional to the information amount displayed. Furthermore the monitoring system is enhanced by using: 3D anchoring attachment of instruments to positions on a 3D model, collision avoidance a physically based spring model prevents instruments from overlapping, and focus+context rendering - giving the user a possibility to examine particular instruments in detail without loosing the context information.\\\",\\\"Authors\\\":\\\"Matkovic, K.;Hauser, H.;Sainitzer, R.;Groller, E.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;LevelOfDetail;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2002.1173149\\\",\\\"Keywords\\\":\\\"information visualization;level-of-detail;focus+context visualization;process visualization\\\",\\\"Keywords_Processed\\\":\\\"focus context visualization;process visualization;information visualization;level of detail\\\",\\\"Title\\\":\\\"Process visualization with levels of detail\\\"},\\\"164\\\":{\\\"Abstract\\\":\\\"Interactive visualization of large digital elevation models is of continuing interest in scientific visualization, GIS, and virtual reality applications. Taking advantage of the regular structure of grid digital elevation models, efficient hierarchical multiresolution triangulation and adaptive level-of-detail (LOD) rendering algorithms have been developed for interactive terrain visualization. Despite the higher triangle count, these approaches generally outperform mesh simplification methods that produce irregular triangulated network (TIN) based LOD representations. In this project we combine the advantage of a TIN based mesh simplification preprocess with high-performance quadtree based LOD triangulation and rendering at run-time. This approach, called QuadTIN, generates an efficient quadtree triangulation hierarchy over any irregular point set that may originate from irregular terrain sampling or from reducing oversampling in high-resolution grid digital elevation models.\\\",\\\"Authors\\\":\\\"Pajarola, R.;Antonijuan, M.;Lario, R.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;GraphNetworkDataAndTechniques;LevelOfDetail;MeshesGridsAndLattices\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183800\\\",\\\"Keywords\\\":\\\"level-of-detail;multi-resolution triangulation;triangulated irregular networks;realtime terrain visualization\\\",\\\"Keywords_Processed\\\":\\\"triangulate irregular network;realtime terrain visualization;level of detail;multi resolution triangulation\\\",\\\"Title\\\":\\\"QuadTIN: quadtree based triangulated irregular networks\\\"},\\\"165\\\":{\\\"Abstract\\\":\\\"For quantitative examination of phenomena that simultaneously occur on very different spatial and temporal scales, adaptive hierarchical schemes are required. A special numerical multilevel technique, associated with a particular hierarchical data structure, is so-called adaptive mesh refinement (AMR). It allows one to bridge a wide range of spatial and temporal resolutions and therefore gains increasing popularity. We describe the interplay of several visualization and VR software packages for rendering time dependent AMR simulations of the evolution of the first star in the universe. The work was done in the framework of a television production for Discovery Channel television, \\\\\\\"The Unfolding Universe.\\\\\\\". Parts of the data were taken from one of the most complex AMR simulation ever carried out: It contained up to 27 levels of resolution, requiring modifications to the texture based AMR volume rendering algorithm that was used to depict the density distribution of the gaseous interstellar matter. A voice and gesture controlled CAVE application was utilized to define camera paths following the interesting features deep inside the computational domains. Background images created from cosmological computational data were combined with the final renderings.\\\",\\\"Authors\\\":\\\"Kahler, R.;Cox, D.;Patterson, R.;Levy, S.;Hege, H.-C.;Abel, T.\\\",\\\"Clusters\\\":\\\"ImmersiveAndVirtualEnvironments;MeshesGridsAndLattices;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183824\\\",\\\"Keywords\\\":\\\"3d texture-based volume rendering;cave applications;adaptive mesh refinement data;visualization\\\",\\\"Keywords_Processed\\\":\\\"visualization;cave application;adaptive mesh refinement datum;3d texture base volume render\\\",\\\"Title\\\":\\\"Rendering the first star in the Universe - A case study\\\"},\\\"166\\\":{\\\"Abstract\\\":\\\"This paper presents a vision-based geometric alignment system for aligning the projectors in an arbitrarily large display wall. Existing algorithms typically rely on a single camera view and degrade in accuracy as the display resolution exceeds the camera resolution by several orders of magnitude. Naive approaches to integrating multiple zoomed camera views fail since small errors in aligning adjacent views propagate quickly over the display surface to create glaring discontinuities. Our algorithm builds and refines a camera homography tree to automatically register any number of uncalibrated camera images; the resulting system is both faster and significantly more accurate than competing approaches, reliably achieving alignment errors of 0.55 pixels on a 24-projector display in under 9 minutes. Detailed experiments compare our system to two recent display wall alignment algorithms, both on our 18 Megapixel display wall and in simulation. These results indicate that our approach achieves sub-pixel accuracy even on displays with hundreds of projectors.\\\",\\\"Authors\\\":\\\"Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.\\\",\\\"Clusters\\\":\\\"AutomaticAnalysisVisualizationTechniques;CamerasCameraViewsAndProjections;EvaluationGeneral;LargeAndHighResDisplays;LargeScaleDataAndScalability;Simulation\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183793\\\",\\\"Keywords\\\":\\\"camera-projector systems;camera-based registration and calibration;large-format tiled projection display;wall displays;automatic alignment;scalability;simulation;evaluation\\\",\\\"Keywords_Processed\\\":\\\"wall display;camera base registration and calibration;scalability;camera projector system;large format tile projection display;automatic alignment;simulation;evaluation\\\",\\\"Title\\\":\\\"Scalable alignment of large-format multi-projector displays using camera homography trees\\\"},\\\"167\\\":{\\\"Abstract\\\":\\\"A long-standing research problem in computer graphics is to reproduce the visual experience of walking through a large photorealistic environment interactively. On one hand, traditional geometry-based rendering systems fall short of simulating the visual realism of a complex environment. On the other hand, image-based rendering systems have to date been unable to capture and store a sampled representation of a large environment with complex lighting and visibility effects. In this paper, we present a \\\\\\\"sea of images,\\\\\\\" a practical approach to dense sampling, storage, and reconstruction of the plenoptic function in large, complex indoor environments. We use a motorized cart to capture omnidirectional images every few inches on a eye-height plane throughout an environment. The captured images are compressed and stored in a multiresolution hierarchy suitable for real-time prefetching during an interactive walkthrough. Later, novel images are reconstructed for a simulated observer by resampling nearby captured images. Our system acquires 15,254 images over 1,050 square feet at an average image spacing of 1.5 inches. The average capture and processing time is 7 hours. We demonstrate realistic walkthroughs of real-world environments reproducing specular reflections and occlusion effects while rendering 15-25 frames per second.\\\",\\\"Authors\\\":\\\"Aliaga, D.;Funkhouser, T.;Yanovsky, D.;Carlbom, I.\\\",\\\"Clusters\\\":\\\"DataAcquisitionAndManagement;EvaluationGeneral;ImageBasedDataImageSignalProcessing;InteractionTechniquesGeneral;Interpolation\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183792\\\",\\\"Keywords\\\":\\\"walkthrough;reconstruction;interactive;capture;image-based rendering\\\",\\\"Keywords_Processed\\\":\\\"image base render;walkthrough;reconstruction;capture;interactive\\\",\\\"Title\\\":\\\"Sea of images\\\"},\\\"168\\\":{\\\"Abstract\\\":\\\"Surface texturing aids the visualization of polygonal meshes by providing additional surface orientation cues and feature annotations. Such texturing is usually implemented via texture mapping, which is easier and more effective when the distortion of the mapping from the surface to the texture map is kept small. We have previously shown that distortion occurs when areas of high surface curvature are flattened into the texture map. By cutting the surface in these areas one can reduce texture map distortion at the expense of additional seam artifacts. This paper describes a faster technique for guiding a texture map seam through high distortion regions, while restricting the seam to regions of low visibility. This results in distortion reducing seams that are less visually distracting and take less time to compute. We have also observed that visibility considerations improve the speed of a recent method that adds cuts to reduce a surface genus.\\\",\\\"Authors\\\":\\\"Sheffer, A.;Hart, J.C.\\\",\\\"Clusters\\\":\\\"SegmentationAndClassification;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183787\\\",\\\"Keywords\\\":\\\"texture mapping;visibility classification\\\",\\\"Keywords_Processed\\\":\\\"texture mapping;visibility classification\\\",\\\"Title\\\":\\\"Seamster: inconspicuous low-distortion texture seam layout\\\"},\\\"169\\\":{\\\"Abstract\\\":\\\"By offering more detail and precision, large data sets can provide greater insights to researchers than small data sets. However, these data sets require greater computing resources to view and manage. Remote visualization techniques allow the use of computers that cannot be operated locally. The Semotus Visum framework applies a high-performance client-server paradigm to the problem. The framework utilizes both client and server resources via multiple rendering methods. Experimental results show the framework delivers high frame rates and low latency across a wide range of data sets.\\\",\\\"Authors\\\":\\\"Luke, E.J.;Hansen, C.\\\",\\\"Clusters\\\":\\\"DistributedSystemsAndGridEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183758\\\",\\\"Keywords\\\":\\\"remote visualization;client-server\\\",\\\"Keywords_Processed\\\":\\\"client server;remote visualization\\\",\\\"Title\\\":\\\"Semotus Visum: a flexible remote visualization framework\\\"},\\\"170\\\":{\\\"Abstract\\\":\\\"We propose the use of textured splats as the basic display primitives for an open surface fire model. The high-detail textures help to achieve a smooth boundary of the fire and gain the small-scale turbulence appearance. We utilize the Lattice Boltzmann Model (LBM) to simulate physically-based equations describing the fire evolution and its interaction with the environment (e.g., obstacles, wind and temperature). The property of fuel and non-burning objects are defined on the lattice of the computation domain. A temperature field is also incorporated to model the generation of smoke from the fire due to incomplete combustion. The linear and local characteristics of the LBM enable us to accelerate the computation with graphics hardware to reach real-time simulation speed, while the texture splat primitives enable interactive rendering frame rates.\\\",\\\"Authors\\\":\\\"Wei, X.;Wei Li;Mueller, K.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"InputAndOutputDevicesGeneral;MeshesGridsAndLattices;PhysicsAndPhysicalSciences;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183779\\\",\\\"Keywords\\\":\\\"lattice boltzmann model;textured splatting;fire modeling;graphics hardware\\\",\\\"Keywords_Processed\\\":\\\"lattice boltzmann model;fire modeling;texture splatting;graphic hardware\\\",\\\"Title\\\":\\\"Simulating fire with texture splats\\\"},\\\"171\\\":{\\\"Abstract\\\":\\\"While many methods exist for visualising scalar and vector data, visualisation of tensor data is still troublesome. We present a method for visualising second order tensors in three dimensions using a hybrid between direct volume rendering and glyph rendering. An overview scalar field is created by using three-dimensional adaptive filtering of a scalar field containing noise. The filtering process is controlled by the tensor field to be visualised, creating patterns that characterise the tensor field. By combining direct volume rendering of the scalar field with standard glyph rendering methods for detailed tensor visualisation, a hybrid solution is created. A combined volume and glyph renderer was implemented and tested with both synthetic tensors and strain-rate tensors from the human heart muscle, calculated from phase contrast magnetic resonance image data. A comprehensible result could be obtained, giving both an overview of the tensor field as well as detailed information on individual tensors.\\\",\\\"Authors\\\":\\\"Sigfridsson, A.;Ebbers, T.;Heiberg, E.;Wigstrom, L.\\\",\\\"Clusters\\\":\\\"GlyphsGlyphBasedTechniques;MaterialScience;Rendering;TensorDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183797\\\",\\\"Keywords\\\":\\\"glyph rendering;tensor;volume rendering;hybrid rendering;strain-rate;visualization\\\",\\\"Keywords_Processed\\\":\\\"visualization;volume render;hybrid render;glyph render;tensor;strain rate\\\",\\\"Title\\\":\\\"Tensor field visualisation using adaptive filtering of noise fields combined with glyph rendering\\\"},\\\"172\\\":{\\\"Abstract\\\":\\\"This paper introduces an algorithm for rapid progressive simplification of tetrahedral meshes: TetFusion. We describe how a simple geometry decimation operation steers a rapid and controlled progressive simplification of tetrahedral meshes, while also taking care of complex mesh-inconsistency problems. The algorithm features a high decimation ratio per step, and inherently discourages any cases of self-intersection of boundary, element-boundary intersection at concave boundary-regions, and negative volume tetrahedra (flipping). We achieved rigorous reduction ratios of up to 98% for meshes consisting of 827,904 elements in less than 2 minutes, progressing through a series of level-of-details (LoDs) of the mesh in a controlled manner. We describe how the approach supports a balanced re-distribution of space between tetrahedral elements, and explain some useful control parameters that make it faster and more intuitive than 'edge collapse'-based decimation methods for volumetric meshes. Finally, we discuss how this approach can be employed for rapid LoD prototyping of large time-varying datasets as an aid to interactive visualization.\\\",\\\"Authors\\\":\\\"Chopra, P.;Meyer, J.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;LevelOfDetail;MeshesGridsAndLattices;MultiresolutionTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183767\\\",\\\"Keywords\\\":\\\"multi-resolution;mesh simplification;level-of-detail;unstructured meshes\\\",\\\"Keywords_Processed\\\":\\\"unstructured mesh;mesh simplification;multi resolution;level of detail\\\",\\\"Title\\\":\\\"TetFusion: an algorithm for rapid tetrahedral mesh simplification\\\"},\\\"173\\\":{\\\"Abstract\\\":\\\"Visualization is a powerful way to facilitate data analysis, but it is crucial that visualization systems explicitly convey the presence, nature, and degree of uncertainty to users. Otherwise, there is a danger that data will be falsely interpreted, potentially leading to inaccurate conclusions. A common method for denoting uncertainty is to use error bars or similar techniques designed to convey the degree of statistical uncertainty. While uncertainty can often be modeled statistically, a second form of uncertainty, bounded uncertainty, can also arise that has very different properties than statistical uncertainty. Error bars should not be used for bounded uncertainty because they do not convey the correct properties, so a different technique should be used instead. We describe a technique for conveying bounded uncertainty in visualizations and show how it can be applied systematically to common displays of abstract charts and graphs. Interestingly, it is not always possible to show the exact degree of uncertainty, and in some cases it can only be displayed approximately.\\\",\\\"Authors\\\":\\\"Olston, C.;Mackinlay, J.\\\",\\\"Clusters\\\":\\\"UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2002.1173145\\\",\\\"Keywords\\\":\\\"bounded uncertainty;uncertainty visualization\\\",\\\"Keywords_Processed\\\":\\\"bound uncertainty;uncertainty visualization\\\",\\\"Title\\\":\\\"Visualizing data with bounded uncertainty\\\"},\\\"174\\\":{\\\"Abstract\\\":\\\"The bioactivity of a molecule strongly depends on its metastable conformational shapes and the transitions between these. Therefore, conformation analysis and visualization is a basic prerequisite for the understanding of biochemical processes. We present techniques for visual analysis of metastable molecular conformations. Core of these are flexibly applicable methods for alignment of molecular geometries, as well as methods for depicting shape and 'fuzziness' of metastable conformations. All analysis tools are provided in an integrated working environment. The described techniques are demonstrated with pharmaceutically active biomolecules.\\\",\\\"Authors\\\":\\\"Schmidt-Ehrenberg, J.;Baum, D.;Hege, H.-C.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;MolecularScienceAndChemistry;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183780\\\",\\\"Keywords\\\":\\\"drug design;molecular conformation analysis;molecular modeling;uncertainty visualization\\\",\\\"Keywords_Processed\\\":\\\"molecular modeling;molecular conformation analysis;uncertainty visualization;drug design\\\",\\\"Title\\\":\\\"Visualizing dynamic molecular conformations\\\"},\\\"175\\\":{\\\"Abstract\\\":\\\"We propose new clipping methods that are capable of using complex geometries for volume clipping. The clipping tests exploit per-fragment operations on the graphics hardware to achieve high frame rates. In combination with texture-based volume rendering, these techniques enable the user to interactively select and explore regions of the data set. We present depth-based clipping techniques that analyze the depth structure of the boundary representation of the clip geometry to decide which parts of the volume have to be clipped. In another approach, a voxelized clip object is used to identify the clipped regions.\\\",\\\"Authors\\\":\\\"Weiskopf, D.;Engel, K.;Ertl, T.\\\",\\\"Clusters\\\":\\\"HardwareAccellerationAndComputationGeneral;Rendering;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183762\\\",\\\"Keywords\\\":\\\"clipping;volume rendering;hardware acceleration\\\",\\\"Keywords_Processed\\\":\\\"volume render;clipping;hardware acceleration\\\",\\\"Title\\\":\\\"Volume clipping via per-fragment operations in texture-based volume visualization\\\"},\\\"176\\\":{\\\"Abstract\\\":\\\"Visualizing second-order 3D tensor fields continue to be a challenging task. Although there are several algorithms that have been presented, no single algorithm by itself is sufficient for the analysis because of the complex nature of tensor fields. In this paper, we present two new methods, based on volume deformation, to show the effects of the tensor field upon its underlying media. We focus on providing a continuous representation of the nature of the tensor fields. Each of these visualization algorithms is good at displaying some particular properties of the tensor field.\\\",\\\"Authors\\\":\\\"Zheng, X.;Pang, A.\\\",\\\"Clusters\\\":\\\"MaterialScience;PhysicsAndPhysicalSciences;TensorDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183798\\\",\\\"Keywords\\\":\\\"strain;symmetric tensors;stress;antisymmetric tensor;anisotropic tensors;shear\\\",\\\"Keywords_Processed\\\":\\\"strain;antisymmetric tensor;anisotropic tensor;symmetric tensor;shear;stress\\\",\\\"Title\\\":\\\"Volume deformation for tensor visualization\\\"},\\\"177\\\":{\\\"Abstract\\\":\\\"Polygonal approximations of isosurfaces extracted from uniformly sampled volumes are increasing in size due to the availability of higher resolution imaging techniques. The large number of I primitives represented hinders the interactive exploration of the dataset. Though many solutions have been proposed to this problem, many require the creation of isosurfaces at multiple resolutions or the use of additional data structures, often hierarchical, to represent the volume. We propose a technique for adaptive isosurface extraction that is easy to implement and allows the user to decide the degree of adaptivity as well as the choice of isosurface extraction algorithm. Our method optimizes the extraction of the isosurface by warping the volume. In a warped volume, areas of importance (e.g. containing significant details) are inflated while unimportant ones are contracted. Once the volume is warped, any extraction algorithm can be applied. The extracted mesh is subsequently unwarped such that the warped areas are rescaled to their initial proportions. The resulting isosurface is represented by a mesh that is more densely sampled in regions decided as important.\\\",\\\"Authors\\\":\\\"Balmelli, L.;Morris, C.J.;Taubin, G.;Bernardini, F.\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;IsosurfaceAndSurfaceExtractionTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183809\\\",\\\"Keywords\\\":\\\"isosurface;adaptive tessellation;volume warping;adaptive isosurface extraction\\\",\\\"Keywords_Processed\\\":\\\"adaptive tessellation;adaptive isosurface extraction;volume warp;isosurface\\\",\\\"Title\\\":\\\"Volume warping for adaptive isosurface extraction\\\"},\\\"178\\\":{\\\"Abstract\\\":\\\"We present a novel disk-based multiresolution triangle mesh data structure that supports paging and view-dependent rendering of very large meshes at interactive frame rates from external memory. Our approach, called XFastMesh, is based on a view-dependent mesh simplification framework that represents half-edge collapse operations in a binary hierarchy known as a merge-tree forest. The proposed technique partitions the merge-tree forest into so-called detail blocks, which consist of binary subtrees, that are stored on disk. We present an efficient external memory data structure and file format that stores all detail information of the multiresolution triangulation method using significantly less storage then previously reported approaches. Furthermore, we present a paging algorithm that provides efficient loading and interactive rendering of large meshes from external memory at varying and view-dependent level-of-detail. The presented approach is highly efficient both in terms of space cost and paging performance.\\\",\\\"Authors\\\":\\\"DeCoro, C.;Pajarola, R.\\\",\\\"Clusters\\\":\\\"LargeScaleDataAndScalability;LevelOfDetail;MultiresolutionTechniques;OutOfCoreProcessing\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2002.1183796\\\",\\\"Keywords\\\":\\\"out-of-core rendering;level-of-detail;multi-resolution modeling;interactive large-scale visualization\\\",\\\"Keywords_Processed\\\":\\\"out of core render;multi resolution modeling;interactive large scale visualization;level of detail\\\",\\\"Title\\\":\\\"XFastMesh: fast view-dependent meshing from external memory\\\"},\\\"179\\\":{\\\"Abstract\\\":\\\"We describe a new animation technique for supporting interactive exploration of a graph. We use the wellknown radial tree layout method, in which the view is determined by the selection of a focus node. Our main contribution is a method for animating the transition to a new layout when a new focus node is selected. In order to keep the transition easy to follow, the animation linearly interpolates the polar coordinates of the nodes, while enforcing ordering and orientation constraints. We apply this technique to visualizations of social networks and of the Gnutella file-sharing network, and discuss the results from our informal usability tests.\\\",\\\"Authors\\\":\\\"Ka-Ping Yee;Fisher, D.;Dhamija, R.;Hearst, M.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;GraphNetworkDataAndTechniques;InteractionTechniquesGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2001.963279\\\",\\\"Keywords\\\":\\\"animation;graph drawing;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;graph drawing;animation\\\",\\\"Title\\\":\\\"Animated exploration of dynamic graphs with radial layout\\\"},\\\"180\\\":{\\\"Abstract\\\":\\\"A new method for the visualization of huge hierarchical data structures is presented. The method is based on the observation that we can easily see the branches, leaves, and their arrangement in a botanical tree, despite of the large number of elements. The strand model of Holton is used to convert an abstract tree into a geometric model. Nonleaf nodes are mapped to branches and child nodes to subbranches. A naive application of this model leads to unsatisfactory results, hence it is tailored to suit our purposes better. Continuing branches are emphasized, long branches are contracted, and sets of leaves are shown as fruit. The method is applied to the visualization of directory structures. The elements, directories and files, as well as their relations can easily be extracted, thereby showing that the use of methods from botanical modeling can be effective for information visualization.\\\",\\\"Authors\\\":\\\"Kleiberg, E.;van de Wetering, H.;van Wijk, J.J.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;HierarchicalTreeDataAndTechniques;LineBasedTechniquesAndApproaches\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2001.963285\\\",\\\"Keywords\\\":\\\"phyllotaxis;huge hierarchy;strands;tree visualization;botanical tree;logical tree;directory tree\\\",\\\"Keywords_Processed\\\":\\\"phyllotaxis;huge hierarchy;directory tree;logical tree;strand;tree visualization;botanical tree\\\",\\\"Title\\\":\\\"Botanical visualization of huge hierarchies\\\"},\\\"181\\\":{\\\"Abstract\\\":\\\"This paper proposes a new visualization and interaction technique for medium-sized trees, called Collapsible Cylindrical Trees (CCT). Child nodes are mapped on rotating cylinders, which will be dynamically displayed or hidden to achieve a useful balance of detail and context. Besides a comprehensible threedimensional visualization of trees, the main feature of CCT is a very fast and intuitive interaction with the displayed nodes. Only a single click is needed to reach every node and perform an action on it, such as displaying a web page. The CCT browsing technique was developed for interaction with web hierarchies but is not limited to this domain. We also present sample implementations of CCT using VRML, which show the usefulness of this intuitive tree navigation technique.\\\",\\\"Authors\\\":\\\"Dachselt, R.;Ebert, J.\\\",\\\"Clusters\\\":\\\"HierarchicalTreeDataAndTechniques;InternetWebVisualizationForTheMasses;ProgrammingAlgorithmsAndDataStructures;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2001.963284\\\",\\\"Keywords\\\":\\\"hierarchy;xml;sitemap;visualization;web navigation;vrml;3d graphics;interactive tree\\\",\\\"Keywords_Processed\\\":\\\"visualization;web navigation;hierarchy;3d graphic;sitemap;xml;vrml;interactive tree\\\",\\\"Title\\\":\\\"Collapsible cylindrical trees: a fast hierarchical navigation technique\\\"},\\\"182\\\":{\\\"Abstract\\\":\\\"We discuss four methodologies for the application of node grouping in graph visualization. In addition, we introduce techniques for force-directed and orthogonal drawing which use node grouping information and have been shown in experiments to perform better than previous techniques. Not only do these techniques have significantly improved performance with respect to standard aesthetic measures, but they also attain qualitative improvement.\\\",\\\"Authors\\\":\\\"Six, J.M.;Tollis, I.G.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;GraphNetworkDataAndTechniques;TextDocumentTopicAnalysisDataAndTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2001.963280\\\",\\\"Keywords\\\":\\\"graph drawing;force-directed drawing;orthogonal drawing;graph visualization;node grouping;experimental studies\\\",\\\"Keywords_Processed\\\":\\\"experimental study;graph drawing;orthogonal drawing;node group;force direct drawing;graph visualization\\\",\\\"Title\\\":\\\"Effective graph visualization via node grouping\\\"},\\\"183\\\":{\\\"Abstract\\\":\\\"We introduce the notion of Graph Sketches. They can be thought of as visual indices that guide the navigation of a multi-graph too large to fit on the available display. We adhere to the Visual Information-Seeking Mantra: Overview first, zoom and filter, then details on demand. Graph Sketches are incorporated into MGV, an integrated visualization and exploration system for massive multi-digraph navigation. We highlight the main algorithmic and visualization tasks behind the computation of Graph Sketches and illustrate several application scenarios. Graph Sketches will be used to guide the navigation of multi-digraphs defined on vertex sets with sizes ranging from 100 to 250 million vertices.\\\",\\\"Authors\\\":\\\"Abello, J.;Finocchi, I.;Korn, J.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;HierarchicalTreeDataAndTechniques;LargeScaleDataAndScalability;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2001.963282\\\",\\\"Keywords\\\":\\\"visualization;massive data sets;hierarchy;graph\\\",\\\"Keywords_Processed\\\":\\\"visualization;massive data set;hierarchy;graph\\\",\\\"Title\\\":\\\"Graph sketches\\\"},\\\"184\\\":{\\\"Abstract\\\":\\\"Treemaps, a space-filling method of visualizing large hierarchical data sets, are receiving increasing attention. Several algorithms have been proposed to create more useful displays by controlling the aspect ratios of the rectangles that make up a treemap. While these algorithms do improve visibility of small items in a single layout, they introduce instability over time in the display of dynamically changing data, and fail to preserve an ordering of the underlying data. This paper introduces the ordered treemap, which addresses these two shortcomings. The ordered treemap algorithm ensures that items near each other in the given order will be near each other in the treemap layout. Using experimental evidence from Monte Carlo trials, we show that compared to other layout algorithms ordered treemaps are more stable while maintaining relatively favorable aspect ratios of the constituent rectangles. A second test set uses stock market data.\\\",\\\"Authors\\\":\\\"Shneiderman, B.;Wattenberg, M.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;HierarchicalTreeDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2001.963283\\\",\\\"Keywords\\\":\\\"information visualization;hierarchy;treemap;tree;ordered treemaps\\\",\\\"Keywords_Processed\\\":\\\"hierarchy;treemap;information visualization;tree;order treemap\\\",\\\"Title\\\":\\\"Ordered treemap layouts\\\"},\\\"185\\\":{\\\"Abstract\\\":\\\"We present a new technique called Semantic Depth of Field (SDOF) as an alternative approach to focus-and-context displays of information. We utilize a well-known method from photography and cinematography (depth-of-field effect) for information visualization, which is to blur different parts of the depicted scene in dependence of their relevance. Independent of their spatial locations, objects of interest are depicted sharply in SDOF, whereas the context of the visualization is blurred. In this paper, we present a flexible model of SDOF which can be easily adopted to various types of applications. We discuss pros and cons of the new technique, give examples of application, and describe a fast prototype implementation of SDOF.\\\",\\\"Authors\\\":\\\"Kosara, R.;Miksch, S.;Hauser, H.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;FocusContextTechniques;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2001.963286\\\",\\\"Keywords\\\":\\\"information visualization;focus+context;depth of field\\\",\\\"Keywords_Processed\\\":\\\"depth of field;information visualization;focus context\\\",\\\"Title\\\":\\\"Semantic depth of field\\\"},\\\"186\\\":{\\\"Abstract\\\":\\\"In this paper, we present a new approach for the visualization of time-series data based on spirals. Different to classical bar charts and line graphs, the spiral is suited to visualize large data sets and supports much better the identification of periodic structures in the data. Moreover, it supports both the visualization of nominal and quantitative data based on a similar visualization metaphor. The extension of the spiral visualization to 3D gives access to concepts for zooming and focusing and linking in the data set. As such, spirals complement other visualization techniques for time series and specifically enhance the identication of periodic patterns.\\\",\\\"Authors\\\":\\\"Weber, M.;Alexa, M.;Muller, W.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;GraphNetworkDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2001.963273\\\",\\\"Keywords\\\":\\\"time-series visualization;data mining;information visualization;graph drawing\\\",\\\"Keywords_Processed\\\":\\\"time series visualization;graph drawing;information visualization;datum mining\\\",\\\"Title\\\":\\\"Visualizing time-series on spirals\\\"},\\\"187\\\":{\\\"Abstract\\\":\\\"We advocate the use of point sets to represent shapes. We provide a definition of a smooth manifold surface from a set of points close to the original surface. The definition is based on local maps from differential geometry, which are approximated by the method of moving least squares (MLS). We present tools to increase or decrease the density of the points, thus, allowing an adjustment of the spacing among the points to control the fidelity of the representation. To display the point set surface, we introduce a novel point rendering technique. The idea is to evaluate the local maps according to the image resolution. This results in high quality shading effects and smooth silhouettes at interactive frame rates.\\\",\\\"Authors\\\":\\\"Alexa, M.;Behr, J.;Cohen-Or, D.;Fleishman, S.;Levin, D.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"DataAcquisitionAndManagement;NumericalMethodsMathematics;PointBasedDataAndTechniques;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964489\\\",\\\"Keywords\\\":\\\"surface representation and reconstruction;moving least squares;point sample rendering;3d acquisition\\\",\\\"Keywords_Processed\\\":\\\"surface representation and reconstruction;3d acquisition;point sample render;move least square\\\",\\\"Title\\\":\\\"Point set surfaces\\\"},\\\"188\\\":{\\\"Abstract\\\":\\\"In this paper we present a novel framework for direct volume rendering using a splatting approach based on elliptical Gaussian kernels. To avoid aliasing artifacts, we introduce the concept of a resampling filter combining a reconstruction with a low-pass kernel. Because of the similarity to Heckbert's EWA (elliptical weighted average) filter for texture mapping we call our technique EWA volume splatting. It provides high image quality without aliasing artifacts or excessive blurring even with non-spherical kernels. Hence it is suitable for regular, rectilinear, and irregular volume data sets. Moreover, our framework introduces a novel approach to compute the footprint function. It facilitates efficient perspective projection of arbitrary elliptical kernels at very little additional cost. Finally, we show that EWA volume reconstruction kernels can be reduced to surface reconstruction kernels. This makes our splat primitive universal in reconstructing surface and volume data.\\\",\\\"Authors\\\":\\\"Zwicker, M.;Pfister, H.;van Baar, J.;Gross, M.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964490\\\",\\\"Keywords\\\":\\\"splatting;antialiasing;volume rendering\\\",\\\"Keywords_Processed\\\":\\\"volume render;antialiase;splatte\\\",\\\"Title\\\":\\\"EWA volume splatting\\\"},\\\"189\\\":{\\\"Abstract\\\":\\\"Multi-resolution hierarchies of polygons and more recently of points are familiar and useful tools for achieving interactive rendering rates. We present an algorithm for tightly integrating the two into a single hierarchical data structure. The trade-off between rendering portions of a model with points or with polygons is made automatically. Our approach to this problem is to apply a bottom-up simplification process involving not only polygon simplification operations, but point replacement and point simplification operations as well. Given one or more surface meshes, our algorithm produces a hybrid hierarchy comprising both polygon and point primitives. This hierarchy may be optimized according to the relative performance characteristics of these primitive types on the intended rendering platform. We also provide a range of aggressiveness for performing point replacement operations. The most conservative approach produces a hierarchy that is better than a purely polygonal hierarchy in some places, and roughly equal in others. A less conservative approach can trade reduced complexity at the far viewing ranges for some increased complexity at the near viewing ranges. We demonstrate our approach on a number of input models, achieving primitive counts that are 1.3 to 4.7 times smaller than those of triangle-only simplification.\\\",\\\"Authors\\\":\\\"Cohen, J.D.;Aliaga, D.;Weiqiang Zhang\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;MeshesGridsAndLattices;MultiresolutionTechniques;PointBasedDataAndTechniques;Rendering;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964491\\\",\\\"Keywords\\\":\\\"multi-resolution;hybrid;points;triangle;simplification;rendering\\\",\\\"Keywords_Processed\\\":\\\"render;multi resolution;triangle;point;simplification;hybrid\\\",\\\"Title\\\":\\\"Hybrid simplification: combining multi-resolution polygon and point rendering\\\"},\\\"190\\\":{\\\"Abstract\\\":\\\"We introduce a simple but effective extension to the existing pure point rendering systems. Rather than using only points, we use both points and polygons to represent and render large mesh models. We start from triangles as leaf nodes and build up a hierarchical tree structure with intermediate nodes as points. During the rendering, the system determines whether to use a point (of a certain intermediate level node) or a triangle (of a leaf node) for display depending on the screen contribution of each node. While points are used to speedup the rendering of distant objects, triangles are used to ensure the quality of close objects. Our method can accelerate the rendering of large models, compromising little in image quality.\\\",\\\"Authors\\\":\\\"Chen, B.;Nguyen, M.X.\\\",\\\"Clusters\\\":\\\"LevelOfDetail;Rendering;SpaceRelatedSpatialDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964492\\\",\\\"Keywords\\\":\\\"level-of-detail algorithms;hybrid rendering systems;rendering system;spatial data structures\\\",\\\"Keywords_Processed\\\":\\\"hybrid render system;level of detail algorithm;render system;spatial data structure\\\",\\\"Title\\\":\\\"POP: A Hybrid Point and Polygon Rendering System for Large Data\\\"},\\\"191\\\":{\\\"Abstract\\\":\\\"The visualization of time-dependent flow is an important and challenging topic in scientific visualization. Its aim is to represent transport phenomena governed by time-dependent vector fields in an intuitively understandable way, using images and animations. Here we pick up the recently presented anisotropic diffusion method, expand and generalize it to allow a multiscale visualization of long-term, complex transport problems. Instead of streamline type patterns generated by the original method now streakline patterns are generated and advected. This process obeys a nonlinear transport diffusion equation with typically dominant transport. Starting from some noisy initial image, the diffusion actually generates and enhances patterns which are then transported in the direction of the flow field. Simultaneously the image is again sharpened in the direction orthogonal to the flow field. A careful adjustment of the models parameters is derived to balance diffusion and transport effects in a reasonable way. Properties of the method can be discussed for the continuous model, which is solved by an efficient upwind finite element discretization. As characteristic for the class of multiscale image processing methods, we can in advance select a suitable scale for representing the flow field.\\\",\\\"Authors\\\":\\\"Burkle, D.;Preusser, T.;Rumpf, M.\\\",\\\"Clusters\\\":\\\"DiffusionRelatedTechniques;FlowVisualizationDataAndTechniques;ImageBasedDataImageSignalProcessing;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964494\\\",\\\"Keywords\\\":\\\"flow visualization;upwind method;non-linear diffusion;transport diffusion;multi-scale image processing\\\",\\\"Keywords_Processed\\\":\\\"upwind method;transport diffusion;non linear diffusion;multi scale image processing;flow visualization\\\",\\\"Title\\\":\\\"Transport and anisotropic diffusion in time-dependent flow visualization\\\"},\\\"192\\\":{\\\"Abstract\\\":\\\"The visualization of scalar functions of two variables is a classic and ubiquitous application. We present a new method to visualize such data. The method is based on a non-linear mapping of the function to a height field, followed by visualization as a shaded mountain landscape. The method is easy to implement and efficient, and leads to intriguing and insightful images: The visualization is enriched by adding ridges. Three types of applications are discussed: visualization of iso-levels, clusters (multivariate data visualization), and dense contours (flow visualization).\\\",\\\"Authors\\\":\\\"van Wijk, J.J.;Telea, A.\\\",\\\"Clusters\\\":\\\"ContourCreasesRidgesValleys;FlowVisualizationDataAndTechniques;GeometryBasedTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964495\\\",\\\"Keywords\\\":\\\"flow visualization;contours;height fields;mapping;multivariate visualization\\\",\\\"Keywords_Processed\\\":\\\"contour;height field;mapping;multivariate visualization;flow visualization\\\",\\\"Title\\\":\\\"Enridged Contour Maps\\\"},\\\"193\\\":{\\\"Abstract\\\":\\\"Remote experience of sporting events has thus far been limited mostly to watching video and the scores and statistics associated with the sport. However, a fast-developing trend is the use of visualization techniques to give new insights into performance, style, and strategy of the players. Automated techniques can extract accurate information from video about player performance that not even the most skilled observer is able to discern. When presented as static images or as a three-dimensional virtual replay, this information makes viewing a game an entirely new and exciting experience.This paper presents one such sports visualization system called LucentVision, which has been developed for the sport of tennis. LucentVision uses real-time video analysis to obtain motion trajectories of players and the ball, and offers a rich set of visualization options based on this trajectory data. The system has been used extensively in the broadcast of international tennis tournaments, both on television and the Internet.\\\",\\\"Authors\\\":\\\"Pingali, G.;Opalach, A.;Jean, Y.;Carlbom, I.\\\",\\\"Clusters\\\":\\\"ImmersiveAndVirtualEnvironments;InputAndOutputDevicesGeneral;MultimediaImageVideoMusic;SportsVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964496\\\",\\\"Keywords\\\":\\\"virtual environment;telepresence;realtime video analysis;sports visualization;multi-camera tracking;multimedia indexing\\\",\\\"Keywords_Processed\\\":\\\"virtual environment;realtime video analysis;multimedia indexing;sport visualization;multi camera tracking;telepresence\\\",\\\"Title\\\":\\\"Visualization of Sports using Motion Trajectories: Providing Insights into Performance, Style, and Strategy\\\"},\\\"194\\\":{\\\"Abstract\\\":\\\"Shape modeling is an integral part of many visualization problems. Recent advances in scanning technology and a number of surface reconstruction algorithms have opened up a new paradigm for modeling shapes from samples. Many of the problems currently faced in this modeling paradigm can be traced back to two anomalies in sampling, namely undersampling and oversampling. Boundaries, non-smoothness and small features create undersampling problems, whereas oversampling leads to too many triangles. We use Voronoi cell geometry as a unified guide to detect undersampling and oversampling. We apply these detections in surface reconstruction and model simplification. Guarantees of the algorithms can be proved. The authors show the success of the algorithms empirically on a number of interesting data sets.\\\",\\\"Authors\\\":\\\"Dey, T.K.;Giesen, J.;Goswami, S.;Hudson, J.;Wenger, R.;Wulue Zhao\\\",\\\"Clusters\\\":\\\"GeometricModeling;GeometryBasedTechniques;MeshesGridsAndLattices;ShapeRelatedTechniques;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964497\\\",\\\"Keywords\\\":\\\"polygonal modeling;shape recognition;computational geometry;mesh generation;geometric modeling;polygonal mesh reduction;surface reconstruction\\\",\\\"Keywords_Processed\\\":\\\"mesh generation;surface reconstruction;geometric modeling;shape recognition;polygonal mesh reduction;polygonal modeling;computational geometry\\\",\\\"Title\\\":\\\"Undersampling and oversampling in sample based shape modeling\\\"},\\\"195\\\":{\\\"Abstract\\\":\\\"The classification of volumetric data sets as well as their rendering algorithms are typically based on the representation of the underlying grid. Grid structures based on a Cartesian lattice are the de-facto standard for regular representations of volumetric data. In this paper we introduce a more general concept of regular grids for the representation of volumetric data. We demonstrate that a specific type of regular lattice-the so-called body-centered cubic-is able to represent the same data set as a Cartesian grid to the same accuracy but with 29.3% fewer samples. This speeds up traditional volume rendering algorithms by the same ratio, which we demonstrate by adopting a splatting implementation for these new lattices. We investigate different filtering methods required for computing the normals on this lattice. The lattice representation results also in lossless compression ratios that are better than previously reported. Although other regular grid structures achieve the same sample efficiency, the body-centered cubic is particularly easy to use. The only assumption necessary is that the underlying volume is isotropic and band-limited-an assumption that is valid for most practical data sets.\\\",\\\"Authors\\\":\\\"Theussl, T.;Mller, T.;Groller, E.\\\",\\\"Clusters\\\":\\\"MaterialScience;MeshesGridsAndLattices;Sampling;SpaceRelatedSpatialDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964498\\\",\\\"Keywords\\\":\\\"body-centered cubic;close packing;cartesian grid;hexagonal sampling;volume data\\\",\\\"Keywords_Processed\\\":\\\"body center cubic;hexagonal sampling;volume datum;cartesian grid;close packing\\\",\\\"Title\\\":\\\"Optimal regular volume sampling\\\"},\\\"196\\\":{\\\"Abstract\\\":\\\"We present a simple denoising technique for geometric data represented as a semiregular mesh, based on locally adaptive Wiener filtering. The degree of denoising is controlled by a single parameter (an estimate of the relative noise level) and the time required for denoising is independent of the magnitude of the estimate. The performance of the algorithm is sufficiently fast to allow interactive local denoising.\\\",\\\"Authors\\\":\\\"Jianbo Peng;Strela, V.;Zorin, D.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;MachineLearningAndStatistics;MeshesGridsAndLattices;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964500\\\",\\\"Keywords\\\":\\\"gaussian scale mixture model;mesh;denoising;multi-resolution surfaces\\\",\\\"Keywords_Processed\\\":\\\"denoise;mesh;gaussian scale mixture model;multi resolution surface\\\",\\\"Title\\\":\\\"A simple algorithm for surface denoising\\\"},\\\"197\\\":{\\\"Abstract\\\":\\\"The paper describes a novel application of feature preserving mesh simplification to the problem of managing large, multidimensional datasets during scientific visualization. To allow this, we view a scientific dataset as a triangulated mesh of data elements, where the attributes embedded in each element form a set of properties arrayed across the surface of the mesh. Existing simplification techniques were not designed to address the high dimensionality that exists in these types of datasets. In addition, vertex operations that relocate, insert, or remove data elements may need to be modified or restricted. Principal component analysis provides an algorithm-independent method for compressing a dataset's dimensionality during simplification. Vertex locking forces certain data elements to maintain their spatial locations; this technique is also used to guarantee a minimum density in the simplified dataset. The result is a visualization that significantly reduces the number of data elements to display, while at the same time ensuring that high-variance regions of potential interest remain intact. We apply our techniques to a number of well-known feature preserving algorithms, and demonstrate their applicability in a real-world context by simplifying a multidimensional weather dataset. Our results show a significant improvement in execution time with only a small reduction in accuracy; even when the dataset was simplified to 10% of its original size, average per attribute error was less than 1%.\\\",\\\"Authors\\\":\\\"Walter, J.D.;Healey, C.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;DataAcquisitionAndManagement;DimensionalityReduction;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964501\\\",\\\"Keywords\\\":\\\"scientific visualization;mesh simplification;dataset management;principal component analysis\\\",\\\"Keywords_Processed\\\":\\\"scientific visualization;dataset management;mesh simplification;principal component analysis\\\",\\\"Title\\\":\\\"Attribute preserving dataset simplification\\\"},\\\"198\\\":{\\\"Abstract\\\":\\\"The authors propose three simple, but significant improvements to the OoCS (Out-of-Core Simplification) algorithm of P. Lindstrom (2000) which increase the quality of approximations and extend the applicability of the algorithm to an even larger class of compute systems. The original OoCS algorithm has memory complexity that depends on the size of the output mesh, but no dependency on the size of the input mesh. That is, it can be used to simplify meshes of arbitrarily large size, but the complexity of the output mesh is limited by the amount of memory available. Our first contribution is a version of OoCS that removes the dependency of having enough memory to hold (even) the simplified mesh. With our new algorithm, the whole process is made essentially independent of the available memory on the host computer. Our new technique uses disk instead of main memory, but it is carefully designed to avoid costly random accesses. Our two other contributions improve the quality of the approximations generated by OoCS. We propose a scheme for preserving surface boundaries which does not use connectivity information, and a scheme for constraining the position of the \\\\\\\"representative vertex\\\\\\\" of a grid cell to an optimal position inside the cell.\\\",\\\"Authors\\\":\\\"Lindstrom, P.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;LargeScaleDataAndScalability;OutOfCoreProcessing\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964502\\\",\\\"Keywords\\\":\\\"large data;external sorting;polygonal surface simplification;out-of-core algorithm;quadric error metrics\\\",\\\"Keywords_Processed\\\":\\\"out of core algorithm;quadric error metric;polygonal surface simplification;external sorting;large datum\\\",\\\"Title\\\":\\\"A memory insensitive technique for large model simplification\\\"},\\\"199\\\":{\\\"Abstract\\\":\\\"The growing availability of massive polygonal models, and the inability of most existing visualization tools to work with such data, has created a pressing need for memory efficient methods capable of simplifying very large meshes. In this paper, we present a method for performing adaptive simplification of polygonal meshes that are too large to fit in-core.Our algorithm performs two passes over an input mesh. In the first pass, the model is quantized using a uniform grid, and surface information is accumulated in the form of quadrics and dual quadrics. This sampling is then used to construct a BSP-Tree in which the partitioning planes are determined by the dual quadrics. In the final pass, the original vertices are clustered using the BSP-Tree, yielding an adaptive approximation of the original mesh. The BSP-Tree describes a natural simplification hierarchy, making it possible to generate a progressive transmission and construct level-of-detail representations. In this way, the algorithm provides some of the features associated with more expensive edge contraction methods while maintaining greater computational efficiency. In addition to performing adaptive simplification, our algorithm exhibits output-sensitive memory requirements and allows fine control over the size of the simplified mesh.\\\",\\\"Authors\\\":\\\"Shaffer, E.;Garland, M.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;MeshesGridsAndLattices;OutOfCoreProcessing;SegmentationAndClassification;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964503\\\",\\\"Keywords\\\":\\\"out-of-core simplification;recursive partitioning;surface simplification;quadric error metrics;massive meshes\\\",\\\"Keywords_Processed\\\":\\\"quadric error metric;massive mesh;recursive partitioning;out of core simplification;surface simplification\\\",\\\"Title\\\":\\\"Efficient Adaptive Simplification of Massive Meshes\\\"},\\\"200\\\":{\\\"Abstract\\\":\\\"We describe a method to visualize the connectivity graph of a mesh using a natural embedding in 3D space. This uses a 3D shape representation that is based solely on mesh connectivity: the connectivity shape. Given a connectivity, we define its natural geometry as a smooth embedding in space with uniform edge lengths and describe efficient techniques to compute it. Our main contribution is to demonstrate that a surprising amount of geometric information is implicit in the connectivity. We also show how to generate connectivity shapes that approximate given 3D shapes. Potential applications of connectivity shapes to modeling and mesh coding are described.\\\",\\\"Authors\\\":\\\"Isenburg, M.;Gumhold, S.;Gotsman, C.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;MeshesGridsAndLattices;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964504\\\",\\\"Keywords\\\":\\\"mesh connectivity;polygonal meshes;implicit geometry;shape compression;natural embedding\\\",\\\"Keywords_Processed\\\":\\\"implicit geometry;mesh connectivity;natural embedding;polygonal mesh;shape compression\\\",\\\"Title\\\":\\\"Connectivity shapes\\\"},\\\"201\\\":{\\\"Abstract\\\":\\\"Presents results from a user study that compared six visualization methods for 2D vector data. Two methods used different distributions of short arrows, two used different distributions of integral curves, one used wedges located to suggest flow lines, and the final one was line-integral convolution (LIC). We defined three simple but representative tasks for users to perform using visualizations from each method: (1) locating all critical points in an image, (2) identifying critical point types, and (3) advecting a particle. The results show different strengths and weaknesses for each method. We found that users performed better with methods that: (1) showed the sign of vectors within the vector field, (2) visually represented integral curves, and (3) visually represented the locations of critical points. These results provide quantitative support for some of the anecdotal evidence concerning visualization methods. The tasks and testing framework also provide a basis for comparing other visualization methods, for creating more effective methods and for defining additional tasks to further understand tradeoffs among methods. They may also be useful for evaluating 2D vectors on 2D surfaces embedded in 3D and for defining analogous tasks for 3D visualization methods.\\\",\\\"Authors\\\":\\\"Laidlaw, D.H.;Kirby, R.M.;Davidson, J.S.;Miller, T.S.;da Silva, M.;Warren, W.H.;Tarr, M.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;FlowVisualizationDataAndTechniques;GlyphsGlyphBasedTechniques;PhysicsAndPhysicalSciences;StreamlinesPathlinesStreaklines;Textures;TopologyBasedTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964505\\\",\\\"Keywords\\\":\\\"jittered grid icons;user study;advection;critical points;scientific visualization;streamlines;iconic textures;fluid flow;line integral convolution;fluid dynamics;2d vector field;image-guided streamlines\\\",\\\"Keywords_Processed\\\":\\\"line integral convolution;jittered grid icon;user study;streamline;scientific visualization;2d vector field;fluid flow;fluid dynamic;image guide streamline;critical point;iconic texture;advection\\\",\\\"Title\\\":\\\"Quantitative comparative evaluation of 2D vector field visualization methods\\\"},\\\"202\\\":{\\\"Abstract\\\":\\\"This paper presents a new algorithm for the calculation of stream surfaces for tetrahedral grids. It propagates the surface through the tetrahedra, one at a time, calculating the intersections with the tetrahedral faces. The method allows us to incorporate topological information from the cells, e.g. critical points. The calculations are based on barycentric coordinates, since this simplifies the theory and the algorithm. The stream surfaces are ruled surfaces inside each cell, and their construction starts with line segments on the faces. Our method supports the analysis of velocity fields resulting from computational fluid dynamics (CFD) simulations.\\\",\\\"Authors\\\":\\\"Scheuermann, G.;Bobach, T.;Hagen, H.;Mahrous, K.;Hamann, B.;Joy, K.I.;Kollmann, W.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;MeshesGridsAndLattices;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964506\\\",\\\"Keywords\\\":\\\"flow surface;flow visualization;tetrahedral grid;vector field visualization;unstructured grid\\\",\\\"Keywords_Processed\\\":\\\"tetrahedral grid;unstructured grid;flow surface;vector field visualization;flow visualization\\\",\\\"Title\\\":\\\"A tetrahedra-based stream surface algorithm\\\"},\\\"203\\\":{\\\"Abstract\\\":\\\"Vector fields can present complex structural behavior, especially in turbulent computational fluid dynamics. The topological analysis of these data sets reduces the information, but one is usually still left with too many details for interpretation. In this paper, we present a simplification approach that removes pairs of critical points from the data set, based on relevance measures. In contrast to earlier methods, no grid changes are necessary, since the whole method uses small local changes of the vector values defining the vector field. An interpretation in terms of bifurcations underlines the continuous, natural flavor of the algorithm.\\\",\\\"Authors\\\":\\\"Tricoche, X.;Scheuermann, G.;Hagen, H.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;FlowVisualizationDataAndTechniques;MeshesGridsAndLattices;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964507\\\",\\\"Keywords\\\":\\\"flow visualization;vector field topology;simplification;unstructured grid\\\",\\\"Keywords_Processed\\\":\\\"vector field topology;simplification;unstructured grid;flow visualization\\\",\\\"Title\\\":\\\"Continuous topology simplification of planar vector fields\\\"},\\\"204\\\":{\\\"Abstract\\\":\\\"This paper presents PixelFlex - a spatially reconfigurable multi-projector display system. The PixelFlex system is composed of ceiling-mounted projectors, each with computer-controlled pan, tilt, zoom and focus; and a camera for closed-loop calibration. Working collectively, these controllable projectors function as a single logical display capable of being easily modified into a variety of spatial formats of differing pixel density, size and shape. New layouts are automatically calibrated within minutes to generate the accurate warping and blending functions needed to produce seamless imagery across planar display surfaces, thus giving the user the flexibility to quickly create, save and restore multiple screen configurations. Overall, PixelFlex provides a new level of automatic reconfigurability and usage, departing from the static, one-size-fits-all design of traditional large-format displays. As a front-projection system, PixelFlex can be installed in most environments with space constraints and requires little or no post-installation mechanical maintenance because of the closed-loop calibration.\\\",\\\"Authors\\\":\\\"Ruigang Yang;Gotz, D.;Hensley, J.;Towles, H.;Brown, M.S.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;LargeAndHighResDisplays\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964508\\\",\\\"Keywords\\\":\\\"camera-based registration and calibration;large-format projection display\\\",\\\"Keywords_Processed\\\":\\\"large format projection display;camera base registration and calibration\\\",\\\"Title\\\":\\\"PixelFlex: a reconfigurable multi-projector display system\\\"},\\\"205\\\":{\\\"Abstract\\\":\\\"Front-projection display environments suffer from a fundamental problem: users and other objects in the environment can easily and inadvertently block projectors, creating shadows on the displayed image. We introduce a technique that detects and corrects transient shadows in a multi-projector display. Our approach is to minimize the difference between predicted (generated) and observed (camera) images by continuous modification of the projected image values for each display device. We are unaware of any other technique that directly addresses this problem. Furthermore, we speculate that the general predictive monitoring framework introduced here is capable of addressing more general radiometric consistency problems such as display-surface inter-reflections and the changes in display color and intensity due to projector bulb temperature variation.Using an automatically-derived relative position of cameras and projectors in the display environment and a straightforward color correction scheme, the system renders an expected image for each camera location. Cameras observe the displayed image, which is compared with the expected image to detect shadowed regions. These regions are transformed to the appropriate projector frames, where corresponding pixel values are increased. In display regions where more than one projector contributes to the image, shadow regions are eliminated. We demonstrate an implementation of the technique to remove shadows in a multi-projector front projection system.\\\",\\\"Authors\\\":\\\"Jaynes, C.;Webb, S.;Steele, R.M.;Brown, M.S.;Seales, W.B.\\\",\\\"Clusters\\\":\\\"DisplaysGeneral;ImmersiveAndVirtualEnvironments;LargeAndHighResDisplays;Rendering\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964509\\\",\\\"Keywords\\\":\\\"calibration;shadow removal;immersive media;large-scale display\\\",\\\"Keywords_Processed\\\":\\\"immersive medium;shadow removal;large scale display;calibration\\\",\\\"Title\\\":\\\"Dynamic Shadow Removal from Front Projection Displays\\\"},\\\"206\\\":{\\\"Abstract\\\":\\\"We have developed a fast, perceptual method for selecting color scales for data visualization that takes advantage of our sensitivity to luminance variations in human faces. To do so, we conducted experiments in which we mapped various color scales onto the intensity values of a digitized photograph of a face and asked observers to rate each image. We found a very strong correlation between the perceived naturalness of the images and the degree to which the underlying color scales increased monotonically in luminance. Color scales that did not include a monotonically increasing luminance component produced no positive rating scores. Since color scales with monotonic luminance profiles are widely recommended for visualizing continuous scalar data, a purely visual technique for identifying such color scales could be very useful, especially in situations where color calibration is not integrated into the visualization environment, such as over the Internet.\\\",\\\"Authors\\\":\\\"Rogowitz, B.;Kalvin, A.D.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964510\\\",\\\"Keywords\\\":\\\"human color vision;perceptual color scales;internet color;visual artifacts in visualization\\\",\\\"Keywords_Processed\\\":\\\"visual artifact in visualization;internet color;perceptual color scale;human color vision\\\",\\\"Title\\\":\\\"The \\\\\\\"Which Blair project\\\\\\\": a quick visual method for evaluating perceptual color maps\\\"},\\\"207\\\":{\\\"Abstract\\\":\\\"We present the circular incident edge lists (CIEL), a new data structure and a high-performance algorithm for generating a series of iso-surfaces in a highly unstructured grid. Slicing-based volume rendering is also considered. The CIEL data structure represents all the combinatorial information of the grid, making it possible to optimize the classical propagation from local minima paradigm. The usual geometric structures are replaced by a more efficient combinatorial structure. An active edges list is maintained, and iteratively propagated from an iso-surface to the next one in a very efficient way. The intersected cells incident to each active edge are retrieved, and the intersection polygons are generated by circulating around their facets. This latter feature enables arbitrary irregular cells to be treated, such as those encountered in certain computational fluid dynamics (CFD) simulations. Since the CIEL data structure solely depends on the connections between the cells, it is possible to take into account dynamic changes in the geometry of the mesh and in property values, which only requires the sorted extrema list to be updated. Experiments have shown that our approach is significantly faster than classical methods. The major drawback of our method is its memory consumption, higher than most classical methods. However, experimental results show that it stays within a practical range.\\\",\\\"Authors\\\":\\\"Levy, B.;Caumon, G.;Conreaux, S.;Cavin, X.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices;TopologyBasedTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964511\\\",\\\"Keywords\\\":\\\"isosurface;combinatorial topology;volume rendering;unstructured grid\\\",\\\"Keywords_Processed\\\":\\\"volume render;combinatorial topology;isosurface;unstructured grid\\\",\\\"Title\\\":\\\"Circular incident edge lists: a data structure for rendering complex unstructured grids\\\"},\\\"208\\\":{\\\"Abstract\\\":\\\"Since the original paper of Lacroute and Levoy (1994), where the shear-warp factorization was also shown for perspective projections, a lot of work has been carried out using the shear-warp factorization with parallel projections. However, none of it has proved or improved the algorithm for the perspective projection. Also in Lacroute's Volpack library, the perspective shear-warp volume rendering algorithm is missing. This paper reports on an implementation of the perspective shear-warp algorithm, which includes enhancements for its application in immersive virtual environments. Furthermore, a mathematical proof for the correctness of the permutation of projection and warp is provided, so far a basic assumption of the shear-warp perspective projection.\\\",\\\"Authors\\\":\\\"Schulze, R.P.;Niemeier, R.;Lang, U.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;ImmersiveAndVirtualEnvironments;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964513\\\",\\\"Keywords\\\":\\\"virtual environment;perspective shear-warp;volume rendering\\\",\\\"Keywords_Processed\\\":\\\"virtual environment;volume render;perspective shear warp\\\",\\\"Title\\\":\\\"The perspective shear-warp algorithm in a virtual environment\\\"},\\\"209\\\":{\\\"Abstract\\\":\\\"Automatic detection of meaningful isosurfaces is important for producing informative visualizations of volume data, especially when no information about the data origin and imaging protocol is available. We propose a computationally efficient method for the automated detection of intensity transitions in volume data. In this approach, the dominant transitions correspond to clear maxima in cumulative Laplacian-weighted gray value histograms. Only one pass through the data volume is required to compute the histogram. Several other features which may be useful for exploration of data of unknown origin can be efficiently computed in a similar manner. The detected intensity transitions can be used for setting of visualization parameters for surface rendering, as well as for direct volume rendering of 3D datasets. When using surface rendering, the detected dominant intensity transition values correspond to the optimal surface isovalues for extraction of boundaries of the objects of interest. In direct volume rendering, such transitions are important for generation of the transfer functions, which are used to assign visualization properties to data voxels and determine the appearance of the rendered image. The proposed method is illustrated by examples with synthetic data as well as real biomedical datasets.\\\",\\\"Authors\\\":\\\"Pekar, V.;Wiemker, R.;Hempel, D.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;SurfaceRelatedDataAndTechniques;VectorFieldsDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964515\\\",\\\"Keywords\\\":\\\"volume rendering;divergence theorem;volume visualization;isosurface;surface rendering\\\",\\\"Keywords_Processed\\\":\\\"volume render;surface render;isosurface;divergence theorem;volume visualization\\\",\\\"Title\\\":\\\"Fast detection of meaningful isosurfaces for volume data visualization\\\"},\\\"210\\\":{\\\"Abstract\\\":\\\"Volume graphics has not been accepted for widespread use. One of the inhibiting reasons is the lack of general methods for data-analysis and simple interfaces for data exploration. An error-and-trial iterative procedure is often used to select a desirable transfer function or mine the dataset for salient iso-values. New semi-automatic methods that are also data-centric have shown much promise. However, general and robust methods are still needed for data-exploration and analysis. In this paper, we propose general model-independent statistical methods based on central moments of data. Using these techniques we show how salient iso-surfaces at material boundaries can be determined. We provide examples from the medical and computational domain to demonstrate the effectiveness of our methods.\\\",\\\"Authors\\\":\\\"Tenginakai, S.;Jinho Lee;Machiraju, R.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964516\\\",\\\"Keywords\\\":\\\"direct volume rendering;iso-values;transfer function;surface extraction\\\",\\\"Keywords_Processed\\\":\\\"iso value;transfer function;surface extraction;direct volume render\\\",\\\"Title\\\":\\\"Salient iso-surface detection with model-independent statistical signatures\\\"},\\\"211\\\":{\\\"Abstract\\\":\\\"We present a generic method for rapid flight planning, virtual navigation and effective camera control in a volumetric environment. Directly derived from an accurate distance from boundary (DFB) field, our automatic path planning algorithm rapidly generates centered flight paths, a skeleton, in the navigable region of the virtual environment. Based on precomputed flight paths and the DFB field, our dual-mode physically based camera control model supports a smooth, safe, and sticking-free virtual navigation with six degrees of freedom. By using these techniques, combined with accelerated volume rendering, we have successfully developed a real-time virtual colonoscopy system on low-cost PCs and confirmed the high speed, high accuracy and robustness of our techniques on more than 40 patient datasets.\\\",\\\"Authors\\\":\\\"Wan, M.;Dachille, F.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;CamerasCameraViewsAndProjections;GeometricModeling;PhysicsAndPhysicalSciences;VisualizationTechniquesAndToolsGeneral;VolumeRenderingModelingAndVisualization;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964517\\\",\\\"Keywords\\\":\\\"physically-based modeling;distance field;path planning;virtual colonoscopy;virtual navigation;centerline;volumetric environment;camera control\\\",\\\"Keywords_Processed\\\":\\\"camera control;distance field;virtual colonoscopy;volumetric environment;path planning;virtual navigation;centerline;physically base modeling\\\",\\\"Title\\\":\\\"Distance-field based skeletons for virtual navigation\\\"},\\\"212\\\":{\\\"Abstract\\\":\\\"Distance fields are an important volume representation. A high quality distance field facilitates accurate surface characterization and gradient estimation. However, due to Nyquist's law, no existing volumetric methods based on the linear sampling theory can fully capture surface details, such as comers and edges, in 3D space. We propose a novel complete distance field representation (CDFR) that does not rely on Nyquist's sampling theory. To accomplish this, we construct a volume where each voxel has a complete description of all portions of surface that affect the local distance field. For any desired distance, we are able to extract a surface contour in true Euclidean distance, at any level of accuracy, from the same CDFR representation. Such point-based iso-distance contours have faithful per-point gradients and can be interactively visualized using splatting, providing per-point shaded image quality. We also demonstrate applying CDFR to a cutting edge design for manufacturing application involving high-complexity parts at unprecedented accuracy using only commonly available computational resources.\\\",\\\"Authors\\\":\\\"Huang, J.;Yan Li;Crawfis, R.;Shao-Chiung Lu;Shuh-Yuan Liou\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;MeshesGridsAndLattices;PointBasedDataAndTechniques;VisualizationTechniquesAndToolsGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964518\\\",\\\"Keywords\\\":\\\"distance field;polygonal surfaces;graphics;point-based models;volume modeling\\\",\\\"Keywords_Processed\\\":\\\"distance field;point base model;polygonal surface;graphic;volume model\\\",\\\"Title\\\":\\\"A complete distance field representation\\\"},\\\"213\\\":{\\\"Abstract\\\":\\\"Most direct volume renderings produced today employ one-dimensional transfer functions, which assign color and opacity to the volume based solely on the single scalar quantity which comprises the dataset. Though they have not received widespread attention, multi-dimensional transfer functions are a very effective way to extract specific material boundaries and convey subtle surface properties. However, identifying good transfer functions is difficult enough in one dimension, let alone two or three dimensions. This paper demonstrates an important class of three-dimensional transfer functions for scalar data (based on data value, gradient magnitude, and a second directional derivative), and describes a set of direct manipulation widgets which make specifying such transfer functions intuitive and convenient. We also describe how to use modem graphics hardware to interactively render with multi-dimensional transfer functions. The transfer functions, widgets, and hardware combine to form a powerful system for interactive volume exploration.\\\",\\\"Authors\\\":\\\"Kniss, J.;Kindlmann, G.;Hansen, C.\\\",\\\"Clusters\\\":\\\"InputAndOutputDevicesGeneral;InteractionTechniquesGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964519\\\",\\\"Keywords\\\":\\\"graphics hardware;direct manipulation widgets;direct volume rendering;multi-dimensional transfer function;volume visualization\\\",\\\"Keywords_Processed\\\":\\\"graphic hardware;direct manipulation widget;multi dimensional transfer function;direct volume render;volume visualization\\\",\\\"Title\\\":\\\"Interactive volume rendering using multi-dimensional transfer functions and direct manipulation widgets\\\"},\\\"214\\\":{\\\"Abstract\\\":\\\"In this paper we present a hardware-assisted rendering technique coupled with a compression scheme for the interactive visual exploration of time-varying scalar volume data. A palette-based decoding technique and an adaptive bit allocation scheme are developed to fully utilize the texturing capability of a commodity 3-D graphics card. Using a single PC equipped with a modest amount of memory, a texture capable graphics card, and an inexpensive disk array, we are able to render hundreds of time steps of regularly gridded volume data (up to 45 millions voxels each time step) at interactive rates, permitting the visual exploration of large scientific data sets in both the temporal and spatial domain.\\\",\\\"Authors\\\":\\\"Lum, E.B.;Ma, K.-L.;Clyne, J.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;DataTransformation;HardwareAccellerationAndComputationGeneral;InputAndOutputDevicesGeneral;OutOfCoreProcessing;TimeseriesTimeVaryingDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964520\\\",\\\"Keywords\\\":\\\"volume rendering;time-varying data;pc;scientific visualization;compression;high-performance computing;out-of-core processing;transform encoding;texture hardware\\\",\\\"Keywords_Processed\\\":\\\"volume render;time vary datum;compression;out of core processing;texture hardware;scientific visualization;transform encoding;high performance computing;pc\\\",\\\"Title\\\":\\\"Texture Hardware Assisted Rendering of Time-Varying Volume Data\\\"},\\\"215\\\":{\\\"Abstract\\\":\\\"Acceleration techniques for volume ray-casting are primarily based on pre-computed data structures that allow one to efficiently traverse empty or homogeneous regions. In order to display volume data that successively undergoes color lookups, however, the data structures have to be re-built continuously. In this paper we propose a technique that circumvents this drawback using hardware accelerated texture mapping. In a first rendering pass we employ graphics hardware to interactively determine for each ray where the material is hit. In a second pass ray-casting is performed, but ray traversal starts right in front of the previously determined regions. The algorithm enables interactive classification and it considerably accelerates the view dependent display of selected materials and surfaces from volume data. In contrast to other techniques that are solely based on texture mapping our approach requires less memory and accurately performs the composition of material contributions along the ray.\\\",\\\"Authors\\\":\\\"Westermann, R.;Sevenich, B.\\\",\\\"Clusters\\\":\\\"InputAndOutputDevicesGeneral;RaytracingRaycasting;Textures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964521\\\",\\\"Keywords\\\":\\\"volume rendering;graphics hardware;visualization;raycasting;texture mapping\\\",\\\"Keywords_Processed\\\":\\\"visualization;volume render;graphic hardware;texture mapping;raycaste\\\",\\\"Title\\\":\\\"Accelerated volume ray-casting using texture mapping\\\"},\\\"216\\\":{\\\"Abstract\\\":\\\"This paper presents several distinguishing design features of RTVR-a Java-based library for real-time volume rendering. We describe, how the careful design of data structures, which in our case are based on voxel enumeration, and an intelligent use of lookup tables enable interactive volume rendering even on low-end PC hardware. By assigning voxels to distinct objects within the volume and by using an individual setup and combination of look-up tables for each object, object-aware rendering is performed: different transfer functions, shading models, and also compositing modes can be mixed within a single scene to depict each object in the most appropriate way, while still providing rendering results in real-time. While providing frame rates similar to volume visualization using 3D consumer hardware, the approach utilized by RTVR offers much more flexibility and extensibility due to its pure software nature. Furthermore, due to the memory-efficiency of the data representation and the implementation in Java, RTVR can be used to provide volume viewing facilities over low-bandwidth networks, with almost full control over rendering and visualization mapping parameters (clipping, shading, compositing, transfer function) for the user. This paper also addresses specific problems which arise by the use of Java for interactive visualization.\\\",\\\"Authors\\\":\\\"Mroz, L.;Hauser, H.\\\",\\\"Clusters\\\":\\\"InternetWebVisualizationForTheMasses;ProgrammingAlgorithmsAndDataStructures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964522\\\",\\\"Keywords\\\":\\\"java;interactive volume visualization;internet-based visualization\\\",\\\"Keywords_Processed\\\":\\\"interactive volume visualization;java;internet base visualization\\\",\\\"Title\\\":\\\"RTVR-a flexible Java library for interactive volume rendering\\\"},\\\"217\\\":{\\\"Abstract\\\":\\\"We present a framework to extract mesh features from unstructured two-manifold surfaces. Our method computes a collection of piecewise linear curves describing the salient features of surfaces, such as edges and ridge lines. We extend these basic techniques to a multiresolution setting which improves the quality of the results and accelerates the extraction process. The extraction process is semi-automatic, that is, the user is required to input a few control parameters and to select the operators to be applied to the input surface. Our mesh feature extraction algorithm can be used as a preprocessor for a variety of applications in geometric modeling including mesh fairing, subdivision and simplification.\\\",\\\"Authors\\\":\\\"Hubeli, A.;Gross, M.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;AlgorithmicPatternFeatureDetectionTracking;GeometricModeling;MultiresolutionTechniques;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964523\\\",\\\"Keywords\\\":\\\"multi-resolution model;geometric modeling;triangle decimation;surface representation;feature extraction\\\",\\\"Keywords_Processed\\\":\\\"triangle decimation;feature extraction;surface representation;geometric modeling;multi resolution model\\\",\\\"Title\\\":\\\"Multiresolution feature extraction for unstructured meshes\\\"},\\\"218\\\":{\\\"Abstract\\\":\\\"We present a new wavelet compression and multiresolution modeling approach for sets of contours (level sets). In contrast to previous wavelet schemes, our algorithm creates a parametrization of a scalar field induced by its contours and compactly stores this parametrization rather than function values sampled on a regular grid. Our representation is based on hierarchical polygon meshes with subdivision connectivity whose vertices are transformed into wavelet coefficients. From this sparse set of coefficients, every set of contours can be efficiently reconstructed at multiple levels of resolution. When applying lossy compression, introducing high quantization errors, our method preserves contour topology, in contrast to compression methods applied to the corresponding field function. We provide numerical results for scalar fields defined on planar domains. Our approach generalizes to volumetric domains, time-varying contours, and level sets of vector fields.\\\",\\\"Authors\\\":\\\"Bertram, M.;Laney, D.;Duchaineau, M.;Hansen, C.;Hamann, B.;Joy, K.I.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;ContourCreasesRidgesValleys;IsosurfaceAndSurfaceExtractionTechniques;MultiresolutionTechniques;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964525\\\",\\\"Keywords\\\":\\\"multi-resolution method;contours;level sets;wavelets;isosurface;geometry compression\\\",\\\"Keywords_Processed\\\":\\\"multi resolution method;level set;geometry compression;contour;isosurface;wavelet\\\",\\\"Title\\\":\\\"Wavelet representation of contour sets\\\"},\\\"219\\\":{\\\"Abstract\\\":\\\"We introduce a new algorithm for fitting a Catmull-Clark subdivision surface to a given shape within a prescribed tolerance, based on the method of quasi-interpolation. The fitting algorithm is fast, local and scales well since it does not require the solution of linear systems. Its convergence rate is optimal for regular meshes and our experiments show that it behaves very well for irregular meshes. We demonstrate the power and versatility of our method with examples from interactive modeling, surface fitting, and scientific visualization.\\\",\\\"Authors\\\":\\\"Litke, N.;Levin, A.;Schrder, P.\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;AnimationAndMotion;ApplicationsGeneralAndOther;CurvesAndCurvature;GeometricModeling;Interpolation\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964527\\\",\\\"Keywords\\\":\\\"cad;quasi interpolation;digital geometry processing;approximation;curves and surfaces;geometric modeling;subdivision schemes;animation;catmull-clark\\\",\\\"Keywords_Processed\\\":\\\"curve and surface;animation;catmull clark;approximation;geometric modeling;subdivision scheme;quasi interpolation;cad;digital geometry processing\\\",\\\"Title\\\":\\\"Fitting Subdivision Surfaces\\\"},\\\"220\\\":{\\\"Abstract\\\":\\\"Commonly-used subdivision schemes require manifold control meshes and produce manifold surfaces. However, it is often necessary to model nonmanifold surfaces, such as several surface patches meeting at a common boundary. In this paper, we describe a subdivision algorithm that makes it possible to model nonmanifold surfaces. Any triangle mesh, subject only to the restriction that no two vertices of any triangle coincide, can serve as an input to the algorithm. Resulting surfaces consist of collections of manifold patches joined along nonmanifold curves and vertices. If desired, constraints may be imposed on the tangent planes of manifold patches sharing a curve or a vertex. The algorithm is an extension of a well-known Loop subdivision scheme, and uses techniques developed for piecewise smooth surfaces.\\\",\\\"Authors\\\":\\\"Lexing Ying;Zorin, D.\\\",\\\"Clusters\\\":\\\"GeometricModeling;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964528\\\",\\\"Keywords\\\":\\\"subdivision surfaces;non-manifold surfaces;geometric modeling\\\",\\\"Keywords_Processed\\\":\\\"non manifold surface;subdivision surface;geometric modeling\\\",\\\"Title\\\":\\\"Nonmanifold subdivision\\\"},\\\"221\\\":{\\\"Abstract\\\":\\\"Subdivision surfaces are an attractive representation when modeling arbitrary-topology free-form surfaces and show great promise for applications in engineering design and computer animation. Interference detection is a critical tool in many of these applications. In this paper, we derive normal bounds for subdivision surfaces and use these to develop an efficient algorithm for (self-) interference detection.\\\",\\\"Authors\\\":\\\"Grinspun, E.;Schroder, P.\\\",\\\"Clusters\\\":\\\"GeometricModeling;InteractionTechniquesGeneral;MeshesGridsAndLattices;NumericalMethodsMathematics;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964529\\\",\\\"Keywords\\\":\\\"multi-resolution surfaces;loop's scheme;subdivision surfaces;gauss map;self-interference\\\",\\\"Keywords_Processed\\\":\\\"subdivision surface;loop scheme;gauss map;multi resolution surface;self interference\\\",\\\"Title\\\":\\\"Normal bounds for subdivision-surface interference detection\\\"},\\\"222\\\":{\\\"Abstract\\\":\\\"Presents an efficient method to automatically compute a smooth approximation of large functional scattered data sets given over arbitrarily shaped planar domains. Our approach is based on the construction of a C 1-continuous bivariate cubic spline and our method offers optimal approximation order. Both local variation and nonuniform distribution of the data are taken into account by using local polynomial least squares approximations of varying degree. Since we only need to solve small linear systems and no triangulation of the scattered data points is required, the overall complexity of the algorithm is linear in the total number of points. Numerical examples dealing with several real-world scattered data sets with up to millions of points demonstrate the efficiency of our method. The resulting spline surface is of high visual quality and can be efficiently evaluated for rendering and modeling. In our implementation we achieve real-time frame rates for typical fly-through sequences and interactive frame rates for recomputing and rendering a locally modified spline surface.\\\",\\\"Authors\\\":\\\"Haber, J.;Zeilfelder, F.;Davydov, O.;Seidel, H.-P.\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;CompressionTechniques;GeographyGeospatialVisCartographyTerrainVis;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964530\\\",\\\"Keywords\\\":\\\"scattered data approximation;terrain visualization;least squares approximation;data compression\\\",\\\"Keywords_Processed\\\":\\\"scatter datum approximation;terrain visualization;least square approximation;data compression\\\",\\\"Title\\\":\\\"Smooth approximation and rendering of large scattered data sets\\\"},\\\"223\\\":{\\\"Abstract\\\":\\\"Interactive exploration of animated volume data is required by many application, but the huge amount of computational time and storage space needed for rendering does not yet allow the visualization of animated volumes. In this paper, we introduce an algorithm running at interactive frame rates using 3D wavelet transforms that allows for any wavelet, motion compensation techniques and various encoding schemes of the resulting wavelet coefficients to be used. We analyze different families and orders of wavelets for compression ratio and the introduced error. We use a quantization that has been optimized for the visual impression of the reconstructed volume, independent of the viewing algorithm. This enables us to achieve very high compression ratios while still being able to reconstruct the volume with as few visual artifacts as possible. A further improvement of the compression ratio has been achieved by applying a motion compensation scheme to exploit temporal coherency. Using these schemes, we are able to decompress each volume of our animation at interactive frame rates, while visualizing these decompressed volumes on a single PC. We also present a number of improved visualization algorithms for high-quality display using OpenGL hardware running at interactive frame rates on a standard PC.\\\",\\\"Authors\\\":\\\"Guthe, S.;Strasser, W.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;TimeCriticalApplications;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964531\\\",\\\"Keywords\\\":\\\"compression for visualization;volume rendering;time-critical visualization\\\",\\\"Keywords_Processed\\\":\\\"volume render;compression for visualization;time critical visualization\\\",\\\"Title\\\":\\\"Real-time decompression and visualization of animated volume data\\\"},\\\"224\\\":{\\\"Abstract\\\":\\\"Presents an algorithm that uses partitioning and gluing to compress large triangular meshes which are too complex to fit in main memory. The algorithm is based largely on the existing mesh compression algorithms, most of which require an 'in-core' representation of the input mesh. Our solution is to partition the mesh into smaller submeshes and compress these submeshes separately using existing mesh compression techniques. Since a direct partition of the input mesh is out of question, instead we partition a simplified mesh and use the partition on the simplified model to obtain a partition on the original model. In order to recover the full connectivity, we present a simple scheme for encoding/decoding the resulting boundary structure from the mesh partition. When compressing large models with few singular vertices, a negligible portion of the compressed output is devoted to gluing information. On desktop computers, we have run experiments on models with millions of vertices, which could not be compressed using standard compression software packages, and have observed compression ratios as high as 17 to 1 using our technique.\\\",\\\"Authors\\\":\\\"Ho, J.;Kuang-Chih Lee;Kriegman, D.\\\",\\\"Clusters\\\":\\\"CompressionTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964532\\\",\\\"Keywords\\\":\\\"compression algorithms\\\",\\\"Keywords_Processed\\\":\\\"compression algorithm\\\",\\\"Title\\\":\\\"Compressing large polygonal models\\\"},\\\"225\\\":{\\\"Abstract\\\":\\\"Presents a method to estimate illumination dependent properties in image synthesis prior to rendering. A preprocessing step is described in which a linear image basis is developed and a lighting-independent formulation defined. A reflection function, similar to hemispherical reflectance, approximates normal Lambertian shading. Intensity errors resulting from this approximation are reduced by use of a polynomial gamma correction function and scaling to a normalized display range. This produces images that are similar to normal Lambertian shading without employing the maximum (max) function. For a single object view, images can then be expressed in a linear form so that lighting direction can be factored out. During normal rendering, image quantities for arbitrary light directions can be found without rendering. This method is demonstrated for estimating image intensity and level-of-detail error prior to rendering an object.\\\",\\\"Authors\\\":\\\"Scoggins, R.;Machiraju, R.;Moorhead, R.J.\\\",\\\"Clusters\\\":\\\"DataAndAnalysisMetrics;LevelOfDetail;Perception;Rendering\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964535\\\",\\\"Keywords\\\":\\\"level-of-detail;perception;image metrics;rendering\\\",\\\"Keywords_Processed\\\":\\\"render;image metric;level of detail;perception\\\",\\\"Title\\\":\\\"Approximate shading for the re-illumination of synthetic images\\\"},\\\"226\\\":{\\\"Abstract\\\":\\\"This paper presents a method concerning the volume rendering of fine details, such as blood vessels and nerves, from medical data. The realistic and efficient visualization of such structures is often of great medical interest, and conventional rendering techniques do not always deal with them adequately. Our method uses preprocessing to reconstruct fine details that are difficult to segment and label. It detects the presence of fine geometrical structures, such as cracks or cylinders that suggest the existence of, for example, blood vessels or nerves; the subsequent volume rendering then displays fine geometrical objects that lie on a surface. The method can also show structures within the volume, using a special \\\\\\\"integration sampling\\\\\\\" scheme to portray reconstructed volume texture, such as that exhibited by muscle fibers. By combining the surface structure and volume texture in the rendering, realistic results can be produced; examples are provided.\\\",\\\"Authors\\\":\\\"Dong, F.;Clapworthy, G.;Krokos, M.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;ImageBasedDataImageSignalProcessing;LevelOfDetail;Textures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964537\\\",\\\"Keywords\\\":\\\"volume rendering;medical visualization;volume textures;image processing;fine details\\\",\\\"Keywords_Processed\\\":\\\"volume render;image processing;volume texture;fine detail;medical visualization\\\",\\\"Title\\\":\\\"Volume Rendering of Fine Details Within Medical Data\\\"},\\\"227\\\":{\\\"Abstract\\\":\\\"We describe a pipeline of image processing steps for deriving symbolic models of vascular structures from radiological data which reflect the branching pattern and diameter of vessels. For the visualization of these symbolic models, concatenated truncated cones are smoothly blended at branching points. We put emphasis on the quality of the visualizations which is achieved by anti-aliasing operations in different stages of the visualization. The methods presented are referred to as HQVV (high quality vessel visualization). Scalable techniques are provided to explore vascular structures of different orders of magnitude. The hierarchy as well as the diameter of the branches of vascular systems are used to restrict visualizations to relevant subtrees and to emphasize parts of vascular systems. Our research is inspired by clear visualizations in textbooks and is targeted toward medical education and therapy planning. We describe the application of vessel visualization techniques for liver surgery planning. For this application it is crucial to recognize the morphology and branching pattern of vascular systems as well as the basic spatial relations between vessels and other anatomic structures.\\\",\\\"Authors\\\":\\\"Hahn, H.K.;Preim, B.;Selle, D.;Peitgen, H.-O.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964538\\\",\\\"Keywords\\\":\\\"computer-aided surgery;vessel visualization;medical visualization\\\",\\\"Keywords_Processed\\\":\\\"medical visualization;vessel visualization;computer aid surgery\\\",\\\"Title\\\":\\\"Visualization and interaction techniques for the exploration of vascular structures\\\"},\\\"228\\\":{\\\"Abstract\\\":\\\"We present a new technique for visualizing surfaces from 3D ultrasound data. 3D ultrasound datasets are typically fuzzy, contain a substantial amount of noise and speckle, and suffer from several other problems that make extraction of continuous and smooth surfaces extremely difficult. We propose a novel opacity classification algorithm for 3D ultrasound datasets, based on the variational principle. More specifically, we compute a volumetric opacity function that optimally satisfies a set of simultaneous requirements. One requirement makes the function attain nonzero values only in the vicinity of a user-specified value, resulting in soft shells of finite, approximately constant thickness around isosurfaces in the volume. Other requirements are designed to make the function smoother and less sensitive to noise and speckle. The computed opacity function lends itself well to explicit geometric surface extraction, as well as to direct volume rendering at interactive rates. We also describe a new splatting algorithm that is particularly well suited for displaying soft opacity shells. Several examples and comparisons are included to illustrate our approach and demonstrate its effectiveness on real 3D ultrasound datasets.\\\",\\\"Authors\\\":\\\"Fattal, R.;Lischinski, D.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;ComputerGraphicsTechniquesGeneral;IsosurfaceAndSurfaceExtractionTechniques;NumericalMethodsMathematics;OcclusionProblemsTechniques;SegmentationAndClassification;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964539\\\",\\\"Keywords\\\":\\\"splatting;volume rendering;isosurface extraction;opacity function;3d ultrasound;classification;variational principle\\\",\\\"Keywords_Processed\\\":\\\"volume render;isosurface extraction;variational principle;3d ultrasound;opacity function;splatte;classification\\\",\\\"Title\\\":\\\"Variational classification for visualization of 3D ultrasound data\\\"},\\\"229\\\":{\\\"Abstract\\\":\\\"The majority of virtual endoscopy techniques tries to simulate a real endoscopy. A real endoscopy does not always give the optimal information due to the physical limitations it is subject to. In this paper, we deal with the unfolding of the surface of the colon as a possible visualization technique for diagnosis and polyp detection. A new two-step technique is presented which deals with the problems of double appearance of polyps and nonuniform sampling that other colon unfolding techniques suffer from. In the first step, a distance map from a central path induces nonlinear rays for unambiguous parameterization of the surface. The second step compensates for locally varying distortions of the unfolded surface. A technique similar to magnification fields in information visualization is hereby applied. The technique produces a single view of a complete, virtually dissected colon.\\\",\\\"Authors\\\":\\\"Vilanova Bartroli, A.V.;Wegenkittl, R.;Konig, A.;Groller, E.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964540\\\",\\\"Keywords\\\":\\\"volume rendering;virtual endoscopy\\\",\\\"Keywords_Processed\\\":\\\"volume render;virtual endoscopy\\\",\\\"Title\\\":\\\"Nonlinear virtual colon unfolding\\\"},\\\"230\\\":{\\\"Abstract\\\":\\\"PingTV generates a logical map of a network that is used as an overlay on a physical geographical image of the location from the user perspective (buildings, floors within buildings, etc.). PingTV is used at Illinois State University as a visualization tool to communicate real-time network conditions to the university community via a dedicated channel on the campus cable TV system. Colored symbols allow students and staff to discern high- congestion rush hours and understand why their specific Internet connectivity is broken from the wide range of potential causes. Lessons learned include the use of color to visually convey confidence intervals using color shading and the visualization of cyclical network traffic patterns. Our implementation is general and flexible with potential for application for other domains.\\\",\\\"Authors\\\":\\\"Gubin, A.;Yurcik, W.;Brumbaugh, L.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;GraphNetworkDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964541\\\",\\\"Keywords\\\":\\\"realtime television monitoring;active network measurement;network visualization\\\",\\\"Keywords_Processed\\\":\\\"network visualization;realtime television monitoring;active network measurement\\\",\\\"Title\\\":\\\"PingTV: A Case Study in Visual Network Monitoring\\\"},\\\"231\\\":{\\\"Abstract\\\":\\\"The case study presents a medical Web service for the automatic analysis of CTA (computer tomography angiography) datasets. It aims at the detection and evaluation of intracranial aneurysms which are malformations of cerebral blood vessels. To obtain a standardized 3D visualization, digital videos are automatically generated. The time-consuming video production caused by the manual delineation of structures, software based volume rendering, and the interactive definition of an optimized camera path is considerably improved with a fully automatic strategy. Therefore, a previously suggested approach (C. Rezk-Salama, 2000) is applied which uses an optimized transfer function as a template and automatically adapts it to an individual dataset. Furthermore, we introduce hardware-accelerated morphologic filtering in order to detect the location of mid-size and giant aneurysms. The actual generation of the video is finally integrated into a hardware accelerated off-screen rendering process based on 3D texture mapping, ensuring fast visualization of high quality. Overall, clinical routine can be considerably assisted by providing a Web based service combining automatic detection and standardized visualization.\\\",\\\"Authors\\\":\\\"Iserhardt-Bauer, S.;Hastreiter, P.;Ertl, T.;Eberhardt, K.;Tomandl, B.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;InternetWebVisualizationForTheMasses;MultimediaImageVideoMusic;SegmentationAndClassification\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964542\\\",\\\"Keywords\\\":\\\"medical visualization;segmentation;automatic web service;video generation\\\",\\\"Keywords_Processed\\\":\\\"video generation;automatic web service;segmentation;medical visualization\\\",\\\"Title\\\":\\\"Case study: medical Web service for the automatic 3D documentation for neuroradiological diagnosis\\\"},\\\"232\\\":{\\\"Abstract\\\":\\\"This paper presents a novel use of visualization applied to debugging the Cplant TM cluster hardware at Sandia National Laboratories. As commodity cluster systems grow in popularity and grow in size, tracking component failures within the hardware will become more and more difficult. We have developed a tool that facilitates visual debugging of errors within the switches and cables connecting the processors. Combining an abstract system model with color-coding for both error and job information enables failing components to be identified.\\\",\\\"Authors\\\":\\\"Crossno, P.;Haynes, R.\\\",\\\"Clusters\\\":\\\"DesignMethodologiesAndInteractionDesign;InputAndOutputDevicesGeneral;Optimization;ProgrammingAlgorithmsAndDataStructures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964543\\\",\\\"Keywords\\\":\\\"performance optimization;design analysis;hardware modeling;visual debugging\\\",\\\"Keywords_Processed\\\":\\\"performance optimization;design analysis;visual debugging;hardware modeling\\\",\\\"Title\\\":\\\"Case study: visual debugging of cluster hardware\\\"},\\\"233\\\":{\\\"Abstract\\\":\\\"For psychophysical studies in spatial cognition a virtual model of the picturesque old town of Tubingen has been constructed. In order to perform psychophysical experiments in highly realistic virtual environments the model is based on high quality texture maps adding up to several hundreds of MBytes. To accomplish the required real-time frame updates, view frustum and occlusion culling without visibility pre-processing, levels of detail, and texture compression are applied in an interleaved manner. Shared memory communication and a standard PC with two commodity graphics cards is used to enable the powerful combination of those techniques because this combination is not yet available on a single graphics card.\\\",\\\"Authors\\\":\\\"Meissner, M.;Orman, J.;Braun, S.J.\\\",\\\"Clusters\\\":\\\"Cognition;GpuBasedTechniques;ImmersiveAndVirtualEnvironments;LevelOfDetail;Rendering;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964544\\\",\\\"Keywords\\\":\\\"virtual environment;pc graphics cards;virtual reality;spatial cognition;level-of-detail;culling;texture compression\\\",\\\"Keywords_Processed\\\":\\\"virtual environment;cull;pc graphic card;texture compression;spatial cognition;level of detail;virtual reality\\\",\\\"Title\\\":\\\"Case study on real-time visualization of virtual Tubingen on commodity PC hardware\\\"},\\\"234\\\":{\\\"Abstract\\\":\\\"We describe a virtual reality environment for visualizing tensor-valued volumetric datasets acquired with diffusion tensor magnetic resonance imaging (DT-MRI). We have prototyped a virtual environment that displays geometric representations of the volumetric second-order diffusion tensor data and are developing interaction and visualization techniques for two application areas: studying changes in white-matter structures after gamma-knife capsulotomy and pre-operative planning for brain tumor surgery. Our feedback shows that compared to desktop displays, our system helps the user better interpret the large and complex geometric models, and facilitates communication among a group of users.\\\",\\\"Authors\\\":\\\"Zhang, S.;Demiralp, C.;Keefe, D.F.;DaSilva, M.;Laidlaw, D.H.;Greenberg, B.D.;Basser, P.J.;Pierpaoli, C.;Chiocca, E.A.;Deisboeck, T.S.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DiffusionRelatedTechniques;ImmersiveAndVirtualEnvironments;TensorDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964545\\\",\\\"Keywords\\\":\\\"virtual reality;scientific visualization;diffusion tensor mri;diffusion;medical imaging\\\",\\\"Keywords_Processed\\\":\\\"diffusion tensor mri;medical imaging;scientific visualization;diffusion;virtual reality\\\",\\\"Title\\\":\\\"An immersive virtual environment for DT-MRI volume visualization applications: a case study\\\"},\\\"235\\\":{\\\"Abstract\\\":\\\"In this case study we discuss an interactive feature tracking system and its use for the analysis of chromatin decondensation. Features are described as points in a multidimensional attribute space. Distances between points are used as a measure for feature correspondence. Users can interactively experiment with the correspondence measure in order to gain insight in chromatin movement. In addition, by defining time as an attribute, tracking problems related to noisy confocal data can be circumvented.\\\",\\\"Authors\\\":\\\"de Leeuw, W.;van Liere, R.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;BiomedicalScienceAndMedicine;MultidimensionalMultivariateMultifieldDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964546\\\",\\\"Keywords\\\":\\\"biomedical imaging;feature tracking;multi-dimensional visualization\\\",\\\"Keywords_Processed\\\":\\\"feature tracking;biomedical imaging;multi dimensional visualization\\\",\\\"Title\\\":\\\"Chromatin decondensation: case study of tracking features in confocal data\\\"},\\\"236\\\":{\\\"Abstract\\\":\\\"We describe a visualization system designed for interactive study of proteins in the field of computational biology. Our system incorporates multiple, custom, three-dimensional and two-dimensional linked views of the proteins. We take advantage of modem commodity graphics cards, which are typically designed for games rather than scientific visualization applications, to provide instantaneous linking between views and three-dimensional interactivity on standard personal computers. Furthermore, we anticipate the usefulness of game techniques such as bump maps and skinning for scientific applications.\\\",\\\"Authors\\\":\\\"Gresh, D.L.;Suits, F.;Yuk Yin Sham\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;ComputerGraphicsTechniquesGeneral;MolecularScienceAndChemistry;ProgrammingAlgorithmsAndDataStructures;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964547\\\",\\\"Keywords\\\":\\\"protein;computational biology;directx;visualization;molecular dynamics;molecular modeling;game graphics\\\",\\\"Keywords_Processed\\\":\\\"visualization;computational biology;directx;molecular dynamic;game graphic;protein;molecular modeling\\\",\\\"Title\\\":\\\"Case study: an environment for understanding protein simulations using game graphics\\\"},\\\"237\\\":{\\\"Abstract\\\":\\\"Computer-based surgical simulation promises to provide a broader scope of clinical training through the introduction of anatomic variation, simulation of untoward events, and collection of performance data. We present a haptically-enabled surgical simulator for the most common techniques in diagnostic and operative hysteroscopy-cervical dilation, endometrial resection and ablation, and lesion excision. Engineering tradeoffs in developing a real-time, haptic-rate simulator are discussed.\\\",\\\"Authors\\\":\\\"Montgomery, K.;Heinrichs, L.R.;Bruyns, C.;Wildermuth, S.;Hasser, C.;Ozenne, S.;Bailey, D.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;InputAndOutputDevicesGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964548\\\",\\\"Keywords\\\":\\\"hysteroscopy;surgical simulation;haptics\\\",\\\"Keywords_Processed\\\":\\\"surgical simulation;hysteroscopy;haptic\\\",\\\"Title\\\":\\\"Surgical simulator for hysteroscopy: a case study of visualization in surgical training\\\"},\\\"238\\\":{\\\"Abstract\\\":\\\"It is of significant interest for neurological studies to determine and visualize neuronal fiber pathways in the human brain. By exploiting the capability of diffusion tensor magnetic resonance imaging to detect local orientations of neuronal fibers, we have developed a system of algorithms to reconstruct, visualize and quantify neuronal fiber pathways in vivo. Illustrative results show that the system is a promising tool for visual analysis of fiber connectivity and quantitative studies of neuronal fibers.\\\",\\\"Authors\\\":\\\"Zhaohua Ding;Gore, J.C.;Anderson, A.W.\\\",\\\"Clusters\\\":\\\"NeurosciencesAndBrainVisualization;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964549\\\",\\\"Keywords\\\":\\\"neuronal fiber pathway;diffusion tensor imaging\\\",\\\"Keywords_Processed\\\":\\\"diffusion tensor imaging;neuronal fiber pathway\\\",\\\"Title\\\":\\\"Case study: reconstruction, visualization and quantification of neuronal fiber pathways\\\"},\\\"239\\\":{\\\"Abstract\\\":\\\"Maps of biophysical and geophysical variables using Earth Observing System (EOS) satellite image data are an important component of Earth science. These maps have a single value derived at every grid cell and standard techniques are used to visualize them. Current tools fall short, however, when it is necessary to describe a distribution of values at each grid cell. Distributions may represent a frequency of occurrence over time, frequency of occurrence from multiple runs of an ensemble forecast or possible values from an uncertainty model. We identify these \\\\\\\"distribution data sets\\\\\\\" and present a case study to visualize such 2D distributions. Distribution data sets are different from multivariate data sets in the sense that the values are for a single variable instead of multiple variables. Data for this case study consists of multiple realizations of percent forest cover, generated using a geostatistical technique that combines ground measurements and satellite imagery to model uncertainty about forest cover. We present two general approaches for analyzing and visualizing such data sets. The first is a pixel-wise analysis of the probability density functions for the 2D image while the second is an analysis of features identified within the image. Such pixel-wise and feature-wise views will give Earth scientists a more complete understanding of distribution data sets. See www.cse.ucsc.edu/research/avis/nasa is for additional information.\\\",\\\"Authors\\\":\\\"Kao, D.;Dungan, J.L.;Pang, A.\\\",\\\"Clusters\\\":\\\"DataRegistrationFusionAndIntegration;GeographyGeospatialVisCartographyTerrainVis;MachineLearningAndStatistics;Simulation;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964550\\\",\\\"Keywords\\\":\\\"geostatistics;conditional simulation;probability density function;uncertainty;data assimilation\\\",\\\"Keywords_Processed\\\":\\\"datum assimilation;uncertainty;probability density function;geostatistic;conditional simulation\\\",\\\"Title\\\":\\\"Visualizing 2D probability distributions from EOS satellite image-derived data sets: a case study\\\"},\\\"240\\\":{\\\"Abstract\\\":\\\"The focus of this paper is to evaluate the usefulness of some basic feature tracking algorithms as analysis tools for combustion datasets by application to a dataset modeling autoignition. Features defined as areas of high intermediate concentrations were examined to explore the initial phases in the autoignition process.\\\",\\\"Authors\\\":\\\"Koegler, W.S.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;PhysicsAndPhysicalSciences\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964551\\\",\\\"Keywords\\\":\\\"feature detection;feature tracking;autoignition;combustion\\\",\\\"Keywords_Processed\\\":\\\"feature tracking;combustion;feature detection;autoignition\\\",\\\"Title\\\":\\\"Case study: application of feature tracking to analysis of autoignition simulation data\\\"},\\\"241\\\":{\\\"Abstract\\\":\\\"The complex geometry of the human brain contains many folds and fissures, making it impossible to view the entire surface at once. Since most of the cortical activity occurs on these folds, it is desirable to be able to view the entire surface of the brain in a single view. This can be achieved using quasi-conformal flat maps of the cortical surface. Computational and visualization tools are now needed to be able to interact with these flat maps of the brain to gain information about spatial and functional relationships that might not otherwise be apparent. Such information can contribute to earlier diagnostic tools for diseases and improved treatment. Our group is developing visualization and analysis tools that will help elucidate new information about the human brain through the interaction between a cortical surface and its corresponding quasiconformal flat map.\\\",\\\"Authors\\\":\\\"Hurdal, M.K.;Kurtz, K.W.;Banks, D.C.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DataFeaturesAndAttributes;InteractionTechniquesGeneral;Maps;NeurosciencesAndBrainVisualization;NumericalMethodsMathematics;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964553\\\",\\\"Keywords\\\":\\\"human brain;neuroscience;flat map;magnetic resonance imaging;cortical features;surfaces;conformal;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;surface;neuroscience;human brain;cortical feature;conformal;flat map;magnetic resonance imaging\\\",\\\"Title\\\":\\\"Case study: interacting with cortical flat maps of the human brain\\\"},\\\"242\\\":{\\\"Abstract\\\":\\\"We present the problem of visualizing time-varying medical data. Two medical imaging modalities are compared-MRI and dynamic SPECT. For each modality, we examine several derived scalar and vector quantities such as the change in intensity over time, the spatial gradient, and the change of the gradient over time. We compare several methods for presenting the data, including isosurfaces, direct volume rendering, and vector visualization using glyphs. These techniques may provide more information and context than methods currently used in practice; thus it is easier to discover temporal changes and abnormalities in a data set.\\\",\\\"Authors\\\":\\\"Tory, M.;Rober, N.;Mller, T.;Celler, A.;Atkins, M.S.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;BiomedicalScienceAndMedicine;GlyphsGlyphBasedTechniques;IsosurfaceAndSurfaceExtractionTechniques;ProgrammingAlgorithmsAndDataStructures;VisualizationTechniquesAndToolsGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964554\\\",\\\"Keywords\\\":\\\"glyph;isosurface;4d visualization;dynamic spect;direct volume rendering;magnetic resonance imaging;health;animation;display algorithms\\\",\\\"Keywords_Processed\\\":\\\"dynamic spect;animation;4d visualization;health;display algorithm;direct volume render;isosurface;glyph;magnetic resonance imaging\\\",\\\"Title\\\":\\\"4D space-time techniques: a medical imaging case study\\\"},\\\"243\\\":{\\\"Abstract\\\":\\\"In this paper, we address the problem of historical data visualization. We describe the data acquisition, preparation, and visualization. Since the data contain four dimensions, the standard 3D exploration techniques have to be extended or appropriately adapted in order to enable interactive exploration. We discuss in detail two interaction concepts: (1) navigation with one fixed dimension, and (2) quasi 4D navigation allowing to simultaneously explore the four-dimensional space. In addition, we also present a picture-in-picture display mode, enabling the user to interactively view the data, while \\\\\\\"flying with\\\\\\\" a particular event, tracking its motion in time and space. Finally, we present a technique for guided exploration and animation generation, allowing for a vivid gain of insight into the historical data.\\\",\\\"Authors\\\":\\\"Stoev, S.L.;Strasser, W.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;InteractionTechniquesGeneral;TimeseriesTimeVaryingDataAndTechniques;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964557\\\",\\\"Keywords\\\":\\\"visualization technique;historical data;time-dependent data;visualization;interaction\\\",\\\"Keywords_Processed\\\":\\\"visualization;interaction;time dependent datum;visualization technique;historical datum\\\",\\\"Title\\\":\\\"A case study on interactive exploration and guidance aids for visualizing historical data\\\"},\\\"244\\\":{\\\"Abstract\\\":\\\"Traditional methods for displaying weather products are generally two-dimensional (2D) plots or just text format. It is hard for forecasters to get the entire picture of the atmosphere using these methods. The problems apparent in 2D with comparing and correlating multiple layers are overcome simply by adding a dimension. This is important because pertinent features in the data sets may lie in multiple layers and span several time steps. However, simply using a three-dimensional (3D) approach is not enough. The capacity for analysis of small-scale, but important, features in 2D are lost when transitioning to 3D. We propose that 3D's advantages can be incorporated with 2D's small-scale analysis by using an immersive virtual environment. In this case study, we evaluate our current standing with the project: have we met our goals, and how should we proceed from this point? To evaluate our application, we invited meteorologists to use the application to explore a data set. Then we presented our goals and asked which ones had we met, from a meteorologist's perspective. The results qualitatively reflected that our application was effective and further research would be worthwhile.\\\",\\\"Authors\\\":\\\"Ziegeler, S.;Moorhead, R.J.;Croft, P.J.;Duanjun Lu\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;ImmersiveAndVirtualEnvironments;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964559\\\",\\\"Keywords\\\":\\\"virtual environment;meteorology;virtual reality;visualization;immersion\\\",\\\"Keywords_Processed\\\":\\\"virtual environment;visualization;meteorology;immersion;virtual reality\\\",\\\"Title\\\":\\\"The MetVR case study: meteorological visualization in an immersive virtual environment\\\"},\\\"245\\\":{\\\"Abstract\\\":\\\"We present the results of an evaluation of the ARCHAVE system, an immersive virtual reality environment for archaeological research. ARCHAVE is implemented in a Cave. The evaluation studied re- searchers analyzing lamp and coin finds throughout the excavation trenches at the Petra Great Temple site in Jordan. Experienced ar- chaeologists used our system to study excavation data, confirming existing hypotheses and postulating new theories they had not been able to discover without the system. ARCHAVE provided access to the excavation database, and researchers were able to examine the data in the context of a life-size representation of the present day architectural ruins of the temple. They also had access to a minia- ture model for site-wide analysis. Because users quickly became comfortable with the interface, they concentrated their efforts on examining the data being retrieved and displayed. The immersive VR visualization of the recovered information gave them the op- portunity to explore it in a new and dynamic way and, in several cases, enabled them to make discoveries that opened new lines of investigation about the excavation.\\\",\\\"Authors\\\":\\\"Acevedo, D.;Vote, E.;Laidlaw, D.H.;Joukowsky, M.S.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;ImmersiveAndVirtualEnvironments;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964560\\\",\\\"Keywords\\\":\\\"immersive virtual reality interfaces;scientific visualization;archaeological data analysis\\\",\\\"Keywords_Processed\\\":\\\"scientific visualization;archaeological datum analysis;immersive virtual reality interface\\\",\\\"Title\\\":\\\"Archaeological Data Visualization in VR: Analysis of Lamp Finds at the Great Temple of Petra, a Case Study\\\"},\\\"246\\\":{\\\"Abstract\\\":\\\"The Temporal Bone Dissection Simulator is an ongoing research project for the construction of a synthetic environment suitable for virtual dissection of human temporal bone and related anatomy. Funded by the National Institute on Deafness and Other Communication Disorders (NIDCD), the primary goal of this project is to provide a safe, robust, and cost-effective virtual environment for learning the anatomy and surgical procedures associated with the temporal bone. Direct volume visualization has been indispensable for the necessary level of realism and interactivity that is vital to the success of this project. This work is being conducted by the Ohio Supercomputer Center in conjunction with the Department of Otolaryngology at the Ohio State University, and NIDCD.\\\",\\\"Authors\\\":\\\"Bryan, J.;Stredney, D.;Wiet, G.;Sessanna, D.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964561\\\",\\\"Keywords\\\":\\\"temporal bone dissection\\\",\\\"Keywords_Processed\\\":\\\"temporal bone dissection\\\",\\\"Title\\\":\\\"Virtual Temporal Bone Dissection: A Case Study\\\"},\\\"247\\\":{\\\"Abstract\\\":\\\"This case study describes the process of fusing the data from several wind tunnel experiments into a single coherent visualization. Each experiment was conducted independently and was designed to explore different flow features around airplane landing gear. In the past, it would have been very difficult to correlate results from the different experiments. However, with a single 3-D visualization representing the fusion of the three experiments, significant insight into the composite flowfield was observed that would have been extremely difficult to obtain by studying its component parts. The results are even more compelling when viewed in an immersive environment.\\\",\\\"Authors\\\":\\\"Severance, K.;Brewstel, P.;Lazos, B.;Keefe, D.F.\\\",\\\"Clusters\\\":\\\"DataRegistrationFusionAndIntegration;Engineering;FlowVisualizationDataAndTechniques;ImageBasedDataImageSignalProcessing;Interpolation;ParticleVisualizationAndTechniques;ProgrammingAlgorithmsAndDataStructures;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2001.964563\\\",\\\"Keywords\\\":\\\"particle image velocimetry;oil flow;reconstruction;photogrammetry;image-based rendering;landing gear;data fusion;line integral convolution;texture mapping;vrml;wind tunnel\\\",\\\"Keywords_Processed\\\":\\\"image base render;line integral convolution;landing gear;oil flow;particle image velocimetry;reconstruction;photogrammetry;wind tunnel;datum fusion;vrml;texture mapping\\\",\\\"Title\\\":\\\"Wind Tunnel Data Fusion and Immersive Visualization: A Case Study\\\"},\\\"248\\\":{\\\"Abstract\\\":\\\"In previous work, researchers have attempted to construct taxonomies of information visualization techniques by examining the data domains that are compatible with these techniques. This is useful because implementers can quickly identify various techniques that can be applied to their domain of interest. However, these taxonomies do not help the implementers understand how to apply and implement these techniques. The author extends and proposes a new way to taxonomize information visualization techniques by using the Data State Model (E.H. Chi and J.T. Reidl, 1998). In fact, as the taxonomic analysis in the paper will show, many of the techniques share similar operating steps that can easily be reused. The paper shows that the Data State Model not only helps researchers understand the space of design, but also helps implementers understand how information visualization techniques can be applied more broadly\\\",\\\"Authors\\\":\\\"Chi, E.H.\\\",\\\"Clusters\\\":\\\"Taxonomies;VisualAnalysisModels;VisualizationTechniquesAndToolsGeneral;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2000.885092\\\",\\\"Keywords\\\":\\\"information visualization;techniques;operators;reference model;taxonomy;data state model\\\",\\\"Keywords_Processed\\\":\\\"data state model;operator;information visualization;reference model;taxonomy;technique\\\",\\\"Title\\\":\\\"A taxonomy of visualization techniques using the data state reference model\\\"},\\\"249\\\":{\\\"Abstract\\\":\\\"Drawing on ethnographic studies of (landscape) architects at work, this paper presents a human-centered approach to information visualization. A 3D collaborative electronic workspace allows people to configure, save and browse arrangements of heterogeneous work materials. Spatial arrangements and links are created and maintained as an integral part of ongoing work with `live' documents and objects. The result is an extension of the physical information space of the architects' studio that utilizes the potential of electronic data storage, visualization and network technologies to support work with information in context\\\",\\\"Authors\\\":\\\"Buscher, M.;Shapiro, D.;Christensen, M.;Mogensen, P.;Orbaek, P.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;FocusContextTechniques;HumanComputerInteractionHumanFactors;MaterialScience;SpatiotemporalDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2000.885105\\\",\\\"Keywords\\\":\\\"information visualization;context;spatio-temporal order;electronic workspace;work materials;architecture\\\",\\\"Keywords_Processed\\\":\\\"work material;spatio temporal order;architecture;information visualization;context;electronic workspace\\\",\\\"Title\\\":\\\"Creativity, complexity, and precision: information visualization for (landscape) architecture\\\"},\\\"250\\\":{\\\"Abstract\\\":\\\"Two tasks in graph visualization require partitioning: the assignment of visual attributes and divisive clustering. Often, we would like to assign a color or other visual attributes to a node or edge that indicates an associated value. In an application involving divisive clustering, we would like to partition the graph into subsets of graph elements based on metric values in such a way that all subsets are evenly populated. Assuming a uniform distribution of metric values during either partitioning or coloring can have undesired effects such as empty clusters or only one level of emphasis for the entire graph. Probability density functions derived from statistics about a metric can help systems succeed at these tasks\\\",\\\"Authors\\\":\\\"Herman, I.;Marshall, M.S.;Melancon, G.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;EvaluationMetricsAndBenchmarks;GraphNetworkDataAndTechniques;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2000.885090\\\",\\\"Keywords\\\":\\\"graph navigation;clustering;metrics;graph visualization\\\",\\\"Keywords_Processed\\\":\\\"graph navigation;metric;graph visualization;clustering\\\",\\\"Title\\\":\\\"Density functions for visual attributes and effective partitioning in graph visualization\\\"},\\\"251\\\":{\\\"Abstract\\\":\\\"Data visualization environments help users understand and analyze their data by permitting interactive browsing of graphical representations of the data. To further facilitate understanding and analysis, many visualization environments have special features known as portals, which are sub-windows of a data canvas. Portals provide a way to display multiple graphical representations simultaneously, in a nested fashion. This makes portals an extremely powerful and flexible paradigm for data visualization. Unfortunately, with this flexibility comes complexity. There are over a hundred possible ways each portal can be configured to exhibit different behaviors. Many of these behaviors are confusing and certain behaviors can be inappropriate for a particular setting. It is desirable to eliminate confusing and inappropriate behaviors. The authors construct a taxonomy of portal behaviors and give recommendations to help designers of visualization systems decide which behaviors are intuitive and appropriate for a particular setting. They apply these recommendations to an example setting that is fully visually programmable and analyze the resulting reduced set of behaviors. Finally, the authors consider a real visualization environment and demonstrate some problems associated with behaviors that do not follow their recommendations\\\",\\\"Authors\\\":\\\"Olston, C.;Woodruff, A.\\\",\\\"Clusters\\\":\\\"InternetWebVisualizationForTheMasses;MultipleLinkedCoordinatedViews;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2000.885087\\\",\\\"Keywords\\\":\\\"visualization;portals;multiple views\\\",\\\"Keywords_Processed\\\":\\\"visualization;multiple view;portal\\\",\\\"Title\\\":\\\"Getting portals to behave\\\"},\\\"252\\\":{\\\"Abstract\\\":\\\"We describe MGV, an integrated visualization and exploration system for massive multi-digraph navigation. MGV's only assumption is that the vertex set of the underlying digraph corresponds to the set of leaves of a predetermined tree T. MGV builds an out-of-core graph hierarchy and provides mechanisms to plug in arbitrary visual representations for each graph hierarchy slice. Navigation from one level to another of the hierarchy corresponds to the implementation of a drill-down interface. In order to provide the user with navigation control and interactive response, MGV incorporates a number of visualization techniques like interactive pixel-oriented 2D and 3D maps, statistical displays, multi-linked views, and a zoomable label based interface. This makes the association of geographic information and graph data very natural. MGV follows the client-server paradigm and it is implemented in C and Java-3D. We highlight the main algorithmic and visualization techniques behind the tools and point out along the way several possible application scenarios. Our techniques are being applied to multi-graphs defined on vertex sets with sizes ranging from 100 million to 250 million vertices\\\",\\\"Authors\\\":\\\"Abello, J.;Korn, J.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;HierarchicalTreeDataAndTechniques;LargeScaleDataAndScalability;OutOfCoreProcessing;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2000.885089\\\",\\\"Keywords\\\":\\\"out-of-core algorithm;hierarchy;visualization;massive data sets;graph\\\",\\\"Keywords_Processed\\\":\\\"visualization;out of core algorithm;hierarchy;graph;massive data set\\\",\\\"Title\\\":\\\"Visualizing massive multi-digraphs\\\"},\\\"253\\\":{\\\"Abstract\\\":\\\"We present a new technique for extracting regions of interest (ROI) applying a local watershed transformation. The proposed strategy for computing catchment basins in a given region of interest is based on a rain-falling simulation. Unlike the standard watershed algorithms, which flood the complete (gradient magnitude of an) image, the proposed approach allows us to perform this task locally. Thus, a controlled region growth is performed, saving time and reducing the memory requirement especially when applied on volume data. A second problem arising from the standard watershed transformation is the over-segmented result and the lack of sound criteria for merging the computed basins. For overcoming this drawback, we present a basin-merging strategy introducing four criteria for merging adjacent basins. The threshold values applied in this strategy are derived from the user input and match rather the attributes of the selected object than of all objects in the image. In doing so, the user is not required to adjust abstract numbers, but to simply select a coarse region of interest. Moreover, the proposed algorithm is not limited to the 2D case. As we show in this work, it is suitable for volume data processing as well. Finally, we present the results of applying the proposed approach on several example images and volume data sets.\\\",\\\"Authors\\\":\\\"Stoev, S.L.;Strasser, W.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;ImageBasedDataImageSignalProcessing;SegmentationAndClassification;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885672\\\",\\\"Keywords\\\":\\\"computer vision;watershed transformation;biomedical image segmentation;visualization;image processing;volume visualization;morphological segmentation;feature extraction\\\",\\\"Keywords_Processed\\\":\\\"visualization;image processing;feature extraction;watershe transformation;biomedical image segmentation;computer vision;volume visualization;morphological segmentation\\\",\\\"Title\\\":\\\"Extracting regions of interest applying a local watershed transformation\\\"},\\\"254\\\":{\\\"Abstract\\\":\\\"We present a new visibility determination algorithm for interactive virtual endoscopy. The algorithm uses a modified version of template-based ray casting to extract a view dependent set of potentially visible voxels from volume data. The voxels are triangulated by Marching Cubes and the triangles are rendered onto the display by a graphics accelerator. Early ray termination and space leaping are used to accelerate the ray casting step and a quadtree subdivision algorithm is used to reduce the number of cast rays. Compared to other recently proposed rendering algorithms for virtual endoscopy, our rendering algorithm does not require a long preprocessing step or a high-end graphics workstation, but achieves interactive frame rates on a standard PC equipped with a low-cost graphics accelerator.\\\",\\\"Authors\\\":\\\"Hietala, R.;Oikarinen, J.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;Perception;SurfaceRelatedDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885673\\\",\\\"Keywords\\\":\\\"isosurface extraction;volume visualization;template;visiblity;surface rendering\\\",\\\"Keywords_Processed\\\":\\\"visiblity;template;isosurface extraction;surface render;volume visualization\\\",\\\"Title\\\":\\\"A visibility determination algorithm for interactive virtual endoscopy\\\"},\\\"255\\\":{\\\"Abstract\\\":\\\"We propose a novel approach for segmentation and digital cleansing of endoscopic organs. Our method can be used for a variety of segmentation needs with little or no modification. It aims at fulfilling the dual and often conflicting requirements of a fast and accurate segmentation and also eliminates the undesirable partial volume effect which contemporary approaches cannot. For segmentation and digital cleansing, we use the peculiar characteristics exhibited by the intersection of any two distinct-intensity regions. To detect these intersections we cast rays through the volume, which we call the segmentation rays as they assist in the segmentation. We then associate a certain task of reconstruction and classification with each intersection the ray detects. We further use volumetric contrast enhancement to reconstruct surface lost by segmentation (if any), which aids in improving the quality of the volume rendering.\\\",\\\"Authors\\\":\\\"Lakare, S.;Wan, M.;Sato, M.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;SegmentationAndClassification;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885674\\\",\\\"Keywords\\\":\\\"volume rendering;segmentation rays;volume segmentation;virtual colonoscopy;partial volume voxels;virtual endoscopy\\\",\\\"Keywords_Processed\\\":\\\"volume render;virtual colonoscopy;virtual endoscopy;partial volume voxel;segmentation ray;volume segmentation\\\",\\\"Title\\\":\\\"3D digital cleansing using segmentation rays\\\"},\\\"256\\\":{\\\"Abstract\\\":\\\"We present a new hierarchical clustering and visualization algorithm called H-BLOB, which groups and visualizes cluster hierarchies at multiple levels-of-detail. Our method is fundamentally different to conventional clustering algorithms, such as C-means, K-means, or linkage methods that are primarily designed to partition a collection of objects into subsets sharing similar attributes. These approaches usually lack an efficient level-of-detail strategy that breaks down the visual complexity of very large datasets for visualization. In contrast, our method combines grouping and visualization in a two stage process constructing a hierarchical setting. In the first stage a cluster tree is computed making use of an edge contraction operator. Exploiting the inherent hierarchical structure of this tree, a second stage visualizes the clusters by computing a hierarchy of implicit surfaces. We believe that H-BLOB is especially suited for the visualization of very large datasets and for visual decision making in information visualization. The versatility of the algorithm is demonstrated using examples from visual data mining.\\\",\\\"Authors\\\":\\\"Sprenger, T.C.;Brunella, R.;Gross, M.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;DimensionalityReduction;GraphNetworkDataAndTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;SegmentationAndClassification;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885677\\\",\\\"Keywords\\\":\\\"information visualization;clustering;partitioning;categorization;multi-dimensional information visualization;physics-based graph layout;cluster visualization;non-linear dimensionality reduction\\\",\\\"Keywords_Processed\\\":\\\"partition;multi dimensional information visualization;information visualization;non linear dimensionality reduction;categorization;cluster visualization;clustering;physics base graph layout\\\",\\\"Title\\\":\\\"H-BLOB: a hierarchical visual clustering method using implicit surfaces\\\"},\\\"257\\\":{\\\"Abstract\\\":\\\"As the size and complexity of data sets continues to increase, the development of user interfaces and interaction techniques that expedite the process of exploring that data must receive new attention. Regardless of the speed of rendering, it is important to coherently organize the visual process of exploration: this information both grants insights about the data to a user and can be used by collaborators to understand the results. To fulfil these needs, we present a spreadsheet-like interface to data exploration. The interface displays a 2-dimensional window into visualization parameter space which users manipulate as they search for desired results. Through tabular organization and a clear correspondence between parameters and results, the interface eases the discovery, comparison and analysis of the underlying data. Users can utilize operators and the integrated interpreter to further explore and automate the visualization process; using a method introduced in this paper, these operations can be applied to cells in different stacks of the interface. Via illustrations using a variety of data sets, we demonstrate the efficacy of this novel interface.\\\",\\\"Authors\\\":\\\"Jankun-Kelly, T.J.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"TabularDataAndTechniques;UserInterfacesGeneral;VisualKnowledgeRepresentationAndExternalization;VisualizationSystemsToolkitsAndEnvironments;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885678\\\",\\\"Keywords\\\":\\\"visualization systems;spreadsheets;volume rendering;user interface;scientific visualization;knowledge representation\\\",\\\"Keywords_Processed\\\":\\\"volume render;user interface;visualization system;scientific visualization;spreadsheet;knowledge representation\\\",\\\"Title\\\":\\\"A spreadsheet interface for visualization exploration\\\"},\\\"258\\\":{\\\"Abstract\\\":\\\"In many applications of scientific visualization, a large quantity of data is being processed and displayed in order to enable a viewer to make informed and effective decisions. Since little data is perfect, there is almost always some degree of associated uncertainty. This uncertainty is an important part of the data and should be taken into consideration when interpreting the data. Uncertainty, however, should not overshadow the data values. Many methods that address the problem of visualizing data with uncertainty can distort the data and emphasize areas with uncertain values. We have developed a method for showing the uncertainty information together with data with minimal distraction. This method uses procedurally generated annotations which are deformed according to the uncertainty information. As another possible technique we propose distorting glyphs according to the uncertainty information.\\\",\\\"Authors\\\":\\\"Cedilnik, A.;Rheingans, P.\\\",\\\"Clusters\\\":\\\"GlyphsGlyphBasedTechniques;Labeling;ProgrammingAlgorithmsAndDataStructures;UncertaintyTechniquesAndVisualization;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885679\\\",\\\"Keywords\\\":\\\"annotation;glyph;uncertainty;visualization;procedure generation\\\",\\\"Keywords_Processed\\\":\\\"visualization;procedure generation;uncertainty;annotation;glyph\\\",\\\"Title\\\":\\\"Procedural annotation of uncertain information\\\"},\\\"259\\\":{\\\"Abstract\\\":\\\"The techniques for reducing the size of a volume dataset by preserving both the geometrical/topological shape and the information encoded in an attached scalar field are attracting growing interest. Given the framework of incremental 3D mesh simplification based on edge collapse, we propose an approach for the integrated evaluation of the error introduced by both the modification of the domain and the approximation of the field of the original volume dataset. We present and compare various techniques to evaluate the approximation error or to produce a sound prediction. A flexible simplification tool has been implemented, which provides a different degree of accuracy and computational efficiency for the selection of the edge to be collapsed. Techniques for preventing a geometric or topological degeneration of the mesh are also presented.\\\",\\\"Authors\\\":\\\"Cignoni, P.;Costanza, D.;Montani, C.;Rocchini, C.;Scopigno, R.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;MeshesGridsAndLattices;TopologyBasedTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885680\\\",\\\"Keywords\\\":\\\"mesh simplification;volume visualization;unstructured grid;simplicial complexes\\\",\\\"Keywords_Processed\\\":\\\"simplicial complex;volume visualization;mesh simplification;unstructured grid\\\",\\\"Title\\\":\\\"Simplification of tetrahedral meshes with accurate error evaluation\\\"},\\\"260\\\":{\\\"Abstract\\\":\\\"Very large irregular-grid data sets are represented as tetrahedral meshes and may incur significant disk I/O access overhead in the rendering process. An effective way to alleviate the disk I/O overhead associated with rendering a large tetrahedral mesh is to reduce the I/O bandwidth requirement through compression. Existing tetrahedral mesh compression algorithms focus only on compression efficiency and cannot be readily integrated into the mesh rendering process, and thus demand that a compressed tetrahedral mesh be decompressed before it can be rendered into a 2D image. This paper presents an integrated tetrahedral mesh compression and rendering algorithm called Gatun, which allows compressed tetrahedral meshes to be rendered incrementally as they are being decompressed, thus leading to an efficient irregular grid rendering pipeline. Both compression and rendering algorithms in Gatun exploit the same local connectivity information among adjacent tetrahedra, and thus can be tightly integrated into a unified implementation framework. Our tetrahedral compression algorithm is specifically designed to facilitate the integration with an irregular grid renderer without any compromise in compression efficiency. A unique performance advantage of Gatun is its ability to reduce the runtime memory footprint requirement by releasing memory allocated to tetrahedra as early as possible.\\\",\\\"Authors\\\":\\\"Chuan-Kai Yang;Mitra, T.;Tzi-cker Chiueh\\\",\\\"Clusters\\\":\\\"CompressionTechniques;MeshesGridsAndLattices;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885682\\\",\\\"Keywords\\\":\\\"volume rendering;irregular grids;tetrahedral compression\\\",\\\"Keywords_Processed\\\":\\\"volume render;tetrahedral compression;irregular grid\\\",\\\"Title\\\":\\\"On-the-fly rendering of losslessly compressed irregular volume data\\\"},\\\"261\\\":{\\\"Abstract\\\":\\\"We present two beneficial rendering extensions to the projected tetrahedra (PT) algorithm proposed by Shirley and Tuchman (1990). These extensions are compatible with any cell sorting technique, for example the BSP-XMPVO sorting algorithm for unstructured meshes. Using 3D texture mapping our first extension solves the longstanding problem of hardware-accelerated but accurate rendering of tetrahedral volume cells with arbitrary transfer functions. By employing 2D texture mapping our second extension realizes the hardware-accelerated rendering of multiple shaded isosurfaces within the PT algorithm without reconstructing the isosurfaces. Additionally, two methods are presented to combine projected tetrahedral volumes with isosurfaces. The time complexity of all our algorithms is linear in the number of tetrahedra and does neither depend on the number of isosurfaces nor on the employed transfer functions.\\\",\\\"Authors\\\":\\\"Rottger, S.;Kraus, M.;Ertl, T.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;ImageBasedDataImageSignalProcessing;InputAndOutputDevicesGeneral;IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices;Textures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885683\\\",\\\"Keywords\\\":\\\"texture mapping;cell projection;volume rendering;graphics hardware;compositing;isosurface;unstructured meshes\\\",\\\"Keywords_Processed\\\":\\\"volume render;graphic hardware;unstructured mesh;isosurface;texture mapping;compositing;cell projection\\\",\\\"Title\\\":\\\"Hardware-accelerated volume and isosurface rendering based on cell-projection\\\"},\\\"262\\\":{\\\"Abstract\\\":\\\"Large area tiled displays are gaining popularity for use in collaborative immersive virtual environments and scientific visualization. While recent work has addressed the issues of geometric registration, rendering architectures, and human interfaces, there has been relatively little work on photometric calibration in general, and photometric non-uniformity in particular. For example, as a result of differences in the photometric characteristics of projectors, the color and intensity of a large area display varies from place to place. Further, the imagery typically appears brighter at the regions of overlap between adjacent projectors. We analyze and classify the causes of photometric non-uniformity in a tiled display. We then propose a methodology for determining corrections designed to achieve uniformity, that can correct for the photometric variations across a tiled projector display in real time using per channel color look-up-tables (LUT).\\\",\\\"Authors\\\":\\\"Majumder, A.;Zhu He;Towles, H.;Welch, G.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;DisplaysGeneral;LargeAndHighResDisplays\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885684\\\",\\\"Keywords\\\":\\\"tiled displays;large area display;projector graphics;color calibration\\\",\\\"Keywords_Processed\\\":\\\"projector graphic;large area display;tile display;color calibration\\\",\\\"Title\\\":\\\"Achieving color uniformity across multi-projector displays\\\"},\\\"263\\\":{\\\"Abstract\\\":\\\"Specific rendering modes are developed for a combined visual/haptic interface to allow exploration and understanding of fluid dynamics data. The focus is on visualization of shock surfaces and vortex cores. Advantages provided by augmenting traditional graphical rendering modes with haptic rendering modes are discussed. Particular emphasis is placed on synergistic combinations of visual and haptic modes which enable rapid, exploratory interaction with the data. Implementation issues are also discussed.\\\",\\\"Authors\\\":\\\"Lawrence, D.A.;Lee, C.D.;Pao, L.Y.;Novoselov, R.Y.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;ImmersiveAndVirtualEnvironments;InputAndOutputDevicesGeneral;PhysicsAndPhysicalSciences;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885686\\\",\\\"Keywords\\\":\\\"virtual environment;haptics;visualization;shock;vortex;fluid dynamics;interface\\\",\\\"Keywords_Processed\\\":\\\"virtual environment;vortex;visualization;shock;fluid dynamic;interface;haptic\\\",\\\"Title\\\":\\\"Shock and vortex visualization using a combined visual/haptic interface\\\"},\\\"264\\\":{\\\"Abstract\\\":\\\"We present an algorithm for haptic display of moderately complex polygonal models with a six degree of freedom (DOF) force feedback device. We make use of incremental algorithms for contact determination between convex primitives. The resulting contact information is used for calculating the restoring forces and torques and thereby used to generate a sense of virtual touch. To speed up the computation, our approach exploits a combination of geometric locality, temporal coherence, and predictive methods to compute object-object contacts at kHz rates. The algorithm has been implemented and interfaced with a 6-DOF PHANToM Premium 1.5. We demonstrate its performance on force display of the mechanical interaction between moderately complex geometric structures that can be decomposed into convex primitives.\\\",\\\"Authors\\\":\\\"Gregory, A.;Mascarenhas, A.;Ehmann, S.;Ming Lin;Manocha, D.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;ImmersiveAndVirtualEnvironments;InputAndOutputDevicesGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885687\\\",\\\"Keywords\\\":\\\"virtual reality;interactive computer graphics;haptics;force feedback device\\\",\\\"Keywords_Processed\\\":\\\"force feedback device;haptic;virtual reality;interactive computer graphic\\\",\\\"Title\\\":\\\"Six degree-of-freedom haptic display of polygonal models\\\"},\\\"265\\\":{\\\"Abstract\\\":\\\"We propose a technique for visualizing steady flow. Using this technique, we first convert the vector field data into a scalar level-set representation. We then analyze the dynamic behavior and subsequent distortion of level-sets and interactively monitor the evolving structures by means of texture-based surface rendering. Next, we combine geometrical and topological considerations to derive a multiscale representation and to implement a method for the automatic placement of a sparse set of graphical primitives depicting homogeneous streams in the fields. Using the resulting algorithms, we have built a visualization system that enables us to effectively display the flow direction and its dynamics even for dense 3D fields.\\\",\\\"Authors\\\":\\\"Westermann, R.;Johnson, C.R.;Ertl, T.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;MultiScaleDataTechniques;NumericalMethodsMathematics;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885688\\\",\\\"Keywords\\\":\\\"flow visualization;level sets;multi-scale representation;texture mapping;feature extraction\\\",\\\"Keywords_Processed\\\":\\\"level set;feature extraction;multi scale representation;texture mapping;flow visualization\\\",\\\"Title\\\":\\\"A level-set method for flow visualization\\\"},\\\"266\\\":{\\\"Abstract\\\":\\\"We present a novel hardware-accelerated texture advection algorithm to visualize the motion of two-dimensional unsteady flows. Making use of several proposed extensions to the OpenGL-1.2 specification, we demonstrate animations of over 65,000 particles at 2 frames/sec on an SGI Octane with EMXI graphics. High image quality is achieved by careful attention to edge effects, noise frequency, and image enhancement. We provide a detailed description of the hardware implementation, including temporal and spatial coherence techniques, dye advection techniques, and feature extraction.\\\",\\\"Authors\\\":\\\"Jobard, B.;Erlebacher, G.;Hussaini, M.Y.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;FlowVisualizationDataAndTechniques;InputAndOutputDevicesGeneral;StreamlinesPathlinesStreaklines;Textures;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885689\\\",\\\"Keywords\\\":\\\"streakline;unsteady;advection;vector field;hardware;opengl;pathlines;texture\\\",\\\"Keywords_Processed\\\":\\\"vector field;unsteady;opengl;pathline;texture;hardware;advection;streakline\\\",\\\"Title\\\":\\\"Hardware-accelerated texture advection for unsteady flow visualization\\\"},\\\"267\\\":{\\\"Abstract\\\":\\\"The paper presents a seed placement strategy for streamlines based on flow features in the dataset. The primary goal of our seeding strategy is to capture flow patterns in the vicinity of critical points in the flow field, even as the density of streamlines is reduced. Secondary goals are to place streamlines such that there is sufficient coverage in non-critical regions, and to vary the streamline placements and lengths so that the overall presentation is aesthetically pleasing (avoid clustering of streamlines, avoid sharp discontinuities across several streamlines, etc.). The procedure is straightforward and non-iterative. First, critical points are identified. Next, the flow field is segmented into regions, each containing a single critical point. The critical point in each region is then seeded with a template depending on the type of critical point. Finally, additional seed points are randomly distributed around the field using a Poisson disk distribution to minimize closely spaced seed points. The main advantage of this approach is that it does not miss the features around critical points. Since the strategy is not image-guided, and hence not view dependent, significant savings are possible when examining flow fields from different viewpoints, especially for 3D flow fields.\\\",\\\"Authors\\\":\\\"Verma, V.;Kao, D.;Pang, A.\\\",\\\"Clusters\\\":\\\"ParticleVisualizationAndTechniques;PointBasedDataAndTechniques;StreamlinesPathlinesStreaklines;TopologyBasedTechniques;VoronoiBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885690\\\",\\\"Keywords\\\":\\\"seed placement;voronoi diagram;critical points;poisson disk distribution;streamlines\\\",\\\"Keywords_Processed\\\":\\\"streamline;critical point;seed placement;poisson disk distribution;voronoi diagram\\\",\\\"Title\\\":\\\"A flow-guided streamline seeding strategy\\\"},\\\"268\\\":{\\\"Abstract\\\":\\\"The work presents a method to enable matching of level-of-detail (LOD) models to image-plane resolution over large variations in viewing distances often present in exterior images. A relationship is developed between image sampling rate, viewing distance, object projection, and expected image error due to LOD approximations. This is employed in an error metric to compute error profiles for LOD models. Multirate filtering in the frequency space of a reference object image is utilized to approximate multiple distant views over a range of orientations. An importance sampling method is described to better characterize perspective projection over view distance. A contrast sensitivity function (CSF) is employed to approximate the response of the vision system. Examples are presented for multiresolution spheres and a terrain height field feature. Future directions for extending this method are described.\\\",\\\"Authors\\\":\\\"Scoggins, R.;Machiraju, R.;Moorhead, R.J.\\\",\\\"Clusters\\\":\\\"DataAndAnalysisMetrics;GeographyGeospatialVisCartographyTerrainVis;LevelOfDetail;MultiresolutionTechniques;Perception;Rendering\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885691\\\",\\\"Keywords\\\":\\\"terrain visualization;multi-resolution model;level-of-detail;perception;image metrics;rendering\\\",\\\"Keywords_Processed\\\":\\\"render;perception;image metric;terrain visualization;level of detail;multi resolution model\\\",\\\"Title\\\":\\\"Enabling level-of-detail matching for exterior scene synthesis\\\"},\\\"269\\\":{\\\"Abstract\\\":\\\"Distance judgments are difficult in current virtual environments,limiting their effectiveness in conveying spatial information. This problem is apparent when contact occurs while a user is manipulating objects. In particular, the computer graphics used to support current generation immersive interfaces does a poor job of providing the visual cues necessary to perceive when contact between objects is about to occur. This perception of imminent contact is important in human motor control. Its absence prevents a sense of naturalness in interactive displays which allow for object manipulation. This paper reports results from an experiment evaluating the effectiveness of binocular disparity, cast shadows, and diffuse interreflections in signaling imminent contact in a manipulation task.\\\",\\\"Authors\\\":\\\"Hu, H.H;Gooch, A.A.;Thompson, W.B.;Smits, B.E.;Rieser, J.J.;Shirley, P.\\\",\\\"Clusters\\\":\\\"DisplaysGeneral;ImmersiveAndVirtualEnvironments;Perception\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885692\\\",\\\"Keywords\\\":\\\"head-mounted displays;virtual reality;human visual perception\\\",\\\"Keywords_Processed\\\":\\\"head mount display;virtual reality;human visual perception\\\",\\\"Title\\\":\\\"Visual cues for imminent object contact in realistic virtual environment\\\"},\\\"270\\\":{\\\"Abstract\\\":\\\"This is basic research for assigning color values to voxels of multichannel MRI volume data. The MRI volume data sets obtained under different scanning conditions are transformed into their components by independent component analysis (ICA), which enhances the physical characteristics of the tissue. The transfer functions for generating color values from independent components are obtained using a radial basis function network, a kind of neural net, by training the network with sample data chosen from the Visible Female data set. The resultant color volume data sets correspond well with the full-color cross-sections of the Visible Human data sets.\\\",\\\"Authors\\\":\\\"Muraki, S.;Nakai, T.;Kita, Y.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;MachineLearningAndStatistics;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885693\\\",\\\"Keywords\\\":\\\"independent component analysis;color mri;transfer function\\\",\\\"Keywords_Processed\\\":\\\"transfer function;color mri;independent component analysis\\\",\\\"Title\\\":\\\"Basic research for coloring multichannel MRI data\\\"},\\\"271\\\":{\\\"Abstract\\\":\\\"Accurately and automatically conveying the structure of a volume model is a problem that has not been fully solved by existing volume rendering approaches. Physics-based volume rendering approaches create images which may match the appearance of translucent materials in nature but may not embody important structural details. Transfer function approaches allow flexible design of the volume appearance but generally require substantial hand-tuning for each new data set in order to be effective. We introduce the volume illustration approach, combining the familiarity of a physics-based illumination model with the ability to enhance important features using non-photorealistic rendering techniques. Since the features to be enhanced are defined on the basis of local volume characteristics rather than volume sample values, the application of volume illustration techniques requires less manual tuning than the design of a good transfer function. Volume illustration provides a flexible unified framework for enhancing structural perception of volume models through the amplification of features and the addition of illumination effects.\\\",\\\"Authors\\\":\\\"Ebert, D.S.;Rheingans, P.\\\",\\\"Clusters\\\":\\\"Illumination;IllustrativeVisualization;Rendering;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885694\\\",\\\"Keywords\\\":\\\"shading;volume rendering;non-photorealistic rendering;lighting model;visualization;illustration\\\",\\\"Keywords_Processed\\\":\\\"visualization;volume render;non photorealistic rendering;shade;illustration;lighting model\\\",\\\"Title\\\":\\\"Volume illustration: non-photorealistic rendering of volume models\\\"},\\\"272\\\":{\\\"Abstract\\\":\\\"Concerns the development of non-photorealistic rendering techniques for volume visualisation. In particular, we present two pen-and-ink rendering methods, a 3D method based on non-photorealistic solid textures, and a 2+D method that involves two rendering phases in the object space and the image space respectively. As both techniques utilize volume- and image-based data representations, they can be built upon a traditional volume rendering pipeline, and can be integrated with the photorealistic methods available in such a pipeline. We demonstrate that such an integration facilitates an effective mechanism for enhancing visualisation and its interpretation.\\\",\\\"Authors\\\":\\\"Treavett, S.M.F.;Chen, M.\\\",\\\"Clusters\\\":\\\"IllustrativeVisualization;Textures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885696\\\",\\\"Keywords\\\":\\\"3d texture mapping;volume rendering;non-photorealistic rendering;pen-and-ink rendering\\\",\\\"Keywords_Processed\\\":\\\"volume render;non photorealistic rendering;3d texture mapping;pen and ink render\\\",\\\"Title\\\":\\\"Pen-and-ink rendering in volume visualisation\\\"},\\\"273\\\":{\\\"Abstract\\\":\\\"Presents a two-level approach for fusing direct volume rendering (DVR) and maximum-intensity projection (MIP) within a joint rendering method. Different structures within the data set are rendered locally by either MIP or DVR on an object-by-object basis. Globally, all the results of subsequent object renderings are combined in a merging step (usually compositing in our case). This allows us to selectively choose the most suitable technique for depicting each object within the data, while keeping the amount of information contained in the image at a reasonable level. This is especially useful when inner structures should be visualized together with semi-transparent outer parts, similar to the focus-and-context approach known from information visualization. We also present an implementation of our approach which allows us to explore volumetric data using two-level rendering at interactive frame rates.\\\",\\\"Authors\\\":\\\"Hauser, H.;Mroz, L.;Bischi, G.-I.;Groller, E.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DynamicVisualizationVisualizationOfChange;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885697\\\",\\\"Keywords\\\":\\\"visualization;medical applications;volume rendering;dynamical systems\\\",\\\"Keywords_Processed\\\":\\\"visualization;volume render;dynamical system;medical application\\\",\\\"Title\\\":\\\"Two-level volume rendering - fusing MIP and DVR\\\"},\\\"274\\\":{\\\"Abstract\\\":\\\"Presents a new rendering technique for processing multiple multi-resolution textures of LOD (level-of-detail) terrain models and describes its application to interactive, animated terrain content design. The approach is based on a multi-resolution model for terrain texture which cooperates with a multi-resolution model for terrain geometry. For each texture layer, an image pyramid and a texture tree are constructed. Multiple texture layers can be associated with one terrain model and can be combined in different ways, e.g. by blending and masking. The rendering algorithm simultaneously traverses the multi-resolution geometry model and the multi-resolution texture model, and takes into account geometric and texture approximation errors. It uses multi-pass rendering and exploits multi-texturing to achieve real-time performance. Applications include interactive texture lenses, texture animation and topographic textures. These techniques offer an enormous potential for developing new visualization applications for presenting, exploring and manipulating spatio-temporal data.\\\",\\\"Authors\\\":\\\"Dollner, J.;Baumann, K.;Hinrichs, K.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;LevelOfDetail;MultiresolutionTechniques;Textures;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885699\\\",\\\"Keywords\\\":\\\"multi-resolution;level-of-detail;terrain rendering;3d map;texture mapping\\\",\\\"Keywords_Processed\\\":\\\"terrain render;multi resolution;3d map;level of detail;texture mapping\\\",\\\"Title\\\":\\\"Texturing techniques for terrain visualization\\\"},\\\"275\\\":{\\\"Abstract\\\":\\\"Geometric models are often annotated to provide additional information during visualization. Maps may be marked with rivers, roads or topographical information, and CAD data models may highlight the underlying mesh structure. While this additional information may be extremely useful, there is a rendering cost associated with it. Texture maps have often been used to convey this information at relatively low cost, but they suffer from blurring and pixelization at high magnification. We present a technique for simplifying surface annotations based on directed, asymmetric tolerance. By maintaining the annotations as geometry, as opposed to textures, we are able to simplify them while still maintaining the overall appearance of the model over a wide range of magnifications. Texture maps may still be used to provide low-resolution surface detail, such as color. We demonstrate a significant gain in rendering performance while retaining the original appearance of objects from many application domains.\\\",\\\"Authors\\\":\\\"Suits, F.;Klosowski, J.T.;Horn, W.;Lecina, G.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;ApplicationsGeneralAndOther;GeographyGeospatialVisCartographyTerrainVis;GeometricModeling;MeshesGridsAndLattices;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885700\\\",\\\"Keywords\\\":\\\"finite element method;polygonal path;mesh;cartography;cad/cam;simplification\\\",\\\"Keywords_Processed\\\":\\\"polygonal path;mesh;finite element method;cad cam;simplification;cartography\\\",\\\"Title\\\":\\\"Simplification of surface annotations\\\"},\\\"276\\\":{\\\"Abstract\\\":\\\"Discusses the concept of uniform frequency images, which exhibit uniform local frequency properties. Such images make optimal use of space when sampled close to their Nyquist limit. A warping function may be applied to an arbitrary image to redistribute its local frequency content, reducing its highest frequencies and increasing its lowest frequencies in order to approach this uniform frequency ideal. The warped image may then be downsampled according to its new, reduced Nyquist limit, thereby reducing its storage requirements. To reconstruct the original image, the inverse warp is applied. We present a general, top-down algorithm to automatically generate a piecewise-linear warping function with this frequency balancing property for a given input image. The image size is reduced by applying the warp and then downsampling. We store this warped, downsampled image plus a small number of polygons with texture coordinates to describe the inverse warp. The original image is later reconstructed by rendering the associated polygons with the warped image applied as a texture map, a process which is easily accelerated by current graphics hardware. As compared to previous image compression techniques, we generate a similar graceful space-quality tradeoff with the advantage of being able to \\\\\\\"uncompress\\\\\\\" images during rendering. We report results for several images with sizes ranging from 15,000 to 300,000 pixels, achieving reduction rates of 70-90% with improved quality over downsampling alone.\\\",\\\"Authors\\\":\\\"Hunter, A.;Cohen, J.D.\\\",\\\"Clusters\\\":\\\"NumericalMethodsMathematics;Parameterization;Sampling;Textures;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885701\\\",\\\"Keywords\\\":\\\"parameterization;sampling;visualization;texture mapping;fourier analysis\\\",\\\"Keywords_Processed\\\":\\\"visualization;fouri analysis;sample;texture mapping;parameterization\\\",\\\"Title\\\":\\\"Uniform frequency images: adding geometry to images to produce space-efficient textures\\\"},\\\"277\\\":{\\\"Abstract\\\":\\\"This paper presents an efficient keyframeless image-based rendering technique. An intermediate image is used to exploit the coherences among neighboring frames. The pixels in the intermediate image are first rendered by a ray-casting method and then warped to the intermediate image at the current viewpoint and view direction. We use an offset buffer to record the precise positions of these pixels in the intermediate image. Every frame is generated in three steps: warping the intermediate image onto the frame, filling in holes, and selectively rendering a group of old pixels. By dynamically adjusting the number of those old pixels in the last step, the workload at every frame can be balanced. The pixels generated by the last two steps make contributions to the new intermediate image. Unlike occasional keyframes in conventional image-based rendering which need to be totally rerendered, intermediate images only need to be partially updated at every frame. In this way, we guarantee more stable frame rates and more uniform image qualities. The intermediate image can be warped efficiently by a modified incremental 3D warp algorithm. As a specific application, we demonstrate our technique with a voxel-based terrain rendering system.\\\\\\\"\\\",\\\"Authors\\\":\\\"Qu, H.;Wan, M.;Qin, J.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;ImageBasedDataImageSignalProcessing;RaytracingRaycasting;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885702\\\",\\\"Keywords\\\":\\\"image-based rendering;terrain rendering;voxel-based modeling;raycasting\\\",\\\"Keywords_Processed\\\":\\\"image base render;terrain render;voxel base modeling;raycaste\\\",\\\"Title\\\":\\\"Image based rendering with stable frame rates\\\"},\\\"278\\\":{\\\"Abstract\\\":\\\"Multiresolution methods are becoming increasingly important tools for the interactive visualization of very large data sets. Multiresolution isosurface visualization allows the user to explore volume data using simplified and coarse representations of the isosurface for overview images, and finer resolution in areas of high interest or when zooming into the data. Ideally, a coarse isosurface should have the same topological structure as the original. The topological genus of the isosurface is one important property which is often neglected in multiresolution algorithms. This results in uncontrolled topological changes which can occur whenever the level-of-detail is changed. The scope of this paper is to propose an efficient technique which allows preservation of topology as well as controlled topology simplification in multiresolution isosurface extraction.\\\",\\\"Authors\\\":\\\"Gerstner, T.;Pajarola, R.\\\",\\\"Clusters\\\":\\\"LevelOfDetail;MeshesGridsAndLattices;SurfaceRelatedDataAndTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885703\\\",\\\"Keywords\\\":\\\"tetrahedral grid refinement;topological genus;level-of-detail;critical points;implicit surface approximation\\\",\\\"Keywords_Processed\\\":\\\"topological genus;critical point;level of detail;implicit surface approximation;tetrahedral grid refinement\\\",\\\"Title\\\":\\\"Topology preserving and controlled topology simplifying multiresolution isosurface extraction\\\"},\\\"279\\\":{\\\"Abstract\\\":\\\"We present a novel method to extract iso-surfaces from distance volumes. It generates high quality semi-regular multiresolution meshes of arbitrary topology. Our technique proceeds in two stages. First, a very coarse mesh with guaranteed topology is extracted. Subsequently an iterative multi-scale force-based solver refines the initial mesh into a semi-regular mesh with geometrically adaptive sampling rate and good aspect ratio triangles. The coarse mesh extraction is performed using a new approach we call surface wavefront propagation. A set of discrete iso-distance ribbons are rapidly built and connected while respecting the topology of the iso-surface implied by the data. Subsequent multi-scale refinement is driven by a simple force-based solver designed to combine good iso-surface fit and high quality sampling through reparameterization. In contrast to the Marching Cubes technique our output meshes adapt gracefully to the iso-surface geometry, have a natural multiresolution structure and good aspect ratio triangles, as demonstrated with a number of examples.\\\",\\\"Authors\\\":\\\"Wood, Z.J.;Desbrun, M.;Schroder, P.;Breen, D.\\\",\\\"Clusters\\\":\\\"GeometricModeling;IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices;NumericalMethodsMathematics;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885705\\\",\\\"Keywords\\\":\\\"surface extraction;volumes;semi-regular meshes;implicit functions;subdivision;level set method\\\",\\\"Keywords_Processed\\\":\\\"semi regular mesh;implicit function;volume;subdivision;surface extraction;level set method\\\",\\\"Title\\\":\\\"Semi-regular mesh extraction from volumes\\\"},\\\"280\\\":{\\\"Abstract\\\":\\\"A standard way to segment medical imaging datasets is by tracing contours around regions of interest in parallel planar slices. Unfortunately, the standard methods for reconstructing three dimensional surfaces from those planar contours tend to be either complicated or not very robust. Furthermore, they fail to consistently mesh abutting structures which share portions of contours. We present a novel, straight-forward algorithm for accurately and automatically reconstructing surfaces from planar contours. Our algorithm is based on scanline rendering and separating surface extraction. By rendering the contours as distinctly colored polygons and reading back each rendered slice into a segmented volume, we reduce the complex problem of building a surface from planar contours to the much simpler problem of extracting separating surfaces from a classified volume. Our scanline surfacing algorithm robustly handles complex surface topologies such as bifurcations, embedded features and abutting surfaces.\\\",\\\"Authors\\\":\\\"Weinstein, D.\\\",\\\"Clusters\\\":\\\"ContourCreasesRidgesValleys;ImageBasedDataImageSignalProcessing;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885706\\\",\\\"Keywords\\\":\\\"surface construction;planar contours;separating surfaces;scanline\\\",\\\"Keywords_Processed\\\":\\\"planar contour;surface construction;scanline;separate surface\\\",\\\"Title\\\":\\\"Scanline surfacing: building separating surfaces from planar contours\\\"},\\\"281\\\":{\\\"Abstract\\\":\\\"Throughout the design cycle, visualization, whether a sketch scribbled on the back of a spare piece of paper or a fully detailed drawing, has been the mainstay of design: we need to see the product. One of the most important stages of the design cycle is the initial, or concept, stage and it is here that design variants occur in large numbers to be vetted quickly. At this initial stage the human element, the designer is crucial to the success of the product. We describe an interactive environment for concept design which recognises the needs of the designer, not only to see the product and make rapid modifications, but also to monitor the progress of their design towards some preferred solution. This leads to the notion of a design parameter space, typically high-dimensional, which must also be visualized in addition to the product itself. Using a module developed for IRIS Explorer design steering is presented as a navigation of this space in order to search for optimal designs, either manually or by local optimisation.\\\",\\\"Authors\\\":\\\"Wright, H.;Brodlie, K.;David, T.\\\",\\\"Clusters\\\":\\\"DesignMethodologiesAndInteractionDesign;HumanComputerInteractionHumanFactors;MultidimensionalMultivariateMultifieldDataAndTechniques;Simulation;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885707\\\",\\\"Keywords\\\":\\\"scientific visualization;multi-dimensional visualization;design steering;computational steering;concept design\\\",\\\"Keywords_Processed\\\":\\\"computational steering;design steering;multi dimensional visualization;scientific visualization;concept design\\\",\\\"Title\\\":\\\"Navigating high-dimensional spaces to support design steering\\\"},\\\"282\\\":{\\\"Abstract\\\":\\\"Multi-dimensional entities are modeled, displayed and understood with a new algorithm vectorizing data of any dimensionality. This algorithm is called SBP; it is a vectorized generalization of parallel coordinates. Classic geometries of any dimensionality can be demonstrated to facilitate perception and understanding of the shapes generated by this algorithm. SBP images of a 4D line, a circle and 3D and 4D spherical helices are shown. A strategy for synthesizing multi-dimensional models matching multi-dimensional data is presented. Current applications include data mining; modeling data-defined structures of scientific interest such as protein structure and Calabi-Yau figures as multi-dimensional geometric entities; generating vector-fused data signature fingerprints of classic frequency spectra that identify substances; and treating complex targets as multi-dimensional entities for automatic target recognition. SBP vector data signatures apply to all pattern recognition problems.\\\",\\\"Authors\\\":\\\"Johnson, R.R.\\\",\\\"Clusters\\\":\\\"GeometryBasedTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885708\\\",\\\"Keywords\\\":\\\"vector data fusion;multi-dimensional visualization;multi-dimensional geometry\\\",\\\"Keywords_Processed\\\":\\\"vector datum fusion;multi dimensional geometry;multi dimensional visualization\\\",\\\"Title\\\":\\\"Visualization of multi-dimensional data with vector-fusion\\\"},\\\"283\\\":{\\\"Abstract\\\":\\\"This paper describes a novel rendering technique for special relativistic visualization. It is an image-based method which allows to render high speed flights through real-world scenes filmed by a standard camera. The relativistic effects on image generation are determined by the relativistic aberration of light, the Doppler effect, and the searchlight effect. These account for changes of apparent geometry, color and brightness of the objects. It is shown how the relativistic effects can be taken into account by a modification of the plenoptic function. Therefore, all known image-based nonrelativistic rendering methods can easily be extended to incorporate relativistic rendering. Our implementation allows interactive viewing of relativistic panoramas and the production of movies which show super-fast travel. Examples in the form of snapshots and film sequences are included.\\\",\\\"Authors\\\":\\\"Weiskopf, D.;Kobras, D.;Ruder, H.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;ImageBasedDataImageSignalProcessing;PhysicsAndPhysicalSciences;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885709\\\",\\\"Keywords\\\":\\\"image-based rendering;scientific visualization;special relativity;plenoptic function\\\",\\\"Keywords_Processed\\\":\\\"image base render;special relativity;plenoptic function;scientific visualization\\\",\\\"Title\\\":\\\"Real-world relativity: image-based special relativistic visualization\\\"},\\\"284\\\":{\\\"Abstract\\\":\\\"One of the main research topics in scientific visualization is to \\\\\\\"visualize the appropriate features\\\\\\\" of a certain structure or data set. Geodesics are very important in geometry and physics, but there is one major problem which prevents scientists from using them as a visualization tool: the differential equations for geodesics are very complicated and in most cases numerical algorithms must be used. There is always a certain approximation error involved. How can you be sure to visualize the features and not only the approximation quality. The paper presents an algorithm to overcome this problem. It consists of two parts. In the first, a geometric method for the construction of geodesics of arbitrary surfaces is introduced. This method is based on the fundamental property that geodesics are a generalization of straight lines on plains. In the second part these geodesics are used to generate local nets on the surfaces.\\\",\\\"Authors\\\":\\\"Hotz, I.;Hagen, H.\\\",\\\"Clusters\\\":\\\"DataFeaturesAndAttributes;GeometricModeling\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885710\\\",\\\"Keywords\\\":\\\"visualization features;geodesics\\\",\\\"Keywords_Processed\\\":\\\"geodesic;visualization feature\\\",\\\"Title\\\":\\\"Visualizing geodesics\\\"},\\\"285\\\":{\\\"Abstract\\\":\\\"The compression of geometric structures is a relatively new field of data compression. Since about 1995, several articles have dealt with the coding of meshes, using for most of them the following approach: the vertices of the mesh are coded in an order that partially contains the topology of the mesh. In the same time, some simple rules attempt to predict the position of each vertex from the positions of its neighbors that have been previously coded. We describe a compression algorithm whose principle is completely different: the coding order of the vertices is used to compress their coordinates, and then the topology of the mesh is reconstructed from the vertices. This algorithm achieves compression ratios that are slightly better than those of the currently available algorithms, and moreover, it allows progressive and interactive transmission of the meshes.\\\",\\\"Authors\\\":\\\"Devillers, O.;Gandoin, P.-M.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;GeographyGeospatialVisCartographyTerrainVis;GeometryBasedTechniques;InteractionTechniquesGeneral;Interpolation;MeshesGridsAndLattices;ProgrammingAlgorithmsAndDataStructures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885711\\\",\\\"Keywords\\\":\\\"geometry;reconstruction;compression;terrain models;mesh;interactivity;coding\\\",\\\"Keywords_Processed\\\":\\\"interactivity;compression;reconstruction;mesh;code;geometry;terrain model\\\",\\\"Title\\\":\\\"Geometric compression for interactive transmission\\\"},\\\"286\\\":{\\\"Abstract\\\":\\\"In 1998 we introduced the idea for a project we call the Office of the Future. Our long-term vision is to provide a better every-day working environment, with high-fidelity scene reconstruction for life-sized 3D tele-collaboration. In particular, we want a true sense of presence with our remote collaborator and their real surroundings. The challenges related to this vision are enormous and involve many technical tradeoffs. This is true in particular for scene reconstruction. Researchers have been striving to achieve real-time approaches, and while they have made respectable progress, the limitations of conventional technologies relegate them to relatively low resolution in a restricted volume. We present a significant step toward our ultimate goal, via a slightly different path. In lieu of low-fidelity dynamic scene modeling we present an exceedingly high fidelity reconstruction of a real but static office. By assembling the best of available hardware and software technologies in static scene acquisition, modeling algorithms, rendering, tracking and stereo projective display, we are able to demonstrate a portal to a real office, occupied today by a mannequin, and in the future by a real remote collaborator. We now have both a compelling sense of just how good it could be, and a framework into which we will later incorporate dynamic scene modeling, as we continue to head toward our ultimate goal of 3D collaborative telepresence.\\\",\\\"Authors\\\":\\\"Wei-Chao Wen;Towles, H.;Nyland, L.;Welch, G.;Fuchs, H.\\\",\\\"Clusters\\\":\\\"CollaborativeVisualization;DisplaysGeneral;ImmersiveAndVirtualEnvironments;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885712\\\",\\\"Keywords\\\":\\\"human-computer interface;telepresence;virtual reality;immersive display;augmented reality;tele-immersion;collaborative visualization\\\",\\\"Keywords_Processed\\\":\\\"immersive display;tele immersion;virtual reality;collaborative visualization;augmented reality;human computer interface;telepresence\\\",\\\"Title\\\":\\\"Toward a compelling sensation of telepresence: demonstrating a portal to a distant (static) office\\\"},\\\"287\\\":{\\\"Abstract\\\":\\\"We present an algorithm for compressing 2D vector fields that preserves topology. Our approach is to simplify the given data set using constrained clustering. We employ different types of global and local error metrics including the earth mover's distance metric to measure the degradation in topology as well as weighted magnitude and angular errors. As a result, we obtain precise error bounds in the compressed vector fields. Experiments with both analytic and simulated data sets are presented. Results indicate that one can obtain significant compression with low errors without losing topology information.\\\",\\\"Authors\\\":\\\"Lodha, S.K.;Renteria, J.C.;Roskin, K.M.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;DataClusteringAndAggregation;EvaluationMetricsAndBenchmarks;TopologyBasedTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885714\\\",\\\"Keywords\\\":\\\"clustering;compression;vector field;error metrics;topology\\\",\\\"Keywords_Processed\\\":\\\"vector field;error metric;topology;compression;clustering\\\",\\\"Title\\\":\\\"Topology preserving compression of 2D vector fields\\\"},\\\"288\\\":{\\\"Abstract\\\":\\\"Topology analysis of plane, turbulent vector fields results in visual clutter caused by critical points indicating vortices of finer and finer scales. A simplification can be achieved by merging critical points within a prescribed radius into higher order critical points. After building clusters containing the singularities to merge, the method generates a piecewise linear representation of the vector field in each cluster containing only one (higher order) singularity. Any visualization method can be applied to the result after this process. Using different maximal distances for the critical points to be merged results in a hierarchy of simplified vector fields that can be used for analysis on different scales.\\\",\\\"Authors\\\":\\\"Tricoche, X.;Scheuermann, G.;Hagen, H.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;DataClusteringAndAggregation;FlowVisualizationDataAndTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885716\\\",\\\"Keywords\\\":\\\"flow visualization;vector field topology;simplification;clustering\\\",\\\"Keywords_Processed\\\":\\\"vector field topology;simplification;clustering;flow visualization\\\",\\\"Title\\\":\\\"A topology simplification method for 2D vector fields\\\"},\\\"289\\\":{\\\"Abstract\\\":\\\"We present a new algorithm for material boundary interface reconstruction from data sets containing volume fractions. We transform the reconstruction problem to a problem that analyzes the dual data set, where each vertex in the dual mesh has an associated barycentric coordinate tuple that represents the fraction of each material present. After constructing the dual tetrahedral mesh from the original mesh, we construct material boundaries by mapping a tetrahedron into barycentric space and calculating the intersections with Voronoi cells in barycentric space. These intersections are mapped back to the original physical space and triangulated to form the boundary surface approximation. This algorithm can be applied to any grid structure and can treat any number of materials per element/vertex.\\\",\\\"Authors\\\":\\\"Bonnell, K.;Schikore, D.R.;Joy, K.I.;Duchaineau, M.;Hamann, B.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;GeometricModeling;IsosurfaceAndSurfaceExtractionTechniques;VolumeRenderingModelingAndVisualization;VoronoiBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885717\\\",\\\"Keywords\\\":\\\"eulerian flow;voronoi diagram;volume fraction;barycentric coordinates;material boundary surface\\\",\\\"Keywords_Processed\\\":\\\"eulerian flow;volume fraction;material boundary surface;barycentric coordinate;voronoi diagram\\\",\\\"Title\\\":\\\"Constructing material interfaces from data sets with volume-fraction information\\\"},\\\"290\\\":{\\\"Abstract\\\":\\\"We present a novel approach to surface reconstruction based on the Delaunay complex. First we give a simple and fast algorithm that picks locally a surface at each vertex. For that, we introduce the concept of -intervals. It turns out that for smooth regions of the surface this method works very well and at difficult parts of the surface yields an output well-suited for postprocessing. As a postprocessing step we propose a topological clean up and a new technique based on linear programming in order to establish a topologically correct surface. These techniques should be useful also for many other reconstruction schemes.\\\",\\\"Authors\\\":\\\"Adamy, U.;Giesen, J.;John, M.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;ProgrammingAlgorithmsAndDataStructures;SurfaceRelatedDataAndTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885718\\\",\\\"Keywords\\\":\\\"gabriel graph;surface reconstruction;topology;linear programming\\\",\\\"Keywords_Processed\\\":\\\"surface reconstruction;linear programming;gabriel graph;topology\\\",\\\"Title\\\":\\\"New techniques for topologically correct surface reconstruction\\\"},\\\"291\\\":{\\\"Abstract\\\":\\\"Polyhedral meshes are used for visualization, computer graphics or geometric modeling purposes and result from many applications like iso-surface extraction, surface reconstruction or CAD/CAM. The paper introduces a method for constructing smooth surfaces from a triangulated polyhedral mesh of arbitrary topology. It presents a new algorithm which generalizes and improves the triangle 4-split method (S. Hahmann and G.-P. Bonneau) in the crucial point of boundary curve network construction. This network is then filled in by a visual smooth surface from which an explicit closed form parametrization is given. Furthermore, the method becomes now completely local and can interpolate normal vector input at the mesh vertices.\\\",\\\"Authors\\\":\\\"Bonneau, G.-P.;Hahmann, S.\\\",\\\"Clusters\\\":\\\"MeshesGridsAndLattices;TopologyBasedTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885719\\\",\\\"Keywords\\\":\\\"visualization;arbitrary topology;triangular mesh;visual continuity\\\",\\\"Keywords_Processed\\\":\\\"visualization;arbitrary topology;visual continuity;triangular mesh\\\",\\\"Title\\\":\\\"Polyhedral modeling\\\"},\\\"292\\\":{\\\"Abstract\\\":\\\"A new multiscale method in surface processing is presented which combines the image processing methodology based on nonlinear diffusion equations and the theory of geometric evolution problems. Its aim is to smooth discretized surfaces while simultaneously enhancing geometric features such as edges and corners. This is obtained by an anisotropic curvature evolution, where time is the multiscale parameter. Here, the diffusion tensor depends on the shape operator of the evolving surface. A spatial finite element discretization on arbitrary unstructured triangular meshes and a semi-implicit finite difference discretization in time are the building blocks of the easy to code algorithm presented. The systems of linear equations in each timestep are solved by appropriate, preconditioned iterative solvers. Different applications underline the efficiency and flexibility of the presented type of surface processing tool.\\\",\\\"Authors\\\":\\\"Clarenz, U.;Diewald, U.;Rumpf, M.\\\",\\\"Clusters\\\":\\\"GeometricModeling;ImageBasedDataImageSignalProcessing;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885721\\\",\\\"Keywords\\\":\\\"numerical analysis;image processing;geometric modeling\\\",\\\"Keywords_Processed\\\":\\\"image processing;geometric modeling;numerical analysis\\\",\\\"Title\\\":\\\"Anisotropic geometric diffusion in surface processing\\\"},\\\"293\\\":{\\\"Abstract\\\":\\\"We present an algorithm for automatically classifying the interior and exterior parts of a polygonal model. The need for visualizing the interiors of objects frequently arises in medical visualization and CAD modeling. The goal of such visualizations is to display the model in a way that the human observer can easily understand the relationship between the different parts of the surface. While there exist excellent methods for visualizing surfaces that are inside one another (nested surfaces), the determination of which parts of the surface are interior is currently done manually. Our automatic method for interior classification takes a sampling approach using a collection of direction vectors. Polygons are said to be interior to the model if they are not visible in any of these viewing directions from a point outside the model. Once we have identified polygons as being inside or outside the model, these can be textured or have different opacities applied to them so that the whole model can be rendered in a more comprehensible manner. An additional consideration for some models is that they may have holes or tunnels running through them that are connected to the exterior surface. Although an external observer can see into these holes. It is often desirable to mark the walls of such tunnels as being part of the interior of a model. In order to allow this modified classification of the interior, we use morphological operators to close all the holes of the model. An input model is used together with its closed version to provide a better classification of the portions of the original model.\\\",\\\"Authors\\\":\\\"Nooruddin, F.S.;Turk, G.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;IsosurfaceAndSurfaceExtractionTechniques;Rendering;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885723\\\",\\\"Keywords\\\":\\\"visibility;surface classification;rendering;interior surfaces\\\",\\\"Keywords_Processed\\\":\\\"render;visibility;surface classification;interior surface\\\",\\\"Title\\\":\\\"Interior/exterior classification of polygonal models\\\"},\\\"294\\\":{\\\"Abstract\\\":\\\"Visualization can be an important tool for displaying, categorizing and digesting large quantities of inter-related information during laboratory and simulation experiments. Summary visualizations that compare and represent data sets in the context of a collection are particularly valuable. Applicable visualizations used in these settings must be fast (near real time) and should allow the addition of data sets as they are acquired without requiring rerendering of the visualization. This paper examines several visualization techniques for representing collections of data sets in a combustion experiment including spectral displays, tiling and geometric mappings of symmetry. The application provides insight into how such visualizations might be used in practical real-time settings to assist in exploration and in conducting parameter space surveys.\\\",\\\"Authors\\\":\\\"Robbins, K.A.;Gorman, M.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;InteractionTechniquesGeneral;MultimediaImageVideoMusic;RealtimeProcessingRenderingAndVisualizationGeneral;VisualEncodingAndLayoutGeneral;VisualPatternFeatureDetectionAndTracking\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885725\\\",\\\"Keywords\\\":\\\"movies;realtime visualization;steering;tiling;pattern formation;symmetry\\\",\\\"Keywords_Processed\\\":\\\"symmetry;steer;movie;pattern formation;tile;realtime visualization\\\",\\\"Title\\\":\\\"Fast visualization methods for comparing dynamics: a case study in combustion\\\"},\\\"295\\\":{\\\"Abstract\\\":\\\"The display of iso-surfaces in medical data sets is an important visualization technique used by radiologists for the diagnosis of volumetric density data sets. The demands put by radiologists on such a display technique are interactivity, multiple stacked transparent surfaces and cutting planes that allow an interactive clipping of the surfaces. This paper presents a Java based, platform independent implementation of a very fast surface rendering algorithm which combines the advantages of explicit surface representation, splatting, and shear-warp projection to fulfill all these requirements. The algorithm is implemented within the context of J-Vision, an application for viewing and diagnosing medical images which is currently in use at various hospitals.\\\",\\\"Authors\\\":\\\"Mroz, L.;Wegenkittl, R.;Groller, E.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;SurfaceRelatedDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885726\\\",\\\"Keywords\\\":\\\"medical applications;tomographic data;surface rendering;volume visualization\\\",\\\"Keywords_Processed\\\":\\\"medical application;surface render;volume visualization;tomographic datum\\\",\\\"Title\\\":\\\"Mastering interactive surface rendering for Java-based diagnostic applications\\\"},\\\"296\\\":{\\\"Abstract\\\":\\\"General relativistic ray tracing is presented as a tool for gravitational physics. It is shown how standard three-dimensional ray tracing can be extended to allow for general relativistic visualization. This visualization technique provides images as seen by an observer under the influence of a gravitational field and allows to probe space-time by null geodesics. Moreover, a technique is proposed for visualizing the caustic surfaces generated by a gravitational lens. The suitability of general relativistic ray tracing is demonstrated by means of two examples, namely the visualization of the rigidly rotating disk of dust and the warp drive metric.\\\",\\\"Authors\\\":\\\"Weiskopf, D.\\\",\\\"Clusters\\\":\\\"GeometryBasedTechniques;PhysicsAndPhysicalSciences;RaytracingRaycasting;SpatiotemporalDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885728\\\",\\\"Keywords\\\":\\\"4d space time;scientific visualization;raytracing;differential geometry;general relativity\\\",\\\"Keywords_Processed\\\":\\\"differential geometry;scientific visualization;general relativity;4d space time;raytrace\\\",\\\"Title\\\":\\\"Four-dimensional non-linear ray tracing as a visualization tool for gravitational physics\\\"},\\\"297\\\":{\\\"Abstract\\\":\\\"We describe a toolkit for the design and visualization of flexible artificial heart valves. The toolkit consists of interlinked modules with a visual programming interface. The user of the toolkit can set the initial geometry and material properties of the valve leaflet, solve for the flexing of the leaflet and the flow of blood around it, and display the results using the visualization capabilities of the toolkit. The interactive nature of our environment is highlighted by the fact that changes in leaflet properties are immediately reflected in the flow field and response of the leaflet. Hence the user may, in a single session, investigate a broad range of designs, each one of which provides important information about the blood flow and motion of the valve during the cardiac cycle.\\\",\\\"Authors\\\":\\\"Fenlon, A.J.;David, T.;Walton, J.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DesignMethodologiesAndInteractionDesign;FlowVisualizationDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885730\\\",\\\"Keywords\\\":\\\"computational fluid dynamics;prosthetic heart valves;visualization systems;interactive design\\\",\\\"Keywords_Processed\\\":\\\"visualization system;computational fluid dynamic;prosthetic heart valve;interactive design\\\",\\\"Title\\\":\\\"An integrated visualization and design toolkit for flexible prosthetic heart valves\\\"},\\\"298\\\":{\\\"Abstract\\\":\\\"Virtual endoscopy presents the cross-sectional acquired 3D-data of a computer tomograph as an endoluminal view. The common approach for the visualization of a virtual endoscopy is surface rendering, yielding images close to a real endoscopy. If external structures are of interest, volume rendering techniques have to be used. These methods do not display the exact shape of the inner lumen very well. For certain applications, e.g. operation planning of a transbronchial biopsy, both the shape of the inner lumen as well as outer structures like blood vessels and the tumor have to be delineated. A method is described, that allows a quick and easy hybrid visualization using overlays of different visualization methods like different surfaces or volume renderings with different transfer functions in real time on a low-end PC. To achieve real time frame rates, image based rendering techniques have been used.\\\",\\\"Authors\\\":\\\"Wegenkittl, R.;Vilanova, A.;Hegedust, B.;Wagner, D.;Freund, M.C.;Groller, E.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885732\\\",\\\"Keywords\\\":\\\"medical visualization;visualization systems;virtual endoscopy\\\",\\\"Keywords_Processed\\\":\\\"virtual endoscopy;visualization system;medical visualization\\\",\\\"Title\\\":\\\"Mastering interactive virtual bronchioscopy on a low-end PC\\\"},\\\"299\\\":{\\\"Abstract\\\":\\\"The study of time dependent characteristics of proteins is important for gaining insight into many biological processes. However, visualizing protein dynamics by animating atom trajectories does not provide satisfactory results. When the trajectory is sampled with large times steps, the impression of smooth motion will be destroyed due to the effects of temporal aliasing. Sampling with small time steps will result in the camouflage of interesting motions. In this case study, we discuss techniques for the interactive 3D visualization of the dynamics of the photoactive yellow protein. We use essential dynamics methods to filter out uninteresting atom motions from the larger concerted motions. In this way, clear and concise 3D animations of protein motions can be produced. In addition, we discuss various interactive techniques that allow exploration of the essential subspace of the protein. We discuss the merits of these techniques when applied to the analysis of the yellow protein.\\\",\\\"Authors\\\":\\\"Huitema, H.;van Liere, R.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;InteractionTechniquesGeneral;MolecularScienceAndChemistry;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885733\\\",\\\"Keywords\\\":\\\"animation;interactive exploration;essential dynamics;molecular graphics\\\",\\\"Keywords_Processed\\\":\\\"molecular graphic;essential dynamic;interactive exploration;animation\\\",\\\"Title\\\":\\\"Interactive visualization of protein dynamics\\\"},\\\"300\\\":{\\\"Abstract\\\":\\\"The authors present a visualization system for interactive real time animation and visualization of simulation results from a parallel Particle-in-Cell code. The system was designed and implemented for the Onyx2 Infinite Reality hardware. A number of different visual objects, such as volume rendered particle density functionals were implemented. To provide sufficient frame rates for interactive visualization, the system was designed to provide performance close to the hardware specifications both in terms of the I/O and graphics subsystems. The presented case study applies the developed system to the evolution of an instability that gives rise to a plasma surfatron, a mechanism which rapidly can accelerate particles to very high velocities and thus be of great importance in the context of electron acceleration in astrophysical shocks, in the solar corona and in particle accelerators. The produced visualizations have allowed us to identify a previously unknown saturation mechanism for the surfatron and direct research efforts into new areas of interest.\\\",\\\"Authors\\\":\\\"Ljung, P.;Dieckmann, M.;Andersson, N.;Ynnerman, A.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;PhysicsAndPhysicalSciences;StreamingDataAndTechniques;Textures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885734\\\",\\\"Keywords\\\":\\\"volume rendering;plasma physics;data streaming;scientific visualization;texture maps;interaction animation\\\",\\\"Keywords_Processed\\\":\\\"volume render;plasma physics;interaction animation;scientific visualization;datum stream;texture map\\\",\\\"Title\\\":\\\"Interactive visualization of particle-in-cell simulations\\\"},\\\"301\\\":{\\\"Abstract\\\":\\\"The microscopic analysis of time dependent 3D live cells provides considerable challenges to visualization. Effective visualization can provide insight into the structure and functioning of living cells. The paper presents a case study in which a number of visualization techniques were applied to analyze a specific problem in cell biology: the condensation and de-condensation of chromosomes during cell division. The spatial complexity of the data required sophisticated presentation techniques. The interactive virtual reality enabled visualization system, proteus, specially equipped for time dependent 3D data sets is described. An important feature of proteus is that it is extendible to cope with application-specific demands.\\\",\\\"Authors\\\":\\\"de Leeuw, W.;van Liere, R.;Verschure, P.J.;Visser, A.E.;Manders, E.M.M.;van Driel, R.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;ImmersiveAndVirtualEnvironments;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885735\\\",\\\"Keywords\\\":\\\"biomedical imaging;volume visualization;virtual reality\\\",\\\"Keywords_Processed\\\":\\\"volume visualization;biomedical imaging;virtual reality\\\",\\\"Title\\\":\\\"Visualization of time dependent confocal microscopy data\\\"},\\\"302\\\":{\\\"Abstract\\\":\\\"Non-traditional applications of scientific data challenge the typical approaches to visualization. In particular popular scientific visualization strategies fail when the expertise of the data consumer is in a different field than the one that generated the data and data from the user's domain must be utilized as well. This problem occurs when predictive weather simulations are used for a number of weather-sensitive applications. A data fusion approach is adopted for visualization design and utilized for specific example problems.\\\",\\\"Authors\\\":\\\"Treinish, L.A.\\\",\\\"Clusters\\\":\\\"DataRegistrationFusionAndIntegration;EarthSpaceAndEnvironmentalSciences;SocialScienceAndHumanities;TasksTaskRequirementsAnalysis;VisualDesignDesignGuidelines\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885736\\\",\\\"Keywords\\\":\\\"energy demand prediction;meteorology;weather forecasting;visualization;user tasks;demographics;data fusion;graphic design\\\",\\\"Keywords_Processed\\\":\\\"visualization;demographic;meteorology;graphic design;user task;datum fusion;weather forecasting;energy demand prediction\\\",\\\"Title\\\":\\\"Visual data fusion for applications of high-resolution numerical weather prediction\\\"},\\\"303\\\":{\\\"Abstract\\\":\\\"Applications of visualization techniques that facilitate comparison of simulation and field datasets of seafloor hydrothermal plumes are demonstrated in order to explore and confirm theories of plume behavior. In comparing these datasets, there is no one-to-one correspondence. We show the comparison by performing quantitative capturing of large scale observable features. The comparisons are needed not only to improve the relevance of the simulations to the field observations, but also to enable real time adjustment of shipboard data collection systems. Our approach for comparing simulation and field datasets is to use skeletonization and centerline representation. Features representing plumes are skeletonized. Skeleton points are used to construct a centerline and to quantify plume properties on planes normal to the centerline. These skeleton points are further used to construct an idealized cone representing a plume isosurface. The difference between the plume feature and the cone is identified as protrusions of turbulent eddies. Comparison of the simulation and field data sets through these abstractions illustrates how these abstractions characterize a plume.\\\",\\\"Authors\\\":\\\"Bemis, K.;Silver, D.;Rona, P.;Chengwei Feng\\\",\\\"Clusters\\\":\\\"AcousticsSoundSonification;ApplicationsGeneralAndOther;EarthSpaceAndEnvironmentalSciences;GeometricModeling\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885737\\\",\\\"Keywords\\\":\\\"centerline;oceanographic visualization;acoustic imaging;plumes\\\",\\\"Keywords_Processed\\\":\\\"plume;acoustic imaging;oceanographic visualization;centerline\\\",\\\"Title\\\":\\\"Case study: a methodology for plume visualization with application to real-time acquisition and navigation\\\"},\\\"304\\\":{\\\"Abstract\\\":\\\"In our study of regional climate modeling and simulation, we frequently encounter vector fields that are crowded with large numbers of critical points. A critical point in a flow is where the vector field vanishes. While these critical points accurately reflect the topology of the vector fields, in our study only a subset of them is worth further investigation. We present a filtering technique based on the vorticity of the vector fields to eliminate the less interesting and sometimes sporadic critical points in a multiresolution fashion. The neighboring regions of the preserved features, which are characterized by strong shear and circulation, are potential locations of weather instability. We apply our feature filtering technique to a regional climate modeling data set covering East Asia in the summer of 1991.\\\",\\\"Authors\\\":\\\"Pak Chung Wong;Foote, H.;Leung, R.;Jurrus, E.;Adams, D.;Thomas, J.\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;TimeseriesTimeVaryingDataAndTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885738\\\",\\\"Keywords\\\":\\\"meteorology;vector field visualization;time-varying fields\\\",\\\"Keywords_Processed\\\":\\\"meteorology;time vary field;vector field visualization\\\",\\\"Title\\\":\\\"Vector fields simplification-a case study of visualizing climate modeling and simulation data sets\\\"},\\\"305\\\":{\\\"Abstract\\\":\\\"WEAVE (Workbench Environment for Analysis and Visual Exploration) is an environment for creating interactive visualization applications. WEAVE differs from previous systems in that it provides transparent linking between custom 3D visualizations and multidimensional statistical representations, and provides interactive color brushing between all visualizations. The authors demonstrate how WEAVE can be used to rapidly prototype a biomedical application, weaving together simulation data, measurement data, and 3D anatomical data concerning the propagation of excitation in the heart. These linked statistical and custom three-dimensional visualizations of the heart can allow scientists to more effectively study the correspondence of structure and behavior.\\\",\\\"Authors\\\":\\\"Gresh, D.L.;Rogowtiz, B.;Winslow, R.L.;Scollan, D.F.;Yung, C.K.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;MachineLearningAndStatistics;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885739\\\",\\\"Keywords\\\":\\\"visualization;data synthesis;medical;heart\\\",\\\"Keywords_Processed\\\":\\\"visualization;datum synthesis;medical;heart\\\",\\\"Title\\\":\\\"WEAVE: a system for visually linking 3-D and statistical visualizations applied to cardiac simulation and measurement data\\\"},\\\"306\\\":{\\\"Abstract\\\":\\\"Visualization techniques enable scientists to interactively explore 3D data sets, segmenting and cutting them to reveal inner structure. While powerful, these techniques suffer from one serious flaw-the images they create are displayed on a flat piece of glass or paper. It is not really 3D-it can only be made to appear 3D. We describe the construction of 3D physical models from volumetric data. Using solid freeform fabrication equipment, these models are built as separate interlocking pieces that express in physical form the segmentation and cutting operations common in display-based visualization.\\\",\\\"Authors\\\":\\\"Nadeau, D.R.;Bailey, M.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;VisualizationTechniquesAndToolsGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885741\\\",\\\"Keywords\\\":\\\"volume visualization;scene graphs;physical models;volume graphics\\\",\\\"Keywords_Processed\\\":\\\"physical model;scene graph;volume visualization;volume graphic\\\",\\\"Title\\\":\\\"Visualizing volume data using physical models\\\"},\\\"307\\\":{\\\"Abstract\\\":\\\"We demonstrate the use of a combination of perceptually effective techniques for visualizing magnetic field data from the DIII-D Tokamak. These techniques can be implemented to run very efficiently on machines with hardware support for OpenGL. Interactive speeds facilitate clear communication of magnetic field structure, enhancing fusion scientists' understanding of their data, and thereby accelerating their research.\\\",\\\"Authors\\\":\\\"Schussman, G.;Kwan-Liu Ma;Schissel, D.;Evans, T.\\\",\\\"Clusters\\\":\\\"Illumination;InputAndOutputDevicesGeneral;InteractionTechniquesGeneral;LineBasedTechniquesAndApproaches;PhysicsAndPhysicalSciences\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885742\\\",\\\"Keywords\\\":\\\"interactive visualization;plasma physics;graphics hardware;haloed lines;illuminated lines;tokamak;magnetic field\\\",\\\"Keywords_Processed\\\":\\\"haloed line;plasma physics;graphic hardware;tokamak;magnetic field;illuminate line;interactive visualization\\\",\\\"Title\\\":\\\"Visualizing DIII-D Tokamak magnetic field lines\\\"},\\\"308\\\":{\\\"Abstract\\\":\\\"The paper describes the effective real-time visualization of the clear-up operation of a former US nuclear submarine base, located in Holy Loch, Scotland. The Whole Field Modelling System has provided an extremely accurate real-time visualization of a large number of varying parameters such as remotely operated vehicles, cranes, barges, grabs, magnets, and detailed seabed topography. The system has improved the field staffs' spatial and temporal awareness of the underwater environment and facilitated decision-making within the complex offshore working environment.\\\",\\\"Authors\\\":\\\"Chapman, P.;Wills, D.;Stevens, P.;Brookes, G.\\\",\\\"Clusters\\\":\\\"AcousticsSoundSonification;EarthSpaceAndEnvironmentalSciences;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885743\\\",\\\"Keywords\\\":\\\"sonar technology;whole field modelling;seabed visualization\\\",\\\"Keywords_Processed\\\":\\\"whole field model;sonar technology;seabed visualization\\\",\\\"Title\\\":\\\"Real-time visualization of the clear-up of a former US naval base\\\"},\\\"309\\\":{\\\"Abstract\\\":\\\"Scaling of simulations challenges the effectiveness of conventional visualization methods. This problem becomes two-fold for mesoscale weather models that operate in near-real-time at cloud-scale resolution. For example, typical approaches to vector field visualization (e.g., wind) are based upon global methods, which may not illustrate detailed structure. In addition, such computations employ multi-resolution meshes to capture small-scale phenomena, which are not properly reflected in both vector and scalar realizations. To address the former critical point analysis and simple bandpass filtering of wind fields is employed for better seed point identification of streamline calculations. For the latter, an encapsulation of nested computational meshes is developed for general realization. It is then combined with the seed point calculation for an improved vector visualization of multi-resolution weather forecasting data.\\\",\\\"Authors\\\":\\\"Treinish, L.A.\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;FlowVisualizationDataAndTechniques;MultiresolutionTechniques;VisualDesignDesignGuidelines\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2000.885745\\\",\\\"Keywords\\\":\\\"flow visualization;visualization design;meteorology;multi-resolution;weather forecasting\\\",\\\"Keywords_Processed\\\":\\\"multi resolution;meteorology;weather forecasting;visualization design;flow visualization\\\",\\\"Title\\\":\\\"Multi-resolution visualization techniques for nested weather models\\\"},\\\"310\\\":{\\\"Abstract\\\":\\\"This paper proposes a new technique to visualize dependencies among cells in a spreadsheet. In this way, the system firstly visualizes a spreadsheet on a plane in three-dimensional space, and draws arcs between interrelated cells. By allowing a user to select an arbitrary cell and lift it up with direct manipulation, the system utilizes the third dimension to ameliorate visual occlusion of crossing arcs. As the user lifts a focused cell up, the interrelated cells are lifted up together; thus hidden dataflow networks can be visually intelligible interactively. Because spreadsheets are aimed at calculation itself rather than appearances of outputs, their mechanism is relatively invisible and not obvious for ordinary users. Our visualization helps such users to understand structures and mechanism of spreadsheets\\\",\\\"Authors\\\":\\\"Shiozawa, H.;Okada, K.;Matsushita, Y.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;BiomedicalScienceAndMedicine;TabularDataAndTechniques;UserInterfacesGeneral;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1999.801861\\\",\\\"Keywords\\\":\\\"information visualization;3d user interfaces;inter-cell dependencies;lifting-up operation;spreadsheets;natto view\\\",\\\"Keywords_Processed\\\":\\\"lift up operation;information visualization;spreadsheet;natto view;inter cell dependency;3d user interface\\\",\\\"Title\\\":\\\"3D interactive visualization for inter-cell dependencies of spreadsheets\\\"},\\\"311\\\":{\\\"Abstract\\\":\\\"This paper aims to give a systematic account of focus+context visualization techniques, i.e. visualizations which aim to give users integrated visual access to details and context in a data set. We introduce the notion that there are different orders of information visualization with focus+context being a second-order visualization and provide a formal framework for describing and constructing focus+context visualizations\\\",\\\"Authors\\\":\\\"Bjork, S.;Holmquist, L.E.;Redstrom, J.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;NumericalMethodsMathematics;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1999.801857\\\",\\\"Keywords\\\":\\\"information visualization;fisheye view;theory;focus+context visualization;formal methods\\\",\\\"Keywords_Processed\\\":\\\"fisheye view;information visualization;formal method;focus context visualization;theory\\\",\\\"Title\\\":\\\"A framework for focus+context visualization\\\"},\\\"312\\\":{\\\"Abstract\\\":\\\"We have developed a technique, Aggregate Towers, that allows geospatial data to be visualized across a range of map scales. We use a combination of data aggregation algorithms and dynamically aggregating data markers (e.g., icons or symbols) to accommodate interactive zooming by a user while maintaining a representation that remains intuitive, consistent across multiple scales and uncluttered. This approach implicitly generates multiple levels of overview displays from a single set of underlying data\\\",\\\"Authors\\\":\\\"Rayson, J.K.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;GeographyGeospatialVisCartographyTerrainVis;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1999.801863\\\",\\\"Keywords\\\":\\\"information visualization;aggregation;zooming;visualization;cartography\\\",\\\"Keywords_Processed\\\":\\\"visualization;zooming;aggregation;information visualization;cartography\\\",\\\"Title\\\":\\\"Aggregate Towers: scale sensitive visualization and decluttering of geospatial data\\\"},\\\"313\\\":{\\\"Abstract\\\":\\\"A new method is presented for the visualization of hierarchical information, such as directory structures and organization structures. Cushion treemaps inherit the elegance of standard treemaps: compact, space-filling displays of hierarchical information, based on recursive subdivision of a rectangular image space. Intuitive shading is used to provide insight in the hierarchical structure. During the subdivision, ridges are added per rectangle, which are rendered with a simple shading model. The result is a surface that consists of recursive cushions. The method is efficient, effective, easy to use and implement, and has a wide applicability\\\",\\\"Authors\\\":\\\"van Wijk, J.J.;van de Wetering, H.\\\",\\\"Clusters\\\":\\\"HierarchicalTreeDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1999.801860\\\",\\\"Keywords\\\":\\\"information visualization;tree visualization;treemap\\\",\\\"Keywords_Processed\\\":\\\"tree visualization;information visualization;treemap\\\",\\\"Title\\\":\\\"Cushion treemaps: visualization of hierarchical information\\\"},\\\"314\\\":{\\\"Abstract\\\":\\\"We examine how animating a viewpoint change in a spatial information system affects a user's ability to build a mental map of the information in the space. We found that animation improves users' ability to reconstruct the information space, with no penalty on task performance time. We believe that this study provides strong evidence for adding animated transitions in many applications with fixed spatial data where the user navigates around the data space\\\",\\\"Authors\\\":\\\"Bederson, B.B.;Boltman, A.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;EvaluationGeneral;RealtimeProcessingRenderingAndVisualizationGeneral;UserInterfacesGeneral;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1999.801854\\\",\\\"Keywords\\\":\\\"multi-scale interfaces;pad++;realtime computer graphics;animation;evaluation;zoomable user interface\\\",\\\"Keywords_Processed\\\":\\\"animation;pad;multi scale interface;zoomable user interface;realtime computer graphic;evaluation\\\",\\\"Title\\\":\\\"Does animation help users build mental maps of spatial information?\\\"},\\\"315\\\":{\\\"Abstract\\\":\\\"Domain Analysis for Data Visualization (DADV) is a technique to use when investigating a domain where data visualizations are going to be designed and added to existing software systems. DADV was used to design the data visualization in VisEIO-LCA, which is a framework to visualize environmental data about products. Most of the visualizations are designed using the following stages: formatting data in tables, selecting visual structures, and rendering the data on the screen. Although many visualization authors perform implicit domain analysis, in this paper domain analysis is added explicitly to the process of designing visualizations with the goal of producing move usable software tools. Environmental Life-Cycle Assessment (LCA) is used as a test bed for this technique\\\",\\\"Authors\\\":\\\"Espinosa, O.J.;Hendrickson, C.;Garrett, J.H.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;BusinessFinanceEconomyManufacturing;HumanComputerInteractionHumanFactors;TasksTaskRequirementsAnalysis;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1999.801856\\\",\\\"Keywords\\\":\\\"domain analysis;computer-human interaction;user tasks;life-cycle assessment;visualization framework;economic input-output\\\",\\\"Keywords_Processed\\\":\\\"visualization framework;user task;computer human interaction;economic input output;life cycle assessment;domain analysis\\\",\\\"Title\\\":\\\"Domain analysis: a technique to design a user-centered visualization framework\\\"},\\\"316\\\":{\\\"Abstract\\\":\\\"Dynamic queries offer continuous feedback during range queries, and have been shown to be effective and satisfying. Recent work has extended them to datasets of 100,000 objects and, separately, to queries involving relations among multiple objects. The latter work enables filtering houses by properties of their owners, for instance. Our primary concern is providing feedback from histograms during dynamic query. The height of each histogram bar shows the count of selected objects whose attribute value falls into a given range. Unfortunately, previous efficient algorithms for single object queries overcount in the case of multiple objects if for instance, a house has multiple owners. This paper presents an efficient algorithm that with high probability closely approximates the true counts\\\",\\\"Authors\\\":\\\"Derthick, M.;Harrison, J.;Moore, A.;Roth, S.F.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;ProgrammingAlgorithmsAndDataStructures;QueriesAndSearch\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1999.801862\\\",\\\"Keywords\\\":\\\"dynamic query;database;probabilistic algorithms\\\",\\\"Keywords_Processed\\\":\\\"dynamic query;probabilistic algorithm;database\\\",\\\"Title\\\":\\\"Efficient multi-object dynamic query histograms\\\"},\\\"317\\\":{\\\"Abstract\\\":\\\"Interactive selection is a critical component in exploratory visualization, allowing users to isolate subsets of the displayed information for highlighting, deleting, analysis, or focussed investigation. Brushing, a popular method for implementing the selection process, has traditionally been performed in either screen space or data space. We introduce the concept of a structure-based brush, which can be used to perform selection in hierarchically structured data sets. Our structure-based brush allows users to navigate hierarchies by specifying focal extents and level-of-detail on a visual representation of the structure. Proximity-based coloring, which maps similar colors to data that are closely related within the structure, helps convey both structural relationships and anomalies. We describe the design and implementation of our structure-based brushing tool. We also validate its usefulness using two distinct hierarchical visualization techniques, namely hierarchical parallel coordinates and tree-maps\\\",\\\"Authors\\\":\\\"Ying-Huey Fua;Ward, M.O.;Rundensteiner, E.A.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;HierarchicalTreeDataAndTechniques;InteractionTechniquesGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1999.801858\\\",\\\"Keywords\\\":\\\"exploratory data analysis;brushing;hierarchical representation;interactive selection\\\",\\\"Keywords_Processed\\\":\\\"hierarchical representation;brush;exploratory datum analysis;interactive selection\\\",\\\"Title\\\":\\\"Navigating hierarchies with structure-based brushes\\\"},\\\"318\\\":{\\\"Abstract\\\":\\\"In the process of knowledge discovery, workers examine available information in order to make sense of it. By sensemaking, we mean interacting with and operating on the information with a variety of information processing mechanisms. Previously, we introduced a concept that uses the spreadsheet metaphor with cells containing visualizations of complex data. We extend and apply a cognitive model called visual sensemaking to the visualization spreadsheet. We use the task of making sense of a large Web site as a concrete example throughout the paper for demonstration. Using a variety of visualization techniques, such as the Disk Tree and Cone Tree, we show that the interactions of the visualization spreadsheet help users draw conclusions from the overall relationships of the entire information set\\\",\\\"Authors\\\":\\\"Chi, E.H.;Card, S.K.\\\",\\\"Clusters\\\":\\\"Cognition;EvaluationGeneral;InternetWebVisualizationForTheMasses;SocialScienceAndHumanities;TabularDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1999.801853\\\",\\\"Keywords\\\":\\\"information visualization;spreadsheets;log file analysis;sensemaking;information ecologies;world wide web\\\",\\\"Keywords_Processed\\\":\\\"information ecology;world wide web;sensemake;information visualization;log file analysis;spreadsheet\\\",\\\"Title\\\":\\\"Sensemaking of evolving Web sites using visualization spreadsheets\\\"},\\\"319\\\":{\\\"Abstract\\\":\\\"This paper introduces the Sunflower visual metaphor for information visualization. The visual metaphor is presented as an alternative to current techniques of dimensional compression and the visualization tools that employ them. The paper discusses the motivation for the Sunflower paradigm, its implementation and critical factors for producing an effective visualization. A primary driver in this research effort has been to develop a visualization tool that facilitates browsing, knowledge discovery, and that supports learning through sense making and integration of new information\\\",\\\"Authors\\\":\\\"Rose, S.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;TextDocumentTopicAnalysisDataAndTechniques;VisualKnowledgeRepresentationAndExternalization\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1999.801868\\\",\\\"Keywords\\\":\\\"information visualization;information retrieval;knowledge management;text visualization;visualization\\\",\\\"Keywords_Processed\\\":\\\"visualization;text visualization;information retrieval;information visualization;knowledge management\\\",\\\"Title\\\":\\\"The sunflower visual metaphor, a new paradigm for dimensional compression\\\"},\\\"320\\\":{\\\"Abstract\\\":\\\"VisageWeb is an information-centric user interface to the World Wide Web built within the Visage data visualization environment. This paper traces the development of the VisageWeb project, using it to motivate an exploration of how an information-centric architecture copes with new visualization challenges. We conclude with a presentation of the VisageWeb prototype itself\\\",\\\"Authors\\\":\\\"Higgins, M.;Lucas, P.;Sean, J.\\\",\\\"Clusters\\\":\\\"InternetWebVisualizationForTheMasses;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1999.801864\\\",\\\"Keywords\\\":\\\"information visualization;user interface;world wide web\\\",\\\"Keywords_Processed\\\":\\\"world wide web;information visualization;user interface\\\",\\\"Title\\\":\\\"VisageWeb: visualizing WWW data in Visage\\\"},\\\"321\\\":{\\\"Abstract\\\":\\\"The advent of superscalar processors with out-of-order execution makes it increasingly difficult to determine how well an application is utilizing the processor and how to adapt the application to improve its performance. We describe a visualization system for the analysis of application behavior on superscalar processors. Our system provides an overview-plus-detail display of the application's execution. A timeline view of pipeline performance data shows the overall utilization of the pipeline. This information is displayed using multiple time scales, enabling the user to drill down from a high-level application overview to a focus region of hundreds of cycles. This region of interest is displayed in detail using an animated cycle-by-cycle view of the execution. This view shows how instructions are reordered and executed and how functional units are being utilized. Additional context views correlate instuctions in this detailed view with the relevant source code for the application. This allows the user to discover the root cause of the poor pipeline utilization and make changes to the application to improve its performance. This visualization system can be easily configured to display a variety of processor models and configurations. We demonstrate it for both the MXS and MMIX processor models\\\",\\\"Authors\\\":\\\"Stolte, C.;Bosche, R.;Hanrahan, P.;Rosenblum, M.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;HardwareAccellerationAndComputationGeneral;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1999.801852\\\",\\\"Keywords\\\":\\\"superscalar processors;computer systems visualization;visualization systems\\\",\\\"Keywords_Processed\\\":\\\"superscalar processor;computer system visualization;visualization system\\\",\\\"Title\\\":\\\"Visualizing application behavior on superscalar processors\\\"},\\\"322\\\":{\\\"Abstract\\\":\\\"Presents a method for the hierarchical representation of vector fields. Our approach is based on iterative refinement using clustering and principal component analysis. The input to our algorithm is a discrete set of points with associated vectors. The algorithm generates a top-down segmentation of the discrete field by splitting clusters of points. We measure the error of the various approximation levels by measuring the discrepancy between streamlines generated by the original discrete field and its approximations based on much smaller discrete data sets. Our method assumes no particular structure of the field, nor does it require any topological connectivity information. It is possible to generate multi-resolution representations of vector fields using this approach.\\\",\\\"Authors\\\":\\\"Heckel, B.;Weber, G.H.;Hamann, B.;Joy, K.I.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;MachineLearningAndStatistics;ProgrammingAlgorithmsAndDataStructures;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809863\\\",\\\"Keywords\\\":\\\"binary space partitioning;hardy's multiquadric method;data simplification;vector field visualization\\\",\\\"Keywords_Processed\\\":\\\"binary space partitioning;datum simplification;vector field visualization;hardy multiquadric method\\\",\\\"Title\\\":\\\"Construction of vector field hierarchies\\\"},\\\"323\\\":{\\\"Abstract\\\":\\\"Presents a system designed for the interactive definition and visualization of fields derived from large data sets: the Demand-Driven Visualizer (DDV). The system allows the user to write arbitrary expressions to define new fields, and then apply a variety of visualization techniques to the result. Expressions can include differential operators and numerous other built-in functions. Determination of field values, both in space and in time, is directed automatically by the demands of the visualization techniques. The payoff of following a demand-driven design philosophy throughout the visualization system becomes particularly evident when working with large time-series data, where the costs of eager evaluation alternatives can be prohibitive.\\\",\\\"Authors\\\":\\\"Moran, P.J.;Henze, C.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;InteractionTechniquesGeneral;LargeScaleDataAndScalability;ProgrammingAlgorithmsAndDataStructures;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809864\\\",\\\"Keywords\\\":\\\"interpreted systems;interactive visualization;lazy evaluation;scientific visualization;demand-driven evaluation;python;large-scale visualization\\\",\\\"Keywords_Processed\\\":\\\"python;large scale visualization;interpret system;lazy evaluation;scientific visualization;interactive visualization;demand drive evaluation\\\",\\\"Title\\\":\\\"Large field visualization with demand-driven calculation\\\"},\\\"324\\\":{\\\"Abstract\\\":\\\"Vector field visualization remains a difficult task. Many local and global visualization methods for vector fields such as flow data exist, but they usually require extensive user experience on setting the visualization parameters in order to produce images communicating the desired insight. We present a visualization method that produces simplified but suggestive images of the vector field automatically, based on a hierarchical clustering of the input data. The resulting clusters are then visualized with straight or curved arrow icons. The presented method has a few parameters with which users can produce various simplified vector field visualizations that communicate different insights on the vector data.\\\",\\\"Authors\\\":\\\"Telea, A.;van Wijk, J.J.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;DataClusteringAndAggregation;FlowVisualizationDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809865\\\",\\\"Keywords\\\":\\\"flow visualization;simplification;clustering\\\",\\\"Keywords_Processed\\\":\\\"simplification;clustering;flow visualization\\\",\\\"Title\\\":\\\"Simplified representation of vector fields\\\"},\\\"325\\\":{\\\"Abstract\\\":\\\"Our ability to accumulate large, complex (multivariate) data sets has far exceeded our ability to effectively process them in searching for patterns, anomalies and other interesting features. Conventional multivariate visualization techniques generally do not scale well with respect to the size of the data set. The focus of this paper is on the interactive visualization of large multivariate data sets based on a number of novel extensions to the parallel coordinates display technique. We develop a multi-resolution view of the data via hierarchical clustering, and use a variation of parallel coordinates to convey aggregation information for the resulting clusters. Users can then navigate the resulting structure until the desired focus region and level of detail is reached, using our suite of navigational and filtering tools. We describe the design and implementation of our hierarchical parallel coordinates system which is based on extending the XmdvTool system. Lastly, we show examples of the tools and techniques applied to large (hundreds of thousands of records) multivariate data sets.\\\",\\\"Authors\\\":\\\"Ying-Huey Fua;Ward, M.O.;Rundensteiner, E.A.\\\",\\\"Clusters\\\":\\\"HierarchicalTreeDataAndTechniques;LargeScaleDataAndScalability;ParallelCoordinates\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809866\\\",\\\"Keywords\\\":\\\"hierarchical data exploration;large-scale multivariate visualization;parallel coordinates\\\",\\\"Keywords_Processed\\\":\\\"hierarchical datum exploration;parallel coordinate;large scale multivariate visualization\\\",\\\"Title\\\":\\\"Hierarchical parallel coordinates for exploration of large datasets\\\"},\\\"326\\\":{\\\"Abstract\\\":\\\"Complex triangle meshes arise naturally in many areas of computer graphics and visualization. Previous work has shown that a quadric error metric allows fast and accurate geometric simplification of meshes. This quadric approach was recently generalized to handle meshes with appearance attributes. In this paper we present an improved quadric error metric for simplifying meshes with attributes. The new metric, based on geometric correspondence in 3D, requires less storage, evaluates more quickly, and results in more accurate simplified meshes. Meshes often have attribute discontinuities, such as surface creases and material boundaries, which require multiple attribute vectors per vertex. We show that a wedge-based mesh data structure captures such discontinuities efficiently and permits simultaneous optimization of these multiple attribute vectors. In addition to the new quadric metric, we experiment with two techniques proposed in geometric simplification, memoryless simplification and volume preservation, and show that both of these are beneficial within the quadric framework. The new scheme is demonstrated on a variety of meshes with colors and normals.\\\",\\\"Authors\\\":\\\"Hoppe, H.\\\",\\\"Clusters\\\":\\\"LevelOfDetail;MeshesGridsAndLattices;MultiresolutionTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809869\\\",\\\"Keywords\\\":\\\"multi-resolution;level-of-detail;mesh decimation\\\",\\\"Keywords_Processed\\\":\\\"mesh decimation;multi resolution;level of detail\\\",\\\"Title\\\":\\\"New quadric metric for simplifying meshes with appearance attributes\\\"},\\\"327\\\":{\\\"Abstract\\\":\\\"In this paper we present a mesh compression method based on a multiresolution decomposition whose detail coefficients have a compact representation and thus smaller entropy than the original mesh. Given an arbitrary triangular mesh with an irregular connectivity, we use a hierarchical simplification scheme, which generates a multiresolution model. By reversing the process we define a hierarchical progressive refinement process, where a simple prediction plus a correction is used for inserting vertices to form a finer level. We show how the connectivity of an arbitrary triangulation can be encoded efficiently by a coloring technique, and recovered incrementally during the progressive reconstruction of the original mesh.\\\",\\\"Authors\\\":\\\"Cohen-Or, D.;Levin, D.;Remez, O.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;CompressionTechniques;MeshesGridsAndLattices;StreamingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VIS.1999.10000\\\",\\\"Keywords\\\":\\\"compression;simplification;streaming;progressive meshes\\\",\\\"Keywords_Processed\\\":\\\"stream;progressive mesh;simplification;compression\\\",\\\"Title\\\":\\\"Progressive Compression of Arbitrary Triangular Meshes\\\"},\\\"328\\\":{\\\"Abstract\\\":\\\"We present a method for compressing non-manifold polygonal meshes, i.e. polygonal meshes with singularities, which occur very frequently in the real-world. Most efficient polygonal compression methods currently available are restricted to a manifold mesh: they require a conversion process, and fail to retrieve the original model connectivity after decompression. The present method works by converting the original model to a manifold model, encoding the manifold model using an existing mesh compression technique, and clustering, or stitching together during the decompression process vertices that were duplicated earlier to faithfully recover the original connectivity. This paper focuses on efficiently encoding and decoding the stitching information. By separating connectivity from geometry and properties, the method avoids encoding vertices (and properties bound to vertices) multiple times; thus a reduction of the size of the bit-stream of about 10% is obtained compared with encoding the model as a manifold.\\\",\\\"Authors\\\":\\\"Gueziec, A.;Bossen, F.;Taubin, G.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;GeometricModeling;MeshesGridsAndLattices;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809870\\\",\\\"Keywords\\\":\\\"stitching;geometry compression;non-manifold;polygonal meshes\\\",\\\"Keywords_Processed\\\":\\\"geometry compression;non manifold;polygonal mesh;stitch\\\",\\\"Title\\\":\\\"Efficient compression of non-manifold polygonal meshes\\\"},\\\"329\\\":{\\\"Abstract\\\":\\\"For types of data visualization where the cost of producing images is high, and the relationship between the rendering parameters and the image produced is less than obvious, a visual representation of the exploration process can make the process more efficient and effective. Image graphs represent not only the results but also the process of data visualization. Each node in an image graph consists of an image and the corresponding visualization parameters used to produce it. Each edge in a graph shows the change in rendering parameters between the two nodes it connects. Image graphs are not just static representations; users can interact with a graph to review a previous visualization session or to perform new rendering. Operations which cause changes in rendering parameters can propagate through the graph. The user can take advantage of the information in image graphs to understand how certain parameter changes affect visualization results. Users can also share image graphs to streamline the process of collaborative visualization. We have implemented a volume visualization system using the image graph interface, and the examples presented come from this application.\\\",\\\"Authors\\\":\\\"Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\";VisualKnowledgeRepresentationAndExternalization;VisualizationSystemsToolkitsAndEnvironments;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809871\\\",\\\"Keywords\\\":\\\"scientific visualization;knowledge representation;volume rendering;visualization systems\\\",\\\"Keywords_Processed\\\":\\\"scientific visualization;knowledge representation;volume render;visualization system\\\",\\\"Title\\\":\\\"Image graphs-a novel approach to visual data exploration\\\"},\\\"330\\\":{\\\"Abstract\\\":\\\"We present a novel forward image mapping algorithm, which speeds up perspective warping, as in texture mapping. It processes the source image in a special scanline order instead of the normal raster scanline order. This special scanline has the property of preserving parallelism when projecting to the target image. The algorithm reduces the complexity of perspective-correct image warping by eliminating the division per pixel and replacing it with a division per scanline. The method also corrects the perspective distortion in Gouraud shading with negligible overhead. Furthermore, the special scanline order is suitable for antialiasing using a more accurate antialiasing conic filter, with minimum additional cost. The algorithm is highlighted by incremental calculations and optimized memory bandwidth by reading each source pixel only once, suggesting a potential hardware implementation.\\\",\\\"Authors\\\":\\\"Chen, B.;Dachille, F.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;FilteringTechniques;ImageBasedDataImageSignalProcessing;InputAndOutputDevicesGeneral;Rendering;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809872\\\",\\\"Keywords\\\":\\\"texture mapping;image warping;forward mapping;antialiasing;anisotropic filtering;hardware;gouraud shading\\\",\\\"Keywords_Processed\\\":\\\"gouraud shade;antialiase;hardware;forward mapping;anisotropic filtering;texture mapping;image warp\\\",\\\"Title\\\":\\\"Forward image mapping\\\"},\\\"331\\\":{\\\"Abstract\\\":\\\"Often, images or datasets have to be compared to facilitate choices of visualization and simulation parameters respectively. Common comparison techniques include side-by-side viewing and juxtaposition, in order to facilitate visual verification of verisimilitude. We propose quantitative techniques which accentuate differences in images and datasets. The comparison is enabled through a collection of partial metrics which, essentially, measure the lack of correlation between the datasets or images being compared. That is, they attempt to expose and measure the extent of the inherent structures in the difference between images or datasets. Besides yielding numerical attributes, the metrics also produce images which can visually highlight differences. Our metrics are simple to compute and operate in the spatial domain. We demonstrate the effectiveness of our metrics through examples for comparing images and datasets.\\\",\\\"Authors\\\":\\\"Sahasrabudhe, N.;West, J.E.;Machiraju, R.;Janus, M.\\\",\\\"Clusters\\\":\\\"DataAndAnalysisMetrics;EvaluationMetricsAndBenchmarks;InteractionTechniquesGeneral;Rendering\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809873\\\",\\\"Keywords\\\":\\\"steering;rendering;metrics;correlation measure\\\",\\\"Keywords_Processed\\\":\\\"render;steer;metric;correlation measure\\\",\\\"Title\\\":\\\"Structured spatial domain image and data comparison metrics\\\"},\\\"332\\\":{\\\"Abstract\\\":\\\"We present a technique for optimizing the rendering of high-depth complexity scenes. Prioritized-Layered Projection (PLP) does this by rendering an estimation of the visible set. The novelty in our work lies in the fact that we do not explicitly compute visible sets. Instead, our work is based on computing on demand a priority order for the polygons that maximizes the likelihood of rendering visible polygons before occluded ones for any given scene. Given a fixed budget, e.g. time or number of triangles, our rendering algorithm makes sure to render geometry, respecting the computed priority. There are two main steps to our technique: (1) an occupancy based tessellation of space; and (2) a solidity based traversal algorithm. PLP works by computing an occupancy based tessellation of space, which tends to have smaller cells where there are more geometric primitives, e.g., polygons. In this spatial tessellation, each cell is assigned a solidity value, which is directly proportional to its likelihood of occluding other cells. In its simplest form, a cell's solidity value is directly proportional to the number of polygons contained within it. During our traversal algorithm, cells are marked for projection, and the geometric primitives contained within them actually rendered. The traversal algorithm makes use of the cells' solidity, and other view-dependent information to determine the ordering in which to project cells. By tailoring the traversal algorithm to the occupancy based tessellation, we can achieve very good frame rates with low preprocessing and rendering costs. We describe our technique and its implementation in detail. We also provide experimental evidence of its performance and briefly discuss extensions of our algorithm.\\\",\\\"Authors\\\":\\\"Klosowski, J.T.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"OcclusionProblemsTechniques;Rendering\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809875\\\",\\\"Keywords\\\":\\\"occlusion culling;polygon rendering;visibility ordering\\\",\\\"Keywords_Processed\\\":\\\"visibility ordering;occlusion cull;polygon render\\\",\\\"Title\\\":\\\"Rendering on a budget: a framework for time-critical rendering\\\"},\\\"333\\\":{\\\"Abstract\\\":\\\"We describe a framework for time-critical rendering of graphics scenes composed of a large number of objects having complex geometric descriptions. Our technique relies upon a scene description in which objects are represented as multiresolution meshes. We perform a constrained optimization at each frame to choose the resolution of each potentially visible object that generates the best quality image while meeting timing constraints. The technique provides smooth level-of-detail control and aims at guaranteeing a uniform, bounded frame rate even for widely changing viewing conditions. The optimization algorithm is independent from the particular data structure used to represent multiresolution meshes. The only requirements are the ability to represent a mesh with an arbitrary number of triangles and to traverse a mesh structure at an arbitrary resolution in a short predictable time. A data structure satisfying these criteria is described and experimental results are discussed.\\\",\\\"Authors\\\":\\\"Gobbetti, E.;Bouvier, E.\\\",\\\"Clusters\\\":\\\"LevelOfDetail;MultiresolutionTechniques;Rendering;TimeCriticalApplications\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809876\\\",\\\"Keywords\\\":\\\"adaptive rendering;level-of-detail;time-critical graphics;multi-resolution modeling\\\",\\\"Keywords_Processed\\\":\\\"multi resolution modeling;adaptive rendering;time critical graphic;level of detail\\\",\\\"Title\\\":\\\"Time-critical Multiresolution Scene Rendering\\\"},\\\"334\\\":{\\\"Abstract\\\":\\\"The reconstruction of isosurfaces from scalar volume data has positioned itself as a fundamental visualization technique in many different applications. But the dramatically increasing size of volumetric data sets often prohibits the handling of these models on affordable low-end single processor architectures. Distributed client-server systems integrating high-bandwidth transmission channels and Web based visualization tools are one alternative to attack this particular problem, but therefore new approaches to reduce the load of numerical processing and the number of generated primitives are required. We outline different scenarios for distributed isosurface reconstruction from large scale volumetric data sets. We demonstrate how to directly generate stripped surface representations and we introduce adaptive and hierarchical concepts to minimize the number of vertices that have to be reconstructed, transmitted and rendered. Furthermore, we propose a novel computation scheme, which allows the user to flexibly exploit locally available resources. The proposed algorithms have been merged together in order to build a platform-independent Web based application. Extensive use of VRML and Java OpenGL bindings allows for the exploration of large scale volume data quite efficiently.\\\",\\\"Authors\\\":\\\"Engel, K.;Westermann, R.;Ertl, T.\\\",\\\"Clusters\\\":\\\"DistributedSystemsAndGridEnvironments;InternetWebVisualizationForTheMasses;IsosurfaceAndSurfaceExtractionTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809878\\\",\\\"Keywords\\\":\\\"distributed systems;volume visualization;isosurface reconstruction;web-based applications\\\",\\\"Keywords_Processed\\\":\\\"web base application;volume visualization;distribute system;isosurface reconstruction\\\",\\\"Title\\\":\\\"Isosurface extraction techniques for Web-based volume visualization\\\"},\\\"335\\\":{\\\"Abstract\\\":\\\"The Temporal Branch-on-Need Tree (T-BON) extends the three dimensional branch-on-need octree for time-varying isosurface extraction. At each time step, only those portions of the tree and data necessary to construct the current isosurface are read from disk. This algorithm can thus exploit the temporal locality of the isosurface and, as a geometric technique, spatial locality between cells in order to improve performance. Experimental results demonstrate the performance gained and memory overhead saved using this technique.\\\",\\\"Authors\\\":\\\"Sutton, P.;Hansen, C.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;MultiresolutionTechniques;ProgrammingAlgorithmsAndDataStructures;ScalarFieldDataTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809879\\\",\\\"Keywords\\\":\\\"isosurface;time-dependent scalar field visualization;octree;multi-resolution method\\\",\\\"Keywords_Processed\\\":\\\"octree;multi resolution method;isosurface;time dependent scalar field visualization\\\",\\\"Title\\\":\\\"Isosurface extraction in time-varying fields using a Temporal Branch-on-Need Tree (T-BON)\\\"},\\\"336\\\":{\\\"Abstract\\\":\\\"The paper describes new techniques for minimally immersive visualization of 3D scalar and vector fields, and visualization of document corpora. In our glyph based visualization system, the user interacts with the 3D volume of glyphs using a pair of button-enhanced 3D position and orientation trackers. The user may also examine the volume using an interactive lens, which is a rectangle that slices through the 3D volume and displays scalar information on its surface. A lens allows the display of scalar data in the 3D volume using a contour diagram, and a texture based volume rendering.\\\",\\\"Authors\\\":\\\"Shaw, C.;Hall, J.A.;Ebert, D.S.;Roberts, D.A.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;ContourCreasesRidgesValleys;DataRegistrationFusionAndIntegration;DisplaysGeneral;GlyphsGlyphBasedTechniques;InteractionTechniquesGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809882\\\",\\\"Keywords\\\":\\\"glyph;contour diagrams;seed fill;interactive volume rendering;volumetric data;stereoscopic field analyzer sfa;two-handed interfaces;over blending\\\",\\\"Keywords_Processed\\\":\\\"contour diagram;interactive volume render;over blend;stereoscopic field analyzer sfa;two handed interface;volumetric datum;glyph;seed fill\\\",\\\"Title\\\":\\\"Interactive lens visualization techniques\\\"},\\\"337\\\":{\\\"Abstract\\\":\\\"Conventional projector-based display systems are typically designed around precise and regular configurations of projectors and display surfaces. While this results in rendering simplicity and speed, it also means painstaking construction and ongoing maintenance. In previously published work, we introduced a vision of projector-based displays constructed from a collection of casually-arranged projectors and display surfaces. In this paper, we present flexible yet practical methods for realizing this vision, enabling low-cost mega-pixel display systems with large physical dimensions, higher resolution, or both. The techniques afford new opportunities to build personal 3D visualization systems in offices, conference rooms, theaters, or even your living room. As a demonstration of the simplicity and effectiveness of the methods that we continue to perfect, we show in the included video that a 10-year old child can construct and calibrate a two-camera, two-projector, head-tracked display system, all in about 15 minutes.\\\",\\\"Authors\\\":\\\"Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.\\\",\\\"Clusters\\\":\\\"DataRegistrationFusionAndIntegration;DimensionalityReduction;DisplaysGeneral;ImageBasedDataImageSignalProcessing;ImmersiveAndVirtualEnvironments;LargeAndHighResDisplays;Perception;Rendering\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809883\\\",\\\"Keywords\\\":\\\"virtual environment;panoramic image display;camera-based registration;display;auto-calibration;intensity blending;projection;image-based modeling;structured light;spatially immersive display;calibration;depth\\\",\\\"Keywords_Processed\\\":\\\"virtual environment;depth;structured light;display;spatially immersive display;intensity blending;panoramic image display;auto calibration;calibration;camera base registration;image base modeling;projection\\\",\\\"Title\\\":\\\"Multi-projector displays using camera-based registration\\\"},\\\"338\\\":{\\\"Abstract\\\":\\\"We present an algorithm which renders opaque and/or translucent polygons embedded within volumetric data. The processing occurs such that all objects are composited in the correct order, by rendering thin slabs of the translucent polygons between volume slices using slice-order volume rendering. We implemented our algorithm with OpenGL on current general-purpose graphics systems. We discuss our system implementation, speed and image quality, as well as the renderings of several mixed scenes.\\\",\\\"Authors\\\":\\\"Kreeger, K.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"OcclusionProblemsTechniques;RaytracingRaycasting;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809887\\\",\\\"Keywords\\\":\\\"volume rendering;voxelization;mixing polygons and volumes;raycasting;translucent polygon rendering\\\",\\\"Keywords_Processed\\\":\\\"volume render;mix polygon and volume;voxelization;translucent polygon render;raycaste\\\",\\\"Title\\\":\\\"Mixing translucent polygons with volumes\\\"},\\\"339\\\":{\\\"Abstract\\\":\\\"We present a new technique which enables direct volume rendering based on 3D texture mapping hardware, enabling shading as well as classification of the interpolated data. Our technique supports accurate lighting for a one directional light source, semi-transparent classification, and correct blending. To circumvent the limitations of one general classification, we introduce multiple classification spaces which are very valuable to understand the visualized data, and even mandatory to comprehensively grasp the 3D relationship of different materials present in the volumetric data. Furthermore, we illustrate how multiple classification spaces can be realized using existing graphics hardware. In contrast to previously reported algorithms, our technique is capable of performing all the above mentioned tasks within the graphics pipeline. Therefore, it is very efficient: The three dimensional texture needs to be stored only once and no load is put onto the CPU. Besides using standard OpenGL functionality, we exploit advanced per pixel operations and make use of available OpenGL extensions.\\\",\\\"Authors\\\":\\\"Meissner, M.;Hoffmann, U.;Strasser, W.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;MeshesGridsAndLattices;Rendering;SegmentationAndClassification;Textures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809889\\\",\\\"Keywords\\\":\\\"shading;volume rendering;classification;rectilinear grid;opengl;3d texture mapping\\\",\\\"Keywords_Processed\\\":\\\"rectilinear grid;volume render;3d texture mapping;shade;classification;opengl\\\",\\\"Title\\\":\\\"Enabling Classification and Shading for 3D Texture Mapping based Volume Rendering using OpenGL and Extensions\\\"},\\\"340\\\":{\\\"Abstract\\\":\\\"Line integral convolution (LIC) is an effective technique for visualizing vector fields. The application of LIC to 3D flow fields has yet been limited by difficulties to efficiently display and animate the resulting 3D-images. Texture-based volume rendering allows interactive visualization and manipulation of 3D-LIC textures. In order to ensure the comprehensive and convenient exploration of flow fields, we suggest interactive functionality including transfer functions and different clipping mechanisms. Thereby, we efficiently substitute the calculation of LIC based on sparse noise textures and show the convenient visual access of interior structures. Further on, we introduce two approaches for animating static 3D-flow fields without the computational expense and the immense memory requirements for pre-computed 3D-textures and without loss of interactivity. This is achieved by using a single 3D-LIC texture and a set of time surfaces as clipping geometries. In our first approach we use the clipping geometry to pre-compute a special 3D-LIC texture that can be animated by time-dependent color tables. Our second approach uses time volumes to actually clip the 3D-LIC volume interactively during rasterization. Additionally, several examples demonstrate the value of our strategy in practice.\\\",\\\"Authors\\\":\\\"Rezk-Salama, C.;Hastreiter, P.;Teitzel, C.;Ertl, T.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;FlowVisualizationDataAndTechniques;Textures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809892\\\",\\\"Keywords\\\":\\\"flow visualization;animated lic;direct volume rendering;3d texture mapping;interactive volume exploration\\\",\\\"Keywords_Processed\\\":\\\"3d texture mapping;animate lic;direct volume render;interactive volume exploration;flow visualization\\\",\\\"Title\\\":\\\"Interactive exploration of volume line integral convolution based on 3D-texture mapping\\\"},\\\"341\\\":{\\\"Abstract\\\":\\\"We approach the problem of exploring a virtual space by exploiting positional and camera-model constraints on navigation to provide extra assistance that focuses the user's explorational wanderings on the task objectives. Our specific design incorporates not only task-based constraints on the viewer's location, gaze, and viewing parameters, but also a personal \\\\\\\"glide\\\\\\\" that serves two important functions: keeping the user oriented in the navigation space, and \\\\\\\"pointing\\\\\\\" to interesting subject areas as they are approached. The guide's cues may be ignored by continuing in motion, but if the user stops, the gaze shifts automatically toward whatever the guide was interested in. This design has the serendipitous feature that it automatically incorporates a nested collaborative paradigm simply by allowing any given viewer to be seen as the \\\\\\\"guide\\\\\\\" of one or more viewers following behind; the leading automated guide (we tend to select a guide dog for this avatar) can remind the leading live human guide of interesting sites to point out, while each real human collaborator down the chain has some choices about whether to follow the local leader's hints. We have chosen VRML as our initial development medium primarily because of its portability, and we have implemented a variety of natural modes for leading and collaborating, including ways for collaborators to attach to and detach from a particular leader.\\\",\\\"Authors\\\":\\\"Wernert, E.A.;Hanson, A.J.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;AnimationAndMotion;CollaborativeVisualization;ImmersiveAndVirtualEnvironments;ProgrammingAlgorithmsAndDataStructures;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809893\\\",\\\"Keywords\\\":\\\"navigation;virtual reality;exploration;collaboration;wayfinding;locomotion;vrml\\\",\\\"Keywords_Processed\\\":\\\"navigation;collaboration;wayfinde;exploration;vrml;locomotion;virtual reality\\\",\\\"Title\\\":\\\"A framework for assisted exploration with collaboration\\\"},\\\"342\\\":{\\\"Abstract\\\":\\\"We present a method for visualizing three dimensional vector fields which are defined on a two dimensional manifold only. These vector fields do exist in real application, as we show by an example of an optical measuring instrument which can gauge the displacement at the surface of a mechanical part. The general idea is to compute LIC textures in the manifold's tangent space and to deform the manifold according to the normal information. The resulting LIC texture is mapped onto the deformed manifold and is rendered as a three dimensional scene. Due to the light's reflection on the deformed manifold, one can interactively explore the result of the deformation.\\\",\\\"Authors\\\":\\\"Scheuermann, G.;Burbach, H.;Hagen, H.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;ManipulationAndDeformation;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809895\\\",\\\"Keywords\\\":\\\"deformation;vector field visualization;line integral convolution\\\",\\\"Keywords_Processed\\\":\\\"line integral convolution;deformation;vector field visualization\\\",\\\"Title\\\":\\\"Visualizing Planar Vector Fields with Normal Component Using Line Integral Convolution\\\"},\\\"343\\\":{\\\"Abstract\\\":\\\"Multiresolution analysis based on FWT (Fast Wavelet Transform) is now widely used in scientific visualization. Spherical biorthogonal wavelets for spherical triangular grids were introduced by P. Schroder and W. Sweldens (1995). In order to improve on the orthogonality of the wavelets, the concept of nearly orthogonality, and two new piecewise-constant (Haar) bases were introduced by G.M. Nielson (1997). We extend the results of Nielson. First we give two one-parameter families of triangular Haar wavelet bases that are nearly orthogonal in the sense of Nielson. Then we introduce a measure of orthogonality. This measure vanishes for orthogonal bases. Eventually, we show that we can find an optimal parameter of our wavelet families, for which the measure of orthogonality is minimized. Several numerical and visual examples for a spherical topographic data set illustrates our results.\\\",\\\"Authors\\\":\\\"Bonneau, G.-P.\\\",\\\"Clusters\\\":\\\"MultiresolutionTechniques;NumericalMethodsMathematics;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809898\\\",\\\"Keywords\\\":\\\"visualization;multi-resolution;orthogonality;wavelets\\\",\\\"Keywords_Processed\\\":\\\"visualization;wavelet;multi resolution;orthogonality\\\",\\\"Title\\\":\\\"Optimal triangular Haar bases for spherical data\\\"},\\\"344\\\":{\\\"Abstract\\\":\\\"We present a novel rendering technique, termed LOD-sprite rendering, which uses a combination of a level-of-detail (LOD) representation of the scene together with reusing image sprites (previously rendered images). Our primary application is accelerating terrain rendering. The LOD-sprite technique renders an initial frame using a high-resolution model of the scene geometry. It renders subsequent frames with a much lower-resolution model of the scene geometry and texture-maps each polygon with the image sprite from the initial high-resolution frame. As it renders these subsequent frames, the technique measures the error associated with the divergence of the view position from the position where the initial frame was rendered. Once this error exceeds a user-defined threshold, the technique re-renders the scene from the high-resolution model. We have efficiently implemented the LOD-sprite technique with texture mapping graphics hardware. Although to date we have only applied LOD-sprite to terrain rendering, it could easily be extended to other applications. We feel LOD-sprite holds particular promise for real time rendering systems.\\\",\\\"Authors\\\":\\\"Chen, B.;Swan, J.E.;Kuo, E.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;HardwareAccellerationAndComputationGeneral;ImageBasedDataImageSignalProcessing;ImmersiveAndVirtualEnvironments;LevelOfDetail;MultiresolutionTechniques;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809900\\\",\\\"Keywords\\\":\\\"virtual environment;image-based modeling and rendering;virtual reality;multi-resolution;level-of-detail;terrain rendering;texture mapping;acceleration techniques\\\",\\\"Keywords_Processed\\\":\\\"virtual environment;terrain render;multi resolution;image base modeling and render;level of detail;texture mapping;virtual reality;acceleration technique\\\",\\\"Title\\\":\\\"LOD-sprite technique for accelerated terrain rendering\\\"},\\\"345\\\":{\\\"Abstract\\\":\\\"Irregular tetrahedral meshes, which are popular in many engineering and scientific applications, often contain a large number of vertices. A mesh of V vertices and T tetrahedra requires 48 V bits or less to store the vertex coordinates, 4Tlog 2(V) bits to store the tetrahedra-vertex incidence relations, also called connectivity information, and kV bits to store the k-bit value samples associated with the vertices. Given that T is 5 to 7 times larger than V and that V often exceeds 32 3, the storage space required for the connectivity is larger than 300 V bits and thus dominates the overall storage cost. Our \\\\\\\"implants spray\\\\\\\" compression approach introduced in the paper reduces this cost to about 30 V bits or less-a 10:1 compression ratio. Furthermore, implant spray supports the progressive refinement of a crude model through a series of vertex-splits operations.\\\",\\\"Authors\\\":\\\"Pajarola, R.;Rossignac, J.;Szymczak, A.\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;CompressionTechniques;MeshesGridsAndLattices;MultiresolutionTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809901\\\",\\\"Keywords\\\":\\\"compression;progressive incremental reconstruction;tetrahedral meshes;multi-resolution model\\\",\\\"Keywords_Processed\\\":\\\"tetrahedral mesh;multi resolution model;progressive incremental reconstruction;compression\\\",\\\"Title\\\":\\\"Implant sprays: compression of progressive tetrahedral mesh connectivity\\\"},\\\"346\\\":{\\\"Abstract\\\":\\\"Many applications produce three-dimensional points that must be further processed to generate a surface. Surface reconstruction algorithms that start with a set of unorganized points are extremely time-consuming. Sometimes however, points are generated such that there is additional information available to the reconstruction algorithm. We present Spiraling Edge, a specialized algorithm for surface reconstruction that is three orders of magnitude faster than algorithms for the general case. In addition to sample point locations, our algorithm starts with normal information and knowledge of each point's neighbors. Our algorithm produces a localized approximation to the surface by creating a star-shaped triangulation between a point and a subset of its nearest neighbors. This surface patch is extended by locally triangulating each of the points along the edge of the patch. As each edge point is triangulated, it is removed from the edge and new edge points along the patch's edge are inserted in its place. The updated edge spirals out over the surface until the edge encounters a surface boundary and stops growing in that direction, or until the edge reduces to a small hole that is filled by the final triangle.\\\",\\\"Authors\\\":\\\"Crossno, P.;Angel, E.\\\",\\\"Clusters\\\":\\\"GeometricModeling;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809903\\\",\\\"Keywords\\\":\\\"advancing front;surface reconstruction;triangulation\\\",\\\"Keywords_Processed\\\":\\\"surface reconstruction;triangulation;advance front\\\",\\\"Title\\\":\\\"Spiraling Edge: fast surface reconstruction from partially organized sample points\\\"},\\\"347\\\":{\\\"Abstract\\\":\\\"Vector field visualization is an important topic in scientific visualization. Its aim is to graphically represent field data in an intuitively understandable and precise way. Here a new approach based on anisotropic nonlinear diffusion is introduced. It enables an easy perception of flow data and serves as an appropriate scale space method for the visualization of complicated flow patterns. The approach is closely related to nonlinear diffusion methods in image analysis where images are smoothed while still retaining and enhancing edges. An initial noisy image is smoothed along streamlines, whereas the image is sharpened in the orthogonal direction. The method is based on a continuous model and requires the solution of a parabolic PDE problem. It is discretized only in the final implementational step. Therefore, many important qualitative aspects can already be discussed on a continuous level. Applications are shown in 2D and 3D and the provisions for flow segmentation are outlined.\\\",\\\"Authors\\\":\\\"Preusser, T.;Rumpf, M.\\\",\\\"Clusters\\\":\\\"DiffusionRelatedTechniques;FlowVisualizationDataAndTechniques;MultiScaleDataTechniques;SegmentationAndClassification\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809904\\\",\\\"Keywords\\\":\\\"flow visualization;multi-scale;segmentation;non-linear diffusion\\\",\\\"Keywords_Processed\\\":\\\"non linear diffusion;multi scale;segmentation;flow visualization\\\",\\\"Title\\\":\\\"Anisotropic nonlinear diffusion in flow visualization\\\"},\\\"348\\\":{\\\"Abstract\\\":\\\"This paper explores mapping strategies for generating LIC-like images from streamlines and streamline-like images from LIC. The main contribution of this paper is a technique which we call pseudo-LIC or PLIC. By adjusting a small set of key parameters, PLIC can generate flow visualizations that span the spectrum of streamline-like to LIC-like images. Among the advantages of PLIC are: image quality comparable with LIC, performance speedup over LIC, use of a template texture that is independent of the size of the flow field, handles the problem of multiple streamlines occupying the same pixel in image space, reduced aliasing, applicability to time varying data sets, and variable speed animation.\\\",\\\"Authors\\\":\\\"Verma, V.;Kao, D.;Pang, A.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;ComparisonComparativeVisualizationAndSimilarity;FlowVisualizationDataAndTechniques;Perception;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809906\\\",\\\"Keywords\\\":\\\"variable speed animation;jitter;unsteady flow;comparative visualization;texture mapping\\\",\\\"Keywords_Processed\\\":\\\"unsteady flow;variable speed animation;comparative visualization;texture mapping;jitter\\\",\\\"Title\\\":\\\"PLIC: bridging the gap between streamlines and LIC\\\"},\\\"349\\\":{\\\"Abstract\\\":\\\"Visualization of topological information of a vector field can provide useful information on the structure of the field. However, in turbulent flows standard critical point visualization will result in a cluttered image which is difficult to interpret. This paper presents a technique for collapsing topologics. The governing idea is to classify the importance of the critical points in the topology. By only displaying the more important critical points, a simplified depiction of the topology can be provided. Flow consistency is maintained when collapsing the topology, resulting in a visualization which is consistent with the original topology. We apply the collapsing topology technique to a turbulent flow field.\\\",\\\"Authors\\\":\\\"de Leeuw, W.;van Liere, R.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;MultiScaleDataTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809907\\\",\\\"Keywords\\\":\\\"flow visualization;multi-level visualization techniques;flow topology\\\",\\\"Keywords_Processed\\\":\\\"multi level visualization technique;flow topology;flow visualization\\\",\\\"Title\\\":\\\"Collapsing Flow Topology Using Area Metrics\\\"},\\\"350\\\":{\\\"Abstract\\\":\\\"We present a multiresolution technique for interactive texture-basedvolume visualization of very large data sets. This method uses anadaptive scheme that renders the volume in a region-of-interest ata high resolution and the volume away from this region at progressivelylower resolutions. The algorithm is based on the segmentationof texture space into an octree, where the leaves of the tree definethe original data and the internal nodes define lower-resolutionversions. Rendering is done adaptively by selecting high-resolutioncells close to a center of attention and low-resolution cells awayfrom this area. We limit the artifacts introduced by this method bymodifying the transfer functions in the lower-resolution data setsand utilizing spherical shells as a proxy geometry. It is possibleto use this technique to produce viewpoint-dependent renderings ofvery large data sets.\\\",\\\"Authors\\\":\\\"La Mar, E.C.;Hamann, B.;Joy, K.I.\\\",\\\"Clusters\\\":\\\"Rendering;Textures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809908\\\",\\\"Keywords\\\":\\\"volume visualization;hardware texture;multi-resolution rendering\\\",\\\"Keywords_Processed\\\":\\\"multi resolution render;volume visualization;hardware texture\\\",\\\"Title\\\":\\\"Multiresolution Techniques for Interactive Texture-based Volume Visualization\\\"},\\\"351\\\":{\\\"Abstract\\\":\\\"We present a fast volume rendering algorithm for time-varying fields. We propose a new data structure, called time-space partitioning (TSP) tree, that can effectively capture both the spatial and the temporal coherence from a time-varying field. Using the proposed data structure, the rendering speed is substantially improved. In addition, our data structure helps to maintain the memory access locality and to provide the sparse data traversal so that our algorithm becomes suitable for large-scale out-of-core applications. Finally, our algorithm allows flexible error control for both the temporal and the spatial coherence so that a trade-off between image quality and rendering speed is possible. We demonstrate the utility and speed of our algorithm with data from several time-varying CFD simulations. Our rendering algorithm can achieve substantial speedup while the storage space overhead for the TSP tree is kept at a minimum.\\\",\\\"Authors\\\":\\\"Han-Wei Shen;Chiang, L.-J.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"ScalarFieldDataTechniques;TimeseriesTimeVaryingDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809910\\\",\\\"Keywords\\\":\\\"time-varying fields;volume rendering;scalar field visualization;volume visualization\\\",\\\"Keywords_Processed\\\":\\\"volume render;volume visualization;time vary field;scalar field visualization\\\",\\\"Title\\\":\\\"A fast volume rendering algorithm for time-varying fields using a time-space partitioning (TSP) tree\\\"},\\\"352\\\":{\\\"Abstract\\\":\\\"We present a novel presence acceleration for volumetric ray casting. A highly accurate estimation for object presence is obtained by projecting all grid cells associated with the object boundary on the image plane. Memory space and access time are reduced by run-length encoding of the boundary cells, while boundary cell projection time is reduced by exploiting projection templates and multiresolution volumes. Efforts have also been made towards a fast perspective projection as well as interactive classification. We further present task partitioning schemes for effective parallelization of both boundary cell projection and ray traversal procedures. Good load balancing has been reached by taking full advantage of both the optimizations in the serial rendering algorithm and shared-memory architecture. Our experimental results on a 16-processor SGI Power Challenge have shown interactive rendering rates for 256 3 volumetric data sets at 10-30 Hz. We describe the theory and implementation of our algorithm, and shows its superiority over the shear-warp factorization approach.\\\",\\\"Authors\\\":\\\"Wan, M.;Kaufman, A.;Bryson, S.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;DimensionalityReduction;HardwareAccellerationAndComputationGeneral;ParallelSystemsAndParallelProcessing;SegmentationAndClassification;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1999.809911\\\",\\\"Keywords\\\":\\\"volume rendering;presence acceleration;multi-resolution volume;run-length encoding;parallel processing;projection template;interactive classification\\\",\\\"Keywords_Processed\\\":\\\"volume render;multi resolution volume;projection template;presence acceleration;run length encoding;interactive classification;parallel processing\\\",\\\"Title\\\":\\\"High performance presence-accelerated ray casting\\\"},\\\"353\\\":{\\\"Abstract\\\":\\\"The paper discusses a concept for virtual reality tools for use in design reviews of mechanical products. In this discussion, the special requirements of a virtual environment are given consideration. The focus of this paper is on suggestions for the visualization and arrangement of a product, its structure, its components and their alternatives together in one environment. The realization of these concepts results in a 3D-interface that allows users, especially engineers, to evaluate different configurations of a product and gives them direct access to the product structure. By applying various visualization techniques, product components and their attributes, e.g., their price, can be brought together into one visualization. Thus, in contrast to state-of-the-art software, the product structure, three-dimensional, real-sized components, and attribute values can be combined together in 3D-visualizations. This research was done in cooperation with Christoph Brandt, member of the Heinz Nixdorf Institute's virtual reality group.\\\",\\\"Authors\\\":\\\"Kremer, K.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;BusinessFinanceEconomyManufacturing;DataAcquisitionAndManagement;DesignMethodologiesAndInteractionDesign;ImmersiveAndVirtualEnvironments;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745304\\\",\\\"Keywords\\\":\\\"virtual environment;virtual reality;engineering data management;cad;product configuration;product attributes;visualization;design reviews;pdm;product structures\\\",\\\"Keywords_Processed\\\":\\\"virtual environment;engineering datum management;visualization;product configuration;product attribute;design review;product structure;pdm;virtual reality;cad\\\",\\\"Title\\\":\\\"A concept for virtual reality tools for design reviews\\\"},\\\"354\\\":{\\\"Abstract\\\":\\\"Many sophisticated solutions have been proposed to reduce the geometric complexity of 3D meshes. A problem studied less often is how to preserve on a simplified mesh the detail (e.g., color, high frequency shape detail, scalar fields, etc.) which is encoded in the original mesh. We present a general approach for preserving detail on simplified meshes. The detail (or high frequency information) lost after simplification is encoded through texture or bump maps. The original contribution is that preservation is performed after simplification, by building set of triangular texture patches that are then packed in a single texture map. Each simplified mesh face is sampled to build the associated triangular texture patch; a new method for storing this set of texture patches into a standard rectangular texture is presented and discussed. Our detail preserving approach makes no assumptions about the simplification process adopted to reduce mesh complexity and allows highly efficient rendering. The solution is very general, allowing preservation of any attribute value defined on the high resolution mesh. We also describe an alternative application: the conversion of 3D models with 3D static procedural textures into standard 3D models with 2D textures.\\\",\\\"Authors\\\":\\\"Cignoni, P.;Montani, C.;Rocchini, C.;Scopigno, R.\\\",\\\"Clusters\\\":\\\"LevelOfDetail;SurfaceRelatedDataAndTechniques;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745285\\\",\\\"Keywords\\\":\\\"texture mapping;detail preservation;surface simplification\\\",\\\"Keywords_Processed\\\":\\\"detail preservation;texture mapping;surface simplification\\\",\\\"Title\\\":\\\"A general method for preserving attribute values on simplified meshes\\\"},\\\"355\\\":{\\\"Abstract\\\":\\\"We present a new approach for simplifying models composed of polygons or spline patches. Given an input model, the algorithm computes a new representation of the model in terms of triangular Bezier patches. It performs a series of geometric operations, consisting of patch merging and swapping diagonals, and makes use of batch connectivity information to generate C-LODs (curved levels-of-detail). Each C-LOD is represented using cubic triangular Bezier patches. The C-LODs provide a compact representation for storing the model. The algorithm tries to minimize the surface deviation error and maintains continuity at patch boundaries. Given the CLODs, the algorithm can generate their polygonal approximations using static and dynamic tessellation schemes. It has been implemented and we highlight its performance on a number of polygonal and spline models.\\\",\\\"Authors\\\":\\\"Gopi, M.;Manocha, D.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;CurvesAndCurvature;LevelOfDetail;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745313\\\",\\\"Keywords\\\":\\\"surface fitting;surface approximation;level-of-detail;model simplification;spline patches;dynamic tessellation\\\",\\\"Keywords_Processed\\\":\\\"model simplification;surface fit;surface approximation;spline patch;dynamic tessellation;level of detail\\\",\\\"Title\\\":\\\"A unified approach for simplifying polygonal and spline models\\\"},\\\"356\\\":{\\\"Abstract\\\":\\\"We present an efficient and robust ray-casting algorithm for directly rendering a curvilinear volume of arbitrarily-shaped cells. We designed the algorithm to alleviate the consumption of CPU power and memory space. By incorporating the essence of the projection paradigm into the ray-casting process, we have successfully accelerated the ray traversal through the grid and data interpolations at sample points. Our algorithm also overcomes the conventional limitation requiring the cells to be convex. Application of this algorithm to several commonly-used curvilinear data sets has produced a favorable performance when compared with recently reported algorithms.\\\",\\\"Authors\\\":\\\"Lichan Hong;Kaufman, A.\\\",\\\"Clusters\\\":\\\"MeshesGridsAndLattices;ParallelSystemsAndParallelProcessing;RaytracingRaycasting;Simulation;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745310\\\",\\\"Keywords\\\":\\\"volume rendering;dynamic simulation;curvilinear grid;irregular grids;volume visualization;raycasting;parallel rendering\\\",\\\"Keywords_Processed\\\":\\\"volume render;curvilinear grid;irregular grid;volume visualization;parallel rendering;raycaste;dynamic simulation\\\",\\\"Title\\\":\\\"Accelerated ray-casting for curvilinear volumes\\\"},\\\"357\\\":{\\\"Abstract\\\":\\\"Information visualization encounters a wide variety of different data domains. The visualization community has developed representation methods and interactive techniques. As a community, we have realized that the requirements in each domain are often dramatically different. In order to easily apply existing methods, researchers have developed a semiology of graphic representations. We have extended this research into a framework that includes operators and interactions in visualization systems, such as a visualization spreadsheet. We discuss properties of this framework and use it to characterize operations spanning a variety of different visualization techniques. The framework developed in the paper enables a new way of exploring and evaluating the design space of visualization operators, and helps end users in their analysis tasks\\\",\\\"Authors\\\":\\\"Ed Huai-Hsin Chi;Riedl, J.\\\",\\\"Clusters\\\":\\\"DataEditing;InteractionTechniquesGeneral;TabularDataAndTechniques;VisualDesignDesignGuidelines;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1998.729560\\\",\\\"Keywords\\\":\\\"user interaction;information visualization;spreadsheets;view/value;operators;visualization systems;extensibility;framework;design\\\",\\\"Keywords_Processed\\\":\\\"user interaction;framework;operator;visualization system;view value;information visualization;spreadsheet;extensibility;design\\\",\\\"Title\\\":\\\"An operator interaction framework for visualization systems\\\"},\\\"358\\\":{\\\"Abstract\\\":\\\"The purpose of the paper is to develop a visualization system of a document space, called BiblioMapper, for CISI collections, one of the bibliographic databases available on the Internet. The major function of BiblioMapper is to visualize the document space with a cluster-based visualization technique. The cluster-based visualization technique assembles a set of documents according to semantic similarities. One advantage of this technique is that users are able to focus on and assess each cluster and the documents which the cluster comprises according to their information needs\\\",\\\"Authors\\\":\\\"Min Song\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;DatabasesAndDataMining;TextDocumentTopicAnalysisDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1998.729569\\\",\\\"Keywords\\\":\\\"visualization;textual information;clustering algorithms;information retrieval\\\",\\\"Keywords_Processed\\\":\\\"visualization;textual information;cluster algorithm;information retrieval\\\",\\\"Title\\\":\\\"BiblioMapper: a cluster-based information visualization technique\\\"},\\\"359\\\":{\\\"Abstract\\\":\\\"Presents a new method for using texture to visualize multi-dimensional data elements arranged on an underlying 3D height field. We hope to use simple texture patterns in combination with other visual features like hue and intensity to increase the number of attribute values we can display simultaneously. Our technique builds perceptual texture elements (or pexels) to represent each data element. Attribute values encoded in the data element are used to vary the appearance of a corresponding pexel. Texture patterns that form when the pexels are displayed can be used to rapidly and accurately explore the dataset. Our pexels are built by controlling three separate texture dimensions: height, density and regularity. Results from computer graphics, computer vision and cognitive psychology have identified these dimensions as important for the formation of perceptual texture patterns. We conducted a set of controlled experiments to measure the effectiveness of these dimensions, and to identify any visual interference that may occur when all three are displayed simultaneously at the same spatial location. Results from our experiments show that these dimensions can be used in specific combinations to form perceptual textures for visualizing multidimensional datasets. We demonstrate the effectiveness of our technique by applying it to two real-world visualization environments: tracking typhoon activity in southeast Asia, and analyzing ocean conditions in the northern Pacific.\\\",\\\"Authors\\\":\\\"Healey, C.;Enns, J.T.\\\",\\\"Clusters\\\":\\\"Cognition;ComputerGraphicsTechniquesGeneral;EarthSpaceAndEnvironmentalSciences;EvaluationGeneral;MultidimensionalMultivariateMultifieldDataAndTechniques;Perception;Textures;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745292\\\",\\\"Keywords\\\":\\\"scientific visualization;perception;computer graphics;human vision;multi-dimensional data sets;preattentive processing;oceanography;typhoon;texture;experimental design\\\",\\\"Keywords_Processed\\\":\\\"computer graphic;multi dimensional datum set;perception;texture;human vision;oceanography;typhoon;scientific visualization;experimental design;preattentive processing\\\",\\\"Title\\\":\\\"Building perceptual textures to visualize multidimensional datasets\\\"},\\\"360\\\":{\\\"Abstract\\\":\\\"Protein fold recognition (threading) involves the prediction of a protein's three-dimensional shape based on its similarity to a protein whose structure is known. Fold predictions are low resolution; no effort is made to rotate the protein's component amino acid side chains into their correct spatial orientations. Rather, the goal is to recognize the protein family member that most closely resembles the target sequence of unknown structure and to create a sensible alignment of the target to the structure (i.e., a structure-sequence alignment). To complement this structure prediction method the authors have implemented a low resolution molecular graphics tool. Since amino acid side chain orientation is not relevant in fold recognition, amino acid residues are represented by abstract shapes or glyphs much like LegoTM blocks. They also borrow techniques from comparative streamline visualization to provide clean depictions of the entire protein structure model. By creating a low resolution representation of protein structure, they are able to approximately double the amount of information on the screen. This implementation also possesses the advantage of eliminating distracting and possibly misleading visual clutter resulting from the mapping of protein alignment information onto a high resolution display of a known structure.\\\",\\\"Authors\\\":\\\"Hansen, M.;Meads, D.;Pang, A.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;ComparisonComparativeVisualizationAndSimilarity;GlyphsGlyphBasedTechniques;MolecularScienceAndChemistry;ParallelSystemsAndParallelProcessing;StreamlinesPathlinesStreaklines;VisualPatternFeatureDetectionAndTracking\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1998.729566\\\",\\\"Keywords\\\":\\\"glyph;protein;alignment;similarity;threading;structure;ribbons;streamlines;amino acids;fold recognition\\\",\\\"Keywords_Processed\\\":\\\"fold recognition;streamline;thread;alignment;similarity;protein;amino acid;glyph;ribbon;structure\\\",\\\"Title\\\":\\\"Comparative visualization of protein structure-sequence alignments\\\"},\\\"361\\\":{\\\"Abstract\\\":\\\"Spot noise and line integral convolution (LIC) are two texture synthesis techniques for vector field visualization. The two techniques are compared. Continuous directional convolution is used as a common basis for comparing the techniques. It is shown that the techniques are based on the same mathematical concept. Comparisons of the visual appearance of the output and performance of the algorithms are made.\\\",\\\"Authors\\\":\\\"de Leeuw, W.;van Liere, R.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745324\\\",\\\"Keywords\\\":\\\"flow visualization;texture synthesis\\\",\\\"Keywords_Processed\\\":\\\"texture synthesis;flow visualization\\\",\\\"Title\\\":\\\"Comparing LIC and spot noise\\\"},\\\"362\\\":{\\\"Abstract\\\":\\\"We propose a general paradigm for computing optimal coordinate frame fields that may be exploited to visualize curves and surfaces. Parallel transport framings, which work well for open curves, generally fail to have desirable properties for cyclic curves and for surfaces. We suggest that minimal quaternion measure provides an appropriate heuristic generalization of parallel transport. Our approach differs from minimal tangential acceleration approaches due to the addition of \\\\\\\"sliding ring\\\\\\\" constraints that fix one frame axis, but allow an axial rotational freedom whose value is varied in the optimization process. Our fundamental tool is the quaternion Gauss map, a generalization to quaternion space of the tangent map for curves and of the Gauss map for surfaces. The quaternion Gauss map takes 3D coordinate frame fields for curves and surfaces into corresponding curves and surfaces constrained to the space of possible orientations in quaternion space. Standard optimization tools provide application specific means of choosing optimal, e.g., length- or area-minimizing, quaternion frame fields in this constrained space.\\\",\\\"Authors\\\":\\\"Hanson, A.J.\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;FlowVisualizationDataAndTechniques;NumericalMethodsMathematics;SurfaceRelatedDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745326\\\",\\\"Keywords\\\":\\\"quaternions;frames;surfaces;curves;tubing\\\",\\\"Keywords_Processed\\\":\\\"tubing;quaternion;surface;frame;curve\\\",\\\"Title\\\":\\\"Constrained optimal framings of curves and surfaces using quaternion Gauss maps\\\"},\\\"363\\\":{\\\"Abstract\\\":\\\"Area cartograms are used for visualizing geographically distributed data by attaching measurements to regions of a map and scaling the regions such that their areas are proportional to the measured quantities. A continuous area cartogram is a cartogram that is constructed without changing the underlying map topology. We present a new algorithm for the construction of continuous area cartograms that was developed by viewing their construction as a constrained optimization problem. The algorithm uses a relaxation method that exploits hierarchical resolution, constrained dynamics, and a scheme that alternates goals of achieving correct region areas and adjusting region shapes. It is compared favorably to existing methods in its ability to preserve region shape recognition cues, while still achieving high accuracy.\\\",\\\"Authors\\\":\\\"House, D.;Kocmoud, C.J.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;DataTransformation;GeographyGeospatialVisCartographyTerrainVis;Maps;Optimization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745303\\\",\\\"Keywords\\\":\\\"map transformation;anamorphosis;value-by-area map;cartogram;constrained optimization;thematic cartography\\\",\\\"Keywords_Processed\\\":\\\"thematic cartography;cartogram;anamorphosis;map transformation;constrain optimization;value by area map\\\",\\\"Title\\\":\\\"Continuous cartogram construction\\\"},\\\"364\\\":{\\\"Abstract\\\":\\\"Interpolating contours and reconstructing a rational surface from a contour map are two essential problems in terrain modeling. They are often met in the field of computer graphics and CAD systems based on geographic information systems. Although many approaches have been developed for these two problems, one difficulty still remains. That is how to ensure that the reconstructed surface is both smooth globally and coincides with the given contours exactly simultaneously. In this paper we solve the two problems in a unified framework. We use gradient controlled partial differential equation (PDE) surfaces to express terrain surfaces, in which the surface shapes can be globally determined by the contours, their locations, height and gradient values. The surface generated by this method is accurate in the sense of exactly coinciding with the original contours and smooth with C1 continuity everywhere. The method can reveal smooth saddle shapes caused by surface branching of one to more and can make rational interpolated sub-contours between two or more neighboring contours.\\\",\\\"Authors\\\":\\\"Chai, J.;Miyoshi, T.;Nakamae, E.\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;Interpolation;PdeSForVisualization;ShapeRelatedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745281\\\",\\\"Keywords\\\":\\\"shape reconstruction;terrain modeling;contour interpolation;partial differential equation surfaces\\\",\\\"Keywords_Processed\\\":\\\"partial differential equation surface;contour interpolation;terrain modeling;shape reconstruction\\\",\\\"Title\\\":\\\"Contour interpolation and surface reconstruction of smooth terrain models\\\"},\\\"365\\\":{\\\"Abstract\\\":\\\"Many real world polygonal surfaces contain topological singularities that represent a challenge for processes such as simplification, compression, smoothing, etc. We present an algorithm for removing such singularities, thus converting non manifold sets of polygons to manifold polygonal surfaces (orientable if necessary). We identify singular vertices and edges, multiply singular vertices, and cut through singular edges. In an optional stitching phase, we join surface boundary edges that were cut, or whose endpoints are sufficiently close, while guaranteeing that the surface is a manifold. We study two different stitching strategies called \\\\\\\"edge pinching\\\\\\\" and \\\\\\\"edge snapping\\\\\\\"; when snapping, special care is required to avoid re-creating singularities. The algorithm manipulates the polygon vertex indices (surface topology) and essentially ignores vertex coordinates (surface geometry). Except for the optional stitching, the algorithm has a linear complexity in the number of vertices edges and faces, and require no floating point operation.\\\",\\\"Authors\\\":\\\"Gueziec, A.;Taubin, G.;Lazarus, F.;Horn, W.\\\",\\\"Clusters\\\":\\\"CuttingPlanes;DimensionalityReduction;MeshesGridsAndLattices;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745327\\\",\\\"Keywords\\\":\\\"cutting;stitching;manifold;polygonal surfaces\\\",\\\"Keywords_Processed\\\":\\\"manifold;cut;polygonal surface;stitch\\\",\\\"Title\\\":\\\"Converting sets of polygons to manifold surfaces by cutting and stitching\\\"},\\\"366\\\":{\\\"Abstract\\\":\\\"Presents an efficient algorithm for the reconstruction of a multivariate function from multiple sets of scattered data. Given N sets of scattered data representing N distinct dependent variables that have been sampled independently over a common domain and N error tolerance values, the algorithm constructs a triangulation of the domain of the data and associates multivariate values with the vertices of the triangulation. The resulting linear interpolation of these multivariate values yields a multivariate function, called a co-triangulation, that represents all of the dependent data up to the given error tolerance. A simple iterative algorithm for the construction of a co-triangulation from any number of data sets is presented and analyzed. The main contribution of this paper lies in the description of a highly efficient framework for the realization of this approximation algorithm. While the asymptotic time complexity of the algorithm certainly remains within the theoretical bounds, we demonstrate that it is possible to achieve running times that depend only linearly on the number of data even for very large problems with more than two million samples. This efficient realization of the algorithm uses adapted dynamic data structures and careful caching in an integrated framework.\\\",\\\"Authors\\\":\\\"Weimer, H.;Warren, J.;Troutner, J.;Wiggins, W.;Shrout, J.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;DataFeaturesAndAttributes;GeometryBasedTechniques;Interpolation;MeshesGridsAndLattices;ProgrammingAlgorithmsAndDataStructures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745293\\\",\\\"Keywords\\\":\\\"computational geometry;high-dimensional approximation;delaunay triangulation;multi-dimensional approximation;data structures;scattered data\\\",\\\"Keywords_Processed\\\":\\\"scatter datum;high dimensional approximation;delaunay triangulation;data structure;multi dimensional approximation;computational geometry\\\",\\\"Title\\\":\\\"Efficient co-triangulation of large data sets\\\"},\\\"367\\\":{\\\"Abstract\\\":\\\"This paper presents efficient image-based rendering techniques used in the context of an architectural walkthrough system. Portals (doors and windows) are rendered by warping layered depth images (LDIs). In a preprocessing phase, for every portal, a number of pre-rendered images are combined into an LDI. The resulting LDI stores, exactly once, all surfaces visible in at least one of the images used in the construction, so most of the exposure errors are efficiently eliminated. The LDI can be warped in the McMillan occlusion compatible ordering. A substantial increase in performance is obtained by warping in parallel. Our parallelization scheme achieves good load balancing, scales with the number of processors, and preserves the occlusion compatible ordering. A fast, conservative reference-image-space clipping algorithm also reduces the warping effort.\\\",\\\"Authors\\\":\\\"Popescu, V.;Lastra, A.;Aliaga, D.;de Oliveira Neto, M.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;BiologyAndBioinformatics;Illumination;ImageBasedDataImageSignalProcessing;InternetWebVisualizationForTheMasses;ParallelSystemsAndParallelProcessing;Rendering\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745305\\\",\\\"Keywords\\\":\\\"architectural walkthrough;exposure error;parallel warping;portals;image-based rendering;occlusion compatible ordering for discrete images;cell;clipping;layered depth image\\\",\\\"Keywords_Processed\\\":\\\"image base render;portal;occlusion compatible ordering for discrete image;cell;parallel warping;architectural walkthrough;exposure error;layer depth image;clipping\\\",\\\"Title\\\":\\\"Efficient warping for architectural walkthroughs using layered depth images\\\"},\\\"368\\\":{\\\"Abstract\\\":\\\"We are interested in feature extraction from volume data in terms of coherent surfaces and 3D space curves. The input can be an inaccurate scalar or vector field, sampled densely or sparsely on a regular 3D grid, in which poor resolution and the presence of spurious noisy samples make traditional iso-surface techniques inappropriate. In this paper, we present a general-purpose methodology to extract surfaces or curves from a digital 3D potential vector field {(s,v~)}, in which each voxel holds a scalar s designating the strength and a vector v~ indicating the direction. For scalar, sparse or low-resolution data, we \\\\\\\"vectorize\\\\\\\" and \\\\\\\"densify\\\\\\\" the volume by tensor voting to produce dense vector fields that are suitable as input to our algorithms, the extremal surface and curve algorithms. Both algorithms extract, with sub-voxel precision, coherent features representing local extrema in the given vector field. These coherent features are a hole-free triangulation mesh (in the surface case), and a set of connected, oriented and non-intersecting polyline segments (in the curve case). We demonstrate the general usefulness of both extremal algorithms on a variety of real data by properly extracting their inherent extremal properties, such as (a) shock waves induced by abrupt velocity or direction changes in a flow field, (b) interacting vortex cores and vorticity lines in a velocity field, (c) crest-lines and ridges implicit in a digital terrain map, and (d) grooves, anatomical lines and complex surfaces from noisy dental data.\\\",\\\"Authors\\\":\\\"Chi-Keung Tang;Medioni, G.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;SurfaceRelatedDataAndTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745290\\\",\\\"Keywords\\\":\\\"scalar and vector field visualization;surface fitting;surface and curve extremality;marching cubes\\\",\\\"Keywords_Processed\\\":\\\"surface fit;march cube;surface and curve extremality;scalar and vector field visualization\\\",\\\"Title\\\":\\\"Extremal feature extraction from 3-D vector and noisy scalar fields\\\"},\\\"369\\\":{\\\"Abstract\\\":\\\"This paper describes by example a strategy for plotting and interacting with data in multiple metric spaces. The example system was designed for use with time-varying computational fluid dynamics (CFD) data sets, but the methodology is directly applicable to other types of field data. The central objects embodied by the tool are portraits, which show the data in various coordinate systems, while preserving their spatial connectivity and temporal variability. The coordinates are derived in various ways from the field data, and an important feature is that new and derived portraits can be created interactively. The primary operations supported by the tool are brushing and linking: the user can select a subset of a given portrait, and this subset is highlighted in all portraits. The user can combine highlighted subsets from an arbitrary number of portraits with the usual logical operators, thereby indicating where an arbitrarily complex set of conditions holds. The system is useful for exploratory visualization and feature detection in multivariate data.\\\",\\\"Authors\\\":\\\"Henze, C.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;InteractionTechniquesGeneral;MultidimensionalMultivariateMultifieldDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745289\\\",\\\"Keywords\\\":\\\"flow visualization;computational fluid dynamics;brushing;multivariate visualization;feature detection\\\",\\\"Keywords_Processed\\\":\\\"brush;feature detection;multivariate visualization;computational fluid dynamic;flow visualization\\\",\\\"Title\\\":\\\"Feature detection in linked derived spaces\\\"},\\\"370\\\":{\\\"Abstract\\\":\\\"For high quality rendering of objects segmented from tomographic volume data the precise location of the boundaries of adjacent objects in subvoxel resolution is required. We describe a new method that determines the membership of a given sample point to an object by reclassifying the sample point using interpolation of the original intensity values and searching for the best fitting object in the neighbourhood. Using a ray-casting approach we then compute the surface location between successive sample points along the viewing-ray by interpolation or bisection. The accurate calculation of the object boundary enables a much more precise computation of the gray-level-gradient yielding the surface normal. Our new approach significantly improves the quality of reconstructed and shaded surfaces and reduces aliasing artifacts for animations and magnified views. We illustrate the results on different cases including the Visible-Human-Data, where we achieve nearly photo-realistic images.\\\",\\\"Authors\\\":\\\"Tiede, U.;Schiemann, T.;Hohne, K.H.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DataAcquisitionAndManagement;RaytracingRaycasting\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745311\\\",\\\"Keywords\\\":\\\"partial volume effect;tomographic data;visible-human-project;raycasting\\\",\\\"Keywords_Processed\\\":\\\"visible human project;partial volume effect;tomographic datum;raycaste\\\",\\\"Title\\\":\\\"High quality rendering of attributed volume data\\\"},\\\"371\\\":{\\\"Abstract\\\":\\\"We attack the problem of image based rendering with occlusions and general camera motions by using distorted multiperspective images; such images provide multiple viewpoint photometry similar to the paintings of cubist artists. We take scene geometry, in contrast, to be embodied in mappings of viewing rays from their original 3D intercepts into the warped multiperspective image space. This approach allows us to render approximations of scenes with occlusions using time dense and spatially sparse sequences of camera rays, which is a significant improvement over the storage requirements of an equivalent animation sequence. Additional data compression can be achieved using sparse time keyframes as well. Interpolating the paths of sparse time key rays correctly in image space requires singular interpolation functions with spatial discontinuities. While there are many technical questions yet to be resolved, the employment of these singular interpolation functions in the multiperspective image space appears to be of potential interest for generating general viewpoint scene renderings with minimal data storage.\\\",\\\"Authors\\\":\\\"Hanson, A.J.;Wernert, E.A.\\\",\\\"Clusters\\\":\\\"ImageBasedDataImageSignalProcessing;OcclusionProblemsTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745320\\\",\\\"Keywords\\\":\\\"image-based rendering;occlusion\\\",\\\"Keywords_Processed\\\":\\\"image base render;occlusion\\\",\\\"Title\\\":\\\"Image-based rendering with occlusions via cubist images\\\"},\\\"372\\\":{\\\"Abstract\\\":\\\"Transfer function design is an integrated component in volume visualization and data exploration. The common trial-and-error approach for transfer function searching is a very difficult and time consuming process. A goal oriented and parameterized transfer function model is therefore crucial in guiding the transfer function searching process for better and more meaningful visualization results. The paper presents an image based transfer function model that integrates 3D image processing tools into the volume visualization pipeline to facilitate the search for an image based transfer function in volume data visualization and exploration. The model defines a transfer function as a sequence of 3D image processing procedures, and allows the users to adjust a set of qualitative and descriptive parameters to achieve their subjective visualization goals. 3D image enhancement and boundary detection tools, and their integration methods with volume visualization algorithms are described. The application of this approach for 3D microscopy data exploration and analysis is also discussed.\\\",\\\"Authors\\\":\\\"Shiaofen Fang;Biddlecome, T.;Tuceryan, M.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;ImageBasedDataImageSignalProcessing;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745319\\\",\\\"Keywords\\\":\\\"data exploration;volume rendering;transfer function;volume visualization;3d image processing\\\",\\\"Keywords_Processed\\\":\\\"volume render;transfer function;3d image processing;volume visualization;datum exploration\\\",\\\"Title\\\":\\\"Image-based transfer function design for data exploration in volume visualization\\\"},\\\"373\\\":{\\\"Abstract\\\":\\\"The success of using a streamline technique for visualizing a vector field usually depends largely on the choice of adequate seed points. G. Turk and D. Banks (1996) developed an elegant technique for automatically placing seed points to achieve a uniform distribution of streamlines on a 2D vector field. Their method uses an energy function calculated from the low-pass filtered streamline image to guide the optimization process of the streamline distribution. This paper proposes a new technique for creating evenly distributed streamlines on 3D parametric surfaces found in curvilinear grids. We make use of Turk and Banks's 2D algorithm by first mapping the vectors on a 3D surface into the computational space of the curvilinear grid. To take into the consideration the mapping distortion caused by the uneven grid density in a curvilinear grid, a new energy function is designed and used for guiding the placement of streamlines in the computational space with desired local densities.\\\",\\\"Authors\\\":\\\"Xiaoyang Mao;Hatanaka, Y.;Higashida, H.;Imamiya, A.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;MeshesGridsAndLattices;StreamlinesPathlinesStreaklines;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745295\\\",\\\"Keywords\\\":\\\"flow visualization;curvilinear grid;vector field visualization;streamlines\\\",\\\"Keywords_Processed\\\":\\\"curvilinear grid;streamline;vector field visualization;flow visualization\\\",\\\"Title\\\":\\\"Image-guided streamline placement on curvilinear grid surfaces\\\"},\\\"374\\\":{\\\"Abstract\\\":\\\"This paper presents techniques for interactively visualizing tensor fields using deformations. The conceptual idea behind this approach is to allow the tensor field to manifest its influence on idealized objects placed within the tensor field. This is similar, though not exactly the same, to surfaces deforming under load in order to relieve built up stress and strain. We illustrate the effectiveness of the Deviator-Isotropic tensor decomposition in deformation visualizations of CFD strain rate. We also investigate how directional flow techniques can be extended to distinguish between regions of tensile versus compressive forces.\\\",\\\"Authors\\\":\\\"Boring, E.;Pang, A.\\\",\\\"Clusters\\\":\\\"ComparisonComparativeVisualizationAndSimilarity;FlowVisualizationDataAndTechniques;GeometricModeling;MaterialScience;NumericalMethodsMathematics;PhysicsAndPhysicalSciences;TensorDataAndTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745316\\\",\\\"Keywords\\\":\\\"symmetric;tensor;strain;directional flow;deviator;stress;antisymmetric;normal;isotropic;shear\\\",\\\"Keywords_Processed\\\":\\\"symmetric;antisymmetric;strain;tensor;normal;isotropic;directional flow;deviator;shear;stress\\\",\\\"Title\\\":\\\"Interactive deformations from tensor fields\\\"},\\\"375\\\":{\\\"Abstract\\\":\\\"Large textures cause bottlenecks in real time applications that often lead to a loss of interactivity. These performance bottlenecks occur because of disk and network transfer, texture translation, and memory swapping. We present a software solution that alleviates the problems associated with large textures by treating texture as a bandwidth limited resource rather than a finite resource. As a result the display of large textures is reduced to a caching problem in which texture memory serves as the primary cache for texture data, main memory the secondary cache, and local disk the tertiary cache. By using this cache hierarchy, applications are able to maintain real time performance while displaying textures hundreds of times larger than can fit into texture memory.\\\",\\\"Authors\\\":\\\"Cline, D.;Egbert, P.\\\",\\\"Clusters\\\":\\\"HardwareAccellerationAndComputationGeneral;InteractionTechniquesGeneral;RealtimeProcessingRenderingAndVisualizationGeneral;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745322\\\",\\\"Keywords\\\":\\\"texture mapping;interactivity;texture caching;bandwidth-limited resource;realtime display\\\",\\\"Keywords_Processed\\\":\\\"interactivity;realtime display;bandwidth limited resource;texture cache;texture mapping\\\",\\\"Title\\\":\\\"Interactive display of very large textures\\\"},\\\"376\\\":{\\\"Abstract\\\":\\\"We present a novel out-of-core technique for the interactive computation of isosurfaces from volume data. Our algorithm minimizes the main memory and disk space requirements on the visualization workstation, while speeding up isosurface extraction queries. Our overall approach is a two-level indexing scheme. First, by our meta-cell technique, we partition the original dataset into clusters of cells, called meta-cells. Secondly, we produce meta-intervals associated with the meta-cells, and build an indexing data structure on the meta-intervals. We separate the cell information, kept only in meta-cells on disk, from the indexing structure, which is also on disk and only contains pointers to meta-cells. Our meta-cell technique is an I/O-efficient approach for computing a k-d-tree-like partition of the dataset. Our indexing data structure, the binary blocked I/O interval tree, is a new I/O-optimal data structure to perform stabbing queries that report from a set of meta-intervals (or intervals) those containing a query value q. Our tree is simpler to implement, and is also more space-efficient in practice than existing structures. To perform an isosurface query, we first query the indexing structure, and then use the reported meta-cell pointers to read from disk the active meta-cells intersected by the isosurface. The isosurface itself can then be generated from active meta-cells. Rather than being a single cost indexing approach, our technique exhibits a smooth trade-off between query time and disk space.\\\",\\\"Authors\\\":\\\"Yi-Jen Chiang;Silva, C.T.;Schroeder, W.J.\\\",\\\"Clusters\\\":\\\"HierarchicalTreeDataAndTechniques;IsosurfaceAndSurfaceExtractionTechniques;OutOfCoreProcessing;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745299\\\",\\\"Keywords\\\":\\\"interval tree;isosurface extraction;scientific visualization;marching cubes;out-of-core computation\\\",\\\"Keywords_Processed\\\":\\\"out of core computation;march cube;isosurface extraction;interval tree;scientific visualization\\\",\\\"Title\\\":\\\"Interactive out-of-core isosurface extraction\\\"},\\\"377\\\":{\\\"Abstract\\\":\\\"We consider interpolation between keyframe hierarchies. We impose a set of weak constraints that allows smooth interpolation between two keyframe hierarchies in an animation or, more generally, allows the interpolation in an n-parameter family of hierarchies. We use hierarchical triangulations obtained by the Rivara element bisection algorithm (M. Rivara, 1984) and impose a weak compatibility constraint on the set of root elements of all keyframe hierarchies. We show that the introduced constraints are rather weak. The strength of our approach is that the interpolation works in the class of conforming triangulations and simplifies the task of finding the intermediate hierarchy, which is the union of the two (or more) keyframe hierarchies involved in the interpolation process. This allows for an efficient generation of the intermediate connectivity and additionally ensures that the intermediate hierarchy is again a conforming hierarchy satisfying the same constraints.\\\",\\\"Authors\\\":\\\"Friedrich, A.;Polthier, K.;Schmies, M.\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;AnimationAndMotion;LevelOfDetail;MultiresolutionTechniques;ShapeRelatedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745328\\\",\\\"Keywords\\\":\\\"multi-resolution representation;level-of-detail;adaptive refinement;animation;shape interpolation\\\",\\\"Keywords_Processed\\\":\\\"animation;adaptive refinement;multi resolution representation;level of detail;shape interpolation\\\",\\\"Title\\\":\\\"Interpolation of triangle hierarchies\\\"},\\\"378\\\":{\\\"Abstract\\\":\\\"Many high-performance isosurface extraction algorithms have been proposed in the past several years as a result of intensive research efforts. When applying these algorithms to large-scale time-varying fields, the storage overhead incurred from storing the search index often becomes overwhelming. This paper proposes an algorithm for locating isosurface cells in time-varying fields. We devise a new data structure, called the temporal hierarchical index tree, which utilizes the temporal coherence that exists in a time-varying field and adaptively coalesces the cells' extreme values over time; the resulting extreme values are then used to create the isosurface cell search index. For a typical time-varying scalar data set, not only does this temporal hierarchical index tree require much less storage space, but also the amount of I/O required to access the indices from the disk at different time steps is substantially reduced. We illustrate the utility and speed of our algorithm with data from several large-scale time-varying CFD simulations. Our algorithm can achieve more than 80% of disk-space savings when compared with the existing techniques, while the isosurface extraction time is nearly optimal.\\\",\\\"Authors\\\":\\\"Shen, H.-W.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;ScalarFieldDataTechniques;SpaceRelatedSpatialDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745298\\\",\\\"Keywords\\\":\\\"time-varying fields;span space;isosurface extraction;scalar field visualization;volume visualization;marching cubes\\\",\\\"Keywords_Processed\\\":\\\"march cube;isosurface extraction;span space;time vary field;scalar field visualization;volume visualization\\\",\\\"Title\\\":\\\"Isosurface extraction in time-varying fields using a temporal hierarchical index tree\\\"},\\\"379\\\":{\\\"Abstract\\\":\\\"We present IVORY a newly developed, platform-independent framework for physics based visualization. IVORY is especially designed for information visualization applications and multidimensional graph layout. It is fully implemented in Java 1.1 and its architecture features client server setup, which allows us to run the visualization even on thin clients. In addition, VRML 2.0 exports can be viewed by any VRML plugged-in WWW browser. Individual visual metaphors are invoked into IVORY via an advanced plug-in mechanism, where plug-ins can be implemented by any experienced user. The configuration of IVORY is accomplished using a script language, called IVML. Some interactive visualization examples, such as the integration of a haptic interface illustrate the performance and versatility of our system. Our current implementation supports NT 4.0\\\",\\\"Authors\\\":\\\"Sprenger, T.C.;Gross, M.;Bielser, D.;Strasser, T.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments;VisualizationTechniquesAndToolsGeneral;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1998.729562\\\",\\\"Keywords\\\":\\\"multi-dimensional information modeling;time-varying data;physics-based graph layout;3d information visualization;object-oriented visualization toolkit\\\",\\\"Keywords_Processed\\\":\\\"time vary datum;multi dimensional information modeling;object orient visualization toolkit;physics base graph layout;3d information visualization\\\",\\\"Title\\\":\\\"IVORY-an object-oriented framework for physics-based information visualization in Java\\\"},\\\"380\\\":{\\\"Abstract\\\":\\\"Real-time rendering of triangulated surfaces has attracted growing interest in the last few years. However, interactive visualization of very large scale grid digital elevation models is still difficult. The graphics load must be controlled by adaptive surface triangulation and by taking advantage of different levels of detail. Furthermore, management of the visible scene requires efficient access to the terrain database. We describe an all-in-one visualization system which integrates adaptive triangulation, dynamic scene management and spatial data handling. The triangulation model is based on the restricted quadtree triangulation. Furthermore, we present new algorithms of restricted quadtree triangulation. These include among others exact error approximation, progressive meshing, performance enhancements and spatial access.\\\",\\\"Authors\\\":\\\"Pajarola, R.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;GeographyGeospatialVisCartographyTerrainVis;ImmersiveAndVirtualEnvironments;LargeScaleDataAndScalability;ProgrammingAlgorithmsAndDataStructures;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745280\\\",\\\"Keywords\\\":\\\"terrain visualization;virtual reality;triangulated surface;computer graphics;terascale visualization;algorithm\\\",\\\"Keywords_Processed\\\":\\\"computer graphic;algorithm;terascale visualization;terrain visualization;triangulate surface;virtual reality\\\",\\\"Title\\\":\\\"Large scale terrain visualization using the restricted quadtree triangulation\\\"},\\\"381\\\":{\\\"Abstract\\\":\\\"In this article, we build a multi-resolution framework intended to be used for the visualization of continuous piecewise linear functions defined over triangular planar or spherical meshes. In particular, the data set can be viewed at different level of detail, that's to say as a piecewise linear function defined over any simplification of the base mesh. In his multi-resolution form, the function requires strictly the same volume of data than the original input: It is then possible to go through consecutive levels by the use of so-called detail coefficients, with exact reconstruction if desired. We also show how to choose a decimation sequence that leads to a good compromise between the resulting approximation error and the number of removed vertices. The theoretical tools used here are inspired from wavelet-based techniques and extended in the sense that they can handle non-nested approximation spaces.\\\",\\\"Authors\\\":\\\"Bonneau, G.-P.;Gerussi, A.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;MeshesGridsAndLattices;NumericalMethodsMathematics;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745287\\\",\\\"Keywords\\\":\\\"visualization;compression;wavelets;non-regular triangulations\\\",\\\"Keywords_Processed\\\":\\\"visualization;non regular triangulation;wavelet;compression\\\",\\\"Title\\\":\\\"Level of detail visualization of scalar data sets on irregular surface meshes\\\"},\\\"382\\\":{\\\"Abstract\\\":\\\"To gain insight and understanding of complex information collections, users must be able to visualize and explore many facets of the information. The paper presents several novel visual methods from an information analyst's perspective. The authors present a sample scenario, using the various methods to gain a variety of insights from a large information collection. They conclude that no single paradigm or visual method is sufficient for many analytical tasks. Often a suite of integrated methods offers a better analytic environment in today's emerging culture of information overload and rapidly changing issues. They also conclude that the interactions among these visual paradigms are equally as important as, if not more important than, the paradigms themselves\\\",\\\"Authors\\\":\\\"Hetzler, E.;Whitney, P.;Martucci, L.;Thomas, J.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;TasksTaskRequirementsAnalysis;TextDocumentTopicAnalysisDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1998.729570\\\",\\\"Keywords\\\":\\\"information analysis;user scenario;information visualization;document analysis\\\",\\\"Keywords_Processed\\\":\\\"information analysis;user scenario;document analysis;information visualization\\\",\\\"Title\\\":\\\"Multi-faceted insight through interoperable visual information analysis paradigms\\\"},\\\"383\\\":{\\\"Abstract\\\":\\\"Rendering objects transparently gives additional insight in complex and overlapping structures. However, traditional techniques for the rendering of transparent objects such as alpha blending are not very well suited for the rendering of multiple transparent objects in dynamic scenes. Screen door transparency is a technique to render transparent objects in a simple and efficient way: no sorting is required and intersecting polygons can be handled without further preprocessing. With this technique, polygons are rendered through a mask: only where the mask is present, pixels are set. However, artifacts such as incorrect opacities and distracting patterns can easily occur if the masks are not carefully designed. The requirements on the masks are considered. Next, three algorithms are presented for the generation of pixel masks. One algorithm is designed for the creation of small (e.g. 44) masks. The other two algorithms can be used for the creation of larger masks (e.g. 3232). For each of these algorithms, results are presented and discussed.\\\",\\\"Authors\\\":\\\"Mulder, J.D.;Groen, F.C.A.;van Wijk, J.J.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745323\\\",\\\"Keywords\\\":\\\"screen-door transparency\\\",\\\"Keywords_Processed\\\":\\\"screen door transparency\\\",\\\"Title\\\":\\\"Pixel masks for screen-door transparency\\\"},\\\"384\\\":{\\\"Abstract\\\":\\\"The paper describes some fundamental issues for robust implementations of progressively refined tetrahedralizations generated through sequences of edge collapses. We address the definition of appropriate cost functions and explain on various tests which are necessary to preserve the consistency of the mesh when collapsing edges. Although considered a special case of progressive simplicial complexes (J. Popovic and H. Hoppe, 1997), the results of our method are of high practical importance and can be used in many different applications, such as finite element meshing, scattered data interpolation, or rendering of unstructured volume data.\\\",\\\"Authors\\\":\\\"Staadt, O.;Gross, M.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;LevelOfDetail;MeshesGridsAndLattices;MultiresolutionTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745329\\\",\\\"Keywords\\\":\\\"multi-resolution;level-of-detail;mesh simplification;mesh generation;unstructured meshes\\\",\\\"Keywords_Processed\\\":\\\"mesh generation;multi resolution;unstructured mesh;level of detail;mesh simplification\\\",\\\"Title\\\":\\\"Progressive tetrahedralizations\\\"},\\\"385\\\":{\\\"Abstract\\\":\\\"Visualization of three-dimensional steady flow has to overcome a lot of problems to be effective. Among them are occlusion of distant details, lack of directional and depth hints and occlusion. We present methods which address these problems for real-time graphic representations applicable in virtual environments. We use dashtubes, i.e., animated, opacity-mapped streamlines, as a visualization icon for 3D-flow visualization. We present a texture mapping technique to keep the level of texture detail along a streamline nearly constant even when the velocity of the flow varies considerably. An algorithm is described which distributes the dashtubes evenly in space. We apply magic lenses and magic boxes as interaction techniques for investigating densely filled areas without overwhelming the observer with visual detail. Implementation details of these methods and their integration in our virtual environment conclude the paper.\\\",\\\"Authors\\\":\\\"Fuhrmann, A.;Groller, E.\\\",\\\"Clusters\\\":\\\"Cognition;FlowVisualizationDataAndTechniques;ImmersiveAndVirtualEnvironments;InteractionTechniquesGeneral;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745317\\\",\\\"Keywords\\\":\\\"flow visualization;virtual environment;focussing;texturing;magic lens;interaction\\\",\\\"Keywords_Processed\\\":\\\"virtual environment;interaction;magic lens;texture;focusse;flow visualization\\\",\\\"Title\\\":\\\"Real-time techniques for 3D flow visualization\\\"},\\\"386\\\":{\\\"Abstract\\\":\\\"We present a new visualization technique, called RDT (Reconfigurable Disc Tree) which can alleviate the disadvantages of cone trees significantly for large hierarchies while maintaining its context of using 3D depth. In RDT, each node is associated with a disc, around which its children are placed. Using discs instead of cones as the basic shape in RDT has several advantages: significant reduction of occluded region, sharp increase in number of displayed nodes, and easy projection onto plane without visual overlapping. We show that RDT can greatly enhance user perception by transforming its shapes dynamically in several ways: (1) disc tree which can significantly reduce the occluded region by the foreground objects; (2) compact disc tree which can increase the number of nodes displayed on the screen; and (3) plane disc tree which can be mapped onto the plane without visual overlapping. We describe an implementation of our visualization system called VISIT (Visual Information System for reconfigurable dIsc tree). It provides 2D and 3D layouts for RDT and various user interface features such as tree reconfiguration, tree transformation, tree shading, viewing transformation, animation, selection and browsing which can enhance the user perception and navigation capabilities. We also evaluate our system using the following three metrics: percentage of occlusion, density of displayed nodes on a screen, and number of identifiable nodes\\\",\\\"Authors\\\":\\\"Chang-Sung Jeong;Pang, A.\\\",\\\"Clusters\\\":\\\"HierarchicalTreeDataAndTechniques;ProgrammingAlgorithmsAndDataStructures;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1998.729555\\\",\\\"Keywords\\\":\\\"information visualization;hierarchy;disc tree;compact disc tree;plane disc tree\\\",\\\"Keywords_Processed\\\":\\\"compact disc tree;hierarchy;information visualization;plane disc tree;disc tree\\\",\\\"Title\\\":\\\"Reconfigurable disc trees for visualizing large hierarchical information space\\\"},\\\"387\\\":{\\\"Abstract\\\":\\\"We present a method for the construction of multiple levels of tetrahedral meshes approximating a trivariate function at different levels of detail. Starting with an initial, high-resolution triangulation of a three-dimensional region, we construct coarser representation levels by collapsing tetrahedra. Each triangulation defines a linear spline function, where the function values associated with the vertices are the spline coefficients. Based on predicted errors, we collapse tetrahedron in the grid that do not cause the maximum error to exceed a use-specified threshold. Bounds are stored for individual tetrahedra and are updated as the mesh is simplified. We continue the simplification process until a certain error is reached. The result is a hierarchical data description suited for the efficient visualization of large data sets at varying levels of detail.\\\",\\\"Authors\\\":\\\"Trotts, I.J.;Hamann, B.;Joy, K.I.;Wiley, D.F.\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;CurvesAndCurvature;DataFeaturesAndAttributes;GeometricModeling;HierarchicalTreeDataAndTechniques;MeshesGridsAndLattices;MultiresolutionTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745315\\\",\\\"Keywords\\\":\\\"triangulation;spline;visualization;approximation;hierarchical representation;mesh generation;multi-resolution method;scattered data\\\",\\\"Keywords_Processed\\\":\\\"visualization;mesh generation;multi resolution method;scatter datum;triangulation;hierarchical representation;approximation;spline\\\",\\\"Title\\\":\\\"Simplification of tetrahedral meshes\\\"},\\\"388\\\":{\\\"Abstract\\\":\\\"There are a variety of application areas in which there is a need for simplifying complex polygonal surface models. These models often have material properties such as colors, textures, and surface normals. Our surface simplification algorithm, based on iterative edge contraction and quadric error metrics, can rapidly produce high quality approximations of such models. We present a natural extension of our original error metric that can account for a wide range of vertex attributes.\\\",\\\"Authors\\\":\\\"Garland, M.;Heckbert, P.S.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;GeometricModeling;LevelOfDetail;MultiresolutionTechniques;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745312\\\",\\\"Keywords\\\":\\\"surface simplification;multi-resolution modeling;discontinuity preservation;quadric error metrics;level-of-detail;edge contraction;surface properties\\\",\\\"Keywords_Processed\\\":\\\"edge contraction;surface property;multi resolution modeling;discontinuity preservation;level of detail;quadric error metric;surface simplification\\\",\\\"Title\\\":\\\"Simplifying surfaces with color and texture using quadric error metrics\\\"},\\\"389\\\":{\\\"Abstract\\\":\\\"In a large number of applications, data is collected and referenced by their spatial locations. Visualizing large amounts of spatially referenced data on a limited-size screen display often results in poor visualizations due to the high degree of overplotting of neighboring datapoints. We introduce a new approach to visualizing large amounts of spatially referenced data. The basic idea is to intelligently use the unoccupied pixels of the display instead of overplotting data points. After formally describing the problem, we present two solutions which are based on: placing overlapping data points on the nearest unoccupied pixel; and shifting data points along a screen-filling curve (e.g., Hilbert-curve). We then develop a more sophisticated approach called Gridfit, which is based on a hierarchical partitioning of the data space. We evaluate all three approaches with respect to their efficiency and effectiveness and show the superiority of the Gridfit approach. For measuring the effectiveness, we not only present the resulting visualizations but also introduce mathematical effectiveness criteria measuring properties of the generated visualizations with respect to the original data such as distance- and position-preservation.\\\",\\\"Authors\\\":\\\"Keim, D.A.;Herrmann, A.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;LargeScaleDataAndScalability;SpaceRelatedSpatialDataAndTechniques;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745301\\\",\\\"Keywords\\\":\\\"geographic visualization;visualizing spatially referenced data;interfaces to databases;large data visualization\\\",\\\"Keywords_Processed\\\":\\\"large datum visualization;geographic visualization;visualize spatially reference datum;interface to database\\\",\\\"Title\\\":\\\"The Gridfit algorithm: an efficient and effective approach to visualizing large amounts of spatial data\\\"},\\\"390\\\":{\\\"Abstract\\\":\\\"Information visualization focuses on the use of visual means for exploring non-visual information. While free-form text is a rich, common source of information, visualization of text is a challenging problem since text is inherently non-spatial. The paper explores the use of implicit surface models for visualizing text. The authors describe several techniques for text visualization that aid in understanding document content and document relationships. A simple method is defined for mapping document content to shape. By comparing the shapes of multiple documents, global content similarities and differences may be noted. In addition, they describe a visual clustering method in which documents are arranged in 3D based upon similarity scoring. Documents deemed closely related blend together as a single connected shape. Hence, a document corpus becomes a collection of shapes that reflect inter-document relationships. These techniques provide methods to visualize individual documents as well as corpus meta-data. They then combine the two techniques to produce transparent clusters enclosing individual document shapes. This provides a way to visualize both local and global contextual information. Finally, they elaborate on several potential applications of these methods\\\",\\\"Authors\\\":\\\"Rohrer, R.M.;Ebert, D.S.;Sibert, J.L.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;DataClusteringAndAggregation;DatabasesAndDataMining;GeometricModeling;SurfaceRelatedDataAndTechniques;TextDocumentTopicAnalysisDataAndTechniques;UserInterfacesGeneral;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1998.729568\\\",\\\"Keywords\\\":\\\"information visualization;user interface;information retrieval;blobby models;document clustering;text visualization;graphics;procedural visualization;implicit surface modeling\\\",\\\"Keywords_Processed\\\":\\\"text visualization;user interface;information retrieval;procedural visualization;blobby model;information visualization;document clustering;graphic;implicit surface model\\\",\\\"Title\\\":\\\"The shape of Shakespeare: visualizing text using implicit surfaces\\\"},\\\"391\\\":{\\\"Abstract\\\":\\\"We present a novel approach to visualize and explore unstructured text. The underlying technology, called TOPIC-O-GRAPHY TM, applies wavelet transforms to a custom digital signal constructed from words within a document. The resultant multiresolution wavelet energy is used to analyze the characteristics of the narrative flow in the frequency domain, such as theme changes, which is then related to the overall thematic content of the text document using statistical methods. The thematic characteristics of a document can be analyzed at varying degrees of detail, ranging from section-sized text partitions to partitions consisting of a few words. Using this technology, we are developing a visualization system prototype known as TOPIC ISLANDS to browse a document, generate fuzzy document outlines, summarize text by levels of detail and according to user interests, define meaningful subdocuments, query text content, and provide summaries of topic evolution.\\\",\\\"Authors\\\":\\\"Miller, N.;Pak Chung Wong;Brewster, M.;Foote, H.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;ImageBasedDataImageSignalProcessing;TextDocumentTopicAnalysisDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745302\\\",\\\"Keywords\\\":\\\"text visualization;information visualization;wavelet transform;information retrieval\\\",\\\"Keywords_Processed\\\":\\\"information retrieval;text visualization;information visualization;wavelet transform\\\",\\\"Title\\\":\\\"TOPIC ISLANDS TM - a wavelet-based text visualization system\\\"},\\\"392\\\":{\\\"Abstract\\\":\\\"3D time-varying unstructured and structured data sets are difficult to visualize and analyze because of the immense amount of data involved. These data sets contain many evolving amorphous regions, and standard visualization techniques provide no facilities to aid the scientist to follow regions of interest. In this paper, we present a basic framework for the visualization of time-varying data sets, and a new algorithm and data structure to track volume features in unstructured scalar data sets. The algorithm and data structure are general and can be used for structured, curvilinear, adaptive and hybrid grids as well. The features tracked can be any type of connected regions. Examples are shown from ongoing research.\\\",\\\"Authors\\\":\\\"Silver, D.;Wang, X.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;ImageBasedDataImageSignalProcessing;TimeseriesTimeVaryingDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745288\\\",\\\"Keywords\\\":\\\"computer vision;computational fluid dynamics;feature tracking;scientific visualization;time-varying visualization\\\",\\\"Keywords_Processed\\\":\\\"scientific visualization;time vary visualization;feature tracking;computer vision;computational fluid dynamic\\\",\\\"Title\\\":\\\"Tracking scalar features in unstructured datasets\\\"},\\\"393\\\":{\\\"Abstract\\\":\\\"Scalar fields arise in every scientific application. Existing scalar visualization techniques require that the user infers the global scalar structure from what is frequently an insufficient display of information. We present a visualization technique which numerically detects the structure at all scales, removing from the user the responsibility of extracting information implicit in the data, and presenting the structure explicitly for analysis. We further demonstrate how scalar topology detection proves useful for correct visualization and image processing applications such as image co-registration, isocontouring, and mesh compression.\\\",\\\"Authors\\\":\\\"Bajaj, C.L.;Pascucci, V.;Schikore, D.R.\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;ScalarFieldDataTechniques;TopologyBasedTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745284\\\",\\\"Keywords\\\":\\\"scientific visualization;curves and surfaces;scalar fields;vector topology\\\",\\\"Keywords_Processed\\\":\\\"scientific visualization;curve and surface;scalar field;vector topology\\\",\\\"Title\\\":\\\"Visualization of scalar topology for structural enhancement\\\"},\\\"394\\\":{\\\"Abstract\\\":\\\"This paper discusses techniques for visualizing structure in video data and other data sets that represent time snapshots of physical phenomena. Individual frames of a movie are treated as vectors and projected onto a low-dimensional subspace spanned by principal components. Movies can be compared and their differences visualized by analyzing the nature of the subspace and the projections of multiple movies onto the same subspace. The approach is demonstrated on an application in neurobiology in which the electrical response of a visual cortex to optical stimulation is imaged onto a high-speed photodiode array to produce a cortical movie. Techniques for sampling movies over a single trial and multiple trials are discussed. The approach provides the traditional benefits of principal component analysis (compression, noise reduction and classification) and also allows the visual separation of spatial and temporal behavior.\\\",\\\"Authors\\\":\\\"Robbins, K.A.;Senseman, D.M.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;MultimediaImageVideoMusic;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745306\\\",\\\"Keywords\\\":\\\"animation;video analysis;scientific visualization\\\",\\\"Keywords_Processed\\\":\\\"scientific visualization;video analysis;animation\\\",\\\"Title\\\":\\\"Visualizing differences in movies of cortical activity\\\"},\\\"395\\\":{\\\"Abstract\\\":\\\"Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.\\\",\\\"Authors\\\":\\\"Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.\\\",\\\"Clusters\\\":\\\"ArtAndAestheticsInVisualization;MultidimensionalMultivariateMultifieldDataAndTechniques;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1998.745294\\\",\\\"Keywords\\\":\\\"oil painting;multi-valued visualization;tensor field visualization\\\",\\\"Keywords_Processed\\\":\\\"oil painting;multi value visualization;tensor field visualization\\\",\\\"Title\\\":\\\"Visualizing diffusion tensor images of the mouse spinal cord\\\"},\\\"396\\\":{\\\"Abstract\\\":\\\"A number of usability studies report that many users of the WWW cannot find pages already visited, additionally many users cannot visualise where they are, or where they have been browsing. Currently, readily available WWW browsers provide history mechanisms that offer little or no support in the presentation and manipulation of visited sites. Manipulation and presentation of usage data, such as a browse history has been used in a number of cases to aid users in searching for previously attained data, and to teach or assist other users in their browse or searching techniques. The paper presents a virtual reality (VR) based application to be used alongside traditional Web browsers, which provides them with a flexibly tailorable real time visualisation of their history\\\",\\\"Authors\\\":\\\"Frecon, E.;Smith, G.\\\",\\\"Clusters\\\":\\\"ImmersiveAndVirtualEnvironments;InternetWebVisualizationForTheMasses;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1998.729553\\\",\\\"Keywords\\\":\\\"virtual environment;visualization;web browsing;world wide web\\\",\\\"Keywords_Processed\\\":\\\"virtual environment;world wide web;web browsing;visualization\\\",\\\"Title\\\":\\\"WEBPATH-a three dimensional Web history\\\"},\\\"397\\\":{\\\"Abstract\\\":\\\"The task of reconstructing the derivative of a discrete function is essential for its shading and rendering as well as being widely used in image processing and analysis. We survey the possible methods for normal estimation in volume rendering and divide them into two classes based on the delivered numerical accuracy. The three members of the first class determine the normal in two steps by employing both interpolation and derivative filters. Among these is a new method which has never been realized. The members of the first class are all equally accurate. The second class has only one member and employs a continuous derivative filter obtained through the analytic derivation of an interpolation filter. We use the new method to analytically compare the accuracy of the first class with that of the second. As a result of our analysis we show that even inexpensive schemes can in fact be more accurate than high order methods. We describe the theoretical computational cost of applying the schemes in a volume rendering application and provide guidelines for helping one choose a scheme for estimating derivatives. In particular we find that the new method can be very inexpensive and can compete with the normal estimations which pre-shade and pre-classify the volume (M. Levoy, 1988).\\\",\\\"Authors\\\":\\\"Mller, T.;Machiraju, R.;Mueller, K.;Yagel, R.\\\",\\\"Clusters\\\":\\\"FilteringTechniques;GeometricModeling;NumericalMethodsMathematics;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663848\\\",\\\"Keywords\\\":\\\"normal estimation;filter design;derivative filters;efficient volume rendering;interpolation filters;taylor series expansion\\\",\\\"Keywords_Processed\\\":\\\"efficient volume render;taylor series expansion;filter design;derivative filter;interpolation filter;normal estimation\\\",\\\"Title\\\":\\\"A comparison of normal estimation schemes\\\"},\\\"398\\\":{\\\"Abstract\\\":\\\"Previous accelerated volume rendering techniques have used auxiliary hierarchical datastructures to skip empty and homogeneous regions. Although some recent research has taken advantage of more efficient direct encoding techniques to skip empty regions, no work has been done to directly encode homogeneous but not empty regions. 3D distance transforms previously used to encode empty space can be extended to preprocess homogeneous regions as well, and these regions can be efficiently encoded and incorporated into volume ray-casting and back projection algorithms with a high degree of flexibility.\\\",\\\"Authors\\\":\\\"Freund, J.;Sloan, K.\\\",\\\"Clusters\\\":\\\"RaytracingRaycasting;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663880\\\",\\\"Keywords\\\":\\\"volume rendering;raycasting\\\",\\\"Keywords_Processed\\\":\\\"volume render;raycaste\\\",\\\"Title\\\":\\\"Accelerated volume rendering using homogeneous region encoding\\\"},\\\"399\\\":{\\\"Abstract\\\":\\\"Splatting is a popular direct volume rendering algorithm. However, the algorithm does not correctly render cases where the volume sampling rate is higher than the image sampling rate (e.g. more than one voxel maps into a pixel). This situation arises with orthographic projections of high-resolution volumes, as well as with perspective projections of volumes of any resolution. The result is potentially severe spatial and temporal aliasing artifacts. Some volume ray-casting algorithms avoid these artifacts by employing reconstruction kernels which vary in width as the rays diverge. Unlike ray-casting algorithms, existing splatting algorithms do not have an equivalent mechanism for avoiding these artifacts. The authors propose such a mechanism, which delivers high-quality splatted images and has the potential for a very efficient hardware implementation.\\\",\\\"Authors\\\":\\\"Swan, J.E.;Mueller, K.;Moller, T.;Shareel, N.;Crawfis, R.;Yagel, R.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;ComputerGraphicsTechniquesGeneral;Interpolation;Sampling;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663882\\\",\\\"Keywords\\\":\\\"splatting;volume rendering;reconstruction;perspective projection;resampling;direct volume rendering;antialiasing\\\",\\\"Keywords_Processed\\\":\\\"volume render;antialiase;perspective projection;reconstruction;direct volume render;resample;splatte\\\",\\\"Title\\\":\\\"An anti-aliasing technique for splatting\\\"},\\\"400\\\":{\\\"Abstract\\\":\\\"An interactive cerebral blood vessel exploration system is described. It has been designed on the basis of neurosurgeons' requirements in order to assist them in the diagnosis of vascular pathologies. The system is based on the construction of a symbolic model of the vascular tree, with automatic identification and labelling of vessel bifurcations, aneurysms and stenoses. It provides several types of visualization: individual MRA (magnetic resonance angiography) slices, MIP (maximum intensity projection), shaded rendering, symbolic schemes and surface reconstruction.\\\",\\\"Authors\\\":\\\"Puig, A.;Tost, D.;Navazo, I.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663917\\\",\\\"Keywords\\\":\\\"medical applications;volume modelling and rendering;cerebral blood vessel\\\",\\\"Keywords_Processed\\\":\\\"medical application;cerebral blood vessel;volume model and render\\\",\\\"Title\\\":\\\"An interactive cerebral blood vessel exploration system\\\"},\\\"401\\\":{\\\"Abstract\\\":\\\"In the area of scientific visualization, input data sets are often very large. In visualization of computational fluid dynamics (CFD) in particular, input data sets today can surpass 100 Gbytes, and are expected to scale with the ability of supercomputers to generate them. Some visualization tools already partition large data sets into segments, and load appropriate segments as they are needed. However, this does not remove the problem for two reasons: 1) there are data sets for which even the individual segments are too large for the largest graphics workstations, 2) many practitioners do not have access to workstations with the memory capacity required to load even a segment, especially since the state-of-the-art visualization tools tend to be developed by researchers with much more powerful machines. When the size of the data that must be accessed is larger than the size of memory, some form of virtual memory is simply required. This may be by segmentation, paging, or by paged segments. The authors demonstrate that complete reliance on operating system virtual memory for out-of-core visualization leads to egregious performance. They then describe a paged segment system that they have implemented, and explore the principles of memory management that can be employed by the application for out-of-core visualization. They show that application control over some of these can significantly improve performance. They show that sparse traversal can be exploited by loading only those data actually required.\\\",\\\"Authors\\\":\\\"Cox, M.;Ellsworth, D.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;OutOfCoreProcessing;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663888\\\",\\\"Keywords\\\":\\\"visualization;computational fluid dynamics;out-of-core visualization\\\",\\\"Keywords_Processed\\\":\\\"visualization;out of core visualization;computational fluid dynamic\\\",\\\"Title\\\":\\\"Application-controlled demand paging for out-of-core visualization\\\"},\\\"402\\\":{\\\"Abstract\\\":\\\"This paper outlines a method to dynamically replace portals with textures in a cell-partitioned model. The rendering complexity is reduced to the geometry of the current cell thus increasing interactive performance. A portal is a generalization of windows and doors. It connects two adjacent cells (or rooms). Each portal of the current cell that is some distance away from the viewpoint is rendered as a texture. The portal texture (smoothly) returns to geometry when the viewpoint gets close to the portal. This way all portal sequences (not too close to the viewpoint) have a depth complexity of one. The size of each texture and distance at which the transition occurs is configurable for each portal.\\\",\\\"Authors\\\":\\\"Aliaga, D.;Lastra, A.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;CamerasCameraViewsAndProjections;InternetWebVisualizationForTheMasses;Sampling;Textures;TransitionsAndMorphing\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663903\\\",\\\"Keywords\\\":\\\"morphing;cells;visibility culling;portals;sample points;texture\\\",\\\"Keywords_Processed\\\":\\\"cell;portal;texture;sample point;visibility cull;morph\\\",\\\"Title\\\":\\\"Architectural walkthroughs using portal textures\\\"},\\\"403\\\":{\\\"Abstract\\\":\\\"We present collaborative scientific visualization in STUDIERSTUBE. STUDIERSTUBE is an augmented reality system that has several advantages over conventional desktop and other virtual reality environments, including true stereoscopy, 3D-interaction, individual viewpoints and customized views for multiple users, unhindered natural collaboration and low cost. We demonstrate the application of this concept for the interaction of multiple users and illustrate it with several visualizations of dynamical systems in DynSys3D, a visualization system running on top of AVS.\\\",\\\"Authors\\\":\\\"Fuhrmann, A.;Loffelmann, H.;Schmalstieg, D.\\\",\\\"Clusters\\\":\\\"DynamicVisualizationVisualizationOfChange;ImmersiveAndVirtualEnvironments;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663921\\\",\\\"Keywords\\\":\\\"virtual environment;scientific visualization;augmented reality;dynamical systems\\\",\\\"Keywords_Processed\\\":\\\"virtual environment;dynamical system;augmented reality;scientific visualization\\\",\\\"Title\\\":\\\"Collaborative augmented reality: exploring dynamical systems\\\"},\\\"404\\\":{\\\"Abstract\\\":\\\"We propose a probability model for the handling of complicated interactions between volumetric objects. In our model each volume is associated with a \\\\\\\"probability map\\\\\\\" that assigns a \\\\\\\"surface crossing\\\\\\\" probability to each space point according to local volume properties. The interaction between two volumes is then described by finding the intersecting regions between the volumes, and calculating the \\\\\\\"collision probabilities\\\\\\\" at each intersecting point from the surface crossing probabilities. To enable fast and efficient calculations, we introduce the concept of a distance map and develop two hierarchical collision detection algorithms, taking advantage of the uniform structure of volumetric datasets.\\\",\\\"Authors\\\":\\\"Taosong He;Kaufman, A.\\\",\\\"Clusters\\\":\\\"HierarchicalTreeDataAndTechniques;ImmersiveAndVirtualEnvironments;Maps;NumericalMethodsMathematics;ProgrammingAlgorithmsAndDataStructures;SurfaceRelatedDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663851\\\",\\\"Keywords\\\":\\\"surface crossing probability;volume rendering;virtual reality;volumetric collision;collision probability;octree;sphere tree;volume visualization;distance map;volume graphics\\\",\\\"Keywords_Processed\\\":\\\"volume render;virtual reality;octree;sphere tree;volume graphic;collision probability;surface cross probability;volume visualization;volumetric collision;distance map\\\",\\\"Title\\\":\\\"Collision detection for volumetric objects\\\"},\\\"405\\\":{\\\"Abstract\\\":\\\"Navigation through 3D spaces is required in many interactive graphics and virtual reality applications. The authors consider the subclass of situations in which a 2D device such as a mouse controls smooth movements among viewpoints for a \\\\\\\"through the screen\\\\\\\" display of a 3D world. Frequently, there is a poor match between the goal of such a navigation activity, the control device, and the skills of the average user. They propose a unified mathematical framework for incorporating context-dependent constraints into the generalized viewpoint generation problem. These designer-supplied constraint modes provide a middle ground between the triviality of a single camera animation path and the confusing excess freedom of common unconstrained control paradigms. They illustrate the approach with a variety of examples, including terrain models, interior architectural spaces, and complex molecules.\\\",\\\"Authors\\\":\\\"Hanson, A.J.;Wernert, E.A.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;ViewDependentVisualization;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663876\\\",\\\"Keywords\\\":\\\"viewing control;navigation;constrained navigation;camera control\\\",\\\"Keywords_Processed\\\":\\\"navigation;camera control;view control;constrain navigation\\\",\\\"Title\\\":\\\"Constrained 3D navigation with 2D controllers\\\"},\\\"406\\\":{\\\"Abstract\\\":\\\"A dynamic query interface (DQI) is a database access mechanism that provides continuous real-time feedback to the user during query formulation. Previous work shows that DQIs are elegant and powerful interfaces to small databases. Unfortunately, when applied to large databases, previous DQI algorithms slow to a crawl. We present a new incremental approach to DQI algorithms and display updates that work well with large databases, both in theory and in practice.\\\",\\\"Authors\\\":\\\"Tanin, E.;Beigel, R.;Shneiderman, B.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;InteractionTechniquesGeneral;ProgrammingAlgorithmsAndDataStructures;QueriesAndSearch;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1997.636790\\\",\\\"Keywords\\\":\\\"information visualization;user interface;dynamic query;database;data structures;algorithm;direct manipulation\\\",\\\"Keywords_Processed\\\":\\\"database;user interface;dynamic query;information visualization;algorithm;data structure;direct manipulation\\\",\\\"Title\\\":\\\"Design and evaluation of incremental data structures and algorithms for dynamic query interfaces\\\"},\\\"407\\\":{\\\"Abstract\\\":\\\"Recursive subdivision schemes have been extensively used in computer graphics and scientific visualization for modeling smooth surfaces of arbitrary topology. Recursive subdivision generates a visually pleasing smooth surface in the limit from an initial user-specified polygonal mesh through the repeated application of a fixed set of subdivision rules. In this paper, we present a new dynamic surface model based on the Catmull-Clark (1978) subdivision scheme, which is a very popular method to model complicated objects of arbitrary genus because of many of its nice properties. Our new dynamic surface model inherits the attractive properties of the Catmull-Clark subdivision scheme as well as that of the physics-based modeling paradigm. This new model provides a direct and intuitive means of manipulating geometric shapes, a fast, robust and hierarchical approach for recovering complex geometric shapes from range and volume data using very few degrees of freedom (control vertices). We provide an analytic formulation and introduce the physical quantities required to develop the dynamic subdivision surface model which can be interactively deformed by applying synthesized forces in real time. The governing dynamic differential equation is derived using Lagrangian mechanics and a finite element discretization. Our experiments demonstrate that this new dynamic model has a promising future in computer graphics, geometric shape design and scientific visualization.\\\",\\\"Authors\\\":\\\"Mandal, C.;Hong Qin;Vemuri, B.C.\\\",\\\"Clusters\\\":\\\"DynamicDataAndTechniques;GeometricModeling;InteractionTechniquesGeneral;NumericalMethodsMathematics;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663905\\\",\\\"Keywords\\\":\\\"subdivision surfaces;visualization;finite elements;dynamics;interactive techniques\\\",\\\"Keywords_Processed\\\":\\\"visualization;dynamic;subdivision surface;finite element;interactive technique\\\",\\\"Title\\\":\\\"Dynamic smooth subdivision surfaces for data visualization\\\"},\\\"408\\\":{\\\"Abstract\\\":\\\"The paper discusses the problem of subdividing unstructured mesh topologies containing hexahedra, prisms, pyramids and tetrahedra into a consistent set of only tetrahedra, while preserving the overall mesh topology. Efficient algorithms for volume rendering, iso-contouring and particle advection exist for mesh topologies comprised solely of tetrahedra. General finite-element simulations however, consist mainly of hexahedra, and possibly prisms, pyramids and tetrahedra. Arbitrary subdivision of these mesh topologies into tetrahedra can lead to discontinuous behaviour across element faces. This will show up as visible artifacts in the iso-contouring and volume rendering algorithms, and lead to impossible face adjacency graphs for many algorithms. The authors present various properties of tetrahedral subdivisions, and an algorithm SOP determining a consistent subdivision containing a minimal set of tetrahedra.\\\",\\\"Authors\\\":\\\"Albertelli, G.;Crawfis, R.\\\",\\\"Clusters\\\":\\\"EvaluationMetricsAndBenchmarks;FlowVisualizationDataAndTechniques;IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663885\\\",\\\"Keywords\\\":\\\"flow visualization;volume rendering;mesh subdivision;irregular grids;metrics;isosurface;tetrahedralization\\\",\\\"Keywords_Processed\\\":\\\"volume render;irregular grid;metric;tetrahedralization;isosurface;mesh subdivision;flow visualization\\\",\\\"Title\\\":\\\"Efficient subdivision of finite-element datasets into consistent tetrahedra\\\"},\\\"409\\\":{\\\"Abstract\\\":\\\"Modular visualization environments (MVEs) have recently been regarded as the de facto standard for scientific data visualization, mainly due to adoption of the visual programming style, reusability, and extendability. However, since scientists and engineers as the MVE principal user are not always familiar with how to map numerical data to proper graphical primitives, the set of built-in modules is not fully used to construct necessary application networks. Therefore, a certain mechanism needs to be incorporated into MVEs, which makes use of heuristics and expertise of visualization specialists (visineers), and which supports the user in designing his/her applications with MVEs. The Wehrend's goal-oriented taxonomy of visualization techniques is adopted as the basic philosophy to develop a system, called GADGET, for application design guidance for MVEs. The GADGET system interactively helps the user design appropriate applications according to the specific visualization goals, temporal efficiency versus accuracy requirements, and such properties as dimension and mesh type of a given target dataset. Also the GADGET system is capable of assisting the user in customizing a prototype modular network for his/her desired applications by showing execution examples involving datasets of the same type. The paper provides an overview of the GADGET guidance mechanism and system architecture, with an emphasis on its knowledge base design. Sample data visualization problems are used to demonstrate the usefulness of the GADGET system.\\\",\\\"Authors\\\":\\\"Fujishiro, I.;Takeshima, Y.;Ichikawa, Y.;Nakamura, K.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;ProgrammingAlgorithmsAndDataStructures;Taxonomies;VisualKnowledgeRepresentationAndExternalization;VisualizationSystemsToolkitsAndEnvironments;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663889\\\",\\\"Keywords\\\":\\\"modular visualization environments;visualization systems;taxonomy of visualization techniques;object-oriented design;knowledge base;data-flow paradigm;visineers' heuristics and expertise\\\",\\\"Keywords_Processed\\\":\\\"taxonomy of visualization technique;visualization system;object orient design;datum flow paradigm;modular visualization environment;visineer heuristic and expertise;knowledge base\\\",\\\"Title\\\":\\\"GADGET: goal-oriented application design guidance for modular visualization environments\\\"},\\\"410\\\":{\\\"Abstract\\\":\\\"The authors present an image synthesis methodology and a system built around it. Given a sparse set of photographs taken from unknown viewpoints, the system generates images from new, different viewpoints with correct perspective, and handles occlusion. It achieves this without requiring any knowledge about the 3D structure of the scene nor the intrinsic camera parameters. The photo-realistic rendering process is polygon based and can be potentially implemented as real time texture mapping. The system is robust to noise by taking advantage of duplicate information from multiple views. They present results on several example scenes.\\\",\\\"Authors\\\":\\\"Qian Chen;Medioni, G.\\\",\\\"Clusters\\\":\\\"DimensionalityReduction;GeometricModeling;ImageBasedDataImageSignalProcessing;MeshesGridsAndLattices;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663892\\\",\\\"Keywords\\\":\\\"image-based rendering;projective invariant;constrained delaunay triangulation;epipolar geometry;homography\\\",\\\"Keywords_Processed\\\":\\\"image base render;projective invariant;homography;epipolar geometry;constrain delaunay triangulation\\\",\\\"Title\\\":\\\"Image synthesis from a sparse set of views\\\"},\\\"411\\\":{\\\"Abstract\\\":\\\"Volumetric data sets require enormous storage capacity even at moderate resolution levels. The excessive storage demands not only stress the capacity of the underlying storage and communications systems, but also seriously limit the speed of volume rendering due to data movement and manipulation. A novel volumetric data visualization scheme is proposed and implemented in this work that renders 2D images directly from compressed 3D data sets. The novelty of this algorithm is that rendering is performed on the compressed representation of the volumetric data without pre-decompression. As a result, the overheads associated with both data movement and rendering processing are significantly reduced. The proposed algorithm generalizes previously proposed whole-volume frequency-domain rendering schemes by first dividing the 3D data set into subcubes, transforming each subcube to a frequency-domain representation, and applying the Fourier projection theorem to produce the projected 2D images according to given viewing angles. Compared to the whole-volume approach, the subcube-based scheme not only achieves higher compression efficiency by exploiting local coherency, but also improves the quality of resultant rendering images because it approximates the occlusion effect on a subcube by subcube basis.\\\",\\\"Authors\\\":\\\"Tzi-cker Chiueh;Chuan-Kai Yang;Taosong He;Pfister, H.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;ImageBasedDataImageSignalProcessing;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663900\\\",\\\"Keywords\\\":\\\"fourier projection theorem;discrete hartley transform;volume compression;image compositing\\\",\\\"Keywords_Processed\\\":\\\"image compositing;fouri projection theorem;volume compression;discrete hartley transform\\\",\\\"Title\\\":\\\"Integrated volume compression and visualization\\\"},\\\"412\\\":{\\\"Abstract\\\":\\\"3D virtual colonoscopy has recently been proposed as a non-invasive alternative procedure for the visualization of the human colon. Surface rendering is sufficient for implementing such a procedure to obtain an overview of the interior surface of the colon at interactive rendering speeds. Unfortunately, physicians can not use it to explore tissues beneath the surface to differentiate between benign and malignant structures. In this paper, we present a direct volume rendering approach based on perspective ray casting, as a supplement to the surface navigation. To accelerate the rendering speed, surface-assistant techniques are used to adapt the resampling rates by skipping the empty space inside the colon. In addition, a parallel version of the algorithm has been implemented on a shared-memory multiprocessing architecture. Experiments have been conducted on both simulation and patient data sets.\\\",\\\"Authors\\\":\\\"Suya You;Lichan Hong;Wan, M.;Junyaprasert, K.;Kaufman, A.;Muraki, S.;Yong Zhou;Wax, M.;Zhengrong Liang\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;CamerasCameraViewsAndProjections;ImmersiveAndVirtualEnvironments;ParallelSystemsAndParallelProcessing;SurfaceRelatedDataAndTechniques;VolumeRenderingModelingAndVisualization;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663915\\\",\\\"Keywords\\\":\\\"virtual environment;visibility;volume rendering;interactive navigation;endoscopy;virtual colonoscopy;parallel processing;surface rendering\\\",\\\"Keywords_Processed\\\":\\\"virtual environment;volume render;virtual colonoscopy;interactive navigation;surface render;visibility;endoscopy;parallel processing\\\",\\\"Title\\\":\\\"Interactive volume rendering for virtual colonoscopy\\\"},\\\"413\\\":{\\\"Abstract\\\":\\\"The Table Lens, focus+context visualization for large data tables, allows users to see 100 times as many data values as a spreadsheet in the same screen space in a manner that enables an extremely immediate form of exploratory data analysis. In the original Table Lens design, data are shown in the context area using graphical representations in a single pixel row. Scaling up the Table Lens technique beyond approximately 500 cases (rows) by 40 variables (columns) requires not showing every value individually and thus raises challenges for preserving the exploratory and navigational ease and power of the original design. We describe two design enhancements for introducing regions of less than a pixel row for each data value and discuss the issues raised by each.\\\",\\\"Authors\\\":\\\"Tenev, T.;Rao, R.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1997.636787\\\",\\\"Keywords\\\":\\\"information visualization;table lens;focus+context;fisheye\\\",\\\"Keywords_Processed\\\":\\\"table lens;fisheye;information visualization;focus context\\\",\\\"Title\\\":\\\"Managing multiple focal levels in Table Lens\\\"},\\\"414\\\":{\\\"Abstract\\\":\\\"The paper presents a framework for multiresolution compression and geometric reconstruction of arbitrarily dimensioned data designed for distributed applications. Although being restricted to uniform sampled data, the versatile approach enables the handling of a large variety of real world elements. Examples include nonparametric, parametric and implicit lines, surfaces or volumes, all of which are common to large scale data sets. The framework is based on two fundamental steps: compression is carried out by a remote server and generates a bit-stream transmitted over the underlying network. Geometric reconstruction is performed by the local client and renders a piecewise linear approximation of the data. More precisely, the compression scheme consists of a newly developed pipeline starting from an initial B-spline wavelet precoding. The fundamental properties of wavelets allow progressive transmission and interactive control of the compression gain by means of global and local oracles. In particular the authors discuss the problem of oracles in semiorthogonal settings and propose sophisticated oracles to remove unimportant coefficients. In addition, geometric constraints such as boundary lines can be compressed in a lossless manner and are incorporated into the resulting bit-stream. The reconstruction pipeline performs a piecewise adaptive linear approximation of data using a fast and easy to use point removal strategy which works with any subsequent triangulation technique.\\\",\\\"Authors\\\":\\\"Staadt, O.;Gross, M.;Weber, R.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;GeometricModeling;IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices;NumericalMethodsMathematics;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663901\\\",\\\"Keywords\\\":\\\"volumes;triangulation;meshing;wavelets;oracles;isosurface;tetrahedralization\\\",\\\"Keywords_Processed\\\":\\\"triangulation;oracle;mesh;volume;tetrahedralization;isosurface;wavelet\\\",\\\"Title\\\":\\\"Multiresolution compression and reconstruction\\\"},\\\"415\\\":{\\\"Abstract\\\":\\\"The authors present a multiresolution framework, called Multi-Tetra framework, that approximates volume data with different levels-of-detail tetrahedra. The framework is generated through a recursive subdivision of the volume data and is represented by binary trees. Instead of using a certain level of the Multi-Tetra framework for approximation, an error-based model (EBM) is generated by recursively fusing a sequence of tetrahedra from different levels of the Multi-Tetra framework. The EBM significantly reduces the number of voxels required to model an object, while preserving the original topology. The approach provides continuous distribution of rendered intensity or generated isosurfaces along boundaries of different levels-of-detail thus solving the crack problem. The model supports typical rendering approaches, such as marching cubes, direct volume projection, and splatting. Experimental results demonstrate the strengths of the approach.\\\",\\\"Authors\\\":\\\"Yong Zhou;Chen, B.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;LevelOfDetail;MeshesGridsAndLattices;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663869\\\",\\\"Keywords\\\":\\\"polygon simplification;isosurface extraction;multi-resolution volume;level-of-detail;volume visualization;volume subdivision\\\",\\\"Keywords_Processed\\\":\\\"multi resolution volume;isosurface extraction;polygon simplification;level of detail;volume subdivision;volume visualization\\\",\\\"Title\\\":\\\"Multiresolution tetrahedral framework for visualizing regular volume data\\\"},\\\"416\\\":{\\\"Abstract\\\":\\\"We introduce nonlinear magnification fields as an abstract representation of nonlinear magnification, providing methods for converting transformation routines to magnification fields and vice-versa. This new representation provides ease of manipulation and power of expression. By removing the restrictions of explicit foci and allowing precise specification of magnification values, we can achieve magnification effects which were not previously possible. Of particular interest are techniques we introduce for expressing complex and subtle magnification effects through magnification brushing, and allowing intrinsic properties of the data being visualized to create data-driven magnifications.\\\",\\\"Authors\\\":\\\"Keahey, T.A.;Robertson, E.L.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;FocusContextTechniques;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1997.636786\\\",\\\"Keywords\\\":\\\"information visualization;fisheye view;data mining;data-driven magnification;non-linear magnification;magnification brushing\\\",\\\"Keywords_Processed\\\":\\\"fisheye view;non linear magnification;information visualization;magnification brushing;datum mining;datum drive magnification\\\",\\\"Title\\\":\\\"Nonlinear magnification fields\\\"},\\\"417\\\":{\\\"Abstract\\\":\\\"This paper describes the SHriMP visualization technique for seamlessly exploring software structure and browsing source code, with a focus on effectively assisting hybrid program comprehension strategies. The technique integrates both pan+zoom and fisheye-view visualization approaches for exploring a nested graph view of software structure. The fisheye-view approach handles multiple focal points, which are necessary when examining several subsystems and their mutual interconnections. Source code is presented by embedding code fragments within the nodes of the nested graph. Finer connections among these fragments are represented by a network that is navigated using a hypertext link-following metaphor. SHriMP combines this hypertext metaphor with animated panning and zooming motions over the nested graph to provide continuous orientation and contextual cues for the user. The SHriMP tool is being evaluated in several user studies. Observations of users performing program understanding tasks with the tool are discussed.\\\",\\\"Authors\\\":\\\"Storey, M.;Wong, K.;Fracchia, F.D.;Muller, H.A.\\\",\\\"Clusters\\\":\\\"Cognition;FocusContextTechniques;GraphNetworkDataAndTechniques;InternetWebVisualizationForTheMasses;SoftwareVisualization;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1997.636784\\\",\\\"Keywords\\\":\\\"pan and zoom;nested graphs;fisheye view;mental map;software visualization;hypertext;program understanding\\\",\\\"Keywords_Processed\\\":\\\"nest graph;fisheye view;hypertext;pan and zoom;mental map;software visualization;program understanding\\\",\\\"Title\\\":\\\"On integrating visualization techniques for effective software exploration\\\"},\\\"418\\\":{\\\"Abstract\\\":\\\"Since 1991, our team of computer scientists, chemists and physicists have worked together to develop an advanced, virtual-environment interface to scanned-probe microscopes. The interface has provided insights and useful capabilities well beyond those of the traditional interface. This paper lists the particular visualization and control techniques that have enabled actual scientific discovery, including specific examples of insight gained using each technique. This information can help scientists determine which features are likely to be useful in their particular application, and which would be just sugar coating. It can also guide computer scientists to suggest the appropriate type of interface to help solve a particular problem. We have found benefit in advanced rendering with natural viewpoint control (but not always), from semi-automatic control techniques, from force feedback during manipulation, and from storing/replaying data for an entire experiment. These benefits come when the system is well-integrated into the existing tool and allows export of the data to standard visualization packages.\\\",\\\"Authors\\\":\\\"Taylor, R.M.;Jun Chen;Okimoto, S.;Llopis-Artime, N.;Chi, V.L.;Brooks, F.P., Jr.;Falvo, M.;Paulson, S.;Thiansathaporn, P.;Glick, D.;Washburn, S.;Superfine, R.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;ImmersiveAndVirtualEnvironments;InputAndOutputDevicesGeneral;InteractionTechniquesGeneral;Microscopy;PhysicsAndPhysicalSciences;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663923\\\",\\\"Keywords\\\":\\\"virtual environment;telepresence;teleoperation;user interface;haptics;scientific visualization;atomic force microscopy;interactive graphics;force;scanning tunneling microscopy\\\",\\\"Keywords_Processed\\\":\\\"virtual environment;scan tunneling microscopy;force;user interface;atomic force microscopy;scientific visualization;interactive graphic;haptic;teleoperation;telepresence\\\",\\\"Title\\\":\\\"Pearls found on the way to the ideal interface for scanned probe microscopes\\\"},\\\"419\\\":{\\\"Abstract\\\":\\\"The use of stream surfaces and streamlines is well established in vector visualization. However, the proper placement of starting points is critical for these constructs to clearly illustrate the flow topology. In this paper, we present the principal stream surface algorithm, which automatically generates stream surfaces that properly depict the topology of an irrotational flow. For each velocity point in the fluid field, we construct the normal to the principal stream surface through the point. The set of all such normal vectors is used to construct the principal stream function, which is a scalar field describing the direction of velocity in the fluid field. Volume rendering can then be used to visualize the principal stream function, which is directly related to the flow topology. Thus, topology in a fluid field can be easily modeled and rendered.\\\",\\\"Authors\\\":\\\"Wenli Cai;Pheng-Ann Heng\\\",\\\"Clusters\\\":\\\"FilteringTechniques;FlowVisualizationDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663859\\\",\\\"Keywords\\\":\\\"visualization;flow field;volume rendering;filtering\\\",\\\"Keywords_Processed\\\":\\\"visualization;volume render;flow field;filter\\\",\\\"Title\\\":\\\"Principal stream surfaces\\\"},\\\"420\\\":{\\\"Abstract\\\":\\\"Terrain visualization is a difficult problem for applications requiring accurate images of large datasets at high frame rates, such as flight simulation and ground-based aircraft testing using synthetic sensor simulation. On current graphics hardware, the problem is to maintain dynamic, view-dependent triangle meshes and texture maps that produce good images at the required frame rate. We present an algorithm for constructing triangle meshes that optimizes flexible view-dependent error metrics, produces guaranteed error bounds, achieves specified triangle counts directly and uses frame-to-frame coherence to operate at high frame rates for thousands of triangles per frame. Our method, dubbed Real-time Optimally Adapting Meshes (ROAM), uses two priority queues to drive split and merge operations that maintain continuous triangulations built from pre-processed bintree triangles. We introduce two additional performance optimizations: incremental triangle stripping and priority-computation deferral lists. ROAM's execution time is proportional to the number of triangle changes per frame, which is typically a few percent of the output mesh size; hence ROAM's performance is insensitive to the resolution and extent of the input terrain. Dynamic terrain and simple vertex morphing are supported.\\\",\\\"Authors\\\":\\\"Duchaineau, M.;Wolinsky, M.;Sigeti, D.E.;Miller, M.;Aldrich, C.;Mineev-Weinstein, M.B.\\\",\\\"Clusters\\\":\\\"MeshesGridsAndLattices;Optimization;Rendering;ViewDependentVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663860\\\",\\\"Keywords\\\":\\\"greedy algorithms;triangle bintree;frame-to-frame coherence;view-dependent mesh\\\",\\\"Keywords_Processed\\\":\\\"frame to frame coherence;view dependent mesh;triangle bintree;greedy algorithm\\\",\\\"Title\\\":\\\"ROAMing terrain: Real-time Optimally Adapting Meshes\\\"},\\\"421\\\":{\\\"Abstract\\\":\\\"We present the use of mapping functions to automatically generate levels of detail with known error bounds for polygonal models. We develop a piece-wise linear mapping function for each simplification operation and use this function to measure deviation of the new surface from both the previous level of detail and from the original surface. In addition, we use the mapping function to compute appropriate texture coordinates if the original map has texture coordinates at its vertices. Our overall algorithm uses edge collapse operations. We present rigorous procedures for the generation of local planar projections as well as for the selection of a new vertex position for the edge collapse operation. As compared to earlier methods, our algorithm is able to compute tight error bounds on surface deviation and produce an entire continuum of levels of detail with mappings between them. We demonstrate the effectiveness of our algorithm on several models: a Ford Bronco consisting of over 300 parts and 70,000 triangles, a textured lion model consisting of 49 parts and 86,000 triangles, and a textured, wrinkled torus consisting of 79,000 triangles.\\\",\\\"Authors\\\":\\\"Cohen, J.;Manocha, D.;Olano, M.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;DimensionalityReduction;LevelOfDetail;ProgrammingAlgorithmsAndDataStructures;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663908\\\",\\\"Keywords\\\":\\\"surface approximation;projection;level-of-detail;model simplification;linear programming\\\",\\\"Keywords_Processed\\\":\\\"model simplification;surface approximation;linear programming;level of detail;projection\\\",\\\"Title\\\":\\\"Simplifying polygonal models using successive mappings\\\"},\\\"422\\\":{\\\"Abstract\\\":\\\"Presents a new method to produce a hierarchical set of triangle meshes that can be used to blend different levels of detail in a smooth fashion. The algorithm produces a sequence of meshes M0, M1, M2..., Mn, where each mesh Mi can be transformed to mesh Mi+1 through a set of triangle-collapse operations. For each triangle, a function is generated that approximates the underlying surface in the area of the triangle, and this function serves as a basis for assigning a weight to the triangle in the ordering operation, and for supplying the point to which the triangles are collapsed. This technique allows us to view a triangulated surface model at varying levels of detail while insuring that the simplified mesh approximates the original surface well.\\\",\\\"Authors\\\":\\\"Gieng, T.S.;Hamann, B.;Joy, K.I.;Schussman, G.;Trotts, I.J.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;LevelOfDetail;MeshesGridsAndLattices;ShapeRelatedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663906\\\",\\\"Keywords\\\":\\\"mesh simplification;triangular mesh;shape approximation;level-of-detail representation\\\",\\\"Keywords_Processed\\\":\\\"level of detail representation;mesh simplification;shape approximation;triangular mesh\\\",\\\"Title\\\":\\\"Smooth hierarchical surface triangulations\\\"},\\\"423\\\":{\\\"Abstract\\\":\\\"The authors introduce the contour spectrum, a user interface component that improves qualitative user interaction and provides real-time exact quantification in the visualization of isocontours. The contour spectrum is a signature consisting of a variety of scalar data and contour attributes, computed over the range of scalar values /spl omega//spl isin/R. They explore the use of surface, area, volume, and gradient integral of the contour that are shown to be univariate B-spline functions of the scalar value /spl omega/ for multi-dimensional unstructured triangular grids. These quantitative properties are calculated in real-time and presented to the user as a collection of signature graphs (plots of functions of /spl omega/) to assist in selecting relevant isovalues /spl omega//sub 0/ for informative visualization. For time-varying data, these quantitative properties can also be computed over time, and displayed using a 2D interface, giving the user an overview of the time-varying function, and allowing interaction in both isovalue and time step. The effectiveness of the current system and potential extensions are discussed.\\\",\\\"Authors\\\":\\\"Bajaj, C.L.;Pascucci, V.;Schikore, D.R.\\\",\\\"Clusters\\\":\\\"QueriesAndSearch;ScalarFieldDataTechniques;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663875\\\",\\\"Keywords\\\":\\\"visualization;scalar data;user interface;realtime quantitative query\\\",\\\"Keywords_Processed\\\":\\\"visualization;realtime quantitative query;user interface;scalar datum\\\",\\\"Title\\\":\\\"The contour spectrum\\\"},\\\"424\\\":{\\\"Abstract\\\":\\\"Research on information visualization has reached the point where a number of successful point designs have been proposed and a variety of techniques have been discovered. It is now appropriate to describe and analyze portions of the design space so as to understand the differences among designs and to suggest new possibilities. This paper proposes an organization of the information visualization literature and illustrates it with a series of examples. The result is a framework for designing new visualizations and augmenting existing designs.\\\",\\\"Authors\\\":\\\"Card, S.K.;Mackinlay, J.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;DesignMethodologiesAndInteractionDesign;Taxonomies;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1997.636792\\\",\\\"Keywords\\\":\\\"design space;information visualization;taxonomy;morphological analysis\\\",\\\"Keywords_Processed\\\":\\\"design space;morphological analysis;taxonomy;information visualization\\\",\\\"Title\\\":\\\"The structure of the information visualization design space\\\"},\\\"425\\\":{\\\"Abstract\\\":\\\"Volume navigation is the interactive exploration of volume data sets by \\\\\\\"flying\\\\\\\" the view point through the data, producing a volume rendered view at each frame. The authors present an inexpensive perspective volume navigation method designed to run on a PC platform with accelerated 3D graphics hardware. They compute perspective projections at each frame, allow trilinear interpolation of sample points, and render both gray scale and RGB volumes by volumetric compositing. The implementation handles arbitrarily large volumes, by dynamically swapping data within the local depth-limited frustum into main memory as the viewpoint moves through the volume. They describe a new ray casting algorithm that takes advantage of the coherence inherent in adjacent frames to generate a sequence of approximate animated frames much faster than they could be computed individually. They also take advantage of the 3D graphics acceleration hardware to offload much of the alpha blending and resampling from the CPU.\\\",\\\"Authors\\\":\\\"Brady, M.;Jung, K.;Nguyen, H.T.;Nguyen, T.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;Textures;VolumeRenderingModelingAndVisualization;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663878\\\",\\\"Keywords\\\":\\\"volume rendering;volume navigation;scientific visualization;texture mapping;3d medical imaging\\\",\\\"Keywords_Processed\\\":\\\"volume render;volume navigation;3d medical imaging;scientific visualization;texture mapping\\\",\\\"Title\\\":\\\"Two-phase perspective ray casting for interactive volume navigation\\\"},\\\"426\\\":{\\\"Abstract\\\":\\\"The paper presents an algorithm, UFLIC (Unsteady Flow LIC), to visualize vector data in unsteady flow fields. Using line integral convolution (LIC) as the underlying method, a new convolution algorithm is proposed that can effectively trace the flow's global features over time. The new algorithm consists of a time-accurate value depositing scheme and a successive feedforward method. The value depositing scheme accurately models the flow advection, and the successive feedforward method maintains the coherence between animation frames. The new algorithm can produce time-accurate, highly coherent flow animations to highlight global features in unsteady flow fields. CFD scientists, for the first time, are able to visualize unsteady surface flows using the algorithm.\\\",\\\"Authors\\\":\\\"Shen, H.-W.;Kao, D.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;ComputerGraphicsTechniquesGeneral;ImageBasedDataImageSignalProcessing;ImmersiveAndVirtualEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663898\\\",\\\"Keywords\\\":\\\"virtual worlds;dynamic scene analysis;view synthesis;modeling from image sequences;computer vision and scene understanding\\\",\\\"Keywords_Processed\\\":\\\"view synthesis;model from image sequence;computer vision and scene understanding;virtual world;dynamic scene analysis\\\",\\\"Title\\\":\\\"UFLIC: a line integral convolution algorithm for visualizing unsteady flows\\\"},\\\"427\\\":{\\\"Abstract\\\":\\\"This paper describes our experiences with using the Virtual Reality Modeling Language (VRML) to view files in the Initial Graphics Exchange Specification (IGES) format using a Java-based translator from IGES to VRML and HTML (Hypertext Markup Language). The paper examines the conversion problems between IGES and VRML and presents some results of the process.\\\",\\\"Authors\\\":\\\"Marti, J.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663924\\\",\\\"Keywords\\\":\\\"applications of visualization;computer-aided design\\\",\\\"Keywords_Processed\\\":\\\"computer aid design;application of visualization\\\",\\\"Title\\\":\\\"Viewing IGES files through VRML\\\"},\\\"428\\\":{\\\"Abstract\\\":\\\"Virtualized reality is a modeling technique that constructs full 3D virtual representations of dynamic events from multiple video streams. Image-based stereo is used to compute a range image corresponding to each intensity image in each video stream. Each range and intensity image pair encodes the scene structure and appearance of the scene visible to the camera at that moment, and is therefore called a visible surface model (VSM). A single time instant of the dynamic event can be modeled as a collection of VSMs from different viewpoints, and the full event can be modeled as a sequence of static scenes-the 3D equivalent of video. Alternatively, the collection of VSMs at a single time can be fused into a global 3D surface model, thus creating a traditional virtual representation out of real world events. Global modeling has the added benefit of eliminating the need to hand-edit the range images to correct errors made in stereo, a drawback of previous techniques. Like image-based rendering models, these virtual representations can be used to synthesize nearly any view of the virtualized event. For this reason, the paper includes a detailed comparison of existing view synthesis techniques with the authors' own approach. In the virtualized representations, however, scene structure is explicitly represented and therefore easily manipulated, for example by adding virtual objects to (or removing virtualized objects from) the model without interfering with real event. Virtualized reality, then, is a platform not only for image-based rendering but also for 3D scene manipulation.\\\",\\\"Authors\\\":\\\"Rander, P.;Narayanan, P.J.;Kanade, T.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;ComputerGraphicsTechniquesGeneral;ImageBasedDataImageSignalProcessing;ImmersiveAndVirtualEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663893\\\",\\\"Keywords\\\":\\\"virtual worlds;dynamic scene analysis;view synthesis;modeling from image sequences;computer vision and scene understanding\\\",\\\"Keywords_Processed\\\":\\\"view synthesis;model from image sequence;computer vision and scene understanding;virtual world;dynamic scene analysis\\\",\\\"Title\\\":\\\"Virtualized reality: constructing time-varying virtual worlds from real world events\\\"},\\\"429\\\":{\\\"Abstract\\\":\\\"This paper investigates the visualization and animation of geometric computing in a distributed electronic classroom. We show how focusing in a well-defined domain makes it possible to develop a compact system that is accessible to even naive users. We present a conceptual model and a system, GASP-II (Geometric Animation System, Princeton, II), that realizes this model in the geometric domain. The system allows the presentation and interactive exploration of 3D geometric algorithms over a network.\\\",\\\"Authors\\\":\\\"Shneerson, M.;Tal, A.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;Education;GeometricModeling\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663920\\\",\\\"Keywords\\\":\\\"algorithm animation;geometric algorithms;visualization in education\\\",\\\"Keywords_Processed\\\":\\\"algorithm animation;visualization in education;geometric algorithm\\\",\\\"Title\\\":\\\"Visualization of geometric algorithms in an electronic classroom\\\"},\\\"430\\\":{\\\"Abstract\\\":\\\"The paper discusses a unique way to visualize height field data-the use of solid fabricated parts with a photomapped texture to display scalar information. In this process, the data in a height field are turned into a 3D solid representation through solid freeform fabrication techniques, in this case laminated object manufacturing. Next, that object is used as a 3D \\\\\\\"photographic plate\\\\\\\" to allow a texture image representing scalar data to be permanently mapped onto it. The paper discusses this process and how it can be used in different visualization situations.\\\",\\\"Authors\\\":\\\"Clark, D.;Bailey, M.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;GeometricModeling;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663862\\\",\\\"Keywords\\\":\\\"object modeling;scientific visualization;computer graphics\\\",\\\"Keywords_Processed\\\":\\\"scientific visualization;computer graphic;object modeling\\\",\\\"Title\\\":\\\"Visualization of height field data with physical models and texture photomapping\\\"},\\\"431\\\":{\\\"Abstract\\\":\\\"The authors describe a software system supporting interactive visualization of large terrains in a resource-limited environment, i.e. a low-end client computer accessing a large terrain database server through a low-bandwidth network. By \\\\\\\"large\\\\\\\", they mean that the size of the terrain database is orders of magnitude larger than the computer RAM. Superior performance is achieved by manipulating both geometric and texture data at a continuum of resolutions, and, at any given moment, using the best resolution dictated by the CPU and bandwidth constraints. The geometry is maintained as a Delaunay triangulation of a dynamic subset of the terrain data points, and the texture compressed by a progressive wavelet scheme. A careful blend of algorithmic techniques enables the system to achieve superior rendering performance on a low-end computer by optimizing the number of polygons and texture pixels sent to the graphics pipeline. It guarantees a frame rate depending only on the size and quality of the rendered image, independent of the viewing parameters and scene database size. An efficient paging scheme minimizes data I/O, thus enabling the use of the system in a low-bandwidth client/server data-streaming scenario, such as on the Internet.\\\",\\\"Authors\\\":\\\"Rabinovich, B.;Gotsman, C.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;InteractionTechniquesGeneral;LevelOfDetail\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663863\\\",\\\"Keywords\\\":\\\"interactive graphics;level-of-detail;terrain rendering\\\",\\\"Keywords_Processed\\\":\\\"interactive graphic;terrain render;level of detail\\\",\\\"Title\\\":\\\"Visualization of large terrains in resource-limited computing environments\\\"},\\\"432\\\":{\\\"Abstract\\\":\\\"The measurement, analysis and visualization of plant growth is of primary interest to plant biologists. We are developing software tools to support such investigations. There are two parts in this investigation, namely growth visualization of (i) a plant root and (ii) a plant stem. For both domains, the input data is a stream of images taken by cameras. The tools being developed make it possible to measure various time-varying quantities, such as differential growth. For both domains, the plant is modeled by using flexible templates to represent non-rigid motions.\\\",\\\"Authors\\\":\\\"Loomis, J.J.;Xiuwen Liu;Zhaohua Ding;Fujimura, K.;Evans, M.L.;Ishikawa, H.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;BiologyAndBioinformatics;ImageBasedDataImageSignalProcessing;ShapeRelatedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663925\\\",\\\"Keywords\\\":\\\"shape representation;plant biology;non-rigid motion;image sequence analysis\\\",\\\"Keywords_Processed\\\":\\\"image sequence analysis;shape representation;plant biology;non rigid motion\\\",\\\"Title\\\":\\\"Visualization of plant growth\\\"},\\\"433\\\":{\\\"Abstract\\\":\\\"We define a rotation field by extending the notion of a vector field to rotations. A vector field has a vector as a value at each point of its domain; a rotation field has a rotation as a value at each point of its domain. Rotation fields result from mapping the orientation error of tracking systems. We build upon previous methods for the visualization of vector fields, tensor fields and rotations at a point, to visualize a rotation field resulting from calibration of a commonly-used magnetic tracking system.\\\",\\\"Authors\\\":\\\"Livingston, M.A.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;StreamlinesPathlinesStreaklines;SurfaceRelatedDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663929\\\",\\\"Keywords\\\":\\\"scientific visualization;stream surfaces;tufts;streamlines\\\",\\\"Keywords_Processed\\\":\\\"scientific visualization;streamline;tuft;stream surface\\\",\\\"Title\\\":\\\"Visualization of rotation fields\\\"},\\\"434\\\":{\\\"Abstract\\\":\\\"We describe a method for the visualization of information units on spherical domains which is employed in the banking industry for risk analysis, stock prediction and other tasks. The system is based on a quantification of the similarity of related objects that governs the parameters of a mass-spring system. Unlike existing approaches we initialize all information units onto the inner surface of two concentric spheres and attach them with springs to the outer sphere. Since the spring stiffnesses correspond to the computed similarity measures, the system converges into an energy minimum which reveals multidimensional relations and adjacencies in terms of spatial neighborhoods. Depending on the application scenario our approach supports different topological arrangements of related objects. In order to cope with large data sets we propose a blobby clustering mechanism that enables encapsulation of similar objects by implicit shapes. In addition, we implemented various interaction techniques allowing semantic analysis of the underlying data sets. Our prototype system IVORY is written in Java, and its versatility is illustrated by an example from financial service providers.\\\",\\\"Authors\\\":\\\"Gross, M.;Sprenger, T.C.;Finger, J.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;HierarchicalTreeDataAndTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1997.636759\\\",\\\"Keywords\\\":\\\"physically-based systems;information visualization;blobby clustering;hierarchy;multi-dimensional information space\\\",\\\"Keywords_Processed\\\":\\\"hierarchy;physically base system;blobby clustering;information visualization;multi dimensional information space\\\",\\\"Title\\\":\\\"Visualizing information on a sphere\\\"},\\\"435\\\":{\\\"Abstract\\\":\\\"A method for efficiently volume rendering dense scatterplots of relational data is described. Plotting difficulties that arise from large numbers of data points, categorical variables, interaction with non-axis dimensions, and unknown values, are addressed by this method. The domain of the plot is voxelized using binning and then volume rendering. Since a table is used as the underlying data structure, no storage is wasted on regions with no data. The opacity of each voxel is a function of the number of data points in a corresponding bin. A voxel's color is derived by averaging the value of one of the variables for all the data points that fall in a bin. Other variables in the data may be mapped to external query sliders. A dragger object permits a user to select regions inside the volume.\\\",\\\"Authors\\\":\\\"Becker, B.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;DataTypesGeneral;MultidimensionalMultivariateMultifieldDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1997.636791\\\",\\\"Keywords\\\":\\\"information visualization;scatterplot;volume rendering;relational data;multivariate data\\\",\\\"Keywords_Processed\\\":\\\"multivariate datum;volume render;scatterplot;relational datum;information visualization\\\",\\\"Title\\\":\\\"Volume rendering for relational data\\\"},\\\"436\\\":{\\\"Abstract\\\":\\\"One well known application area of volume rendering is the reconstruction and visualization of output from medical scanners like computed tomography (CT). 2D greyscale slices produced by these scanners can be reconstructed and displayed onscreen as a 3D model. Volume visualization of medical images must address two important issues. First, it is difficult to segment medical scans into individual materials based only on intensity values. Second, although greyscale images are the normal method for displaying medical volumes, these types of images are not necessarily appropriate for highlighting regions of interest within the volume. Studies of the human visual system have shown that individual intensity values are difficult to detect in a greyscale image. In these situations colour is a more effective visual feature. We addressed both problems during the visualization of CT scans of abdominal aortic aneurysms. We have developed a classification method that empirically segments regions of interest in each of the 2D slices. We use a perceptual colour selection technique to identify each region of interest in both the 2D slices and the 3D reconstructed volumes. The result is a colourized volume that the radiologists are using to rapidly and accurately identify the locations and spatial interactions of different materials from their scans. Our technique is being used in an experimental post operative environment to help to evaluate the results of surgery designed to prevent the rupture of the aneurysm. In the future, we hope to use the technique during the planning of placement of support grafts prior to the actual operation.\\\",\\\"Authors\\\":\\\"Tam, R.;Healey, C.;Flak, B.;Cahoon, P.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;ColorColorPerception;ImageBasedDataImageSignalProcessing;SegmentationAndClassification;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663855\\\",\\\"Keywords\\\":\\\"volume rendering;computed tomography;scientific visualization;image processing;segmentation;aneurysm;colorization;medical imaging\\\",\\\"Keywords_Processed\\\":\\\"volume render;compute tomography;image processing;segmentation;colorization;medical imaging;scientific visualization;aneurysm\\\",\\\"Title\\\":\\\"Volume rendering of abdominal aortic aneurysms\\\"},\\\"437\\\":{\\\"Abstract\\\":\\\"The paper addresses multiresolutional representation of datasets arising from a computational field simulation. The approach determines the regions of interest, breaks the volume into variable size blocks to localize the information, and then codes each block using a wavelet transform. The blocks are then ranked by visual information content so that the most informative wavelet coefficients can be embedded in a bit stream for progressive transmission or access. The technique is demonstrated on a widely-used computational field simulation dataset.\\\",\\\"Authors\\\":\\\"Zhifan Zhu;Machiraju, R.;Fry, B.;Moorhead, R.J.\\\",\\\"Clusters\\\":\\\"ImageBasedDataImageSignalProcessing;Perception;ProgrammingAlgorithmsAndDataStructures;VisualPatternFeatureDetectionAndTracking\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1997.663872\\\",\\\"Keywords\\\":\\\"human visual system;wavelet transform;progressive transmission;structure detection\\\",\\\"Keywords_Processed\\\":\\\"structure detection;human visual system;progressive transmission;wavelet transform\\\",\\\"Title\\\":\\\"Wavelet-based multiresolutional representation of computational field simulation datasets\\\"},\\\"438\\\":{\\\"Abstract\\\":\\\"A technique is presented for the layout of high dimensional data in a low dimensional space. This technique builds upon the force based methods that have been used previously to make visualisations of various types of data such as bibliographies and sets of software modules. The canonical force based model, related to solutions of the N body problem, has a computational complexity of O(N 2) per iteration. The paper presents a stochastically based algorithm of linear complexity per iteration which produces good layouts, has low overhead, and is easy to implement. Its performance and accuracy are discussed, in particular with regard to the data to which it is applied. Experience with application to bibliographic and time series data, which may have a dimensionality in the tens of thousands, is described.\\\",\\\"Authors\\\":\\\"Chalmers, M.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;ProgrammingAlgorithmsAndDataStructures;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.567787\\\",\\\"Keywords\\\":\\\"high-dimensional data;stochastic algorithms;force-directed placement;visualization;layout algorithm;spring models\\\",\\\"Keywords_Processed\\\":\\\"visualization;stochastic algorithm;layout algorithm;spring model;high dimensional datum;force direct placement\\\",\\\"Title\\\":\\\"A linear iteration time layout algorithm for visualising high-dimensional data\\\"},\\\"439\\\":{\\\"Abstract\\\":\\\"Anatomy-based facial tissue modeling for surgical simulation is a field whose time has come. Real-time facial animation has been created in the last few years using models based on the anatomical structure of the human skin. Anatomy-based models are also under development in the field of medical visualization, with which facial surgery can be realistically simulated. In this article, we present an anatomy-based 3D finite element tissue model. Integrated into a computer-aided surgical planning system, this model allows the precise prediction of soft tissue changes resulting from the realignment of the underlying bone structure. The model has already been used in our Department of Oral and Maxillofacial Surgery and has improved craniofacial surgical planning procedures. The model is described in detail, and surgical simulation results are shown and discussed.\\\",\\\"Authors\\\":\\\"Keeve, E.;Girod, S.;Pfeifle, P.;Girod, B.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;GeometricModeling;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.567595\\\",\\\"Keywords\\\":\\\"finite element method;computer-aided surgery;human facial modeling;surgery planning and simulation\\\",\\\"Keywords_Processed\\\":\\\"surgery planning and simulation;human facial modeling;finite element method;computer aid surgery\\\",\\\"Title\\\":\\\"Anatomy-based facial tissue modeling using the finite element method\\\"},\\\"440\\\":{\\\"Abstract\\\":\\\"As ecological awareness increases there has been a shift towards more integrated forest management. Accurate modeling of future states of forested landscapes will allow better planning for safeguarding our forest resource for future generations. We present an initial exploration into providing visual access to information generated by SELES (Spatially Explicit Landscape Event Simulator). We explore the application of our visual access distortion technique to a block of temporal data created from a sequence of landscape event based information. This type of access extends the possibilities of visual exploration for temporal and spatial interrelations in a data set.\\\",\\\"Authors\\\":\\\"Carpendale, S.;Fall, A.;Cowperthwaite, D.J.;Fall, J.;Fracchia, F.D.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;InteractionTechniquesGeneral;TimeseriesTimeVaryingDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.568148\\\",\\\"Keywords\\\":\\\"information visualization;3d interaction;distortion viewing;temporal data\\\",\\\"Keywords_Processed\\\":\\\"3d interaction;distortion view;temporal datum;information visualization\\\",\\\"Title\\\":\\\"Case Study: Visual access for landscape event based temporal data\\\"},\\\"441\\\":{\\\"Abstract\\\":\\\"As the amount of electronic information explodes, hierarchies to handle this information become huge and complex. Visualizing and interacting with these hierarchies become daunting tasks. The problem is exacerbated if the visualization is to be done on mass-market personal computers, with limited processing power and visual resolution. Many of the current visualization techniques work effectively for hierarchies of 1000 nodes, but as the number of nodes increases toward 5000, these techniques tend to break down. Hierarchies above 5000 nodes usually require special modifications such as clustering, which can affect visual stability. This paper introduces Cheops, a novel approach to the representation, browsing and exploration of huge, complex information hierarchies such as the Dewey Decimal Classification system, which can contain between a million and a billion nodes. The Cheops approach maintains context within a huge hierarchy, while simultaneously providing easy access to details. This paper presents some preliminary results from usability tests performed on an 8-wide-by-9-deep classification hierarchy, which if fully populated would contain over 19 million nodes.\\\",\\\"Authors\\\":\\\"Beaudoin, L.;Parent, M.-A.;Vroomen, L.C.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;FocusContextTechniques;HierarchicalTreeDataAndTechniques;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.567745\\\",\\\"Keywords\\\":\\\"focus+context technique;information visualization and exploration;hierarchical representation;graphical browser\\\",\\\"Keywords_Processed\\\":\\\"information visualization and exploration;hierarchical representation;focus context technique;graphical browser\\\",\\\"Title\\\":\\\"Cheops: a compact explorer for complex hierarchies\\\"},\\\"442\\\":{\\\"Abstract\\\":\\\"The case study describes a system that allows the use of interactive volume rendering for routine clinical diagnosis. In this setup, a SGI RealityStation acts like a remote rendering system which is controlled by a user interface that was added to an existing clinical system. The paper describes some implementation aspects, including several system optimizations that were carried out in order to optimize rendering speed. Initial results are very promising; the authors present three examples of clinical findings that were made using this system. Because of the setup, clinicians are now much more aware of the possibilities that modern hardware offers for interactive volume visualization.\\\",\\\"Authors\\\":\\\"Zuiderveld, K.J.;van Ooijen, P.M.A.;Chin-A-Woeng, J.W.C.;Buijs, P.C.;Olree, M.;Post, F.H.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;Textures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.568134\\\",\\\"Keywords\\\":\\\"volume rendering;clinical evaluation;mr angiography;visualization;texture mapping\\\",\\\"Keywords_Processed\\\":\\\"visualization;volume render;clinical evaluation;mr angiography;texture mapping\\\",\\\"Title\\\":\\\"Clinical evaluation of interactive volume visualization\\\"},\\\"443\\\":{\\\"Abstract\\\":\\\"Given (n-1)-dimensional parallel cross-sections of an n-dimensional body, one would like to reconstruct the n-dimensional body. The method based on Distance Field Interpolation (DFI) gives a robust solution to this problem in its ability to deal with any topology in any dimension. Still this method may give undesired solutions to the problem if the changes from one cross-section to the next are significant relative to the size of the details in the cross-sections. We consider the problem of solid reconstruction from contours, which can also be considered as a contour blending or contour morphing problem, where the third dimension is time. The method presented is based on interpolation of the distance field, guided by a warp function which is controlled by a set of corresponding anchor points. Some rules for defining a smooth least-distorting warp function are given. To reduce the distortion of the intermediate shapes, the warp function is decomposed into a rigid rotational part and an elastic part. The distance field interpolation method is modified so that the interpolation is guided by the warp function. The advantage of the new approach is that it is capable of blending between contours having different topological genus, and no correspondence between the geometric primitives should be established. The desired general correspondence is defined by the user in terms of a relatively small number of anchor points.\\\",\\\"Authors\\\":\\\"Cohen-Or, D.;Levin, D.;Solomovici, A.\\\",\\\"Clusters\\\":\\\"Interpolation;NumericalMethodsMathematics;ShapeRelatedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.567812\\\",\\\"Keywords\\\":\\\"shape-plending;radial basis functions;interpolation;shape reconstruction\\\",\\\"Keywords_Processed\\\":\\\"shape plending;interpolation;radial basis function;shape reconstruction\\\",\\\"Title\\\":\\\"Contour blending using warp-guided distance field interpolation\\\"},\\\"444\\\":{\\\"Abstract\\\":\\\"Rendering deformable volume data currently needs separate processes for deformation and rendering, and is expensive in terms of both computational and memory costs. Recognizing the importance of unifying these processes, we present a new approach to the direct rendering of deformable volumes without explicitly constructing the intermediate deformed volumes. The volume deformation is done by a radial basis function that is piecewise linearly approximated by an adaptive subdivision of the octree encoded target volume. The octree blocks in the target volume are then projected, reverse morphed and texture mapped, using the SGI 3D texture mapping hardware, in a back-to-front order. A template-based Z-plane/block intersection method is used to expedite the block projection computation.\\\",\\\"Authors\\\":\\\"Shiaofen Fang;Su Huang;Srinivasan, R.;Raghu Raghavan\\\",\\\"Clusters\\\":\\\"ProgrammingAlgorithmsAndDataStructures;Textures;TransitionsAndMorphing;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.567609\\\",\\\"Keywords\\\":\\\"volume deformation;volume rendering;morphing;scientific visualization;octree;3d texture mapping\\\",\\\"Keywords_Processed\\\":\\\"volume render;3d texture mapping;volume deformation;octree;scientific visualization;morph\\\",\\\"Title\\\":\\\"Deformable volume rendering by 3D texture mapping and octree encoding\\\"},\\\"445\\\":{\\\"Abstract\\\":\\\"The paper presents interactive flow visualization methods that highlight directional information in the flow field. An added benefit of the proposed methods is that they reduce the amount of data being displayed and hence reduce clutter. The main idea behind these methods is the use of light sources to select and highlight regions in the flow field with similar directions. Varying the lighting conditions, by moving the light source and/or adding more lights, emphasizes different vector directions, set of directions, and vectors within a specified angle of a particular direction. The methods are straight forward, computationally inexpensive, and can be combined with other techniques that use glyph representation and other flow geometry such as streamlines for feature visualization. The authors apply these methods to an analytic data set to help explain how they work, and then to a simulation data set to highlight flow reversals.\\\",\\\"Authors\\\":\\\"Boring, E.;Pang, A.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;DataFeaturesAndAttributes;FlowVisualizationDataAndTechniques;GlyphsGlyphBasedTechniques;Illumination;InteractionTechniquesGeneral;StreamlinesPathlinesStreaklines;VisualClutterAndItsReduction\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.568139\\\",\\\"Keywords\\\":\\\"glyph;region selection;flow reversal;clutter reduction;streamlines;lighting;hue;value\\\",\\\"Keywords_Processed\\\":\\\"streamline;hue;clutter reduction;flow reversal;glyph;value;region selection;lighting\\\",\\\"Title\\\":\\\"Directional flow visualization of vector fields\\\"},\\\"446\\\":{\\\"Abstract\\\":\\\"As the use of 3D information presentation becomes more prevalent, the need for effective viewing tools grows accordingly. Much work has been done in developing tools for 2D spaces which allow for detail in context views. We examine the extension of such 2D methods to 3D and explore the limitations encountered in accessing internal regions of the data with these methods. We then describe a novel solution to this problem of internal access with the introduction of a distortion function which creates a clear line of sight to the focus revealing sections previously obscured. The distortion is symmetric about the line of sight and is smoothly integrated back into the original 3D layout.\\\",\\\"Authors\\\":\\\"Carpendale, S.;Cowperthwaite, D.J.;Fracchia, F.D.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;InteractionTechniquesGeneral;UserInterfacesGeneral;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1996.559215\\\",\\\"Keywords\\\":\\\"information visualization;screen layout;interface metaphors;3d interaction;distortion viewing;interface design issues\\\",\\\"Keywords_Processed\\\":\\\"3d interaction;information visualization;interface design issue;distortion view;screen layout;interface metaphor\\\",\\\"Title\\\":\\\"Distortion viewing techniques for 3-dimensional data\\\"},\\\"447\\\":{\\\"Abstract\\\":\\\"Information visualization faces challenges presented by the need to represent abstract data and the relationships within the data. Previously, we presented a system for visualizing similarities between a single DNA sequence and a large database of other DNA sequences (E.H. Chi et al., 1995). Similarity algorithms generate similarity information in textual reports that can be hundreds or thousands of pages long. Our original system visualized the most important variables from these reports. However, the biologists we work with found this system so useful they requested visual representations of other variables. We present an enhanced system for interactive exploration of this multivariate data. We identify a larger set of useful variables in the information space. The new system involves more variables, so it focuses on exploring subsets of the data. We present an interactive system allowing mapping of different variables to different axes, incorporating animation using a time axis, and providing tools for viewing subsets of the data. Detail-on-demand is preserved by hyperlinks to the analysis reports. We present three case studies illustrating the use of these techniques. The combined technique of applying a time axis with a 3D scatter plot and query filters to visualization of biological sequence similarity data is both powerful and novel.\\\",\\\"Authors\\\":\\\"Chi, E.H.;Riedl, J.;Shoop, E.;Carlis, J.V.;Retzel, E.;Barry, P.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;BiomedicalScienceAndMedicine;MultidimensionalMultivariateMultifieldDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.567796\\\",\\\"Keywords\\\":\\\"applications of visualization;information visualization;multimodal and multi-dimensional visualization;biomedical visualization\\\",\\\"Keywords_Processed\\\":\\\"information visualization;multimodal and multi dimensional visualization;application of visualization;biomedical visualization\\\",\\\"Title\\\":\\\"Flexible information visualization of multivariate data from biological sequence similarity searches\\\"},\\\"448\\\":{\\\"Abstract\\\":\\\"A general volume rendering technique is described that efficiently produces images of excellent quality from data defined over irregular grids having a wide variety of formats. Rendering is done in software, eliminating the need for special graphics hardware, as well as any artifacts associated with graphics hardware. Images of volumes with about 1,000,000 cells can be produced in one to several minutes on a workstation with a 150-MHz processor. A significant advantage of this method for applications such as computational fluid dynamics is that it can process multiple intersecting grids. Such grids present problems for most current volume rendering techniques. Also, the wide range of cell sizes does not present difficulties, as it does for many techniques. A spatial hierarchical organization makes it possible to access data from a restricted region efficiently. The tree has greater depth in regions of greater detail, determined by the number of cells in the region. It also makes it possible to render useful \\\\\\\"preview\\\\\\\" images very quickly by displaying each region associated with a tree node as one cell. Previews show enough detail to navigate effectively in very large data sets. The algorithmic techniques include use of a k-d tree, with prefix-order partitioning of triangles, to reduce the number of primitives that must be processed for one rendering, coarse-grain parallelism for a shared-memory MIMD architecture, a new perspective transformation that achieves greater numerical accuracy, and a scanline algorithm with depth sorting and a new clipping technique.\\\",\\\"Authors\\\":\\\"Wilhelms, J.;Van Gelder, A.;Tarantino, P.;Gibbs, J.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;ImageBasedDataImageSignalProcessing;MeshesGridsAndLattices;ProgrammingAlgorithmsAndDataStructures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.567606\\\",\\\"Keywords\\\":\\\"scientific visualization;computer graphics;direct volume rendering;curvilinear grid;irregular grids;k-d tree;scanline\\\",\\\"Keywords_Processed\\\":\\\"irregular grid;curvilinear grid;computer graphic;scanline;direct volume render;scientific visualization;tree\\\",\\\"Title\\\":\\\"Hierarchical and parallelizable direct volume rendering for irregular and multiple grids\\\"},\\\"449\\\":{\\\"Abstract\\\":\\\"We introduce an algorithm for reconstructing a solid model given a series of planar cross sections. The main contribution of this work is the use of knowledge obtained during the interpolation of neighboring layers while attempting to interpolate a particular layer. This knowledge is used to reconstruct a surface in which consecutive layers are connected smoothly. In most previous work, each layer is interpolated independently of what happened or will happen in the other layers. We also discuss various objective functions which aim to optimize the reconstruction, and present an evaluation of the different objective functions by using various criteria.\\\",\\\"Authors\\\":\\\"Barequet, G.;Shapiro, D.;Tal, A.\\\",\\\"Clusters\\\":\\\"GeometricModeling;Interpolation\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.567804\\\",\\\"Keywords\\\":\\\"reconstruction;interpolation;triangulation\\\",\\\"Keywords_Processed\\\":\\\"triangulation;reconstruction;interpolation\\\",\\\"Title\\\":\\\"History consideration in reconstructing polyhedral surfaces from parallel slices\\\"},\\\"450\\\":{\\\"Abstract\\\":\\\"Integrated presentation of data with uncertainty is a worthy goal in scientific visualization. It allows researchers to make informed decisions based on imperfect data. It also allows users to visually compare and contrast different algorithms for performing the same task or different models for representing the same physical phenomenon. We present LISTEN-a data sonification system that has been incorporated into two visualization systems: a system for visualizing geometric uncertainty of surface interpolants; and a system for visualizing uncertainty in fluid flow. LISTEN is written in C++ for the SGI platform. It works with the SGI internal audio chip or a MIDI device or both. LISTEN is an object-oriented system that is modular, flexible, adaptable, portable, interactive and extensible. We demonstrate that sonification is very effective as an additional tool in visualizing geometric and fluid flow uncertainty.\\\",\\\"Authors\\\":\\\"Lodha, S.K.;Wilson, C.M.;Sheehan, R.E.\\\",\\\"Clusters\\\":\\\"AcousticsSoundSonification;FlowVisualizationDataAndTechniques;GeometryBasedTechniques;InteractionTechniquesGeneral;Interpolation;ProgrammingAlgorithmsAndDataStructures;SmallMobileUbiquitousDevicesDisplays;UncertaintyTechniquesAndVisualization;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.568105\\\",\\\"Keywords\\\":\\\"modular;sonification;geometry;interactive;uncertainty;interpolation;midi;visualization;flow;portable\\\",\\\"Keywords_Processed\\\":\\\"visualization;sonification;midi;uncertainty;geometry;interpolation;modular;portable;interactive;flow\\\",\\\"Title\\\":\\\"LISTEN: sounding uncertainty visualization\\\"},\\\"451\\\":{\\\"Abstract\\\":\\\"In many cases the surfaces of geometric models consist of a large number of triangles. Several algorithms were developed to reduce the number of triangles required to approximate such objects. Algorithms that measure the deviation between the approximated object and the original object are only available for special cases. We use the Hausdorff distance between the original and the simplified mesh as a geometrically meaningful error value which can be applied to arbitrary triangle meshes. We present a new algorithm to reduce the number of triangles of a mesh without exceeding a user defined Hausdorff distance between the original and simplified mesh. As this distance is parameterization independent, its use as error measure is superior to the use of the L -Norm between parameterized surfaces. Furthermore the Hausdorff distance is always less than the distance induced by the L -Norm. This results in higher reduction rates. Excellent results were achieved by the new decimation algorithm for triangle meshes that has been used in different application areas such as volume rendering, terrain modeling and the approximations of parameterized surfaces. The key advantages of the new algorithm are: it guarantees a user defined position dependent approximation error; it allows one to generate a hierarchical geometric representation in a canonical way; it automatically preserves sharp edges.\\\",\\\"Authors\\\":\\\"Klein, R.;Liebich, G.;Strasser, W.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;LevelOfDetail;ShapeRelatedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.568124\\\",\\\"Keywords\\\":\\\"level-of-detail generation;shape approximation;model simplification;hierarchical approximation\\\",\\\"Keywords_Processed\\\":\\\"model simplification;hierarchical approximation;level of detail generation;shape approximation\\\",\\\"Title\\\":\\\"Mesh reduction with error control\\\"},\\\"452\\\":{\\\"Abstract\\\":\\\"Interactive techniques are powerful tools for manipulating visualizations to analyze, communicate and acquire information. This is especially true for large data sets or complex 3D visualizations. Although many new types of interaction have been introduced recently, very little work has been done on understanding what their components are, how they are related and how they can be combined. This paper begins to address these issues with a framework for classifying interactive visualizations. Our goal is a framework that will enable us to develop toolkits for assembling visualization interfaces both interactively and automatically\\\",\\\"Authors\\\":\\\"Chuah, M.C.;Roth, S.F.\\\",\\\"Clusters\\\":\\\"AutomaticAnalysisVisualizationTechniques;ComputerGraphicsTechniquesGeneral;InteractionTechniquesGeneral;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1996.559213\\\",\\\"Keywords\\\":\\\"automatic presentation systems;information visualization;user interface;interactive techniques;graphics\\\",\\\"Keywords_Processed\\\":\\\"automatic presentation system;user interface;information visualization;interactive technique;graphic\\\",\\\"Title\\\":\\\"On the semantics of interactive visualizations\\\"},\\\"453\\\":{\\\"Abstract\\\":\\\"Discusses a software tool called VANISH (Visualizing And Navigating Information Structured Hierarchically), which supports the rapid prototyping of interactive 2D and 3D information visualizations. VANISH supports rapid prototyping through a special-purpose visual language called VaPL (VANISH Programming Language) tailored for visualizations, through a software architecture that insulates visualization-specific code from changes in both the domain being visualized and the presentation toolkit used, and through the reuse of visualization techniques between application domains. The generality of VANISH is established by showing how it is able to re-create a wide variety of standard visualization techniques. VANISH's support for prototyping is shown through an extended example, where we build a C++ class browser, exploring many visualization alternatives in the process\\\",\\\"Authors\\\":\\\"Kazman, R.;Carriere, J.\\\",\\\"Clusters\\\":\\\"ProgrammingAlgorithmsAndDataStructures;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1996.559212\\\",\\\"Keywords\\\":\\\"visual programming languages;information visualization;software tools\\\",\\\"Keywords_Processed\\\":\\\"visual programming language;information visualization;software tool\\\",\\\"Title\\\":\\\"Rapid prototyping of information visualizations using VANISH\\\"},\\\"454\\\":{\\\"Abstract\\\":\\\"We present a method for producing real-time volume visualizations of continuously captured, arbitrarily-oriented 2D arrays (slices) of data. Our system constructs a 3D representation on-the-fly from incoming 2D ultrasound slices by modeling and rendering the slices as planar polygons with translucent surface textures. We use binary space partition (BSP) tree data structures to provide non-intersecting, visibility-ordered primitives for accurate opacity accumulation images. New in our system is a method of using parallel, time-shifted BSP trees to efficiently manage the continuously captured ultrasound data and to decrease the variability in image generation time between output frames. This technique is employed in a functioning real-time augmented reality system that a physician has used to examine human patients prior to breast biopsy procedures. We expect the technique can be used for real-time visualization of any 2D data being collected from a tracked sensor moving along an arbitrary path.\\\",\\\"Authors\\\":\\\"Garrett, W.F.;Fuchs, H.;Whitton, M.C.;State, A.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DatabasesAndDataMining;ImmersiveAndVirtualEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.568114\\\",\\\"Keywords\\\":\\\"augmented reality;ultrasound echography;3d medical imaging;binary space partitioning tree\\\",\\\"Keywords_Processed\\\":\\\"ultrasound echography;binary space partitioning tree;3d medical imaging;augmented reality\\\",\\\"Title\\\":\\\"Real-time incremental visualization of dynamic ultrasound volumes using parallel BSP trees\\\"},\\\"455\\\":{\\\"Abstract\\\":\\\"Real time rendering of iso contour surfaces is problematic for large complex data sets. An algorithm is presented that allows very rapid representation of an interval set surrounding an iso contour surface. The algorithm draws upon three main ideas. A fast indexing scheme is used to select only those data points near the contour surface. Hardware assisted splatting is then employed on these data points to produce a volume rendering of the interval set. Finally, by shifting a small window through the indexing scheme or data space, animated volumes are produced showing the changing contour values. In addition to allowing fast selection and rendering of the data, the indexing scheme allows a much compressed representation of the data by eliminating \\\\\\\"noise\\\\\\\" data points.\\\",\\\"Authors\\\":\\\"Crawfis, R.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;CompressionTechniques;ComputerGraphicsTechniquesGeneral;ContourCreasesRidgesValleys;InteractionTechniquesGeneral;IsosurfaceAndSurfaceExtractionTechniques;RealtimeProcessingRenderingAndVisualizationGeneral;SegmentationAndClassification;SurfaceRelatedDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.568119\\\",\\\"Keywords\\\":\\\"splatting;isosurface;volume rendering;data partitioning;interactive;compression;realtime;scientific visualization;contour surface;isocontour;animation\\\",\\\"Keywords_Processed\\\":\\\"volume render;realtime;contour surface;compression;animation;scientific visualization;splatte;isosurface;isocontour;datum partitioning;interactive\\\",\\\"Title\\\":\\\"Real-time slicing of data space\\\"},\\\"456\\\":{\\\"Abstract\\\":\\\"Uncertainty or errors are introduced in fluid flow data as the data is acquired, transformed and rendered. Although researchers are aware of these uncertainties, little has been done to incorporate them in the existing visualization systems for fluid flow. In the absence of integrated presentation of data and its associated uncertainty, the analysis of the visualization is incomplete at best and may lead to inaccurate or incorrect conclusions. The article presents UFLOW-a system for visualizing uncertainty in fluid flow. Although there are several sources of uncertainties in fluid flow data, in this work, we focus on uncertainty arising from the use of different numerical algorithms for computing particle traces in a fluid flow. The techniques that we have employed to visualize uncertainty in fluid flow include uncertainty glyphs, flow envelopes, animations, priority sequences, twirling batons of trace viewpoints, and rakes. These techniques are effective in making the users aware of the effects of different integration methods and their sensitivity, especially near critical points in the flow field.\\\",\\\"Authors\\\":\\\"Lodha, S.K.;Pang, A.;Sheehan, R.E.;Wittenbrink, C.M.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;FlowVisualizationDataAndTechniques;StreamlinesPathlinesStreaklines;UncertaintyTechniquesAndVisualization;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.568116\\\",\\\"Keywords\\\":\\\"flow visualization;flow envelopes;uncertainty glyphs;streamlines;rakes;animation\\\",\\\"Keywords_Processed\\\":\\\"streamline;animation;flow envelope;rake;uncertainty glyph;flow visualization\\\",\\\"Title\\\":\\\"UFLOW: visualizing uncertainty in fluid flow\\\"},\\\"457\\\":{\\\"Abstract\\\":\\\"Visage is a prototype user interface environment for exploring and analyzing information. It represents an approach to coordinating multiple visualizations, analysis and presentation tools in data-intensive domains. Visage is based on an information-centric approach to user interface design which strives to eliminate impediments to direct user access to information objects across applications and visualizations. Visage consists of a set of data manipulation operations, an intelligent system for generating a wide variety of data visualizations (SAGE) and a briefing tool that supports the conversion of visual displays used during exploration into interactive presentation slides. This paper presents the user interface components and styles of interaction that are central to Visage's information-centric approach\\\",\\\"Authors\\\":\\\"Roth, S.F.;Lucas, P.;Senn, J.A.;Gomberg, C.C.;Burks, M.B.;Stroffolino, P.J.;Kolojechick, A.J.;Dunmire, C.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;ComputerGraphicsTechniquesGeneral;HumanComputerInteractionHumanFactors;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1996.559210\\\",\\\"Keywords\\\":\\\"user interface environment;exploratory data analysis;visualization;human-computer interaction;graphics\\\",\\\"Keywords_Processed\\\":\\\"visualization;human computer interaction;graphic;exploratory datum analysis;user interface environment\\\",\\\"Title\\\":\\\"Visage: a user interface environment for exploring information\\\"},\\\"458\\\":{\\\"Abstract\\\":\\\"3D time varying datasets are difficult to visualize and analyze because of the immense amount of data involved. This is especially true when the datasets are turbulent with many evolving amorphous regions, as it is difficult to observe patterns and follow regions of interest. We present our volume based feature tracking algorithm and discuss how it can be used to help visualize and analyze large time varying datasets. We also address efficiency issues in dealing with massive time varying datasets.\\\",\\\"Authors\\\":\\\"Silver, D.;Wang, X.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;ImageBasedDataImageSignalProcessing;MultidimensionalMultivariateMultifieldDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1996.567807\\\",\\\"Keywords\\\":\\\"computer vision;computational fluid dynamics;feature tracking;scientific visualization;multi-dimensional visualization\\\",\\\"Keywords_Processed\\\":\\\"multi dimensional visualization;scientific visualization;feature tracking;computer vision;computational fluid dynamic\\\",\\\"Title\\\":\\\"Volume tracking\\\"},\\\"459\\\":{\\\"Abstract\\\":\\\"A software architecture is presented to integrate a database management system with data visualization. One of its primary objectives, the retention of user-data interactions, is detailed. By storing all queries over the data along with high-level descriptions of the query results and the associated visualization, the processes by which a database is explored can be analyzed. This approach can lead to important contributions in the development of user models as data explorers, metadata models for scientific databases, intelligent assistants and data exploration services. We describe the underlying elements of this approach, specifically the visual database exploration model and the metadata objects that support the model\\\",\\\"Authors\\\":\\\"Lee, J.P.;Grinstein, G.\\\",\\\"Clusters\\\":\\\"DataTypesGeneral;DatabasesAndDataMining;InteractionTechniquesGeneral;TasksTaskRequirementsAnalysis\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1995.480801\\\",\\\"Keywords\\\":\\\"database visualization;user modeling;meta-data;visual database exploration;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;meta datum;visual database exploration;database visualization;user model\\\",\\\"Title\\\":\\\"An architecture for retaining and analyzing visual explorations of databases\\\"},\\\"460\\\":{\\\"Abstract\\\":\\\"This paper reports on the development of a strategy to generate databases used for real-time interactive landscape visualization. The database construction from real world data is intended to be as automated as possible. The primary sources of information are remote sensing imagery recorded by Landsat's Thematic Mapper (TM) and digital elevation models (DEM). Additional datasets (traffic networks and buildings) are added to extend the database. In a first step the TM images are geocoded and then segmented into areas of different land coverage. During the visual simulation highly detailed photo textures are applied onto the terrain based on the classification results to increase the apparent amount of detail. The data processing and integration is carried out using custom image processing and geographic information systems (GIS) software. Finally, a sample visual simulation application is implemented. Emphasis is put on practical implementation to test the feasibility of the approach as a whole\\\",\\\"Authors\\\":\\\"Suter, M.;Nuesch, D.\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;GeographyGeospatialVisCartographyTerrainVis;LevelOfDetail;SegmentationAndClassification;Simulation\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1995.480799\\\",\\\"Keywords\\\":\\\"geographic information systems;visual simulation;level-of-detail;satellite images;classification;remote sensing;geographic databases\\\",\\\"Keywords_Processed\\\":\\\"satellite image;geographic database;visual simulation;geographic information system;remote sensing;level of detail;classification\\\",\\\"Title\\\":\\\"Automated generation of visual simulation databases using remote sensing and GIS\\\"},\\\"461\\\":{\\\"Abstract\\\":\\\"An important challenge in the visualization of three-dimensional volume data is the efficient processing and rendering of time-resolved sequences. Only the use of compression techniques, which allow the reconstruction of the original domain from the compressed one locally, makes it possible to evaluate these sequences in their entirety. In this paper, a new approach for the extraction and visualization of so-called time features from within time-resolved volume data is presented. Based on the asymptotic decay of multiscale representations of spatially localized time evolutions of the data, singular points can be discriminated. Also, the corresponding Lipschitz exponents, which describe the signals' local regularity, can be determined, and can be taken as a measure of the variation in time. The compression ratio and the comprehension of the underlying signal is improved if we first restore the extracted regions which contain the most important information\\\",\\\"Authors\\\":\\\"Westermann, R.\\\",\\\"Clusters\\\":\\\"ImageBasedDataImageSignalProcessing;NumericalMethodsMathematics;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1995.480809\\\",\\\"Keywords\\\":\\\"wavelet transform;singularities;volume rendering;lipschitz exponents\\\",\\\"Keywords_Processed\\\":\\\"volume render;lipschitz exponent;singularity;wavelet transform\\\",\\\"Title\\\":\\\"Compression domain rendering of time-resolved volume data\\\"},\\\"462\\\":{\\\"Abstract\\\":\\\"Presents a conceptual framework and a process model for feature extraction and iconic visualization. Feature extraction is viewed as a process of data abstraction, which can proceed in multiple stages, and corresponding data abstraction levels. The features are represented by attribute sets, which play a key role in the visualization process. Icons are symbolic parametric objects, designed as visual representations of features. The attributes are mapped to the parameters (or degrees of freedom) of an icon. We describe some generic techniques to generate attribute sets, such as volume integrals and medial axis transforms. A simple but powerful modeling language was developed to create icons, and to link the attributes to the icon parameters. We present illustrative examples of iconic visualization created with the techniques described, showing the effectiveness of this approach\\\",\\\"Authors\\\":\\\"Post, F.J.;Van Walsum, T.;Post, F.H.;Silver, D.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;DataFeaturesAndAttributes;GlyphsGlyphBasedTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1995.485141\\\",\\\"Keywords\\\":\\\"scientific visualization;iconic visualization;attribute calculation;feature extraction\\\",\\\"Keywords_Processed\\\":\\\"scientific visualization;iconic visualization;feature extraction;attribute calculation\\\",\\\"Title\\\":\\\"Iconic techniques for feature visualization\\\"},\\\"463\\\":{\\\"Abstract\\\":\\\"Proposes as a generalization of isosurfaces, the `interval volume', which is a new type of geometric model representing 3D subvolumes with field values belonging to a closed interval. A dominant surface fitting algorithm called `marching cubes' is extended to obtain a solid fitting algorithm, which extracts from a given volumetric dataset a high-resolution polyhedral solid data structure of the interval volume. Rendering methods for the interval volume and principal related operations are also presented. The effectiveness of this approach is illustrated with 4D simulated data from atomic collision research\\\",\\\"Authors\\\":\\\"Fujishiro, I.;Maeda, Y.;Sato, H.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;PhysicsAndPhysicalSciences;SurfaceRelatedDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1995.480807\\\",\\\"Keywords\\\":\\\"surface fitting;volume visualization;marching cubes;isosurface;atomic collision\\\",\\\"Keywords_Processed\\\":\\\"march cube;surface fit;isosurface;atomic collision;volume visualization\\\",\\\"Title\\\":\\\"Interval volume: a solid fitting technique for volumetric data display and analysis\\\"},\\\"464\\\":{\\\"Abstract\\\":\\\"An important goal of visualization technology is to support the exploration and analysis of very large amounts of data. In this paper, we propose a new visualization technique called a `recursive pattern', which has been developed for visualizing large amounts of multidimensional data. The technique is based on a generic recursive scheme which generalizes a wide range of pixel-oriented arrangements for displaying large data sets. By instantiating the technique with adequate data- and application-dependent parameters, the user may greatly influence the structure of the resulting visualizations. Since the technique uses one pixel for presenting each data value, the amount of data which can be displayed is only limited by the resolution of current display technology and by the limitations of human perceptibility. Beside describing the basic idea of the `recursive pattern' technique, we provide several examples of useful parameter settings for the various recursion levels. We further show that our `recursive pattern' technique is particularly advantageous for the large class of data sets which have a natural order according to one dimension (e.g. time series data). We demonstrate the usefulness of our technique by using a stock market application\\\",\\\"Authors\\\":\\\"Keim, D.A.;Kriegel, H.-P.;Ankerst, M.\\\",\\\"Clusters\\\":\\\"LargeScaleDataAndScalability;MultidimensionalMultivariateMultifieldDataAndTechniques;UserInterfacesGeneral;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1995.485140\\\",\\\"Keywords\\\":\\\"large data visualization;visualizing large sequential data sets;interfaces to databases;recursive visualization techniques;multi-dimensional multi-variate visualization\\\",\\\"Keywords_Processed\\\":\\\"interface to database;visualize large sequential data set;large datum visualization;recursive visualization technique;multi dimensional multi variate visualization\\\",\\\"Title\\\":\\\"Recursive pattern: a technique for visualizing very large amounts of data\\\"},\\\"465\\\":{\\\"Abstract\\\":\\\"Selective dynamic manipulation (SDM) is a paradigm for interacting with objects in visualizations. Its methods offer a high degree of selectivity, in choosing object sets, in the selection of interactive techniques and the properties they affect, and in the degree to which a user action affects the visualization. Our goal is to provide a flexible set of techniques and feedback mechanisms that enable users to move objects and transform their appearance to perform a variety of information analysis tasks.\\\",\\\"Authors\\\":\\\"Chuah, M.C.;Roth, S.F.;Mattis, J.;Kolojejchick, J.\\\",\\\"Clusters\\\":\\\"InteractionTechniquesGeneral;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1995.528684\\\",\\\"Keywords\\\":\\\"interactive techniques;visualization;direct manipulation\\\",\\\"Keywords_Processed\\\":\\\"visualization;direct manipulation;interactive technique\\\",\\\"Title\\\":\\\"SDM: malleable information graphics\\\"},\\\"466\\\":{\\\"Abstract\\\":\\\"Presents a method for constructing tensor product Bezier surfaces from contour (cross-section) data. Minimal area triangulations are used to guide the surface construction, and the final surface reflects the optimality of the triangulation. The resulting surface differs from the initial triangulation in two important ways: it is smooth (as opposed to the piecewise planar triangulation), and it is in tensor product form (as opposed to the irregular triangular mesh). The surface reconstruction is efficient because we do not require an exact minimal surface. The triangulations are used as strong hints, but no more than that. The method requires the computation of both open and closed isoparametric curves of the surface, using triangulations as a guide. These isoparametric curves form a tensor product Bezier surface. We show how to control sampling density by filling and pruning isoparametric curves, for accuracy and economy. A rectangular grid of points is produced that is compatible with the expected format for a tensor product surface interpolation, so that a host of well-supported methods are available to generate and manipulate the surface\\\",\\\"Authors\\\":\\\"Johnstone, J.K.;Sloan, K.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;ContourCreasesRidgesValleys;GeometricModeling;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1995.480820\\\",\\\"Keywords\\\":\\\"bezier surface;minimum area triangulation;biomedical visualization;contour data;surface reconstruction\\\",\\\"Keywords_Processed\\\":\\\"minimum area triangulation;contour datum;biomedical visualization;surface reconstruction;bezi surface\\\",\\\"Title\\\":\\\"Tensor product surfaces guided by minimal surface area triangulations\\\"},\\\"467\\\":{\\\"Abstract\\\":\\\"Virtual reality can aid in designing large and complex structures such as ships, skyscrapers, factories, and aircraft. But before VR can realize this potential, we need to solve a number of problems. One of these problems: the user's need to see and interact with non-geometric information is examined. Our VR environment, RealEyes, can display large-scale and detailed geometry at reasonable frame rates (>20 Hz) allowing a user to see and navigate within a design from a first person perspective. However, much (if not most) of the information associated with a particular design has no geometric representation. This includes information such as schematics of electrical, hydraulic, and plumbing systems; information describing materials or processes; and descriptive (textual) information of other types. Many researchers have developed a wealth of techniques for presenting such data on flat-screen displays, but until recently, we have not had a means for naturally displaying such information within a VR environment. To make non-geometric data more available, we have implemented a version of Mosaic that functions within a fully immersive VR system. Our system, VRMosaic, allows a user of VR to access and display most of the data available using flat screen Mosaic. Moreover, we have made it extensible to allow for the seamless integration of specialized forms of data and interaction. This paper describes how we implemented VRMosaic using a VR-capable version of Interviews, It also describes some Mosaic-like uses of that system and some \\\\\\\"non-Mosaic-like\\\\\\\" extensions.\\\",\\\"Authors\\\":\\\"Angus, I.G.;Sowizral, H.A.\\\",\\\"Clusters\\\":\\\"ImmersiveAndVirtualEnvironments;UserInterfacesGeneral;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.1995.528687\\\",\\\"Keywords\\\":\\\"user interface components;mosaic;virtual reality\\\",\\\"Keywords_Processed\\\":\\\"virtual reality;mosaic;user interface component\\\",\\\"Title\\\":\\\"VRMosaic: WEB access from within a virtual environment\\\"},\\\"468\\\":{\\\"Abstract\\\":\\\"Cortex has been designed for interactive analysis and display of simulation data generated by CFD applications based on unstructured-grid solvers. Unlike post-processing visualization environments, Cortex is designed to work in co-processing mode with the CFD application. This significantly reduces data storage and data movement requirements for visualization and also allows users to interactively steer the application. Further, Cortex supports high-performance by running on massively parallel computers and workstation clusters. An important goal for Cortex, is to provide visualization to a variety of solvers which differ in their solution methodologies and supported flow models. Coupled with the co-processing requirement, this has required the development of a well defined programming interface to the CFD solver that lets the visualization system communicate efficiently with the solver, and requires minimal programming effort for porting to new solvers. Further, the requirement for targeting multiple solvers and application niches demands that the visualization system be rapidly and easily modifiable. Such flexibility is attained in Cortex by using the high-level, interpreted language Scheme for implementing user-interfaces and high-level visualization functions. By making the Scheme interpreter available from the Cortex text interface, the user can also customize and extend the visualization system\\\",\\\"Authors\\\":\\\"Banerjee, D.;Morley, C.;Smith, W.\\\",\\\"Clusters\\\":\\\"InteractionTechniquesGeneral;ParticleVisualizationAndTechniques;Rendering;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1994.346310\\\",\\\"Keywords\\\":\\\"smart particles;spray rendering;interactive;visualization environment;extensible\\\",\\\"Keywords_Processed\\\":\\\"spray render;visualization environment;extensible;smart particle;interactive\\\",\\\"Title\\\":\\\"The design and implementation of the Cortex visualization system\\\"},\\\"469\\\":{\\\"Abstract\\\":\\\"One of the most fundamental issues in magnetic fusion research is the understanding of turbulent transport observed in present-day tokamak experiments. Plasma turbulence is very challenging from a theoretical point of view due to the nonlinearity and high dimensionality of the governing equations. Recent developments in algorithms along with the astounding advances in high performance computing now make first-principle particle simulations an important tool for improved understanding of such phenomena. Due to the five dimensional phase space (3 spatial, 2 velocity) and complex toroidal geometry, visualization is crucial for interpreting such simulation data. This paper discusses how visualization tools are currently used and what new physics has been elucidated, along with what can be learned about tokamak turbulence through the interplay between theory, simulation and visualization\\\",\\\"Authors\\\":\\\"Parker, S.E.;Samtaney, R.\\\",\\\"Clusters\\\":\\\"GeometricModeling;GeometryBasedTechniques;InteractionTechniquesGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1994.346301\\\",\\\"Keywords\\\":\\\"sweeping;object modeling;implicit modeling;computational geometry;geometric modeling;volume modeling\\\",\\\"Keywords_Processed\\\":\\\"sweep;geometric modeling;implicit model;object modeling;volume model;computational geometry\\\",\\\"Title\\\":\\\"Tokamak plasma turbulence visualization\\\"},\\\"470\\\":{\\\"Abstract\\\":\\\"We present a 3-D antialiasing algorithm for voxel-based geometric models. The technique band-limits the continuous object before sampling it at the desired 3-D raster resolution. By precomputing tables of filter values for different types and sizes of geometric objects, the algorithm is very efficient and has a complexity that is linear with the number of voxels generated. The algorithm not only creates voxel models which are free from object space aliasing, but it also incorporates the image space antialiasing information as part of the view independent voxel model. The resulting alias-free voxel models have been used to model synthetic scenes, for discrete ray tracing applications. The discrete ray-traced image is superior in quality to the image generated with a conventional surface-based ray tracer, since silhouettes of objects, shadows, and reflections appear smooth (jaggy-less). In addition, the alias-free models are also suitable for intermixing with sampled datasets, since they can be treated uniformly as one common data representation\\\",\\\"Authors\\\":\\\"Wang, S.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"FilteringTechniques;RaytracingRaycasting;Sampling;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1993.398854\\\",\\\"Keywords\\\":\\\"filtering;volume sampling;voxelization;discrete raytracing\\\",\\\"Keywords_Processed\\\":\\\"volume sample;voxelization;filter;discrete raytracing\\\",\\\"Title\\\":\\\"Volume sampled voxelization of geometric primitives\\\"},\\\"471\\\":{\\\"Abstract\\\":\\\"The device unified interface is a generalized and easily expandable protocol for the communication between applications and input devices. The key idea is to unify various device data into the parameters of a so-called \\\\\\\"virtual input device.\\\\\\\" The device information-base, which includes device dependent information, is also incorporated into the virtual input device. Using the device unified interface, system builders are able to design their applications independent of the input devices as well as utilize the capabilities of several devices in the same application\\\",\\\"Authors\\\":\\\"Taosong He;Kaufman, A.\\\",\\\"Clusters\\\":\\\"InputAndOutputDevicesGeneral;InteractionTechniquesGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1993.398862\\\",\\\"Keywords\\\":\\\"3d input device;device information-base;device unified interface;virtual input device\\\",\\\"Keywords_Processed\\\":\\\"device unify interface;3d input device;device information base;virtual input device\\\",\\\"Title\\\":\\\"Virtual input devices for 3D systems\\\"},\\\"472\\\":{\\\"Abstract\\\":\\\"This paper introduces a novel representation, called the InfoCrystal, that can be used as a visualization tool as well as a visual query language to help users search for information. The InfoCrystal visualizes all the possible relationships among N concepts. Users can assign relevance weights to the concepts and use thresholding to select relationships of interest. The InfoCrystal allows users to specify Boolean as well as vector-space queries graphically. Arbitrarily complex queries can be created by using the InfoCrystals as building blocks and organizing them in a hierarchical structure. The InfoCrystal enables users to explore and filter information in a flexible, dynamic and interactive way\\\",\\\"Authors\\\":\\\"Spoerri, A.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;HumanComputerInteractionHumanFactors;QueriesAndSearch;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1993.398863\\\",\\\"Keywords\\\":\\\"visual query language;information visualization;information retrieval;graphical user interface;human factors\\\",\\\"Keywords_Processed\\\":\\\"graphical user interface;visual query language;information retrieval;human factor;information visualization\\\",\\\"Title\\\":\\\"InfoCrystal: A visual tool for information retrieval\\\"},\\\"473\\\":{\\\"Abstract\\\":\\\"A fast range search algorithm for visualizing extrema of d-dimensional volume data in real time as the user interactively moves the query range is presented. The algorithm is based on an efficient data structure, called index heap, which needs only O(N/log N) space and O(d2 dN) preprocessing time to be set up, where N is the size of the d-dimensional data volume. The algorithm can answer an extremum query in O(4d) expected time, and its worst-case time complexity is O(2d log N) per query. For dimensions two and three, the range search for extrema is effected in average O(1) time per query independently of the size of query range. Unlike previous range query algorithms in the computational geometry literature, the proposed algorithm is very simple and can be easily implemented.\\\",\\\"Authors\\\":\\\"Xiaolin Wu;Yonggang Fang\\\",\\\"Clusters\\\":\\\"GeometryBasedTechniques;HierarchicalTreeDataAndTechniques;ProgrammingAlgorithmsAndDataStructures;QueriesAndSearch;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1992.235216\\\",\\\"Keywords\\\":\\\"multi-dimensional range search;expected time complexity;computational geometry;volume visualization;data structures;nearest common ancestor;algorithm\\\",\\\"Keywords_Processed\\\":\\\"near common ancestor;multi dimensional range search;algorithm;data structure;expect time complexity;volume visualization;computational geometry\\\",\\\"Title\\\":\\\"An efficient range search algorithm for visualizing extrema of volume data\\\"},\\\"474\\\":{\\\"Abstract\\\":\\\"A visual interface for a multimedia database management system (MDBMS) is described. DBMS query languages are linear in syntax. Although natural language interfaces have been found to be useful, natural language is ambiguous and difficult to process. For queries on standard (relational) data, these difficulties can be avoided with the use of a visual, graphical interface to guide the user in specifying the query. For image and other media data which are ambiguous in nature, natural language processing, combined with direct graphical access to the domain knowledge, is used to interpret and evaluate the natural language query. The system fully supports graphical and image input/output in different formats. The combination of visual effect and natural language specification, the support of media data, and the allowance of incremental query specification simplify the process of query specification not only for image or multimedia databases but also for all databases\\\",\\\"Authors\\\":\\\"Keim, D.A.;Lum, V.\\\",\\\"Clusters\\\":\\\"DataAcquisitionAndManagement;DatabasesAndDataMining;QueriesAndSearch;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1992.235208\\\",\\\"Keywords\\\":\\\"multimedia database system;information retrieval;visual query specification;graphical user interface;image data management;natural language interface\\\",\\\"Keywords_Processed\\\":\\\"graphical user interface;image datum management;natural language interface;information retrieval;multimedia database system;visual query specification\\\",\\\"Title\\\":\\\"Visual query specification in a multimedia database system\\\"},\\\"475\\\":{\\\"Abstract\\\":\\\"In order to visualize both clouds and wind in climate simulations, clouds were rendered using a 3D texture which was advected by the wind flow. The simulation is described. Rendering, the advection of texture coordinates, and haze effects are discussed. Results are presented\\\",\\\"Authors\\\":\\\"Max, N.;Crawfis, R.;Williams, D.\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;FlowVisualizationDataAndTechniques;Textures;VectorFieldsDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1992.235210\\\",\\\"Keywords\\\":\\\"advection;vector field;clouds;volume visualization;wind;3d texture;climate modeling\\\",\\\"Keywords_Processed\\\":\\\"vector field;cloud;climate modeling;3d texture;volume visualization;advection;wind\\\",\\\"Title\\\":\\\"Visualizing wind velocities by advecting cloud textures\\\"},\\\"476\\\":{\\\"Abstract\\\":\\\"Partial automation of the task of designing graphical displays that effectively depict the data to be visualized through cooperative computer-aided design (CCAD) is described. This paradigm combines the strengths of manual and automated design by interspersing guiding design operations by the human user with the exploration of design alternatives by the computer. The approach is demonstrated in the context of the IVE design system, a CCAD environment for the design of scientific visualizations using a set of design rules that combine primitive visualization components in different ways. These alternatives are presented graphically to the user, who can browse through them, select the most promising visualization, and refine it manually\\\",\\\"Authors\\\":\\\"Kochhar, S.;Friedell, M.;LaPolla, M.\\\",\\\"Clusters\\\":\\\"AutomaticAnalysisVisualizationTechniques;CollaborativeVisualization;DesignMethodologiesAndInteractionDesign;HumanComputerInteractionHumanFactors\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.1991.175819\\\",\\\"Keywords\\\":\\\"grammar-directed design;automated design of graphical displays;design automation;cooperative design and modeling;human-computer interaction\\\",\\\"Keywords_Processed\\\":\\\"grammar direct design;design automation;human computer interaction;cooperative design and modeling;automate design of graphical display\\\",\\\"Title\\\":\\\"Cooperative, computer-aided design of scientific visualizations\\\"},\\\"477\\\":{\\\"Abstract\\\":\\\"While a number of information visualization software frameworks exist, creating new visualizations, especially those that involve novel visualization metaphors, interaction techniques, data analysis strategies, and specialized rendering algorithms, is still often a difficult process. To facilitate the creation of novel visualizations we present a new software framework, behaviorism, which provides a wide range of flexibility when working with dynamic information on visual, temporal, and ontological levels, but at the same time providing appropriate abstractions which allow developers to create prototypes quickly which can then easily be turned into robust systems. The core of the framework is a set of three interconnected graphs, each with associated operators: a scene graph for high-performance 3D rendering, a data graph for different layers of semantically-linked heterogeneous data, and a timing graph for sophisticated control of scheduling, interaction, and animation. In particular, the timing graph provides a unified system to add behaviors to both data and visual elements, as well as to the behaviors themselves. To evaluate the framework we look briefly at three different projects all of which required novel visualizations in different domains, and all of which worked with dynamic data in different ways: an interactive ecological simulation, an information art installation, and an information visualization technique.\\\",\\\"Authors\\\":\\\"Forbes, A.;Hollerer, T.;Legrady, G.\\\",\\\"Clusters\\\":\\\"ArtAndAestheticsInVisualization;DynamicDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.126\\\",\\\"Keywords\\\":\\\"dynamic data;information visualization;information art;framework\\\",\\\"Keywords_Processed\\\":\\\"dynamic datum;information art;framework;information visualization\\\",\\\"Title\\\":\\\"behaviorism: a framework for dynamic data visualization\\\"},\\\"478\\\":{\\\"Abstract\\\":\\\"We introduce the concept of a Visual Backchannel as a novel way of following and exploring online conversations about large-scale events. Microblogging communities, such as Twitter, are increasingly used as digital backchannels for timely exchange of brief comments and impressions during political speeches, sport competitions, natural disasters, and other large events. Currently, shared updates are typically displayed in the form of a simple list, making it difficult to get an overview of the fast-paced discussions as it happens in the moment and how it evolves over time. In contrast, our Visual Backchannel design provides an evolving, interactive, and multi-faceted visual overview of large-scale ongoing conversations on Twitter. To visualize a continuously updating information stream, we include visual saliency for what is happening now and what has just happened, set in the context of the evolving conversation. As part of a fully web-based coordinated-view system we introduce Topic Streams, a temporally adjustable stacked graph visualizing topics over time, a People Spiral representing participants and their activity, and an Image Cloud encoding the popularity of event photos by size. Together with a post listing, these mutually linked views support cross-filtering along topics, participants, and time ranges. We discuss our design considerations, in particular with respect to evolving visualizations of dynamically changing data. Initial feedback indicates significant interest and suggests several unanticipated uses.\\\",\\\"Authors\\\":\\\"Dork, M.;Gruen, D.;Williamson, C.;Carpendale, S.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;EventsTrendsOutlierDetectionAnalysisAndVisualization;InternetWebVisualizationForTheMasses;MultipleLinkedCoordinatedViews;SocialNetworksAndSocialMedia;SocialScienceAndHumanities;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.129\\\",\\\"Keywords\\\":\\\"information visualization;information retrieval;backchannel;multiple views;microblogging;events;world wide web\\\",\\\"Keywords_Processed\\\":\\\"world wide web;information retrieval;information visualization;backchannel;multiple view;microblogge;event\\\",\\\"Title\\\":\\\"A Visual Backchannel for Large-Scale Events\\\"},\\\"479\\\":{\\\"Abstract\\\":\\\"The non-data components of a visualization, such as axes and legends, can often be just as important as the data itself. They provide contextual information essential to interpreting the data. In this paper, we describe an automated system for choosing positions and labels for axis tick marks. Our system extends Wilkinson's optimization-based labeling approach to create a more robust, full-featured axis labeler. We define an expanded space of axis labelings by automatically generating additional nice numbers as needed and by permitting the extreme labels to occur inside the data range. These changes provide flexibility in problematic cases, without degrading quality elsewhere. We also propose an additional optimization criterion, legibility, which allows us to simultaneously optimize over label formatting, font size, and orientation. To solve this revised optimization problem, we describe the optimization function and an efficient search algorithm. Finally, we compare our method to previous work using both quantitative and qualitative metrics. This paper is a good example of how ideas from automated graphic design can be applied to information visualization.\\\",\\\"Authors\\\":\\\"Talbot, J.;Lin, S.;Hanrahan, P.\\\",\\\"Clusters\\\":\\\"Labeling;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.130\\\",\\\"Keywords\\\":\\\"axis labeling;nice numbers\\\",\\\"Keywords_Processed\\\":\\\"nice number;axis labeling\\\",\\\"Title\\\":\\\"An Extension of Wilkinson's Algorithm for Positioning Tick Labels on Axes\\\"},\\\"480\\\":{\\\"Abstract\\\":\\\"When analyzing multidimensional, quantitative data, the comparison of two or more groups of dimensions is a common task. Typical sources of such data are experiments in biology, physics or engineering, which are conducted in different configurations and use replicates to ensure statistically significant results. One common way to analyze this data is to filter it using statistical methods and then run clustering algorithms to group similar values. The clustering results can be visualized using heat maps, which show differences between groups as changes in color. However, in cases where groups of dimensions have an a priori meaning, it is not desirable to cluster all dimensions combined, since a clustering algorithm can fragment continuous blocks of records. Furthermore, identifying relevant elements in heat maps becomes more difficult as the number of dimensions increases. To aid in such situations, we have developed Matchmaker, a visualization technique that allows researchers to arbitrarily arrange and compare multiple groups of dimensions at the same time. We create separate groups of dimensions which can be clustered individually, and place them in an arrangement of heat maps reminiscent of parallel coordinates. To identify relations, we render bundled curves and ribbons between related records in different groups. We then allow interactive drill-downs using enlarged detail views of the data, which enable in-depth comparisons of clusters between groups. To reduce visual clutter, we minimize crossings between the views. This paper concludes with two case studies. The first demonstrates the value of our technique for the comparison of clustering algorithms. In the second, biologists use our system to investigate why certain strains of mice develop liver disease while others remain healthy, informally showing the efficacy of our system when analyzing multidimensional data containing distinct groups of dimensions.\\\",\\\"Authors\\\":\\\"Lex, A.;Streit, M.;Partl, C.;Kashofer, K.;Schmalstieg, D.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;DataClusteringAndAggregation;MultidimensionalMultivariateMultifieldDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.138\\\",\\\"Keywords\\\":\\\"bioinformatics visualization;cluster comparison;multi-dimensional data\\\",\\\"Keywords_Processed\\\":\\\"bioinformatic visualization;multi dimensional datum;cluster comparison\\\",\\\"Title\\\":\\\"Comparative Analysis of Multidimensional; Quantitative Data\\\"},\\\"481\\\":{\\\"Abstract\\\":\\\"We investigate the design of declarative, domain-specific languages for constructing interactive visualizations. By separating specification from execution, declarative languages can simplify development, enable unobtrusive optimization, and support retargeting across platforms. We describe the design of the Protovis specification language and its implementation within an object-oriented, statically-typed programming language (Java). We demonstrate how to support rich visualizations without requiring a toolkit-specific data model and extend Protovis to enable declarative specification of animated transitions. To support cross-platform deployment, we introduce rendering and event-handling infrastructures decoupled from the runtime platform, letting designers retarget visualization specifications (e.g., from desktop to mobile phone) with reduced effort. We also explore optimizations such as runtime compilation of visualization specifications, parallelized execution, and hardware-accelerated rendering. We present benchmark studies measuring the performance gains provided by these optimizations and compare performance to existing Java-based visualization tools, demonstrating scalability improvements exceeding an order of magnitude.\\\",\\\"Authors\\\":\\\"Heer, J.;Bostock, M.\\\",\\\"Clusters\\\":\\\"Optimization;ProgrammingAlgorithmsAndDataStructures;UserInterfacesGeneral;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.144\\\",\\\"Keywords\\\":\\\"information visualization;user interface;optimization;toolkits;declarative languages;domain-specific languages\\\",\\\"Keywords_Processed\\\":\\\"optimization;user interface;domain specific language;information visualization;declarative language;toolkit\\\",\\\"Title\\\":\\\"Declarative Language Design for Interactive Visualization\\\"},\\\"482\\\":{\\\"Abstract\\\":\\\"Pixel-based visualization is a popular method of conveying large amounts of numerical data graphically. Application scenarios include business and finance, bioinformatics and remote sensing. In this work, we examined how the usability of such visual representations varied across different tasks and block resolutions. The main stimuli consisted of temporal pixel-based visualization with a white-red color map, simulating monthly temperature variation over a six-year period. In the first study, we included 5 separate tasks to exert different perceptual loads. We found that performance varied considerably as a function of task, ranging from 75% correct in low-load tasks to below 40% in high-load tasks. There was a small but consistent effect of resolution, with the uniform patch improving performance by around 6% relative to higher block resolution. In the second user study, we focused on a high-load task for evaluating month-to-month changes across different regions of the temperature range. We tested both CIE L*u*v* and RGB color spaces. We found that the nature of the change-evaluation errors related directly to the distance between the compared regions in the mapped color space. We were able to reduce such errors by using multiple color bands for the same data range. In a final study, we examined more fully the influence of block resolution on performance, and found block resolution had a limited impact on the effectiveness of pixel-based visualization.\\\",\\\"Authors\\\":\\\"Borgo, R.;Proctor, K.;Chen, M.;Jnicke, H.;Murray, T.;Thornton, I.M.\\\",\\\"Clusters\\\":\\\"DynamicVisualizationVisualizationOfChange;EvaluationGeneral;PixelOrientedEncodings;QueriesAndSearch\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.150\\\",\\\"Keywords\\\":\\\"user study;change detection;pixel-based visualization;visual search;evaluation\\\",\\\"Keywords_Processed\\\":\\\"change detection;user study;visual search;pixel base visualization;evaluation\\\",\\\"Title\\\":\\\"Evaluating the impact of task demands and block resolution on the effectiveness of pixel-based visualization\\\"},\\\"483\\\":{\\\"Abstract\\\":\\\"Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present FacetAtlas, a multifaceted visualization technique for visually analyzing rich text corpora. FacetAtlas combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of FacetAtlas, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of FacetAtlas through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis.\\\",\\\"Authors\\\":\\\"Nan Cao;Jimeng Sun;Yu-Ru Lin;Gotz, D.;Shixia Liu;Huamin Qu\\\",\\\"Clusters\\\":\\\"DataFacetsAndTechniques;GraphNetworkDataAndTechniques;QueriesAndSearch;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.154\\\",\\\"Keywords\\\":\\\"search user interface;multi-facet visualization;multi-relational graph;text visualization\\\",\\\"Keywords_Processed\\\":\\\"text visualization;search user interface;multi relational graph;multi facet visualization\\\",\\\"Title\\\":\\\"FacetAtlas: Multifaceted Visualization for Rich Text Corpora\\\"},\\\"484\\\":{\\\"Abstract\\\":\\\"GeneaQuilts is a new visualization technique for representing large genealogies of up to several thousand individuals. The visualization takes the form of a diagonally-filled matrix, where rows are individuals and columns are nuclear families. After identifying the major tasks performed in genealogical research and the limits of current software, we present an interactive genealogy exploration system based on GeneaQuilts. The system includes an overview, a timeline, search and filtering components, and a new interaction technique called Bring & Slide that allows fluid navigation in very large genealogies. We report on preliminary feedback from domain experts and show how our system supports a number of their tasks.\\\",\\\"Authors\\\":\\\"Bezerianos, A.;Dragicevic, P.;Fekete, J.;Juhee Bae;Watson, B.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;InteractionTechniquesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.159\\\",\\\"Keywords\\\":\\\"genealogy visualization;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;genealogy visualization\\\",\\\"Title\\\":\\\"GeneaQuilts: A System for Exploring Large Genealogies\\\"},\\\"485\\\":{\\\"Abstract\\\":\\\"How do we know if what we see is really there? When visualizing data, how do we avoid falling into the trap of apophenia where we see patterns in random noise? Traditionally, infovis has been concerned with discovering new relationships, and statistics with preventing spurious relationships from being reported. We pull these opposing poles closer with two new techniques for rigorous statistical inference of visual discoveries. The \\\\\\\"Rorschach\\\\\\\" helps the analyst calibrate their understanding of uncertainty and \\\\\\\"line-up\\\\\\\" provides a protocol for assessing the significance of visual discoveries, protecting against the discovery of spurious structure.\\\",\\\"Authors\\\":\\\"Wickham, H.;Cook, D.;Hofmann, H.;Buja, Andreas\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;EvaluationGeneral;MachineLearningAndStatistics;QuantitativeEvaluation\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.161\\\",\\\"Keywords\\\":\\\"visual testing;permutation tests;data plots;null hypotheses;statistics\\\",\\\"Keywords_Processed\\\":\\\"visual testing;null hypothesis;data plot;permutation test;statistic\\\",\\\"Title\\\":\\\"Graphical inference for infovis\\\"},\\\"486\\\":{\\\"Abstract\\\":\\\"Line graphs have been the visualization of choice for temporal data ever since the days of William Playfair (1759-1823), but realistic temporal analysis tasks often include multiple simultaneous time series. In this work, we explore user performance for comparison, slope, and discrimination tasks for different line graph techniques involving multiple time series. Our results show that techniques that create separate charts for each time series--such as small multiples and horizon graphs--are generally more efficient for comparisons across time series with a large visual span. On the other hand, shared-space techniques--like standard line graphs--are typically more efficient for comparisons over smaller visual spans where the impact of overlap and clutter is reduced.\\\",\\\"Authors\\\":\\\"Javed, W.;McDonnel, B.;Elmqvist, N.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;EvaluationGeneral;VisualDesignDesignGuidelines;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.162\\\",\\\"Keywords\\\":\\\"stacked graphs;design guidelines;braided graphs;horizon graphs;line charts;small multiples;evaluation\\\",\\\"Keywords_Processed\\\":\\\"braid graph;design guideline;line chart;small multiple;stack graph;horizon graphs;evaluation\\\",\\\"Title\\\":\\\"Graphical Perception of Multiple Time Series\\\"},\\\"487\\\":{\\\"Abstract\\\":\\\"In this work we present, apply, and evaluate a novel, interactive visualization model for comparative analysis of structural variants and rearrangements in human and cancer genomes, with emphasis on data integration and uncertainty visualization. To support both global trend analysis and local feature detection, this model enables explorations continuously scaled from the high-level, complete genome perspective, down to the low-level, structural rearrangement view, while preserving global context at all times. We have implemented these techniques in Gremlin, a genomic rearrangement explorer with multi-scale, linked interactions, which we apply to four human cancer genome data sets for evaluation. Using an insight-based evaluation methodology, we compare Gremlin to Circos, the state-of-the-art in genomic rearrangement visualization, through a small user study with computational biologists working in rearrangement analysis. Results from user study evaluations demonstrate that this visualization model enables more total insights, more insights per minute, and more complex insights than the current state-of-the-art for visual analysis and exploration of genome rearrangements.\\\",\\\"Authors\\\":\\\"O'Brien, T.M.;Ritz, A.M.;Raphael, B.J.;Laidlaw, D.H.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;EvaluationGeneral;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.163\\\",\\\"Keywords\\\":\\\"information visualization;insight-based evaluation;bioinformatics\\\",\\\"Keywords_Processed\\\":\\\"bioinformatic;information visualization;insight base evaluation\\\",\\\"Title\\\":\\\"Gremlin: An Interactive Visualization Model for Analyzing Genomic Rearrangements\\\"},\\\"488\\\":{\\\"Abstract\\\":\\\"It remains challenging for information visualization novices to rapidly construct visualizations during exploratory data analysis. We conducted an exploratory laboratory study in which information visualization novices explored fictitious sales data by communicating visualization specifications to a human mediator, who rapidly constructed the visualizations using commercial visualization software. We found that three activities were central to the iterative visualization construction process: data attribute selection, visual template selection, and visual mapping specification. The major barriers faced by the participants were translating questions into data attributes, designing visual mappings, and interpreting the visualizations. Partial specification was common, and the participants used simple heuristics and preferred visualizations they were already familiar with, such as bar, line and pie charts. We derived abstract models from our observations that describe barriers in the data exploration process and uncovered how information visualization novices think about visualization specifications. Our findings support the need for tools that suggest potential visualizations and support iterative refinement, that provide explanations and help with learning, and that are tightly integrated into tool support for the overall visual analytics process.\\\",\\\"Authors\\\":\\\"Grammel, L.;Tory, M.;Storey, M.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;HumanComputerInteractionHumanFactors;VisualDesignDesignGuidelines;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.164\\\",\\\"Keywords\\\":\\\"visual mapping;novices;visualization;visualization construction;visual analytics;empirical study\\\",\\\"Keywords_Processed\\\":\\\"visualization;visual mapping;empirical study;visual analytic;visualization construction;novice\\\",\\\"Title\\\":\\\"How Information Visualization Novices Construct Visualizations\\\"},\\\"489\\\":{\\\"Abstract\\\":\\\"Many of the pressing questions in information visualization deal with how exactly a user reads a collection of visual marks as information about relationships between entities. Previous research has suggested that people see parts of a visualization as objects, and may metaphorically interpret apparent physical relationships between these objects as suggestive of data relationships. We explored this hypothesis in detail in a series of user experiments. Inspired by the concept of implied dynamics in psychology, we first studied whether perceived gravity acting on a mark in a scatterplot can lead to errors in a participant's recall of the mark's position. The results of this study suggested that such position errors exist, but may be more strongly influenced by attraction between marks. We hypothesized that such apparent attraction may be influenced by elements used to suggest relationship between objects, such as connecting lines, grouping elements, and visual similarity. We further studied what visual elements are most likely to cause this attraction effect, and whether the elements that best predicted attraction errors were also those which suggested conceptual relationships most strongly. Our findings show a correlation between attraction errors and intuitions about relatedness, pointing towards a possible mechanism by which the perception of visual marks becomes an interpretation of data relationships.\\\",\\\"Authors\\\":\\\"Ziemkiewicz, C.;Kosara, R.\\\",\\\"Clusters\\\":\\\"Cognition;LaboratoryStudies;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.174\\\",\\\"Keywords\\\":\\\"perceptual cognition;laboratory studies;visualization models;cognition theory\\\",\\\"Keywords_Processed\\\":\\\"laboratory study;perceptual cognition;visualization model;cognition theory\\\",\\\"Title\\\":\\\"Laws of Attraction: From Perceptual Forces to Conceptual Similarity\\\"},\\\"490\\\":{\\\"Abstract\\\":\\\"Among the multifarious tag-clouding techniques, Wordle stands out to the community by providing an aesthetic layout, eliciting the emergence of the participatory culture and usage of tag-clouding in the artistic creations. In this paper, we introduce ManiWordle, a Wordle-based visualization tool that revamps interactions with the layout by supporting custom manipulations. ManiWordle allows people to manipulate typography, color, and composition not only for the layout as a whole, but also for the individual words, enabling them to have better control over the layout result. We first describe our design rationale along with the interaction techniques for tweaking the layout. We then present the results both from the preliminary usability study and from the comparative study between ManiWordle and Wordle. The results suggest that ManiWordle provides higher user satisfaction and an efficient method of creating the desired \\\\\\\"art work,\\\\\\\" harnessing the power behind the ever-increasing popularity of Wordle.\\\",\\\"Authors\\\":\\\"Koh, K.;Bongshin Lee;Bohyoung Kim;Jinwook Seo\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;CollaborativeVisualization;DesignMethodologiesAndInteractionDesign;EvaluationGeneral;HumanComputerInteractionHumanFactors;InteractionTechniquesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.175\\\",\\\"Keywords\\\":\\\"user study;interaction design;flexibility-usability tradeoff;tag clouds;participatory visualization;direct manipulation\\\",\\\"Keywords_Processed\\\":\\\"user study;participatory visualization;flexibility usability tradeoff;tag cloud;direct manipulation;interaction design\\\",\\\"Title\\\":\\\"ManiWordle: Providing Flexible Control over Wordle\\\"},\\\"491\\\":{\\\"Abstract\\\":\\\"Conveying data uncertainty in visualizations is crucial for preventing viewers from drawing conclusions based on untrustworthy data points. This paper proposes a methodology for efficiently generating density plots of uncertain multivariate data sets that draws viewers to preattentively identify values of high certainty while not calling attention to uncertain values. We demonstrate how to augment scatter plots and parallel coordinates plots to incorporate statistically modeled uncertainty and show how to integrate them with existing multivariate analysis techniques, including outlier detection and interactive brushing. Computing high quality density plots can be expensive for large data sets, so we also describe a probabilistic plotting technique that summarizes the data without requiring explicit density plot computation. These techniques have been useful for identifying brain tumors in multivariate magnetic resonance spectroscopy data and we describe how to extend them to visualize ensemble data sets.\\\",\\\"Authors\\\":\\\"Feng, D.;Kwock, L.;Yueh Lee;Taylor, R.M.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;InteractionTechniquesGeneral;MultidimensionalMultivariateMultifieldDataAndTechniques;ParallelCoordinates;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.176\\\",\\\"Keywords\\\":\\\"scatterplot;uncertainty visualization;brushing;multivariate data;parallel coordinates\\\",\\\"Keywords_Processed\\\":\\\"multivariate datum;parallel coordinate;brush;scatterplot;uncertainty visualization\\\",\\\"Title\\\":\\\"Matching Visual Saliency to Confidence in Plots of Uncertain Data\\\"},\\\"492\\\":{\\\"Abstract\\\":\\\"Although previous research has suggested that examining the interplay between internal and external representations can benefit our understanding of the role of information visualization (InfoVis) in human cognitive activities, there has been little work detailing the nature of internal representations, the relationship between internal and external representations and how interaction is related to these representations. In this paper, we identify and illustrate a specific kind of internal representation, mental models, and outline the high-level relationships between mental models and external visualizations. We present a top-down perspective of reasoning as model construction and simulation, and discuss the role of visualization in model based reasoning. From this perspective, interaction can be understood as active modeling for three primary purposes: external anchoring, information foraging, and cognitive offloading. Finally we discuss the implications of our approach for design, evaluation and theory development.\\\",\\\"Authors\\\":\\\"Zhicheng Liu;Stasko, J.\\\",\\\"Clusters\\\":\\\"Cognition;InteractionTechniquesGeneral;ReasoningProblemSolvingAndDecisionMaking;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.177\\\",\\\"Keywords\\\":\\\"information visualization;theory;mental model;distributed cognition;model-based reasoning;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;mental model;information visualization;theory;model base reasoning;distribute cognition\\\",\\\"Title\\\":\\\"Mental Models; Visual Reasoning and Interaction in Information Visualization: A Top-down Perspective\\\"},\\\"493\\\":{\\\"Abstract\\\":\\\"Cells in an organism share the same genetic information in their DNA, but have very different forms and behavior because of the selective expression of subsets of their genes. The widely used approach of measuring gene expression over time from a tissue sample using techniques such as microarrays or sequencing do not provide information about the spatial position with in the tissue where these genes are expressed. In contrast, we are working with biologists who use techniques that measure gene expression in every individual cell of entire fruitfly embryos over an hour of their development, and do so for multiple closely-related subspecies of Drosophila. These scientists are faced with the challenge of integrating temporal gene expression data with the spatial location of cells and, moreover, comparing this data across multiple related species. We have worked with these biologists over the past two years to develop MulteeSum, a visualization system that supports inspection and curation of data sets showing gene expression over time, in conjunction with the spatial location of the cells where the genes are expressed - it is the first tool to support comparisons across multiple such data sets. MulteeSum is part of a general and flexible framework we developed with our collaborators that is built around multiple summaries for each cell, allowing the biologists to explore the results of computations that mix spatial information, gene expression measurements over time, and data from multiple related species or organisms. We justify our design decisions based on specific descriptions of the analysis needs of our collaborators, and provide anecdotal evidence of the efficacy of MulteeSum through a series of case studies.\\\",\\\"Authors\\\":\\\"Meyer, M.;Munzner, T.;DePace, A.;Pfister, H.\\\",\\\"Clusters\\\":\\\"Genetics;SpaceRelatedSpatialDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.137\\\",\\\"Keywords\\\":\\\"spatial data;gene expression;temporal data\\\",\\\"Keywords_Processed\\\":\\\"spatial datum;temporal datum;gene expression\\\",\\\"Title\\\":\\\"MulteeSum: A Tool for Comparative Spatial and Temporal Gene Expression Data\\\"},\\\"494\\\":{\\\"Abstract\\\":\\\"Data visualization is regularly promoted for its ability to reveal stories within data, yet these data stories differ in important ways from traditional forms of storytelling. Storytellers, especially online journalists, have increasingly been integrating visualizations into their narratives, in some cases allowing the visualization to function in place of a written story. In this paper, we systematically review the design space of this emerging class of visualizations. Drawing on case studies from news media to visualization research, we identify distinct genres of narrative visualization. We characterize these design differences, together with interactivity and messaging, in terms of the balance between the narrative flow intended by the author (imposed by graphical elements and the interface) and story discovery on the part of the reader (often through interactive exploration). Our framework suggests design strategies for narrative visualization, including promising under-explored approaches to journalistic storytelling and educational media.\\\",\\\"Authors\\\":\\\"Segel, E.;Heer, J.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;DesignMethodologiesAndInteractionDesign;DesignStudiesAndCaseStudies;SocialNetworksAndSocialMedia;Storytelling\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.179\\\",\\\"Keywords\\\":\\\"narrative visualization;journalism;case study;storytelling;design methods;social data analysis\\\",\\\"Keywords_Processed\\\":\\\"case study;narrative visualization;storytelle;journalism;design method;social datum analysis\\\",\\\"Title\\\":\\\"Narrative Visualization: Telling Stories with Data\\\"},\\\"495\\\":{\\\"Abstract\\\":\\\"Statistical data associated with geographic regions is nowadays globally available in large amounts and hence automated methods to visually display these data are in high demand. There are several well-established thematic map types for quantitative data on the ratio-scale associated with regions: choropleth maps, cartograms, and proportional symbol maps. However, all these maps suffer from limitations, especially if large data values are associated with small regions. To overcome these limitations, we propose a novel type of quantitative thematic map, the necklace map. In a necklace map, the regions of the underlying two-dimensional map are projected onto intervals on a one-dimensional curve (the necklace) that surrounds the map regions. Symbols are scaled such that their area corresponds to the data of their region and placed without overlap inside the corresponding interval on the necklace. Necklace maps appear clear and uncluttered and allow for comparatively large symbol sizes. They visualize data sets well which are not proportional to region sizes. The linear ordering of the symbols along the necklace facilitates an easy comparison of symbol sizes. One map can contain several nested or disjoint necklaces to visualize clustered data. The advantages of necklace maps come at a price: the association between a symbol and its region is weaker than with other types of maps. Interactivity can help to strengthen this association if necessary. We present an automated approach to generate necklace maps which allows the user to interactively control the final symbol placement. We validate our approach with experiments using various data sets and maps.\\\",\\\"Authors\\\":\\\"Speckmann, B.;Verbeek, K.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;Maps;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.180\\\",\\\"Keywords\\\":\\\"necklace maps;automated cartography;geographic visualization;proportional symbol maps\\\",\\\"Keywords_Processed\\\":\\\"geographic visualization;necklace map;automate cartography;proportional symbol map\\\",\\\"Title\\\":\\\"Necklace Maps\\\"},\\\"496\\\":{\\\"Abstract\\\":\\\"The rapid development of Web technology has resulted in an increasing number of hotel customers sharing their opinions on the hotel services. Effective visual analysis of online customer opinions is needed, as it has a significant impact on building a successful business. In this paper, we present OpinionSeer, an interactive visualization system that could visually analyze a large collection of online hotel customer reviews. The system is built on a new visualization-centric opinion mining technique that considers uncertainty for faithfully modeling and analyzing customer opinions. A new visual representation is developed to convey customer opinions by augmenting well-established scatterplots and radial visualization. To provide multiple-level exploration, we introduce subjective logic to handle and organize subjective opinions with degrees of uncertainty. Several case studies illustrate the effectiveness and usefulness of OpinionSeer on analyzing relationships among multiple data dimensions and comparing opinions of different groups. Aside from data on hotel customer feedback, OpinionSeer could also be applied to visually analyze customer opinions on other products or services.\\\",\\\"Authors\\\":\\\"Yingcai Wu;Furu Wei;Shixia Liu;Au, N.;Weiwei Cui;Hong Zhou;Huamin Qu\\\",\\\"Clusters\\\":\\\"TextDocumentTopicAnalysisDataAndTechniques;UncertaintyTechniquesAndVisualization;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.183\\\",\\\"Keywords\\\":\\\"radial visualization;opinion visualization;uncertainty visualization\\\",\\\"Keywords_Processed\\\":\\\"radial visualization;opinion visualization;uncertainty visualization\\\",\\\"Title\\\":\\\"OpinionSeer: Interactive Visualization of Hotel Customer Feedback\\\"},\\\"497\\\":{\\\"Abstract\\\":\\\"Interactive visualization requires the translation of data into a screen space of limited resolution. While currently ignored by most visualization models, this translation entails a loss of information and the introduction of a number of artifacts that can be useful, (e.g., aggregation, structures) or distracting (e.g., over-plotting, clutter) for the analysis. This phenomenon is observed in parallel coordinates, where overlapping lines between adjacent axes form distinct patterns, representing the relation between variables they connect. However, even for a small number of dimensions, the challenge is to effectively convey the relationships for all combinations of dimensions. The size of the dataset and a large number of dimensions only add to the complexity of this problem. To address these issues, we propose Pargnostics, parallel coordinates diagnostics, a model based on screen-space metrics that quantify the different visual structures. Pargnostics metrics are calculated for pairs of axes and take into account the resolution of the display as well as potential axis inversions. Metrics include the number of line crossings, crossing angles, convergence, overplotting, etc. To construct a visualization view, the user can pick from a ranked display showing pairs of coordinate axes and the structures between them, or examine all possible combinations of axes at once in a matrix display. Picking the best axes layout is an NP-complete problem in general, but we provide a way of automatically optimizing the display according to the user's preferences based on our metrics and model.\\\",\\\"Authors\\\":\\\"Dasgupta, A.;Kosara, R.\\\",\\\"Clusters\\\":\\\"DisplaysGeneral;EvaluationMetricsAndBenchmarks;ParallelCoordinates;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.184\\\",\\\"Keywords\\\":\\\"display optimization;visualization models;parallel coordinates;metrics\\\",\\\"Keywords_Processed\\\":\\\"parallel coordinate;metric;visualization model;display optimization\\\",\\\"Title\\\":\\\"Pargnostics: Screen-Space Metrics for Parallel Coordinates\\\"},\\\"498\\\":{\\\"Abstract\\\":\\\"Public genealogical databases are becoming increasingly populated with historical data and records of the current population's ancestors. As this increasing amount of available information is used to link individuals to their ancestors, the resulting trees become deeper and more dense, which justifies the need for using organized, space-efficient layouts to display the data. Existing layouts are often only able to show a small subset of the data at a time. As a result, it is easy to become lost when navigating through the data or to lose sight of the overall tree structure. On the contrary, leaving space for unknown ancestors allows one to better understand the tree's structure, but leaving this space becomes expensive and allows fewer generations to be displayed at a time. In this work, we propose that the H-tree based layout be used in genealogical software to display ancestral trees. We will show that this layout presents an increase in the number of displayable generations, provides a nicely arranged, symmetrical, intuitive and organized fractal structure, increases the user's ability to understand and navigate through the data, and accounts for the visualization requirements necessary for displaying such trees. Finally, user-study results indicate potential for user acceptance of the new layout.\\\",\\\"Authors\\\":\\\"Tuttle, C.;Nonato, L.G.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;HierarchicalTreeDataAndTechniques;ProvenanceAndHistory\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.185\\\",\\\"Keywords\\\":\\\"h-tree;genealogy;pedigree\\\",\\\"Keywords_Processed\\\":\\\"pedigree;genealogy;tree\\\",\\\"Title\\\":\\\"PedVis: A Structured; Space-Efficient Technique for Pedigree Visualization\\\"},\\\"499\\\":{\\\"Abstract\\\":\\\"Treemaps are space-filling visualizations that make efficient use of limited display space to depict large amounts of hierarchical data. Creating perceptually effective treemaps requires carefully managing a number of design parameters including the aspect ratio and luminance of rectangles. Moreover, treemaps encode values using area, which has been found to be less accurate than judgments of other visual encodings, such as length. We conduct a series of controlled experiments aimed at producing a set of design guidelines for creating effective rectangular treemaps. We find no evidence that luminance affects area judgments, but observe that aspect ratio does have an effect. Specifically, we find that the accuracy of area comparisons suffers when the compared rectangles have extreme aspect ratios or when both are squares. Contrary to common assumptions, the optimal distribution of rectangle aspect ratios within a treemap should include non-squares, but should avoid extremes. We then compare treemaps with hierarchical bar chart displays to identify the data densities at which length-encoded bar charts become less effective than area-encoded treemaps. We report the transition points at which treemaps exhibit judgment accuracy on par with bar charts for both leaf and non-leaf tree nodes. We also find that even at relatively low data densities treemaps result in faster comparisons than bar charts. Based on these results, we present a set of guidelines for the effective use of treemaps and suggest alternate approaches for treemap layout.\\\",\\\"Authors\\\":\\\"Kong, N.;Heer, J.;Agrawala, M.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;HierarchicalTreeDataAndTechniques;Perception;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.186\\\",\\\"Keywords\\\":\\\"mechanical turk;treemap;graphical perception;rectangular area;visualization;visual encoding;experiment\\\",\\\"Keywords_Processed\\\":\\\"visualization;rectangular area;treemap;visual encoding;graphical perception;experiment;mechanical turk\\\",\\\"Title\\\":\\\"Perceptual Guidelines for Creating Rectangular Treemaps\\\"},\\\"500\\\":{\\\"Abstract\\\":\\\"This design paper presents new guidance for creating map legends in a dynamic environment. Our contribution is a set ofguidelines for legend design in a visualization context and a series of illustrative themes through which they may be expressed. Theseare demonstrated in an applications context through interactive software prototypes. The guidelines are derived from cartographicliterature and in liaison with EDINA who provide digital mapping services for UK tertiary education. They enhance approaches tolegend design that have evolved for static media with visualization by considering: selection, layout, symbols, position, dynamismand design and process. Broad visualization legend themes include: The Ground Truth Legend, The Legend as Statistical Graphicand The Map is the Legend. Together, these concepts enable us to augment legends with dynamic properties that address specificneeds, rethink their nature and role and contribute to a wider re-evaluation of maps as artifacts of usage rather than statements offact. EDINA has acquired funding to enhance their clients with visualization legends that use these concepts as a consequence ofthis work. The guidance applies to the design of a wide range of legends and keys used in cartography and information visualization.\\\",\\\"Authors\\\":\\\"Dykes, J.;Wood, J.;Slingsby, A.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;InternetWebVisualizationForTheMasses;VisualDesignDesignGuidelines;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.191\\\",\\\"Keywords\\\":\\\"online web mapping;legend;visualization;cartography;design;digimap service\\\",\\\"Keywords_Processed\\\":\\\"online web mapping;visualization;legend;digimap service;design;cartography\\\",\\\"Title\\\":\\\"Rethinking Map Legends with Visualization\\\"},\\\"501\\\":{\\\"Abstract\\\":\\\"Electronic test and measurement systems are becoming increasingly sophisticated in order to match the increased complexity and ultra-high speed of the devices under test. A key feature in many such instruments is a vastly increased capacity for storage of digital signals. Storage of 109 time points or more is now possible. At the same time, the typical screens on such measurement devices are relatively small. Therefore, these instruments can only render an extremely small fraction of the complete signal at any time. SignalLens uses a Focus+Context approach to provide a means of navigating to and inspecting low-level signal details in the context of the entire signal trace. This approach provides a compact visualization suitable for embedding into the small displays typically provided by electronic measurement instruments. We further augment this display with computed tracks which display time-aligned computed properties of the signal. By combining and filtering these computed tracks it is possible to easily and quickly find computationally detected features in the data which are often obscured by the visual compression required to render the large data sets on a small screen. Further, these tracks can be viewed in the context of the entire signal trace as well as visible high-level signal features. Several examples using real-world electronic measurement data are presented, which demonstrate typical use cases and the effectiveness of the design.\\\",\\\"Authors\\\":\\\"Kincaid, R.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;FocusContextTechniques;ImageBasedDataImageSignalProcessing;PhysicsAndPhysicalSciences\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.193\\\",\\\"Keywords\\\":\\\"lens;electronic signal;test and measurement;focus+context;signal processing\\\",\\\"Keywords_Processed\\\":\\\"electronic signal;signal processing;test and measurement;lens;focus context\\\",\\\"Title\\\":\\\"SignalLens: Focus+Context Applied to Electronic Time Series\\\"},\\\"502\\\":{\\\"Abstract\\\":\\\"Tag clouds have proliferated over the web over the last decade. They provide a visual summary of a collection of texts by visually depicting the tag frequency by font size. In use, tag clouds can evolve as the associated data source changes over time. Interesting discussions around tag clouds often include a series of tag clouds and consider how they evolve over time. However, since tag clouds do not explicitly represent trends or support comparisons, the cognitive demands placed on the person for perceiving trends in multiple tag clouds are high. In this paper, we introduce SparkClouds, which integrate sparklines into a tag cloud to convey trends between multiple tag clouds. We present results from a controlled study that compares SparkClouds with two traditional trend visualizations-multiple line graphs and stacked bar charts-as well as Parallel Tag Clouds. Results show that SparkClouds' ability to show trends compares favourably to the alternative visualizations.\\\",\\\"Authors\\\":\\\"Bongshin Lee;Riche, N.H.;Karlson, A.;Carpendale, S.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;EvaluationGeneral;EventsTrendsOutlierDetectionAnalysisAndVisualization;GraphNetworkDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.194\\\",\\\"Keywords\\\":\\\"trend visualization;stacked bar charts;multiple line graphs;tag clouds;evaluation\\\",\\\"Keywords_Processed\\\":\\\"trend visualization;stack bar chart;tag cloud;evaluation;multiple line graphs\\\",\\\"Title\\\":\\\"SparkClouds: Visualizing Trends in Tag Clouds\\\"},\\\"503\\\":{\\\"Abstract\\\":\\\"An ongoing challenge for information visualization is how to deal with over-plotting forced by ties or the relatively limited visual field of display devices. A popular solution is to represent local data density with area (bubble plots, treemaps), color(heatmaps), or aggregation (histograms, kernel densities, pixel displays). All of these methods have at least one of three deficiencies:1) magnitude judgments are biased because area and color have convex downward perceptual functions, 2) area, hue, and brightnesshave relatively restricted ranges of perceptual intensity compared to length representations, and/or 3) it is difficult to brush or link toindividual cases when viewing aggregations. In this paper, we introduce a new technique for visualizing and interacting with datasets that preserves density information by stacking overlapping cases. The overlapping data can be points or lines or other geometric elements, depending on the type of plot. We show real-dataset applications of this stacking paradigm and compare them to other techniques that deal with over-plotting in high-dimensional displays.\\\",\\\"Authors\\\":\\\"Tuan Nhon Dang;Wilkinson, L.;Anand, A.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;MultidimensionalMultivariateMultifieldDataAndTechniques;ParallelCoordinates;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.197\\\",\\\"Keywords\\\":\\\"dot plots;density-based visualization;parallel coordinate plot;multi-dimensional data\\\",\\\"Keywords_Processed\\\":\\\"density base visualization;parallel coordinate plot;multi dimensional datum;dot plot\\\",\\\"Title\\\":\\\"Stacking Graphic Elements to Avoid Over-Plotting\\\"},\\\"504\\\":{\\\"Abstract\\\":\\\"A standard approach for visualizing multivariate networks is to use one or more multidimensional views (for example, scatterplots) for selecting nodes by various metrics, possibly coordinated with a node-link view of the network. In this paper, we present three novel approaches for achieving a tighter integration of these views through hybrid techniques for multidimensional visualization, graph selection and layout. First, we present the FlowVizMenu, a radial menu containing a scatterplot that can be popped up transiently and manipulated with rapid, fluid gestures to select and modify the axes of its scatterplot. Second, the FlowVizMenu can be used to steer an attribute-driven layout of the network, causing certain nodes of a node-link diagram to move toward their corresponding positions in a scatterplot while others can be positioned manually or by force-directed layout. Third, we describe a novel hybrid approach that combines a scatterplot matrix (SPLOM) and parallel coordinates called the Parallel Scatterplot Matrix (P-SPLOM), which can be used to visualize and select features within the network. We also describe a novel arrangement of scatterplots called the Scatterplot Staircase (SPLOS) that requires less space than a traditional scatterplot matrix. Initial user feedback is reported.\\\",\\\"Authors\\\":\\\"Viau, C.;McGuffin, M.J.;Chiricota, Y.;Jurisica, I.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;GraphNetworkDataAndTechniques;ParallelCoordinates;UserInterfacesGeneral;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.205\\\",\\\"Keywords\\\":\\\"attribute-driven layout;interactive graph drawing;scatterplot matrix;radial menus;parallel coordinates;network layout\\\",\\\"Keywords_Processed\\\":\\\"parallel coordinate;attribute drive layout;radial menu;scatterplot matrix;network layout;interactive graph drawing\\\",\\\"Title\\\":\\\"The FlowVizMenu and Parallel Scatterplot Matrix: Hybrid Multidimensional Visualizations for Network Exploration\\\"},\\\"505\\\":{\\\"Abstract\\\":\\\"The choices we take when listening to music are expressions of our personal taste and character. Storing and accessing our listening histories is trivial due to services like Last.fm, but learning from them and understanding them is not. Existing solutions operate at a very abstract level and only produce statistics. By applying techniques from information visualization to this problem, we were able to provide average people with a detailed and powerful tool for accessing their own musical past. LastHistory is an interactive visualization for displaying music listening histories, along with contextual information from personal photos and calendar entries. Its two main user tasks are (1) analysis, with an emphasis on temporal patterns and hypotheses related to musical genre and sequences, and (2) reminiscing, where listening histories and context represent part of one's past. In this design study paper we give an overview of the field of music listening histories and explain their unique characteristics as a type of personal data. We then describe the design rationale, data and view transformations of LastHistory and present the results from both a laband a large-scale online study. We also put listening histories in contrast to other lifelogging data. The resonant and enthusiastic feedback that we received from average users shows a need for making their personal data accessible. We hope to stimulate such developments through this research.\\\",\\\"Authors\\\":\\\"Baur, D.;Seiffert, F.;Sedlmair, M.;Boring, S.\\\",\\\"Clusters\\\":\\\"DesignStudiesAndCaseStudies;MultimediaImageVideoMusic;ProvenanceAndHistory;SocialNetworksAndSocialMedia;TimeseriesTimeVaryingDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.206\\\",\\\"Keywords\\\":\\\"timeline;information visualization;design study;calendars;photos;lifelogging;music;listening history\\\",\\\"Keywords_Processed\\\":\\\"design study;listen history;information visualization;lifelogge;timeline;music;calendar;photo\\\",\\\"Title\\\":\\\"The Streams of Our Lives: Visualizing Listening Histories in Context\\\"},\\\"506\\\":{\\\"Abstract\\\":\\\"Radial visualizations play an important role in the information visualization community. But the decision to choose a radial coordinate system is rather based on intuition than on scientific foundations. The empirical approach presented in this paper aims at uncovering strengths and weaknesses of radial visualizations by comparing them to equivalent ones in Cartesian coordinate systems. We identified memorizing positions of visual elements as a generic task when working with visualizations. A first study with 674 participants provides a broad data spectrum for exploring differences between the two visualization types. A second, complementing study with fewer participants focuses on further questions raised by the first study. Our findings document that Cartesian visualizations tend to outperform their radial counterparts especially with respect to answer times. Nonetheless, radial visualization seem to be more appropriate for focusing on a particular data dimension.\\\",\\\"Authors\\\":\\\"Diehl, S.;Beck, F.;Burch, M.\\\",\\\"Clusters\\\":\\\"Cognition;EvaluationGeneral;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.209\\\",\\\"Keywords\\\":\\\"radial visualization;user study;visual memory\\\",\\\"Keywords_Processed\\\":\\\"radial visualization;user study;visual memory\\\",\\\"Title\\\":\\\"Uncovering Strengths and Weaknesses of Radial Visualizations---an Empirical Approach\\\"},\\\"507\\\":{\\\"Abstract\\\":\\\"In many common data analysis scenarios the data elements are logically grouped into sets. Venn and Euler style diagrams are a common visual representation of such set membership where the data elements are represented by labels or glyphs and sets are indicated by boundaries surrounding their members. Generating such diagrams automatically such that set regions do not intersect unless the corresponding sets have a non-empty intersection is a difficult problem. Further, it may be impossible in some cases if regions are required to be continuous and convex. Several approaches exist to draw such set regions using more complex shapes, however, the resulting diagrams can be difficult to interpret. In this paper we present two novel approaches for simplifying a complex collection of intersecting sets into a strict hierarchy that can be more easily automatically arranged and drawn (Figure 1). In the first approach, we use compact rectangular shapes for drawing each set, attempting to improve the readability of the set intersections. In the second approach, we avoid drawing intersecting set regions by duplicating elements belonging to multiple sets. We compared both of our techniques to the traditional non-convex region technique using five readability tasks. Our results show that the compact rectangular shapes technique was often preferred by experimental subjects even though the use of duplications dramatically improves the accuracy and performance time for most of our tasks. In addition to general set representation our techniques are also applicable to visualization of networks with intersecting clusters of nodes.\\\",\\\"Authors\\\":\\\"Riche, N.H.;Dwyer, T.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;GraphNetworkDataAndTechniques;SetRelatedDataTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.210\\\",\\\"Keywords\\\":\\\"information visualization;euler diagrams;set visualization;graph visualization\\\",\\\"Keywords_Processed\\\":\\\"graph visualization;information visualization;set visualization;euler diagram\\\",\\\"Title\\\":\\\"Untangling Euler Diagrams\\\"},\\\"508\\\":{\\\"Abstract\\\":\\\"Understanding the diversity of a set of multivariate objects is an important problem in many domains, including ecology, college admissions, investing, machine learning, and others. However, to date, very little work has been done to help users achieve this kind of understanding. Visual representation is especially appealing for this task because it offers the potential to allow users to efficiently observe the objects of interest in a direct and holistic way. Thus, in this paper, we attempt to formalize the problem of visualizing the diversity of a large (more than 1000 objects), multivariate (more than 5 attributes) data set as one worth deeper investigation by the information visualization community. In doing so, we contribute a precise definition of diversity, a set of requirements for diversity visualizations based on this definition, and a formal user study design intended to evaluate the capacity of a visual representation for communicating diversity information. Our primary contribution, however, is a visual representation, called the Diversity Map, for visualizing diversity. An evaluation of the Diversity Map using our study design shows that users can judge elements of diversity consistently and as or more accurately than when using the only other representation specifically designed to visualize diversity.\\\",\\\"Authors\\\":\\\"Pham, T.;Hess, R.;Ju, C.;Zhang, E.;Metoyer, R.\\\",\\\"Clusters\\\":\\\"CategoricalDataAndTechniques;DataFeaturesAndAttributes;EvaluationGeneral;MultidimensionalMultivariateMultifieldDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.216\\\",\\\"Keywords\\\":\\\"information visualization;categorical data;diversity;multivariate data;evaluation\\\",\\\"Keywords_Processed\\\":\\\"multivariate datum;information visualization;categorical datum;diversity;evaluation\\\",\\\"Title\\\":\\\"Visualization of Diversity in Large Multivariate Data Sets\\\"},\\\"509\\\":{\\\"Abstract\\\":\\\"Graphs are a versatile structure and abstraction for binary relationships between objects. To gain insight into such relationships, their corresponding graph can be visualized. In the past, many classes of graphs have been defined, e.g. trees, planar graphs, directed acyclic graphs, and visualization algorithms were proposed for these classes. Although many graphs may only be classified as \\\\\\\"general\\\\\\\" graphs, they can contain substructures that belong to a certain class. Archambault proposed the TopoLayout framework: rather than draw any arbitrary graph using one method, split the graph into components that are homogeneous with respect to one graph class and then draw each component with an algorithm best suited for this class. Graph products constitute a class that arises frequently in graph theory, but for which no visualization algorithm has been proposed until now. In this paper, we present an algorithm for drawing graph products and the aesthetic criterion graph product's drawings are subject to. We show that the popular High-Dimensional Embedder approach applied to cartesian products already respects this aestetic criterion, but has disadvantages. We also present how our method is integrated as a new component into the TopoLayout framework. Our implementation is used for further research of graph products in a biological context.\\\",\\\"Authors\\\":\\\"Jnicke, S.;Heine, C.;Hellmuth, M.;Stadler, P.F.;Scheuermann, G.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.217\\\",\\\"Keywords\\\":\\\"topolayout;graph drawing;graph products\\\",\\\"Keywords_Processed\\\":\\\"graph drawing;graph product;topolayout\\\",\\\"Title\\\":\\\"Visualization of Graph Products\\\"},\\\"510\\\":{\\\"Abstract\\\":\\\"In order to use new visualizations, most toolkits require application developers to rebuild their applications and distribute new versions to users. The WebCharts Framework take a different approach by hosting Javascript from within an application and providing a standard data and events interchange.. In this way, applications can be extended dynamically, with a wide variety of visualizations. We discuss the benefits of this architectural approach, contrast it to existing techniques, and give a variety of examples and extensions of the basic system.\\\",\\\"Authors\\\":\\\"Fisher, D.;Drucker, S.;Fernandez, R.;Ruble, S.\\\",\\\"Clusters\\\":\\\"DataTransformation;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.222\\\",\\\"Keywords\\\":\\\"visualization systems;data transformation and representation;toolkit design\\\",\\\"Keywords_Processed\\\":\\\"toolkit design;visualization system;datum transformation and representation\\\",\\\"Title\\\":\\\"Visualizations everywhere: A Multiplatform Infrastructure for Linked Visualizations\\\"},\\\"511\\\":{\\\"Abstract\\\":\\\"Most images used in visualization are computed with the planar pinhole camera. This classic camera model has important advantages such as simplicity, which enables efficient software and hardware implementations, and similarity to the human eye, which yields images familiar to the user. However, the planar pinhole camera has only a single viewpoint, which limits images to parts of the scene to which there is direct line of sight. In this paper we introduce the curved ray camera to address the single viewpoint limitation. Rays are C1-continuous curves that bend to circumvent occluders. Our camera is designed to provide a fast 3-D point projection operation, which enables interactive visualization. The camera supports both 3-D surface and volume datasets. The camera is a powerful tool that enables seamless integration of multiple perspectives for overcoming occlusions in visualization while minimizing distortions.\\\",\\\"Authors\\\":\\\"Jian Cui;Rosen, P.;Popescu, V.;Hoffmann, C.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;InteractionTechniquesGeneral;OcclusionProblemsTechniques;RaytracingRaycasting;ViewDependentVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.127\\\",\\\"Keywords\\\":\\\"interactive visualization;curved rays;camera model;multiperspective visualization;alleviating occlusions\\\",\\\"Keywords_Processed\\\":\\\"alleviate occlusion;multiperspective visualization;camera model;curve ray;interactive visualization\\\",\\\"Title\\\":\\\"A Curved Ray Camera for Handling Occlusions through Continuous Multiperspective Visualization\\\"},\\\"512\\\":{\\\"Abstract\\\":\\\"The process of visualization can be seen as a visual communication channel where the input to the channel is the raw data, and the output is the result of a visualization algorithm. From this point of view, we can evaluate the effectiveness of visualization by measuring how much information in the original data is being communicated through the visual communication channel. In this paper, we present an information-theoretic framework for flow visualization with a special focus on streamline generation. In our framework, a vector field is modeled as a distribution of directions from which Shannon's entropy is used to measure the information content in the field. The effectiveness of the streamlines displayed in visualization can be measured by first constructing a new distribution of vectors derived from the existing streamlines, and then comparing this distribution with that of the original data set using the conditional entropy. The conditional entropy between these two distributions indicates how much information in the original data remains hidden after the selected streamlines are displayed. The quality of the visualization can be improved by progressively introducing new streamlines until the conditional entropy converges to a small value. We describe the key components of our framework with detailed analysis, and show that the framework can effectively visualize 2D and 3D flow data.\\\",\\\"Authors\\\":\\\"Lijie Xu;Teng-Yok Lee;Han-Wei Shen\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;InformationTheory;StreamlinesPathlinesStreaklines\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.131\\\",\\\"Keywords\\\":\\\"information theory;flow field visualization;streamline generation\\\",\\\"Keywords_Processed\\\":\\\"flow field visualization;streamline generation;information theory\\\",\\\"Title\\\":\\\"An Information-Theoretic Framework for Flow Visualization\\\"},\\\"513\\\":{\\\"Abstract\\\":\\\"In this paper, we examine whether or not information theory can be one of the theoretic frameworks for visualization. We formulate concepts and measurements for qualifying visual information. We illustrate these concepts with examples that manifest the intrinsic and implicit use of information theory in many existing visualization techniques. We outline the broad correlation between visualization and the major applications of information theory, while pointing out the difference in emphasis and some technical gaps. Our study provides compelling evidence that information theory can explain a significant number of phenomena or events in visualization, while no example has been found which is fundamentally in conflict with information theory. We also notice that the emphasis of some traditional applications of information theory, such as data compression or data communication, may not always suit visualization, as the former typically focuses on the efficient throughput of a communication channel, whilst the latter focuses on the effectiveness in aiding the perceptual and cognitive process for data understanding and knowledge discovery. These findings suggest that further theoretic developments are necessary for adopting and adapting information theory for visualization.\\\",\\\"Authors\\\":\\\"Chen, M.;Jnicke, H.\\\",\\\"Clusters\\\":\\\"InformationTheory;QuantitativeEvaluation;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.132\\\",\\\"Keywords\\\":\\\"information theory;theory of visualization;quantitative evaluation\\\",\\\"Keywords_Processed\\\":\\\"quantitative evaluation;information theory;theory of visualization\\\",\\\"Title\\\":\\\"An Information-theoretic Framework for Visualization\\\"},\\\"514\\\":{\\\"Abstract\\\":\\\"In the development of magnetic confinement fusion which will potentially be a future source for low cost power, physicists must be able to analyze the magnetic field that confines the burning plasma. While the magnetic field can be described as a vector field, traditional techniques for analyzing the field's topology cannot be used because of its Hamiltonian nature. In this paper we describe a technique developed as a collaboration between physicists and computer scientists that determines the topology of a toroidal magnetic field using fieldlines with near minimal lengths. More specifically, we analyze the Poincare map of the sampled fieldlines in a Poincare section including identifying critical points and other topological features of interest to physicists. The technique has been deployed into an interactiveparallel visualization tool which physicists are using to gain new insight into simulations of magnetically confined burning plasmas.\\\",\\\"Authors\\\":\\\"Sanderson, A.;Guoning Chen;Tricoche, X.;Pugmire, D.;Kruger, S.;Breslau, J.\\\",\\\"Clusters\\\":\\\"NumericalMethodsMathematics;PhysicsAndPhysicalSciences;VisualPatternFeatureDetectionAndTracking\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.133\\\",\\\"Keywords\\\":\\\"periodic magnetic fieldlines;magnetic field visualization;confined magnetic fusion;recurrent patterns;poincare map\\\",\\\"Keywords_Processed\\\":\\\"poincare map;recurrent pattern;periodic magnetic fieldline;confine magnetic fusion;magnetic field visualization\\\",\\\"Title\\\":\\\"Analysis of Recurrent Patterns in Toroidal Magnetic fields\\\"},\\\"515\\\":{\\\"Abstract\\\":\\\"Conventional browsing of image collections use mechanisms such as thumbnails arranged on a regular grid or on a line, often mounted over a scrollable panel. However, this approach does not scale well with the size of the datasets (number of images). In this paper, we propose a new thumbnail-based interface to browse large collections of images. Our approach is based on weighted centroidal anisotropic Voronoi diagrams. A dynamically changing subset of images is represented by thumbnails and shown on the screen. Thumbnails are shaped like general polygons, to better cover screen space, while still reflecting the original aspect ratios or orientation of the represented images. During the browsing process, thumbnails are dynamically rearranged, reshaped and rescaled. The objective is to devote more screen space (more numerous and larger thumbnails) to the parts of the dataset closer to the current region of interest, and progressively lesser away from it, while still making the dataset visible as a whole. During the entire process, temporal coherence is always maintained. GPU implementation easily guarantees the frame rates needed for fully smooth interactivity.\\\",\\\"Authors\\\":\\\"Brivio, P.;Tarini, M.;Cignoni, P.\\\",\\\"Clusters\\\":\\\"LargeScaleDataAndScalability;UserInterfacesGeneral;VisualizationSystemsToolkitsAndEnvironments;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.136\\\",\\\"Keywords\\\":\\\"visualization system and toolkit design;zooming and navigation techniques;user interface;scalability issues\\\",\\\"Keywords_Processed\\\":\\\"visualization system and toolkit design;zooming and navigation technique;scalability issue;user interface\\\",\\\"Title\\\":\\\"Browsing Large Image Datasets through Voronoi Diagrams\\\"},\\\"516\\\":{\\\"Abstract\\\":\\\"We are interested in 3-dimensional images given as arrays of voxels with intensity values. Extending these values to a continuous function, we study the robustness of homology classes in its level and interlevel sets, that is, the amount of perturbation needed to destroy these classes. The structure of the homology classes and their robustness, over all level and interlevel sets, can be visualized by a triangular diagram of dots obtained by computing the extended persistence of the function. We give a fast hierarchical algorithm using the dual complexes of oct-tree approximations of the function. In addition, we show that for balanced oct-trees, the dual complexes are geometrically realized in R3 and can thus be used to construct level and interlevel sets. We apply these tools to study 3-dimensional images of plant root systems.\\\",\\\"Authors\\\":\\\"Bendich, P.;Edelsbrunner, H.;Kerber, M.\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;BiologyAndBioinformatics;EvaluationMetricsAndBenchmarks;NumericalMethodsMathematics;ProgrammingAlgorithmsAndDataStructures;TopologyBasedTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.139\\\",\\\"Keywords\\\":\\\"voxel arrays;persistence diagrams;persistent homology;level sets;octree;plant roots;approximation;robustness\\\",\\\"Keywords_Processed\\\":\\\"level set;persistent homology;plant root;robustness;octree;approximation;voxel array;persistence diagram\\\",\\\"Title\\\":\\\"Computing Robustness and Persistence for Images\\\"},\\\"517\\\":{\\\"Abstract\\\":\\\"We extend direct volume rendering with a unified model for generalized isosurfaces, also called interval volumes, allowing a wider spectrum of visual classification. We generalize the concept of scale-invariant opacity-typical for isosurface rendering-to semi-transparent interval volumes. Scale-invariant rendering is independent of physical space dimensions and therefore directly facilitates the analysis of data characteristics. Our model represents sharp isosurfaces as limits of interval volumes and combines them with features of direct volume rendering. Our objective is accurate rendering, guaranteeing that all isosurfaces and interval volumes are visualized in a crack-free way with correct spatial ordering. We achieve simultaneous direct and interval volume rendering by extending preintegration and explicit peak finding with data-driven splitting of ray integration and hybrid computation in physical and data domains. Our algorithm is suitable for efficient parallel processing for interactive applications as demonstrated by our CUDA implementation.\\\",\\\"Authors\\\":\\\"Ament, M.;Weiskopf, D.;Carr, H.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;DataRegistrationFusionAndIntegration;IsosurfaceAndSurfaceExtractionTechniques;RaytracingRaycasting;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.145\\\",\\\"Keywords\\\":\\\"direct volume rendering;preintegration;raycasting;isosurface;interval volume;scale-invariant opacity\\\",\\\"Keywords_Processed\\\":\\\"preintegration;direct volume render;scale invariant opacity;isosurface;raycaste;interval volume\\\",\\\"Title\\\":\\\"Direct Interval Volume Visualization\\\"},\\\"518\\\":{\\\"Abstract\\\":\\\"The concept of continuous scatterplot (CSP) is a modern visualization technique. The idea is to define a scalar density value based on the map between an n-dimensional spatial domain and an m-dimensional data domain, which describe the CSP space. Usually the data domain is two-dimensional to visually convey the underlying, density coded, data. In this paper we investigate kinds of map-based discontinuities, especially for the practical cases n = m = 2 and n = 3 | m = 2, and we depict relations between them and attributes of the resulting CSP itself. Additionally, we show that discontinuities build critical line structures, and we introduce algorithms to detect them. Further, we introduce a discontinuity-based visualization approach - called contribution map (CM) -which establishes a relationship between the CSP's data domain and the number of connected components in the spatial domain. We show that CMs enhance the CSP-based linking & brushing interaction. Finally, we apply our approaches to a number of synthetic as well as real data sets.\\\",\\\"Authors\\\":\\\"Lehmann, D.J.;Theisel, H.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;DataFeaturesAndAttributes;TopologyBasedTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.146\\\",\\\"Keywords\\\":\\\"discontinuity;visualization;scatterplot;topology\\\",\\\"Keywords_Processed\\\":\\\"visualization;scatterplot;discontinuity;topology\\\",\\\"Title\\\":\\\"Discontinuities in Continuous Scatter Plots\\\"},\\\"519\\\":{\\\"Abstract\\\":\\\"High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.\\\",\\\"Authors\\\":\\\"Fraedrich, R.;Auer, S.;Westermann, R.\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;ParticleVisualizationAndTechniques;RaytracingRaycasting;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.148\\\",\\\"Keywords\\\":\\\"gpu resampling;volume rendering;particle visualization;raycasting\\\",\\\"Keywords_Processed\\\":\\\"volume render;gpu resampling;raycaste;particle visualization\\\",\\\"Title\\\":\\\"Efficient High-Quality Volume Rendering of SPH Data\\\"},\\\"520\\\":{\\\"Abstract\\\":\\\"We present a technique for visualizing complicated mathematical surfaces that is inspired by hand-designed topological illustrations. Our approach generates exploded views that expose the internal structure of such a surface by partitioning it into parallel slices, which are separated from each other along a single linear explosion axis. Our contributions include a set of simple, prescriptive design rules for choosing an explosion axis and placing cutting planes, as well as automatic algorithms for applying these rules. First we analyze the input shape to select the explosion axis based on the detected rotational and reflective symmetries of the input model. We then partition the shape into slices that are designed to help viewers better understand how the shape of the surface and its cross-sections vary along the explosion axis. Our algorithms work directly on triangle meshes, and do not depend on any specific parameterization of the surface. We generate exploded views for a variety of mathematical surfaces using our system.\\\",\\\"Authors\\\":\\\"Karpenko, O.;Li, W.;Mitra, N.;Agrawala, M.\\\",\\\"Clusters\\\":\\\"Mathematics;VisualEncodingAndLayoutGeneral;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.151\\\",\\\"Keywords\\\":\\\"exploded view diagrams;mathematical visualization;symmetry\\\",\\\"Keywords_Processed\\\":\\\"symmetry;mathematical visualization;explode view diagram\\\",\\\"Title\\\":\\\"Exploded View Diagrams of Mathematical Surfaces\\\"},\\\"521\\\":{\\\"Abstract\\\":\\\"We develop an interactive analysis and visualization tool for probabilistic segmentation in medical imaging. The originality of our approach is that the data exploration is guided by shape and appearance knowledge learned from expert-segmented images of a training population. We introduce a set of multidimensional transfer function widgets to analyze the multivariate probabilistic field data. These widgets furnish the user with contextual information about conformance or deviation from the population statistics. We demonstrate the user's ability to identify suspicious regions (e.g. tumors) and to correct the misclassification results. We evaluate our system and demonstrate its usefulness in the context of static anatomical and time-varying functional imaging datasets.\\\",\\\"Authors\\\":\\\"Saad, A.;Hamarneh, G.;Moller, T.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;SegmentationAndClassification;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.152\\\",\\\"Keywords\\\":\\\"uncertainty visualization;probabilistic segmentation;medical imaging\\\",\\\"Keywords_Processed\\\":\\\"medical imaging;uncertainty visualization;probabilistic segmentation\\\",\\\"Title\\\":\\\"Exploration and Visualization of Segmentation Uncertainty using Shape and Appearance Prior Information\\\"},\\\"522\\\":{\\\"Abstract\\\":\\\"Insight into the dynamics of blood-flow considerably improves the understanding of the complex cardiovascular system and its pathologies. Advances in MRI technology enable acquisition of 4D blood-flow data, providing quantitative blood-flow velocities over time. The currently typical slice-by-slice analysis requires a full mental reconstruction of the unsteady blood-flow field, which is a tedious and highly challenging task, even for skilled physicians. We endeavor to alleviate this task by means of comprehensive visualization and interaction techniques. In this paper we present a framework for pre-clinical cardiovascular research, providing tools to both interactively explore the 4D blood-flow data and depict the essential blood-flow characteristics. The framework encompasses a variety of visualization styles, comprising illustrative techniques as well as improved methods from the established field of flow visualization. Each of the incorporated styles, including exploded planar reformats, flow-direction highlights, and arrow-trails, locally captures the blood-flow dynamics and may be initiated by an interactively probed vessel cross-section. Additionally, we present the results of an evaluation with domain experts, measuring the value of each of the visualization styles and related rendering parameters.\\\",\\\"Authors\\\":\\\"van Pelt, R.;Olivan Bescos, J.;Breeuwer, M.;Clough, R.E.;Groller, E.;ter Haar Romenij, B.;Vilanova, A.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;FlowVisualizationDataAndTechniques;IllustrativeVisualization;InteractionTechniquesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.153\\\",\\\"Keywords\\\":\\\"flow visualization;phase-contrast cine mri;illustrative visualization;probing;4d mri blood-flow\\\",\\\"Keywords_Processed\\\":\\\"illustrative visualization;probe;4d mri blood flow;phase contrast cine mri;flow visualization\\\",\\\"Title\\\":\\\"Exploration of 4D MRI Blood Flow using Stylistic Visualization\\\"},\\\"523\\\":{\\\"Abstract\\\":\\\"Volume ray-casting with a higher order reconstruction filter and/or a higher sampling rate has been adopted in direct volume rendering frameworks to provide a smooth reconstruction of the volume scalar and/or to reduce artifacts when the combined frequency of the volume and transfer function is high. While it enables high-quality volume rendering, it cannot support interactive rendering due to its high computational cost. In this paper, we propose a fast high-quality volume ray-casting algorithm which effectively increases the sampling rate. While a ray traverses the volume, intensity values are uniformly reconstructed using a high-order convolution filter. Additional samplings, referred to as virtual samplings, are carried out within a ray segment from a cubic spline curve interpolating those uniformly reconstructed intensities. These virtual samplings are performed by evaluating the polynomial function of the cubic spline curve via simple arithmetic operations. The min max blocks are refined accordingly for accurate empty space skipping in the proposed method. Experimental results demonstrate that the proposed algorithm, also exploiting fast cubic texture filtering supported by programmable GPUs, offers renderings as good as a conventional ray-casting algorithm using high-order reconstruction filtering at the same sampling rate, while delivering 2.5x to 3.3x rendering speed-up.\\\",\\\"Authors\\\":\\\"Byeonghun Lee;Jihye Yun;Jinwook Seo;Byonghyo Shim;Yeong Gil Shin;Bohyoung Kim\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;GpuBasedTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.155\\\",\\\"Keywords\\\":\\\"direct volume rendering;curve interpolation;high quality;gpu\\\",\\\"Keywords_Processed\\\":\\\"curve interpolation;gpu;high quality;direct volume render\\\",\\\"Title\\\":\\\"Fast High-Quality Volume Ray Casting with Virtual Samplings\\\"},\\\"524\\\":{\\\"Abstract\\\":\\\"Applying certain visualization techniques to datasets described on unstructured grids requires the interpolation of variables of interest at arbitrary locations within the dataset's domain of definition. Typical solutions to the problem of finding the grid element enclosing a given interpolation point make use of a variety of spatial subdivision schemes. However, existing solutions are memory- intensive, do not scale well to large grids, or do not work reliably on grids describing complex geometries. In this paper, we propose a data structure and associated construction algorithm for fast cell location in unstructured grids, and apply it to the interpolation problem. Based on the concept of bounding interval hierarchies, the proposed approach is memory-efficient, fast and numerically robust. We examine the performance characteristics of the proposed approach and compare it to existing approaches using a number of benchmark problems related to vector field visualization. Furthermore, we demonstrate that our approach can successfully accommodate large datasets, and discuss application to visualization on both CPUs and GPUs.\\\",\\\"Authors\\\":\\\"Garth, C.;Joy, K.I.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;Interpolation;MeshesGridsAndLattices;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.156\\\",\\\"Keywords\\\":\\\"cell location;vector field visualization;unstructured grid;interpolation\\\",\\\"Keywords_Processed\\\":\\\"interpolation;unstructured grid;vector field visualization;cell location\\\",\\\"Title\\\":\\\"Fast; Memory-Efficient Cell Location in Unstructured Grids for Visualization\\\"},\\\"525\\\":{\\\"Abstract\\\":\\\"We present the design and evaluation of FI3D, a direct-touch data exploration technique for 3D visualization spaces. The exploration of three-dimensional data is core to many tasks and domains involving scientific visualizations. Thus, effective data navigation techniques are essential to enable comprehension, understanding, and analysis of the information space. While evidence exists that touch can provide higher-bandwidth input, somesthetic information that is valuable when interacting with virtual worlds, and awareness when working in collaboration, scientific data exploration in 3D poses unique challenges to the development of effective data manipulations. We present a technique that provides touch interaction with 3D scientific data spaces in 7 DOF. This interaction does not require the presence of dedicated objects to constrain the mapping, a design decision important for many scientific datasets such as particle simulations in astronomy or physics. We report on an evaluation that compares the technique to conventional mouse-based interaction. Our results show that touch interaction is competitive in interaction speed for translation and integrated interaction, is easy to learn and use, and is preferred for exploration and wayfinding tasks. To further explore the applicability of our basic technique for other types of scientific visualizations we present a second case study, adjusting the interaction to the illustrative visualization of fiber tracts of the brain and the manipulation of cutting planes in this context.\\\",\\\"Authors\\\":\\\"Lingyun Yu;Svetachov, P.;Isenberg, P.;Everts, M.H.;Isenberg, T.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;IllustrativeVisualization;InteractionTechniquesGeneral;LargeAndHighResDisplays;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.157\\\",\\\"Keywords\\\":\\\"direct-touch interaction;illustrative visualization;wall displays;evaluation;3d navigation and exploration\\\",\\\"Keywords_Processed\\\":\\\"direct touch interaction;3d navigation and exploration;illustrative visualization;wall display;evaluation\\\",\\\"Title\\\":\\\"FI3D: Direct-Touch Interaction for the Exploration of 3D Scientific Visualization Spaces\\\"},\\\"526\\\":{\\\"Abstract\\\":\\\"We investigate the use of a Fourier-domain derivative error kernel to quantify the error incurred while estimating the gradient of a function from scalar point samples on a regular lattice. We use the error kernel to show that gradient reconstruction quality is significantly enhanced merely by shifting the reconstruction kernel to the centers of the principal lattice directions. Additionally, we exploit the algebraic similarities between the scalar and derivative error kernels to design asymptotically optimal gradient estimation filters that can be factored into an infinite impulse response interpolation prefilter and a finite impulse response directional derivative filter. This leads to a significant performance gain both in terms of accuracy and computational efficiency. The interpolation prefilter provides an accurate scalar approximation and can be re-used to cheaply compute directional derivatives on-the-fly without the need to store gradients. We demonstrate the impact of our filters in the context of volume rendering of scalar data sampled on the Cartesian and Body-Centered Cubic lattices. Our results rival those obtained from other competitive gradient estimation methods while incurring no additional computational or storage overhead.\\\",\\\"Authors\\\":\\\"Alim, U.;Moller, T.;Condat, L.\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;Interpolation;MachineLearningAndStatistics;MeshesGridsAndLattices;NumericalMethodsMathematics;Sampling\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.160\\\",\\\"Keywords\\\":\\\"derivative;frequency error kernel;reconstruction;interpolation;sampling;approximation;gradient;lattice\\\",\\\"Keywords_Processed\\\":\\\"derivative;gradient;reconstruction;frequency error kernel;lattice;approximation;sample;interpolation\\\",\\\"Title\\\":\\\"Gradient Estimation Revitalized\\\"},\\\"527\\\":{\\\"Abstract\\\":\\\"Stream surfaces are an intuitive approach to represent 3D vector fields. In many cases, however, they are challenging objects to visualize and to understand, due to a high degree of self-occlusion. Despite the need for adequate rendering methods, little work has been done so far in this important research area. In this paper, we present an illustrative rendering strategy for stream surfaces. In our approach, we apply various rendering techniques, which are inspired by the traditional flow illustrations drawn by Dallmann and Abraham & Shaw in the early 1980s. Among these techniques are contour lines and halftoning to show the overall surface shape. Flow direction as well as singularities on the stream surface are depicted by illustrative surface streamlines. ;To go beyond reproducing static text book images, we provide several interaction features, such as movable cuts and slabs allowing an interactive exploration of the flow and insights into subjacent structures, e.g., the inner windings of vortex breakdown bubbles. These methods take only the parameterized stream surface as input, require no further preprocessing, and can be freely combined by the user. We explain the design, GPU-implementation, and combination of the different illustrative rendering and interaction methods and demonstrate the potential of our approach by applying it to stream surfaces from various flow simulations.\\\",\\\"Authors\\\":\\\"Born, S.;Wiebel, A.;Friedrich, J.;Scheuermann, G.;Bartz, D.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;GpuBasedTechniques;IllustrativeVisualization;SurfaceRelatedDataAndTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.166\\\",\\\"Keywords\\\":\\\"flow visualization;3d vector field data;silhouettes;illustrative rendering;gpu techniques;stream surfaces\\\",\\\"Keywords_Processed\\\":\\\"3d vector field datum;stream surface;silhouette;illustrative render;gpu technique;flow visualization\\\",\\\"Title\\\":\\\"Illustrative Stream Surfaces\\\"},\\\"528\\\":{\\\"Abstract\\\":\\\"Histology is the study of the structure of biological tissue using microscopy techniques. As digital imaging technology advances, high resolution microscopy of large tissue volumes is becoming feasible; however, new interactive tools are needed to explore and analyze the enormous datasets. In this paper we present a visualization framework that specifically targets interactive examination of arbitrarily large image stacks. Our framework is built upon two core techniques: display-aware processing and GPU-accelerated texture compression. With display-aware processing, only the currently visible image tiles are fetched and aligned on-the-fly, reducing memory bandwidth and minimizing the need for time-consuming global pre-processing. Our novel texture compression scheme for GPUs is tailored for quick browsing of image stacks. We evaluate the usability of our viewer for two histology applications: digital pathology and visualization of neural structure at nanoscale-resolution in serial electron micrographs.\\\",\\\"Authors\\\":\\\"Won-Ki Jeong;Schneider, J.;Turney, S.G.;Faulkner-Jones, B.E.;Meyer, D.;Westermann, R.;Reid, R.C.;Lichtman, J.;Pfister, H.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;GpuBasedTechniques;LargeAndHighResDisplays;Textures\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.168\\\",\\\"Keywords\\\":\\\"texture compression;biomedical image processing;gigapixel viewer;gpu\\\",\\\"Keywords_Processed\\\":\\\"texture compression;gpu;biomedical image processing;gigapixel viewer\\\",\\\"Title\\\":\\\"Interactive Histology of Large-Scale Biomedical Image Stacks\\\"},\\\"529\\\":{\\\"Abstract\\\":\\\"Streak surfaces are among the most important features to support 3D unsteady flow exploration, but they are also among the computationally most demanding. Furthermore, to enable a feature driven analysis of the flow, one is mainly interested in streak surfaces that show separation profiles and thus detect unstable manifolds in the flow. The computation of such separation surfaces requires to place seeding structures at the separation locations and to let the structures move correspondingly to these locations in the unsteady flow. Since only little knowledge exists about the time evolution of separating streak surfaces, at this time, an automated exploration of 3D unsteady flows using such surfaces is not feasible. Therefore, in this paper we present an interactive approach for the visual analysis of separating streak surfaces. Our method draws upon recent work on the extraction of Lagrangian coherent structures (LCS) and the real-time visualization of streak surfaces on the GPU. We propose an interactive technique for computing ridges in the finite time Lyapunov exponent (FTLE) field at each time step, and we use these ridges as seeding structures to track streak surfaces in the time-varying flow. By showing separation surfaces in combination with particle trajectories, and by letting the user interactively change seeding parameters such as particle density and position, visually guided exploration of separation profiles in 3D is provided. To the best of our knowledge, this is the first time that the reconstruction and display of semantic separable surfaces in 3D unsteady flows can be performed interactively, giving rise to new possibilities for gaining insight into complex flow phenomena.\\\",\\\"Authors\\\":\\\"Ferstl, F.;Burger, K.;Theisel, H.;Westermann, R.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;GpuBasedTechniques;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.169\\\",\\\"Keywords\\\":\\\"unsteady flow visualization;feature extraction;streak surface generation;gpu\\\",\\\"Keywords_Processed\\\":\\\"feature extraction;gpu;unsteady flow visualization;streak surface generation\\\",\\\"Title\\\":\\\"Interactive Separating Streak Surfaces\\\"},\\\"530\\\":{\\\"Abstract\\\":\\\"We introduce a flexible technique for interactive exploration of vector field data through classification derived from user-specified feature templates. Our method is founded on the observation that, while similar features within the vector field may be spatially disparate, they share similar neighborhood characteristics. Users generate feature-based visualizations by interactively highlighting well-accepted and domain specific representative feature points. Feature exploration begins with the computation of attributes that describe the neighborhood of each sample within the input vector field. Compilation of these attributes forms a representation of the vector field samples in the attribute space. We project the attribute points onto the canonical 2D plane to enable interactive exploration of the vector field using a painting interface. The projection encodes the similarities between vector field points within the distances computed between their associated attribute points. The proposed method is performed at interactive rates for enhanced user experience and is completely flexible as showcased by the simultaneous identification of diverse feature types.\\\",\\\"Authors\\\":\\\"Daniels II, J.;Anderson, E.W.;Nonato, L.G.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;DataClusteringAndAggregation;InteractionTechniquesGeneral;MultidimensionalMultivariateMultifieldDataAndTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.170\\\",\\\"Keywords\\\":\\\"user interaction;high-dimensional data;vector field;feature classification;data clustering\\\",\\\"Keywords_Processed\\\":\\\"user interaction;vector field;feature classification;high dimensional datum;datum clustering\\\",\\\"Title\\\":\\\"Interactive Vector field Feature Identification\\\"},\\\"531\\\":{\\\"Abstract\\\":\\\"Multiple simulation runs using the same simulation model with different values of control parameters generate a large data set that captures the behavior of the modeled phenomenon. However, there is a conceptual and visual gap between the simulation model behavior and the data set that makes data analysis more difficult. We propose a simulation model view that helps to bridge that gap by visually combining the simulation model description and the generated data. The simulation model view provides a visual outline of the simulation process and the corresponding simulation model. The view is integrated in a Coordinated Multiple Views; (CMV) system. As the simulation model view provides a limited display space, we use three levels of details. We explored the use of the simulation model view, in close collaboration with a domain expert, to understand and tune an electronic unit injector (EUI). We also developed analysis procedures based on the view. The EUI is mostly used in heavy duty Diesel engines. We were mainly interested in understanding the model and how to tune it for three different operation modes: low emission, low consumption, and high power. Very positive feedback from the domain expert shows that the use of the simulation model view and the corresponding ;analysis procedures within a CMV system represents an effective technique for interactive visual analysis of multiple simulation runs.\\\",\\\"Authors\\\":\\\"Matkovic, K.;Gracanin, D.;Jelovic, M.;Ammer, A.;Lez, A.;Hauser, H.\\\",\\\"Clusters\\\":\\\"MultipleLinkedCoordinatedViews;PhysicsAndPhysicalSciences;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.171\\\",\\\"Keywords\\\":\\\"visualization in physical sciences and engineering;time-series data;coordinated & multiple views\\\",\\\"Keywords_Processed\\\":\\\"coordinate multiple view;time series datum;visualization in physical science and engineering\\\",\\\"Title\\\":\\\"Interactive Visual Analysis of Multiple Simulation Runs Using the Simulation Model View: Understanding and Tuning of an Electronic Unit Injector\\\"},\\\"532\\\":{\\\"Abstract\\\":\\\"This paper presents an interactive visualization tool to study and analyze hyperspectral images (HSI) of historical documents. This work is part of a collaborative effort with the Nationaal Archief of the Netherlands (NAN) and Art Innovation, a manufacturer of hyperspectral imaging hardware designed for old and fragile documents. The NAN is actively capturing HSI of historical documents for use in a variety of tasks related to the analysis and management of archival collections, from ink and paper analysis to monitoring the effects of environmental aging. To assist their work, we have developed a comprehensive visualization tool that offers an assortment of visualization and analysis methods, including interactive spectral selection, spectral similarity analysis, time-varying data analysis and visualization, and selective spectral band fusion. This paper describes our visualization software and how it is used to facilitate the tasks needed by our collaborators. Evaluation feedback from our collaborators on how this tool benefits their work is included.\\\",\\\"Authors\\\":\\\"Seon Joo Kim;Shaojie Zhuo;Fanbo Deng;Chi-Wing Fu;Brown, M.S.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;DataRegistrationFusionAndIntegration;ImageBasedDataImageSignalProcessing;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.172\\\",\\\"Keywords\\\":\\\"image fusion;document processing and analysis;data exploration;hyperspectral visualization\\\",\\\"Keywords_Processed\\\":\\\"image fusion;hyperspectral visualization;document processing and analysis;datum exploration\\\",\\\"Title\\\":\\\"Interactive Visualization of Hyperspectral Images of Historical Documents\\\"},\\\"533\\\":{\\\"Abstract\\\":\\\"Integral surfaces are ideal tools to illustrate vector fields and fluid flow structures. However, these surfaces can be visually complex and exhibit difficult geometric properties, owing to strong stretching, shearing and folding of the flow from which they are derived. Many techniques for non-photorealistic rendering have been presented previously. It is, however, unclear how these techniques can be applied to integral surfaces. In this paper, we examine how transparency and texturing techniques can be used with integral surfaces to convey both shape and directional information. We present a rendering pipeline that combines these techniques aimed at faithfully and accurately representing integral surfaces while improving visualization insight. The presented pipeline is implemented directly on the GPU, providing real-time interaction for all rendering modes, and does not require expensive preprocessing of integral surfaces after computation.\\\",\\\"Authors\\\":\\\"Hummel, M.;Garth, C.;Hamann, B.;Hagen, H.;Joy, K.I.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;IllustrativeVisualization;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.173\\\",\\\"Keywords\\\":\\\"flow visualization;integral surfaces;illustrative rendering\\\",\\\"Keywords_Processed\\\":\\\"illustrative render;integral surface;flow visualization\\\",\\\"Title\\\":\\\"IRIS: Illustrative Rendering for Integral Surfaces\\\"},\\\"534\\\":{\\\"Abstract\\\":\\\"Numerical weather prediction ensembles are routinely used for operational weather forecasting. The members of these ensembles are individual simulations with either slightly perturbed initial conditions or different model parameterizations, or occasionally both. Multi-member ensemble output is usually large, multivariate, and challenging to interpret interactively. Forecast meteorologists are interested in understanding the uncertainties associated with numerical weather prediction; specifically variability between the ensemble members. Currently, visualization of ensemble members is mostly accomplished through spaghetti plots of a single midtroposphere pressure surface height contour. In order to explore new uncertainty visualization methods, the Weather Research and Forecasting (WRF) model was used to create a 48-hour, 18 member parameterization ensemble of the 13 March 1993 \\\\\\\"Superstorm\\\\\\\". A tool was designed to interactively explore the ensemble uncertainty of three important weather variables: water-vapor mixing ratio, perturbation potential temperature, and perturbation pressure. Uncertainty was quantified using individual ensemble member standard deviation, inter-quartile range, and the width of the 95% confidence interval. Bootstrapping was employed to overcome the dependence on normality in the uncertainty metrics. A coordinated view of ribbon and glyph-based uncertainty visualization, spaghetti plots, iso-pressure colormaps, and data transect plots was provided to two meteorologists for expert evaluation. They found it useful in assessing uncertainty in the data, especially in finding outliers in the ensemble run and therefore avoiding the WRF parameterizations that lead to these outliers. Additionally, the meteorologists could identify spatial regions where the uncertainty was significantly high, allowing for identification of poorly simulated storm environments and physical interpretation of these model issues.\\\",\\\"Authors\\\":\\\"Sanyal, J.;Song Zhang;Dyer, J.;Mercer, A.;Amburn, P.;Moorhead, R.J.\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;GeographyGeospatialVisCartographyTerrainVis;GlyphsGlyphBasedTechniques;QualitativeEvaluation;TimeseriesTimeVaryingDataAndTechniques;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.181\\\",\\\"Keywords\\\":\\\"glyph-based techniques;uncertainty visualization;time-varying data;weather ensemble;qualitative evaluation;geographic/geospatial visualization\\\",\\\"Keywords_Processed\\\":\\\"time vary datum;weather ensemble;glyph base technique;geographic geospatial visualization;qualitative evaluation;uncertainty visualization\\\",\\\"Title\\\":\\\"Noodles: A Tool for Visualization of Numerical Weather Model Ensemble Uncertainty\\\"},\\\"535\\\":{\\\"Abstract\\\":\\\"A (3D) scalar grid is a regular n1  n2  n3 grid of vertices where each vertex v is associated with some scalar value sv. Applying trilinear interpolation, the scalar grid determines a scalar function g where g(v) = sv for each grid vertex v. An isosurface with isovalue  is a triangular mesh which approximates the level set g-1 (). The fractal dimension of an isosurface represents the growth in the isosurface as the number of grid cubes increases. We define and discuss the fractal isosurface dimension. Plotting the fractal dimension as a function of the isovalues in a data set provides information about the isosurfaces determined by the data set. We present statistics on the average fractal dimension of 60 publicly available benchmark data sets. We also show the fractal dimension is highly correlated with topological noise in the benchmark data sets, measuring the topological noise by the number of connected components in the isosurface. Lastly, we present a formula predicting the fractal dimension as a function of noise and validate the formula with experimental results.\\\",\\\"Authors\\\":\\\"Khoury, M.;Wenger, R.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;NumericalMethodsMathematics;ScalarFieldDataTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.182\\\",\\\"Keywords\\\":\\\"fractal dimension;isosurface;scalar data\\\",\\\"Keywords_Processed\\\":\\\"fractal dimension;isosurface;scalar datum\\\",\\\"Title\\\":\\\"On the Fractal Dimension of Isosurfaces\\\"},\\\"536\\\":{\\\"Abstract\\\":\\\"Shading is an important feature for the comprehension of volume datasets, but is difficult to implement accurately. Current techniques based on pre-integrated direct volume rendering approximate the volume rendering integral by ignoring non-linear gradient variations between front and back samples, which might result in cumulated shading errors when gradient variations are important and / or when the illumination function features high frequencies. In this paper, we explore a simple approach for pre-integrated volume rendering with non-linear gradient interpolation between front and back samples. We consider that the gradient smoothly varies along a quadratic curve instead of a segment in-between consecutive samples. This not only allows us to compute more accurate shaded pre-integrated look-up tables, but also allows us to more efficiently process shading amplifying effects, based on gradient filtering. An interesting property is that the pre-integration tables we use remain two-dimensional as for usual pre-integrated classification. We conduct experiments using a full hardware approach with the Blinn-Phong illumination model as well as with a non-photorealistic illumination model.\\\",\\\"Authors\\\":\\\"Guetat, A.;Ancel, A.;Marchesin, S.;Dischler, J.-M.\\\",\\\"Clusters\\\":\\\"DataAcquisitionAndManagement;RaytracingRaycasting;Rendering;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.187\\\",\\\"Keywords\\\":\\\"pre-integration;volume rendering;raycasting;phong shading\\\",\\\"Keywords_Processed\\\":\\\"volume render;raycaste;phong shading;pre integration\\\",\\\"Title\\\":\\\"Pre-Integrated Volume Rendering with Non-Linear Gradient Interpolation\\\"},\\\"537\\\":{\\\"Abstract\\\":\\\"Many visualization applications benefit from displaying content on real-world objects rather than on a traditional display (e.g., a monitor). This type of visualization display is achieved by projecting precisely controlled illumination from multiple projectors onto the real-world colored objects. For such a task, the placement of the projectors is critical in assuring that the desired visualization is possible. Using ad hoc projector placement may cause some appearances to suffer from color shifting due to insufficient projector light radiance being exposed onto the physical surface. This leads to an incorrect appearance and ultimately to a false and potentially misleading visualization. In this paper, we present a framework to discover the optimal position and orientation of the projectors for such projection-based visualization displays. An optimal projector placement should be able to achieve the desired visualization with minimal projector light radiance. When determining optimal projector placement, object visibility, surface reflectance properties, and projector-surface distance and orientation need to be considered. We first formalize a theory for appearance editing image formation and construct a constrained linear system of equations that express when a desired novel appearance or visualization is possible given a geometric and surface reflectance model of the physical surface. Then, we show how to apply this constrained system in an adaptive search to efficiently discover the optimal projector placement which achieves the desired appearance. Constraints can be imposed on the maximum radiance allowed by the projectors and the projectors' placement to support specific goals of various visualization applications. We perform several real-world and simulated appearance edits and visualizations to demonstrate the improvement obtained by our discovered projector placement over ad hoc projector placement.\\\",\\\"Authors\\\":\\\"Law, A.J.;Aliaga, D.;Majumder, A.\\\",\\\"Clusters\\\":\\\"DesignMethodologiesAndInteractionDesign;LargeAndHighResDisplays;SmallMobileUbiquitousDevicesDisplays\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.189\\\",\\\"Keywords\\\":\\\"mobile and ubiquitous visualization;interaction design;large and high-resolution display\\\",\\\"Keywords_Processed\\\":\\\"large and high resolution display;mobile and ubiquitous visualization;interaction design\\\",\\\"Title\\\":\\\"Projector Placement Planning for High Quality Visualizations on Real-World Colored Objects\\\"},\\\"538\\\":{\\\"Abstract\\\":\\\"Graphics artists commonly employ physically-based simulation for the generation of effects such as smoke, explosions, and similar phenomena. The task of finding the correct parameters for a desired result, however, is difficult and time-consuming as current tools provide little to no guidance. In this paper, we present a new approach for the visual exploration of such parameter spaces. Given a three-dimensional scene description, we utilize sampling and spatio-temporal clustering techniques to generate a concise overview of the achievable variations and their temporal evolution. Our visualization system then allows the user to explore the simulation space in a goal-oriented manner. Animation sequences with a set of desired characteristics can be composed using a novel search-by-example approach and interactive direct volume rendering is employed to provide instant visual feedback.\\\",\\\"Authors\\\":\\\"Bruckner, S.;Moller, T.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;ApplicationsGeneralAndOther;DataClusteringAndAggregation;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.190\\\",\\\"Keywords\\\":\\\"visual exploration;visual effects;clustering;time-dependent volume data\\\",\\\"Keywords_Processed\\\":\\\"time dependent volume datum;clustering;visual effect;visual exploration\\\",\\\"Title\\\":\\\"Result-Driven Exploration of Simulation Parameter Spaces for Visual Effects Design\\\"},\\\"539\\\":{\\\"Abstract\\\":\\\"Over the past few years, large human populations around the world have been affected by an increase in significant seismic activities. For both conducting basic scientific research and for setting critical government policies, it is crucial to be able to explore and understand seismic and geographical information obtained through all scientific instruments. In this work, we present a visual analytics system that enables explorative visualization of seismic data together with satellite-based observational data, and introduce a suite of visual analytical tools. Seismic and satellite data are integrated temporally and spatially. Users can select temporal ;and spatial ranges to zoom in on specific seismic events, as well as to inspect changes both during and after the events. Tools for designing high dimensional transfer functions have been developed to enable efficient and intuitive comprehension of the multi-modal data. Spread-sheet style comparisons are used for data drill-down as well as presentation. Comparisons between distinct seismic events are also provided for characterizing event-wise differences. Our system has been designed for scalability in terms of data size, complexity (i.e. number of modalities), and varying form factors of display environments.\\\",\\\"Authors\\\":\\\"Xiaoru Yuan;He Xiao;Hanqi Guo;Peihong Guo;Kendall, W.;Huang, J.;Yongxian Zhang\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;LargeScaleDataAndScalability;MultidimensionalMultivariateMultifieldDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.192\\\",\\\"Keywords\\\":\\\"scalable visualization;seismic data;earth science visualization;multivariate visualization\\\",\\\"Keywords_Processed\\\":\\\"scalable visualization;earth science visualization;multivariate visualization;seismic datum\\\",\\\"Title\\\":\\\"Scalable Multi-variate Analytics of Seismic and Satellite-based Observational Data\\\"},\\\"540\\\":{\\\"Abstract\\\":\\\"In many applications of Direct Volume Rendering (DVR) the importance of a certain material or feature is highly dependent on its relative spatial location. For instance, in the medical diagnostic procedure, the patient's symptoms often lead to specification of features, tissues and organs of particular interest. One such example is pockets of gas which, if found inside the body at abnormal locations, are a crucial part of a diagnostic visualization. This paper presents an approach that enhances DVR transfer function design with spatial localization based on user specified material dependencies. Semantic expressions are used to define conditions based on relations between different materials, such as only render iodine uptake when close to liver. The underlying methods rely on estimations of material distributions which are acquired by weighing local neighborhoods of the data against approximations of material likelihood functions. This information is encoded and used to influence rendering according to the user's specifications. The result is improved focus on important features by allowing the user to suppress spatially less-important data. In line with requirements from actual clinical DVR practice, the methods do not require explicit material segmentation that would be impossible or prohibitively time-consuming to achieve in most real cases. The scheme scales well to higher dimensions which accounts for multi-dimensional transfer functions and multivariate data. Dual-Energy Computed Tomography, an important new modality in radiology, is used to demonstrate this scalability. In several examples we show significantly improved focus on clinically important aspects in the rendered images.\\\",\\\"Authors\\\":\\\"Lindholm, S.;Ljung, P.;Lundstrom, C.;Persson, A.;Ynnerman, A.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;SpaceRelatedSpatialDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.195\\\",\\\"Keywords\\\":\\\"direct volume rendering;spatial conditioning;neighborhood meta-data;transfer function\\\",\\\"Keywords_Processed\\\":\\\"transfer function;neighborhood meta datum;spatial conditioning;direct volume render\\\",\\\"Title\\\":\\\"Spatial Conditioning of Transfer Functions Using Local Material Distributions\\\"},\\\"541\\\":{\\\"Abstract\\\":\\\"Special relativistic visualization offers the possibility of experiencing the optical effects of traveling near the speed of light, including apparent geometric distortions as well as Doppler and searchlight effects. Early high-quality computer graphics images of relativistic scenes were created using offline, computationally expensive CPU-side 4D ray tracing. Alternate approaches such as image-based rendering and polygon-distortion methods are able to achieve interactivity, but exhibit inferior visual quality due to sampling artifacts. In this paper, we introduce a hybrid rendering technique based on polygon distortion and local ray tracing that facilitates interactive high-quality visualization of multiple objects moving at relativistic speeds in arbitrary directions. The method starts by calculating tight image-space footprints for the apparent triangles of the 3D scene objects. The final image is generated using a single image-space ray tracing step incorporating Doppler and searchlight effects. Our implementation uses GPU shader programming and hardware texture filtering to achieve high rendering speed.\\\",\\\"Authors\\\":\\\"Mller, T.;Grottel, S.;Weiskopf, D.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;GpuBasedTechniques;Illumination;NumericalMethodsMathematics;PhysicsAndPhysicalSciences\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.196\\\",\\\"Keywords\\\":\\\"aberration of light;illumination;gpu raytracing;poincare transformation;doppler effect;searchlight effect;special relativity\\\",\\\"Keywords_Processed\\\":\\\"searchlight effect;special relativity;illumination;gpu raytracing;aberration of light;doppler effect;poincare transformation\\\",\\\"Title\\\":\\\"Special Relativistic Visualization by Local Ray Tracing\\\"},\\\"542\\\":{\\\"Abstract\\\":\\\"Characteristic curves of vector fields include stream, path, and streak lines. Stream and path lines can be obtained by a simple vector field integration of an autonomous ODE system, i.e., they can be described as tangent curves of a vector field. This facilitates their mathematical analysis including the extraction of core lines around which stream or path lines exhibit swirling motion, or the computation of their curvature for every point in the domain without actually integrating them. Such a description of streak lines is not yet available, which excludes them from most of the feature extraction and analysis tools that have been developed in our community. In this paper, we develop the first description of streak lines as tangent curves of a derived vector field - the streak line vector field - and show how it can be computed from the spatial and temporal gradients of the flow map, i.e., a dense path line integration is required. We demonstrate the high accuracy of our approach by comparing it to solutions where the ground truth is analytically known and to solutions where the ground truth has been obtained using the classic streak line computation. Furthermore, we apply a number of feature extraction and analysis tools to the new streak line vector field including the extraction of cores of swirling streak lines and the computation of streak line curvature fields. These first applications foreshadow the large variety of possible future research directions based on our new mathematical description of streak lines.\\\",\\\"Authors\\\":\\\"Weinkauf, T.;Theisel, H.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;StreamlinesPathlinesStreaklines;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.198\\\",\\\"Keywords\\\":\\\"unsteady flow visualization;streak surfaces;feature extraction;streaklines\\\",\\\"Keywords_Processed\\\":\\\"streak surface;feature extraction;streakline;unsteady flow visualization\\\",\\\"Title\\\":\\\"Streak Lines as Tangent Curves of a Derived Vector field\\\"},\\\"543\\\":{\\\"Abstract\\\":\\\"Symmetric second-order tensor fields play a central role in scientific and biomedical studies as well as in image analysis and feature-extraction methods. The utility of displaying tensor field samples has driven the development of visualization techniques that encode the tensor shape and orientation into the geometry of a tensor glyph. With some exceptions, these methods work only for positive-definite tensors (i.e. having positive eigenvalues, such as diffusion tensors). We expand the scope of tensor glyphs to all symmetric second-order tensors in two and three dimensions, gracefully and unambiguously depicting any combination of positive and negative eigenvalues. We generalize a previous method of superquadric glyphs for positive-definite tensors by drawing upon a larger portion of the superquadric shape space, supplemented with a coloring that indicates the tensor's quadratic form. We show that encoding arbitrary eigenvalue sign combinations requires design choices that differ fundamentally from those in previous work on traceless tensors (arising in the study of liquid crystals). Our method starts with a design of 2-D tensor glyphs guided by principles of symmetry and continuity, and creates 3-D glyphs that include the 2-D glyphs in their axis-aligned cross-sections. A key ingredient of our method is a novel way of mapping from the shape space of three-dimensional symmetric second-order tensors to the unit square. We apply our new glyphs to stress tensors from mechanics, geometry tensors and Hessians from image analysis, and rate-of-deformation tensors in computational fluid dynamics.\\\",\\\"Authors\\\":\\\"Schultz, T.;Kindlmann, G.\\\",\\\"Clusters\\\":\\\"GlyphsGlyphBasedTechniques;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.199\\\",\\\"Keywords\\\":\\\"stress tensor;glyph design;geometry tensors;rate-of-deformation tensors;tensor glyphs\\\",\\\"Keywords_Processed\\\":\\\"stress tensor;geometry tensor;tensor glyph;glyph design;rate of deformation tensor\\\",\\\"Title\\\":\\\"Superquadric Glyphs for Symmetric Second-Order Tensors\\\"},\\\"544\\\":{\\\"Abstract\\\":\\\"In virtual colonoscopy, CT scans are typically acquired with the patient in both supine (facing up) and prone (facing down) positions. The registration of these two scans is desirable so that the user can clarify situations or confirm polyp findings at a location in one scan with the same location in the other, thereby improving polyp detection rates and reducing false positives. However, this supine-prone registration is challenging because of the substantial distortions in the colon shape due to the patient's change in position. We present an efficient algorithm and framework for performing this registration through the use of conformal geometry to guarantee that the registration is a diffeomorphism (a one-to-one and onto mapping). The taeniae coli and colon flexures are automatically extracted for each supine and prone surface, employing the colon geometry. The two colon surfaces are then divided into several segments using the flexures, and each segment is cut along a taenia coli and conformally flattened to the rectangular domain using holomorphic differentials. The mean curvature is color encoded as texture images, from which feature points are automatically detected using graph cut segmentation, mathematic morphological operations, and principal component analysis. Corresponding feature points are found between supine and prone and are used to adjust the conformal flattening to be quasi-conformal, such that the features become aligned. We present multiple methods of visualizing our results, including 2D flattened rendering, corresponding 3D endoluminal views, and rendering of distortion measurements. We demonstrate the efficiency and efficacy of our registration method by illustrating matched views on both the 2D flattened colon images and in the 3D volume rendered colon endoluminal view. We analytically evaluate the correctness of the results by measuring the distance between features on the registered colons.\\\",\\\"Authors\\\":\\\"Wei Zeng;Marino, J.;Chaitanya Gurijala, K.;Xianfeng Gu;Kaufman, A.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DataRegistrationFusionAndIntegration;GeometryBasedTechniques;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.200\\\",\\\"Keywords\\\":\\\"data registration;medical visualization;geometry-based technique;mathematical foundations for visualization\\\",\\\"Keywords_Processed\\\":\\\"geometry base technique;mathematical foundation for visualization;medical visualization;datum registration\\\",\\\"Title\\\":\\\"Supine and Prone Colon Registration Using Quasi-Conformal Mapping\\\"},\\\"545\\\":{\\\"Abstract\\\":\\\"We present TanGeoMS, a tangible geospatial modeling visualization system that couples a laser scanner, projector, and a flexible physical three-dimensional model with a standard geospatial information system (GIS) to create a tangible user interface for terrain data. TanGeoMS projects an image of real-world data onto a physical terrain model. Users can alter the topography of the model by modifying the clay surface or placing additional objects on the surface. The modified model is captured by an overhead laser scanner then imported into a GIS for analysis and simulation of real-world processes. The results are projected back onto the surface of the model providing feedback on the impact of the modifications on terrain parameters and simulated processes. Interaction with a physical model is highly intuitive, allowing users to base initial design decisions on geospatial data, test the impact of these decisions in GIS simulations, and use the feedback to improve their design. We demonstrate the system on three applications: investigating runoff management within a watershed, assessing the impact of storm surge on barrier islands, and exploring landscape rehabilitation in military training areas.\\\",\\\"Authors\\\":\\\"Tateosian, L.;Mitasova, H.;Harmon, B.;Fogleman, B.;Weaver, K.;Harmon, R.\\\",\\\"Clusters\\\":\\\"CollaborativeVisualization;GeographyGeospatialVisCartographyTerrainVis;HumanComputerInteractionHumanFactors;UserInterfacesGeneral;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.202\\\",\\\"Keywords\\\":\\\"terrain visualization;visualization systems;tangible user interface;human-computer interaction;geographic/geospatial visualization;collaborative visualization\\\",\\\"Keywords_Processed\\\":\\\"human computer interaction;visualization system;geographic geospatial visualization;terrain visualization;collaborative visualization;tangible user interface\\\",\\\"Title\\\":\\\"TanGeoMS: Tangible Geospatial Modeling System\\\"},\\\"546\\\":{\\\"Abstract\\\":\\\"Most multidimensional projection techniques rely on distance (dissimilarity) information between data instances to embed high-dimensional data into a visual space. When data are endowed with Cartesian coordinates, an extra computational effort is necessary to compute the needed distances, making multidimensional projection prohibitive in applications dealing with interactivity and massive data. The novel multidimensional projection technique proposed in this work, called Part-Linear Multidimensional Projection (PLMP), has been tailored to handle multivariate data represented in Cartesian high-dimensional spaces, requiring only distance information between pairs of representative samples. This characteristic renders PLMP faster than previous methods when processing large data sets while still being competitive in terms of precision. Moreover, knowing the range of variation for data instances in the high-dimensional space, we can make PLMP a truly streaming data projection technique, a trait absent in previous methods.\\\",\\\"Authors\\\":\\\"Paulovich, F.V.;Silva, C.T.;Nonato, L.G.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;DimensionalityReduction;StreamingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.207\\\",\\\"Keywords\\\":\\\"dimension reduction;visual data mining;projection methods;streaming technique\\\",\\\"Keywords_Processed\\\":\\\"stream technique;projection method;dimension reduction;visual datum mining\\\",\\\"Title\\\":\\\"Two-Phase Mapping for Projecting Massive Data Sets\\\"},\\\"547\\\":{\\\"Abstract\\\":\\\"Although direct volume rendering is established as a powerful tool for the visualization of volumetric data, efficient and reliable feature detection is still an open topic. Usually, a tradeoff between fast but imprecise classification schemes and accurate but time-consuming segmentation techniques has to be made. Furthermore, the issue of uncertainty introduced with the feature detection process is completely neglected by the majority of existing approaches.In this paper we propose a guided probabilistic volume segmentation approach that focuses on the minimization of uncertainty. In an iterative process, our system continuously assesses uncertainty of a random walker-based segmentation in order to detect regions with high ambiguity, to which the user's attention is directed to support the correction of potential misclassifications. This reduces the risk of critical segmentation errors and ensures that information about the segmentation's reliability is conveyed to the user in a dependable way. In order to improve the efficiency of the segmentation process, our technique does not only take into account the volume data to be segmented, but also enables the user to incorporate classification information. An interactive workflow has been achieved by implementing the presented system on the GPU using the OpenCL API. Our results obtained for several medical data sets of different modalities, including brain MRI and abdominal CT, demonstrate the reliability and efficiency of our approach.\\\",\\\"Authors\\\":\\\"Prassni, J.-S.;Ropinski, T.;Hinrichs, K.\\\",\\\"Clusters\\\":\\\"ImageBasedDataImageSignalProcessing;SegmentationAndClassification;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.208\\\",\\\"Keywords\\\":\\\"random walker;classification;uncertainty;volume segmentation\\\",\\\"Keywords_Processed\\\":\\\"volume segmentation;uncertainty;classification;random walker\\\",\\\"Title\\\":\\\"Uncertainty-Aware Guided Volume Segmentation\\\"},\\\"548\\\":{\\\"Abstract\\\":\\\"Practical volume visualization pipelines are never without compromises and errors. A delicate and often-studied component is the interpolation of off-grid samples, where aliasing can lead to misleading artifacts and blurring, potentially hiding fine details of critical importance. The verifiable visualization framework we describe aims to account for these errors directly in the volume generation stage, and we specifically target volumetric data obtained via computed tomography (CT) reconstruction. In this case the raw data are the X-ray projections obtained from the scanner and the volume data generation process is the CT algorithm. Our framework informs the CT reconstruction process of the specific filter intended for interpolation in the subsequent visualization process, and this in turn ensures an accurate interpolation there at a set tolerance. Here, we focus on fast trilinear interpolation in conjunction with an octree-type mixed resolution volume representation without T-junctions. Efficient rendering is achieved by a space-efficient and locality-optimized representation, which can straightforwardly exploit fast fixed-function pipelines on GPUs.\\\",\\\"Authors\\\":\\\"Ziyi Zheng;Wei Xu;Mueller, K.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DisplaysGeneral;EvaluationGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.211\\\",\\\"Keywords\\\":\\\"direct volume rendering;filtered back-projection;computed tomography;verifiable visualization\\\",\\\"Keywords_Processed\\\":\\\"filter back projection;verifiable visualization;compute tomography;direct volume render\\\",\\\"Title\\\":\\\"VDVR: Verifiable Volume Visualization of Projection-Based Data\\\"},\\\"549\\\":{\\\"Abstract\\\":\\\"This paper introduces a new streamline placement and selection algorithm for 3D vector fields. Instead of considering the problem as a simple feature search in data space, we base our work on the observation that most streamline fields generate a lot of self-occlusion which prevents proper visualization. In order to avoid this issue, we approach the problem in a view-dependent fashion and dynamically determine a set of streamlines which contributes to data understanding without cluttering the view. Since our technique couples flow characteristic criteria and view-dependent streamline selection we are able achieve the best of both worlds: relevant flow description and intelligible, uncluttered pictures. We detail an efficient GPU implementation of our algorithm, show comprehensive visual results on multiple datasets and compare our method with existing flow depiction techniques. Our results show that our technique greatly improves the readability of streamline visualizations on different datasets without requiring user intervention.\\\",\\\"Authors\\\":\\\"Marchesin, S.;Cheng-Kai Chen;Ho, C.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"StreamlinesPathlinesStreaklines;VectorFieldsDataAndTechniques;ViewDependentVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.212\\\",\\\"Keywords\\\":\\\"view-dependent;vector field;streamlines\\\",\\\"Keywords_Processed\\\":\\\"vector field;view dependent;streamline\\\",\\\"Title\\\":\\\"View-Dependent Streamlines for 3D Vector fields\\\"},\\\"550\\\":{\\\"Abstract\\\":\\\"An important goal of scientific data analysis is to understand the behavior of a system or process based on a sample of the system. In many instances it is possible to observe both input parameters and system outputs, and characterize the system as a high-dimensional function. Such data sets arise, for instance, in large numerical simulations, as energy landscapes in optimization problems, or in the analysis of image data relating to biological or medical parameters. This paper proposes an approach to analyze and visualizing such data sets. The proposed method combines topological and geometric techniques to provide interactive visualizations of discretely sampled high-dimensional scalar fields. The method relies on a segmentation of the parameter space using an approximate Morse-Smale complex on the cloud of point samples. For each crystal of the Morse-Smale complex, a regression of the system parameters with respect to the output yields a curve in the parameter space. The result is a simplified geometric representation of the Morse-Smale complex in the high dimensional input domain. Finally, the geometric representation is embedded in 2D, using dimension reduction, to provide a visualization platform. The geometric properties of the regression curves enable the visualization of additional information about each crystal such as local and global shape, width, length, and sampling densities. The method is illustrated on several synthetic examples of two dimensional functions. Two use cases, using data sets from the UCI machine learning repository, demonstrate the utility of the proposed approach on real data. Finally, in collaboration with domain experts the proposed method is applied to two scientific challenges. The analysis of parameters of climate simulations and their relationship to predicted global energy flux and the concentrations of chemical species in a combustion simulation and their integration with temperature.\\\",\\\"Authors\\\":\\\"Gerber, S.;Bremer, P.-T.;Pascucci, V.;Whitaker, R.T.\\\",\\\"Clusters\\\":\\\"MultidimensionalMultivariateMultifieldDataAndTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.213\\\",\\\"Keywords\\\":\\\"high-dimensional visualization;morse-smale complex;morse theory\\\",\\\"Keywords_Processed\\\":\\\"morse smale complex;morse theory;high dimensional visualization\\\",\\\"Title\\\":\\\"Visual Exploration of High Dimensional Scalar Functions\\\"},\\\"551\\\":{\\\"Abstract\\\":\\\"Interactivity is key to exploration of volume data. Interactivity may be hindered due to many factors, e.g. large data size,high resolution or complexity of a data set, or an expensive rendering algorithm. We present a novel framework for visualizing volumedata that enables interactive exploration using proxy images, without accessing the original 3D data. Data exploration using directvolume rendering requires multiple (often redundant) accesses to possibly large amounts of data. The notion of visualization by proxyrelies on the ability to defer operations traditionally used for exploring 3D data to a more suitable intermediate representation forinteraction - proxy images. Such operations include view changes, transfer function exploration, and relighting. While previous workhas addressed specific interaction needs, we provide a complete solution that enables real-time interaction with large data sets andhas low hardware and storage requirements.\\\",\\\"Authors\\\":\\\"Tikhonova, A.;Correa, C.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;ImageBasedDataImageSignalProcessing;InteractionTechniquesGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.215\\\",\\\"Keywords\\\":\\\"image-based rendering;volume visualization;volume distortion camera;deferred interaction\\\",\\\"Keywords_Processed\\\":\\\"image base render;volume visualization;defer interaction;volume distortion camera\\\",\\\"Title\\\":\\\"Visualization by Proxy: A Novel Framework for Deferred Interaction with Volume Data\\\"},\\\"552\\\":{\\\"Abstract\\\":\\\"In flow simulations the behavior and properties of particle trajectories often depend on the physical geometry contained in the simulated environment. Understanding the flow in and around the geometry itself is an important part of analyzing the data. Previous work has often utilized focus+context rendering techniques, with an emphasis on showing trajectories while simplifying or illustratively rendering the physical areas. Our research instead emphasizes the local relationship between particle paths and geometry by using a projected multi-field visualization technique. The correlation between a particle path and its surrounding area is calculated on-the-fly and displayed in a non-intrusive manner. In addition, we support visual exploration and comparative analysis through the use of linked information visualization, such as manipulatable curve plots and one-on-one similarity plots. Our technique is demonstrated on particle trajectories from a groundwater simulation and a computer room airflow simulation, where the flow of particles is highly influenced by the dense geometry.\\\",\\\"Authors\\\":\\\"Jones, C.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;FocusContextTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;MultipleLinkedCoordinatedViews\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.218\\\",\\\"Keywords\\\":\\\"flow visualization;coordinated linked views;focus+context visualization;multi-field visualization\\\",\\\"Keywords_Processed\\\":\\\"coordinate link view;focus context visualization;multi field visualization;flow visualization\\\",\\\"Title\\\":\\\"Visualizing Flow Trajectories Using Locality-based Rendering and Warped Curve Plots\\\"},\\\"553\\\":{\\\"Abstract\\\":\\\"In this paper, we introduce a novel application of volume modeling techniques on laser Benign Prostatic Hyperplasia (BPH) therapy simulation. The core technique in our system is an algorithm for simulating the tissue vaporization process by laser heating. Different from classical volume CSG operations, our technique takes experimental data as the guidance to determine the vaporization amount so that only a specified amount of tissue is vaporized in each time. Our algorithm uses a predictor-corrector strategy. First, we apply the classical CSG algorithm on a tetrahedral grid based distance field to estimate the vaporized tissue amount. Then, a volume-correction phase is applied on the distance field. To improve the performance, we further propose optimization approaches for efficient implementation.\\\",\\\"Authors\\\":\\\"Zhang, N.;Xiangmin Zhou;Yunhe Shen;Sweet, R.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.221\\\",\\\"Keywords\\\":\\\"volume csg;medical simulation;large benign prostatic hyperplasia simulator;controlled-volume vaporization;volume modeling\\\",\\\"Keywords_Processed\\\":\\\"control volume vaporization;medical simulation;large benign prostatic hyperplasia simulator;volume csg;volume model\\\",\\\"Title\\\":\\\"Volumetric Modeling in Laser BPH Therapy Simulation\\\"},\\\"554\\\":{\\\"Abstract\\\":\\\"In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.\\\",\\\"Authors\\\":\\\"Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, E.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;FlowVisualizationDataAndTechniques;ParticleVisualizationAndTechniques;ReasoningProblemSolvingAndDecisionMaking;Simulation\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2010.223\\\",\\\"Keywords\\\":\\\"decision making;simulation steering;computational fluid dynamics;smoothed particle hydrodynamics;parallel worlds;problem solving environments\\\",\\\"Keywords_Processed\\\":\\\"simulation steering;decision make;smoothed particle hydrodynamic;problem solve environment;computational fluid dynamic;parallel world\\\",\\\"Title\\\":\\\"World Lines\\\"},\\\"555\\\":{\\\"Abstract\\\":\\\"In risk assessment applications well informed decisions are made based on huge amounts of multi-dimensional data. In many domains not only the risk of a wrong decision, but in particular the trade-off between the costs of possible decisions are of utmost importance. In this paper we describe a framework tightly integrating interactive visual exploration with machine learning to support the decision making process. The proposed approach uses a series of interactive 2D visualizations of numeric and ordinal data combined with visualization of classification models. These series of visual elements are further linked to the classifier's performance visualized using an interactive performance curve. An interactive decision point on the performance curve allows the decision maker to steer the classification model and instantly identify the critical, cost changing data elements, in the various linked visualizations. The critical data elements are represented as images in order to trigger associations related to the knowledge of the expert. In this context the data visualization and classification results are not only linked together, but are also linked back to the classification model. Such a visual analytics framework allows the user to interactively explore the costs of his decisions for different settings of the model and accordingly use the most suitable classification model and make more informed and reliable decisions. A case study on data from the Forensic Psychiatry domain reveals the usefulness of the suggested approach.\\\",\\\"Authors\\\":\\\"Migut, M.;Worring, M.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;MachineLearningAndStatistics;MultidimensionalMultivariateMultifieldDataAndTechniques;SegmentationAndClassification;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2010.5652398\\\",\\\"Keywords\\\":\\\"decision boundary visualization;classification;multi-dimensional space;interactive visual exploration;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;interactive visual exploration;classification;multi dimensional space;decision boundary visualization\\\",\\\"Title\\\":\\\"Visual exploration of classification models for risk assessment\\\"},\\\"556\\\":{\\\"Abstract\\\":\\\"Data sets in astronomy are growing to enormous sizes. Modern astronomical surveys provide not only image data but also catalogues of millions of objects (stars, galaxies), each object with hundreds of associated parameters. Exploration of this very high-dimensional data space poses a huge challenge. Subspace clustering is one among several approaches which have been proposed for this purpose in recent years. However, many clustering algorithms require the user to set a large number of parameters without any guidelines. Some methods also do not provide a concise summary of the datasets, or, if they do, they lack additional important information such as the number of clusters present or the significance of the clusters. In this paper, we propose a method for ranking subspaces for clustering which overcomes many of the above limitations. First we carry out a transformation from parametric space to discrete image space where the data are represented by a grid-based density field. Then we apply so-called connected morphological operators on this density field of astronomical objects that provides visual support for the analysis of the important subspaces. Clusters in subspaces correspond to high-intensity regions in the density image. The importance of a cluster is measured by a new quality criterion based on the dynamics of local maxima of the density. Connected operators are able to extract such regions with an indication of the number of clusters present. The subspaces are visualized during computation of the quality measure, so that the user can interact with the system to improve the results. In the result stage, we use three visualization toolkits linked within a graphical user interface so that the user can perform an in-depth exploration of the ranked subspaces. Evaluation based on synthetic as well as real astronomical datasets demonstrates the power of the new method. We recover various known astronomical relations directly from the data with little or no a pri- - ori assumptions. Hence, our method holds good prospects for discovering new relations as well.\\\",\\\"Authors\\\":\\\"Ferdosi, B.J.;Buddelmeijer, H.;Trager, S.;Wilkinson, M.H.F.;Roerdink, J.B.T.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;AstronomyAstrophysics;DataClusteringAndAggregation;ImageBasedDataImageSignalProcessing;SpaceRelatedSpatialDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2010.5652450\\\",\\\"Keywords\\\":\\\"astronomical data;clustering high-dimensional data;visual exploration;connected morphological operators;subspace finding\\\",\\\"Keywords_Processed\\\":\\\"visual exploration;cluster high dimensional datum;connected morphological operator;astronomical datum;subspace finding\\\",\\\"Title\\\":\\\"finding and visualizing relevant subspaces for clustering high-dimensional astronomical data using connected morphological operators\\\"},\\\"557\\\":{\\\"Abstract\\\":\\\"Visualization of multi-dimensional data is challenging due to the number of complex correlations that may be present in the data but that are difficult to be visually identified. One of the main causes for this problem is the inherent loss of information that occurs when high-dimensional data is projected into 2D or 3D. Although 2D scatterplots are ubiquitous due to their simplicity and familiarity, there are not a lot of variations on their basic metaphor. In this paper, we present a new way of visualizing multidimensional data using scatterplots. We extend 2D scatterplots using sensitivity coefficients to highlight local variation of one variable with respect to another. When applied to a scatterplot, these sensitivities can be understood as velocities, and the resulting visualization resembles a flow field. We also present a number of operations, based on flow-field analysis, that help users navigate, select and cluster points in an efficient manner. We show the flexibility and generality of this approach using a number of multidimensional data sets across different domains.\\\",\\\"Authors\\\":\\\"Yu-Hsuan Chan;Correa, C.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"DataTransformation;DimensionalityReduction;MachineLearningAndStatistics;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VAST.2010.5652460\\\",\\\"Keywords\\\":\\\"uncertainty;data transformation;principal component analysis;model fitting\\\",\\\"Keywords_Processed\\\":\\\"datum transformation;uncertainty;model fit;principal component analysis\\\",\\\"Title\\\":\\\"Flow-based scatterplots for sensitivity analysis\\\"},\\\"558\\\":{\\\"Abstract\\\":\\\"Events that happened in the past are important for understanding the ongoing processes, predicting future developments, and making informed decisions. Significant and/or interesting events tend to attract many people. Some people leave traces of their attendance in the form of computer-processable data, such as records in the databases of mobile phone operators or photos on photo sharing web sites. We developed a suite of visual analytics methods for reconstructing past events from these activity traces. Our tools combine geocomputations, interactive geovisualizations and statistical methods to enable integrated analysis of the spatial, temporal, and thematic components of the data, including numeric attributes and texts. We demonstrate the utility of our approach on two large real data sets, mobile phone calls in Milano during 9 days and flickr photos made on British Isles during 5 years.\\\",\\\"Authors\\\":\\\"Andrienko, G.;Andrienko, N.;Mladenov, M.;Mock, M.;Politz, C.\\\",\\\"Clusters\\\":\\\"EventsTrendsOutlierDetectionAnalysisAndVisualization;GeographyGeospatialVisCartographyTerrainVis;LargeScaleDataAndScalability;SpatiotemporalDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2010.5652478\\\",\\\"Keywords\\\":\\\"spatio-temporal data;event detection;time-series analysis;scalable visualization;geovisualization\\\",\\\"Keywords_Processed\\\":\\\"spatio temporal datum;time series analysis;geovisualization;event detection;scalable visualization\\\",\\\"Title\\\":\\\"Discovering bits of place histories from people's activity traces\\\"},\\\"559\\\":{\\\"Abstract\\\":\\\"The massive amount of financial time series data that originates from the stock market generates large amounts of complex data of high interest. However, adequate solutions that can effectively handle the information in order to gain insight and to understand the market mechanisms are rare. In this paper, we present two techniques and applications that enable the user to interactively analyze large amounts of time series data in real-time in order to get insight into the development of assets, market sectors, countries, and the financial market as a whole. The first technique allows users to quickly analyze combinations of single assets, market sectors as well as countries, compare them to each other, and to visually discover the periods of time where market sectors and countries get into turbulence. The second application clusters a selection of large amounts of financial time series data according to their similarity, and analyzes the distribution of the assets among market sectors. This allows users to identify the characteristic graphs which are representative for the development of a particular market sector, and also to identify the assets which behave considerably differently compared to other assets in the same sector. Both applications allow the user to perform investigative exploration techniques and interactive visual analysis in real-time.\\\",\\\"Authors\\\":\\\"Ziegler, H.;Jenny, M.;Gruse, T.;Keim, D.A.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;BusinessFinanceEconomyManufacturing;TimeseriesTimeVaryingDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2010.5652530\\\",\\\"Keywords\\\":\\\"exploratory data analysis;time-series data;time-series clustering;visual analytics;financial information visualization\\\",\\\"Keywords_Processed\\\":\\\"time series clustering;financial information visualization;visual analytic;time series datum;exploratory datum analysis\\\",\\\"Title\\\":\\\"Visual market sector analysis for financial time series data\\\"},\\\"560\\\":{\\\"Abstract\\\":\\\"Text visualization becomes an increasingly more important research topic as the need to understand massive-scale textual information is proven to be imperative for many people and businesses. However, it is still very challenging to design effective visual metaphors to represent large corpora of text due to the unstructured and high-dimensional nature of text. In this paper, we propose a data model that can be used to represent most of the text corpora. Such a data model contains four basic types of facets: time, category, content (unstructured), and structured facet. To understand the corpus with such a data model, we develop a hybrid visualization by combining the trend graph with tag-clouds. We encode the four types of data facets with four separate visual dimensions. To help people discover evolutionary and correlation patterns, we also develop several visual interaction methods that allow people to interactively analyze text by one or more facets. Finally, we present two case studies to demonstrate the effectiveness of our solution in support of multi-faceted visual analysis of text corpora.\\\",\\\"Authors\\\":\\\"Shi, L.;Furu Wei;Shixia Liu;Li Tan;Xiaoxiao Lian;Zhou, M.X.\\\",\\\"Clusters\\\":\\\"DataFacetsAndTechniques;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2010.5652931\\\",\\\"Keywords\\\":\\\"text visualization;multi-faceted visualization\\\",\\\"Keywords_Processed\\\":\\\"multi faceted visualization;text visualization\\\",\\\"Title\\\":\\\"Understanding text corpora with multiple facets\\\"},\\\"561\\\":{\\\"Abstract\\\":\\\"In this paper, we present a new web-based visual analytics system, VizCept, which is designed to support fluid, collaborative analysis of large textual intelligence datasets. The main approach of the design is to combine individual workspace and shared visualization in an integrated environment. Collaborating analysts will be able to identify concepts and relationships from the dataset based on keyword searches in their own workspace and collaborate visually with other analysts using visualization tools such as a concept map view and a timeline view. The system allows analysts to parallelize the work by dividing initial sets of concepts, investigating them on their own workspace, and then integrating individual findings automatically on shared visualizations with support for interaction and personal graph layout in real time, in order to develop a unified plot. We highlight several design considerations that promote communication and analytic performance in small team synchronous collaboration. We report the result of a pair of case study applications including collaboration and communication methods, analysis strategies, and user behaviors under a competition setting in the same location at the same time. The results of these demonstrate the tool's effectiveness for synchronous collaborative construction and use of visualizations in intelligence data analysis.\\\",\\\"Authors\\\":\\\"Haeyong Chung;Seungwon Yang;Massjouni, N.;Andrews, C.;Kanna, R.;North, C.\\\",\\\"Clusters\\\":\\\"CollaborativeVisualization;PrivacySecurityIntelligenceAnalysis;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2010.5652932\\\",\\\"Keywords\\\":\\\"text and document data;intelligence analysis;collaborative visualization\\\",\\\"Keywords_Processed\\\":\\\"text and document datum;collaborative visualization;intelligence analysis\\\",\\\"Title\\\":\\\"VizCept: Supporting synchronous collaboration for constructing visualizations in intelligence analysis\\\"},\\\"562\\\":{\\\"Abstract\\\":\\\"Journalists increasingly turn to social media sources such as Facebook or Twitter to support their coverage of various news events. For large-scale events such as televised debates and speeches, the amount of content on social media can easily become overwhelming, yet still contain information that may aid and augment reporting via individual content items as well as via aggregate information from the crowd's response. In this work we present a visual analytic tool, Vox Civitas, designed to help journalists and media professionals extract news value from large-scale aggregations of social media content around broadcast events. We discuss the design of the tool, present the text analysis techniques used to enable the presentation, and provide details on the visual and interaction design. We provide an exploratory evaluation based on a user study in which journalists interacted with the system to explore and report on a dataset of over one hundred thousand twitter messages collected during the U.S. State of the Union presidential address in 2010.\\\",\\\"Authors\\\":\\\"Diakopoulos, N.;Naaman, M.;Kivran-Swaine, F.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;Cognition;SocialNetworksAndSocialMedia\\\",\\\"DOI\\\":\\\"10.1109/VAST.2010.5652922\\\",\\\"Keywords\\\":\\\"social media;computer-assisted reporting;sensemaking;computational journalism\\\",\\\"Keywords_Processed\\\":\\\"computer assist reporting;sensemake;social medium;computational journalism\\\",\\\"Title\\\":\\\"Diamonds in the rough: Social media visual analytics for journalistic inquiry\\\"},\\\"563\\\":{\\\"Abstract\\\":\\\"Diagnosing faults in an operational computer network is a frustrating, time-consuming exercise. Despite advances, automatic diagnostic tools are far from perfect: they occasionally miss the true culprit and are mostly only good at narrowing down the search to a few potential culprits. This uncertainty and the inability to extract useful sense from tool output renders most tools not usable to administrators. To bridge this gap, we present NetClinic, a visual analytics system that couples interactive visualization with an automated diagnostic tool for enterprise networks. It enables administrators to verify the output of the automatic analysis at different levels of detail and to move seamlessly across levels while retaining appropriate context. A qualitative user study shows that NetClinic users can accurately identify the culprit, even when it is not present in the suggestions made by the automated component. We also find that supporting a variety of sensemaking strategies is a key to the success of systems that enhance automated diagnosis.\\\",\\\"Authors\\\":\\\"Zhicheng Liu;Bongshin Lee;Kandula, S.;Mahajan, R.\\\",\\\"Clusters\\\":\\\"Cognition;ComputerNetworksNetworkSecurity;GraphNetworkDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2010.5652910\\\",\\\"Keywords\\\":\\\"information visualization;network diagnosis;sensemaking;semantic graph layout;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"semantic graph layout;sensemake;information visualization;visual analytic;network diagnosis\\\",\\\"Title\\\":\\\"NetClinic: Interactive visualization to enhance automated fault diagnosis in enterprise networks\\\"},\\\"564\\\":{\\\"Abstract\\\":\\\"Information foraging and sensemaking with heterogeneous information are context-dependent activities. Thus visual analytics tools to support these activities must incorporate context. But, context is a difficult concept to define, model, and represent. Creating and representing context in support of visually-enabled reasoning about complex problems with complex information is a complementary but different challenge than that addressed in context-aware computing. In the latter, the goal is automated adaptation of the system to meet user needs for applications such as mobile location-based services where information about the location, the user, and the user goals filters what gets presented on a small mobile device. In contrast, for visual analytics-enabled information foraging and sensemaking, the user is likely to take an active role in foraging for the contextual information needed to support sensemaking in relation to some multifaceted problem. In this paper, we address the challenges of constructing and representing context within visual interfaces that support analytical reasoning in crisis management and humanitarian relief. The challenges stem from the diverse forms of information that can provide context and difficulty in defining and operationalizing context itself. Here, we pay particular attention to document foraging to support construction of the geographic and historical context within which monitoring and sensemaking can be carried out. Specifically, we present the concept of geo-historical context (GHC) and outline an empirical assessment of both the concept and its implementation in the Context Discovery Application, a web-based tool that supports document foraging and sensemaking.\\\",\\\"Authors\\\":\\\"Tomaszewski, B.;MacEachren, A.M.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;Cognition;DataAcquisitionAndManagement;FocusContextTechniques;TextDocumentTopicAnalysisDataAndTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/VAST.2010.5652895\\\",\\\"Keywords\\\":\\\"context;sensemaking;geographic information retrieval;mapping;foraging;text analysis\\\",\\\"Keywords_Processed\\\":\\\"text analysis;sensemake;context;forage;mapping;geographic information retrieval\\\",\\\"Title\\\":\\\"Geo-historical context support for information foraging and sensemaking: Conceptual model, implementation, and assessment\\\"},\\\"565\\\":{\\\"Abstract\\\":\\\"Insight Externalization (IE) refers to the process of capturing and recording the semantics of insights in decision making and problem solving. To reduce human effort, Automated Insight Externalization (AIE) is desired. Most existing IE approaches achieve automation by capturing events (e.g., clicks and key presses) or actions (e.g., panning and zooming). In this paper, we propose a novel AIE approach named Click2Annotate. It allows semi-automatic insight annotation that captures low-level analytics task results (e.g., clusters and outliers), which have higher semantic richness and abstraction levels than actions and events. Click2Annotate has two significant benefits. First, it reduces human effort required in IE and generates annotations easy to understand. Second, the rich semantic information encoded in the annotations enables various insight management activities, such as insight browsing and insight retrieval. We present a formal user study that proved this first benefit. We also illustrate the second benefit by presenting the novel insight management activities we developed based on Click2Annotate, namely scented insight browsing and faceted insight search.\\\",\\\"Authors\\\":\\\"Yang Chen;Barlowe, S.;Jing Yang\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;Labeling;MultidimensionalMultivariateMultifieldDataAndTechniques;ReasoningProblemSolvingAndDecisionMaking;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2010.5652885\\\",\\\"Keywords\\\":\\\"annotation;decision making;insight management;multi-dimensional visualization;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"multi dimensional visualization;decision make;visual analytic;insight management;annotation\\\",\\\"Title\\\":\\\"Click2Annotate: Automated Insight Externalization with rich semantics\\\"},\\\"566\\\":{\\\"Abstract\\\":\\\"This paper highlights the important role that record-keeping (i.e. taking notes and saving charts) plays in collaborative data analysis within the business domain. The discussion of record-keeping is based on observations from a user study in which co-located teams worked on collaborative visual analytics tasks using large interactive wall and tabletop displays. Part of our findings is a collaborative data analysis framework that encompasses note taking as one of the main activities. We observed that record-keeping was a critical activity within the analysis process. Based on our observations, we characterize notes according to their content, scope, and usage, and describe how they fit into a process of collaborative data analysis. We then discuss suggestions for the design of collaborative visual analytics tools.\\\",\\\"Authors\\\":\\\"Mahyar, N.;Sarvghad, A.;Tory, M.\\\",\\\"Clusters\\\":\\\"CollaborativeVisualization;EvaluationGeneral;LargeAndHighResDisplays;ProvenanceAndHistory;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2010.5652879\\\",\\\"Keywords\\\":\\\"wall displays;collaboration;tabletop;note taking;provenance;recording;history\\\",\\\"Keywords_Processed\\\":\\\"history;wall display;tabletop;collaboration;note take;recording;provenance\\\",\\\"Title\\\":\\\"A closer look at note taking in the co-located collaborative visual analytics process\\\"},\\\"567\\\":{\\\"Abstract\\\":\\\"The final product of an analyst's investigation using a visualization is often a report of the discovered knowledge, as well as the methods employed and reasoning behind the discovery. We believe that analysts may have difficulty keeping track of their knowledge discovery process and will require tools to assist in accurately recovering their reasoning. We first report on a study examining analysts' recall of their strategies and methods, demonstrating their lack of memory of the path of knowledge discovery. We then explore whether a tool visualizing the steps of the visual analysis can aid users in recalling their reasoning process. The results of our second study indicate that visualizations of interaction logs can serve as an effective memory aid, allowing analysts to recall additional details of their strategies and decisions.\\\",\\\"Authors\\\":\\\"Lipford, H.R.;Stukes, F.;Wenwen Dou;Hawkins, M.E.;Chang, R.\\\",\\\"Clusters\\\":\\\"ReasoningProblemSolvingAndDecisionMaking;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2010.5653598\\\",\\\"Keywords\\\":\\\"visualization;reasoning process;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"visualization;visual analytic;reason process\\\",\\\"Title\\\":\\\"Helping users recall their reasoning process\\\"},\\\"568\\\":{\\\"Abstract\\\":\\\"Interaction and manual manipulation have been shown in the cognitive science literature to play a critical role in problem solving. Given different types of interactions or constraints on interactions, a problem can appear to have different degrees of difficulty. While this relationship between interaction and problem solving has been well studied in the cognitive science literatures, the visual analytics community has yet to exploit this understanding for analytical problem solving. In this paper, we hypothesize that constraints on interactions and constraints encoded in visual representations can lead to strategies of varying effectiveness during problem solving. To test our hypothesis, we conducted a user study in which participants were given different levels of interaction constraints when solving a simple math game called Number Scrabble. Number Scrabble is known to have an optimal visual problem isomorph, and the goal of this study is to learn if and how the participants could derive the isomorph and to analyze the strategies that the participants utilize in solving the problem. Our results indicate that constraints on interactions do affect problem solving, and that while the optimal visual isomorph is difficult to derive, certain interaction constraints can lead to a higher chance of deriving the isomorph.\\\",\\\"Authors\\\":\\\"Wenwen Dou;Ziemkiewicz, C.;Harrison, L.;Dong Hyun Jeong;Ryan, R.;Ribarsky, W.;Xiaoyu Wang;Chang, R.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;InteractionTechniquesGeneral;ReasoningProblemSolvingAndDecisionMaking\\\",\\\"DOI\\\":\\\"10.1109/VAST.2010.5653599\\\",\\\"Keywords\\\":\\\"problem solving;visual isomorph;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;problem solve;visual isomorph\\\",\\\"Title\\\":\\\"Comparing different levels of interaction constraints for deriving visual problem isomorphs\\\"},\\\"569\\\":{\\\"Abstract\\\":\\\"These current studies explored the impact of individual differences in personality factors on interface interaction and learning performance behaviors in both an interactive visualization and a menu-driven web table in two studies. Participants were administered 3 psychometric measures designed to assess Locus of Control, Extraversion, and Neuroticism. Participants were then asked to complete multiple procedural learning tasks in each interface. Results demonstrated that all three measures predicted completion times. Additionally, results analyses demonstrated personality factors also predicted the number of insights participants reported while completing the tasks in each interface. We discuss how these findings advance our ongoing research in the Personal Equation of Interaction.\\\",\\\"Authors\\\":\\\"Green, T.M.;Fisher, B.\\\",\\\"Clusters\\\":\\\"Cognition;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/VAST.2010.5653587\\\",\\\"Keywords\\\":\\\"cognition and perception theory;embodied cognition;visualization taxonomies and models;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"visualization taxonomy and model;visual analytic;embody cognition;cognition and perception theory\\\",\\\"Title\\\":\\\"Towards the Personal Equation of Interaction: The impact of personality factors on visual analytics interface interaction\\\"},\\\"570\\\":{\\\"Abstract\\\":\\\"A common goal in graph visualization research is the design of novel techniques for displaying an overview of an entire graph. However, there are many situations where such an overview is not relevant or practical for users, as analyzing the global structure may not be related to the main task of the users that have semi-specific information needs. Furthermore, users accessing large graph databases through an online connection or users running on less powerful (mobile) hardware simply do not have the resources needed to compute these overviews. In this paper, we advocate an interaction model that allows users to remotely browse the immediate context graph around a specific node of interest. We show how Furnas' original degree of interest function can be adapted from trees to graphs and how we can use this metric to extract useful contextual subgraphs, control the complexity of the generated visualization and direct users to interesting datapoints in the context. We demonstrate the effectiveness of our approach with an exploration of a dense online database containing over 3 million legal citations.\\\",\\\"Authors\\\":\\\"van Ham, F.;Perer, A.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;GraphNetworkDataAndTechniques;InteractionTechniquesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.108\\\",\\\"Keywords\\\":\\\"legal citation networks;focus+context;graph visualization;degree of interest;network visualization\\\",\\\"Keywords_Processed\\\":\\\"network visualization;legal citation network;degree of interest;graph visualization;focus context\\\",\\\"Title\\\":\\\"\\\\\\\"Search, Show Context, Expand on Demand\\\\\\\": Supporting Large Graph Exploration with Degree-of-Interest\\\"},\\\"571\\\":{\\\"Abstract\\\":\\\"The research presented in this paper compares user-generated and automatic graph layouts. Following the methods suggested by van Ham et al. (2008), a group of users generated graph layouts using both multi-touch interaction on a tabletop display and mouse interaction on a desktop computer. Users were asked to optimize their layout for aesthetics and analytical tasks with a social network. We discuss characteristics of the user-generated layouts and interaction methods employed by users in this process. We then report on a web-based study to compare these layouts with the output of popular automatic layout algorithms. Our results demonstrate that the best of the user-generated layouts performed as well as or better than the physics-based layout. Orthogonal and circular automatic layouts were found to be considerably less effective than either the physics-based layout or the best of the user-generated layouts. We highlight several attributes of the various layouts that led to high accuracy and improved task completion time, as well as aspects in which traditional automatic layout methods were unsuccessful for our tasks.\\\",\\\"Authors\\\":\\\"Dwyer, T.;Bongshin Lee;Fisher, D.;Quinn, K.I.;Isenberg, P.;Robertson, G.;North, C.\\\",\\\"Clusters\\\":\\\"ArtAndAestheticsInVisualization;AutomaticAnalysisVisualizationTechniques;GraphNetworkDataAndTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.109\\\",\\\"Keywords\\\":\\\"automatic layout algorithms;graph layout;graph drawing aesthetics;network layout;user-generated layout\\\",\\\"Keywords_Processed\\\":\\\"graph layout;user generate layout;graph drawing aesthetic;network layout;automatic layout algorithm\\\",\\\"Title\\\":\\\"A Comparison of User-Generated and Automatic Graph Layouts\\\"},\\\"572\\\":{\\\"Abstract\\\":\\\"During continuous user interaction, it is hard to provide rich visual feedback at interactive rates for datasets containing millions of entries. The contribution of this paper is a generic architecture that ensures responsiveness of the application even when dealing with large data and that is applicable to most types of information visualizations. Our architecture builds on the separation of the main application thread and the visualization thread, which can be cancelled early due to user interaction. In combination with a layer mechanism, our architecture facilitates generating previews incrementally to provide rich visual feedback quickly. To help avoiding common pitfalls of multi-threading, we discuss synchronization and communication in detail. We explicitly denote design choices to control trade-offs. A quantitative evaluation based on the system VI S P L ORE shows fast visual feedback during continuous interaction even for millions of entries. We describe instantiations of our architecture in additional tools.\\\",\\\"Authors\\\":\\\"Piringer, H.;Tominski, C.;Muigg, P.;Berger, W.\\\",\\\"Clusters\\\":\\\"InteractionTechniquesGeneral;ParallelSystemsAndParallelProcessing;VisualEncodingAndLayoutGeneral;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.110\\\",\\\"Keywords\\\":\\\"multi-threading;layer;preview;information visualization architecture;continuous interaction\\\",\\\"Keywords_Processed\\\":\\\"information visualization architecture;multi threading;continuous interaction;preview;layer\\\",\\\"Title\\\":\\\"A Multi-Threading Architecture to Support Interactive Visual Exploration\\\"},\\\"573\\\":{\\\"Abstract\\\":\\\"We present a nested model for the visualization design and validation with four layers: characterize the task and data in the vocabulary of the problem domain, abstract into operations and data types, design visual encoding and interaction techniques, and create algorithms to execute techniques efficiently. The output from a level above is input to the level below, bringing attention to the design challenge that an upstream error inevitably cascades to all downstream levels. This model provides prescriptive guidance for determining appropriate evaluation approaches by identifying threats to validity unique to each level. We also provide three recommendations motivated by this model: authors should distinguish between these levels when claiming contributions at more than one of them, authors should explicitly state upstream assumptions at levels above the focus of a paper, and visualization venues should accept more papers on domain characterization.\\\",\\\"Authors\\\":\\\"Munzner, T.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;VisualDesignDesignGuidelines;VisualizationSystemsToolkitsAndEnvironments;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.111\\\",\\\"Keywords\\\":\\\"model;design;evaluation;framework\\\",\\\"Keywords_Processed\\\":\\\"model;framework;design;evaluation\\\",\\\"Title\\\":\\\"A Nested Model for Visualization Design and Validation\\\"},\\\"574\\\":{\\\"Abstract\\\":\\\"One bottleneck in large-scale genome sequencing projects is reconstructing the full genome sequence from the short subsequences produced by current technologies. The final stages of the genome assembly process inevitably require manual inspection of data inconsistencies and could be greatly aided by visualization. This paper presents our design decisions in translating key data features identified through discussions with analysts into a concise visual encoding. Current visualization tools in this domain focus on local sequence errors making high-level inspection of the assembly difficult if not impossible. We present a novel interactive graph display, ABySS-Explorer, that emphasizes the global assembly structure while also integrating salient data features such as sequence length. Our tool replaces manual and in some cases pen-and-paper based analysis tasks, and we discuss how user feedback was incorporated into iterative design refinements. Finally, we touch on applications of this representation not initially considered in our design phase, suggesting the generality of this encoding for DNA sequence data.\\\",\\\"Authors\\\":\\\"Nielsen, C.B.;Jackman, S.D.;Birol, I.;Jones, S.J.M.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;DesignStudiesAndCaseStudies;Genetics\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.116\\\",\\\"Keywords\\\":\\\"dna sequence;design study;bioinformatics visualization;genome assembly\\\",\\\"Keywords_Processed\\\":\\\"dna sequence;design study;genome assembly;bioinformatic visualization\\\",\\\"Title\\\":\\\"ABySS-Explorer: Visualizing Genome Sequence Assemblies\\\"},\\\"575\\\":{\\\"Abstract\\\":\\\"The identification of significant sequences in large and complex event-based temporal data is a challenging problem with applications in many areas of today's information intensive society. Pure visual representations can be used for the analysis, but are constrained to small data sets. Algorithmic search mechanisms used for larger data sets become expensive as the data size increases and typically focus on frequency of occurrence to reduce the computational complexity, often overlooking important infrequent sequences and outliers. In this paper we introduce an interactive visual data mining approach based on an adaptation of techniques developed for Web searching, combined with an intuitive visual interface, to facilitate user-centred exploration of the data and identification of sequences significant to that user. The search algorithm used in the exploration executes in negligible time, even for large data, and so no pre-processing of the selected data is required, making this a completely interactive experience for the user. Our particular application area is social science diary data but the technique is applicable across many other disciplines.\\\",\\\"Authors\\\":\\\"Vrotsou, K.;Johansson, J.;Cooper, M.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;ComparisonComparativeVisualizationAndSimilarity;EventsTrendsOutlierDetectionAnalysisAndVisualization;TextDocumentTopicAnalysisDataAndTechniques;VisualPatternFeatureDetectionAndTracking\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.117\\\",\\\"Keywords\\\":\\\"node similarity;sequence identification;graph similarity;interactive visual exploration;event-based data\\\",\\\"Keywords_Processed\\\":\\\"sequence identification;node similarity;interactive visual exploration;graph similarity;event base datum\\\",\\\"Title\\\":\\\"ActiviTree: Interactive Visual Exploration of Sequences in Event-Based Data Using Graph Similarity\\\"},\\\"576\\\":{\\\"Abstract\\\":\\\"While many data sets contain multiple relationships, depicting more than one data relationship within a single visualization is challenging. We introduce Bubble Sets as a visualization technique for data that has both a primary data relation with a semantically significant spatial organization and a significant set membership relation in which members of the same set are not necessarily adjacent in the primary layout. In order to maintain the spatial rights of the primary data relation, we avoid layout adjustment techniques that improve set cluster continuity and density. Instead, we use a continuous, possibly concave, isocontour to delineate set membership, without disrupting the primary layout. Optimizations minimize cluster overlap and provide for calculation of the isocontours at interactive speeds. Case studies show how this technique can be used to indicate multiple sets on a variety of common visualizations.\\\",\\\"Authors\\\":\\\"Collins, C.;Penn, G.;Carpendale, S.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;GraphNetworkDataAndTechniques;HierarchicalTreeDataAndTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.122\\\",\\\"Keywords\\\":\\\"spatial layout;clustering;tree visualization;graph visualization\\\",\\\"Keywords_Processed\\\":\\\"spatial layout;tree visualization;graph visualization;clustering\\\",\\\"Title\\\":\\\"Bubble Sets: Revealing Set Relations with Isocontours over Existing Visualizations\\\"},\\\"577\\\":{\\\"Abstract\\\":\\\"Spatialization displays use a geographic metaphor to arrange non-spatial data. For example, spatializations are commonly applied to document collections so that document themes appear as geographic features such as hills. Many common spatialization interfaces use a 3-D landscape metaphor to present data. However, it is not clear whether 3-D spatializations afford improved speed and accuracy for user tasks compared to similar 2-D spatializations. We describe a user study comparing users' ability to remember dot displays, 2-D landscapes, and 3-D landscapes for two different data densities (500 vs. 1000 points). Participants' visual memory was statistically more accurate when viewing dot displays and 3-D landscapes compared to 2-D landscapes. Furthermore, accuracy remembering a spatialization was significantly better overall for denser spatializations. Theseresults are of benefit to visualization designers who are contemplating the best ways to present data using spatialization techniques.\\\",\\\"Authors\\\":\\\"Tory, M.;Swindells, C.;Dreezer, R.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;GeographyGeospatialVisCartographyTerrainVis;HumanComputerInteractionHumanFactors;SoftwareVisualization;UserInterfacesGeneral;VisualDesignDesignGuidelines\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.127\\\",\\\"Keywords\\\":\\\"information interfaces and presentation;software psychology;landscape visualization;evaluation methodology;user / machine systems;screen design\\\",\\\"Keywords_Processed\\\":\\\"software psychology;evaluation methodology;landscape visualization;information interface and presentation;screen design;user machine system\\\",\\\"Title\\\":\\\"Comparing Dot and Landscape Spatializations for Visual Memory Differences\\\"},\\\"578\\\":{\\\"Abstract\\\":\\\"We explore the effects of selecting alternative layouts in hierarchical displays that show multiple aspects of large multivariate datasets, including spatial and temporal characteristics. Hierarchical displays of this type condition a dataset by multiple discrete variable values, creating nested graphical summaries of the resulting subsets in which size, shape and colour can be used to show subset properties. These 'small multiples' are ordered by the conditioning variable values and are laid out hierarchically using dimensional stacking. Crucially, we consider the use of different layouts at different hierarchical levels, so that the coordinates of the plane can be used more effectively to draw attention to trends and anomalies in the data. We argue that these layouts should be informed by the type of conditioning variable and by the research question being explored. We focus on space-filling rectangular layouts that provide data-dense and rich overviews of data to address research questions posed in our exploratory analysis of spatial and temporal aspects of property sales in London. We develop a notation ('HiVE') that describes visualisation and layout states and provides reconfiguration operators, demonstrate its use for reconfiguring layouts to pursue research questions and provide guidelines for this process. We demonstrate how layouts can be related through animated transitions to reduce the cognitive load associated with their reconfiguration whilst supporting the exploratory process.\\\",\\\"Authors\\\":\\\"Slingsby, A.;Dykes, J.;Wood, J.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;GeographyGeospatialVisCartographyTerrainVis;HierarchicalTreeDataAndTechniques;VisualDesignDesignGuidelines;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.128\\\",\\\"Keywords\\\":\\\"notation;hierarchical;layout;guidelines;exploratory;geovisualization\\\",\\\"Keywords_Processed\\\":\\\"guideline;notation;exploratory;layout;geovisualization;hierarchical\\\",\\\"Title\\\":\\\"Configuring Hierarchical Layouts to Address Research Questions\\\"},\\\"579\\\":{\\\"Abstract\\\":\\\"Visual exploration of multidimensional data is a process of isolating and extracting relationships within and between dimensions. Coordinated multiple view approaches are particularly effective for visual exploration because they support precise expression of heterogeneous multidimensional queries using simple interactions. Recent visual analytics research has made significant progress in identifying and understanding patterns of composed views and coordinations that support fast, flexible, and open-ended data exploration. What is missing is formalization of the space of expressible queries in terms of visual representation and interaction. This paper introduces the conjunctive visual form model in which visual exploration consists of interactively-driven sequences of transitions between visual states that correspond to conjunctive normal forms in boolean logic. The model predicts several new and useful ways to extend the space of rapidly expressible queries through addition of simple interactive capabilities to existing compositional patterns. Two recent related visual tools offer a subset of these capabilities, providing a basis for conjecturing about such extensions.\\\",\\\"Authors\\\":\\\"Weaver, C.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;AnalysisProcessGeneral;InteractionTechniquesGeneral;MultipleLinkedCoordinatedViews;NumericalMethodsMathematics;QueriesAndSearch\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.129\\\",\\\"Keywords\\\":\\\"exploratory visualization;brushing;multiple views;boolean query;conjunctive normal form;visual abstraction\\\",\\\"Keywords_Processed\\\":\\\"visual abstraction;brush;conjunctive normal form;exploratory visualization;multiple view;boolean query\\\",\\\"Title\\\":\\\"Conjunctive Visual Forms\\\"},\\\"580\\\":{\\\"Abstract\\\":\\\"A dendrogram that visualizes a clustering hierarchy is often integrated with a re-orderable matrix for pattern identification. The method is widely used in many research fields including biology, geography, statistics, and data mining. However, most dendrograms do not scale up well, particularly with respect to problems of graphical and cognitive information overload. This research proposes a strategy that links an overview dendrogram and a detail-view dendrogram, each integrated with a re-orderable matrix. The overview displays only a user-controlled, limited number of nodes that represent the ldquoskeletonrdquo of a hierarchy. The detail view displays the sub-tree represented by a selected meta-node in the overview. The research presented here focuses on constructing a concise overview dendrogram and its coordination with a detail view. The proposed method has the following benefits: dramatic alleviation of information overload, enhanced scalability and data abstraction quality on the dendrogram, and the support of data exploration at arbitrary levels of detail. The contribution of the paper includes a new metric to measure the ldquoimportancerdquo of nodes in a dendrogram; the method to construct the concise overview dendrogram from the dynamically-identified, important nodes; and measure for evaluating the data abstraction quality for dendrograms. We evaluate and compare the proposed method to some related existing methods, and demonstrating how the proposed method can help users find interesting patterns through a case study on county-level U.S. cervical cancer mortality and demographic data.\\\",\\\"Authors\\\":\\\"Jin Chen;MacEachren, A.M.;Peuquet, D.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;EvaluationMetricsAndBenchmarks;GraphNetworkDataAndTechniques;HierarchicalTreeDataAndTechniques;MatrixRelatedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.130\\\",\\\"Keywords\\\":\\\"reorderable matrix;hierarchical clusters;dendrogram;compound graphs;data abstraction quality metrics\\\",\\\"Keywords_Processed\\\":\\\"datum abstraction quality metric;dendrogram;reorderable matrix;compound graph;hierarchical cluster\\\",\\\"Title\\\":\\\"Constructing Overview + Detail Dendrogram-Matrix Views\\\"},\\\"581\\\":{\\\"Abstract\\\":\\\"With the rapid growth of the World Wide Web and electronic information services, text corpus is becoming available online at an incredible rate. By displaying text data in a logical layout (e.g., color graphs), text visualization presents a direct way to observe the documents as well as understand the relationship between them. In this paper, we propose a novel technique, Exemplar-based visualization (EV), to visualize an extremely large text corpus. Capitalizing on recent advances in matrix approximation and decomposition, EV presents a probabilistic multidimensional projection model in the low-rank text subspace with a sound objective function. The probability of each document proportion to the topics is obtained through iterative optimization and embedded to a low dimensional space using parameter embedding. By selecting the representative exemplars, we obtain a compact approximation of the data. This makes the visualization highly efficient and flexible. In addition, the selected exemplars neatly summarize the entire data set and greatly reduce the cognitive overload in the visualization, leading to an easier interpretation of large text corpus. Empirically, we demonstrate the superior performance of EV through extensive experiments performed on the publicly available text data sets.\\\",\\\"Authors\\\":\\\"Yanhua Chen;Lijun Wang;Ming Dong;Jing Hua\\\",\\\"Clusters\\\":\\\"DimensionalityReduction;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.140\\\",\\\"Keywords\\\":\\\"exemplar;multi-dimensional projection;large-scale document visualization\\\",\\\"Keywords_Processed\\\":\\\"multi dimensional projection;large scale document visualization;exemplar\\\",\\\"Title\\\":\\\"Exemplar-based Visualization of Large Document Corpus\\\"},\\\"582\\\":{\\\"Abstract\\\":\\\"Spatial interactions (or flows), such as population migration and disease spread, naturally form a weighted location-to-location network (graph). Such geographically embedded networks (graphs) are usually very large. For example, the county-to-county migration data in the U.S. has thousands of counties and about a million migration paths. Moreover, many variables are associated with each flow, such as the number of migrants for different age groups, income levels, and occupations. It is a challenging task to visualize such data and discover network structures, multivariate relations, and their geographic patterns simultaneously. This paper addresses these challenges by developing an integrated interactive visualization framework that consists three coupled components: (1) a spatially constrained graph partitioning method that can construct a hierarchy of geographical regions (communities), where there are more flows or connections within regions than across regions; (2) a multivariate clustering and visualization method to detect and present multivariate patterns in the aggregated region-to-region flows; and (3) a highly interactive flow mapping component to map both flow and multivariate patterns in the geographic space, at different hierarchical levels. The proposed approach can process relatively large data sets and effectively discover and visualize major flow structures and multivariate relations at the same time. User interactions are supported to facilitate the understanding of both an overview and detailed patterns.\\\",\\\"Authors\\\":\\\"Diansheng Guo\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;DatabasesAndDataMining;FlowVisualizationDataAndTechniques;InteractionTechniquesGeneral;MultidimensionalMultivariateMultifieldDataAndTechniques;MultipleLinkedCoordinatedViews\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.143\\\",\\\"Keywords\\\":\\\"graph partitioning;data mining;hierarchical clustering;multi-dimensional visualization;contiguity constraints;flow mapping;spatial interaction;coordinated views\\\",\\\"Keywords_Processed\\\":\\\"graph partitioning;multi dimensional visualization;flow mapping;hierarchical clustering;contiguity constraint;spatial interaction;datum mining;coordinated view\\\",\\\"Title\\\":\\\"Flow Mapping and Multivariate Visualization of Large Spatial Interaction Data\\\"},\\\"583\\\":{\\\"Abstract\\\":\\\"When displaying thousands of aircraft trajectories on a screen, the visualization is spoiled by a tangle of trails. The visual analysis is therefore difficult, especially if a specific class of trajectories in an erroneous dataset has to be studied. We designed FromDaDy, a trajectory visualization tool that tackles the difficulties of exploring the visualization of multiple trails. This multidimensional data exploration is based on scatterplots, brushing, pick and drop, juxtaposed views and rapid visual design. Users can organize the workspace composed of multiple juxtaposed views. They can define the visual configuration of the views by connecting data dimensions from the dataset to Bertin's visual variables. They can then brush trajectories, and with a pick and drop operation they can spread the brushed information across views. They can then repeat these interactions, until they extract a set of relevant data, thus formulating complex queries. Through two real-world scenarios, we show how FromDaDy supports iterative queries and the extraction of trajectories in a dataset that contains up to 5 million data.\\\",\\\"Authors\\\":\\\"Hurter, C.;Tissoires, B.;Conversy, S.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;AnimationAndMotion;InteractionTechniquesGeneral;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.145\\\",\\\"Keywords\\\":\\\"visualization;trajectory;iterative exploration;direct manipulation\\\",\\\"Keywords_Processed\\\":\\\"visualization;direct manipulation;trajectory;iterative exploration\\\",\\\"Title\\\":\\\"FromDaDy: Spreading Aircraft Trajectories Across Views to Support Iterative Queries\\\"},\\\"584\\\":{\\\"Abstract\\\":\\\"A widespread use of high-throughput gene expression analysis techniques enabled the biomedical research community to share a huge body of gene expression datasets in many public databases on the web. However, current gene expression data repositories provide static representations of the data and support limited interactions. This hinders biologists from effectively exploring shared gene expression datasets. Responding to the growing need for better interfaces to improve the utility of the public datasets, we have designed and developed a new web-based visual interface entitled GeneShelf (http://bioinformatics.cnmcresearch.org/GeneShelf). It builds upon a zoomable grid display to represent two categorical dimensions. It also incorporates an augmented timeline with expandable time points that better shows multiple data values for the focused time point by embedding bar charts. We applied GeneShelf to one of the largest microarray datasets generated to study the progression and recovery process of injuries at the spinal cord of mice and rats. We present a case study and a preliminary qualitative user study with biologists to show the utility and usability of GeneShelf.\\\",\\\"Authors\\\":\\\"Bohyoung Kim;Bongshin Lee;Knoblach, S.;Hoffman, E.;Jinwook Seo\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;BiologyAndBioinformatics;Genetics;MeshesGridsAndLattices;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.146\\\",\\\"Keywords\\\":\\\"gene expression profiling;augmented timeline;bioinformatics visualization;animation;zoomable grid\\\",\\\"Keywords_Processed\\\":\\\"gene expression profiling;bioinformatic visualization;animation;augment timeline;zoomable grid\\\",\\\"Title\\\":\\\"GeneShelf: A Web-based Visual Interface for Large Gene Expression Time-Series Data Repositories\\\"},\\\"585\\\":{\\\"Abstract\\\":\\\"We describe the design and deployment of Dashiki, a public Website where users may collaboratively build visualization dashboards through a combination of a wiki-like syntax and interactive editors. Our goals are to extend existing research on social data analysis into presentation and organization of data from multiple sources, explore new metaphors for these activities, and participate more fully in the Web's information ecology by providing tighter integration with real-time data. To support these goals, our design includes novel and low-barrier mechanisms for editing and layout of dashboard pages and visualizations, connection to data sources, and coordinating interaction between visualizations. In addition to describing these technologies, we provide a preliminary report on the public launch of a prototype based on this design, including a description of the activities of our users derived from observation and interviews.\\\",\\\"Authors\\\":\\\"McKeon, M.\\\",\\\"Clusters\\\":\\\"CollaborativeVisualization;InternetWebVisualizationForTheMasses;SocialNetworksAndSocialMedia;UserInterfacesGeneral;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.148\\\",\\\"Keywords\\\":\\\"wiki;collaboration;visualization;visual analytics;dashboards;social data analysis;social software;world wide web\\\",\\\"Keywords_Processed\\\":\\\"visualization;social software;world wide web;collaboration;visual analytic;social datum analysis;wiki;dashboard\\\",\\\"Title\\\":\\\"Harnessing the Information Ecosystem with Wiki-based Visualization Dashboards\\\"},\\\"586\\\":{\\\"Abstract\\\":\\\"We present a novel and extensible set of interaction techniques for manipulating visualizations of networks by selecting subgraphs and then applying various commands to modify their layout or graphical properties. Our techniques integrate traditional rectangle and lasso selection, and also support selecting a node's neighbourhood by dragging out its radius (in edges) using a novel kind of radial menu. Commands for translation, rotation, scaling, or modifying graphical properties (such as opacity) and layout patterns can be performed by using a hotbox (a transiently popped-up, semi-transparent set of widgets) that has been extended in novel ways to integrate specification of commands with 1D or 2D arguments. Our techniques require only one mouse button and one keyboard key, and are designed for fast, gestural, in-place interaction. We present the design and integration of these interaction techniques, and illustrate their use in interactive graph visualization. Our techniques are implemented in NAViGaTOR, a software package for visualizing and analyzing biological networks. An initial usability study is also reported.\\\",\\\"Authors\\\":\\\"McGuffin, M.J.;Jurisica, I.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;GraphNetworkDataAndTechniques;InteractionTechniquesGeneral;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.151\\\",\\\"Keywords\\\":\\\"hotbox;interactive graph drawing;marking menus;radial menus;biological networks;network layout\\\",\\\"Keywords_Processed\\\":\\\"hotbox;biological network;radial menu;mark menu;network layout;interactive graph drawing\\\",\\\"Title\\\":\\\"Interaction Techniques for Selecting and Manipulating Subgraphs in Network Visualizations\\\"},\\\"587\\\":{\\\"Abstract\\\":\\\"Multivariate data sets including hundreds of variables are increasingly common in many application areas. Most multivariate visualization techniques are unable to display such data effectively, and a common approach is to employ dimensionality reduction prior to visualization. Most existing dimensionality reduction systems focus on preserving one or a few significant structures in data. For many analysis tasks, however, several types of structures can be of high significance and the importance of a certain structure compared to the importance of another is often task-dependent. This paper introduces a system for dimensionality reduction by combining user-defined quality metrics using weight functions to preserve as many important structures as possible. The system aims at effective visualization and exploration of structures within large multivariate data sets and provides enhancement of diverse structures by supplying a range of automatic variable orderings. Furthermore it enables a quality-guided reduction of variables through an interactive display facilitating investigation of trade-offs between loss of structure and the number of variables to keep. The generality and interactivity of the system is demonstrated through a case scenario.\\\",\\\"Authors\\\":\\\"Johansson, S.;Johansson, J.\\\",\\\"Clusters\\\":\\\"DataAndAnalysisMetrics;DimensionalityReduction;InteractionTechniquesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.153\\\",\\\"Keywords\\\":\\\"dimension reduction;quality metrics;variable ordering;interactivity\\\",\\\"Keywords_Processed\\\":\\\"variable ordering;quality metric;interactivity;dimension reduction\\\",\\\"Title\\\":\\\"Interactive Dimensionality Reduction Through User-defined Combinations of Quality Metrics\\\"},\\\"588\\\":{\\\"Abstract\\\":\\\"Large multi-touch displays are expanding the possibilities of multiple-coordinated views by allowing multiple people to interact with data in concert or independently. We present Lark, a system that facilitates the coordination of interactions with information visualizations on shared digital workspaces. We focus on supporting this coordination according to four main criteria: scoped interaction, temporal flexibility, spatial flexibility, and changing collaboration styles. These are achieved by integrating a representation of the information visualization pipeline into the shared workspace, thus explicitly indicating coordination points on data, representation, presentation, and view levels. This integrated meta-visualization supports both the awareness of how views are linked and the freedom to work in concert or independently. Lark incorporates these four main criteria into a coherent visualization collaboration interaction environment by providing direct visual and algorithmic support for the coordination of data analysis actions over shared large displays.\\\",\\\"Authors\\\":\\\"Tobiasz, M.;Isenberg, P.;Carpendale, S.\\\",\\\"Clusters\\\":\\\"CollaborativeVisualization;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.162\\\",\\\"Keywords\\\":\\\"information visualization;coordination;workspace awareness;collaboration;meta-visualization;co-located work\\\",\\\"Keywords_Processed\\\":\\\"meta visualization;collaboration;information visualization;coordination;workspace awareness;co locate work\\\",\\\"Title\\\":\\\"Lark: Coordinating Co-located Collaboration with Information Visualization\\\"},\\\"589\\\":{\\\"Abstract\\\":\\\"We present a new technique, the phrase net, for generating visual overviews of unstructured text. A phrase net displays a graph whose nodes are words and whose edges indicate that two words are linked by a user-specified relation. These relations may be defined either at the syntactic or lexical level; different relations often produce very different perspectives on the same text. Taken together, these perspectives often provide an illuminating visual overview of the key concepts and relations in a document or set of documents.\\\",\\\"Authors\\\":\\\"van Ham, F.;Wattenberg, M.;Viegas, F.B.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;TextDocumentTopicAnalysisDataAndTechniques;VisualKnowledgeRepresentationAndExternalization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.165\\\",\\\"Keywords\\\":\\\"semantic net;natural language processing;tag clouds;text visualization\\\",\\\"Keywords_Processed\\\":\\\"semantic net;text visualization;tag cloud;natural language processing\\\",\\\"Title\\\":\\\"Mapping Text with Phrase Nets\\\"},\\\"590\\\":{\\\"Abstract\\\":\\\"In the field of comparative genomics, scientists seek to answer questions about evolution and genomic function by comparing the genomes of species to find regions of shared sequences. Conserve dsyntenic blocks are an important biological data abstraction for indicating regions of shared sequences. The goal of this work is to show multiple types of relationships at multiple scales in a way that is visually comprehensible in accordance with known perceptual principles. We present a task analysis for this domain where the fundamental questions asked by biologists can be understood by a characterization of relationships into the four types of proximity/location, size, orientation, and similarity/strength, and the four scales of genome, chromosome, block, and genomic feature. We also propose a new taxonomy of the design space for visually encoding conservation data. We present MizBee, a multiscale synteny browser with the unique property of providing interactive side-by-side views of the data across the range of scales supporting exploration of all of these relationship types. We conclude with case studies from two biologists who used MizBee to augment their previous automatic analysis work flow, providing anecdotal evidence about the efficacy of the system for the visualization of syntenic data, the analysis of conservation relationships, and the communication of scientific insights.\\\",\\\"Authors\\\":\\\"Meyer, M.;Munzner, T.;Pfister, H.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;DesignStudiesAndCaseStudies;Genetics;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.167\\\",\\\"Keywords\\\":\\\"information visualization;design study;synteny;bioinformatics\\\",\\\"Keywords_Processed\\\":\\\"synteny;design study;information visualization;bioinformatic\\\",\\\"Title\\\":\\\"MizBee: A Multiscale Synteny Browser\\\"},\\\"591\\\":{\\\"Abstract\\\":\\\"We discuss the design and usage of ldquoWordle,rdquo a Web-based tool for visualizing text. Wordle creates tag-cloud-like displays that give careful attention to typography, color, and composition. We describe the algorithms used to balance various aesthetic criteria and create the distinctive Wordle layouts. We then present the results of a study of Wordle usage, based both on spontaneous behaviour observed in the wild, and on a large-scale survey of Wordle users. The results suggest that Wordles have become a kind of medium of expression, and that a ldquoparticipatory culturerdquo has arisen around them.\\\",\\\"Authors\\\":\\\"Viegas, F.B.;Wattenberg, M.;Feinberg, J.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;Cognition;Education;SocialNetworksAndSocialMedia;SocialScienceAndHumanities;TextDocumentTopicAnalysisDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.171\\\",\\\"Keywords\\\":\\\"participatory culture;memory;educational visualization;text;visualization;tag clouds;social data analysis\\\",\\\"Keywords_Processed\\\":\\\"visualization;educational visualization;memory;social datum analysis;text;tag cloud;participatory culture\\\",\\\"Title\\\":\\\"Participatory Visualization with Wordle\\\"},\\\"592\\\":{\\\"Abstract\\\":\\\"Despite myriad tools for visualizing data, there remains a gap between the notational efficiency of high-level visualization systems and the expressiveness and accessibility of low-level graphical systems. Powerful visualization systems may be inflexible or impose abstractions foreign to visual thinking, while graphical systems such as rendering APIs and vector-based drawing programs are tedious for complex work. We argue that an easy-to-use graphical system tailored for visualization is needed. In response, we contribute Protovis, an extensible toolkit for constructing visualizations by composing simple graphical primitives. In Protovis, designers specify visualizations as a hierarchy of marks with visual properties defined as functions of data. This representation achieves a level of expressiveness comparable to low-level graphics systems, while improving efficiency - the effort required to specify a visualization - and accessibility - the effort required to learn and modify the representation. We substantiate this claim through a diverse collection of examples and comparative analysis with popular visualization tools.\\\",\\\"Authors\\\":\\\"Bostock, M.;Heer, J.\\\",\\\"Clusters\\\":\\\";UserInterfacesGeneral;VisualizationSystemsToolkitsAndEnvironments;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.174\\\",\\\"Keywords\\\":\\\"information visualization;toolkits;2d graphics;user interface\\\",\\\"Keywords_Processed\\\":\\\"toolkit;user interface;information visualization;2d graphic\\\",\\\"Title\\\":\\\"Protovis: A Graphical Toolkit for Visualization\\\"},\\\"593\\\":{\\\"Abstract\\\":\\\"Hierarchical representations are common in digital repositories, yet are not always fully leveraged in their online search interfaces. This work describes ResultMaps, which use hierarchical treemap representations with query string-driven digital library search engines. We describe two lab experiments, which find that ResultsMap users yield significantly better results over a control condition on some subjective measures, and we find evidence that ResultMaps have ancillary benefits via increased understanding of some aspects of repository content. The ResultMap system and experiments contribute an understanding of the benefits-direct and indirect-of the ResultMap approach to repository search visualization.\\\",\\\"Authors\\\":\\\"Clarkson, E.;Desai, K.;Foley, J.D.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;EvaluationGeneral;HierarchicalTreeDataAndTechniques;QueriesAndSearch;TextDocumentTopicAnalysisDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.176\\\",\\\"Keywords\\\":\\\"information visualization;user study;digital repository;digital library;treemap;search visualization;search engine;evaluation\\\",\\\"Keywords_Processed\\\":\\\"user study;treemap;search engine;digital library;information visualization;search visualization;digital repository;evaluation\\\",\\\"Title\\\":\\\"ResultMaps: Visualization for Search Interfaces\\\"},\\\"594\\\":{\\\"Abstract\\\":\\\"In this paper, we present a novel parallel coordinates design integrated with points (scattering points in parallel coordinates, SPPC), by taking advantage of both parallel coordinates and scatterplots. Different from most multiple views visualization frameworks involving parallel coordinates where each visualization type occupies an individual window, we convert two selected neighboring coordinate axes into a scatterplot directly. Multidimensional scaling is adopted to allow converting multiple axes into a single subplot. The transition between two visual types is designed in a seamless way. In our work, a series of interaction tools has been developed. Uniform brushing functionality is implemented to allow the user to perform data selection on both points and parallel coordinate polylines without explicitly switching tools. A GPU accelerated dimensional incremental multidimensional scaling (DIMDS) has been developed to significantly improve the system performance. Our case study shows that our scheme is more efficient than traditional multi-view methods in performing visual analysis tasks.\\\",\\\"Authors\\\":\\\"Xiaoru Yuan;Peihong Guo;He Xiao;Hong Zhou;Huamin Qu\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;DimensionalityReduction;ParallelCoordinates;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.179\\\",\\\"Keywords\\\":\\\"multi-dimensional scaling;information visualization;scatterplot;parallel coordinates\\\",\\\"Keywords_Processed\\\":\\\"parallel coordinate;information visualization;scatterplot;multi dimensional scaling\\\",\\\"Title\\\":\\\"Scattering Points in Parallel Coordinates\\\"},\\\"595\\\":{\\\"Abstract\\\":\\\"We present a case study of our experience designing SellTrend, a visualization system for analyzing airline travel purchase requests. The relevant transaction data can be characterized as multi-variate temporal and categorical event sequences, and the chief problem addressed is how to help company analysts identify complex combinations of transaction attributes that contribute to failed purchase requests. SellTrend combines a diverse set of techniques ranging from time series visualization to faceted browsing and historical trend analysis in order to help analysts make sense of the data. We believe that the combination of views and interaction capabilities in SellTrend provides an innovative approach to this problem and to other similar types of multivariate, temporally driven transaction data analysis. Initial feedback from company analysts confirms the utility and benefits of the system.\\\",\\\"Authors\\\":\\\"Zhicheng Liu;Stasko, J.;Sullivan, T.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;BusinessFinanceEconomyManufacturing;CategoricalDataAndTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;MultipleLinkedCoordinatedViews;TimeseriesTimeVaryingDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.180\\\",\\\"Keywords\\\":\\\"information visualization;categorical data;multiple attributes;time-series data;multiple views;investigative analysis;transaction analysis\\\",\\\"Keywords_Processed\\\":\\\"investigative analysis;information visualization;multiple view;multiple attribute;transaction analysis;time series datum;categorical datum\\\",\\\"Title\\\":\\\"SellTrend: Inter-Attribute Visual Analysis of Temporal Transaction Data\\\"},\\\"596\\\":{\\\"Abstract\\\":\\\"In this paper, we present a new visual way of exploring state sequences in large observational time-series. A key advantage of our method is that it can directly visualize higher-order state transitions. A standard first order state transition is a sequence of two states that are linked by a transition. A higher-order state transition is a sequence of three or more states where the sequence of participating states are linked together by consecutive first order state transitions. Our method extends the current state-graph exploration methods by employing a two dimensional graph, in which higher-order state transitions are visualized as curved lines. All transitions are bundled into thick splines, so that the thickness of an edge represents the frequency of instances. The bundling between two states takes into account the state transitions before and after the transition. This is done in such a way that it forms a continuous representation in which any subsequence of the timeseries is represented by a continuous smooth line. The edge bundles in these graphs can be explored interactively through our incremental selection algorithm. We demonstrate our method with an application in exploring labeled time-series data from a biological survey, where a clustering has assigned a single label to the data at each time-point. In these sequences, a large number of cyclic patterns occur, which in turn are linked to specific activities. We demonstrate how our method helps to find these cycles, and how the interactive selection process helps to find and investigate activities.\\\",\\\"Authors\\\":\\\"Blaas, J.;Botha, C.P.;Grundy, E.;Jones, M.;Laramee, R.S.;Post, F.H.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;GraphNetworkDataAndTechniques;StateRelatedDataTechniques;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.181\\\",\\\"Keywords\\\":\\\"state transitions;time-series;biological data;graph drawing\\\",\\\"Keywords_Processed\\\":\\\"graph drawing;biological datum;time series;state transition\\\",\\\"Title\\\":\\\"Smooth Graphs for Visual Exploration of Higher-Order State Transitions\\\"},\\\"597\\\":{\\\"Abstract\\\":\\\"Spatiotemporal analysis of sensor logs is a challenging research field due to three facts: a) traditional two-dimensional maps do not support multiple events to occur at the same spatial location, b) three-dimensional solutions introduce ambiguity and are hard to navigate, and c) map distortions to solve the overlap problem are unfamiliar to most users. This paper introduces a novel approach to represent spatial data changing over time by plotting a number of non-overlapping pixels, close to the sensor positions in a map. Thereby, we encode the amount of time that a subject spent at a particular sensor to the number of plotted pixels. Color is used in a twofold manner; while distinct colors distinguish between sensor nodes in different regions, the colors' intensity is used as an indicator to the temporal property of the subjects' activity. The resulting visualization technique, called growth ring maps, enables users to find similarities and extract patterns of interest in spatiotemporal data by using humans' perceptual abilities. We demonstrate the newly introduced technique on a dataset that shows the behavior of healthy and Alzheimer transgenic, male and female mice. We motivate the new technique by showing that the temporal analysis based on hierarchical clustering and the spatial analysis based on transition matrices only reveal limited results. Results and findings are cross-validated using multidimensional scaling. While the focus of this paper is to apply our visualization for monitoring animal behavior, the technique is also applicable for analyzing data, such as packet tracing, geographic monitoring of sales development, or mobile phone capacity planning.\\\",\\\"Authors\\\":\\\"Bak, P.;Mansmann, F.;Janetzko, H.;Keim, D.A.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;PixelOrientedEncodings;SpatiotemporalDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.182\\\",\\\"Keywords\\\":\\\"dense pixel displays;animal behavior;spatio-temporal visualization;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;spatio temporal visualization;dense pixel display;animal behavior\\\",\\\"Title\\\":\\\"Spatiotemporal Analysis of Sensor Logs using Growth Ring Maps\\\"},\\\"598\\\":{\\\"Abstract\\\":\\\"Trees and graphs are relevant to many online tasks such as visualizing social networks, product catalogs, educational portals, digital libraries, the semantic web, concept maps and personalized information management. SpicyNodes is an information-visualization technology that builds upon existing research on radial tree layouts and graph structures. Users can browse a tree, clicking from node to node, as well as successively viewing a node, immediately related nodes and the path back to the ldquohomerdquo nodes. SpicyNodes' layout algorithms maintain balanced layouts using a hybrid mixture of a geometric layout (a succession of spanning radial trees) and force-directed layouts to minimize overlapping nodes, plus several other improvements over prior art. It provides XML-based API and GUI authoring tools. The goal of the SpicyNodes project is to implement familiar principles of radial maps and focus+context with an attractive and inviting look and feel in an open system that is accessible to virtually any Internet user.\\\",\\\"Authors\\\":\\\"Douma, M.;Ligierko, G.;Ancuta, O.;Gritsai, P.;Liu, S.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;GraphNetworkDataAndTechniques;HierarchicalTreeDataAndTechniques;HumanComputerInteractionHumanFactors;InteractionTechniquesGeneral;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.183\\\",\\\"Keywords\\\":\\\"information visualization;trees and network visualization;hierarchy visualization;focus+context;human-computer interaction;radial tree layout;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;radial tree layout;human computer interaction;hierarchy visualization;tree and network visualization;information visualization;focus context\\\",\\\"Title\\\":\\\"SpicyNodes: Radial Layout Authoring for the General Public\\\"},\\\"599\\\":{\\\"Abstract\\\":\\\"When analyzing thousands of event histories, analysts often want to see the events as an aggregate to detect insights and generate new hypotheses about the data. An analysis tool must emphasize both the prevalence and the temporal ordering of these events. Additionally, the analysis tool must also support flexible comparisons to allow analysts to gather visual evidence. In a previous work, we introduced align, rank, and filter (ARF) to accentuate temporal ordering. In this paper, we present temporal summaries, an interactive visualization technique that highlights the prevalence of event occurrences. Temporal summaries dynamically aggregate events in multiple granularities (year, month, week, day, hour, etc.) for the purpose of spotting trends over time and comparing several groups of records. They provide affordances for analysts to perform temporal range filters. We demonstrate the applicability of this approach in two extensive case studies with analysts who applied temporal summaries to search, filter, and look for patterns in electronic health records and academic records.\\\",\\\"Authors\\\":\\\"Wang, T.D.;Plaisant, C.;Shneiderman, B.;Spring, N.;Roseman, D.;Marchand, G.;Mukherjee, V.;Smith, M.\\\",\\\"Clusters\\\":\\\"DesignMethodologiesAndInteractionDesign;HumanComputerInteractionHumanFactors;TimeseriesTimeVaryingDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.187\\\",\\\"Keywords\\\":\\\"information visualization;temporal categorical visualization;human-computer interaction;interaction design\\\",\\\"Keywords_Processed\\\":\\\"human computer interaction;temporal categorical visualization;information visualization;interaction design\\\",\\\"Title\\\":\\\"Temporal Summaries: Supporting Temporal Categorical Searching, Aggregation and Comparison\\\"},\\\"600\\\":{\\\"Abstract\\\":\\\"A great corpus of studies reports empirical evidence of how information visualization supports comprehension and analysis of data. The benefits of visualization for synchronous group knowledge work, however, have not been addressed extensively. Anecdotal evidence and use cases illustrate the benefits of synchronous collaborative information visualization, but very few empirical studies have rigorously examined the impact of visualization on group knowledge work. We have consequently designed and conducted an experiment in which we have analyzed the impact of visualization on knowledge sharing in situated work groups. Our experimental study consists of evaluating the performance of 131 subjects (all experienced managers) in groups of 5 (for a total of 26 groups), working together on a real-life knowledge sharing task. We compare (1) the control condition (no visualization provided), with two visualization supports: (2) optimal and (3) suboptimal visualization (based on a previous survey). The facilitator of each group was asked to populate the provided interactive visual template with insights from the group, and to organize the contributions according to the group consensus. We have evaluated the results through both objective and subjective measures. Our statistical analysis clearly shows that interactive visualization has a statistically significant, objective and positive impact on the outcomes of knowledge sharing, but that the subjects seem not to be aware of this. In particular, groups supported by visualization achieved higher productivity, higher quality of outcome and greater knowledge gains. No statistically significant results could be found between an optimal and a suboptimal visualization though (as classified by the pre-experiment survey). Subjects also did not seem to be aware of the benefits that the visualizations provided as no difference between the visualization and the control conditions was found for the self-reported measures of satisfaction a- - nd participation. An implication of our study for information visualization applications is to extend them by using real-time group annotation functionalities that aid in the group sense making process of the represented data.\\\",\\\"Authors\\\":\\\"Bresciani, S.;Eppler, M.J.\\\",\\\"Clusters\\\":\\\"CollaborativeVisualization;EvaluationGeneral;LaboratoryStudies;VisualKnowledgeRepresentationAndExternalization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.188\\\",\\\"Keywords\\\":\\\"visual knowledge representation;laboratory studies;collaborative and distributed visualization;group work;experiment;knowledge sharing;synchronous situated collaboration\\\",\\\"Keywords_Processed\\\":\\\"collaborative and distribute visualization;knowledge sharing;visual knowledge representation;laboratory study;synchronous situated collaboration;experiment;group work\\\",\\\"Title\\\":\\\"The Benefits of Synchronous Collaborative Information Visualization: Evidence from an Experimental Evaluation\\\"},\\\"601\\\":{\\\"Abstract\\\":\\\"Modern programmable GPUs represent a vast potential in terms of performance and visual flexibility for information visualization research, but surprisingly few applications even begin to utilize this potential. In this paper, we conjecture that this may be due to the mismatch between the high-level abstract data types commonly visualized in our field, and the low-level floating-point model supported by current GPU shader languages. To help remedy this situation, we present a refinement of the traditional information visualization pipeline that is amenable to implementation using GPU shaders. The refinement consists of a final image-space step in the pipeline where the multivariate data of the visualization is sampled in the resolution of the current view. To concretize the theoretical aspects of this work, we also present a visual programming environment for constructing visualization shaders using a simple drag-and-drop interface. Finally, we give some examples of the use of shaders for well-known visualization techniques.\\\",\\\"Authors\\\":\\\"McDonnel, B.;Elmqvist, N.\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;HardwareAccellerationAndComputationGeneral;InteractionTechniquesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.191\\\",\\\"Keywords\\\":\\\"gpu acceleration;shader programming;high-performance visualization;interaction\\\",\\\"Keywords_Processed\\\":\\\"high performance visualization;shader programming;gpu acceleration;interaction\\\",\\\"Title\\\":\\\"Towards Utilizing GPUs in Information Visualization: A Model and Implementation of Image-Space Operations\\\"},\\\"602\\\":{\\\"Abstract\\\":\\\"In serial computation, program profiling is often helpful for optimization of key sections of code. When moving to parallel computation, not only does the code execution need to be considered but also communication between the different processes which can induce delays that are detrimental to performance. As the number of processes increases, so does the impact of the communication delays on performance. For large-scale parallel applications, it is critical to understand how the communication impacts performance in order to make the code more efficient. There are several tools available for visualizing program execution and communications on parallel systems. These tools generally provide either views which statistically summarize the entire program execution or process-centric views. However, process-centric visualizations do not scale well as the number of processes gets very large. In particular, the most common representation of parallel processes is a Gantt chart with a row for each process. As the number of processes increases, these charts can become difficult to work with and can even exceed screen resolution. We propose a new visualization approach that affords more scalability and then demonstrate it on systems running with up to 16,384 processes.\\\",\\\"Authors\\\":\\\"Muelder, C.;Gygi, F.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"LargeScaleDataAndScalability;ProgrammingAlgorithmsAndDataStructures;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.196\\\",\\\"Keywords\\\":\\\"information visualization;scalability;mpi profiling\\\",\\\"Keywords_Processed\\\":\\\"scalability;information visualization;mpi profiling\\\",\\\"Title\\\":\\\"Visual Analysis of Inter-Process Communication for Large-Scale Parallel Computing\\\"},\\\"603\\\":{\\\"Abstract\\\":\\\"Social photos, which are taken during family events or parties, represent individuals or groups of people. We show in this paper how a Hasse diagram is an efficient visualization strategy for eliciting different groups and navigating through them. However, we do not limit this strategy to these traditional uses. Instead we show how it can also be used for assisting in indexing new photos. Indexing consists of identifying the event and people in photos. It is an integral phase that takes place before searching and sharing. In our method we use existing indexed photos to index new photos. This is performed through a manual drag and drop procedure followed by a content fusion process that we call 'propagation'. At the core of this process is the necessity to organize and visualize the photos that will be used for indexing in a manner that is easily recognizable and accessible by the user. In this respect we make use of an object Galois sub-hierarchy and display it using a Hasse diagram. The need for an incremental display that maintains the user's mental map also leads us to propose a novel way of building the Hasse diagram. To validate the approach, we present some tests conducted with a sample of users that confirm the interest of this organization, visualization and indexation approach. Finally, we conclude by considering scalability, the possibility to extract social networks and automatically create personalised albums.\\\",\\\"Authors\\\":\\\"Crampes, M.;de Oliveira-Kumar, J.;Ranwez, S.;Villerd, J.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;DataAcquisitionAndManagement;HierarchicalTreeDataAndTechniques;SocialNetworksAndSocialMedia;VisualAnalysisModels\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.201\\\",\\\"Keywords\\\":\\\"information visualization;formal concept analysis;hasse diagram;galois sub-hierarchy;social photos;indexing\\\",\\\"Keywords_Processed\\\":\\\"galois sub hierarchy;information visualization;hasse diagram;indexing;social photo;formal concept analysis\\\",\\\"Title\\\":\\\"Visualizing Social Photos on a Hasse Diagram for Eliciting Relations and Indexing New Photos\\\"},\\\"604\\\":{\\\"Abstract\\\":\\\"Visualizing the intellectual structure of scientific domains using co-cited units such as references or authors has become a routine for domain analysis. In previous studies, paper-reference matrices are usually transformed into reference-reference matrices to obtain co-citation relationships, which are then visualized in different representations, typically as node-link networks, to represent the intellectual structures of scientific domains. Such network visualizations sometimes contain tightly knit components, which make visual analysis of the intellectual structure a challenging task. In this study, we propose a new approach to reveal co-citation relationships. Instead of using a reference-reference matrix, we directly use the original paper-reference matrix as the information source, and transform the paper-reference matrix into an FP-tree and visualize it in a Java-based prototype system. We demonstrate the usefulness of our approach through visual analyses of the intellectual structure of two domains: information visualization and Sloan Digital Sky Survey (SDSS). The results show that our visualization not only retains the major information of co-citation relationships, but also reveals more detailed sub-structures of tightly knit clusters than a conventional node-link network visualization.\\\",\\\"Authors\\\":\\\"Jian Zhang;Chen, C.;Jiexun Li\\\",\\\"Clusters\\\":\\\"HierarchicalTreeDataAndTechniques;MatrixRelatedTechniques;SocialScienceAndHumanities;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.202\\\",\\\"Keywords\\\":\\\"intellectual structure;co-citation;paper-reference matrix;fp-tree\\\",\\\"Keywords_Processed\\\":\\\"co citation;intellectual structure;paper reference matrix;fp tree\\\",\\\"Title\\\":\\\"Visualizing the Intellectual Structure with Paper-Reference Matrices\\\"},\\\"605\\\":{\\\"Abstract\\\":\\\"Visual exploration is essential to the visualization and analysis of densely sampled 3D DTI fibers in biological speciments, due to the high geometric, spatial, and anatomical complexity of fiber tracts. Previous methods for DTI fiber visualization use zooming, color-mapping, selection, and abstraction to deliver the characteristics of the fibers. However, these schemes mainly focus on the optimization of visualization in the 3D space where cluttering and occlusion make grasping even a few thousand fibers difficult. This paper introduces a novel interaction method that augments the 3D visualization with a 2D representation containing a low-dimensional embedding of the DTI fibers. This embedding preserves the relationship between the fibers and removes the visual clutter that is inherent in 3D renderings of the fibers. This new interface allows the user to manipulate the DTI fibers as both 3D curves and 2D embedded points and easily compare or validate his or her results in both domains. The implementation of the framework is GPU based to achieve real-time interaction. The framework was applied to several tasks, and the results show that our method reduces the user's workload in recognizing 3D DTI fibers and permits quick and accurate DTI fiber selection.\\\",\\\"Authors\\\":\\\"Wei Chen;Zi'ang Ding;Song Zhang;MacKay-Brandt, A.;Correia, S.;Huamin Qu;Crow, J.A.;Tate, D.F.;Zhicheng Yan;Qunsheng Peng\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;TensorDataAndTechniques;Tractography;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.112\\\",\\\"Keywords\\\":\\\"fibers;visualization interface;fiber clustering;diffusion tensor imaging\\\",\\\"Keywords_Processed\\\":\\\"fiber;diffusion tensor imaging;visualization interface;fiber clustering\\\",\\\"Title\\\":\\\"A Novel Interface for Interactive Exploration of DTI fibers\\\"},\\\"606\\\":{\\\"Abstract\\\":\\\"Color vision deficiency (CVD) affects approximately 200 million people worldwide, compromising the ability of these individuals to effectively perform color and visualization-related tasks. This has a significant impact on their private and professional lives. We present a physiologically-based model for simulating color vision. Our model is based on the stage theory of human color vision and is derived from data reported in electrophysiological studies. It is the first model to consistently handle normal color vision, anomalous trichromacy, and dichromacy in a unified way. We have validated the proposed model through an experimental evaluation involving groups of color vision deficient individuals and normal color vision ones. Our model can provide insights and feedback on how to improve visualization experiences for individuals with CVD. It also provides a framework for testing hypotheses about some aspects of the retinal photoreceptors in color vision deficient individuals.\\\",\\\"Authors\\\":\\\"Machado, G..;Oliveira, M.M.;Fernandes, L.A.F.\\\",\\\"Clusters\\\":\\\"ColorColorPerception\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.113\\\",\\\"Keywords\\\":\\\"color perception;dichromacy;anomalous trichromacy;models of color vision;simulation of color vision deficiency\\\",\\\"Keywords_Processed\\\":\\\"model of color vision;anomalous trichromacy;color perception;simulation of color vision deficiency;dichromacy\\\",\\\"Title\\\":\\\"A Physiologically-based Model for Simulation of Color Vision Deficiency\\\"},\\\"607\\\":{\\\"Abstract\\\":\\\"Many techniques have been proposed to show uncertainty in data visualizations. However, very little is known about their effectiveness in conveying meaningful information. In this paper, we present a user study that evaluates the perception of uncertainty amongst four of the most commonly used techniques for visualizing uncertainty in one-dimensional and two-dimensional data. The techniques evaluated are traditional errorbars, scaled size of glyphs, color-mapping on glyphs, and color-mapping of uncertainty on the data surface. The study uses generated data that was designed to represent the systematic and random uncertainty components. Twenty-seven users performed two types of search tasks and two types of counting tasks on 1D and 2D datasets. The search tasks involved finding data points that were least or most uncertain. The counting tasks involved counting data features or uncertainty features. A 4 times 4 full-factorial ANOVA indicated a significant interaction between the techniques used and the type of tasks assigned for both datasets indicating that differences in performance between the four techniques depended on the type of task performed. Several one-way ANOVAs were computed to explore the simple main effects. Bonferronni's correction was used to control for the family-wise error rate for alpha-inflation. Although we did not find a consistent order among the four techniques for all the tasks, there are several findings from the study that we think are useful for uncertainty visualization design. We found a significant difference in user performance between searching for locations of high and searching for locations of low uncertainty. Errorbars consistently underperformed throughout the experiment. Scaling the size of glyphs and color-mapping of the surface performed reasonably well. The efficiency of most of these techniques were highly dependent on the tasks performed. We believe that these findings can be used in future uncertainty visualization desig- - n. In addition, the framework developed in this user study presents a structured approach to evaluate uncertainty visualization techniques, as well as provides a basis for future research in uncertainty visualization.\\\",\\\"Authors\\\":\\\"Sanyal, J.;Song Zhang;Bhattacharya, G.;Amburn, P.;Moorhead, R.J.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.114\\\",\\\"Keywords\\\":\\\"user study;uncertainty visualization\\\",\\\"Keywords_Processed\\\":\\\"uncertainty visualization;user study\\\",\\\"Title\\\":\\\"A User Study to Compare Four Uncertainty Visualization Methods for 1D and 2D Datasets\\\"},\\\"608\\\":{\\\"Abstract\\\":\\\"This paper describes advanced volume visualization and quantification for applications in non-destructive testing (NDT), which results in novel and highly effective interactive workflows for NDT practitioners. We employ a visual approach to explore and quantify the features of interest, based on transfer functions in the parameter spaces of specific application scenarios. Examples are the orientations of fibres or the roundness of particles. The applicability and effectiveness of our approach is illustrated using two specific scenarios of high practical relevance. First, we discuss the analysis of Steel Fibre Reinforced Sprayed Concrete (SFRSpC). We investigate the orientations of the enclosed steel fibres and their distribution, depending on the concrete's application direction. This is a crucial step in assessing the material's behavior under mechanical stress, which is still in its infancy and therefore a hot topic in the building industry. The second application scenario is the designation of the microstructure of ductile cast irons with respect to the contained graphite. This corresponds to the requirements of the ISO standard 945-1, which deals with 2D metallographic samples. We illustrate how the necessary analysis steps can be carried out much more efficiently using our system for 3D volumes. Overall, we show that a visual approach with custom transfer functions in specific application domains offers significant benefits and has the potential of greatly improving and optimizing the workflows of domain scientists and engineers.\\\",\\\"Authors\\\":\\\"Fritz, L.;Hadwiger, M.;Geier, G.;Pittino, G.;Groller, E.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;VectorFieldsDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.115\\\",\\\"Keywords\\\":\\\"multi-dimensional transfer function;non-destructive testing;volume rendering;direction visualization\\\",\\\"Keywords_Processed\\\":\\\"non destructive testing;volume render;direction visualization;multi dimensional transfer function\\\",\\\"Title\\\":\\\"A Visual Approach to Efficient Analysis and Quantification of Ductile Iron and Reinforced Sprayed Concrete\\\"},\\\"609\\\":{\\\"Abstract\\\":\\\"Confocal microscopy is widely used in neurobiology for studying the three-dimensional structure of the nervous system. Confocal image data are often multi-channel, with each channel resulting from a different fluorescent dye or fluorescent protein; one channel may have dense data, while another has sparse; and there are often structures at several spatial scales: subneuronal domains, neurons, and large groups of neurons (brain regions). Even qualitative analysis can therefore require visualization using techniques and parameters fine-tuned to a particular dataset. Despite the plethora of volume rendering techniques that have been available for many years, the techniques standardly used in neurobiological research are somewhat rudimentary, such as looking at image slices or maximal intensity projections. Thus there is a real demand from neurobiologists, and biologists in general, for a flexible visualization tool that allows interactive visualization of multi-channel confocal data, with rapid fine-tuning of parameters to reveal the three-dimensional relationships of structures of interest. Together with neurobiologists, we have designed such a tool, choosing visualization methods to suit the characteristics of confocal data and a typical biologist's workflow. We use interactive volume rendering with intuitive settings for multidimensional transfer functions, multiple render modes and multi-views for multi-channel volume data, and embedding of polygon data into volume data for rendering and editing. As an example, we apply this tool to visualize confocal microscopy datasets of the developing zebrafish visual system.\\\",\\\"Authors\\\":\\\"Yong Wan;Otsuna, H.;Chi-Bin Chien;Hansen, C.\\\",\\\"Clusters\\\":\\\"Microscopy;NeurosciencesAndBrainVisualization;QualitativeEvaluation;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.118\\\",\\\"Keywords\\\":\\\"neurobiology;volume rendering;qualitative analysis;visualization;confocal microscopy\\\",\\\"Keywords_Processed\\\":\\\"confocal microscopy;volume render;visualization;neurobiology;qualitative analysis\\\",\\\"Title\\\":\\\"An interactive visualization tool for multi-channel confocal microscopy data in neurobiology research\\\"},\\\"610\\\":{\\\"Abstract\\\":\\\"Transfer functions facilitate the volumetric data visualization by assigning optical properties to various data features and scalar values. Automation of transfer function specifications still remains a challenge in volume rendering. This paper presents an approach for automating transfer function generations by utilizing topological attributes derived from the contour tree of a volume. The contour tree acts as a visual index to volume segments, and captures associated topological attributes involved in volumetric data. A residue flow model based on Darcy's law is employed to control distributions of opacity between branches of the contour tree. Topological attributes are also used to control color selection in a perceptual color space and create harmonic color transfer functions. The generated transfer functions can depict inclusion relationship between structures and maximize opacity and color differences between them. The proposed approach allows efficient automation of transfer function generations, and exploration on the data to be carried out based on controlling of opacity residue flow rate instead of complex low-level transfer function parameter adjustments. Experiments on various data sets demonstrate the practical use of our approach in transfer function generations.\\\",\\\"Authors\\\":\\\"Jianlong Zhou;Takatsuka, M.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;FlowVisualizationDataAndTechniques;TopologyBasedTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.120\\\",\\\"Keywords\\\":\\\"volume rendering;residue flow;harmonic color;contour tree;transfer function\\\",\\\"Keywords_Processed\\\":\\\"contour tree;volume render;harmonic color;transfer function;residue flow\\\",\\\"Title\\\":\\\"Automatic Transfer Function Generation Using Contour Tree Controlled Residue Flow Model and Color Harmonics\\\"},\\\"611\\\":{\\\"Abstract\\\":\\\"Neurobiology investigates how anatomical and physiological relationships in the nervous system mediate behavior. Molecular genetic techniques, applied to species such as the common fruit fly Drosophila melanogaster, have proven to be an important tool in this research. Large databases of transgenic specimens are being built and need to be analyzed to establish models of neural information processing. In this paper we present an approach for the exploration and analysis of neural circuits based on such a database. We have designed and implemented emph{BrainGazer}, a system which integrates visualization techniques for volume data acquired through confocal microscopy as well as annotated anatomical structures with an intuitive approach for accessing the available information. We focus on the ability to visually query the data based on semantic as well as spatial relationships. Additionally, we present visualization techniques for the concurrent depiction of neurobiological volume data and geometric objects which aim to reduce visual clutter. The described system is the result of an ongoing interdisciplinary collaboration between neurobiologists and visualization researchers.\\\",\\\"Authors\\\":\\\"Bruckner, S.;Solteszova, V.;Groller, E.;Hladuvka, J.;Buhler, K.;Yu, J.Y.;Dickson, B.J.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;NeurosciencesAndBrainVisualization;QueriesAndSearch;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.121\\\",\\\"Keywords\\\":\\\"biomedical visualization;neurobiology;visual queries;volume visualization\\\",\\\"Keywords_Processed\\\":\\\"volume visualization;visual query;neurobiology;biomedical visualization\\\",\\\"Title\\\":\\\"BrainGazer - Visual Queries for Neurobiology Research\\\"},\\\"612\\\":{\\\"Abstract\\\":\\\"Multi-projector displays show significant spatial variation in 3D color gamut due to variation in the chromaticity gamuts across the projectors, vignetting effect of each projector and also overlap across adjacent projectors. In this paper we present a new constrained gamut morphing algorithm that removes all these variations and results in true color seamlessness across tiled multi-projector displays. Our color morphing algorithm adjusts the intensities of light from each pixel of each projector precisely to achieve a smooth morphing from one projector's gamut to the other's through the overlap region. This morphing is achieved by imposing precise constraints on the perceptual difference between the gamuts of two adjacent pixels. In addition, our gamut morphing assures a C1 continuity yielding visually pleasing appearance across the entire display. We demonstrate our method successfully on a planar and a curved display using both low and high-end projectors. Our approach is completely scalable, efficient and automatic. We also demonstrate the real-time performance of our image correction algorithm on GPUs for interactive applications. To the best of our knowledge, this is the first work that presents a scalable method with a strong foundation in perception and realizes, for the first time, a truly seamless display where the number of projectors cannot be deciphered.\\\",\\\"Authors\\\":\\\"Sajadi, B.;Lazarov, M.;Gopi, M.;Majumder, A.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;DisplaysGeneral;LargeAndHighResDisplays\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.124\\\",\\\"Keywords\\\":\\\"tiled displays;multi-projector displays;color calibration\\\",\\\"Keywords_Processed\\\":\\\"color calibration;multi projector display;tile display\\\",\\\"Title\\\":\\\"Color Seamlessness in Multi-Projector Displays Using Constrained Gamut Morphing\\\"},\\\"613\\\":{\\\"Abstract\\\":\\\"We introduce a new method for coloring 3D line fields and show results from its application in visualizing orientation in DTI brain data sets. The method uses Boy's surface, an immersion of RP2 in 3D. This coloring method is smooth and one-to-one except on a set of measure zero, the double curve of Boy's surface.\\\",\\\"Authors\\\":\\\"Demiralp, C.;Hughes, J.F.;Laidlaw, D.H.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;NumericalMethodsMathematics;TensorDataAndTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.125\\\",\\\"Keywords\\\":\\\"colormapping;real projective plane;tensor field;orientation;diffusion tensor imaging;line field\\\",\\\"Keywords_Processed\\\":\\\"colormappe;orientation;real projective plane;diffusion tensor imaging;line field;tensor field\\\",\\\"Title\\\":\\\"Coloring 3D Line fields Using Boy's Real Projective Plane Immersion\\\"},\\\"614\\\":{\\\"Abstract\\\":\\\"In a user study comparing four visualization methods for three-dimensional vector data, participants used visualizations from each method to perform five simple but representative tasks: 1) determining whether a given point was a critical point, 2) determining the type of a critical point, 3) determining whether an integral curve would advect through two points, 4) determining whether swirling movement is present at a point, and 5) determining whether the vector field is moving faster at one point than another. The visualization methods were line and tube representations of integral curves with both monoscopic and stereoscopic viewing. While participants reported a preference for stereo lines, quantitative results showed performance among the tasks varied by method. Users performed all tasks better with methods that: 1) gave a clear representation with no perceived occlusion, 2) clearly visualized curve speed and direction information, and 3) provided fewer rich 3D cues (e.g., shading, polygonal arrows, overlap cues, and surface textures). These results provide quantitative support for anecdotal evidence on visualization methods. The tasks and testing framework also give a basis for comparing other visualization methods, for creating more effective methods, and for defining additional tasks to explore further the tradeoffs among the methods.\\\",\\\"Authors\\\":\\\"Forsberg, A.;Jian Chen;Laidlaw, D.H.\\\",\\\"Clusters\\\":\\\"DisplaysGeneral;EvaluationGeneral;LineBasedTechniquesAndApproaches;VectorFieldsDataAndTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.126\\\",\\\"Keywords\\\":\\\"user study;stereoscopic and monoscopic viewing;visualization;tubes;lines;3d vector fields\\\",\\\"Keywords_Processed\\\":\\\"visualization;user study;stereoscopic and monoscopic viewing;3d vector field;tube;line\\\",\\\"Title\\\":\\\"Comparing 3D Vector field Visualization Methods: A User Study\\\"},\\\"615\\\":{\\\"Abstract\\\":\\\"Typical scientific data is represented on a grid with appropriate interpolation or approximation schemes,defined on a continuous domain. The visualization of such data in parallel coordinates may reveal patterns latently contained in the data and thus can improve the understanding of multidimensional relations. In this paper, we adopt the concept of continuous scatterplots for the visualization of spatially continuous input data to derive a density model for parallel coordinates. Based on the point-line duality between scatterplots and parallel coordinates, we propose a mathematical model that maps density from a continuous scatterplot to parallel coordinates and present different algorithms for both numerical and analytical computation of the resulting density field. In addition, we show how the 2-D model can be used to successively construct continuous parallel coordinates with an arbitrary number of dimensions. Since continuous parallel coordinates interpolate data values within grid cells, a scalable and dense visualization is achieved, which will be demonstrated for typical multi-variate scientific data.\\\",\\\"Authors\\\":\\\"Heinrich, J.;Weiskopf, D.\\\",\\\"Clusters\\\":\\\"IntegratingSpatialAndNonSpatialDataVisualization;Interpolation;MultidimensionalMultivariateMultifieldDataAndTechniques;ParallelCoordinates\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.131\\\",\\\"Keywords\\\":\\\"integrating spatial and non-spatial visualization;parallel coordinates;multivariate visualization;interpolation\\\",\\\"Keywords_Processed\\\":\\\"parallel coordinate;interpolation;multivariate visualization;integrate spatial and non spatial visualization\\\",\\\"Title\\\":\\\"Continuous Parallel Coordinates\\\"},\\\"616\\\":{\\\"Abstract\\\":\\\"We present two visualization techniques for curve-centric volume reformation with the aim to create compelling comparative visualizations. A curve-centric volume reformation deforms a volume, with regards to a curve in space, to create a new space in which the curve evaluates to zero in two dimensions and spans its arc-length in the third. The volume surrounding the curve is deformed such that spatial neighborhood to the curve is preserved. The result of the curve-centric reformation produces images where one axis is aligned to arc-length, and thus allows researchers and practitioners to apply their arc-length parameterized data visualizations in parallel for comparison. Furthermore we show that when visualizing dense data, our technique provides an inside out projection, from the curve and out into the volume, which allows for inspection what is around the curve. Finally we demonstrate the usefulness of our techniques in the context of two application cases. We show that existing data visualizations of arc-length parameterized data can be enhanced by using our techniques, in addition to creating a new view and perspective on volumetric data around curves. Additionally we show how volumetric data can be brought into plotting environments that allow precise readouts. In the first case we inspect streamlines in a flow field around a car, and in the second we inspect seismic volumes and well logs from drilling.\\\",\\\"Authors\\\":\\\"Lampe, O.D.;Correa, C.;Kwan-Liu Ma;Hauser, H.\\\",\\\"Clusters\\\":\\\"ComparisonComparativeVisualizationAndSimilarity;DimensionalityReduction;RaytracingRaycasting;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.136\\\",\\\"Keywords\\\":\\\"comparative visualization;volume deformation;curve-centric-reformation;radial raycasting\\\",\\\"Keywords_Processed\\\":\\\"volume deformation;comparative visualization;radial raycasting;curve centric reformation\\\",\\\"Title\\\":\\\"Curve-Centric Volume Reformation for Comparative Visualization\\\"},\\\"617\\\":{\\\"Abstract\\\":\\\"One way to provide global illumination for the scientist who performs an interactive sweep through a 3D scalar dataset is to pre-compute global illumination, resample the radiance onto a 3D grid, then use it as a 3D texture. The basic approach of repeatedly extracting isosurfaces, illuminating them, and then building a 3D illumination grid suffers from the non-uniform sampling that arises from coupling the sampling of radiance with the sampling of isosurfaces. We demonstrate how the illumination step can be decoupled from the isosurface extraction step by illuminating the entire 3D scalar function as a 3-manifold in 4-dimensional space. By reformulating light transport in a higher dimension, one can sample a 3D volume without requiring the radiance samples to aggregate along individual isosurfaces in the pre-computed illumination grid.\\\",\\\"Authors\\\":\\\"Banks, D.C.;Beason, K.\\\",\\\"Clusters\\\":\\\"Illumination;IsosurfaceAndSurfaceExtractionTechniques;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.137\\\",\\\"Keywords\\\":\\\"isosurface;physically-based illumination;light transport;level sets\\\",\\\"Keywords_Processed\\\":\\\"light transport;level set;isosurface;physically base illumination\\\",\\\"Title\\\":\\\"Decoupling Illumination from Isosurface Generation Using 4D Light Transport\\\"},\\\"618\\\":{\\\"Abstract\\\":\\\"We present a visual exploration paradigm that facilitates navigation through complex fiber tracts by combining traditional 3D model viewing with lower dimensional representations. To this end, we create standard streamtube models along with two two-dimensional representations, an embedding in the plane and a hierarchical clustering tree, for a given set of fiber tracts. We then link these three representations using both interaction and color obtained by embedding fiber tracts into a perceptually uniform color space. We describe an anecdotal evaluation with neuroscientists to assess the usefulness of our method in exploring anatomical and functional structures in the brain. Expert feedback indicates that, while a standalone clinical use of the proposed method would require anatomical landmarks in the lower dimensional representations, the approach would be particularly useful in accelerating tract bundle selection. Results also suggest that combining traditional 3D model viewing with lower dimensional representations can ease navigation through the complex fiber tract models, improving exploration of the connectivity in the brain.\\\",\\\"Authors\\\":\\\"Jianu, R.;Demiralp, C.;Laidlaw, D.H.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;DimensionalityReduction;InteractionTechniquesGeneral;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.141\\\",\\\"Keywords\\\":\\\"embedding;coloring;diffusion tensor imaging fiber tracts;interaction\\\",\\\"Keywords_Processed\\\":\\\"color;diffusion tensor image fiber tract;embed;interaction\\\",\\\"Title\\\":\\\"Exploring 3D DTI fiber Tracts with Linked 2D Representations\\\"},\\\"619\\\":{\\\"Abstract\\\":\\\"In this paper we investigate scalability limitations in the visualization of large-scale particle-based cosmological simulations, and we present methods to reduce these limitations on current PC architectures. To minimize the amount of data to be streamed from disk to the graphics subsystem, we propose a visually continuous level-of-detail (LOD) particle representation based on a hierarchical quantization scheme for particle coordinates and rules for generating coarse particle distributions. Given the maximal world space error per level, our LOD selection technique guarantees a sub-pixel screen space error during rendering. A brick-based page-tree allows to further reduce the number of disk seek operations to be performed. Additional particle quantities like density, velocity dispersion, and radius are compressed at no visible loss using vector quantization of logarithmically encoded floating point values. By fine-grain view-frustum culling and presence acceleration in a geometry shader the required geometry throughput on the GPU can be significantly reduced. We validate the quality and scalability of our method by presenting visualizations of a particle-based cosmological dark-matter simulation exceeding 10 billion elements.\\\",\\\"Authors\\\":\\\"Fraedrich, R.;Schneider, J.;Westermann, R.\\\",\\\"Clusters\\\":\\\"AstronomyAstrophysics;LargeScaleDataAndScalability;ParticleVisualizationAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.142\\\",\\\"Keywords\\\":\\\"scalability;particle visualization;cosmology\\\",\\\"Keywords_Processed\\\":\\\"particle visualization;cosmology;scalability\\\",\\\"Title\\\":\\\"Exploring the Millennium Run - Scalable Rendering of Large-Scale Cosmological Datasets\\\"},\\\"620\\\":{\\\"Abstract\\\":\\\"In this paper we present a novel focus+context zooming technique, which allows users to zoom into a route and its associated landmarks in a 3D urban environment from a 45-degree bird's-eye view. Through the creative utilization of the empty space in an urban environment, our technique can informatively reveal the focus region and minimize distortions to the context buildings. We first create more empty space in the 2D map by broadening the road with an adapted seam carving algorithm. A grid-based zooming technique is then used to enlarge the landmarks to reclaim the created empty space and thus reduce distortions to the other parts. Finally,an occlusion-free route visualization scheme adaptively scales the buildings occluding the route to make the route always visible to users. Our method can be conveniently integrated into Google Earth and Virtual Earth to provide seamless route zooming and help users better explore a city and plan their tours. It can also be used in other applications such as information overlay to a virtual city.\\\",\\\"Authors\\\":\\\"Huamin Qu;Haomian Wang;Weiwei Cui;Yingcai Wu;Ming-Yuen Chan\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;ImageBasedDataImageSignalProcessing;ImmersiveAndVirtualEnvironments;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.144\\\",\\\"Keywords\\\":\\\"focus+context visualization;3d virtual environment;zooming;seam carving\\\",\\\"Keywords_Processed\\\":\\\"focus context visualization;seam carving;zooming;3d virtual environment\\\",\\\"Title\\\":\\\"Focus+Context Route Zooming and Information Overlay in 3D Urban Environments\\\"},\\\"621\\\":{\\\"Abstract\\\":\\\"This paper describes GL4D, an interactive system for visualizing 2-manifolds and 3-manifolds embedded in four Euclidean dimensions and illuminated by 4D light sources. It is a tetrahedron-based rendering pipeline that projects geometry into volume images, an exact parallel to the conventional triangle-based rendering pipeline for 3D graphics. Novel features include GPU-based algorithms for real-time 4D occlusion handling and transparency compositing; we thus enable a previously impossible level of quality and interactivity for exploring lit 4D objects. The 4D tetrahedrons are stored in GPU memory as vertex buffer objects, and the vertex shader is used to perform per-vertex 4D modelview transformations and 4D-to-3D projection. The geometry shader extension is utilized to slice the projected tetrahedrons and rasterize the slices into individual 2D layers of voxel fragments. Finally, the fragment shader performs per-voxel operations such as lighting and alpha blending with previously computed layers. We account for 4D voxel occlusion along the 4D-to-3D projection ray by supporting a multi-pass back-to-front fragment composition along the projection ray; to accomplish this, we exploit a new adaptation of the dual depth peeling technique to produce correct volume image data and to simultaneously render the resulting volume data using 3D transfer functions into the final 2D image. Previous CPU implementations of the rendering of 4D-embedded 3-manifolds could not perform either the 4D depth-buffered projection or manipulation of the volume-rendered image in real-time; in particular, the dual depth peeling algorithm is a novel GPU-based solution to the real-time 4D depth-buffering problem. GL4D is implemented as an integrated OpenGL-style API library, so that the underlying shader operations are as transparent as possible to the user.\\\",\\\"Authors\\\":\\\"Chu, A.;Chi-Wing Fu;Hanson, A.J.;Pheng-Ann Heng\\\",\\\"Clusters\\\":\\\"Illumination;InputAndOutputDevicesGeneral;Mathematics;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.147\\\",\\\"Keywords\\\":\\\"interactive illumination;4d visualization;mathematical visualization;graphics hardware\\\",\\\"Keywords_Processed\\\":\\\"4d visualization;mathematical visualization;interactive illumination;graphic hardware\\\",\\\"Title\\\":\\\"GL4D: A GPU-based Architecture for Interactive 4D Visualization\\\"},\\\"622\\\":{\\\"Abstract\\\":\\\"This paper presents a pipeline for high quality volume rendering of adaptive mesh refinement (AMR) datasets. We introduce a new method allowing high quality visualization of hexahedral cells in this context; this method avoids artifacts like discontinuities in the isosurfaces. To achieve this, we choose the number and placement of sampling points over the cast rays according to the analytical properties of the reconstructed signal inside each cell. We extend our method to handle volume shading of such cells. We propose an interpolation scheme that guarantees continuity between adjacent cells of different AMR levels. We introduce an efficient hybrid CPU-GPU mesh traversal technique. We present an implementation of our AMR visualization method on current graphics hardware, and show results demonstrating both the quality and performance of our method.\\\",\\\"Authors\\\":\\\"Marchesin, S.;de Verdiere, G.C.\\\",\\\"Clusters\\\":\\\"MeshesGridsAndLattices;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.149\\\",\\\"Keywords\\\":\\\"volume shading;volume rendering;adaptive mesh refinement data\\\",\\\"Keywords_Processed\\\":\\\"volume shade;volume render;adaptive mesh refinement datum\\\",\\\"Title\\\":\\\"High-Quality, Semi-Analytical Volume Rendering for AMR Data\\\"},\\\"623\\\":{\\\"Abstract\\\":\\\"We propose a new perception-guided compositing operator for color blending. The operator maintains the same rules for achromatic compositing as standard operators (such as the over operator), but it modifies the computation of the chromatic channels. Chromatic compositing aims at preserving the hue of the input colors; color continuity is achieved by reducing the saturation of colors that are to change their hue value. The main benefit of hue preservation is that color can be used for proper visual labeling, even under the constraint of transparency rendering or image overlays. Therefore, the visualization of nominal data is improved. Hue-preserving blending can be used in any existing compositing algorithm, and it is particularly useful for volume rendering. The usefulness of hue-preserving blending and its visual characteristics are shown for several examples of volume visualization.\\\",\\\"Authors\\\":\\\"Chuang, J.;Weiskopf, D.;Moller, T.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;IllustrativeVisualization;ImageBasedDataImageSignalProcessing;Perception;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.150\\\",\\\"Keywords\\\":\\\"volume rendering;illustrative visualization;perceptual transparency;color blending;image compositing\\\",\\\"Keywords_Processed\\\":\\\"perceptual transparency;volume render;illustrative visualization;color blending;image compositing\\\",\\\"Title\\\":\\\"Hue-Preserving Color Blending\\\"},\\\"624\\\":{\\\"Abstract\\\":\\\"We present an interactive framework for exploring space-time and form-function relationships in experimentally collected high-resolution biomechanical data sets. These data describe complex 3D motions (e.g. chewing, walking, flying) performed by animals and humans and captured via high-speed imaging technologies, such as biplane fluoroscopy. In analyzing these 3D biomechanical motions, interactive 3D visualizations are important, in particular, for supporting spatial analysis. However, as researchers in information visualization have pointed out, 2D visualizations can also be effective tools for multi-dimensional data analysis, especially for identifying trends over time. Our approach, therefore, combines techniques from both 3D and 2D visualizations. Specifically, it utilizes a multi-view visualization strategy including a small multiples view of motion sequences, a parallel coordinates view, and detailed 3D inspection views. The resulting framework follows an overview first, zoom and filter, then details-on-demand style of analysis, and it explicitly targets a limitation of current tools, namely, supporting analysis and comparison at the level of a collection of motions rather than sequential analysis of a single or small number of motions. Scientific motion collections appropriate for this style of analysis exist in clinical work in orthopedics and physical rehabilitation, in the study of functional morphology within evolutionary biology, and in other contexts. An application is described based on a collaboration with evolutionary biologists studying the mechanics of chewing motions in pigs. Interactive exploration of data describing a collection of more than one hundred experimentally captured pig chewing cycles is described.\\\",\\\"Authors\\\":\\\"Keefe, D.F.;Ewert, M.;Ribarsky, W.;Chang, R.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;MultipleLinkedCoordinatedViews;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.152\\\",\\\"Keywords\\\":\\\"biomechanics;information visualization;coordinated & multiple views;scientific visualization\\\",\\\"Keywords_Processed\\\":\\\"coordinate multiple view;information visualization;biomechanic;scientific visualization\\\",\\\"Title\\\":\\\"Interactive Coordinated Multiple-View Visualization of Biomechanical Motion Data\\\"},\\\"625\\\":{\\\"Abstract\\\":\\\"In this paper we present techniques for the visualization of unsteady flows using streak surfaces, which allow for the first time an adaptive integration and rendering of such surfaces in real-time. The techniques consist of two main components, which are both realized on the GPU to exploit computational and bandwidth capacities for numerical particle integration and to minimize bandwidth requirements in the rendering of the surface. In the construction stage, an adaptive surface representation is generated. Surface refinement and coarsening strategies are based on local surface properties like distortion and curvature. We compare two different methods to generate a streak surface: a) by computing a patch-based surface representation that avoids any interdependence between patches, and b) by computing a particle-based surface representation including particle connectivity, and by updating this connectivity during particle refinement and coarsening. In the rendering stage, the surface is either rendered as a set of quadrilateral surface patches using high-quality point-based approaches, or a surface triangulation is built in turn from the given particle connectivity and the resulting triangle mesh is rendered. We perform a comparative study of the proposed techniques with respect to surface quality, visual quality and performance by visualizing streak surfaces in real flows using different rendering options.\\\",\\\"Authors\\\":\\\"Burger, K.;Ferstl, F.;Theisel, H.;Westermann, R.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;GpuBasedTechniques;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.154\\\",\\\"Keywords\\\":\\\"unsteady flow visualization;streak surface generation;gpu\\\",\\\"Keywords_Processed\\\":\\\"gpu;unsteady flow visualization;streak surface generation\\\",\\\"Title\\\":\\\"Interactive Streak Surface Visualization on the GPU\\\"},\\\"626\\\":{\\\"Abstract\\\":\\\"The widespread use of computational simulation in science and engineering provides challenging research opportunities. Multiple independent variables are considered and large and complex data are computed, especially in the case of multi-run simulation. Classical visualization techniques deal well with 2D or 3D data and also with time-dependent data. Additional independent dimensions, however, provide interesting new challenges. We present an advanced visual analysis approach that enables a thorough investigation of families of data surfaces, i.e., datasets, with respect to pairs of independent dimensions. While it is almost trivial to visualize one such data surface, the visual exploration and analysis of many such data surfaces is a grand challenge, stressing the users' perception and cognition. We propose an approach that integrates projections and aggregations of the data surfaces at different levels (one scalar aggregate per surface, a 1D profile per surface, or the surface as such). We demonstrate the necessity for a flexible visual analysis system that integrates many different (linked) views for making sense of this highly complex data. To demonstrate its usefulness, we exemplify our approach in the context of a meteorological multi-run simulation data case and in the context of the engineering domain, where our collaborators are working with the simulation of elastohydrodynamic (EHD) lubrication bearing in the automotive industry.\\\",\\\"Authors\\\":\\\"Matkovic, K.;Gracanin, D.;Klarin, B.;Hauser, H.\\\",\\\"Clusters\\\":\\\"InteractionTechniquesGeneral;MultidimensionalMultivariateMultifieldDataAndTechniques;MultipleLinkedCoordinatedViews;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.155\\\",\\\"Keywords\\\":\\\"interactive visual analysis;coordinated & multiple views;multi-dimensional multi-variate data;family of surfaces\\\",\\\"Keywords_Processed\\\":\\\"coordinate multiple view;family of surface;interactive visual analysis;multi dimensional multi variate datum\\\",\\\"Title\\\":\\\"Interactive Visual Analysis of Complex Scientific Data as Families of Data Surfaces\\\"},\\\"627\\\":{\\\"Abstract\\\":\\\"Radiofrequency identification (RFID) is a powerful automatic remote identification technique that has wide applications. To facilitate RFID deployment, an RFID benchmarking instrument called aGate has been invented to identify the strengths and weaknesses of different RFID technologies in various environments. However, the data acquired by aGate are usually complex time varying multidimensional 3D volumetric data, which are extremely challenging for engineers to analyze. In this paper, we introduce a set of visualization techniques, namely, parallel coordinate plots, orientation plots, a visual history mechanism, and a 3D spatial viewer, to help RFID engineers analyze benchmark data visually and intuitively. With the techniques, we further introduce two workflow procedures (a visual optimization procedure for finding the optimum reader antenna configuration and a visual analysis procedure for comparing the performance and identifying the flaws of RFID devices) for the RFID benchmarking, with focus on the performance analysis of the aGate system. The usefulness and usability of the system are demonstrated in the user evaluation.\\\",\\\"Authors\\\":\\\"Yingcai Wu;Ka-Kei Chung;Huamin Qu;Xiaoru Yuan;Cheung, S.C.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;Optimization;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.156\\\",\\\"Keywords\\\":\\\"rfid visualization;visual optimization;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;rfid visualization;visual optimization\\\",\\\"Title\\\":\\\"Interactive Visual Optimization and Analysis for RfiD Benchmarking\\\"},\\\"628\\\":{\\\"Abstract\\\":\\\"Molecular dynamics simulations of proteins play a growing role in various fields such as pharmaceutical, biochemical and medical research. Accordingly, the need for high quality visualization of these protein systems raises. Highly interactive visualization techniques are especially needed for the analysis of time-dependent molecular simulations. Beside various other molecular representations the surface representations are of high importance for these applications. So far, users had to accept a trade-off between rendering quality and performance - particularly when visualizing trajectories of time-dependent protein data. We present a new approach for visualizing the solvent excluded surface of proteins using a GPU ray casting technique and thus achieving interactive frame rates even for long protein trajectories where conventional methods based on precomputation are not applicable. Furthermore, we propose a semantic simplification of the raw protein data to reduce the visual complexity of the surface and thereby accelerate the rendering without impeding perception of the protein's basic shape. We also demonstrate the application of our solvent excluded surface method to visualize the spatial probability density for the protein atoms over the whole period of the trajectory in one frame, providing a qualitative analysis of the protein flexibility.\\\",\\\"Authors\\\":\\\"Krone, M.;Bidmon, K.;Ertl, T.\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;IsosurfaceAndSurfaceExtractionTechniques;MolecularScienceAndChemistry;PointBasedDataAndTechniques;RaytracingRaycasting;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.157\\\",\\\"Keywords\\\":\\\"surface extraction;molecular visualization;time-varying data;raycasting;gpu;isosurface;point-based data\\\",\\\"Keywords_Processed\\\":\\\"surface extraction;time vary datum;point base datum;molecular visualization;isosurface;raycaste;gpu\\\",\\\"Title\\\":\\\"Interactive Visualization of Molecular Surface Dynamics\\\"},\\\"629\\\":{\\\"Abstract\\\":\\\"Simulation and computation in chemistry studies have been improved as computational power has increased over decades. Many types of chemistry simulation results are available, from atomic level bonding to volumetric representations of electron density. However, tools for the visualization of the results from quantum chemistry computations are still limited to showing atomic bonds and isosurfaces or isocontours corresponding to certain isovalues. In this work, we study the volumetric representations of the results from quantum chemistry computations, and evaluate and visualize the representations directly on the GPU without resampling the result in grid structures. Our visualization tool handles the direct evaluation of the approximated wavefunctions described as a combination of Gaussian-like primitive basis functions. For visualizations, we use a slice based volume rendering technique with a 2D transfer function, volume clipping, and illustrative rendering in order to reveal and enhance the quantum chemistry structure. Since there is no need of resampling the volume from the functional representations, two issues, data transfer and resampling resolution, can be ignored, therefore, it is possible to interactively explore large amount of different information in the computation results.\\\",\\\"Authors\\\":\\\"Yun Jang;Varetto, U.\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;MolecularScienceAndChemistry;PhysicsAndPhysicalSciences;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.158\\\",\\\"Keywords\\\":\\\"quantum chemistry;gaussian type orbital;volume rendering;gpu\\\",\\\"Keywords_Processed\\\":\\\"volume render;gpu;gaussian type orbital;quantum chemistry\\\",\\\"Title\\\":\\\"Interactive Volume Rendering of Functional Representations in Quantum Chemistry\\\"},\\\"630\\\":{\\\"Abstract\\\":\\\"This paper formalizes a novel, intrinsic geometric scale space (IGSS) of 3D surface shapes. The intrinsic geometry of a surface is diffused by means of the Ricci flow for the generation of a geometric scale space. We rigorously prove that this multiscale shape representation satisfies the axiomatic causality property. Within the theoretical framework, we further present a feature-based shape representation derived from IGSS processing, which is shown to be theoretically plausible and practically effective. By integrating the concept of scale-dependent saliency into the shape description, this representation is not only highly descriptive of the local structures, but also exhibits several desired characteristics of global shape representations, such as being compact, robust to noise and computationally efficient. We demonstrate the capabilities of our approach through salient geometric feature detection and highly discriminative matching of 3D scans.\\\",\\\"Authors\\\":\\\"Guangyu Zou;Jing Hua;Zhaoqiang Lai;Xianfeng Gu;Ming Dong\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;MultiScaleDataTechniques;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.159\\\",\\\"Keywords\\\":\\\"riemannian manifolds;geometric flow;feature extraction;scale space\\\",\\\"Keywords_Processed\\\":\\\"geometric flow;feature extraction;riemannian manifold;scale space\\\",\\\"Title\\\":\\\"Intrinsic Geometric Scale Space by Shape Diffusion\\\"},\\\"631\\\":{\\\"Abstract\\\":\\\"We develop a new algorithm for isosurface extraction and view-dependent filtering from large time-varying fields, by using a novel persistent time-octree (PTOT) indexing structure. Previously, the persistent octree (POT) was proposed to perform isosurface extraction and view-dependent filtering, which combines the advantages of the interval tree (for optimal searches of active cells) and of the branch-on-need octree (BONO, for view-dependent filtering), but it only works for steady-state(i.e., single time step) data. For time-varying fields, a 4D version of POT, 4D-POT, was proposed for 4D isocontour slicing, where slicing on the time domain gives all active cells in the queried timestep and isovalue. However, such slicing is not output sensitive and thus the searching is sub-optimal. Moreover, it was not known how to support view-dependent filtering in addition to time-domain slicing.In this paper, we develop a novel persistent time-octree (PTOT) indexing structure, which has the advantages of POT and performs 4D isocontour slicing on the time domain with an output-sensitive and optimal searching. In addition, when we query the same iso value q over m consecutive time steps, there is no additional searching overhead (except for reporting the additional active cells) compared to querying just the first time step. Such searching performance for finding active cells is asymptotically optimal, with asymptotically optimal space and preprocessing time as well. Moreover, our PTOT supports view-dependent filtering in addition to time-domain slicing. We propose a simple and effective out-of-core scheme, where we integrate our PTOT with implicit occluders, batched occlusion queries and batched CUDA computing tasks, so that we can greatly reduce the I/O cost as well as increase the amount of data being concurrently computed in GPU.This results in an efficient algorithm for isosurface extraction with view-dependent filtering utilizing a state-of-the-art programmable GPU for ti me-varying fields larger than main memory. Our experiments on datasets as large as 192 GB (with 4 GB per time step) having no more than 870 MB of memory footprint in both preprocessing and run-time phases demonstrate the efficacy of our new technique.\\\",\\\"Authors\\\":\\\"Cong Wang;Yi-Jen Chiang\\\",\\\"Clusters\\\":\\\"FilteringTechniques;IsosurfaceAndSurfaceExtractionTechniques;OutOfCoreProcessing;ProgrammingAlgorithmsAndDataStructures;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.160\\\",\\\"Keywords\\\":\\\"time-varying fields;persistent data structure;isosurface extraction;view-dependent filtering;out-of-core methods\\\",\\\"Keywords_Processed\\\":\\\"isosurface extraction;out of core method;time vary field;view dependent filtering;persistent datum structure\\\",\\\"Title\\\":\\\"Isosurface Extraction and View-Dependent filtering from Time-Varying fields Using Persistent Time-Octree (PTOT)\\\"},\\\"632\\\":{\\\"Abstract\\\":\\\"Stackless traversal techniques are often used to circumvent memory bottlenecks by avoiding a stack and replacing return traversal with extra computation. This paper addresses whether the stackless traversal approaches are useful on newer hardware and technology (such as CUDA). To this end, we present a novel stackless approach for implicit kd-trees, which exploits the benefits of index-based node traversal, without incurring extra node visitation. This approach, which we term Kd-Jump, enables the traversal to immediately return to the next valid node, like a stack, without incurring extra node visitation (kd-restart). Also, Kd-Jump does not require global memory (stack) at all and only requires a small matrix in fast constant-memory. We report that Kd-Jump outperforms a stack by 10 to 20% and kd-restar t by 100%. We also present a Hybrid Kd-Jump, which utilizes a volume stepper for leaf testing and a run-time depth threshold to define where kd-tree traversal stops and volume-stepping occurs. By using both methods, we gain the benefits of empty space removal, fast texture-caching and realtime ability to determine the best threshold for current isosurface and view direction.\\\",\\\"Authors\\\":\\\"Hughes, D.M.;Ik Soo Lim\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;IsosurfaceAndSurfaceExtractionTechniques;ParallelSystemsAndParallelProcessing;RaytracingRaycasting;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.161\\\",\\\"Keywords\\\":\\\"raytracing;volume visualization;gpu;isosurface;parallel computing\\\",\\\"Keywords_Processed\\\":\\\"parallel computing;isosurface;volume visualization;gpu;raytrace\\\",\\\"Title\\\":\\\"Kd-Jump: a Path-Preserving Stackless Traversal for Faster Isosurface Raytracing on GPUs\\\"},\\\"633\\\":{\\\"Abstract\\\":\\\"This paper introduces an efficient algorithm for computing the Reeb graph of a scalar function f defined on a volumetric mesh M in Ropf3. We introduce a procedure called \\\\\\\"loop surgery\\\\\\\" that transforms M into a mesh M' by a sequence of cuts and guarantees the Reeb graph of f(M') to be loop free. Therefore, loop surgery reduces Reeb graph computation to the simpler problem of computing a contour tree, for which well-known algorithms exist that are theoretically efficient (O(n log n)) and fast in practice. Inverse cuts reconstruct the loops removed at the beginning. The time complexity of our algorithm is that of a contour tree computation plus a loop surgery overhead, which depends on the number of handles of the mesh. Our systematic experiments confirm that for real-life data, this overhead is comparable to the computation of the contour tree, demonstrating virtually linear scalability on meshes ranging from 70 thousand to 3.5 million tetrahedra. Performance numbers show that our algorithm, although restricted to volumetric data, has an average speedup factor of 6,500 over the previous fastest techniques, handling larger and more complex data-sets. We demonstrate the verstility of our approach by extending fast topologically clean isosurface extraction to non simply-connected domains. We apply this technique in the context of pressure analysis for mechanical design. In this case, our technique produces results in matter of seconds even for the largest meshes. For the same models, previous Reeb graph techniques do not produce a result.\\\",\\\"Authors\\\":\\\"Tierny, J.;Gyulassy, A.;Simon, E.;Pascucci, V.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;ScalarFieldDataTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.163\\\",\\\"Keywords\\\":\\\"isosurface;reeb graph;scalar field topology;topological simplification\\\",\\\"Keywords_Processed\\\":\\\"reeb graph;scalar field topology;topological simplification;isosurface\\\",\\\"Title\\\":\\\"Loop surgery for volumetric meshes: Reeb graphs reduced to contour trees\\\"},\\\"634\\\":{\\\"Abstract\\\":\\\"Medical volumetric imaging requires high fidelity, high performance rendering algorithms. We motivate and analyze new volumetric rendering algorithms that are suited to modern parallel processing architectures. First, we describe the three major categories of volume rendering algorithms and confirm through an imaging scientist-guided evaluation that ray-casting is the most acceptable. We describe a thread- and data-parallel implementation of ray-casting that makes it amenable to key architectural trends of three modern commodity parallel architectures: multi-core, GPU, and an upcoming many-core Intelreg architecture code-named Larrabee. We achieve more than an order of magnitude performance improvement on a number of large 3D medical datasets. We further describe a data compression scheme that significantly reduces data-transfer overhead. This allows our approach to scale well to large numbers of Larrabee cores.\\\",\\\"Authors\\\":\\\"Smelyanskiy, M.;Holmes, D.;Chhugani, J.;Larson, A.;Carmean, D.M.;Hanson, D.;Dubey, P.;Augustine, K.;Daehyun Kim;Kyker, A.;Lee, V.W.;Nguyen, A.D.;Seiler, L.;Robb, R.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;GpuBasedTechniques;InputAndOutputDevicesGeneral;MultiCoreProcessing;ParallelSystemsAndParallelProcessing;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.164\\\",\\\"Keywords\\\":\\\"volume compositing;gpgpu;many-core computing;graphics architecture;parallel processing;medical imaging\\\",\\\"Keywords_Processed\\\":\\\"graphic architecture;medical imaging;gpgpu;many core computing;volume compositing;parallel processing\\\",\\\"Title\\\":\\\"Mapping High-fidelity Volume Rendering for Medical Imaging to CPU, GPU and Many-Core Architectures\\\"},\\\"635\\\":{\\\"Abstract\\\":\\\"In this paper, we present the first algorithm to geometrically register multiple projectors in a view-independent manner (i.e. wallpapered) on a common type of curved surface, vertically extruded surface, using an uncalibrated camera without attaching any obtrusive markers to the display screen. Further, it can also tolerate large non-linear geometric distortions in the projectors as is common when mounting short throw lenses to allow a compact set-up. Our registration achieves sub-pixel accuracy on a large number of different vertically extruded surfaces and the image correction to achieve this registration can be run in real time on the GPU. This simple markerless registration has the potential to have a large impact on easy set-up and maintenance of large curved multi-projector displays, common for visualization, edutainment, training and simulation applications.\\\",\\\"Authors\\\":\\\"Sajadi, B.;Majumder, A.\\\",\\\"Clusters\\\":\\\"DataRegistrationFusionAndIntegration;DisplaysGeneral;LargeAndHighResDisplays\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.166\\\",\\\"Keywords\\\":\\\"calibration;multi-projector displays;tiled displays;registration\\\",\\\"Keywords_Processed\\\":\\\"registration;multi projector display;calibration;tile display\\\",\\\"Title\\\":\\\"Markerless View-Independent Registration of Multiple Distorted Projectors on Extruded Surfaces Using an Uncalibrated Camera\\\"},\\\"636\\\":{\\\"Abstract\\\":\\\"Local shape descriptors compactly characterize regions of a surface, and have been applied to tasks in visualization, shape matching, and analysis. Classically, curvature has be used as a shape descriptor; however, this differential property characterizes only an infinitesimal neighborhood. In this paper, we provide shape descriptors for surface meshes designed to be multi-scale, that is, capable of characterizing regions of varying size. These descriptors capture statistically the shape of a neighborhood around a central point by fitting a quadratic surface. They therefore mimic differential curvature, are efficient to compute, and encode anisotropy. We show how simple variants of mesh operations can be used to compute the descriptors without resorting to expensive parameterizations, and additionally provide a statistical approximation for reduced computational cost. We show how these descriptors apply to a number of uses in visualization, analysis, and matching of surfaces, particularly to tasks in protein surface analysis.\\\",\\\"Authors\\\":\\\"Cipriano, G.;Phillips, G.N.;Gleicher, M.\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;DataFeaturesAndAttributes;IllustrativeVisualization;ShapeRelatedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.168\\\",\\\"Keywords\\\":\\\"stylized rendering;non-photorealistic rendering;descriptors;shape matching;curvature\\\",\\\"Keywords_Processed\\\":\\\"non photorealistic rendering;shape matching;descriptor;curvature;stylize render\\\",\\\"Title\\\":\\\"Multi-Scale Surface Descriptors\\\"},\\\"637\\\":{\\\"Abstract\\\":\\\"In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.\\\",\\\"Authors\\\":\\\"Ropinski, T.;Hermann, S.;Reich, R.;Schafers, M.;Hinrichs, K.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;MultimodalDataTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.169\\\",\\\"Keywords\\\":\\\"multimodal curved planar reformation;vessel visualization;plaque growth;vessel flattening\\\",\\\"Keywords_Processed\\\":\\\"multimodal curve planar reformation;vessel visualization;plaque growth;vessel flattening\\\",\\\"Title\\\":\\\"Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans\\\"},\\\"638\\\":{\\\"Abstract\\\":\\\"Fiber tracking of diffusion tensor imaging (DTI) data offers a unique insight into the three-dimensional organisation of white matter structures in the living brain. However, fiber tracking algorithms require a number of user-defined input parameters that strongly affect the output results. Usually the fiber tracking parameters are set once and are then re-used for several patient datasets. However, the stability of the chosen parameters is not evaluated and a small change in the parameter values can give very different results. The user remains completely unaware of such effects. Furthermore, it is difficult to reproduce output results between different users. We propose a visualization tool that allows the user to visually explore how small variations in parameter values affect the output of fiber tracking. With this knowledge the user cannot only assess the stability of commonly used parameter values but also evaluate in a more reliable way the output results between different patients. Existing tools do not provide such information. A small user evaluation of our tool has been done to show the potential of the technique.\\\",\\\"Authors\\\":\\\"Brecheisen, R.;Vilanova, A.;Platel, B.;ter Haar Romenij, B.\\\",\\\"Clusters\\\":\\\"Parameterization;ProgrammingAlgorithmsAndDataStructures;TensorDataAndTechniques;Tractography;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.170\\\",\\\"Keywords\\\":\\\"parameter sensitivity;uncertainty visualization;fiber tracking;diffusion tensor imaging;stopping criteria\\\",\\\"Keywords_Processed\\\":\\\"fiber tracking;diffusion tensor imaging;paramet sensitivity;uncertainty visualization;stop criterion\\\",\\\"Title\\\":\\\"Parameter Sensitivity Visualization for DTI fiber Tracking\\\"},\\\"639\\\":{\\\"Abstract\\\":\\\"The semi-transparent nature of direct volume rendered images is useful to depict layered structures in a volume. However, obtaining a semi-transparent result with the layers clearly revealed is difficult and may involve tedious adjustment on opacity and other rendering parameters. Furthermore, the visual quality of layers also depends on various perceptual factors. In this paper, we propose an auto-correction method for enhancing the perceived quality of the semi-transparent layers in direct volume rendered images. We introduce a suite of new measures based on psychological principles to evaluate the perceptual quality of transparent structures in the rendered images. By optimizing rendering parameters within an adaptive and intuitive user interaction process, the quality of the images is enhanced such that specific user requirements can be met. Experimental results on various datasets demonstrate the effectiveness and robustness of our method.\\\",\\\"Authors\\\":\\\"Ming-Yuen Chan;Yingcai Wu;Wai-Ho Mak;Wei Chen;Huamin Qu\\\",\\\"Clusters\\\":\\\"ImageBasedDataImageSignalProcessing;Perception;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.172\\\",\\\"Keywords\\\":\\\"direct volume rendering;layer perception;image enhancement\\\",\\\"Keywords_Processed\\\":\\\"image enhancement;layer perception;direct volume render\\\",\\\"Title\\\":\\\"Perception-Based Transparency Optimization for Direct Volume Rendering\\\"},\\\"640\\\":{\\\"Abstract\\\":\\\"In this paper we present a method for vortex core line extraction which operates directly on the smoothed particle hydrodynamics (SPH) representation and, by this, generates smoother and more (spatially and temporally) coherent results in an efficient way. The underlying predictor-corrector scheme is general enough to be applied to other line-type features and it is extendable to the extraction of surfaces such as isosurfaces or Lagrangian coherent structures. The proposed method exploits temporal coherence to speed up computation for subsequent time steps. We show how the predictor-corrector formulation can be specialized for several variants of vortex core line definitions including two recent unsteady extensions, and we contribute a theoretical and practical comparison of these. In particular, we reveal a close relation between unsteady extensions of Fuchs et al. and Weinkauf et al. and we give a proof of the Galilean invariance of the latter. When visualizing SPH data, there is the possibility to use the same interpolation method for visualization as has been used for the simulation. This is different from the case of finite volume simulation results, where it is not possible to recover from the results the spatial interpolation that was used during the simulation. Such data are typically interpolated using the basic trilinear interpolant, and if smoothness is required, some artificial processing is added. In SPH data, however, the smoothing kernels are specified from the simulation, and they provide an exact and smooth interpolation of data or gradients at arbitrary points in the domain.\\\",\\\"Authors\\\":\\\"Schindler, B.;Fuchs, R.;Biddiscombe, J.;Peikert, R.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;ParticleVisualizationAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.173\\\",\\\"Keywords\\\":\\\"flow visualization;unsteady flow;smoothed particle hydrodynamics;feature extraction;vortex core lines\\\",\\\"Keywords_Processed\\\":\\\"unsteady flow;vortex core line;feature extraction;smoothed particle hydrodynamic;flow visualization\\\",\\\"Title\\\":\\\"Predictor-Corrector Schemes for Visualization ofSmoothed Particle Hydrodynamics Data\\\"},\\\"641\\\":{\\\"Abstract\\\":\\\"Representing bivariate scalar maps is a common but difficult visualization problem. One solution has been to use two dimensional color schemes, but the results are often hard to interpret and inaccurately read. An alternative is to use a color sequence for one variable and a texture sequence for another. This has been used, for example, in geology, but much less studied than the two dimensional color scheme, although theory suggests that it should lead to easier perceptual separation of information relating to the two variables. To make a texture sequence more clearly readable the concept of the quantitative texton sequence (QTonS) is introduced. A QTonS is defined a sequence of small graphical elements, called textons, where each texton represents a different numerical value and sets of textons can be densely displayed to produce visually differentiable textures. An experiment was carried out to compare two bivariate color coding schemes with two schemes using QTonS for one bivariate map component and a color sequence for the other. Two different key designs were investigated (a key being a sequence of colors or textures used in obtaining quantitative values from a map). The first design used two separate keys, one for each dimension, in order to measure how accurately subjects could independently estimate the underlying scalar variables. The second key design was two dimensional and intended to measure the overall integral accuracy that could be obtained. The results show that the accuracy is substantially higher for the QTonS/color sequence schemes. A hypothesis that texture/color sequence combinations are better for independent judgments of mapped quantities was supported. A second experiment probed the limits of spatial resolution for QTonSs.\\\",\\\"Authors\\\":\\\"Ware, C.\\\",\\\"Clusters\\\":\\\"EvaluationMetricsAndBenchmarks;GlyphsGlyphBasedTechniques;Maps;Perception;Textures\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.175\\\",\\\"Keywords\\\":\\\"qtons;legibility;bivariate maps;texton;quantitative texton sequence;texture\\\",\\\"Keywords_Processed\\\":\\\"bivariate map;legibility;texton;texture;qton;quantitative texton sequence\\\",\\\"Title\\\":\\\"Quantitative Texton Sequences for Legible Bivariate Maps\\\"},\\\"642\\\":{\\\"Abstract\\\":\\\"Particle systems have gained importance as a methodology for sampling implicit surfaces and segmented objects to improve mesh generation and shape analysis. We propose that particle systems have a significantly more general role in sampling structure from unsegmented data. We describe a particle system that computes samplings of crease features (i.e. ridges and valleys, as lines or surfaces) that effectively represent many anatomical structures in scanned medical data. Because structure naturally exists at a range of sizes relative to the image resolution, computer vision has developed the theory of scale-space, which considers an n-D image as an (n + 1)-D stack of images at different blurring levels. Our scale-space particles move through continuous four-dimensional scale-space according to spatial constraints imposed by the crease features, a particle-image energy that draws particles towards scales of maximal feature strength, and an inter-particle energy that controls sampling density in space and scale. To make scale-space practical for large three-dimensional data, we present a spline-based interpolation across scale from a small number of pre-computed blurrings at optimally selected scales. The configuration of the particle system is visualized with tensor glyphs that display information about the local Hessian of the image, and the scale of the particle. We use scale-space particles to sample the complex three-dimensional branching structure of airways in lung CT, and the major white matter structures in brain DTI.\\\",\\\"Authors\\\":\\\"Kindlmann, G.;Estepar, R.S.J.;Smith, S.;Westin, C.-F.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;ContourCreasesRidgesValleys;ParticleVisualizationAndTechniques;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.177\\\",\\\"Keywords\\\":\\\"lung ct;crease features;ridge and valley detection;diffusion tensor mri;particle systems\\\",\\\"Keywords_Processed\\\":\\\"particle system;diffusion tensor mri;crease feature;lung ct;ridge and valley detection\\\",\\\"Title\\\":\\\"Sampling and Visualizing Creases with Scale-Space Particles\\\"},\\\"643\\\":{\\\"Abstract\\\":\\\"Recent advances in scanning technology provide high resolution EM (electron microscopy) datasets that allow neuro-scientists to reconstruct complex neural connections in a nervous system. However, due to the enormous size and complexity of the resulting data, segmentation and visualization of neural processes in EM data is usually a difficult and very time-consuming task. In this paper, we present NeuroTrace, a novel EM volume segmentation and visualization system that consists of two parts: a semi-automatic multiphase level set segmentation with 3D tracking for reconstruction of neural processes, and a specialized volume rendering approach for visualization of EM volumes. It employs view-dependent on-demand filtering and evaluation of a local histogram edge metric, as well as on-the-fly interpolation and ray-casting of implicit surfaces for segmented neural structures. Both methods are implemented on the GPU for interactive performance. NeuroTrace is designed to be scalable to large datasets and data-parallel hardware architectures. A comparison of NeuroTrace with a commonly used manual EM segmentation tool shows that our interactive workflow is faster and easier to use for the reconstruction of complex neural processes.\\\",\\\"Authors\\\":\\\"Jeong, W.-K.;Beyer, J.;Hadwiger, M.;Vazquez, A.;Pfister, H.;Whitaker, R.T.\\\",\\\"Clusters\\\":\\\"InputAndOutputDevicesGeneral;NeurosciencesAndBrainVisualization;SegmentationAndClassification;SurfaceRelatedDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.178\\\",\\\"Keywords\\\":\\\"volume rendering;neuroscience;graphics hardware;implicit surface rendering;segmentation;connectome\\\",\\\"Keywords_Processed\\\":\\\"volume render;implicit surface render;neuroscience;segmentation;graphic hardware;connectome\\\",\\\"Title\\\":\\\"Scalable and Interactive Segmentation and Visualization of Neural Processes in EM Datasets\\\"},\\\"644\\\":{\\\"Abstract\\\":\\\"We demonstrate the application of advanced 3D visualization techniques to determine the optimal implant design and position in hip joint replacement planning. Our methods take as input the physiological stress distribution inside a patient's bone under load and the stress distribution inside this bone under the same load after a simulated replacement surgery. The visualization aims at showing principal stress directions and magnitudes, as well as differences in both distributions. By visualizing changes of normal and shear stresses with respect to the principal stress directions of the physiological state, a comparative analysis of the physiological stress distribution and the stress distribution with implant is provided, and the implant parameters that most closely replicate the physiological stress state in order to avoid stress shielding can be determined. Our method combines volume rendering for the visualization of stress magnitudes with the tracing of short line segments for the visualization of stress directions. To improve depth perception, transparent, shaded, and antialiased lines are rendered in correct visibility order, and they are attenuated by the volume rendering. We use a focus+context approach to visually guide the user to relevant regions in the data, and to support a detailed stress analysis in these regions while preserving spatial context information. Since all of our techniques have been realized on the GPU, they can immediately react to changes in the simulated stress tensor field and thus provide an effective means for optimal implant selection and positioning in a computational steering environment.\\\",\\\"Authors\\\":\\\"Dick, C.;Georgii, J.;Burgkart, R.;Westermann, R.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;ComparisonComparativeVisualizationAndSimilarity;GpuBasedTechniques;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.184\\\",\\\"Keywords\\\":\\\"implant planning;biomedical visualization;stress tensor fields;comparative visualization;gpu techniques\\\",\\\"Keywords_Processed\\\":\\\"stress tensor field;comparative visualization;biomedical visualization;gpu technique;implant planning\\\",\\\"Title\\\":\\\"Stress Tensor field Visualization for Implant Planning in Orthopedics\\\"},\\\"645\\\":{\\\"Abstract\\\":\\\"The use of multi-dimensional transfer functions for direct volume rendering has been shown to be an effective means of extracting materials and their boundaries for both scalar and multivariate data. The most common multi-dimensional transfer function consists of a two-dimensional (2D) histogram with axes representing a subset of the feature space (e.g., value vs. value gradient magnitude), with each entry in the 2D histogram being the number of voxels at a given feature space pair. Users then assign color and opacity to the voxel distributions within the given feature space through the use of interactive widgets (e.g., box, circular, triangular selection). Unfortunately, such tools lead users through a trial-and-error approach as they assess which data values within the feature space map to a given area of interest within the volumetric space. In this work, we propose the addition of non-parametric clustering within the transfer function feature space in order to extract patterns and guide transfer function generation. We apply a non-parametric kernel density estimation to group voxels of similar features within the 2D histogram. These groups are then binned and colored based on their estimated density, and the user may interactively grow and shrink the binned regions to explore feature boundaries and extract regions of interest. We also extend this scheme to temporal volumetric data in which time steps of 2D histograms are composited into a histogram volume. A three-dimensional (3D) density estimation is then applied, and users can explore regions within the feature space across time without adjusting the transfer function at each time step. Our work enables users to effectively explore the structures found within a feature space of the volume and provide a context in which the user can understand how these structures relate to their volumetric data. We provide tools for enhanced exploration and manipulation of the transfer function, and we show that the initial t ransfer function generation serves as a reasonable base for volumetric rendering, reducing the trial-and-error overhead typically found in transfer function design.\\\",\\\"Authors\\\":\\\"Maciejewski, R.;Insoo Woo;Wei Chen;Ebert, D.S.\\\",\\\"Clusters\\\":\\\"MachineLearningAndStatistics;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.185\\\",\\\"Keywords\\\":\\\"kernel density estimation;volume rendering;transfer function design;temporal volume rendering\\\",\\\"Keywords_Processed\\\":\\\"volume render;transfer function design;kernel density estimation;temporal volume render\\\",\\\"Title\\\":\\\"Structuring Feature Space: A Non-Parametric Method for Volumetric Transfer Function Generation\\\"},\\\"646\\\":{\\\"Abstract\\\":\\\"Volumetric datasets are often modeled using a multiresolution approach based on a nested decomposition of the domain into a polyhedral mesh. Nested tetrahedral meshes generated through the longest edge bisection rule are commonly used to decompose regular volumetric datasets since they produce highly adaptive crack-free representations. Efficient representations for such models have been achieved by clustering the set of tetrahedra sharing a common longest edge into a structure called a diamond. The alignment and orientation of the longest edge can be used to implicitly determine the geometry of a diamond and its relations to the other diamonds within the hierarchy. We introduce the supercube as a high-level primitive within such meshes that encompasses all unique types of diamonds. A supercube is a coherent set of edges corresponding to three consecutive levels of subdivision. Diamonds are uniquely characterized by the longest edge of the tetrahedra forming them and are clustered in supercubes through the association of the longest edge of a diamond with a unique edge in a supercube. Supercubes are thus a compact and highly efficient means of associating information with a subset of the vertices, edges and tetrahedra of the meshes generated through longest edge bisection. We demonstrate the effectiveness of the supercube representation when encoding multiresolution diamond hierarchies built on a subset of the points of a regular grid. We also show how supercubes can be used to efficiently extract meshes from diamond hierarchies and to reduce the storage requirements of such variable-resolution meshes.\\\",\\\"Authors\\\":\\\"Weiss, K.;De Floriani, L.\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;GeometricModeling;HierarchicalTreeDataAndTechniques;MaterialScience;MultiresolutionTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.186\\\",\\\"Keywords\\\":\\\"longest edge bisection;multi-resolution model;diamonds;hierarchy of diamonds;selective refinement\\\",\\\"Keywords_Processed\\\":\\\"selective refinement;diamond;long edge bisection;hierarchy of diamond;multi resolution model\\\",\\\"Title\\\":\\\"Supercubes: A High-Level Primitive for Diamond Hierarchies\\\"},\\\"647\\\":{\\\"Abstract\\\":\\\"Despite the ever-growing improvements on graphics processing units and computational power, classifying 3D volume data remains a challenge.In this paper, we present a new method for classifying volume data based on the ambient occlusion of voxels. This information stems from the observation that most volumes of a certain type, e.g., CT, MRI or flow simulation, contain occlusion patterns that reveal the spatial structure of their materials or features. Furthermore, these patterns appear to emerge consistently for different data sets of the same type. We call this collection of patterns the occlusion spectrum of a dataset. We show that using this occlusion spectrum leads to better two-dimensional transfer functions that can help classify complex data sets in terms of the spatial relationships among features. In general, the ambient occlusion of a voxel can be interpreted as a weighted average of the intensities in a spherical neighborhood around the voxel. Different weighting schemes determine the ability to separate structures of interest in the occlusion spectrum. We present a general methodology for finding such a weighting. We show results of our approach in 3D imaging for different applications, including brain and breast tumor detection and the visualization of turbulent flow.\\\",\\\"Authors\\\":\\\"Correa, C.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"Illumination;SegmentationAndClassification;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.189\\\",\\\"Keywords\\\":\\\"ambient occlusion;volume rendering;transfer function;interactive classification\\\",\\\"Keywords_Processed\\\":\\\"ambient occlusion;volume render;interactive classification;transfer function\\\",\\\"Title\\\":\\\"The Occlusion Spectrum for Volume Classification and Visualization\\\"},\\\"648\\\":{\\\"Abstract\\\":\\\"Time and streak surfaces are ideal tools to illustrate time-varying vector fields since they directly appeal to the intuition about coherently moving particles. However, efficient generation of high-quality time and streak surfaces for complex, large and time-varying vector field data has been elusive due to the computational effort involved. In this work, we propose a novel algorithm for computing such surfaces. Our approach is based on a decoupling of surface advection and surface adaptation and yields improved efficiency over other surface tracking methods, and allows us to leverage inherent parallelization opportunities in the surface advection, resulting in more rapid parallel computation. Moreover, we obtain as a result of our algorithm the entire evolution of a time or streak surface in a compact representation, allowing for interactive, high-quality rendering, visualization and exploration of the evolving surface. Finally, we discuss a number of ways to improve surface depiction through advanced rendering and texturing, while preserving interactivity, and provide a number of examples for real-world datasets and analyze the behavior of our algorithm on them.\\\",\\\"Authors\\\":\\\"Krishnan, H.;Garth, C.;Joy, K.I.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;IsosurfaceAndSurfaceExtractionTechniques;SurfaceRelatedDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.190\\\",\\\"Keywords\\\":\\\"flow visualization;surface extraction;time-varying;time and streak surfaces;3d vector field visualization\\\",\\\"Keywords_Processed\\\":\\\"time vary;time and streak surface;3d vector field visualization;surface extraction;flow visualization\\\",\\\"Title\\\":\\\"Time and Streak Surfaces for Flow Visualization in Large Time-Varying Data Sets\\\"},\\\"649\\\":{\\\"Abstract\\\":\\\"Visual representations of isosurfaces are ubiquitous in the scientific and engineering literature. In this paper, we present techniques to assess the behavior of isosurface extraction codes. Where applicable, these techniques allow us to distinguish whether anomalies in isosurface features can be attributed to the underlying physical process or to artifacts from the extraction process. Such scientific scrutiny is at the heart of verifiable visualization - subjecting visualization algorithms to the same verification process that is used in other components of the scientific pipeline. More concretely, we derive formulas for the expected order of accuracy (or convergence rate) of several isosurface features, and compare them to experimentally observed results in the selected codes. This technique is practical: in two cases, it exposed actual problems in implementations. We provide the reader with the range of responses they can expect to encounter with isosurface techniques, both under ldquonormal operating conditionsrdquo and also under adverse conditions. Armed with this information - the results of the verification process - practitioners can judiciously select the isosurface extraction technique appropriate for their problem of interest, and have confidence in its behavior.\\\",\\\"Authors\\\":\\\"Etiene, T.;Scheidegger, C.E.;Nonato, L.G.;Kirby, R.M.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.194\\\",\\\"Keywords\\\":\\\"isosurface extraction;verification;verification and validation;marching cubes\\\",\\\"Keywords_Processed\\\":\\\"march cube;verification;isosurface extraction;verification and validation\\\",\\\"Title\\\":\\\"Verifiable Visualization for Isosurface Extraction\\\"},\\\"650\\\":{\\\"Abstract\\\":\\\"Visualization is essential for understanding the increasing volumes of digital data. However, the process required to create insightful visualizations is involved and time consuming. Although several visualization tools are available, including tools with sophisticated visual interfaces, they are out of reach for users who have little or no knowledge of visualization techniques and/or who do not have programming expertise. In this paper, we propose VisMashup, a new framework for streamlining the creation of customized visualization applications. Because these applications can be customized for very specific tasks, they can hide much of the complexity in a visualization specification and make it easier for users to explore visualizations by manipulating a small set of parameters. We describe the framework and how it supports the various tasks a designer needs to carry out to develop an application, from mining and exploring a set of visualization specifications (pipelines), to the creation of simplified views of the pipelines, and the automatic generation of the application and its interface. We also describe the implementation of the system and demonstrate its use in two real application scenarios.\\\",\\\"Authors\\\":\\\"Santos, E.;Lins, L.;Ahrens, J.;Freire, J.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"DataAcquisitionAndManagement;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.195\\\",\\\"Keywords\\\":\\\"scientific visualization;visualization systems;data-flow\\\",\\\"Keywords_Processed\\\":\\\"scientific visualization;visualization system;datum flow\\\",\\\"Title\\\":\\\"VisMashup: Streamlining the Creation of Custom Visualization Applications\\\"},\\\"651\\\":{\\\"Abstract\\\":\\\"Due to its nonlinear nature, the climate system shows quite high natural variability on different time scales, including multiyear oscillations such as the El Nino southern oscillation phenomenon. Beside a shift of the mean states and of extreme values of climate variables, climate change may also change the frequency or the spatial patterns of these natural climate variations. Wavelet analysis is a well established tool to investigate variability in the frequency domain. However, due to the size and complexity of the analysis results, only few time series are commonly analyzed concurrently. In this paper we will explore different techniques to visually assist the user in the analysis of variability and variability changes to allow for a holistic analysis of a global climate model data set consisting of several variables and extending over 250 years. Our new framework and data from the IPCC AR4 simulations with the coupled climate model ECHAM5/MPI-OM are used to explore the temporal evolution of El Nino due to climate change.\\\",\\\"Authors\\\":\\\"Jnicke, H.;Bottinger, M.;Mikolajewicz, U.;Scheuermann, G.\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;MultidimensionalMultivariateMultifieldDataAndTechniques;NumericalMethodsMathematics;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.197\\\",\\\"Keywords\\\":\\\"el nino;time-dependent data;wavelet analysis;climate variability change visualization;multivariate data\\\",\\\"Keywords_Processed\\\":\\\"multivariate datum;wavelet analysis;time dependent datum;climate variability change visualization;el nino\\\",\\\"Title\\\":\\\"Visual Exploration of Climate Variability Changes Using Wavelet Analysis\\\"},\\\"652\\\":{\\\"Abstract\\\":\\\"Rhinologists are often faced with the challenge of assessing nasal breathing from a functional point of view to derive effective therapeutic interventions. While the complex nasal anatomy can be revealed by visual inspection and medical imaging, only vague information is available regarding the nasal airflow itself: Rhinomanometry delivers rather unspecific integral information on the pressure gradient as well as on total flow and nasal flow resistance. In this article we demonstrate how the understanding of physiological nasal breathing can be improved by simulating and visually analyzing nasal airflow, based on an anatomically correct model of the upper human respiratory tract. In particular we demonstrate how various information visualization (InfoVis) techniques, such as a highly scalable implementation of parallel coordinates, time series visualizations, as well as unstructured grid multi-volume rendering, all integrated within a multiple linked views framework, can be utilized to gain a deeper understanding of nasal breathing. Evaluation is accomplished by visual exploration of spatio-temporal airflow characteristics that include not only information on flow features but also on accompanying quantities such as temperature and humidity. To our knowledge, this is the first in-depth visual exploration of the physiological function of the nose over several simulated breathing cycles under consideration of a complete model of the nasal airways, realistic boundary conditions, and all physically relevant time-varying quantities.\\\",\\\"Authors\\\":\\\"Zachow, S.;Muigg, P.;Hildebrandt, T.;Doleisch, H.;Hege, H.-C.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;FlowVisualizationDataAndTechniques;InteractionTechniquesGeneral;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.198\\\",\\\"Keywords\\\":\\\"flow visualization;exploratory data analysis;interactive visual analysis of scientific data;time-dependent data\\\",\\\"Keywords_Processed\\\":\\\"time dependent datum;exploratory datum analysis;interactive visual analysis of scientific datum;flow visualization\\\",\\\"Title\\\":\\\"Visual Exploration of Nasal Airflow\\\"},\\\"653\\\":{\\\"Abstract\\\":\\\"In this paper we describe a novel method to integrate interactive visual analysis and machine learning to support the insight generation of the user. The suggested approach combines the vast search and processing power of the computer with the superior reasoning and pattern recognition capabilities of the human user. An evolutionary search algorithm has been adapted to assist in the fuzzy logic formalization of hypotheses that aim at explaining features inside multivariate, volumetric data. Up to now, users solely rely on their knowledge and expertise when looking for explanatory theories. However, it often remains unclear whether the selected attribute ranges represent the real explanation for the feature of interest. Other selections hidden in the large number of data variables could potentially lead to similar features. Moreover, as simulation complexity grows, users are confronted with huge multidimensional data sets making it almost impossible to find meaningful hypotheses at all. We propose an interactive cycle of knowledge-based analysis and automatic hypothesis generation. Starting from initial hypotheses, created with linking and brushing, the user steers a heuristic search algorithm to look for alternative or related hypotheses. The results are analyzed in information visualization views that are linked to the volume rendering. Individual properties as well as global aggregates are visually presented to provide insight into the most relevant aspects of the generated hypotheses. This novel approach becomes computationally feasible due to a GPU implementation of the time-critical parts in the algorithm. A thorough evaluation of search times and noise sensitivity as well as a case study on data from the automotive domain substantiate the usefulness of the suggested approach.\\\",\\\"Authors\\\":\\\"Fuchs, R.;Waser, J.;Groller, E.\\\",\\\"Clusters\\\":\\\"Genetics;HypothesisFormingTestingAndVisualEvidence;InteractionTechniquesGeneral;KnowledgeDiscovery;MultidimensionalMultivariateMultifieldDataAndTechniques;VisualAnalysisModels;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.199\\\",\\\"Keywords\\\":\\\"interactive visual analysis;genetic algorithm;knowledge discovery;predictive analysis;volumetric data;curse of dimensionality;computer-assisted multi-variate data exploration;multiple competing hypotheses\\\",\\\"Keywords_Processed\\\":\\\"computer assist multi variate datum exploration;multiple compete hypothesis;knowledge discovery;predictive analysis;curse of dimensionality;volumetric datum;genetic algorithm;interactive visual analysis\\\",\\\"Title\\\":\\\"Visual Human+Machine Learning\\\"},\\\"654\\\":{\\\"Abstract\\\":\\\"We present a new algorithm to explore and visualize multivariate time-varying data sets. We identify important trend relationships among the variables based on how the values of the variables change over time and how those changes are related to each other in different spatial regions and time intervals. The trend relationships can be used to describe the correlation and causal effects among the different variables. To identify the temporal trends from a local region, we design a new algorithm called SUBDTW to estimate when a trend appears and vanishes in a given time series. Based on the beginning and ending times of the trends, their temporal relationships can be modeled as a state machine representing the trend sequence. Since a scientific data set usually contains millions of data points, we propose an algorithm to extract important trend relationships in linear time complexity. We design novel user interfaces to explore the trend relationships, to visualize their temporal characteristics, and to display their spatial distributions. We use several scientific data sets to test our algorithm and demonstrate its utilities.\\\",\\\"Authors\\\":\\\"Teng-Yok Lee;Han-Wei Shen\\\",\\\"Clusters\\\":\\\"EventsTrendsOutlierDetectionAnalysisAndVisualization;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.200\\\",\\\"Keywords\\\":\\\"subdtw;trend sequence clustering;trend sequence\\\",\\\"Keywords_Processed\\\":\\\"subdtw;trend sequence;trend sequence clustering\\\",\\\"Title\\\":\\\"Visualization and Exploration of Temporal Trend Relationships in Multivariate Time-Varying Data\\\"},\\\"655\\\":{\\\"Abstract\\\":\\\"Medical illustration has demonstrated its effectiveness to depict salient anatomical features while hiding the irrelevant details. Current solutions are ineffective for visualizing fibrous structures such as muscle, because typical datasets (CT or MRI) do not contain directional details. In this paper, we introduce a new muscle illustration approach that leverages diffusion tensor imaging (DTI) data and example-based texture synthesis techniques. Beginning with a volumetric diffusion tensor image, we reformulate it into a scalar field and an auxiliary guidance vector field to represent the structure and orientation of a muscle bundle. A muscle mask derived from the input diffusion tensor image is used to classify the muscle structure. The guidance vector field is further refined to remove noise and clarify structure. To simulate the internal appearance of the muscle, we propose a new two-dimensional example based solid texture synthesis algorithm that builds a solid texture constrained by the guidance vector field. Illustrating the constructed scalar field and solid texture efficiently highlights the global appearance of the muscle as well as the local shape and structure of the muscle fibers in an illustrative fashion. We have applied the proposed approach to five example datasets (four pig hearts and a pig leg), demonstrating plausible illustration and expressiveness.\\\",\\\"Authors\\\":\\\"Wei Chen;Zhicheng Yan;Song Zhang;Crow, J.A.;Ebert, D.S.;McLaughlin, R.M.;Mullins, K.B.;Cooper, R.;Zi'ang Ding;Jun Liao\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;IllustrativeVisualization;TensorDataAndTechniques;Textures\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.203\\\",\\\"Keywords\\\":\\\"solid texture synthesis;muscle;illustrative visualization;diffusion tensor imaging\\\",\\\"Keywords_Processed\\\":\\\"muscle;illustrative visualization;diffusion tensor imaging;solid texture synthesis\\\",\\\"Title\\\":\\\"Volume Illustration of Muscle from Diffusion Tensor Images\\\"},\\\"656\\\":{\\\"Abstract\\\":\\\"Direct volume rendering and isosurfacing are ubiquitous rendering techniques in scientific visualization, commonly employed in imaging 3D data from simulation and scan sources. Conventionally, these methods have been treated as separate modalities, necessitating different sampling strategies and rendering algorithms. In reality, an isosurface is a special case of a transfer function, namely a Dirac impulse at a given isovalue. However, artifact-free rendering of discrete isosurfaces in a volume rendering framework is an elusive goal, requiring either infinite sampling or smoothing of the transfer function. While preintegration approaches solve the most obvious deficiencies in handling sharp transfer functions, artifacts can still result, limiting classification. In this paper, we introduce a method for rendering such features by explicitly solving for isovalues within the volume rendering integral. In addition, we present a sampling strategy inspired by ray differentials that automatically matches the frequency of the image plane, resulting in fewer artifacts near the eye and better overall performance. These techniques exhibit clear advantages over standard uniform ray casting with and without preintegration, and allow for high-quality interactive volume rendering with sharp C0 transfer functions.\\\",\\\"Authors\\\":\\\"Knoll, A.;Hijazi, Y.;Westerteiger, R.;Schott, M.;Hansen, C.;Hagen, H.\\\",\\\"Clusters\\\":\\\"DataRegistrationFusionAndIntegration;IsosurfaceAndSurfaceExtractionTechniques;RaytracingRaycasting;Sampling;ViewDependentVisualization;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2009.204\\\",\\\"Keywords\\\":\\\"transfer function;sampling;direct volume rendering;preintegration;raycasting;isosurface;view-dependent;ray differentials\\\",\\\"Keywords_Processed\\\":\\\"ray differential;preintegration;direct volume render;transfer function;sample;isosurface;raycaste;view dependent\\\",\\\"Title\\\":\\\"Volume Ray Casting with Peak finding and Differential Sampling\\\"},\\\"657\\\":{\\\"Abstract\\\":\\\"One of the most common operations in exploration and analysis of various kinds of data is clustering, i.e. discovery and interpretation of groups of objects having similar properties and/or behaviors. In clustering, objects are often treated as points in multi-dimensional space of properties. However, structurally complex objects, such as trajectories of moving entities and other kinds of spatio-temporal data, cannot be adequately represented in this manner. Such data require sophisticated and computationally intensive clustering algorithms, which are very hard to scale effectively to large datasets not fitting in the computer main memory. We propose an approach to extracting meaningful clusters from large databases by combining clustering and classification, which are driven by a human analyst through an interactive visual interface.\\\",\\\"Authors\\\":\\\"Andrienko, G.;Andrienko, N.;Rinzivillo, S.;Nanni, M.;Pedreschi, D.;Giannotti, F.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;DataClusteringAndAggregation;GeographyGeospatialVisCartographyTerrainVis;LargeScaleDataAndScalability;SegmentationAndClassification;SpatiotemporalDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5332584\\\",\\\"Keywords\\\":\\\"spatio-temporal data;clustering;classification;scalable visualization;movement data;trajectory;geovisualization\\\",\\\"Keywords_Processed\\\":\\\"spatio temporal datum;trajectory;scalable visualization;geovisualization;clustering;classification;movement datum\\\",\\\"Title\\\":\\\"Interactive visual clustering of large collections of trajectories\\\"},\\\"658\\\":{\\\"Abstract\\\":\\\"The increasing availability of motion sensors and video cameras in living spaces has made possible the analysis of motion patterns and collective behavior in a number of situations. The visualization of this movement data, however, remains a challenge. Although maintaining the actual layout of the data space is often desirable, direct visualization of movement traces becomes cluttered and confusing as the spatial distribution of traces may be disparate and uneven. We present proximity-based visualization as a novel approach to the visualization of movement traces in an abstract space rather than the given spatial layout. This abstract space is obtained by considering proximity data, which is computed as the distance between entities and some number of important locations. These important locations can range from a single fixed point, to a moving point, several points, or even the proximities between the entities themselves. This creates a continuum of proximity spaces, ranging from the fixed absolute reference frame to completely relative reference frames. By combining these abstracted views with the concrete spatial views, we provide a way to mentally map the abstract spaces back to the real space. We demonstrate the effectiveness of this approach, and its applicability to visual analytics problems such as hazard prevention, migration patterns, and behavioral studies.\\\",\\\"Authors\\\":\\\"Crnovrsanin, T.;Muelder, C.;Correa, C.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;DataAndAnalysisMetrics;DimensionalityReduction;MultipleLinkedCoordinatedViews;Perception;SpatiotemporalDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5332593\\\",\\\"Keywords\\\":\\\"spatio-temporal visualization;temporal trajectories;proximity;linked views;movement patterns;principal component analysis\\\",\\\"Keywords_Processed\\\":\\\"temporal trajectory;spatio temporal visualization;proximity;link view;principal component analysis;movement pattern\\\",\\\"Title\\\":\\\"Proximity-based visualization of movement trace data\\\"},\\\"659\\\":{\\\"Abstract\\\":\\\"This paper demonstrates the promise of augmenting interactive multivariate representations with information from statistical processes in the domain of weather data analysis. Statistical regression, correlation analysis, and descriptive statistical calculations are integrated via graphical indicators into an enhanced parallel coordinates system, called the Multidimensional Data eXplorer (MDX). These statistical indicators, which highlight significant associations in the data, are complemented with interactive visual analysis capabilities. The resulting system allows a smooth, interactive, and highly visual workflow. The system's utility is demonstrated with an extensive hurricane climate study that was conducted by a hurricane expert. In the study, the expert used a new data set of environmental weather data, composed of 28 independent variables, to predict annual hurricane activity. MDX shows the Atlantic Meridional Mode increases the explained variance of hurricane seasonal activity by 7-15% and removes less significant variables used in earlier studies. The findings and feedback from the expert (1) validate the utility of the data set for hurricane prediction, and (2) indicate that the integration of statistical processes with interactive parallel coordinates, as implemented in MDX, addresses both deficiencies in traditional weather data analysis and exhibits some of the expected benefits of visual data analysis.\\\",\\\"Authors\\\":\\\"Steed, C.A.;Swan, J.E.;Jankun-Kelly, T.J.;Fitzpatrick, P.J.\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;InteractionTechniquesGeneral;MachineLearningAndStatistics;MultidimensionalMultivariateMultifieldDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5332586\\\",\\\"Keywords\\\":\\\"regression;correlation;visual analytics;multivariate data;climate study;statistical analysis;interaction\\\",\\\"Keywords_Processed\\\":\\\"multivariate datum;interaction;climate study;visual analytic;regression;correlation;statistical analysis\\\",\\\"Title\\\":\\\"Guided analysis of hurricane trends using statistical processes integrated with interactive parallel coordinates\\\"},\\\"660\\\":{\\\"Abstract\\\":\\\"An increasing number of temporal categorical databases are being collected: Electronic Health Records in healthcare organizations, traffic incident logs in transportation systems, or student records in universities. Finding similar records within these large databases requires effective similarity measures that capture the searcher's intent. Many similarity measures exist for numerical time series, but temporal categorical records are different. We propose a temporal categorical similarity measure, the M&M (Match & Mismatch) measure, which is based on the concept of aligning records by sentinel events, then matching events between the target and the compared records. The M&M measure combines the time differences between pairs of events and the number of mismatches. To accom-modate customization of parameters in the M&M measure and results interpretation, we implemented Similan, an interactive search and visualization tool for temporal categorical records. A usability study with 8 participants demonstrated that Similan was easy to learn and enabled them to find similar records, but users had difficulty understanding the M&M measure. The usability study feedback, led to an improved version with a continuous timeline, which was tested in a pilot study with 5 participants.\\\",\\\"Authors\\\":\\\"Wongsuphasawat, K.;Shneiderman, B.\\\",\\\"Clusters\\\":\\\"EvaluationMetricsAndBenchmarks;QueriesAndSearch;TimeseriesTimeVaryingDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5332595\\\",\\\"Keywords\\\":\\\"match & mismatch measure;temporal categorical records;similarity search;similan\\\",\\\"Keywords_Processed\\\":\\\"match mismatch measure;temporal categorical record;similan;similarity search\\\",\\\"Title\\\":\\\"Finding comparable temporal categorical records: A similarity measure with an interactive visualization\\\"},\\\"661\\\":{\\\"Abstract\\\":\\\"Cellular radio networks are continually growing in both node count and complexity. It therefore becomes more difficult to manage the networks and necessary to use time and cost effective automatic algorithms to organize the networks neighbor cell relations. There have been a number of attempts to develop such automatic algorithms. Network operators, however, may not trust them because they need to have an understanding of their behavior and of their reliability and performance, which is not easily perceived. This paper presents a novel Web-enabled geovisual analytics approach to exploration and understanding of self-organizing network data related to cells and neighbor cell relations. A demonstrator and case study are presented in this paper, developed in close collaboration with the Swedish telecom company Ericsson and based on large multivariate, time-varying and geospatial data provided by the company. It allows the operators to follow, interact with and analyze the evolution of a self-organizing network and enhance their understanding of how an automatic algorithm configures locally-unique physical cell identities and organizes neighbor cell relations of the network. The geovisual analytics tool is tested with a self-organizing network that is operated by the automatic neighbor relations (ANR) algorithm. The demonstrator has been tested with positive results by a group of domain experts from Ericsson and will be tested in production.\\\",\\\"Authors\\\":\\\"Ho Van Quan;Astrom, T.;Jern, M.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;GraphNetworkDataAndTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5332610\\\",\\\"Keywords\\\":\\\"multi-layer;time-varying;visualization;geospatial data;self-organizing network;geovisual analytics;multi-dimensional\\\",\\\"Keywords_Processed\\\":\\\"visualization;time vary;multi dimensional;self organizing network;geospatial datum;geovisual analytic;multi layer\\\",\\\"Title\\\":\\\"Geovisual analytics for self-organizing network data\\\"},\\\"662\\\":{\\\"Abstract\\\":\\\"Visual analytics has become an important tool for gaining insight on large and complex collections of data. Numerous statistical tools and data transformations, such as projections, binning and clustering, have been coupled with visualization to help analysts understand data better and faster. However, data is inherently uncertain, due to error, noise or unreliable sources. When making decisions based on uncertain data, it is important to quantify and present to the analyst both the aggregated uncertainty of the results and the impact of the sources of that uncertainty. In this paper, we present a new framework to support uncertainty in the visual analytics process, through statistic methods such as uncertainty modeling, propagation and aggregation. We show that data transformations, such as regression, principal component analysis and k-means clustering, can be adapted to account for uncertainty. This framework leads to better visualizations that improve the decision-making process and help analysts gain insight on the analytic process itself.\\\",\\\"Authors\\\":\\\"Correa, C.;Yu-Hsuan Chan;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"DataTransformation;DimensionalityReduction;MachineLearningAndStatistics;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5332611\\\",\\\"Keywords\\\":\\\"uncertainty;data transformation;principal component analysis;model fitting\\\",\\\"Keywords_Processed\\\":\\\"datum transformation;uncertainty;model fit;principal component analysis\\\",\\\"Title\\\":\\\"A framework for uncertainty-aware visual analytics\\\"},\\\"663\\\":{\\\"Abstract\\\":\\\"In this paper, we discuss dimension reduction methods for 2D visualization of high dimensional clustered data. We propose a two-stage framework for visualizing such data based on dimension reduction methods. In the first stage, we obtain the reduced dimensional data by applying a supervised dimension reduction method such as linear discriminant analysis which preserves the original cluster structure in terms of its criteria. The resulting optimal reduced dimension depends on the optimization criteria and is often larger than 2. In the second stage, the dimension is further reduced to 2 for visualization purposes by another dimension reduction method such as principal component analysis. The role of the second-stage is to minimize the loss of information due to reducing the dimension all the way to 2. Using this framework, we propose several two-stage methods, and present their theoretical characteristics as well as experimental comparisons on both artificial and real-world text data sets.\\\",\\\"Authors\\\":\\\"Jaegul Choo;Bohn, S.;Haesun Park\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;DimensionalityReduction;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5332629\\\",\\\"Keywords\\\":\\\"dimension reduction;orthogonal centroid method;regularization;linear discriminant analysis;2d projection;clustered data;generalized singular value decomposition;principal component analysis\\\",\\\"Keywords_Processed\\\":\\\"2d projection;regularization;generalized singular value decomposition;linear discriminant analysis;orthogonal centroid method;principal component analysis;dimension reduction;cluster datum\\\",\\\"Title\\\":\\\"Two-stage framework for visualization of clustered high dimensional data\\\"},\\\"664\\\":{\\\"Abstract\\\":\\\"Discovering and extracting linear trends and correlations in datasets is very important for analysts to understand multivariate phenomena. However, current widely used multivariate visualization techniques, such as parallel coordinates and scatterplot matrices, fail to reveal and illustrate such linear relationships intuitively, especially when more than 3 variables are involved or multiple trends coexist in the dataset. We present a novel multivariate model parameter space visualization system that helps analysts discover single and multiple linear patterns and extract subsets of data that fit a model well. Using this system, analysts are able to explore and navigate in model parameter space, interactively select and tune patterns, and refine the model for accuracy using computational techniques. We build connections between model space and data space visually, allowing analysts to employ their domain knowledge during exploration to better interpret the patterns they discover and their validity. Case studies with real datasets are used to investigate the effectiveness of the visualizations.\\\",\\\"Authors\\\":\\\"Zhenyu Guo;Ward, M.O.;Rundensteiner, E.A.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;KnowledgeDiscovery;MachineLearningAndStatistics;MultidimensionalMultivariateMultifieldDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5333431\\\",\\\"Keywords\\\":\\\"model space visualization;multivariate linear model construction;knowledge discovery;visual analysis\\\",\\\"Keywords_Processed\\\":\\\"visual analysis;knowledge discovery;model space visualization;multivariate linear model construction\\\",\\\"Title\\\":\\\"Model space visualization for multivariate linear trend discovery\\\"},\\\"665\\\":{\\\"Abstract\\\":\\\"Do court cases differ from place to place? What kind of picture do we get by looking at a country's collection of law cases? We introduce parallel tag clouds: a new way to visualize differences amongst facets of very large metadata-rich text corpora. We have pointed parallel tag clouds at a collection of over 600,000 US Circuit Court decisions spanning a period of 50 years and have discovered regional as well as linguistic differences between courts. The visualization technique combines graphical elements from parallel coordinates and traditional tag clouds to provide rich overviews of a document collection while acting as an entry point for exploration of individual texts. We augment basic parallel tag clouds with a details-in-context display and an option to visualize changes over a second facet of the data, such as time. We also address text mining challenges such as selecting the best words to visualize, and how to do so in reasonable time periods to maintain interactivity.\\\",\\\"Authors\\\":\\\"Collins, C.;Viegas, F.B.;Wattenberg, M.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;DatabasesAndDataMining;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5333443\\\",\\\"Keywords\\\":\\\"information retrieval;text mining;text visualization;corpus visualization;tag clouds\\\",\\\"Keywords_Processed\\\":\\\"text visualization;information retrieval;text mining;corpus visualization;tag cloud\\\",\\\"Title\\\":\\\"Parallel Tag Clouds to explore and analyze faceted text corpora\\\"},\\\"666\\\":{\\\"Abstract\\\":\\\"A common task in literary analysis is to study characters in a novel or collection. Automatic entity extraction, text analysis and effective user interfaces facilitate character analysis. Using our interface, called POSvis, the scholar uses word clouds and self-organizing graphs to review vocabulary, to filter by part of speech, and to explore the network of characters located near characters under review. Further, visualizations show word usages within an analysis window (i.e. a book chapter), which can be compared with a reference window (i.e. the whole book). We describe the interface and report on an early case study with a humanities scholar.\\\",\\\"Authors\\\":\\\"Vuillemot, R.;Clement, T.;Plaisant, C.;Kumar, A.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;HumanComputerInteractionHumanFactors;VisualDesignDesignGuidelines\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5333248\\\",\\\"Keywords\\\":\\\"experimentation;design;visual analytics;human factors\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;experimentation;design;human factor\\\",\\\"Title\\\":\\\"What's being said near \\\\\\\"Martha\\\\\\\"? Exploring name entities in literary text collections\\\"},\\\"667\\\":{\\\"Abstract\\\":\\\"The IEEE Visual Analytics Science and Technology (VAST) Symposium has held a contest each year since its inception in 2006. These events are designed to provide visual analytics researchers and developers with analytic challenges similar to those encountered by professional information analysts. The VAST contest has had an extended life outside of the symposium, however, as materials are being used in universities and other educational settings, either to help teachers of visual analytics-related classes or for student projects. We describe how we develop VAST contest datasets that results in products that can be used in different settings and review some specific examples of the adoption of the VAST contest materials in the classroom. The examples are drawn from graduate and undergraduate courses at Virginia Tech and from the Visual Analytics ldquoSummer Camprdquo run by the National Visualization and Analytics Center in 2008. We finish with a brief discussion on evaluation metrics for education.\\\",\\\"Authors\\\":\\\"Whiting, M.A.;North, C.;Endert, A.;Scholtz, J.;Haack, J.;Varley, C.;Thomas, J.\\\",\\\"Clusters\\\":\\\"DataAcquisitionAndManagement;Education;EvaluationGeneral\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5333245\\\",\\\"Keywords\\\":\\\"synthetic data;evaluation;education\\\",\\\"Keywords_Processed\\\":\\\"synthetic datum;education;evaluation\\\",\\\"Title\\\":\\\"VAST contest dataset use in education\\\"},\\\"668\\\":{\\\"Abstract\\\":\\\"This paper presents a working graph analytics model that embraces the strengths of the traditional top-down and bottom-up approaches with a resilient crossover concept to exploit the vast middle-ground information overlooked by the two extreme analytical approaches. Our graph analytics model is co-developed by users and researchers, who carefully studied the functional requirements that reflect the critical thinking and interaction pattern of a real-life intelligence analyst. To evaluate the model, we implement a system prototype, known as GreenHornet, which allows our analysts to test the theory in practice, identify the technological and usage-related gaps in the model, and then adapt the new technology in their work space. The paper describes the implementation of GreenHornet and compares its strengths and weaknesses against the other prevailing models and tools.\\\",\\\"Authors\\\":\\\"Pak Chung Wong;Mackey, P.;Cook, K.A.;Rohrer, R.M.;Foote, H.;Whiting, M.A.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5333880\\\",\\\"Keywords\\\":\\\"information visualization;graph analytics\\\",\\\"Keywords_Processed\\\":\\\"graph analytic;information visualization\\\",\\\"Title\\\":\\\"A multi-level middle-out cross-zooming approach for large graph analytics\\\"},\\\"669\\\":{\\\"Abstract\\\":\\\"Protein complexes are formed when two or more proteins non-covalently interact to form a larger three dimensional structure with specific biological function. Understanding the composition of such complexes is vital to understanding cell biology at the molecular level. MassVis is a visual analysis tool designed to assist the interpretation of data from a new workflow for detecting the composition of such protein complexes in biological samples. The data generated by the laboratory workflow naturally lends itself to a scatter plot visualization. However, characteristics of this data give rise to some unique aspects not typical of a standard scatter plot. We are able to take the output from tandem mass spectrometry and render the data in such a way that it mimics more traditional two-dimensional gel techniques and at the same time reveals the correlated behavior indicative of protein complexes. By computationally measuring these correlated patterns in the data, membership in putative complexes can be inferred. User interactions are provided to support both an interactive discovery mode as well as an unsupervised clustering of likely complexes. The specific analysis tasks led us to design a unique arrangement of item selection and coordinated detail views in order to simultaneously view different aspects of the selected item.\\\",\\\"Authors\\\":\\\"Kincaid, R.;Dejgaard, K.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;MachineLearningAndStatistics;MolecularScienceAndChemistry;PhysicsAndPhysicalSciences;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5333895\\\",\\\"Keywords\\\":\\\"information visualization;proteomics;correlation analysis;mass spectrometry;interactome;visual analysis\\\",\\\"Keywords_Processed\\\":\\\"mass spectrometry;proteomic;correlation analysis;visual analysis;information visualization;interactome\\\",\\\"Title\\\":\\\"MassVis: Visual analysis of protein complexes using mass spectrometry\\\"},\\\"670\\\":{\\\"Abstract\\\":\\\"Gene mapping is a statistical method used to localize human disease genes to particular regions of the human genome. When performing such analysis, a genetic likelihood space is generated and sampled, which results in a multidimensional scalar field. Researchers are interested in exploring this likelihood space through the use of visualization. Previous efforts at visualizing this space, though, were slow and cumbersome, only showing a small portion of the space at a time, thus requiring the user to keep a mental picture of several views. We have developed a new technique that displays much more data at once by projecting the multidimensional data into several 2D plots. One plot is created for each parameter that shows the change along that parameter. A radial projection is used to create another plot that provides an overview of the high dimensional surface from the perspective of a single point. Linking and brushing between all the plots are used to determine relationships between parameters. We demonstrate our techniques on real world autism data, showing how to visually examine features of the high dimensional space.\\\",\\\"Authors\\\":\\\"Nouanesengsy, B.;Sang-Cheol Seok;Han-Wei Shen;Vieland, V.J.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;BiologyAndBioinformatics;MachineLearningAndStatistics;MultidimensionalMultivariateMultifieldDataAndTechniques;NeurosciencesAndBrainVisualization;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5333917\\\",\\\"Keywords\\\":\\\"linkage disequilibrium analysis;autism;linkage disequilibrium;posterior probability of linkage disequilibrium;visualization;posterior probability of linkage;multi-dimensional data;linkage analysis\\\",\\\"Keywords_Processed\\\":\\\"visualization;posterior probability of linkage;posterior probability of linkage disequilibrium;multi dimensional datum;autism;linkage analysis;linkage disequilibrium analysis;linkage disequilibrium\\\",\\\"Title\\\":\\\"Using projection and 2D plots to visually reveal genetic mechanisms of complex human disorders\\\"},\\\"671\\\":{\\\"Abstract\\\":\\\"We present a new application, SpRay, designed for the visual exploration of gene expression data. It is based on an extension and adaption of parallel coordinates to support the visual exploration of large and high-dimensional datasets. In particular, we investigate the visual analysis of gene expression data as generated by micro-array experiments; We combine refined visual exploration with statistical methods to a visual analytics approach that proved to be particularly successful in this application domain. We will demonstrate the usefulness on several multidimensional gene expression datasets from different bioinformatics applications.\\\",\\\"Authors\\\":\\\"Dietzsch, J.;Heinrich, J.;Nieselt, K.;Bartz, D.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;Genetics;LargeScaleDataAndScalability;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5333911\\\",\\\"Keywords\\\":\\\"microarray data;bioinformatics;large-scale microarray;gene expression experiments;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"gene expression experiment;large scale microarray;microarray datum;visual analytic;bioinformatic\\\",\\\"Title\\\":\\\"SpRay: A visual analytics approach for gene expression data\\\"},\\\"672\\\":{\\\"Abstract\\\":\\\"Today, online stores collect a lot of customer feedback in the form of surveys, reviews, and comments. This feedback is categorized and in some cases responded to, but in general it is underutilized - even though customer satisfaction is essential to the success of their business. In this paper, we introduce several new techniques to interactively analyze customer comments and ratings to determine the positive and negative opinions expressed by the customers. First, we introduce a new discrimination-based technique to automatically extract the terms that are the subject of the positive or negative opinion (such as price or customer service) and that are frequently commented on. Second, we derive a Reverse-Distance-Weighting method to map the attributes to the related positive and negative opinions in the text. Third, the resulting high-dimensional feature vectors are visualized in a new summary representation that provides a quick overview. We also cluster the reviews according to the similarity of the comments. Special thumbnails are used to provide insight into the composition of the clusters and their relationship. In addition, an interactive circular correlation map is provided to allow analysts to detect the relationships of the comments to other important attributes and the scores. We have applied these techniques to customer comments from real-world online stores and product reviews from web sites to identify the strength and problems of different products and services, and show the potential of our technique.\\\",\\\"Authors\\\":\\\"Oelke, D.;Ming Hao;Rohrdantz, C.;Keim, D.A.;Dayal, U.;Haug, L.;Janetzko, H.\\\",\\\"Clusters\\\":\\\"DataFeaturesAndAttributes;SocialNetworksAndSocialMedia;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5333919\\\",\\\"Keywords\\\":\\\"visual document analysis;attribute extraction;visual sentiment analysis;visual opinion analysis\\\",\\\"Keywords_Processed\\\":\\\"visual sentiment analysis;visual opinion analysis;attribute extraction;visual document analysis\\\",\\\"Title\\\":\\\"Visual opinion analysis of customer feedback data\\\"},\\\"673\\\":{\\\"Abstract\\\":\\\"FinVis is a visual analytics tool that allows the non-expert casual user to interpret the return, risk and correlation aspects of financial data and make personal finance decisions. This interactive exploratory tool helps the casual decision-maker quickly choose between various financial portfolio options and view possible outcomes. FinVis allows for exploration of inter-temporal data to analyze outcomes of short-term or long-term investment decisions. FinVis helps the user overcome cognitive limitations and understand the impact of correlation between financial instruments in order to reap the benefits of portfolio diversification. Because this software is accessible by non-expert users, decision-makers from the general population can benefit greatly from using FinVis in practical applications. We quantify the value of FinVis using experimental economics methods and find that subjects using the FinVis software make better financial portfolio decisions as compared to subjects using a tabular version with the same information. We also find that FinVis engages the user, which results in greater exploration of the dataset and increased learning as compared to a tabular display. Further, participants using FinVis reported increased confidence in financial decision-making and noted that they were likely to use this tool in practical application.\\\",\\\"Authors\\\":\\\"Rudolph, S.;Savikhin, A.;Ebert, D.S.\\\",\\\"Clusters\\\":\\\"BusinessFinanceEconomyManufacturing;ReasoningProblemSolvingAndDecisionMaking;UncertaintyTechniquesAndVisualization;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5333920\\\",\\\"Keywords\\\":\\\"economic decision-making;casual information visualization;visualization of risk;personal finance;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"economic decision making;visual analytic;casual information visualization;personal finance;visualization of risk\\\",\\\"Title\\\":\\\"finVis: Applied visual analytics for personal financial planning\\\"},\\\"674\\\":{\\\"Abstract\\\":\\\"Patents are an important economic factor in todays globalized markets. Therefore, the analysis of patent information has become an inevitable task for a variety of interest groups. The retrieval of relevant patent information is an integral part of almost every patent analysis scenario. Unfortunately, the complexity of patent material inhibits a straightforward retrieval of all relevant patent documents and leads to iterative, time-consuming approaches in practice. With `PatViz', a new system for interactive analysis of patent information has been developed to leverage iterative query refinement. PatViz supports users in building complex queries visually and in exploring patent result sets interactively. Thereby, the visual query module introduces an abstraction layer that provides uniform access to different retrieval systems and relieves users of the burden to learn different complex query languages. By establishing an integrated environment it allows for interactive reintegration of insights gained from visual result set exploration into the visual query representation. We expect that the approach we have taken is also suitable to improve iterative query refinement in other Visual Analytics systems.\\\",\\\"Authors\\\":\\\"Koch, S.;Bosch, H.;Giereth, M.;Ertl, T.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;MultipleLinkedCoordinatedViews;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2009.5333564\\\",\\\"Keywords\\\":\\\"information visualization;coordinated & multiple views;patent retrieval;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"coordinate multiple view;visual analytic;patent retrieval;information visualization\\\",\\\"Title\\\":\\\"Iterative integration of visual insights during patent search and analysis\\\"},\\\"675\\\":{\\\"Abstract\\\":\\\"Interaction cost is an important but poorly understood factor in visualization design. We propose a framework of interaction costs inspired by Normanpsilas Seven Stages of Action to facilitate study. From 484 papers, we collected 61 interaction-related usability problems reported in 32 user studies and placed them into our framework of seven costs: (1) Decision costs to form goals; (2) system-power costs to form system operations; (3) Multiple input mode costs to form physical sequences; (4) Physical-motion costs to execute sequences; (5) Visual-cluttering costs to perceive state; (6) View-change costs to interpret perception; (7) State-change costs to evaluate interpretation. We also suggested ways to narrow the gulfs of execution (2-4) and evaluation (5-7) based on collected reports. Our framework suggests a need to consider decision costs (1) as the gulf of goal formation.\\\",\\\"Authors\\\":\\\"Lam, H.\\\",\\\"Clusters\\\":\\\"InteractionTechniquesGeneral;UserInterfacesGeneral;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.109\\\",\\\"Keywords\\\":\\\"interface evaluation;information visualization;framework;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;interface evaluation;framework;information visualization\\\",\\\"Title\\\":\\\"A Framework of Interaction Costs in Information Visualization\\\"},\\\"676\\\":{\\\"Abstract\\\":\\\"The treemap is one of the most popular methods for visualizing hierarchical data. When a treemap contains a large number of items, inspecting or comparing a few selected items in a greater level of detail becomes very challenging. In this paper, we present a seamless multi-focus and context technique, called Balloon Focus, that allows the user to smoothly enlarge multiple treemap items served as the foci, while maintaining a stable treemap layout as the context. Our method has several desirable features. First, this method is quite general and can be used with different treemap layout algorithms. Second, as the foci are enlarged, the relative positions among all items are preserved. Third, the foci are placed in a way that the remaining space is evenly distributed back to the non-focus treemap items. When Balloon Focus enlarges the focus items to a maximum degree, the above features ensure that the treemap will maintain a consistent appearance and avoid any abrupt layout changes. In our algorithm, a DAG (Directed Acyclic Graph) is used to maintain the positional constraints, and an elastic model is employed to govern the placement of the treemap items. We demonstrate a treemap visualization system that integrates data query, manual focus selection, and our novel multi-focus+context technique, Balloon Focus, together. A user study was conducted. Results show that with Balloon Focus, users can better perform the tasks of comparing the values and the distribution of the foci.\\\",\\\"Authors\\\":\\\"Ying Tu;Han-Wei Shen\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;HierarchicalTreeDataAndTechniques;MultiScaleDataTechniques;QueriesAndSearch\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.114\\\",\\\"Keywords\\\":\\\"magnification;multi-focus;focus+context;fisheye;treemap;multi-scale viewing;visualizing query results\\\",\\\"Keywords_Processed\\\":\\\"treemap;visualize query result;multi scale viewing;fisheye;magnification;multi focus;focus context\\\",\\\"Title\\\":\\\"Balloon Focus: a Seamless Multi-Focus+Context Method for Treemaps\\\"},\\\"677\\\":{\\\"Abstract\\\":\\\"Systems biologists use interaction graphs to model the behavior of biological systems at the molecular level. In an iterative process, such biologists observe the reactions of living cells under various experimental conditions, view the results in the context of the interaction graph, and then propose changes to the graph model. These graphs serve as a form of dynamic knowledge representation of the biological system being studied and evolve as new insight is gained from the experimental data. While numerous graph layout and drawing packages are available, these tools did not fully meet the needs of our immunologist collaborators. In this paper, we describe the data information display needs of these immunologists and translate them into design decisions. These decisions led us to create Cerebral, a system that uses a biologically guided graph layout and incorporates experimental data directly into the graph display. Small multiple views of different experimental conditions and a data-driven parallel coordinates view enable correlations between experimental conditions to be analyzed at the same time that the data is viewed in the graph context. This combination of coordinated views allows the biologist to view the data from many different perspectives simultaneously. To illustrate the typical analysis tasks performed, we analyze two datasets using Cerebral. Based on feedback from our collaborators we conclude that Cerebral is a valuable tool for analyzing experimental data in the context of an interaction graph model.\\\",\\\"Authors\\\":\\\"Barsky, A.;Munzner, T.;Gardy, J.;Kincaid, R.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;DesignStudiesAndCaseStudies;GraphNetworkDataAndTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.117\\\",\\\"Keywords\\\":\\\"small multiples;design study;graph layout;systems biology visualization\\\",\\\"Keywords_Processed\\\":\\\"graph layout;design study;system biology visualization;small multiple\\\",\\\"Title\\\":\\\"Cerebral: Visualizing Multiple Experimental Conditions on a Graph with Biological Context\\\"},\\\"678\\\":{\\\"Abstract\\\":\\\"Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate.\\\",\\\"Authors\\\":\\\"Robertson, G.;Fernandez, R.;Fisher, D.;Bongshin Lee;Stasko, J.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;EvaluationGeneral;EventsTrendsOutlierDetectionAnalysisAndVisualization;VisualDesignDesignGuidelines\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.125\\\",\\\"Keywords\\\":\\\"trends;information visualization;experiment;animation;design\\\",\\\"Keywords_Processed\\\":\\\"animation;information visualization;trend;design;experiment\\\",\\\"Title\\\":\\\"Effectiveness of Animation in Trend Visualization\\\"},\\\"679\\\":{\\\"Abstract\\\":\\\"Data transformation, the process of preparing raw data for effective visualization, is one of the key challenges in information visualization. Although researchers have developed many data transformation techniques, there is little empirical study of the general impact of data transformation on visualization. Without such study, it is difficult to systematically decide when and which data transformation techniques are needed. We thus have designed and conducted a two-part empirical study that examines how the use of common data transformation techniques impacts visualization quality, which in turn affects user task performance. Our first experiment studies the impact of data transformation on user performance in single-step, typical visual analytic tasks. The second experiment assesses the impact of data transformation in multi-step analytic tasks. Our results quantify the benefits of data transformation in both experiments. More importantly, our analyses reveal that (1) the benefits of data transformation vary significantly by task and by visualization, and (2) the use of data transformation depends on a user's interaction context. Based on our findings, we present a set of design recommendations that help guide the development and use of data transformation techniques.\\\",\\\"Authors\\\":\\\"Zhen Wen;Zhou, M.X.\\\",\\\"Clusters\\\":\\\"DataCleaningAndSmoothing;DataTransformation;EvaluationGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.129\\\",\\\"Keywords\\\":\\\"user study;data transformation;empirical evaluation;data cleaning\\\",\\\"Keywords_Processed\\\":\\\"datum transformation;empirical evaluation;datum cleaning;user study\\\",\\\"Title\\\":\\\"Evaluating the Use of Data Transformation for Information Visualization\\\"},\\\"680\\\":{\\\"Abstract\\\":\\\"A standard approach to large network visualization is to provide an overview of the network and a detailed view of a small component of the graph centred around a focal node. The user explores the network by changing the focal node in the detailed view or by changing the level of detail of a node or cluster. For scalability, fast force-based layout algorithms are used for the overview and the detailed view. However, using the same layout algorithm in both views is problematic since layout for the detailed view has different requirements to that in the overview. Here we present a model in which constrained graph layout algorithms are used for layout in the detailed view. This means the detailed view has high-quality layout including sophisticated edge routing and is customisable by the user who can add placement constraints on the layout. Scalability is still ensured since the slower layout techniques are only applied to the small subgraph shown in the detailed view. The main technical innovations are techniques to ensure that the overview and detailed view remain synchronized, and modifying constrained graph layout algorithms to support smooth, stable layout. The key innovation supporting stability are new dynamic graph layout algorithms that preserve the topology or structure of the network when the user changes the focus node or the level of detail by in situ semantic zooming. We have built a prototype tool and demonstrate its use in two application domains, UML class diagrams and biological networks.\\\",\\\"Authors\\\":\\\"Dwyer, T.;Marriott, K.;Schreiber, F.;Stuckey, P.;Woodward, M.;Wybrow, M.\\\",\\\"Clusters\\\":\\\"DataFeaturesAndAttributes;DimensionalityReduction;GraphNetworkDataAndTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.130\\\",\\\"Keywords\\\":\\\"multi-dimensional scaling;graph drawing;constraints;stress majorization;force-directed algorithm\\\",\\\"Keywords_Processed\\\":\\\"graph drawing;constraint;stress majorization;force direct algorithm;multi dimensional scaling\\\",\\\"Title\\\":\\\"Exploration of Networks using overview+detail with Constraint-based cooperative layout\\\"},\\\"681\\\":{\\\"Abstract\\\":\\\"Graphs have been widely used to model relationships among data. For large graphs, excessive edge crossings make the display visually cluttered and thus difficult to explore. In this paper, we propose a novel geometry-based edge-clustering framework that can group edges into bundles to reduce the overall edge crossings. Our method uses a control mesh to guide the edge-clustering process; edge bundles can be formed by forcing all edges to pass through some control points on the mesh. The control mesh can be generated at different levels of detail either manually or automatically based on underlying graph patterns. Users can further interact with the edge-clustering results through several advanced visualization techniques such as color and opacity enhancement. Compared with other edge-clustering methods, our approach is intuitive, flexible, and efficient. The experiments on some large graphs demonstrate the effectiveness of our method.\\\",\\\"Authors\\\":\\\"Weiwei Cui;Hong Zhou;Huamin Qu;Pak Chung Wong;Xiaoming Li\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;GraphNetworkDataAndTechniques;MeshesGridsAndLattices;VisualClutterAndItsReduction\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.135\\\",\\\"Keywords\\\":\\\"visual clutter;mesh;graph visualization;edge clustering\\\",\\\"Keywords_Processed\\\":\\\"edge clustering;graph visualization;visual clutter;mesh\\\",\\\"Title\\\":\\\"Geometry-Based Edge Clustering for Graph Visualization\\\"},\\\"682\\\":{\\\"Abstract\\\":\\\"Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.\\\",\\\"Authors\\\":\\\"Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;EvaluationGeneral;InteractionTechniquesGeneral;PresentationProductionAndDissemination;ProvenanceAndHistory;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.137\\\",\\\"Keywords\\\":\\\"presentations;visualization;history;analysis;evaluation;undo\\\",\\\"Keywords_Processed\\\":\\\"visualization;history;undo;presentation;analysis;evaluation\\\",\\\"Title\\\":\\\"Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation\\\"},\\\"683\\\":{\\\"Abstract\\\":\\\"Point placement strategies aim at mapping data points represented in higher dimensions to bi-dimensional spaces and are frequently used to visualize relationships amongst data instances. They have been valuable tools for analysis and exploration of data sets of various kinds. Many conventional techniques, however, do not behave well when the number of dimensions is high, such as in the case of documents collections. Later approaches handle that shortcoming, but may cause too much clutter to allow flexible exploration to take place. In this work we present a novel hierarchical point placement technique that is capable of dealing with these problems. While good grouping and separation of data with high similarity is maintained without increasing computation cost, its hierarchical structure lends itself both to exploration in various levels of detail and to handling data in subsets, improving analysis capability and also allowing manipulation of larger data sets.\\\",\\\"Authors\\\":\\\"Paulovich, F.V.;Minghim, R.\\\",\\\"Clusters\\\":\\\"HierarchicalTreeDataAndTechniques;KnowledgeDiscovery;MultidimensionalMultivariateMultifieldDataAndTechniques;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.138\\\",\\\"Keywords\\\":\\\"text and document visualization;high-dimensional data;hierarchical multidimensional visualization;visual knowledge discovery\\\",\\\"Keywords_Processed\\\":\\\"high dimensional datum;visual knowledge discovery;text and document visualization;hierarchical multidimensional visualization\\\",\\\"Title\\\":\\\"HiPP: A Novel Hierarchical Point Placement Strategy and its Application to the Exploration of Document Collections\\\"},\\\"684\\\":{\\\"Abstract\\\":\\\"Exploring communities is an important task in social network analysis. Such communities are currently identified using clustering methods to group actors. This approach often leads to actors belonging to one and only one cluster, whereas in real life a person can belong to several communities. As a solution we propose duplicating actors in social networks and discuss potential impact of such a move. Several visual duplication designs are discussed and a controlled experiment comparing network visualization with and without duplication is performed, using 6 tasks that are important for graph readability and visual interpretation of social networks. We show that in our experiment, duplications significantly improve community-related tasks but sometimes interfere with other graph readability tasks. Finally, we propose a set of guidelines for deciding when to duplicate actors and choosing candidates for duplication, and alternative ways to render them in social network representations.\\\",\\\"Authors\\\":\\\"Henr, N.;Bezerianos, A.;Fekete, J.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;GraphNetworkDataAndTechniques;SocialNetworksAndSocialMedia;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.141\\\",\\\"Keywords\\\":\\\"social networks;node duplications;clustering;graph visualization\\\",\\\"Keywords_Processed\\\":\\\"clustering;graph visualization;node duplication;social network\\\",\\\"Title\\\":\\\"Improving the Readability of Clustered Social Networks using Node Duplication\\\"},\\\"685\\\":{\\\"Abstract\\\":\\\"While it is quite typical to deal with attributes of different data types in the visualization of heterogeneous and multivariate datasets, most existing techniques still focus on the most usual data types such as numerical attributes or strings. In this paper we present a new approach to the interactive visual exploration and analysis of data that contains attributes which are of set type. A set-typed attribute of a data item - like one cell in a table - has a list of nGt=0 elements as its value. We present the setpsilaopsilagram as a new visualization approach to represent data of set type and to enable interactive visual exploration and analysis. We also demonstrate how this approach is capable to help in dealing with datasets that have a larger number of dimensions (more than a dozen or more), especially also in the context of categorical data. To illustrate the effectiveness of our approach, we present the interactive visual analysis of a CRM dataset with data from a questionnaire on the education and shopping habits of about 90000 people.\\\",\\\"Authors\\\":\\\"Freiler, W.;Matkovic, K.;Hauser, H.\\\",\\\"Clusters\\\":\\\"CategoricalDataAndTechniques;FocusContextTechniques;InteractionTechniquesGeneral;MultidimensionalMultivariateMultifieldDataAndTechniques;MultipleLinkedCoordinatedViews\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.144\\\",\\\"Keywords\\\":\\\"interactive visualization;interactive visual analysis;focus+context visualization;multi-dimensional multi-variate visualization;categorical visualization;coordinated & multiple views\\\",\\\"Keywords_Processed\\\":\\\"categorical visualization;focus context visualization;coordinate multiple view;interactive visualization;interactive visual analysis;multi dimensional multi variate visualization\\\",\\\"Title\\\":\\\"Interactive Visual Analysis of Set-Typed Data\\\"},\\\"686\\\":{\\\"Abstract\\\":\\\"Traditional geospatial information visualizations often present views that restrict the user to a single perspective. When zoomed out, local trends and anomalies become suppressed and lost; when zoomed in for local inspection, spatial awareness and comparison between regions become limited. In our model, coordinated visualizations are integrated within individual probe interfaces, which depict the local data in user-defined regions-of-interest. Our probe concept can be incorporated into a variety of geospatial visualizations to empower users with the ability to observe, coordinate, and compare data across multiple local regions. It is especially useful when dealing with complex simulations or analyses where behavior in various localities differs from other localities and from the system as a whole. We illustrate the effectiveness of our technique over traditional interfaces by incorporating it within three existing geospatial visualization systems: an agent-based social simulation, a census data exploration tool, and an 3D GIS environment for analyzing urban change over time. In each case, the probe-based interaction enhances spatial awareness, improves inspection and comparison capabilities, expands the range of scopes, and facilitates collaboration among multiple users.\\\",\\\"Authors\\\":\\\"Butkiewicz, T.;Wenwen Dou;Wartell, Z.;Ribarsky, W.;Chang, R.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;GeographyGeospatialVisCartographyTerrainVis;InteractionTechniquesGeneral;MultipleLinkedCoordinatedViews\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.149\\\",\\\"Keywords\\\":\\\"multiple-view techniques;focus+context;geospatial analysis;probes;geospatial visualization\\\",\\\"Keywords_Processed\\\":\\\"geospatial analysis;probe;geospatial visualization;multiple view technique;focus context\\\",\\\"Title\\\":\\\"Multi-Focused Geospatial Analysis Using Probes\\\"},\\\"687\\\":{\\\"Abstract\\\":\\\"This paper proposes novel methods for visualizing specifically the large power-law graphs that arise in sociology and the sciences. In such cases a large portion of edges can be shown to be less important and removed while preserving component connectedness and other features (e.g. cliques) to more clearly reveal the networkpsilas underlying connection pathways. This simplification approach deterministically filters (instead of clustering) the graph to retain important node and edge semantics, and works both automatically and interactively. The improved graph filtering and layout is combined with a novel computer graphics anisotropic shading of the dense crisscrossing array of edges to yield a full social network and scale-free graph visualization system. Both quantitative analysis and visual results demonstrate the effectiveness of this approach.\\\",\\\"Authors\\\":\\\"Yuntao Jia;Hoberock, J.;Garland, M.;Hart, J.C.\\\",\\\"Clusters\\\":\\\"FilteringTechniques;GraphNetworkDataAndTechniques;Illumination\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.151\\\",\\\"Keywords\\\":\\\"edge filtering;scale-free network;betweenness centrality;anisotropic shading\\\",\\\"Keywords_Processed\\\":\\\"anisotropic shading;scale free network;betweenness centrality;edge filtering\\\",\\\"Title\\\":\\\"On the Visualization of Social and other Scale-Free Networks\\\"},\\\"688\\\":{\\\"Abstract\\\":\\\"In many information visualization techniques, labels are an essential part to communicate the visualized data. To preserve the expressiveness of the visual representation, a placed label should neither occlude other labels nor visual representatives (e.g., icons, lines) that communicate crucial information. Optimal, non-overlapping labeling is an NP-hard problem. Thus, only a few approaches achieve a fast non-overlapping labeling in highly interactive scenarios like information visualization. These approaches generally target the point-feature label placement (PFLP) problem, solving only label-label conflicts. This paper presents a new, fast, solid and flexible 2D labeling approach for the PFLP problem that additionally respects other visual elements and the visual extent of labeled features. The results (number of placed labels, processing time) of our particle-based method compare favorably to those of existing techniques. Although the esthetic quality of non-real-time approaches may not be achieved with our method, it complies with practical demands and thus supports the interactive exploration of information spaces. In contrast to the known adjacent techniques, the flexibility of our technique enables labeling of dense point clouds by the use of non-occluding distant labels. Our approach is independent of the underlying visualization technique, which enables us to demonstrate the application of our labeling method within different information visualization scenarios.\\\",\\\"Authors\\\":\\\"Luboschik, M.;Schumann, H.;Cords, H.\\\",\\\"Clusters\\\":\\\"Labeling;OcclusionProblemsTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.152\\\",\\\"Keywords\\\":\\\"dynamic labeling;information visualization;occlusion-free;interactive labeling;automatic label placement\\\",\\\"Keywords_Processed\\\":\\\"dynamic labeling;information visualization;interactive labeling;occlusion free;automatic label placement\\\",\\\"Title\\\":\\\"Particle-based labeling: Fast point-feature labeling without obscuring other visual features\\\"},\\\"689\\\":{\\\"Abstract\\\":\\\"Many graph layout algorithms optimize visual characteristics to achieve useful representations. Implicitly, their goal is to create visual representations that are more intuitive to human observers. In this paper, we asked users to explicitly manipulate nodes in a network diagram to create layouts that they felt best captured the relationships in the data. This allowed us to measure organizational behavior directly, allowing us to evaluate the perceptual importance of particular visual features, such as edge crossings and edge-lengths uniformity. We also manipulated the interior structure of the node relationships by designing data sets that contained clusters, that is, sets of nodes that are strongly interconnected. By varying the degree to which these clusters were ldquomaskedrdquo by extraneous edges we were able to measure observerspsila sensitivity to the existence of clusters and how they revealed them in the network diagram. Based on these measurements we found that observers are able to recover cluster structure, that the distance between clusters is inversely related to the strength of the clustering, and that users exhibit the tendency to use edges to visually delineate perceptual groups. These results demonstrate the role of perceptual organization in representing graph data and provide concrete recommendations for graph layout algorithms.\\\",\\\"Authors\\\":\\\"van Ham, F.;Rogowitz, B.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;GraphNetworkDataAndTechniques;Perception\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.155\\\",\\\"Keywords\\\":\\\"user study;graph layout;network layout visualization;perceptual organization\\\",\\\"Keywords_Processed\\\":\\\"graph layout;user study;perceptual organization;network layout visualization\\\",\\\"Title\\\":\\\"Perceptual Organization in User-Generated Graph Layouts\\\"},\\\"690\\\":{\\\"Abstract\\\":\\\"Network data frequently arises in a wide variety of fields, and node-link diagrams are a very natural and intuitive representation of such data. In order for a node-link diagram to be effective, the nodes must be arranged well on the screen. While many graph layout algorithms exist for this purpose, they often have limitations such as high computational complexity or node colocation. This paper proposes a new approach to graph layout through the use of space filling curves which is very fast and guarantees that there will be no nodes that are colocated. The resulting layout is also aesthetic and satisfies several criteria for graph layout effectiveness.\\\",\\\"Authors\\\":\\\"Muelder, C.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;GraphNetworkDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.158\\\",\\\"Keywords\\\":\\\"information visualization;graph layout;space-filling curves\\\",\\\"Keywords_Processed\\\":\\\"graph layout;space filling curve;information visualization\\\",\\\"Title\\\":\\\"Rapid Graph Layout Using Space filling Curves\\\"},\\\"691\\\":{\\\"Abstract\\\":\\\"Scatterplots remain one of the most popular and widely-used visual representations for multidimensional data due to their simplicity, familiarity and visual clarity, even if they lack some of the flexibility and visual expressiveness of newer multidimensional visualization techniques. This paper presents new interactive methods to explore multidimensional data using scatterplots. This exploration is performed using a matrix of scatterplots that gives an overview of the possible configurations, thumbnails of the scatterplots, and support for interactive navigation in the multidimensional space. Transitions between scatterplots are performed as animated rotations in 3D space, somewhat akin to rolling dice. Users can iteratively build queries using bounding volumes in the dataset, sculpting the query from different viewpoints to become more and more refined. Furthermore, the dimensions in the navigation space can be reordered, manually or automatically, to highlight salient correlations and differences among them. An example scenario presents the interaction techniques supporting smooth and effortless visual exploration of multidimensional datasets.\\\",\\\"Authors\\\":\\\"Elmqvist, N.;Dragicevic, P.;Fekete, J.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;InteractionTechniquesGeneral;MultidimensionalMultivariateMultifieldDataAndTechniques;QueriesAndSearch;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.153\\\",\\\"Keywords\\\":\\\"navigation;visual queries;visual exploration;visual analytics;multivariate data;interaction\\\",\\\"Keywords_Processed\\\":\\\"multivariate datum;interaction;navigation;visual exploration;visual analytic;visual query\\\",\\\"Title\\\":\\\"Rolling the Dice: Multidimensional Visual Exploration using Scatterplot Matrix Navigation\\\"},\\\"692\\\":{\\\"Abstract\\\":\\\"Existing treemap layout algorithms suffer to some extent from poor or inconsistent mappings between data order and visual ordering in their representation, reducing their cognitive plausibility. While attempts have been made to quantify this mismatch, and algorithms proposed to minimize inconsistency, solutions provided tend to concentrate on one-dimensional ordering. We propose extensions to the existing squarified layout algorithm that exploit the two-dimensional arrangement of treemap nodes more effectively. Our proposed spatial squarified layout algorithm provides a more consistent arrangement of nodes while maintaining low aspect ratios. It is suitable for the arrangement of data with a geographic component and can be used to create tessellated cartograms for geovisualization. Locational consistency is measured and visualized and a number of layout algorithms are compared. CIELab color space and displacement vector overlays are used to assess and emphasize the spatial layout of treemap nodes. A case study involving locations of tagged photographs in the Flickr database is described.\\\",\\\"Authors\\\":\\\"Wood, J.;Dykes, J.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;GeographyGeospatialVisCartographyTerrainVis;HierarchicalTreeDataAndTechniques;Maps\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.165\\\",\\\"Keywords\\\":\\\"tree structure;treemap;cartogram;cie lab;geographic information;geovisualization\\\",\\\"Keywords_Processed\\\":\\\"treemap;cartogram;geovisualization;geographic information;tree structure;cie lab\\\",\\\"Title\\\":\\\"Spatially Ordered Treemaps\\\"},\\\"693\\\":{\\\"Abstract\\\":\\\"In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different ldquoenergy functionrdquo. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.\\\",\\\"Authors\\\":\\\"Byron, L.;Wattenberg, M.\\\",\\\"Clusters\\\":\\\"ArtAndAestheticsInVisualization;CollaborativeVisualization;ProvenanceAndHistory;SocialNetworksAndSocialMedia;TimeseriesTimeVaryingDataAndTechniques;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.166\\\",\\\"Keywords\\\":\\\"aesthetics;time-series;last.fm;streamgraph;listening history;communication-minded visualization;themeriver\\\",\\\"Keywords_Processed\\\":\\\"listen history;time series;last fm;communication minded visualization;streamgraph;themeriver;aesthetic\\\",\\\"Title\\\":\\\"Stacked Graphs - Geometry & Aesthetics\\\"},\\\"694\\\":{\\\"Abstract\\\":\\\"The nature of an information visualization can be considered to lie in the visual metaphors it uses to structure information. The process of understanding a visualization therefore involves an interaction between these external visual metaphors and the user's internal knowledge representations. To investigate this claim, we conducted an experiment to test the effects of visual metaphor and verbal metaphor on the understanding of tree visualizations. Participants answered simple data comprehension questions while viewing either a treemap or a node-link diagram. Questions were worded to reflect a verbal metaphor that was either compatible or incompatible with the visualization a participant was using. The results suggest that the visual metaphor indeed affects how a user derives information from a visualization. Additionally, we found that the degree to which a user is affected by the metaphor is strongly correlated with the user's ability to answer task questions correctly. These findings are a first step towards illuminating how visual metaphors shape user understanding, and have significant implications for the evaluation, application, and theory of visualization.\\\",\\\"Authors\\\":\\\"Ziemkiewicz, C.;Kosara, R.\\\",\\\"Clusters\\\":\\\"Cognition;EvaluationGeneral;HierarchicalTreeDataAndTechniques;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.171\\\",\\\"Keywords\\\":\\\"hierarchy;evaluation;cognition;visualization theory;metaphors\\\",\\\"Keywords_Processed\\\":\\\"hierarchy;visualization theory;cognition;metaphor;evaluation\\\",\\\"Title\\\":\\\"The Shaping of Information by Visual Metaphors\\\"},\\\"695\\\":{\\\"Abstract\\\":\\\"We introduce the Word Tree, a new visualization and information-retrieval technique aimed at text documents. A Word Tree is a graphical version of the traditional \\\\\\\"keyword-in-context\\\\\\\" method, and enables rapid querying and exploration of bodies of text. In this paper we describe the design of the technique, along with some of the technical issues that arise in its implementation. In addition, we discuss the results of several months of public deployment of word trees on Many Eyes, which provides a window onto the ways in which users obtain value from the visualization.\\\",\\\"Authors\\\":\\\"Wattenberg, M.;Viegas, F.B.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;DesignStudiesAndCaseStudies;QueriesAndSearch;TextDocumentTopicAnalysisDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.172\\\",\\\"Keywords\\\":\\\"concordance;information retrieval;search;document visualization;text visualization;case study;many eyes\\\",\\\"Keywords_Processed\\\":\\\"case study;search;many eye;document visualization;text visualization;information retrieval;concordance\\\",\\\"Title\\\":\\\"The Word Tree, an Interactive Visual Concordance\\\"},\\\"696\\\":{\\\"Abstract\\\":\\\"In common Web-based search interfaces, it can be difficult to formulate queries that simultaneously combine temporal, spatial, and topical data filters. We investigate how coordinated visualizations can enhance search and exploration of information on the World Wide Web by easing the formulation of these types of queries. Drawing from visual information seeking and exploratory search, we introduce VisGets - interactive query visualizations of Web-based information that operate with online information within a Web browser. VisGets provide the information seeker with visual overviews of Web resources and offer a way to visually filter the data. Our goal is to facilitate the construction of dynamic search queries that combine filters from more than one data dimension. We present a prototype information exploration system featuring three linked VisGets (temporal, spatial, and topical), and used it to visually explore news items from online RSS feeds.\\\",\\\"Authors\\\":\\\"Dork, M.;Carpendale, S.;Collins, C.;Williamson, C.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;DatabasesAndDataMining;InternetWebVisualizationForTheMasses;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.175\\\",\\\"Keywords\\\":\\\"information visualization;information retrieval;exploratory search;visual information seeking;world wide web\\\",\\\"Keywords_Processed\\\":\\\"world wide web;exploratory search;information retrieval;information visualization;visual information seek\\\",\\\"Title\\\":\\\"VisGets: Coordinated Visualizations for Web-based Information Exploration and Discovery\\\"},\\\"697\\\":{\\\"Abstract\\\":\\\"Wikipedia is an example of the collaborative, semi-structured data sets emerging on the Web. These data sets have large, non-uniform schema that require costly data integration into structured tables before visualization can begin. We present Vispedia, a Web-based visualization system that reduces the cost of this data integration. Users can browse Wikipedia, select an interesting data table, then use a search interface to discover, integrate, and visualize additional columns of data drawn from multiple Wikipedia articles. This interaction is supported by a fast path search algorithm over DBpedia, a semantic graph extracted from Wikipedia's hyperlink structure. Vispedia can also export the augmented data tables produced for use in traditional visualization systems. We believe that these techniques begin to address the \\\\\\\"long tail\\\\\\\" of visualization by allowing a wider audience to visualize a broader class of data. We evaluated this system in a first-use formative lab study. Study participants were able to quickly create effective visualizations for a diverse set of domains, performing data integration as needed.\\\",\\\"Authors\\\":\\\"Chan, B.;Wu, L.;Talbot, J.;Cammarano, M.;Hanrahan, P.\\\",\\\"Clusters\\\":\\\"DataAcquisitionAndManagement;InternetWebVisualizationForTheMasses;QueriesAndSearch;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.178\\\",\\\"Keywords\\\":\\\"information visualization;search interfaces;data integration;wikipedia;semantic web\\\",\\\"Keywords_Processed\\\":\\\"semantic web;datum integration;search interface;information visualization;wikipedia\\\",\\\"Title\\\":\\\"Vispedia: Interactive Visual Exploration of Wikipedia Data via Search-Based Integration\\\"},\\\"698\\\":{\\\"Abstract\\\":\\\"Ranking data, which result from m raters ranking n items, are difficult to visualize due to their discrete algebraic structure, and the computational difficulties associated with them when n is large. This problem becomes worse when raters provide tied rankings or not all items are ranked. We develop an approach for the visualization of ranking data for large n which is intuitive, easy to use, and computationally efficient. The approach overcomes the structural and computational difficulties by utilizing a natural measure of dissimilarity for raters, and projecting the raters into a low dimensional vector space where they are viewed. The visualization techniques are demonstrated using voting data, jokes, and movie preferences.\\\",\\\"Authors\\\":\\\"Kidwell, P.;Lebanon, G.;Cleveland, W.S.\\\",\\\"Clusters\\\":\\\"DimensionalityReduction;Ranking\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.181\\\",\\\"Keywords\\\":\\\"multi-dimensional scaling;incomplete rankings;partial rankings\\\",\\\"Keywords_Processed\\\":\\\"partial ranking;multi dimensional scaling;incomplete ranking\\\",\\\"Title\\\":\\\"Visualizing Incomplete and Partially Ranked Data\\\"},\\\"699\\\":{\\\"Abstract\\\":\\\"In the established procedural model of information visualization, the first operation is to transform raw data into data tables. The transforms typically include abstractions that aggregate and segment relevant data and are usually defined by a human, user or programmer. The theme of this paper is that for video, data transforms should be supported by low level computer vision. High level reasoning still resides in the human analyst, while part of the low level perception is handled by the computer. To illustrate this approach, we present Viz-A-Vis, an overhead video capture and access system for activity analysis in natural settings over variable periods of time. Overhead video provides rich opportunities for long-term behavioral and occupancy analysis, but it poses considerable challenges. We present initial steps addressing two challenges. First, overhead video generates overwhelmingly large volumes of video impractical to analyze manually. Second, automatic video analysis remains an open problem for computer vision.\\\",\\\"Authors\\\":\\\"Romero, M.;Summet, J.;Stasko, J.;Abowd, G.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;MultimediaImageVideoMusic;SpatiotemporalDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.185\\\",\\\"Keywords\\\":\\\"spatio-temporal visualization;video visualization;time-series data;sensor analytics;image/video analytics\\\",\\\"Keywords_Processed\\\":\\\"spatio temporal visualization;image video analytic;sensor analytic;video visualization;time series datum\\\",\\\"Title\\\":\\\"Viz-A-Vis: Toward Visualizing Video through Computer Vision\\\"},\\\"700\\\":{\\\"Abstract\\\":\\\"Surveys and opinion polls are extremely popular in the media, especially in the months preceding a general election. However, the available tools for analyzing poll results often require specialized training. Hence, data analysis remains out of reach for many casual computer users. Moreover, the visualizations used to communicate the results of surveys are typically limited to traditional statistical graphics like bar graphs and pie charts, both of which are fundamentally noninteractive. We present a simple interactive visualization that allows users to construct queries on large tabular data sets, and view the results in real time. The results of two separate user studies suggest that our interface lowers the learning curve for naive users, while still providing enough analytical power to discover interesting correlations in the data.\\\",\\\"Authors\\\":\\\"Draper, G.;Riesenfeld, R.F.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;HumanComputerInteractionHumanFactors;QueriesAndSearch;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.187\\\",\\\"Keywords\\\":\\\"data analysis;radial visualization;visual query language;human-computer interaction\\\",\\\"Keywords_Processed\\\":\\\"radial visualization;human computer interaction;datum analysis;visual query language\\\",\\\"Title\\\":\\\"Who Votes For What? A Visual Query Language for Opinion Data\\\"},\\\"701\\\":{\\\"Abstract\\\":\\\"Large datasets typically contain coarse features comprised of finer sub-features. Even if the shapes of the small structures are evident in a 3D display, the aggregate shapes they suggest may not be easily inferred. From previous studies in shape perception, the evidence has not been clear whether physically-based illumination confers any advantage over local illumination for understanding scenes that arise in visualization of large data sets that contain features at two distinct scales. In this paper we show that physically-based illumination can improve the perception for some static scenes of complex 3D geometry from flow fields. We perform human-subjects experiments to quantify the effect of physically-based illumination on participant performance for two tasks: selecting the closer of two streamtubes from a field of tubes, and identifying the shape of the domain of a flow field over different densities of tubes. We find that physically-based illumination influences participant performance as strongly as perspective projection, suggesting that physically-based illumination is indeed a strong cue to the layout of complex scenes. We also find that increasing the density of tubes for the shape identification task improved participant performance under physically-based illumination but not under the traditional hardware-accelerated illumination model.\\\",\\\"Authors\\\":\\\"Weigle, C.;Banks, D.C.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;FlowVisualizationDataAndTechniques;Illumination;MultiScaleDataTechniques;Perception;StreamlinesPathlinesStreaklines;TensorDataAndTechniques;Tractography;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.108\\\",\\\"Keywords\\\":\\\"flow visualization;physically-based illumination;3d shape perception;streamtubes;user study;volume completion;white matter tractography;local illumination;diffusion tensor mri;global illumination;multi-scale visualization\\\",\\\"Keywords_Processed\\\":\\\"white matter tractography;user study;multi scale visualization;streamtube;global illumination;diffusion tensor mri;physically base illumination;volume completion;local illumination;3d shape perception;flow visualization\\\",\\\"Title\\\":\\\"A Comparison of the Perceptual Benefits of Linear Perspective and Physically-Based Illumination for Display of Dense 3D Streamtubes\\\"},\\\"702\\\":{\\\"Abstract\\\":\\\"The Morse-Smale (MS) complex has proven to be a useful tool in extracting and visualizing features from scalar-valued data. However, efficient computation of the MS complex for large scale data remains a challenging problem. We describe a new algorithm and easily extensible framework for computing MS complexes for large scale data of any dimension where scalar values are given at the vertices of a closure-finite and weak topology (CW) complex, therefore enabling computation on a wide variety of meshes such as regular grids, simplicial meshes, and adaptive multiresolution (AMR) meshes. A new divide-and-conquer strategy allows for memory-efficient computation of the MS complex and simplification on-the-fly to control the size of the output. In addition to being able to handle various data formats, the framework supports implementation-specific optimizations, for example, for regular data. We present the complete characterization of critical point cancellations in all dimensions. This technique enables the topology based analysis of large data on off-the-shelf computers. In particular we demonstrate the first full computation of the MS complex for a 1 billion/10243 node grid on a laptop computer with 2 Gb memory.\\\",\\\"Authors\\\":\\\"Gyulassy, A.;Bremer, P.-T.;Hamann, B.;Pascucci, V.\\\",\\\"Clusters\\\":\\\"LargeScaleDataAndScalability;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.110\\\",\\\"Keywords\\\":\\\"topology-based analysis;large-scale data;morse-smale complex\\\",\\\"Keywords_Processed\\\":\\\"topology base analysis;large scale datum;morse smale complex\\\",\\\"Title\\\":\\\"A Practical Approach to Morse-Smale Complex Computation: Scalability and Generality\\\"},\\\"703\\\":{\\\"Abstract\\\":\\\"We present an interactive algorithm to compute sound propagation paths for transmission, specular reflection and edge diffraction in complex scenes. Our formulation uses an adaptive frustum representation that is automatically sub-divided to accurately compute intersections with the scene primitives. We describe a simple and fast algorithm to approximate the visible surface for each frustum and generate new frusta based on specular reflection and edge diffraction. Our approach is applicable to all triangulated models and we demonstrate its performance on architectural and outdoor models with tens or hundreds of thousands of triangles and moving objects. In practice, our algorithm can perform geometric sound propagation in complex scenes at 4-20 frames per second on a multi-core PC.\\\",\\\"Authors\\\":\\\"Chandak, A.;Lauterbach, C.;Taylor, M.;Zhimin Ren;Manocha, D.\\\",\\\"Clusters\\\":\\\"AcousticsSoundSonification;InteractionTechniquesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.111\\\",\\\"Keywords\\\":\\\"sound propagation;interactive system;auralization\\\",\\\"Keywords_Processed\\\":\\\"sound propagation;interactive system;auralization\\\",\\\"Title\\\":\\\"AD-Frustum: Adaptive Frustum Tracing for Interactive Sound Propagation\\\"},\\\"704\\\":{\\\"Abstract\\\":\\\"We present an efficient and automatic image-recoloring technique for dichromats that highlights important visual details that would otherwise be unnoticed by these individuals. While previous techniques approach this problem by potentially changing all colors of the original image, causing their results to look unnatural to color vision deficients, our approach preserves, as much as possible, the image's original colors. Our approach is about three orders of magnitude faster than previous ones. The results of a paired-comparison evaluation carried out with fourteen color-vision deficients (CVDs) indicated the preference of our technique over the state-of-the-art automatic recoloring technique for dichromats. When considering information visualization examples, the subjects tend to prefer our results over the original images. An extension of our technique that exaggerates color contrast tends to be preferred when CVDs compared pairs of scientific visualization images. These results provide valuable information for guiding the design of visualizations for color-vision deficients.\\\",\\\"Authors\\\":\\\"Kuhn, G.R.;Oliveira, M.M.;Fernandes, L.A.F.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;IntegratingSpatialAndNonSpatialDataVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.112\\\",\\\"Keywords\\\":\\\"color-vision deficiency;color-contrast enhancement;recoloring algorithms;information and scientific visualization\\\",\\\"Keywords_Processed\\\":\\\"color contrast enhancement;recolore algorithm;information and scientific visualization;color vision deficiency\\\",\\\"Title\\\":\\\"An Efficient Naturalness-Preserving Image-Recoloring Method for Dichromats\\\"},\\\"705\\\":{\\\"Abstract\\\":\\\"We introduce and analyze an efficient reconstruction algorithm for FCC-sampled data. The reconstruction is based on the 6-direction box spline that is naturally associated with the FCC lattice and shares the continuity and approximation order of the triquadratic B-spline. We observe less aliasing for generic level sets and derive special techniques to attain the higher evaluation efficiency promised by the lower degree and smaller stencil-size of the C1 6-direction box spline over the triquadratic B-spline.\\\",\\\"Authors\\\":\\\"Minho Kim;Entezari, A.;Peters, J.\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;MeshesGridsAndLattices;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.115\\\",\\\"Keywords\\\":\\\"face-centered cubic lattice;box spline;volumetric data reconstruction\\\",\\\"Keywords_Processed\\\":\\\"box spline;volumetric datum reconstruction;face center cubic lattice\\\",\\\"Title\\\":\\\"Box Spline Reconstruction On The Face-Centered Cubic Lattice\\\"},\\\"706\\\":{\\\"Abstract\\\":\\\"The visualization and exploration of multivariate data is still a challenging task. Methods either try to visualize all variables simultaneously at each position using glyph-based approaches or use linked views for the interaction between attribute space and physical domain such as brushing of scatterplots. Most visualizations of the attribute space are either difficult to understand or suffer from visual clutter. We propose a transformation of the high-dimensional data in attribute space to 2D that results in a point cloud, called attribute cloud, such that points with similar multivariate attributes are located close to each other. The transformation is based on ideas from multivariate density estimation and manifold learning. The resulting attribute cloud is an easy to understand visualization of multivariate data in two dimensions. We explain several techniques to incorporate additional information into the attribute cloud, that help the user get a better understanding of multivariate data. Using different examples from fluid dynamics and climate simulation, we show how brushing can be used to explore the attribute cloud and find interesting structures in physical space.\\\",\\\"Authors\\\":\\\"Jnicke, H.;Bottinger, M.;Scheuermann, G.\\\",\\\"Clusters\\\":\\\"DataTransformation;InteractionTechniquesGeneral;MachineLearningAndStatistics;MultidimensionalMultivariateMultifieldDataAndTechniques;MultipleLinkedCoordinatedViews\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.116\\\",\\\"Keywords\\\":\\\"manifold learning;brushing;linked views;multivariate data;data transformation\\\",\\\"Keywords_Processed\\\":\\\"multivariate datum;brush;datum transformation;link view;manifold learning\\\",\\\"Title\\\":\\\"Brushing of Attribute Clouds for the Visualization of Multivariate Data\\\"},\\\"707\\\":{\\\"Abstract\\\":\\\"Professional designers and artists are quite cognizant of the rules that guide the design of effective color palettes, from both aesthetic and attention-guiding points of view. In the field of visualization, however, the use of systematic rules embracing these aspects has received less attention. The situation is further complicated by the fact that visualization often uses semi-transparencies to reveal occluded objects, in which case the resulting color mixing effects add additional constraints to the choice of the color palette. Color design forms a crucial part in visual aesthetics. Thus, the consideration of these issues can be of great value in the emerging field of illustrative visualization. We describe a knowledge-based system that captures established color design rules into a comprehensive interactive framework, aimed to aid users in the selection of colors for scene objects and incorporating individual preferences, importance functions, and overall scene composition. Our framework also offers new knowledge and solutions for the mixing, ordering and choice of colors in the rendering of semi-transparent layers and surfaces. All design rules are evaluated via user studies, for which we extend the method of conjoint analysis to task-based testing scenarios. Our framework's use of principles rooted in color design with application for the illustration of features in pre-classified data distinguishes it from existing systems which target the exploration of continuous-range density data via perceptual color maps.\\\",\\\"Authors\\\":\\\"Lujin Wang;Giesen, J.;McDonnell, K.T.;Zolliker, P.;Mueller, K.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;EvaluationGeneral;IllustrativeVisualization;MachineLearningAndStatistics;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.118\\\",\\\"Keywords\\\":\\\"color design;volume rendering;illustrative visualization;user study evaluation;transparency;conjoint analysis\\\",\\\"Keywords_Processed\\\":\\\"volume render;illustrative visualization;transparency;color design;user study evaluation;conjoint analysis\\\",\\\"Title\\\":\\\"Color Design for Illustrative Visualization\\\"},\\\"708\\\":{\\\"Abstract\\\":\\\"Scatterplots are well established means of visualizing discrete data values with two data variables as a collection of discrete points. We aim at generalizing the concept of scatterplots to the visualization of spatially continuous input data by a continuous and dense plot. An example of a continuous input field is data defined on an n-D spatial grid with respective interpolation or reconstruction of in-between values. We propose a rigorous, accurate, and generic mathematical model of continuous scatterplots that considers an arbitrary density defined on an input field on an n-D domain and that maps this density to m-D scatterplots. Special cases are derived from this generic model and discussed in detail: scatterplots where the n-D spatial domain and the m-D data attribute domain have identical dimension, 1-D scatterplots as a way to define continuous histograms, and 2-D scatterplots of data on 3-D spatial grids. We show how continuous histograms are related to traditional discrete histograms and to the histograms of isosurface statistics. Based on the mathematical model of continuous scatterplots, respective visualization algorithms are derived, in particular for 2-D scatterplots of data from 3-D tetrahedral grids. For several visualization tasks, we show the applicability of continuous scatterplots. Since continuous scatterplots do not only sample data at grid points but interpolate data values within cells, a dense and complete visualization of the data set is achieved that scales well with increasing data set size. Especially for irregular grids with varying cell size, improved results are obtained when compared to conventional scatterplots. Therefore, continuous scatterplots are a suitable extension of a statistics visualization technique to be applied to typical data from scientific computation.\\\",\\\"Authors\\\":\\\"Bachthaler, S.;Weiskopf, D.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;Interpolation\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.119\\\",\\\"Keywords\\\":\\\"scatterplot;continuous frequency plot;histogram;interpolation\\\",\\\"Keywords_Processed\\\":\\\"scatterplot;continuous frequency plot;histogram;interpolation\\\",\\\"Title\\\":\\\"Continuous Scatterplots\\\"},\\\"709\\\":{\\\"Abstract\\\":\\\"In this work we present basic methodology for interactive volume editing on GPUs, and we demonstrate the use of these methods to achieve a number of different effects. We present fast techniques to modify the appearance and structure of volumetric scalar fields given on Cartesian grids. Similar to 2D circular brushes as used in surface painting we present 3D spherical brushes for intuitive coloring of particular structures in such fields. This paint metaphor is extended to allow the user to change the data itself, and the use of this functionality for interactive structure isolation, hole filling, and artefact removal is demonstrated. Building on previous work in the field we introduce high-resolution selection volumes, which can be seen as a resolution-based focus+context metaphor. By utilizing such volumes we present a novel approach to interactive volume editing at sub-voxel accuracy. Finally, we introduce a fast technique to paste textures onto iso-surfaces in a 3D scalar field. Since the texture resolution is independent of the volume resolution, this technique allows structure-aligned textures containing appearance properties or textual information to be used for volume augmentation and annotation.\\\",\\\"Authors\\\":\\\"Burger, K.;Kruger, J.;Westermann, R.\\\",\\\"Clusters\\\":\\\"ArtAndAestheticsInVisualization;GpuBasedTechniques;InteractionTechniquesGeneral;Labeling;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.120\\\",\\\"Keywords\\\":\\\"annotation;volume editing;carving;gpu;painting\\\",\\\"Keywords_Processed\\\":\\\"volume edit;annotation;painting;carve;gpu\\\",\\\"Title\\\":\\\"Direct Volume Editing\\\"},\\\"710\\\":{\\\"Abstract\\\":\\\"Marching cubes is the most popular isosurface extraction algorithm due to its simplicity, efficiency and robustness. It has been widely studied, improved, and extended. While much early work was concerned with efficiency and correctness issues, lately there has been a push to improve the quality of marching cubes meshes so that they can be used in computational codes. In this work we present a new classification of MC cases that we call edge groups, which helps elucidate the issues that impact the triangle quality of the meshes that the method generates. This formulation allows a more systematic way to bound the triangle quality, and is general enough to extend to other polyhedral cell shapes used in other polygonization algorithms. Using this analysis, we also discuss ways to improve the quality of the resulting triangle mesh, including some that require only minor modifications of the original algorithm.\\\",\\\"Authors\\\":\\\"Dietrich, C.A.;Scheidegger, C.E.;Comba, J.L.D.;Nedel, L.P.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.122\\\",\\\"Keywords\\\":\\\"isosurface extraction;marching cubes\\\",\\\"Keywords_Processed\\\":\\\"march cube;isosurface extraction\\\",\\\"Title\\\":\\\"Edge Groups: An Approach to Understanding the Mesh Quality of Marching Methods\\\"},\\\"711\\\":{\\\"Abstract\\\":\\\"The effective visualization of vascular structures is critical for diagnosis, surgical planning as well as treatment evaluation. In recent work, we have developed an algorithm for vessel detection that examines the intensity profile around each voxel in an angiographic image and determines the likelihood that any given voxel belongs to a vessel; we term this the \\\\\\\"vesselness coefficient\\\\\\\" of the voxel. Our results show that our algorithm works particularly well for visualizing branch points in vessels. Compared to standard Hessian based techniques, which are fine-tuned to identify long cylindrical structures, our technique identifies branches and connections with other vessels. Using our computed vesselness coefficient, we explore a set of techniques for visualizing vasculature. Visualizing vessels is particularly challenging because not only is their position in space important for clinicians but it is also important to be able to resolve their spatial relationship. We applied visualization techniques that provide shape cues as well as depth cues to allow the viewer to differentiate between vessels that are closer from those that are farther. We use our computed vesselness coefficient to effectively visualize vasculature in both clinical neurovascular x-ray computed tomography based angiography images, as well as images from three different animal studies. We conducted a formal user evaluation of our visualization techniques with the help of radiologists, surgeons, and other expert users. Results indicate that experts preferred distance color blending and tone shading for conveying depth over standard visualization techniques.\\\",\\\"Authors\\\":\\\"Joshi, A.;Xiaoning Qian;Dione, D.P.;Bulsara, K.;Breuer, C.;Sinusas, A.J.;Papademetris, X.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;EvaluationGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.123\\\",\\\"Keywords\\\":\\\"vessel identification;vessel visualization;evaluation of visualization techniques\\\",\\\"Keywords_Processed\\\":\\\"evaluation of visualization technique;vessel visualization;vessel identification\\\",\\\"Title\\\":\\\"Effective visualization of complex vascular structures using a non-parametric vessel detection method\\\"},\\\"712\\\":{\\\"Abstract\\\":\\\"In this work we develop a new alternative to conventional maps for visualization of relatively short paths as they are frequently encountered in hotels, resorts or museums. Our approach is based on a warped rendering of a 3D model of the environment such that the visualized path appears to be straight even though it may contain several junctions. This has the advantage that the beholder of the image gains a realistic impression of the surroundings along the way which makes it easy to retrace the route in practice. We give an intuitive method for generation of such images and present results from user studies undertaken to evaluate the benefit of the warped images for orientation in unknown environments.\\\",\\\"Authors\\\":\\\"Degener, P.;Schnabel, R.;Schwartz, C.;Klein, R.\\\",\\\"Clusters\\\":\\\"ManipulationAndDeformation;Maps;Traffic\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.124\\\",\\\"Keywords\\\":\\\"route visualization;maps;space deformation\\\",\\\"Keywords_Processed\\\":\\\"route visualization;map;space deformation\\\",\\\"Title\\\":\\\"Effective Visualization of Short Routes\\\"},\\\"713\\\":{\\\"Abstract\\\":\\\"Many interesting and promising prototypes for visualizing video data have been proposed, including those that combine videos with their spatial context (contextualized videos). However, relatively little work has investigated the fundamental design factors behind these prototypes in order to provide general design guidance. Focusing on real-time video data visualization, we evaluated two important design factors - video placement method and spatial context presentation method - through a user study. In addition, we evaluated the effect of spatial knowledge of the environment. Participantspsila performance was measured through path reconstruction tasks, where the participants followed a target through simulated surveillance videos and marked the target paths on the environment model. We found that embedding videos inside the model enabled realtime strategies and led to faster performance. With the help of contextualized videos, participants not familiar with the real environment achieved similar task performance to participants that worked in that environment. We discuss design implications and provide general design recommendations for traffic and security surveillance system interfaces.\\\",\\\"Authors\\\":\\\"Yi Wang;Bowman, D.A.;Krum, D.;Coalho, E.;Smith-Jackson, T.;Bailey, D.;Peck, S.;Anand, S.;Kennedy, T.;Abdrazakov, Y.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;EvaluationGeneral;Interpolation;MultimediaImageVideoMusic;SpaceRelatedSpatialDataAndTechniques;VisualDesignDesignGuidelines\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.126\\\",\\\"Keywords\\\":\\\"design factors;user study;path reconstruction;contextualized videos;video placement;tracking;spatial context\\\",\\\"Keywords_Processed\\\":\\\"path reconstruction;contextualized video;user study;design factor;tracking;spatial context;video placement\\\",\\\"Title\\\":\\\"Effects of Video Placement and Spatial Context Presentation on Path Reconstruction Tasks with Contextualized Videos\\\"},\\\"714\\\":{\\\"Abstract\\\":\\\"Diffusion weighted magnetic resonance imaging is a unique tool for non-invasive investigation of major nerve fiber tracts. Since the popular diffusion tensor (DT-MRI) model is limited to voxels with a single fiber direction, a number of high angular resolution techniques have been proposed to provide information about more diverse fiber distributions. Two such approaches are Q-Ball imaging and spherical deconvolution, which produce orientation distribution functions (ODFs) on the sphere. For analysis and visualization, the maxima of these functions have been used as principal directions, even though the results are known to be biased in case of crossing fiber tracts. In this paper, we present a more reliable technique for extracting discrete orientations from continuous ODFs, which is based on decomposing their higher-order tensor representation into an isotropic component, several rank-1 terms, and a small residual. Comparing to ground truth in synthetic data shows that the novel method reduces bias and reliably reconstructs crossing fibers which are not resolved as individual maxima in the ODF We present results on both Q-Ball and spherical deconvolution data and demonstrate that the estimated directions allow for plausible fiber tracking in a real data set.\\\",\\\"Authors\\\":\\\"Schultz, T.;Seidel, H.-P.\\\",\\\"Clusters\\\":\\\"NeurosciencesAndBrainVisualization;TensorDataAndTechniques;Tractography\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.128\\\",\\\"Keywords\\\":\\\"higher-order tensor;tensor decomposition;diffusion weighted mri;fiber tracking;spherical deconvolution;q-ball\\\",\\\"Keywords_Processed\\\":\\\"diffusion weight mri;tensor decomposition;fiber tracking;ball;high order tensor;spherical deconvolution\\\",\\\"Title\\\":\\\"Estimating Crossing fibers: A Tensor Decomposition Approach\\\"},\\\"715\\\":{\\\"Abstract\\\":\\\"Parallel coordinate plots (PCPs) are commonly used in information visualization to provide insight into multi-variate data. These plots help to spot correlations between variables. PCPs have been successfully applied to unstructured datasets up to a few millions of points. In this paper, we present techniques to enhance the usability of PCPs for the exploration of large, multi-timepoint volumetric data sets, containing tens of millions of points per timestep. The main difficulties that arise when applying PCPs to large numbers of data points are visual clutter and slow performance, making interactive exploration infeasible. Moreover, the spatial context of the volumetric data is usually lost. We describe techniques for preprocessing using data quantization and compression, and for fast GPU-based rendering of PCPs using joint density distributions for each pair of consecutive variables, resulting in a smooth, continuous visualization. Also, fast brushing techniques are proposed for interactive data selection in multiple linked views, including a 3D spatial volume view. These techniques have been successfully applied to three large data sets: Hurricane Isabel (Vis'04 contest), the ionization front instability data set (Vis'08 design contest), and data from a large-eddy simulation of cumulus clouds. With these data, we show how PCPs can be extended to successfully visualize and interactively explore multi-timepoint volumetric datasets with an order of magnitude more data points.\\\",\\\"Authors\\\":\\\"Blaas, J.;Botha, C.P.;Post, F.H.\\\",\\\"Clusters\\\":\\\"MultidimensionalMultivariateMultifieldDataAndTechniques;MultipleLinkedCoordinatedViews;ParallelCoordinates;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.131\\\",\\\"Keywords\\\":\\\"linked related views;time-varying;parallel coordinate plot;multi-field\\\",\\\"Keywords_Processed\\\":\\\"link related view;time vary;multi field;parallel coordinate plot\\\",\\\"Title\\\":\\\"Extensions of Parallel Coordinates for Interactive Exploration of Large Multi-Timepoint Data Sets\\\"},\\\"716\\\":{\\\"Abstract\\\":\\\"The need to examine and manipulate large surface models is commonly found in many science, engineering, and medical applications. On a desktop monitor, however, seeing the whole model in detail is not possible. In this paper, we present a new, interactive Focus+Context method for visualizing large surface models. Our method, based on an energy optimization model, allows the user to magnify an area of interest to see it in detail while deforming the rest of the area without perceivable distortion. The rest of the surface area is essentially shrunk to use as little of the screen space as possible in order to keep the entire model displayed on screen. We demonstrate the efficacy and robustness of our method with a variety of models.\\\",\\\"Authors\\\":\\\"Yu-Shuen Wang;Tong-Yee Lee;Chiew-Lan Tai\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.132\\\",\\\"Keywords\\\":\\\"magnification;focus+context visualization;bounding space\\\",\\\"Keywords_Processed\\\":\\\"focus context visualization;bound space;magnification\\\",\\\"Title\\\":\\\"Focus+Context Visualization with Distortion Minimization\\\"},\\\"717\\\":{\\\"Abstract\\\":\\\"We present a novel approach for the direct computation of integral surfaces in time-dependent vector fields. As opposed to previous work, which we analyze in detail, our approach is based on a separation of integral surface computation into two stages: surface approximation and generation of a graphical representation. This allows us to overcome several limitations of existing techniques. We first describe an algorithm for surface integration that approximates a series of time lines using iterative refinement and computes a skeleton of the integral surface. In a second step, we generate a well-conditioned triangulation. Our approach allows a highly accurate treatment of very large time-varying vector fields in an efficient, streaming fashion. We examine the properties of the presented methods on several example datasets and perform a numerical study of its correctness and accuracy. Finally, we investigate some visualization aspects of integral surfaces.\\\",\\\"Authors\\\":\\\"Garth, C.;Krishnan, H.;Tricoche, X.;Tricoche, X.;Joy, K.I.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;IsosurfaceAndSurfaceExtractionTechniques;TimeseriesTimeVaryingDataAndTechniques;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.133\\\",\\\"Keywords\\\":\\\"flow visualization;3d vector field visualization;time-varying and time-series visualization;surface extraction\\\",\\\"Keywords_Processed\\\":\\\"3d vector field visualization;surface extraction;time varying and time series visualization;flow visualization\\\",\\\"Title\\\":\\\"Generation of Accurate Integral Surfaces in Time-Dependent Vector fields\\\"},\\\"718\\\":{\\\"Abstract\\\":\\\"This paper presents a novel and efficient surface matching and visualization framework through the geodesic distance-weighted shape vector image diffusion. Based on conformal geometry, our approach can uniquely map a 3D surface to a canonical rectangular domain and encode the shape characteristics (e.g., mean curvatures and conformal factors) of the surface in the 2D domain to construct a geodesic distance-weighted shape vector image, where the distances between sampling pixels are not uniform but the actual geodesic distances on the manifold. Through the novel geodesic distance-weighted shape vector image diffusion presented in this paper, we can create a multiscale diffusion space, in which the cross-scale extrema can be detected as the robust geometric features for the matching and registration of surfaces. Therefore, statistical analysis and visualization of surface properties across subjects become readily available. The experiments on scanned surface models show that our method is very robust for feature extraction and surface matching even under noise and resolution change. We have also applied the framework on the real 3D human neocortical surfaces, and demonstrated the excellent performance of our approach in statistical analysis and integrated visualization of the multimodality volumetric data over the shape vector image.\\\",\\\"Authors\\\":\\\"Jing Hua;Zhaoqiang Lai;Ming Dong;Xianfeng Gu;Hong Qin\\\",\\\"Clusters\\\":\\\"DiffusionRelatedTechniques;ShapeRelatedTechniques;SurfaceRelatedDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.134\\\",\\\"Keywords\\\":\\\"visualization;surface matching;shape vector image;multi-scale diffusion\\\",\\\"Keywords_Processed\\\":\\\"visualization;surface matching;multi scale diffusion;shape vector image\\\",\\\"Title\\\":\\\"Geodesic Distance-weighted Shape Vector Image Diffusion\\\"},\\\"719\\\":{\\\"Abstract\\\":\\\"Myocardial perfusion imaging with single photon emission computed tomography (SPECT) is an established method for the detection and evaluation of coronary artery disease (CAD). State-of-the-art SPECT scanners yield a large number of regional parameters of the left-ventricular myocardium (e.g., blood supply at rest and during stress, wall thickness, and wall thickening during heart contraction) that all need to be assessed by the physician. Today, the individual parameters of this multivariate data set are displayed as stacks of 2D slices, bull's eye plots, or, more recently, surfaces in 3D, which depict the left-ventricular wall. In all these visualizations, the data sets are displayed side-by-side rather than in an integrated manner, such that the multivariate data have to be examined sequentially and need to be fused mentally. This is time consuming and error-prone. In this paper we present an interactive 3D glyph visualization, which enables an effective integrated visualization of the multivariate data. Results from semiotic theory are used to optimize the mapping of different variables to glyph properties. This facilitates an improved perception of important information and thus an accelerated diagnosis. The 3D glyphs are linked to the established 2D views, which permit a more detailed inspection, and to relevant meta-information such as known stenoses of coronary vessels supplying the myocardial region. Our method has demonstrated its potential for clinical routine use in real application scenarios assessed by nuclear physicians.\\\",\\\"Authors\\\":\\\"Meyer-Spradow, J.;Stegger, L.;Doring, C.;Ropinski, T.;Hinrichs, K.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;GlyphsGlyphBasedTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.136\\\",\\\"Keywords\\\":\\\"spect;myocardial perfusion imaging;multivariate visualization;glyph-based techniques\\\",\\\"Keywords_Processed\\\":\\\"spect;multivariate visualization;myocardial perfusion imaging;glyph base technique\\\",\\\"Title\\\":\\\"Glyph-Based SPECT Visualization for the Diagnosis of Coronary Artery Disease\\\"},\\\"720\\\":{\\\"Abstract\\\":\\\"One of the most prominent topics in climate research is the investigation, detection, and allocation of climate change. In this paper, we aim at identifying regions in the atmosphere (e.g., certain height layers) which can act as sensitive and robust indicators for climate change. We demonstrate how interactive visual data exploration of large amounts of multi-variate and time-dependent climate data enables the steered generation of promising hypotheses for subsequent statistical evaluation. The use of new visualization and interaction technology-in the context of a coordinated multiple views framework-allows not only to identify these promising hypotheses, but also to efficiently narrow down parameters that are required in the process of computational data analysis. Two datasets, namely an ECHAM5 climate model run and the ERA-40 reanalysis incorporating observational data, are investigated. Higher-order information such as linear trends or signal-to-noise ratio is derived and interactively explored in order to detect and explore those regions which react most sensitively to climate change. As one conclusion from this study, we identify an excellent potential for usefully generalizing our approach to other, similar application cases, as well.\\\",\\\"Authors\\\":\\\"Kehrer, J.;Ladstadter, F.;Muigg, P.;Doleisch, H.;Steiner, A.;Hauser, H.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;EarthSpaceAndEnvironmentalSciences;HypothesisFormingTestingAndVisualEvidence\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.139\\\",\\\"Keywords\\\":\\\"interactive visual hypothesis generation;visualization for climate research;interactive visual exploration and analysis\\\",\\\"Keywords_Processed\\\":\\\"interactive visual exploration and analysis;interactive visual hypothesis generation;visualization for climate research\\\",\\\"Title\\\":\\\"Hypothesis Generation in Climate Research with Interactive Visual Data Exploration\\\"},\\\"721\\\":{\\\"Abstract\\\":\\\"The ability to identify and present the most essential aspects of time-varying data is critically important in many areas of science and engineering. This paper introduces an importance-driven approach to time-varying volume data visualization for enhancing that ability. By conducting a block-wise analysis of the data in the joint feature-temporal space, we derive an importance curve for each data block based on the formulation of conditional entropy from information theory. Each curve characterizes the local temporal behavior of the respective block, and clustering the importance curves of all the volume blocks effectively classifies the underlying data. Based on different temporal trends exhibited by importance curves and their clustering results, we suggest several interesting and effective visualization techniques to reveal the important aspects of time-varying data.\\\",\\\"Authors\\\":\\\"Chaoli Wang;Hongfeng Yu;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;InformationTheory;TimeseriesTimeVaryingDataAndTechniques;VisualEncodingAndLayoutGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.140\\\",\\\"Keywords\\\":\\\"clustering;time-varying data;highlighting;transfer function;joint feature-temporal space;conditional entropy\\\",\\\"Keywords_Processed\\\":\\\"time vary datum;conditional entropy;transfer function;clustering;highlight;joint feature temporal space\\\",\\\"Title\\\":\\\"Importance-Driven Time-Varying Data Visualization\\\"},\\\"722\\\":{\\\"Abstract\\\":\\\"Ventricular Assist Devices (VADs) support the heart in its vital task of maintaining circulation in the human body when the heart alone is not able to maintain a sufficient flow rate due to illness or degenerative diseases. However, the engineering of these devices is a highly demanding task. Advanced modeling methods and computer simulations allow the investigation of the fluid flow inside such a device and in particular of potential blood damage. In this paper we present a set of visualization methods which have been designed to specifically support the analysis of a tensor-based blood damage prediction model. This model is based on the tracing of particles through the VAD, for each of which the cumulative blood damage can be computed. The model's tensor output approximates a single blood cell's deformation in the flow field. The tensor and derived scalar data are subsequently visualized using techniques based on icons, particle visualization, and function plotting. All these techniques are accessible through a Virtual Reality-based user interface, which features not only stereoscopic rendering but also natural interaction with the complex three-dimensional data. To illustrate the effectiveness of these visualization methods, we present the results of an analysis session that was performed by domain experts for a specific data set for the MicroMed DeBakey VAD.\\\",\\\"Authors\\\":\\\"Hentschel, B.;Tedjo, I.;Probst, M.;Wolter, M.;Behr, M.;Bischof, C.;Kuhlen, T.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;ImmersiveAndVirtualEnvironments;TensorDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.142\\\",\\\"Keywords\\\":\\\"virtual reality;tensor visualization;blood damage;time-dependent data;ventricular assist device\\\",\\\"Keywords_Processed\\\":\\\"time dependent datum;tensor visualization;virtual reality;blood damage;ventricular assist device\\\",\\\"Title\\\":\\\"Interactive Blood Damage Analysis for Ventricular Assist Devices\\\"},\\\"723\\\":{\\\"Abstract\\\":\\\"Understanding fluid flow data, especially vortices, is still a challenging task. Sophisticated visualization tools help to gain insight. In this paper, we present a novel approach for the interactive comparison of scalar fields using isosurfaces, and its application to fluid flow datasets. Features in two scalar fields are defined by largest contour segmentation after topological simplification. These features are matched using a volumetric similarity measure based on spatial overlap of individual features. The relationships defined by this similarity measure are ranked and presented in a thumbnail gallery of feature pairs and a graph representation showing all relationships between individual contours. Additionally, linked views of the contour trees are provided to ease navigation. The main render view shows the selected features overlapping each other. Thus, by displaying individual features and their relationships in a structured fashion, we enable exploratory visualization of correlations between similar structures in two scalar fields. We demonstrate the utility of our approach by applying it to a number of complex fluid flow datasets, where the emphasis is put on the comparison of vortex related scalar quantities.\\\",\\\"Authors\\\":\\\"Schneider, D.;Wiebel, A.;Carr, H.;Hlawitschka, M.;Scheuermann, G.\\\",\\\"Clusters\\\":\\\"ComparisonComparativeVisualizationAndSimilarity;ContourCreasesRidgesValleys;FlowVisualizationDataAndTechniques;ScalarFieldDataTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.143\\\",\\\"Keywords\\\":\\\"scalar topology;flow visualization;contour tree;comparative visualization;largest contours\\\",\\\"Keywords_Processed\\\":\\\"contour tree;comparative visualization;scalar topology;large contour;flow visualization\\\",\\\"Title\\\":\\\"Interactive Comparison of Scalar fields Based on Largest Contours with Applications to Flow Visualization\\\"},\\\"724\\\":{\\\"Abstract\\\":\\\"Interactive steering with visualization has been a common goal of the visualization research community for twenty years, but it is rarely ever realized in practice. In this paper we describe a successful realization of a tightly coupled steering loop, integrating new simulation technology and interactive visual analysis in a prototyping environment for automotive industry system design. Due to increasing pressure on car manufacturers to meet new emission regulations, to improve efficiency, and to reduce noise, both simulation and visualization are pushed to their limits. Automotive system components, such as the powertrain system or the injection system have an increasing number of parameters, and new design approaches are required. It is no longer possible to optimize such a system solely based on experience or forward optimization. By coupling interactive visualization with the simulation back-end (computational steering), it is now possible to quickly prototype a new system, starting from a non-optimized initial prototype and the corresponding simulation model. The prototyping continues through the refinement of the simulation model, of the simulation parameters and through trial-and-error attempts to an optimized solution. The ability to early see the first results from a multidimensional simulation space - thousands of simulations are run for a multidimensional variety of input parameters - and to quickly go back into the simulation and request more runs in particular parameter regions of interest significantly improves the prototyping process and provides a deeper understanding of the system behavior. The excellent results which we achieved for the common rail injection system strongly suggest that our approach has a great potential of being generalized to other, similar scenarios.\\\",\\\"Authors\\\":\\\"Matkovic, K.;Gracanin, D.;Jelovic, M.;Hauser, H.\\\",\\\"Clusters\\\":\\\"Engineering;InteractionTechniquesGeneral;Simulation\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.145\\\",\\\"Keywords\\\":\\\"interactive visual analysis;common rail injection system;interactive computational steering;simulation\\\",\\\"Keywords_Processed\\\":\\\"simulation;interactive computational steering;interactive visual analysis;common rail injection system\\\",\\\"Title\\\":\\\"Interactive Visual Steering - Rapid Visual Prototyping of a Common Rail Injection System\\\"},\\\"725\\\":{\\\"Abstract\\\":\\\"A stand-alone visualization application has been developed by a multi-disciplinary, collaborative team with the sole purpose of creating an interactive exploration environment allowing turbulent flow researchers to experiment and validate hypotheses using visualization. This system has specific optimizations made in data management, caching computations, and visualization allowing for the interactive exploration of datasets on the order of 1TB in size. Using this application, the user (co-author Calo) is able to interactively visualize and analyze all regions of a transitional flow volume, including the laminar, transitional and fully turbulent regions. The underlying goal of the visualizations produced from these transitional flow simulations is to localize turbulent spots in the laminar region of the boundary layer, determine under which conditions they form, and follow their evolution. The initiation of turbulent spots, which ultimately lead to full turbulence, was located via a proposed feature detection condition and verified by experimental results. The conditions under which these turbulent spots form and coalesce are validated and presented.\\\",\\\"Authors\\\":\\\"Johnson, G.P.;Calo, V.M.;Gaither, K.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;FlowVisualizationDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.146\\\",\\\"Keywords\\\":\\\"applications of visualization;turbulence;flow visualization;transitional flow\\\",\\\"Keywords_Processed\\\":\\\"turbulence;transitional flow;application of visualization;flow visualization\\\",\\\"Title\\\":\\\"Interactive Visualization and Analysis of Transitional Flow\\\"},\\\"726\\\":{\\\"Abstract\\\":\\\"This paper presents a novel method for interactive exploration of industrial CT volumes such as cast metal parts, with the goal of interactively detecting, classifying, and quantifying features using a visualization-driven approach. The standard approach for defect detection builds on region growing, which requires manually tuning parameters such as target ranges for density and size, variance, as well as the specification of seed points. If the results are not satisfactory, region growing must be performed again with different parameters. In contrast, our method allows interactive exploration of the parameter space, completely separated from region growing in an unattended pre-processing stage. The pre-computed feature volume tracks a feature size curve for each voxel over time, which is identified with the main region growing parameter such as variance. A novel 3D transfer function domain over (density, feature.size, time) allows for interactive exploration of feature classes. Features and feature size curves can also be explored individually, which helps with transfer function specification and allows coloring individual features and disabling features resulting from CT artifacts. Based on the classification obtained through exploration, the classified features can be quantified immediately.\\\",\\\"Authors\\\":\\\"Hadwiger, M.;Laura, F.;Rezk-Salama, C.;Hollt, T.;Geier, G.;Pabel, T.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;ImageBasedDataImageSignalProcessing;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.147\\\",\\\"Keywords\\\":\\\"multi-dimensional transfer function;non-destructive testing;volume rendering;region growing\\\",\\\"Keywords_Processed\\\":\\\"non destructive testing;volume render;region growing;multi dimensional transfer function\\\",\\\"Title\\\":\\\"Interactive Volume Exploration for Feature Detection and Quantification in Industrial CT Data\\\"},\\\"727\\\":{\\\"Abstract\\\":\\\"We introduce a versatile framework for characterizing and extracting salient structures in three-dimensional symmetric second-order tensor fields. The key insight is that degenerate lines in tensor fields, as defined by the standard topological approach, are exactly crease (ridge and valley) lines of a particular tensor invariant called mode. This reformulation allows us to apply well-studied approaches from scientific visualization or computer vision to the extraction of topological lines in tensor fields. More generally, this main result suggests that other tensor invariants, such as anisotropy measures like fractional anisotropy (FA), can be used in the same framework in lieu of mode to identify important structural properties in tensor fields. Our implementation addresses the specific challenge posed by the non-linearity of the considered scalar measures and by the smoothness requirement of the crease manifold computation. We use a combination of smooth reconstruction kernels and adaptive refinement strategy that automatically adjust the resolution of the analysis to the spatial variation of the considered quantities. Together, these improvements allow for the robust application of existing ridge line extraction algorithms in the tensor context of our problem. Results are proposed for a diffusion tensor MRI dataset, and for a benchmark stress tensor field used in engineering research.\\\",\\\"Authors\\\":\\\"Tricoche, X.;Kindlmann, G.;Westin, C.-F.\\\",\\\"Clusters\\\":\\\"ContourCreasesRidgesValleys;TensorDataAndTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.148\\\",\\\"Keywords\\\":\\\"tensor field;crease extraction;tensor invariants;ridge lines;structural analysis;topology\\\",\\\"Keywords_Processed\\\":\\\"ridge line;tensor invariant;topology;crease extraction;structural analysis;tensor field\\\",\\\"Title\\\":\\\"Invariant Crease Lines for Topological and Structural Analysis of Tensor fields\\\"},\\\"728\\\":{\\\"Abstract\\\":\\\"Neurosurgical planning and image guided neurosurgery require the visualization of multimodal data obtained from various functional and structural image modalities, such as magnetic resonance imaging (MRI), computed tomography (CT), functional MRI, Single photon emission computed tomography (SPECT) and so on. In the case of epilepsy neurosurgery for example, these images are used to identify brain regions to guide intracranial electrode implantation and resection. Generally, such data is visualized using 2D slices and in some cases using a 3D volume rendering along with the functional imaging results. Visualizing the activation region effectively by still preserving sufficient surrounding brain regions for context is exceedingly important to neurologists and surgeons. We present novel interaction techniques for visualization of multimodal data to facilitate improved exploration and planning for neurosurgery. We extended the line widget from VTK to allow surgeons to control the shape of the region of the brain that they can visually crop away during exploration and surgery. We allow simple spherical, cubical, ellipsoidal and cylindrical (probe aligned cuts) for exploration purposes. In addition we integrate the cropping tool with the image-guided navigation system used for epilepsy neurosurgery. We are currently investigating the use of these new tools in surgical planning and based on further feedback from our neurosurgeons we will integrate them into the setup used for image-guided neurosurgery.\\\",\\\"Authors\\\":\\\"Joshi, A.;Scheinost, D.;Vives, K.P.;Spencer, D.D.;Staib, L.H.;Papademetris, X.\\\",\\\"Clusters\\\":\\\"InteractionTechniquesGeneral;Rendering\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.150\\\",\\\"Keywords\\\":\\\"user interaction;irregular cropping\\\",\\\"Keywords_Processed\\\":\\\"user interaction;irregular cropping\\\",\\\"Title\\\":\\\"Novel interaction techniques for neurosurgical planning and stereotactic navigation\\\"},\\\"729\\\":{\\\"Abstract\\\":\\\"Methods that faithfully and robustly capture the geometry of complex material interfaces in labeled volume data are important for generating realistic and accurate visualizations and simulations of real-world objects. The generation of such multimaterial models from measured data poses two unique challenges: first, the surfaces must be well-sampled with regular, efficient tessellations that are consistent across material boundaries; and second, the resulting meshes must respect the nonmanifold geometry of the multimaterial interfaces. This paper proposes a strategy for sampling and meshing multimaterial volumes using dynamic particle systems, including a novel, differentiable representation of the material junctions that allows the particle system to explicitly sample corners, edges, and surfaces of material intersections. The distributions of particles are controlled by fundamental sampling constraints, allowing Delaunay-based meshing algorithms to reliably extract watertight meshes of consistently high-quality.\\\",\\\"Authors\\\":\\\"Meyer, M.;Whitaker, R.T.;Kirby, R.M.;Ledergerber, C.;Pfister, H.\\\",\\\"Clusters\\\":\\\"MeshesGridsAndLattices;Sampling;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.154\\\",\\\"Keywords\\\":\\\"visualization;meshing;sampling\\\",\\\"Keywords_Processed\\\":\\\"visualization;sample;mesh\\\",\\\"Title\\\":\\\"Particle-based Sampling and Meshing of Surfaces in Multimaterial Volumes\\\"},\\\"730\\\":{\\\"Abstract\\\":\\\"The visualization and analysis of AMR-based simulations is integral to the process of obtaining new insight in scientific research. We present a new method for performing query-driven visualization and analysis on AMR data, with specific emphasis on time-varying AMR data. Our work introduces a new method that directly addresses the dynamic spatial and temporal properties of AMR grids that challenge many existing visualization techniques. Further, we present the first implementation of query-driven visualization on the GPU that uses a GPU-based indexing structure to both answer queries and efficiently utilize GPU memory. We apply our method to two different science domains to demonstrate its broad applicability.\\\",\\\"Authors\\\":\\\"Gosink, L.;Anderson, J.C.;Bethel, E.W.;Joy, K.I.\\\",\\\"Clusters\\\":\\\"AdaptiveProcessingAndRefinement;QueriesAndSearch;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.157\\\",\\\"Keywords\\\":\\\"adaptive mesh refinement;multi-temporal visualization;query-driven visualization\\\",\\\"Keywords_Processed\\\":\\\"adaptive mesh refinement;query drive visualization;multi temporal visualization\\\",\\\"Title\\\":\\\"Query-Driven Visualization of Time-Varying Adaptive Mesh Refinement Data\\\"},\\\"731\\\":{\\\"Abstract\\\":\\\"Volume exploration is an important issue in scientific visualization. Research on volume exploration has been focused on revealing hidden structures in volumetric data. While the information of individual structures or features is useful in practice, spatial relations between structures are also important in many applications and can provide further insights into the data. In this paper, we systematically study the extraction, representation,exploration, and visualization of spatial relations in volumetric data and propose a novel relation-aware visualization pipeline for volume exploration. In our pipeline, various relations in the volume are first defined and measured using region connection calculus (RCC) and then represented using a graph interface called relation graph. With RCC and the relation graph, relation query and interactive exploration can be conducted in a comprehensive and intuitive way. The visualization process is further assisted with relation-revealing viewpoint selection and color and opacity enhancement. We also introduce a quality assessment scheme which evaluates the perception of spatial relations in the rendered images. Experiments on various datasets demonstrate the practical use of our system in exploratory visualization.\\\",\\\"Authors\\\":\\\"Ming-Yuen Chan;Huamin Qu;Ka-Kei Chung;Wai-Ho Mak;Yingcai Wu\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;ComparisonComparativeVisualizationAndSimilarity;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.159\\\",\\\"Keywords\\\":\\\"exploratory visualization;relation-based visualization;visualization pipeline\\\",\\\"Keywords_Processed\\\":\\\"visualization pipeline;exploratory visualization;relation base visualization\\\",\\\"Title\\\":\\\"Relation-Aware Volume Exploration Pipeline\\\"},\\\"732\\\":{\\\"Abstract\\\":\\\"Recent results have shown a link between geometric properties of isosurfaces and statistical properties of the underlying sampled data. However, this has two defects: not all of the properties described converge to the same solution, and the statistics computed are not always invariant under isosurface-preserving transformations. We apply Federer's Coarea Formula from geometric measure theory to explain these discrepancies. We describe an improved substitute for histograms based on weighting with the inverse gradient magnitude, develop a statistical model that is invariant under isosurface-preserving transformations, and argue that this provides a consistent method for algorithm evaluation across multiple datasets based on histogram equalization. We use our corrected formulation to reevaluate recent results on average isosurface complexity, and show evidence that noise is one cause of the discrepancy between the expected figure and the observed one.\\\",\\\"Authors\\\":\\\"Scheidegger, C.E.;Schreiner, J.;Duffy, B.;Carr, H.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;IsosurfaceAndSurfaceExtractionTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.160\\\",\\\"Keywords\\\":\\\"isosurface;coarea formula;histogram\\\",\\\"Keywords_Processed\\\":\\\"histogram;isosurface;coarea formula\\\",\\\"Title\\\":\\\"Revisiting Histograms and Isosurface Statistics\\\"},\\\"733\\\":{\\\"Abstract\\\":\\\"For difficult cases in endoscopic sinus surgery, a careful planning of the intervention is necessary. Due to the reduced field of view during the intervention, the surgeons have less information about the surrounding structures in the working area compared to open surgery. Virtual endoscopy enables the visualization of the operating field and additional information, such as risk structures (e.g., optical nerve and skull base) and target structures to be removed (e.g., mucosal swelling). The Sinus Endoscopy system provides the functional range of a virtual endoscopic system with special focus on a realistic representation. Furthermore, by using direct volume rendering, we avoid time-consuming segmentation steps for the use of individual patient datasets. However, the image quality of the endoscopic view can be adjusted in a way that a standard computer with a modern standard graphics card achieves interactive frame rates with low CPU utilization. Thereby, characteristics of the endoscopic view are systematically used for the optimization of the volume rendering speed. The system design was based on a careful analysis of the endoscopic sinus surgery and the resulting needs for computer support. As a small standalone application it can be instantly used for surgical planning and patient education. First results of a clinical evaluation with ENT surgeons were employed to fine-tune the user interface, in particular to reduce the number of controls by using appropriate default values wherever possible. The system was used for preoperative planning in 102 cases, provides useful information for intervention planning (e.g., anatomic variations of the Rec. Frontalis), and closely resembles the intraoperative situation.\\\",\\\"Authors\\\":\\\"Kruger, A.;Kubisch, C.;Preim, B.;Preim, B.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.161\\\",\\\"Keywords\\\":\\\"volume rendering;medical visualization;operation planning;sinus surgery;virtual endoscopy\\\",\\\"Keywords_Processed\\\":\\\"volume render;virtual endoscopy;operation planning;sinus surgery;medical visualization\\\",\\\"Title\\\":\\\"Sinus Endoscopy - Application of Advanced GPU Volume Rendering for Virtual Endoscopy\\\"},\\\"734\\\":{\\\"Abstract\\\":\\\"The visualization of complex 3D images remains a challenge, a fact that is magnified by the difficulty to classify or segment volume data. In this paper, we introduce size-based transfer functions, which map the local scale of features to color and opacity. Features in a data set with similar or identical scalar values can be classified based on their relative size. We achieve this with the use of scale fields, which are 3D fields that represent the relative size of the local feature at each voxel. We present a mechanism for obtaining these scale fields at interactive rates, through a continuous scale-space analysis and a set of detection filters. Through a number of examples, we show that size-based transfer functions can improve classification and enhance volume rendering techniques, such as maximum intensity projection. The ability to classify objects based on local size at interactive rates proves to be a powerful method for complex data exploration.\\\",\\\"Authors\\\":\\\"Correa, C.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;InteractionTechniquesGeneral;MultiScaleDataTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.162\\\",\\\"Keywords\\\":\\\"interactive visualization;volume rendering;transfer function;gpu techniques;scale space\\\",\\\"Keywords_Processed\\\":\\\"volume render;scale space;transfer function;gpu technique;interactive visualization\\\",\\\"Title\\\":\\\"Size-based Transfer Functions: A New Volume Exploration Technique\\\"},\\\"735\\\":{\\\"Abstract\\\":\\\"Smoke rendering is a standard technique for flow visualization. Most approaches are based on a volumetric, particle based, or image based representation of the smoke. This paper introduces an alternative representation of smoke structures: as semi-transparent streak surfaces. In order to make streak surface integration fast enough for interactive applications, we avoid expensive adaptive retriangulations by coupling the opacity of the triangles to their shapes. This way, the surface shows a smoke-like look even in rather turbulent areas. Furthermore, we show modifications of the approach to mimic smoke nozzles, wool tufts, and time surfaces. The technique is applied to a number of test data sets.\\\",\\\"Authors\\\":\\\"von Funck, W.;Weinkauf, T.;Theisel, H.;Seidel, H.-P.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;ParticleVisualizationAndTechniques;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.163\\\",\\\"Keywords\\\":\\\"unsteady flow visualization;smoke visualization;streak surfaces\\\",\\\"Keywords_Processed\\\":\\\"smoke visualization;streak surface;unsteady flow visualization\\\",\\\"Title\\\":\\\"Smoke Surfaces: An Interactive Flow Visualization Technique Inspired by Real-World Flow Experiments\\\"},\\\"736\\\":{\\\"Abstract\\\":\\\"Smooth surface extraction using partial differential equations (PDEs) is a well-known and widely used technique for visualizing volume data. Existing approaches operate on gridded data and mainly on regular structured grids. When considering unstructured point-based volume data where sample points do not form regular patterns nor are they connected in any form, one would typically resample the data over a grid prior to applying the known PDE-based methods. We propose an approach that directly extracts smooth surfaces from unstructured point-based volume data without prior resampling or mesh generation. When operating on unstructured data one needs to quickly derive neighborhood information. The respective information is retrieved by partitioning the 3D domain into cells using a fed-tree and operating on its cells. We exploit neighborhood information to estimate gradients and mean curvature at every sample point using a four-dimensional least-squares fitting approach. Gradients and mean curvature are required for applying the chosen PDE-based method that combines hyperbolic advection to an isovalue of a given scalar field and mean curvature flow. Since we are using an explicit time-integration scheme, time steps and neighbor locations are bounded to ensure convergence of the process. To avoid small global time steps, one can use asynchronous local integration. We extract a smooth surface by successively fitting a smooth auxiliary function to the data set. This auxiliary function is initialized as a signed distance function. For each sample and for every time step we compute the respective gradient, the mean curvature, and a stable time step. With these informations the auxiliary function is manipulated using an explicit Euler time integration. The process successively continues with the next sample point in time. If the norm of the auxiliary function gradient in a sample exceeds a given threshold at some time, the auxiliary function is reinitialized to a signed dista- - nce function. After convergence of the evolvution, the resulting smooth surface is obtained by extracting the zero isosurface from the auxiliary function using direct isosurface extraction from unstructured point-based volume data and rendering the extracted surface using point-based rendering methods.\\\",\\\"Authors\\\":\\\"Rosenthal, P.;Linsen, L.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;NumericalMethodsMathematics;PdeSForVisualization;PointBasedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.164\\\",\\\"Keywords\\\":\\\"surface extraction;partial differential equation;point-based visualization;level sets\\\",\\\"Keywords_Processed\\\":\\\"level set;partial differential equation;surface extraction;point base visualization\\\",\\\"Title\\\":\\\"Smooth Surface Extraction from Unstructured Point-based Volume Data Using PDEs\\\"},\\\"737\\\":{\\\"Abstract\\\":\\\"Data sets resulting from physical simulations typically contain a multitude of physical variables. It is, therefore, desirable that visualization methods take into account the entire multi-field volume data rather than concentrating on one variable. We present a visualization approach based on surface extraction from multi-field particle volume data. The surfaces segment the data with respect to the underlying multi-variate function. Decisions on segmentation properties are based on the analysis of the multi-dimensional feature space. The feature space exploration is performed by an automated multi-dimensional hierarchical clustering method, whose resulting density clusters are shown in the form of density level sets in a 3D star coordinate layout. In the star coordinate layout, the user can select clusters of interest. A selected cluster in feature space corresponds to a segmenting surface in object space. Based on the segmentation property induced by the cluster membership, we extract a surface from the volume data. Our driving applications are smoothed particle hydrodynamics (SPH) simulations, where each particle carries multiple properties. The data sets are given in the form of unstructured point-based volume data. We directly extract our surfaces from such data without prior resampling or grid generation. The surface extraction computes individual points on the surface, which is supported by an efficient neighborhood computation. The extracted surface points are rendered using point-based rendering operations. Our approach combines methods in scientific visualization for object-space operations with methods in information visualization for feature-space operations.\\\",\\\"Authors\\\":\\\"Linsen, L.;Van Long, T.;Rosenthal, P.;Rosswog, S.\\\",\\\"Clusters\\\":\\\"AstronomyAstrophysics;IsosurfaceAndSurfaceExtractionTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;ParticleVisualizationAndTechniques;PointBasedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.167\\\",\\\"Keywords\\\":\\\"visualization in astrophysics;multi-field and multi-variate visualization;star coordinates;isosurfaces and surface extraction;point-based visualization;particle simulations\\\",\\\"Keywords_Processed\\\":\\\"star coordinate;particle simulation;point base visualization;multi field and multi variate visualization;visualization in astrophysic;isosurface and surface extraction\\\",\\\"Title\\\":\\\"Surface Extraction from Multi-field Particle Volume Data Using Multi-dimensional Cluster Visualization\\\"},\\\"738\\\":{\\\"Abstract\\\":\\\"In this paper we introduce a technique for applying textual labels to 3D surfaces. An effective labeling must balance the conflicting goals of conveying the shape of the surface while being legible from a range of viewing directions. Shape can be conveyed by placing the text as a texture directly on the surface, providing shape cues, meaningful landmarks and minimally obstructing the rest of the model. But rendering such surface text is problematic both in regions of high curvature, where text would be warped, and in highly occluded regions, where it would be hidden. Our approach achieves both labeling goals by applying surface labels to a psilatext scaffoldpsila, a surface explicitly constructed to hold the labels. Text scaffolds conform to the underlying surface whenever possible, but can also float above problem regions, allowing them to be smooth while still conveying the overall shape. This paper provides methods for constructing scaffolds from a variety of input sources, including meshes, constructive solid geometry, and scalar fields. These sources are first mapped into a distance transform, which is then filtered and used to construct a new mesh on which labels are either manually or automatically placed. In the latter case, annotated regions of the input surface are associated with proximal regions on the new mesh, and labels placed using cartographic principles.\\\",\\\"Authors\\\":\\\"Cipriano, G.;Gleicher, M.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;Labeling;SurfaceRelatedDataAndTechniques;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.168\\\",\\\"Keywords\\\":\\\"annotation;computational cartography;surface labeling;text authoring\\\",\\\"Keywords_Processed\\\":\\\"annotation;computational cartography;surface labeling;text author\\\",\\\"Title\\\":\\\"Text Scaffolds for Effective Surface Labeling\\\"},\\\"739\\\":{\\\"Abstract\\\":\\\"Visualization of volumetric data faces the difficult task of finding effective parameters for the transfer functions. Those parameters can determine the effectiveness and accuracy of the visualization. Frequently, volumetric data includes multiple structures and features that need to be differentiated. However, if those features have the same intensity and gradient values, existing transfer functions are limited at effectively illustrating those similar features with different rendering properties. We introduce texture-based transfer functions for direct volume rendering. In our approach, the voxelpsilas resulting opacity and color are based on local textural properties rather than individual intensity values. For example, if the intensity values of the vessels are similar to those on the boundary of the lungs, our texture-based transfer function will analyze the textural properties in those regions and color them differently even though they have the same intensity values in the volume. The use of texture-based transfer functions has several benefits. First, structures and features with the same intensity and gradient values can be automatically visualized with different rendering properties. Second, segmentation or prior knowledge of the specific features within the volume is not required for classifying these features differently. Third, textural metrics can be combined and/or maximized to capture and better differentiate similar structures. We demonstrate our texture-based transfer function for direct volume rendering with synthetic and real-world medical data to show the strength of our technique.\\\",\\\"Authors\\\":\\\"Caban, J.J.;Rheingans, P.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DataFeaturesAndAttributes;MachineLearningAndStatistics;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.169\\\",\\\"Keywords\\\":\\\"volume rendering;data variability;visualization;statistical analysis;medical imaging\\\",\\\"Keywords_Processed\\\":\\\"visualization;volume render;medical imaging;data variability;statistical analysis\\\",\\\"Title\\\":\\\"Texture-based Transfer Functions for Direct Volume Rendering\\\"},\\\"740\\\":{\\\"Abstract\\\":\\\"We present a toolbox for quickly interpreting and illustrating 2D slices of seismic volumetric reflection data. Searching for oil and gas involves creating a structural overview of seismic reflection data to identify hydrocarbon reservoirs. We improve the search of seismic structures by precalculating the horizon structures of the seismic data prior to interpretation. We improve the annotation of seismic structures by applying novel illustrative rendering algorithms tailored to seismic data, such as deformed texturing and line and texture transfer functions. The illustrative rendering results in multi-attribute and scale invariant visualizations where features are represented clearly in both highly zoomed in and zoomed out views. Thumbnail views in combination with interactive appearance control allows for a quick overview of the data before detailed interpretation takes place. These techniques help reduce the work of seismic illustrators and interpreters.\\\",\\\"Authors\\\":\\\"Patel, D.;Giertsen, C.;Thurmond, J.;Gjelberg, J.;Groller, E.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;EarthSpaceAndEnvironmentalSciences;IllustrativeVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.170\\\",\\\"Keywords\\\":\\\"seismic interpretation;top-down interpretation;seismic attributes;illustrative rendering\\\",\\\"Keywords_Processed\\\":\\\"illustrative render;top down interpretation;seismic attribute;seismic interpretation\\\",\\\"Title\\\":\\\"The Seismic Analyzer: Interpreting and Illustrating 2D Seismic Data\\\"},\\\"741\\\":{\\\"Abstract\\\":\\\"Radviz is a radial visualization with dimensions assigned to points called dimensional anchors (DAs) placed on the circumference of a circle. Records are assigned locations within the circle as a function of its relative attraction to each of the DAs. The DAs can be moved either interactively or algorithmically to reveal different meaningful patterns in the dataset. In this paper we describe Vectorized Radviz (VRV) which extends the number of dimensions through data flattening. We show how VRV increases the power of Radviz through these extra dimensions by enhancing the flexibility in the layout of the DAs. We apply VRV to the problem of analyzing the results of multiple clusterings of the same data set, called multiple cluster sets or cluster ensembles. We show how features of VRV help discern patterns across the multiple cluster sets. We use the Iris data set to explain VRV and a newt gene microarray data set used in studying limb regeneration to show its utility. We then discuss further applications of VRV.\\\",\\\"Authors\\\":\\\"Sharko, J.;Grinstein, G.;Marx, K.\\\",\\\"Clusters\\\":\\\"DataAcquisitionAndManagement;DataClusteringAndAggregation;MultidimensionalMultivariateMultifieldDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.173\\\",\\\"Keywords\\\":\\\"clustering;flattening datasets;visualization;multiple clustering;vectorized radviz;cluster ensembles;radviz\\\",\\\"Keywords_Processed\\\":\\\"visualization;flatten dataset;cluster ensemble;vectorize radviz;multiple clustering;clustering;radviz\\\",\\\"Title\\\":\\\"Vectorized Radviz and Its Application to Multiple Cluster Datasets\\\"},\\\"742\\\":{\\\"Abstract\\\":\\\"Building visualization and analysis pipelines is a large hurdle in the adoption of visualization and workflow systems by domain scientists. In this paper, we propose techniques to help users construct pipelines by consensus-automatically suggesting completions based on a database of previously created pipelines. In particular, we compute correspondences between existing pipeline subgraphs from the database, and use these to predict sets of likely pipeline additions to a given partial pipeline. By presenting these predictions in a carefully designed interface, users can create visualizations and other data products more efficiently because they can augment their normal work patterns with the suggested completions. We present an implementation of our technique in a publicly-available, open-source scientific workflow system and demonstrate efficiency gains in real-world situations.\\\",\\\"Authors\\\":\\\"Koop, D.;Scheidegger, C.E.;Callahan, S.P.;Freire, J.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.174\\\",\\\"Keywords\\\":\\\"scientific visualization;auto completion;scientific workflows\\\",\\\"Keywords_Processed\\\":\\\"scientific visualization;scientific workflow;auto completion\\\",\\\"Title\\\":\\\"VisComplete: Automating Suggestions for Visualization Pipelines\\\"},\\\"743\\\":{\\\"Abstract\\\":\\\"In this paper we present an algorithm that operates on a triangular mesh and classifies each face of a triangle as either inside or outside. We present three example applications of this core algorithm: normal orientation, inside removal, and layer-based visualization. The distinguishing feature of our algorithm is its robustness even if a difficult input model that includes holes, coplanar triangles, intersecting triangles, and lost connectivity is given. Our algorithm works with the original triangles of the input model and uses sampling to construct a visibility graph that is then segmented using graph cut.\\\",\\\"Authors\\\":\\\"Zhou, K.;Zhang, E.;Bittner, J.;Wonka, P.\\\",\\\"Clusters\\\":\\\"GeometricModeling;ImageBasedDataImageSignalProcessing;SegmentationAndClassification\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.176\\\",\\\"Keywords\\\":\\\"normal orientation;graph cut;interior/exterior classification;inside removal;layer classification\\\",\\\"Keywords_Processed\\\":\\\"normal orientation;graph cut;interior exterior classification;layer classification;inside removal\\\",\\\"Title\\\":\\\"Visibility-driven Mesh Analysis and Visualization through Graph Cuts\\\"},\\\"744\\\":{\\\"Abstract\\\":\\\"Visualization of general relativity illustrates aspects of Einstein's insights into the curved nature of space and time to the expert as well as the layperson. One of the most interesting models which came up with Einstein's theory was developed by Kurt Godel in 1949. The Godel universe is a valid solution of Einstein's field equations, making it a possible physical description of our universe. It offers remarkable features like the existence of an optical horizon beyond which time travel is possible. Although we know that our universe is not a Godel universe, it is interesting to visualize physical aspects of a world model resulting from a theory which is highly confirmed in scientific history. Standard techniques to adopt an egocentric point of view in a relativistic world model have shortcomings with respect to the time needed to render an image as well as difficulties in applying a direct illumination model. In this paper we want to face both issues to reduce the gap between common visualization standards and relativistic visualization. We will introduce two techniques to speed up recalculation of images by means of preprocessing and lookup tables and to increase image quality through a special optimization applicable to the Godel universe. The first technique allows the physicist to understand the different effects of general relativity faster and better by generating images from existing datasets interactively. By using the intrinsic symmetries of Godel's spacetime which are expressed by the Killing vector field, we are able to reduce the necessary calculations to simple cases using the second technique. This even makes it feasible to account for a direct illumination model during the rendering process. Although the presented methods are applied to Godel's universe, they can also be extended to other manifolds, for example light propagation in moving dielectric media. Therefore, other areas of research can benefit from these generic improvements.\\\",\\\"Authors\\\":\\\"Grave, F.;Buser, M.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;PhysicsAndPhysicalSciences;RaytracingRaycasting\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.177\\\",\\\"Keywords\\\":\\\"godel universe;time travel;non-linear raytracing;general relativity\\\",\\\"Keywords_Processed\\\":\\\"general relativity;time travel;godel universe;non linear raytracing\\\",\\\"Title\\\":\\\"Visiting the G&#x0F6;del Universe\\\"},\\\"745\\\":{\\\"Abstract\\\":\\\"Understanding the structure of microvasculature structures and their relationship to cells in biological tissue is an important and complex problem. Brain microvasculature in particular is known to play an important role in chronic diseases. However, these networks are only visible at the microscopic level and can span large volumes of tissue. Due to recent advances in microscopy, large volumes of data can be imaged at the resolution necessary to reconstruct these structures. Due to the dense and complex nature of microscopy data sets, it is important to limit the amount of information displayed. In this paper, we describe methods for encoding the unique structure of microvascular data, allowing researchers to selectively explore microvascular anatomy. We also identify the queries most useful to researchers studying microvascular and cellular relationships. By associating cellular structures with our microvascular framework, we allow researchers to explore interesting anatomical relationships in dense and complex data sets.\\\",\\\"Authors\\\":\\\"Mayerich, D.;Abbott, L..;Keyser, J.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;BiomedicalScienceAndMedicine;Microscopy\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.179\\\",\\\"Keywords\\\":\\\"cells;biomedical;blood vessels;medical;microscopy\\\",\\\"Keywords_Processed\\\":\\\"cell;microscopy;medical;blood vessel;biomedical\\\",\\\"Title\\\":\\\"Visualization of Cellular and Microvascular Relationships\\\"},\\\"746\\\":{\\\"Abstract\\\":\\\"Visually assessing the effect of the coronary artery anatomy on the perfusion of the heart muscle in patients with coronary artery disease remains a challenging task. We explore the feasibility of visualizing this effect on perfusion using a numerical approach. We perform a computational simulation of the way blood is perfused throughout the myocardium purely based on information from a three-dimensional anatomical tomographic scan. The results are subsequently visualized using both three-dimensional visualizations and bullpsilas eye plots, partially inspired by approaches currently common in medical practice. Our approach results in a comprehensive visualization of the coronary anatomy that compares well to visualizations commonly used for other scanning technologies. We demonstrate techniques giving detailed insight in blood supply, coronary territories and feeding coronary arteries of a selected region. We demonstrate the advantages of our approach through visualizations that show information which commonly cannot be directly observed in scanning data, such as a separate visualization of the supply from each coronary artery. We thus show that the results of a computational simulation can be effectively visualized and facilitate visually correlating these results to for example perfusion data.\\\",\\\"Authors\\\":\\\"Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, E.;Nagel, E.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.180\\\",\\\"Keywords\\\":\\\"cardiac visualization;coronary artery territories;myocardial perfusion\\\",\\\"Keywords_Processed\\\":\\\"cardiac visualization;coronary artery territory;myocardial perfusion\\\",\\\"Title\\\":\\\"Visualization of Myocardial Perfusion Derived from Coronary Anatomy\\\"},\\\"747\\\":{\\\"Abstract\\\":\\\"With recent advances in the measurement technology for allsky astrophysical imaging, our view of the sky is no longer limited to the tiny visible spectral range over the 2D Celestial sphere. We now can access a third dimension corresponding to a broad electromagnetic spectrum with a wide range of allsky surveys; these surveys span frequency bands including long long wavelength radio, microwaves, very short X-rays, and gamma rays. These advances motivate us to study and examine multiwavelength visualization techniques to maximize our capabilities to visualize and exploit these informative image data sets. In this work, we begin with the processing of the data themselves, uniformizing the representations and units of raw data obtained from varied detector sources. Then we apply tools to map, convert, color-code, and format the multiwavelength data in forms useful for applications. We explore different visual representations for displaying the data, including such methods as textured image stacks, the horseshoe representation, and GPU-based volume visualization. A family of visual tools and analysis methods are introduced to explore the data, including interactive data mapping on the graphics processing unit (GPU), the mini-map explorer, and GPU-based interactive feature analysis.\\\",\\\"Authors\\\":\\\"Hongwei Li;Chi-Wing Fu;Hanson, A.J.\\\",\\\"Clusters\\\":\\\"AstronomyAstrophysics;MultiScaleDataTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.182\\\",\\\"Keywords\\\":\\\"astronomy;multiwavelength data;astrophysical visualization\\\",\\\"Keywords_Processed\\\":\\\"multiwavelength datum;astrophysical visualization;astronomy\\\",\\\"Title\\\":\\\"Visualizing Multiwavelength Astrophysical Data\\\"},\\\"748\\\":{\\\"Abstract\\\":\\\"Particle deposition in the small bronchial tubes (generations six through twelve) is strongly influenced by the vortex-dominated secondary flows that are induced by axial curvature of the tubes. In this paper, we employ particle destination maps in conjunction with two-dimensional, finite-time Lyapunov exponent maps to illustrate how the trajectories of finite-mass particles are influenced by the presence of vortices. We consider two three-generation bronchial tube models: a planar, asymmetric geometry and a non-planar, asymmetric geometry. Our visualizations demonstrate that these techniques, coupled with judiciously seeded particle trajectories, are effective tools for studying particle/flow structure interactions.\\\",\\\"Authors\\\":\\\"Soni, B.;Thompson, D.;Machiraju, R.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;NumericalMethodsMathematics;ParticleVisualizationAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.183\\\",\\\"Keywords\\\":\\\"visualization;bronchial tube;finite-time lyapunov exponent;particle trajectory\\\",\\\"Keywords_Processed\\\":\\\"visualization;finite time lyapunov exponent;bronchial tube;particle trajectory\\\",\\\"Title\\\":\\\"Visualizing Particle/Flow Structure Interactions in the Small Bronchial Tubes\\\"},\\\"749\\\":{\\\"Abstract\\\":\\\"Extracting and visualizing temporal patterns in large scientific data is an open problem in visualization research. First, there are few proven methods to flexibly and concisely define general temporal patterns for visualization. Second, with large time-dependent data sets, as typical with todaypsilas large-scale simulations, scalable and general solutions for handling the data are still not widely available. In this work, we have developed a textual pattern matching approach for specifying and identifying general temporal patterns. Besides defining the formalism of the language, we also provide a working implementation with sufficient efficiency and scalability to handle large data sets. Using recent large-scale simulation data from multiple application domains, we demonstrate that our visualization approach is one of the first to empower a concept driven exploration of large-scale time-varying multivariate data.\\\",\\\"Authors\\\":\\\"Glatter, M.;Huang, J.;Ahern, S.;Daniel, J.;Aidong Lu\\\",\\\"Clusters\\\":\\\"MultidimensionalMultivariateMultifieldDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.184\\\",\\\"Keywords\\\":\\\"uncertainty;time-varying;multivariate visualization\\\",\\\"Keywords_Processed\\\":\\\"uncertainty;time vary;multivariate visualization\\\",\\\"Title\\\":\\\"Visualizing Temporal Patterns in Large Multivariate Data using Textual Pattern Matching\\\"},\\\"750\\\":{\\\"Abstract\\\":\\\"The method of Moving Least Squares (MLS) is a popular framework for reconstructing continuous functions from scattered data due to its rich mathematical properties and well-understood theoretical foundations. This paper applies MLS to volume rendering, providing a unified mathematical framework for ray casting of scalar data stored over regular as well as irregular grids. We use the MLS reconstruction to render smooth isosurfaces and to compute accurate derivatives for high-quality shading effects. We also present a novel, adaptive preintegration scheme to improve the efficiency of the ray casting algorithm by reducing the overall number of function evaluations, and an efficient implementation of our framework exploiting modern graphics hardware. The resulting system enables high-quality volume integration and shaded isosurface rendering for regular and irregular volume data.\\\",\\\"Authors\\\":\\\"Ledergerber, C.;Guennebaud, G.;Meyer, M.;Bacher, M.;Pfister, H.\\\",\\\"Clusters\\\":\\\"DataRegistrationFusionAndIntegration;Interpolation;MeshesGridsAndLattices;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2008.186\\\",\\\"Keywords\\\":\\\"adaptive integration;volume visualization;moving least squares reconstruction;unstructured grid\\\",\\\"Keywords_Processed\\\":\\\"volume visualization;adaptive integration;unstructured grid;move least square reconstruction\\\",\\\"Title\\\":\\\"Volume MLS Ray Casting\\\"},\\\"751\\\":{\\\"Abstract\\\":\\\"We describe a visual analytics (VA) infrastructure, rooted on techniques in machine learning and logic-based deductive reasoning that will assist analysts to make sense of large, complex data sets by facilitating the generation and validation of models representing relationships in the data. We use logic programming (LP) as the underlying computing machinery to encode the relations as rules and facts and compute with them. A unique aspect of our approach is that the LP rules are automatically learned, using Inductive Logic Programming, from examples of data that the analyst deems interesting when viewing the data in the high-dimensional visualization interface. Using this system, analysts will be able to construct models of arbitrary relationships in the data, explore the data for scenarios that fit the model, refine the model if necessary, and query the model to automatically analyze incoming (future) data exhibiting the encoded relationships. In other words it will support both model-driven data exploration, as well as data-driven model evolution. More importantly, by basing the construction of models on techniques from machine learning and logic-based deduction, the VA process will be both flexible in terms of modeling arbitrary, user-driven relationships in the data as well as readily scale across different data domains.\\\",\\\"Authors\\\":\\\"Garg, S.;Nam, J.E.;Ramakrishnan, I.;Mueller, K.\\\",\\\"Clusters\\\":\\\"ComputerNetworksNetworkSecurity;DataClusteringAndAggregation;KnowledgeDiscovery;MachineLearningAndStatistics;MultidimensionalMultivariateMultifieldDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2008.4677352\\\",\\\"Keywords\\\":\\\"high-dimensional data;machine learning;grand tour;knowledge discovery;visual clustering;network security;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"visual clustering;high dimensional datum;knowledge discovery;visual analytic;machine learning;grand tour;network security\\\",\\\"Title\\\":\\\"Model-driven Visual Analytics\\\"},\\\"752\\\":{\\\"Abstract\\\":\\\"We present a novel collaborative visual analytics application for cognitively overloaded users in the astrophysics domain. The system was developed for scientists needing to analyze heterogeneous, complex data under time pressure, and then make predictions and time-critical decisions rapidly and correctly under a constant influx of changing data. The Sunfall Data Taking system utilizes several novel visualization and analysis techniques to enable a team of geographically distributed domain specialists to effectively and remotely maneuver a custom-built instrument under challenging operational conditions. Sunfall Data Taking has been in use for over eighteen months by a major international astrophysics collaboration (the largest data volume supernova search currently in operation), and has substantially improved the operational efficiency of its users. We describe the system design process by an interdisciplinary team, the system architecture, and the results of an informal usability evaluation of the production system by domain experts in the context of Endsleypsilas three levels of situation awareness.\\\",\\\"Authors\\\":\\\"Aragon, C.R.;Poon, S.S.;Aldering, G.S.;Thomas, R.C.;Quimby, R.\\\",\\\"Clusters\\\":\\\"AstronomyAstrophysics;Cognition;VisualKnowledgeRepresentationAndExternalization\\\",\\\"DOI\\\":\\\"10.1109/VAST.2008.4677353\\\",\\\"Keywords\\\":\\\"scientific visualization;data and knowledge visualization;situation awareness;visual analytics;astrophysics\\\",\\\"Keywords_Processed\\\":\\\"datum and knowledge visualization;astrophysic;scientific visualization;visual analytic;situation awareness\\\",\\\"Title\\\":\\\"Using visual analytics to maintain situation awareness in astrophysics\\\"},\\\"753\\\":{\\\"Abstract\\\":\\\"Social network graphs, concept maps, and process charts are examples of diagrammatic representations employed by intelligence analysts to understand complex systems. Unfortunately, these 2D representations currently do not easily convey the flow, sequence, tempo and other important dynamic behaviors within these systems. In this paper we present Configurable Spaces, a novel analytical method for visualizing patterns of activity over time in complex diagrammatically- represented systems. Configurable Spaces extends GeoTime's X, Y, T coordinate workspace space for temporal analysis to any arbitrary diagrammatic work space by replacing a geographic map with a diagram. This paper traces progress from concept to prototype, and discusses how diagrams can be created, transformed and leveraged for analysis, including generating diagrams from knowledge bases, visualizing temporal concept maps, and the use of linked diagrams for exploring complex, multi-dimensional, sequences of events. An evaluation of the prototype by the National Institute of Standards and Technology showed intelligence analysts believed they were able to attain an increased level of insight, were able to explore data more efficiently, and that Configurable Spaces would help them work faster.\\\",\\\"Authors\\\":\\\"Kapler, T.;Eccles, R.;Harper, R.;Wright, W.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;HumanComputerInteractionHumanFactors;SpatiotemporalDataAndTechniques;VisualKnowledgeRepresentationAndExternalization\\\",\\\"DOI\\\":\\\"10.1109/VAST.2008.4677355\\\",\\\"Keywords\\\":\\\"concept maps;graph visualization;geo-temporal analysis;visual analytics;human-information interaction\\\",\\\"Keywords_Processed\\\":\\\"human information interaction;concept map;visual analytic;geo temporal analysis;graph visualization\\\",\\\"Title\\\":\\\"Configurable Spaces: Temporal analysis in diagrammatic contexts\\\"},\\\"754\\\":{\\\"Abstract\\\":\\\"Data about movements of various objects are collected in growing amounts by means of current tracking technologies. Traditional approaches to visualization and interactive exploration of movement data cannot cope with data of such sizes. In this research paper we investigate the ways of using aggregation for visual analysis of movement data. We define aggregation methods suitable for movement data and find visualization and interaction techniques to represent results of aggregations and enable comprehensive exploration of the data. We consider two possible views of movement, traffic-oriented and trajectory-oriented. Each view requires different methods of analysis and of data aggregation. We illustrate our argument with example data resulting from tracking multiple cars in Milan and example analysis tasks from the domain of city traffic management.\\\",\\\"Authors\\\":\\\"Andrienko, G.;Andrienko, N.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;DataClusteringAndAggregation;GeographyGeospatialVisCartographyTerrainVis;LargeScaleDataAndScalability;SpatiotemporalDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2008.4677356\\\",\\\"Keywords\\\":\\\"spatio-temporal data;aggregation;scalable visualization;movement data;geovisualization\\\",\\\"Keywords_Processed\\\":\\\"spatio temporal datum;aggregation;scalable visualization;geovisualization;movement datum\\\",\\\"Title\\\":\\\"Spatio-temporal aggregation for visual analysis of movements\\\"},\\\"755\\\":{\\\"Abstract\\\":\\\"Visual analytic tools allow analysts to generate large collections of useful analytical results. We anticipate that analysts in most real world situations will draw from these collections when working together to solve complicated problems. This indicates a need to understand how users synthesize multiple collections of results. This paper reports the results of collaborative synthesis experiments conducted with expert geographers and disease biologists. Ten participants were worked in pairs to complete a simulated real-world synthesis task using artifacts printed on cards on a large, paper-covered workspace. Experiment results indicate that groups use a number of different approaches to collaborative synthesis, and that they employ a variety of organizational metaphors to structure their information. It is further evident that establishing common ground and role assignment are critical aspects of collaborative synthesis. We conclude with a set of general design guidelines for collaborative synthesis support tools.\\\",\\\"Authors\\\":\\\"Robinson, A.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;DataClusteringAndAggregation;GeographyGeospatialVisCartographyTerrainVis;LargeScaleDataAndScalability;SpatiotemporalDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2008.4677358\\\",\\\"Keywords\\\":\\\"spatio-temporal data;aggregation;scalable visualization;movement data;geovisualization\\\",\\\"Keywords_Processed\\\":\\\"spatio temporal datum;aggregation;scalable visualization;geovisualization;movement datum\\\",\\\"Title\\\":\\\"Collaborative synthesis of visual analytic results\\\"},\\\"756\\\":{\\\"Abstract\\\":\\\"As the information being visualized and the process of understanding that information both become increasingly complex, it is necessary to develop new visualization approaches that facilitate the flow of human reasoning. In this paper, we endeavor to push visualization design a step beyond current user models by discussing a modeling framework of human ldquohigher cognition.rdquo Based on this cognition model, we present design guidelines for the development of visual interfaces designed to maximize the complementary cognitive strengths of both human and computer. Some of these principles are already being reflected in the better visual analytics designs, while others have not yet been applied or fully applied. But none of the guidelines have explained the deeper rationale that the model provides. Lastly, we discuss and assess these visual analytics guidelines through the evaluation of several visualization examples.\\\",\\\"Authors\\\":\\\"Green, T.M.;Ribarsky, W.;Fisher, B.\\\",\\\"Clusters\\\":\\\"Cognition;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/VAST.2008.4677361\\\",\\\"Keywords\\\":\\\"cognition and perception theory;embodied cognition;visualization taxonomies and models;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"visualization taxonomy and model;visual analytic;embody cognition;cognition and perception theory\\\",\\\"Title\\\":\\\"Visual analytics for complex concepts using a human cognition model\\\"},\\\"757\\\":{\\\"Abstract\\\":\\\"Software tools that make it easier for analysts to collaborate as a natural part of their work will lead to better analysis that is informed by more perspectives. We are interested to know if software tools can be designed that support collaboration even as they allow analysts to find documents and organize information (including evidence, schemas, and hypotheses). We have modified the Entity Workspace system, described previously, to test such designs. We have evaluated the resulting design in both a laboratory study and a study where it is situated with an analysis team. In both cases, effects on collaboration appear to be positive. Key aspects of the design include an evidence notebook optimized for organizing entities (rather than text characters), information structures that can be collapsed and expanded, visualization of evidence that emphasizes events and documents (rather than emphasizing the entity graph), and a notification system that finds entities of mutual interest to multiple analysts.\\\",\\\"Authors\\\":\\\"Bier, E.A.;Card, S.K.;Bodnar, J.W.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;Cognition;CollaborativeVisualization;InteractionTechniquesGeneral;PrivacySecurityIntelligenceAnalysis;SemanticsSemioticsRelatedTechniques;TextDocumentTopicAnalysisDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VAST.2008.4677362\\\",\\\"Keywords\\\":\\\"information foraging;intelligence analysis;collective intelligence;exploratory search;sensemaking;entity-based;collaboration;argumentation marshalling;information workspace;semantic notebook;visualization;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"visualization;exploratory search;intelligence analysis;collaboration;sensemake;semantic notebook;visual analytic;collective intelligence;entity base;information workspace;argumentation marshalling;information forage\\\",\\\"Title\\\":\\\"Entity-based collaboration tools for intelligence analysis\\\"},\\\"758\\\":{\\\"Abstract\\\":\\\"Analyzing unstructured text streams can be challenging. One popular approach is to isolate specific themes in the text, and to visualize the connections between them. Some existing systems, like ThemeRiver, provide a temporal view of changes in themes; other systems, like In-Spire, use clustering techniques to help an analyst identify the themes at a single point in time. Narratives combines both of these techniques; it uses a temporal axis to visualize ways that concepts have changed over time, and introduces several methods to explore how those concepts relate to each other. Narratives is designed to help the user place news stories in their historical and social context by understanding how the major topics associated with them have changed over time. Users can relate articles through time by examining the topical keywords that summarize a specific news event. By tracking the attention to a news article in the form of references in social media (such as weblogs), a user discovers both important events and measures the social relevance of these stories.\\\",\\\"Authors\\\":\\\"Fisher, D.;Hoff, A.;Robertson, G.;Hurst, M.\\\",\\\"Clusters\\\":\\\"EventsTrendsOutlierDetectionAnalysisAndVisualization;SocialNetworksAndSocialMedia;TextDocumentTopicAnalysisDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2008.4677364\\\",\\\"Keywords\\\":\\\"trends;blogs;time-series;topic detection and tracking;events\\\",\\\"Keywords_Processed\\\":\\\"time series;trend;blog;topic detection and tracking;event\\\",\\\"Title\\\":\\\"Narratives: A visualization to track narrative events as they develop\\\"},\\\"759\\\":{\\\"Abstract\\\":\\\"Insight provenance - a historical record of the process and rationale by which an insight is derived - is an essential requirement in many visual analytics applications. While work in this area has relied on either manually recorded provenance (e.g., user notes) or automatically recorded event-based insight provenance (e.g., clicks, drags, and key-presses), both approaches have fundamental limitations. Our aim is to develop a new approach that combines the benefits of both approaches while avoiding their deficiencies. Toward this goal, we characterize userspsila visual analytic activity at multiple levels of granularity. Moreover, we identify a critical level of abstraction, Actions, that can be used to represent visual analytic activity with a set of general but semantically meaningful behavior types. In turn, the action types can be used as the semantic building blocks for insight provenance. We present a catalog of common actions identified through observations of several different visual analytic systems. In addition, we define a taxonomy to categorize actions into three major classes based on their semantic intent. The concept of actions has been integrated into our labpsilas prototype visual analytic system, HARVEST, as the basis for its insight provenance capabilities.\\\",\\\"Authors\\\":\\\"Gotz, D.;Zhou, M.X.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;ProvenanceAndHistory;Taxonomies;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2008.4677365\\\",\\\"Keywords\\\":\\\"insight provenance;information visualization;analytic activity;visual analytics;taxonomy\\\",\\\"Keywords_Processed\\\":\\\"information visualization;visual analytic;taxonomy;insight provenance;analytic activity\\\",\\\"Title\\\":\\\"Characterizing users&#x2019; visual analytic activity for insight provenance\\\"},\\\"760\\\":{\\\"Abstract\\\":\\\"A central challenge in visual analytics is the creation of accessible, widely distributable analysis applications that bring the benefits of visual discovery to as broad a user base as possible. Moreover, to support the role of visualization in the knowledge creation process, it is advantageous to allow users to describe the reasoning strategies they employ while interacting with analytic environments. We introduce an application suite called the scalable reasoning system (SRS), which provides Web-based and mobile interfaces for visual analysis. The service-oriented analytic framework that underlies SRS provides a platform for deploying pervasive visual analytic environments across an enterprise. SRS represents a ldquolightweightrdquo approach to visual analytics whereby thin client analytic applications can be rapidly deployed in a platform-agnostic fashion. Client applications support multiple coordinated views while giving analysts the ability to record evidence, assumptions, hypotheses and other reasoning artifacts. We describe the capabilities of SRS in the context of a real-world deployment at a regional law enforcement organization.\\\",\\\"Authors\\\":\\\"Pike, W.A.;Bruce, J.;Baddeley, B.;Best, D.;Franklin, L.;May, R.;Rice, D.M.;Riensche, R.;Younkin, K.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;Cognition;InternetWebVisualizationForTheMasses;MultipleLinkedCoordinatedViews;SmallMobileUbiquitousDevicesDisplays\\\",\\\"DOI\\\":\\\"10.1109/VAST.2008.4677366\\\",\\\"Keywords\\\":\\\"mobile visualization;multiple views;law enforcement;analytic reasoning;web visualization\\\",\\\"Keywords_Processed\\\":\\\"law enforcement;mobile visualization;multiple view;analytic reasoning;web visualization\\\",\\\"Title\\\":\\\"The Scalable Reasoning System: Lightweight visualization for distributed analytics\\\"},\\\"761\\\":{\\\"Abstract\\\":\\\"Understanding multivariate relationships is an important task in multivariate data analysis. Unfortunately, existing multivariate visualization systems lose effectiveness when analyzing relationships among variables that span more than a few dimensions. We present a novel multivariate visual explanation approach that helps users interactively discover multivariate relationships among a large number of dimensions by integrating automatic numerical differentiation techniques and multidimensional visualization techniques. The result is an efficient workflow for multivariate analysis model construction, interactive dimension reduction, and multivariate knowledge discovery leveraging both automatic multivariate analysis and interactive multivariate data visual exploration. Case studies and a formal user study with a real dataset illustrate the effectiveness of this approach.\\\",\\\"Authors\\\":\\\"Barlowe, S.;Tianyi Zhang;Yujie Liu;Jing Yang;Jacobs, D.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;DimensionalityReduction;MultidimensionalMultivariateMultifieldDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2008.4677368\\\",\\\"Keywords\\\":\\\"multivariate model construction;dimension reduction;multivariate visualization;multivariate analysis;visual analysis\\\",\\\"Keywords_Processed\\\":\\\"visual analysis;multivariate model construction;dimension reduction;multivariate visualization;multivariate analysis\\\",\\\"Title\\\":\\\"Multivariate visual explanation for high dimensional datasets\\\"},\\\"762\\\":{\\\"Abstract\\\":\\\"With advances in computing techniques, a large amount of high-resolution high-quality multimedia data (video and audio, etc.) has been collected in research laboratories in various scientific disciplines, particularly in social and behavioral studies. How to automatically and effectively discover new knowledge from rich multimedia data poses a compelling challenge since state-of-the-art data mining techniques can most often only search and extract pre-defined patterns or knowledge from complex heterogeneous data. In light of this, our approach is to take advantages of both the power of human perception system and the power of computational algorithms. More specifically, we propose an approach that allows scientists to use data mining as a first pass, and then forms a closed loop of visual analysis of current results followed by more data mining work inspired by visualization, the results of which can be in turn visualized and lead to the next round of visual exploration and analysis. In this way, new insights and hypotheses gleaned from the raw data and the current level of analysis can contribute to further analysis. As a first step toward this goal, we implement a visualization system with three critical components: (1) A smooth interface between visualization and data mining. The new analysis results can be automatically loaded into our visualization tool. (2) A flexible tool to explore and query temporal data derived from raw multimedia data. We represent temporal data into two forms - continuous variables and event variables. We have developed various ways to visualize both temporal correlations and statistics of multiple variables with the same type, and conditional and high-order statistics between continuous and event variables. (3) A seamless interface between raw multimedia data and derived data. Our visualization tool allows users to explore, compare, and analyze multi-stream derived variables and simultaneously switch to access raw multimedia data. We de- - monstrate various functions in our visualization program using a set of multimedia data including video, audio and motion tracking data.\\\",\\\"Authors\\\":\\\"Chen Yu;Yiwen Zhong;Smith, T.;Park, I.;Weixia Huang\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;MultimediaImageVideoMusic\\\",\\\"DOI\\\":\\\"10.1109/VAST.2008.4677369\\\",\\\"Keywords\\\":\\\"visual data mining;multimedia data\\\",\\\"Keywords_Processed\\\":\\\"multimedia datum;visual datum mining\\\",\\\"Title\\\":\\\"Visual mining of multimedia data for social and behavioral studies\\\"},\\\"763\\\":{\\\"Abstract\\\":\\\"Information visualisation is about gaining insight into data through a visual representation. This data is often multivariate and increasingly, the datasets are very large. To help us explore all this data, numerous visualisation applications, both commercial and research prototypes, have been designed using a variety of techniques and algorithms. Whether they are dedicated to geo-spatial data or skewed hierarchical data, most of the visualisations need to adopt strategies for dealing with overcrowded displays, brought about by too much data to fit in too small a display space. This paper analyses a large number of these clutter reduction methods, classifying them both in terms of how they deal with clutter reduction and more importantly, in terms of the benefits and losses. The aim of the resulting taxonomy is to act as a guide to match techniques to problems where different criteria may have different importance, and more importantly as a means to critique and hence develop existing and new techniques.\\\",\\\"Authors\\\":\\\"Ellis, G.;Dix, A.\\\",\\\"Clusters\\\":\\\"LargeScaleDataAndScalability;OcclusionProblemsTechniques;Taxonomies;VisualClutterAndItsReduction\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70535\\\",\\\"Keywords\\\":\\\"large data;information visualization;clutter reduction;occlusion;taxonomy\\\",\\\"Keywords_Processed\\\":\\\"information visualization;clutter reduction;occlusion;large datum;taxonomy\\\",\\\"Title\\\":\\\"A Taxonomy of Clutter Reduction for Information Visualisation\\\"},\\\"764\\\":{\\\"Abstract\\\":\\\"Online pick'em games, such as the recent NCAA college basketball March Madness tournament, form a large and rapidly growing industry. In these games, players make predictions on a tournament bracket that defines which competitors play each other and how they proceed toward a single champion. Throughout the course of the tournament, players monitor the brackets to track progress and to compare predictions made by multiple players. This is often a complex sense making task. The classic bracket visualization was designed for use on paper and utilizes an incrementally additive system in which the winner of each match-up is rewritten in the next round as the tournament progresses. Unfortunately, this representation requires a significant amount of space and makes it relatively difficult to get a quick overview of the tournament state since competitors take arbitrary paths through the static bracket. In this paper, we present AdaptiviTree, a novel visualization that adaptively deforms the representation of the tree and uses its shape to convey outcome information. AdaptiviTree not only provides a more compact and understandable representation, but also allows overlays that display predictions as well as other statistics. We describe results from a lab study we conducted to explore the efficacy of AdaptiviTree, as well as from a deployment of the system in a recent real-world sports tournament.\\\",\\\"Authors\\\":\\\"Tan, D.S.;Smith, G.;Bongshin Lee;Robertson, G.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;HierarchicalTreeDataAndTechniques;InteractionTechniquesGeneral;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70537\\\",\\\"Keywords\\\":\\\"online fantasy sports;adaptive tree visualization;picks;bracket;tournament\\\",\\\"Keywords_Processed\\\":\\\"adaptive tree visualization;pick;online fantasy sport;tournament;bracket\\\",\\\"Title\\\":\\\"AdaptiviTree: Adaptive Tree Visualization for Tournament-Style Brackets\\\"},\\\"765\\\":{\\\"Abstract\\\":\\\"In this paper we investigate the effectiveness of animated transitions between common statistical data graphics such as bar charts, pie charts, and scatter plots. We extend theoretical models of data graphics to include such transitions, introducing a taxonomy of transition types. We then propose design principles for creating effective transitions and illustrate the application of these principles in DynaVis, a visualization system featuring animated data graphics. Two controlled experiments were conducted to assess the efficacy of various transition types, finding that animated transitions can significantly improve graphical perception.\\\",\\\"Authors\\\":\\\"Heer, J.;Robertson, G.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;EvaluationGeneral;MachineLearningAndStatistics;TransitionsAndMorphing;VisualDesignDesignGuidelines\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70539\\\",\\\"Keywords\\\":\\\"statistical graphics;information visualization;transitions;experiment;animation;design\\\",\\\"Keywords_Processed\\\":\\\"animation;information visualization;statistical graphic;design;transition;experiment\\\",\\\"Title\\\":\\\"Animated Transitions in Statistical Data Graphics\\\"},\\\"766\\\":{\\\"Abstract\\\":\\\"Treemaps provide an interesting solution for representing hierarchical data. However, most studies have mainly focused on layout algorithms and paid limited attention to the interaction with treemaps. This makes it difficult to explore large data sets and to get access to details, especially to those related to the leaves of the trees. We propose the notion of zoomable treemaps (ZTMs), an hybridization between treemaps and zoomable user interfaces that facilitates the navigation in large hierarchical data sets. By providing a consistent set of interaction techniques, ZTMs make it possible for users to browse through very large data sets (e.g., 700,000 nodes dispatched amongst 13 levels). These techniques use the structure of the displayed data to guide the interaction and provide a way to improve interactive navigation in treemaps.\\\",\\\"Authors\\\":\\\"Blanch, R.;Lecolinet, E.\\\",\\\"Clusters\\\":\\\"DesignMethodologiesAndInteractionDesign;HierarchicalTreeDataAndTechniques;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70540\\\",\\\"Keywords\\\":\\\"multi-scale interaction;information visualization;structure-aware navigation;zoomable treemaps\\\",\\\"Keywords_Processed\\\":\\\"multi scale interaction;structure aware navigation;zoomable treemap;information visualization\\\",\\\"Title\\\":\\\"Browsing Zoomable Treemaps: Structure-Aware Multi-Scale Navigation Techniques\\\"},\\\"767\\\":{\\\"Abstract\\\":\\\"Information visualization has often focused on providing deep insight for expert user populations and on techniques for amplifying cognition through complicated interactive visual models. This paper proposes a new subdomain for infovis research that complements the focus on analytic tasks and expert use. Instead of work-related and analytically driven infovis, we propose casual information visualization (or casual infovis) as a complement to more traditional infovis domains. Traditional infovis systems, techniques, and methods do not easily lend themselves to the broad range of user populations, from expert to novices, or from work tasks to more everyday situations. We propose definitions, perspectives, and research directions for further investigations of this emerging subfield. These perspectives build from ambient information visualization (Skog et al., 2003), social visualization, and also from artistic work that visualizes information (Viegas and Wattenberg, 2007). We seek to provide a perspective on infovis that integrates these research agendas under a coherent vocabulary and framework for design. We enumerate the following contributions. First, we demonstrate how blurry the boundary of infovis is by examining systems that exhibit many of the putative properties of infovis systems, but perhaps would not be considered so. Second, we explore the notion of insight and how, instead of a monolithic definition of insight, there may be multiple types, each with particular characteristics. Third, we discuss design challenges for systems intended for casual audiences. Finally we conclude with challenges for system evaluation in this emerging subfield.\\\",\\\"Authors\\\":\\\"Pousman, Z.;Stasko, J.;Mateas, M.\\\",\\\"Clusters\\\":\\\"AmbientVisualization;EvaluationGeneral;SocialNetworksAndSocialMedia;TextDocumentTopicAnalysisDataAndTechniques;VisualDesignDesignGuidelines;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70541\\\",\\\"Keywords\\\":\\\"ambient information visualization;editorial;casual information visualization;design;evaluation;social infovis\\\",\\\"Keywords_Processed\\\":\\\"ambient information visualization;social infovi;design;casual information visualization;editorial;evaluation\\\",\\\"Title\\\":\\\"Casual Information Visualization: Depictions of Data in Everyday Life\\\"},\\\"768\\\":{\\\"Abstract\\\":\\\"We present a directed acyclic graph visualisation designed to allow interaction with a set of multiple classification trees, specifically to find overlaps and differences between groups of trees and individual trees. The work is motivated by the need to find a representation for multiple trees that has the space-saving property of a general graph representation and the intuitive parent-child direction cues present in individual representation of trees. Using example taxonomic data sets, we describe augmentations to the common barycenter DAG layout method that reveal shared sets of child nodes between common parents in a clearer manner. Other interactions such as displaying the multiple ancestor paths of a node when it occurs in several trees, and revealing intersecting sibling sets within the context of a single DAG representation are also discussed.\\\",\\\"Authors\\\":\\\"Graham, M.;Kennedy, J.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;HierarchicalTreeDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70556\\\",\\\"Keywords\\\":\\\"directed acyclic graph;multiple trees\\\",\\\"Keywords_Processed\\\":\\\"direct acyclic graph;multiple tree\\\",\\\"Title\\\":\\\"Exploring Multiple Trees through DAG Representations\\\"},\\\"769\\\":{\\\"Abstract\\\":\\\"We introduce a series of geographically weighted (GW) interactive graphics, or geowigs, and use them to explore spatial relationships at a range of scales. We visually encode information about geographic and statistical proximity and variation in novel ways through gw-choropleth maps, multivariate gw-boxplots, gw-shading and scalograms. The new graphic types reveal information about GW statistics at several scales concurrently. We impement these views in prototype software containing dynamic links and GW interactions that encourage exploration and refine them to consider directional geographies. An informal evaluation uses interactive GW techniques to consider Guerry's dataset of 'moral statistics', casting doubt on correlations originally proposed through visual analysis, revealing new local anomalies and suggesting multivariate geographic relationships. Few attempts at visually synthesising geography with multivariate statistical values at multiple scales have been reported. The geowigs proposed here provide informative representations of multivariate local variation, particularly when combined with interactions that coordinate views and result in gw-shading. We argue that they are widely applicable to area and point-based geographic data and provide a set of methods to support visual analysis using GW statistics through which the effects of geography can be explored at multiple scales.\\\",\\\"Authors\\\":\\\"Dykes, J.;Brunsdon, C.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;GeographyGeospatialVisCartographyTerrainVis;InteractionTechniquesGeneral;LargeScaleDataAndScalability;MultidimensionalMultivariateMultifieldDataAndTechniques;MultipleLinkedCoordinatedViews;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70558\\\",\\\"Keywords\\\":\\\"directional;exploratory data analysis;geographical weighting;scale;multivariate;coordinated views;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;directional;multivariate;coordinated view;scale;geographical weighting;exploratory datum analysis\\\",\\\"Title\\\":\\\"Geographically Weighted Visualization: Interactive Graphics for Scale-Varying Exploratory Analysis\\\"},\\\"770\\\":{\\\"Abstract\\\":\\\"Understanding how people use online maps allows data acquisition teams to concentrate their efforts on the portions of the map that are most seen by users. Online maps represent vast databases, and so it is insufficient to simply look at a list of the most-accessed URLs. Hotmap takes advantage of the design of a mapping system's imagery pyramid to superpose a heatmap of the log files over the original maps. Users' behavior within the system can be observed and interpreted. This paper discusses the imagery acquisition task that motivated Hotmap, and presents several examples of information that Hotmap makes visible. We discuss the design choices behind Hotmap, including logarithmic color schemes; low-saturation background images; and tuning images to explore both infrequently-viewed and frequently-viewed spaces.\\\",\\\"Authors\\\":\\\"Fisher, D.\\\",\\\"Clusters\\\":\\\"ComputerNetworksNetworkSecurity;GeographyGeospatialVisCartographyTerrainVis;Maps;SocialNetworksAndSocialMedia\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70561\\\",\\\"Keywords\\\":\\\"geographic visualization;geographic information systems;online mapping systems;heatmap;server log analysis;social navigation\\\",\\\"Keywords_Processed\\\":\\\"heatmap;geographic information system;geographic visualization;server log analysis;online mapping system;social navigation\\\",\\\"Title\\\":\\\"Hotmap: Looking at Geographic Attention\\\"},\\\"771\\\":{\\\"Abstract\\\":\\\"In many domains, increased collaboration has lead to more innovation by fostering the sharing of knowledge, skills, and ideas. Shared analysis of information visualizations does not only lead to increased information processing power, but team members can also share, negotiate, and discuss their views and interpretations on a dataset and contribute unique perspectives on a given problem. Designing technologies to support collaboration around information visualizations poses special challenges and relatively few systems have been designed. We focus on supporting small groups collaborating around information visualizations in a co-located setting, using a shared interactive tabletop display. We introduce an analysis of challenges and requirements for the design of co-located collaborative information visualization systems. We then present a new system that facilitates hierarchical data comparison tasks for this type of collaborative work. Our system supports multi-user input, shared and individual views on the hierarchical data visualization, flexible use of representations, and flexible workspace organization to facilitate group work around visualizations.\\\",\\\"Authors\\\":\\\"Isenberg, P.;Carpendale, S.\\\",\\\"Clusters\\\":\\\"CollaborativeVisualization;ComparisonComparativeVisualizationAndSimilarity;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70568\\\",\\\"Keywords\\\":\\\"collaboration;information visualization;co-located work;hierarchical data comparison\\\",\\\"Keywords_Processed\\\":\\\"collaboration;co locate work;information visualization;hierarchical datum comparison\\\",\\\"Title\\\":\\\"Interactive Tree Comparison for Co-located Collaborative Information Visualization\\\"},\\\"772\\\":{\\\"Abstract\\\":\\\"Exploratory visual analysis is useful for the preliminary investigation of large structured, multifaceted spatio-temporal datasets. This process requires the selection and aggregation of records by time, space and attribute, the ability to transform data and the flexibility to apply appropriate visual encodings and interactions. We propose an approach inspired by geographical 'mashups' in which freely-available functionality and data are loosely but flexibly combined using de facto exchange standards. Our case study combines MySQL, PHP and the LandSerf GIS to allow Google Earth to be used for visual synthesis and interaction with encodings described in KML. This approach is applied to the exploration of a log of 1.42 million requests made of a mobile directory service. Novel combinations of interaction and visual encoding are developed including spatial 'tag clouds', 'tag maps', 'data dials' and multi-scale density surfaces. Four aspects of the approach are informally evaluated: the visual encodings employed, their success in the visual exploration of the dataset, the specific tools used and the 'mashup' approach. Preliminary findings will be beneficial to others considering using mashups for visualization. The specific techniques developed may be more widely applied to offer insights into the structure of multifarious spatio-temporal data of the type explored here.\\\",\\\"Authors\\\":\\\"Wood, J.;Dykes, J.;Slingsby, A.;Clarke, K.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;GeographyGeospatialVisCartographyTerrainVis;LargeScaleDataAndScalability;MultiresolutionTechniques;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70570\\\",\\\"Keywords\\\":\\\"text and document visualization;geographic visualization;large data visualization;applications of information visualization;multi-resoution visualization\\\",\\\"Keywords_Processed\\\":\\\"text and document visualization;large datum visualization;geographic visualization;multi resoution visualization;application of information visualization\\\",\\\"Title\\\":\\\"Interactive Visual Exploration of a Large Spatio-temporal Dataset: Reflections on a Geovisualization Mashup.\\\"},\\\"773\\\":{\\\"Abstract\\\":\\\"Numerous systems have been developed to display large collections of data for urban contexts; however, most have focused on layering of single dimensions of data and manual calculations to understand relationships within the urban environment. Furthermore, these systems often limit the user's perspectives on the data, thereby diminishing the user's spatial understanding of the viewing region. In this paper, we introduce a highly interactive urban visualization tool that provides intuitive understanding of the urban data. Our system utilizes an aggregation method that combines buildings and city blocks into legible clusters, thus providing continuous levels of abstraction while preserving the user's mental model of the city. In conjunction with a 3D view of the urban model, a separate but integrated information visualization view displays multiple disparate dimensions of the urban data, allowing the user to understand the urban environment both spatially and cognitively in one glance. For our evaluation, expert users from various backgrounds viewed a real city model with census data and confirmed that our system allowed them to gain more intuitive and deeper understanding of the urban model from different perspectives and levels of abstraction than existing commercial urban visualization systems.\\\",\\\"Authors\\\":\\\"Chang, R.;Wessel, G.;Kosara, R.;Sauda, E.;Ribarsky, W.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;MultiresolutionTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70574\\\",\\\"Keywords\\\":\\\"multi-resolution;information visualization;urban models\\\",\\\"Keywords_Processed\\\":\\\"information visualization;multi resolution;urban model\\\",\\\"Title\\\":\\\"Legible Cities: Focus-Dependent Multi-Resolution Visualization of Urban Relationships\\\"},\\\"774\\\":{\\\"Abstract\\\":\\\"We describe the design and deployment of Many Eyes, a public Web site where users may upload data, create interactive visualizations, and carry on discussions. The goal of the site is to support collaboration around visualizations at a large scale by fostering a social style of data analysis in which visualizations not only serve as a discovery tool for individuals but also as a medium to spur discussion among users. To support this goal, the site includes novel mechanisms for end-user creation of visualizations and asynchronous collaboration around those visualizations. In addition to describing these technologies, we provide a preliminary report on the activity of our users.\\\",\\\"Authors\\\":\\\"Viegas, F.B.;Wattenberg, M.;van Ham, F.;Kriss, J.;McKeon, M.\\\",\\\"Clusters\\\":\\\"CollaborativeVisualization;InternetWebVisualizationForTheMasses;SocialNetworksAndSocialMedia;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70577\\\",\\\"Keywords\\\":\\\"visualization;communication-minded visualization;social data analysis;social software;world wide web\\\",\\\"Keywords_Processed\\\":\\\"visualization;world wide web;social software;communication minded visualization;social datum analysis\\\",\\\"Title\\\":\\\"ManyEyes: a Site for Visualization at Internet Scale\\\"},\\\"775\\\":{\\\"Abstract\\\":\\\"This paper presents a new algorithm for force directed graph layout on the GPU. The algorithm, whose goal is to compute layouts accurately and quickly, has two contributions. The first contribution is proposing a general multi-level scheme, which is based on spectral partitioning. The second contribution is computing the layout on the GPU. Since the GPU requires a data parallel programming model, the challenge is devising a mapping of a naturally unstructured graph into a well-partitioned structured one. This is done by computing a balanced partitioning of a general graph. This algorithm provides a general multi-level scheme, which has the potential to be used not only for computation on the GPU, but also on emerging multi-core architectures. The algorithm manages to compute high quality layouts of large graphs in a fraction of the time required by existing algorithms of similar quality. An application for visualization of the topologies of ISP (Internet service provider) networks is presented.\\\",\\\"Authors\\\":\\\"Frishman, Y.;Tal, A.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;GpuBasedTechniques;GraphNetworkDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70580\\\",\\\"Keywords\\\":\\\"graph partitioning;graph layout;gpu\\\",\\\"Keywords_Processed\\\":\\\"graph partitioning;gpu;graph layout\\\",\\\"Title\\\":\\\"Multi-Level Graph Layout on the GPU\\\"},\\\"776\\\":{\\\"Abstract\\\":\\\"The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in existing systems do not satisfactorily resolve the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. To address this problem, we present NodeTrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. A key contribution is a set of interaction techniques. These allow analysts to create a NodeTrix visualization by dragging selections to and from node-link and matrix forms, and to flexibly manipulate the NodeTrix representation to explore the dataset and create meaningful summary visualizations of their findings. Finally, we present a case study applying NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate the capabilities of NodeTrix as both an exploration tool and an effective means of communicating results.\\\",\\\"Authors\\\":\\\"Henry, N.;Fekete, J.;McGuffin, M.J.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;GraphNetworkDataAndTechniques;InteractionTechniquesGeneral;MatrixRelatedTechniques;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70582\\\",\\\"Keywords\\\":\\\"interaction;matrix visualization;aggregation;hybrid visualization;network visualization\\\",\\\"Keywords_Processed\\\":\\\"interaction;network visualization;aggregation;matrix visualization;hybrid visualization\\\",\\\"Title\\\":\\\"NodeTrix: a Hybrid Visualization of Social Networks\\\"},\\\"777\\\":{\\\"Abstract\\\":\\\"In interfaces that provide multiple visual information resolutions (VIR), low-VIR overviews typically sacrifice visual details for display capacity, with the assumption that users can select regions of interest to examine at higher VI Rs. Designers can create low VIRs based on multi-level structure inherent in the data, but have little guidance with single-level data. To better guide design tradeoff between display capacity and visual target perceivability, we looked at overview use in two multiple-VIR interfaces with high-VIR displays either embedded within, or separate from, the overviews. We studied two visual requirements for effective overview and found that participants would reliably use the low-VIR overviews only when the visual targets were simple and had small visual spans. Otherwise, at least 20% chose to use the high-VIR view exclusively. Surprisingly, neither of the multiple-VIR interfaces provided performance benefits when compared to using the high-VIR view alone. However, we did observe benefits in providing side-by-side comparisons for target matching. We conjecture that the high cognitive load of multiple-VIR interface interactions, whether real or perceived, is a more considerable barrier to their effective use than was previously considered.\\\",\\\"Authors\\\":\\\"Lam, H.;Munzner, T.;Kincaid, R.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;FocusContextTechniques;MultiresolutionTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70583\\\",\\\"Keywords\\\":\\\"overview use;user study;multiple resolutions\\\",\\\"Keywords_Processed\\\":\\\"multiple resolution;user study;overview use\\\",\\\"Title\\\":\\\"Overview Use in Multiple Visual Information Resolution Interfaces\\\"},\\\"778\\\":{\\\"Abstract\\\":\\\"This paper presents scented widgets, graphical user interface controls enhanced with embedded visualizations that facilitate navigation in information spaces. We describe design guidelines for adding visual cues to common user interface widgets such as radio buttons, sliders, and combo boxes and contribute a general software framework for applying scented widgets within applications with minimal modifications to existing source code. We provide a number of example applications and describe a controlled experiment which finds that users exploring unfamiliar data make up to twice as many unique discoveries using widgets imbued with social navigation data. However, these differences equalize as familiarity with the data increases.\\\",\\\"Authors\\\":\\\"Willett, W.;Heer, J.;Agrawala, M.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;SocialNetworksAndSocialMedia;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70589\\\",\\\"Keywords\\\":\\\"information visualization;information foraging;user interface toolkits;social data analysis;social navigation\\\",\\\"Keywords_Processed\\\":\\\"information visualization;social datum analysis;social navigation;information forage;user interface toolkit\\\",\\\"Title\\\":\\\"Scented Widgets: Improving Navigation Cues with Embedded Visualizations\\\"},\\\"779\\\":{\\\"Abstract\\\":\\\"Documents and other categorical valued time series are often characterized by the frequencies of short range sequential patterns such as n-grams. This representation converts sequential data of varying lengths to high dimensional histogram vectors which are easily modeled by standard statistical models. Unfortunately, the histogram representation ignores most of the medium and long range sequential dependencies making it unsuitable for visualizing sequential data. We present a novel framework for sequential visualization of discrete categorical time series based on the idea of local statistical modeling. The framework embeds categorical time series as smooth curves in the multinomial simplex summarizing the progression of sequential trends. We discuss several visualization techniques based on the above framework and demonstrate their usefulness for document visualization.\\\",\\\"Authors\\\":\\\"Yi Mao;Dillon, J.V.;Lebanon, G.\\\",\\\"Clusters\\\":\\\"MachineLearningAndStatistics;MultiresolutionTechniques;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70592\\\",\\\"Keywords\\\":\\\"multi-resolution analysis;document visualization;local fitting\\\",\\\"Keywords_Processed\\\":\\\"local fitting;document visualization;multi resolution analysis\\\",\\\"Title\\\":\\\"Sequential Document Visualization\\\"},\\\"780\\\":{\\\"Abstract\\\":\\\"This paper describes Show Me, an integrated set of user interface commands and defaults that incorporate automatic presentation into a commercial visual analysis system called Tableau. A key aspect of Tableau is VizQL, a language for specifying views, which is used by Show Me to extend automatic presentation to the generation of tables of views (commonly called small multiple displays). A key research issue for the commercial application of automatic presentation is the user experience, which must support the flow of visual analysis. User experience has not been the focus of previous research on automatic presentation. The Show Me user experience includes the automatic selection of mark types, a command to add a single field to a view, and a pair of commands to build views for multiple fields. Although the use of these defaults and commands is optional, user interface logs indicate that Show Me is used by commercial users.\\\",\\\"Authors\\\":\\\"Mackinlay, J.;Hanrahan, P.;Stolte, C.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;AutomaticAnalysisVisualizationTechniques;VisualDesignDesignGuidelines;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70594\\\",\\\"Keywords\\\":\\\"visualization;best practices;small multiples;automatic presentation;graphic design;visual analysis\\\",\\\"Keywords_Processed\\\":\\\"visualization;visual analysis;graphic design;small multiple;automatic presentation;good practice\\\",\\\"Title\\\":\\\"Show Me: Automatic Presentation for Visual Analysis\\\"},\\\"781\\\":{\\\"Abstract\\\":\\\"Spatializations represent non-spatial data using a spatial layout similar to a map. We present an experiment comparing different visual representations of spatialized data, to determine which representations are best for a non-trivial search and point estimation task. Primarily, we compare point-based displays to 2D and 3D information landscapes. We also compare a colour (hue) scale to a grey (lightness) scale. For the task we studied, point-based spatializations were far superior to landscapes, and 2D landscapes were superior to 3D landscapes. Little or no benefit was found for redundantly encoding data using colour or greyscale combined with landscape height. 3D landscapes with no colour scale (height-only) were particularly slow and inaccurate. A colour scale was found to be better than a greyscale for all display types, but a greyscale was helpful compared to height-only. These results suggest that point-based spatializations should be chosen over landscape representations, at least for tasks involving only point data itself rather than derived information about the data space.\\\",\\\"Authors\\\":\\\"Tory, M.;Sprague, D.W.;Fuqu Wu;Wing Yan So;Munzner, T.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;EvaluationGeneral;NumericalMethodsMathematics;PointBasedDataAndTechniques;SpaceRelatedSpatialDataAndTechniques;SurfaceRelatedDataAndTechniques;VisualEncodingAndLayoutGeneral;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70596\\\",\\\"Keywords\\\":\\\"color;information landscape;3d;user study;grey scale;numerosity;points;spatialization;2d;surfaces\\\",\\\"Keywords_Processed\\\":\\\"grey scale;numerosity;3d;user study;surface;2d;point;information landscape;color;spatialization\\\",\\\"Title\\\":\\\"Spatialization Design: Comparing Points and Landscapes\\\"},\\\"782\\\":{\\\"Abstract\\\":\\\"Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user's intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction.\\\",\\\"Authors\\\":\\\"Ji Soo Yi;Youn-ah Kang;Stasko, J.;Jacko, J.A.\\\",\\\"Clusters\\\":\\\"InteractionTechniquesGeneral;Taxonomies;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70515\\\",\\\"Keywords\\\":\\\"taxonomy;information visualization;visual analytics;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;visual analytic;taxonomy;information visualization\\\",\\\"Title\\\":\\\"Toward a Deeper Understanding of the Role of Interaction in Information Visualization\\\"},\\\"783\\\":{\\\"Abstract\\\":\\\"We present VisLink, a method by which visualizations and the relationships between them can be interactively explored. VisLink readily generalizes to support multiple visualizations, empowers inter-representational queries, and enables the reuse of the spatial variables, thus supporting efficient information encoding and providing for powerful visualization bridging. Our approach uses multiple 2D layouts, drawing each one in its own plane. These planes can then be placed and re-positioned in 3D space: side by side, in parallel, or in chosen placements that provide favoured views. Relationships, connections, and patterns between visualizations can be revealed and explored using a variety of interaction techniques including spreading activation and search filters.\\\",\\\"Authors\\\":\\\"Collins, C.;Carpendale, S.\\\",\\\"Clusters\\\":\\\"ComparisonComparativeVisualizationAndSimilarity;DataClusteringAndAggregation;GraphNetworkDataAndTechniques;HierarchicalTreeDataAndTechniques;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70521\\\",\\\"Keywords\\\":\\\"edge aggregation;hierarchy;node-link diagrams;3d visualization;graph visualization;structural comparison\\\",\\\"Keywords_Processed\\\":\\\"structural comparison;hierarchy;edge aggregation;3d visualization;graph visualization;node link diagram\\\",\\\"Title\\\":\\\"VisLink: Revealing Relationships Amongst Visualizations\\\"},\\\"784\\\":{\\\"Abstract\\\":\\\"The Internet has become a wild place: malicious code is spread on personal computers across the world, deploying botnets ready to attack the network infrastructure. The vast number of security incidents and other anomalies overwhelms attempts at manual analysis, especially when monitoring service provider backbone links. We present an approach to interactive visualization with a case study indicating that interactive visualization can be applied to gain more insight into these large data sets. We superimpose a hierarchy on IP address space, and study the suitability of Treemap variants for each hierarchy level. Because viewing the whole IP hierarchy at once is not practical for most tasks, we evaluate layout stability when eliding large parts of the hierarchy, while maintaining the visibility and ordering of the data of interest.\\\",\\\"Authors\\\":\\\"Mansmann, F.;Keim, D.A.;North, S.C.;Rexroad, B.;Sheleheda, D.\\\",\\\"Clusters\\\":\\\"ComputerNetworksNetworkSecurity;HierarchicalTreeDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70522\\\",\\\"Keywords\\\":\\\"treemap;information visualization;network security;network monitoring\\\",\\\"Keywords_Processed\\\":\\\"network monitoring;information visualization;network security;treemap\\\",\\\"Title\\\":\\\"Visual Analysis of Network Traffic for Resource Planning, Interactive Monitoring, and Interpretation of Security Threats\\\"},\\\"785\\\":{\\\"Abstract\\\":\\\"Both the resource description framework (RDF), used in the semantic web, and Maya Viz u-forms represent data as a graph of objects connected by labeled edges. Existing systems for flexible visualization of this kind of data require manual specification of the possible visualization roles for each data attribute. When the schema is large and unfamiliar, this requirement inhibits exploratory visualization by requiring a costly up-front data integration step. To eliminate this step, we propose an automatic technique for mapping data attributes to visualization attributes. We formulate this as a schema matching problem, finding appropriate paths in the data model for each required visualization attribute in a visualization template.\\\",\\\"Authors\\\":\\\"Cammarano, M.;Xin Dong;Bryan Chan;Klingner, J.;Talbot, J.;Halevy, A.;Hanrahan, P.\\\",\\\"Clusters\\\":\\\"DataAcquisitionAndManagement;DataFeaturesAndAttributes;InternetWebVisualizationForTheMasses\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70617\\\",\\\"Keywords\\\":\\\"attribute inference;rdf;data integration\\\",\\\"Keywords_Processed\\\":\\\"attribute inference;rdf;datum integration\\\",\\\"Title\\\":\\\"Visualization of Heterogeneous Data\\\"},\\\"786\\\":{\\\"Abstract\\\":\\\"Michotte's theory of ampliation suggests that causal relationships are perceived by objects animated under appropriate spatiotemporal conditions. We extend the theory of ampliation and propose that the immediate perception of complex causal relations is also dependent on a set of structural and temporal rules. We designed animated representations, based on Michotte's rules, for showing complex causal relationships or causal semantics. In this paper we describe a set of animations for showing semantics such as causal amplification, causal strength, causal dampening, and causal multiplicity. In a two part study we compared the effectiveness of both the static and animated representations. The first study (N=44) asked participants to recall passages that were previously displayed using both types of representations. Participants were 8% more accurate in recalling causal semantics when they were presented using animations instead of static graphs. In the second study (N=112) we evaluated the intuitiveness of the representations. Our results showed that while users were as accurate with the static graphs as with the animations, they were 9% faster in matching the correct causal statements in the animated condition. Overall our results show that animated diagrams that are designed based on perceptual rules such as those proposed by Michotte have the potential to facilitate comprehension of complex causal relations.\\\",\\\"Authors\\\":\\\"Kadaba, N.R.;Irani, P.;Leboe, J.\\\",\\\"Clusters\\\":\\\"DynamicVisualizationVisualizationOfChange;GraphNetworkDataAndTechniques;Perception;SemanticsSemioticsRelatedTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70528\\\",\\\"Keywords\\\":\\\"animated graphs;semantics;graph semantics;perception;visualization;visualizing cause and effect;causality\\\",\\\"Keywords_Processed\\\":\\\"visualization;perception;causality;animate graph;visualize cause and effect;graph semantic;semantic\\\",\\\"Title\\\":\\\"Visualizing Causal Semantics Using Animations\\\"},\\\"787\\\":{\\\"Abstract\\\":\\\"While the treemap is a popular method for visualizing hierarchical data, it is often difficult for users to track layout and attribute changes when the data evolve over time. When viewing the treemaps side by side or back and forth, there exist several problems that can prevent viewers from performing effective comparisons. Those problems include abrupt layout changes, a lack of prominent visual patterns to represent layouts, and a lack of direct contrast to highlight differences. In this paper, we present strategies to visualize changes of hierarchical data using treemaps. A new treemap layout algorithm is presented to reduce abrupt layout changes and produce consistent visual patterns. Techniques are proposed to effectively visualize the difference and contrast between two treemap snapshots in terms of the map items' colors, sizes, and positions. Experimental data show that our algorithm can achieve a good balance in maintaining a treemap's stability, continuity, readability, and average aspect ratio. A software tool is created to compare treemaps and generate the visualizations. User studies show that the users can better understand the changes in the hierarchy and layout, and more quickly notice the color and size differences using our method.\\\",\\\"Authors\\\":\\\"Ying Tu;Han-Wei Shen\\\",\\\"Clusters\\\":\\\"DynamicVisualizationVisualizationOfChange;HierarchicalTreeDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70529\\\",\\\"Keywords\\\":\\\"treemap;treemap layout algorithm;visualize changes;tree comparison\\\",\\\"Keywords_Processed\\\":\\\"visualize change;tree comparison;treemap layout algorithm;treemap\\\",\\\"Title\\\":\\\"Visualizing Changes of Hierarchical Data using Treemaps\\\"},\\\"788\\\":{\\\"Abstract\\\":\\\"The technology available to building designers now makes it possible to monitor buildings on a very large scale. Video cameras and motion sensors are commonplace in practically every office space, and are slowly making their way into living spaces. The application of such technologies, in particular video cameras, while improving security, also violates privacy. On the other hand, motion sensors, while being privacy-conscious, typically do not provide enough information for a human operator to maintain the same degree of awareness about the space that can be achieved by using video cameras. We propose a novel approach in which we use a large number of simple motion sensors and a small set of video cameras to monitor a large office space. In our system we deployed 215 motion sensors and six video cameras to monitor the 3,000-square-meter office space occupied by 80 people for a period of about one year. The main problem in operating such systems is finding a way to present this highly multidimensional data, which includes both spatial and temporal components, to a human operator to allow browsing and searching recorded data in an efficient and intuitive way. In this paper we present our experiences and the solutions that we have developed in the course of our work on the system. We consider this work to be the first step in helping designers and managers of building systems gain access to information about occupants' behavior in the context of an entire building in a way that is only minimally intrusive to the occupants' privacy.\\\",\\\"Authors\\\":\\\"Ivanov, Y.A.;Wren, C.R.;Sorokin, A.;Kaur, I.\\\",\\\"Clusters\\\":\\\"PrivacySecurityIntelligenceAnalysis;SensorNetworks;SpatiotemporalDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70621\\\",\\\"Keywords\\\":\\\"sensor networks;timeline;spatio-temporal visualization;user interface;surveillance\\\",\\\"Keywords_Processed\\\":\\\"spatio temporal visualization;user interface;sensor network;timeline;surveillance\\\",\\\"Title\\\":\\\"Visualizing the History of Living Spaces\\\"},\\\"789\\\":{\\\"Abstract\\\":\\\"In many applications, it is important to understand the individual values of, and relationships between, multiple related scalar variables defined across a common domain. Several approaches have been proposed for representing data in these situations. In this paper we focus on strategies for the visualization of multivariate data that rely on color mixing. In particular, through a series of controlled observer experiments, we seek to establish a fundamental understanding of the information-carrying capacities of two alternative methods for encoding multivariate information using color: color blending and color weaving. We begin with a baseline experiment in which we assess participants' abilities to accurately read numerical data encoded in six different basic color scales defined in the L*a*b* color space. We then assess participants' abilities to read combinations of 2, 3, 4 and 6 different data values represented in a common region of the domain, encoded using either color blending or color weaving. In color blending a single mixed color is formed via linear combination of the individual values in L*a*b* space, and in color weaving the original individual colors are displayed side-by-side in a high frequency texture that fills the region. A third experiment was conducted to clarify some of the trends regarding the color contrast and its effect on the magnitude of the error that was observed in the second experiment. The results indicate that when the component colors are represented side-by-side in a high frequency texture, most participants' abilities to infer the values of individual components are significantly improved, relative to when the colors are blended. Participants' performance was significantly better with color weaving particularly when more than 2 colors were used, and even when the individual colors subtended only 3 minutes of visual angle in the texture. However, the information-carrying capacity of the color weaving approach has its limits. - - We found that participants' abilities to accurately interpret each of the individual components in a high frequency color texture typically falls off as the number of components increases from 4 to 6. We found no significant advantages, in either color blending or color weaving, to using color scales based on component hues thatare more widely separated in the L*a*b* color space. Furthermore, we found some indications that extra difficulties may arise when opponent hues are employed.\\\",\\\"Authors\\\":\\\"Hagh-Shenas, H.;Sunghee Kim;Interrante, V.;Healey, C.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;Perception;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70623\\\",\\\"Keywords\\\":\\\"color;perception;color weaving;visualization;color blending\\\",\\\"Keywords_Processed\\\":\\\"visualization;perception;color blending;color;color weaving\\\",\\\"Title\\\":\\\"Weaving Versus Blending: a quantitative assessment of the information carrying capacities of two alternative methods for conveying multivariate data with color.\\\"},\\\"790\\\":{\\\"Abstract\\\":\\\"We present a powerful framework for 3D-texture-based rendering of multiple arbitrarily intersecting volumetric datasets. Each volume is represented by a multi-resolution octree-based structure and we use out-of-core techniques to support extremely large volumes. Users define a set of convex polyhedral volume lenses, which may be associated with one or more volumetric datasets. The volumes or the lenses can be interactively moved around while the region inside each lens is rendered using interactively defined multi-volume shaders. Our rendering pipeline splits each lens into multiple convex regions such that each region is homogenous and contains a fixed number of volumes. Each such region is further split by the brick boundaries of the associated octree representations. The resulting puzzle of lens fragments is sorted in front-to-back or back-to-front order using a combination of a view-dependent octree traversal and a GPU-based depth peeling technique. Our current implementation uses slice-based volume rendering and allows interactive roaming through multiple intersecting multi-gigabyte volumes.\\\",\\\"Authors\\\":\\\"Plate, J.;Holtkaemper, T.;Froehlich, B.\\\",\\\"Clusters\\\":\\\"GeometricModeling;ProgrammingAlgorithmsAndDataStructures;Rendering;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70534\\\",\\\"Keywords\\\":\\\"shading;constructive solid geometry;display algorithms;multi-volume visualization\\\",\\\"Keywords_Processed\\\":\\\"constructive solid geometry;multi volume visualization;shade;display algorithm\\\",\\\"Title\\\":\\\"A Flexible Multi-Volume Shader Framework for Arbitrarily Intersecting Multi-Resolution Datasets\\\"},\\\"791\\\":{\\\"Abstract\\\":\\\"We present a general framework for the modeling and optimization of scalable multi-projector displays. Based on this framework, we derive algorithms that can robustly optimize the visual quality of an arbitrary combination of projectors without manual adjustment. When the projectors are tiled, we show that our framework automatically produces blending maps that outperform state-of-the-art projector blending methods. When all the projectors are superimposed, the framework can produce high-resolution images beyond the Nyquist resolution limits of component projectors. When a combination of tiled and superimposed projectors are deployed, the same framework harnesses the best features of both tiled and superimposed multi-projector projection paradigms. The framework creates for the first time a new unified paradigm that is agnostic to a particular configuration of projectors yet robustly optimizes for the brightness, contrast, and resolution of that configuration. In addition, we demonstrate that our algorithms support high resolution video at real-time interactive frame rates achieved on commodity graphics platforms. This work allows for inexpensive, compelling, flexible, and robust large scale visualization systems to be built and deployed very efficiently.\\\",\\\"Authors\\\":\\\"Damera-Venkata, N.;Chang, N.L.;DiCarlo, J.M.\\\",\\\"Clusters\\\":\\\"DisplaysGeneral;GeometricModeling;LargeAndHighResDisplays;MultiresolutionTechniques;TransitionsAndMorphing;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70536\\\",\\\"Keywords\\\":\\\"superimposed projection;blending;large format displays;automatic geometric alignment;stitching;tiled displays;super-resolution;multi-projector displays;photometric correction\\\",\\\"Keywords_Processed\\\":\\\"large format display;stitch;automatic geometric alignment;blend;photometric correction;tile display;super resolution;multi projector display;superimpose projection\\\",\\\"Title\\\":\\\"A Unified Paradigm For Scalable Multi-Projector Displays\\\"},\\\"792\\\":{\\\"Abstract\\\":\\\"Conveying shape using feature lines is an important visualization tool in visual computing. The existing feature lines (e.g., ridges, valleys, silhouettes, suggestive contours, etc.) are solely determined by local geometry properties (e.g., normals and curvatures) as well as the view position. This paper is strongly inspired by the observation in human vision and perception that a sudden change in the luminance plays a critical role to faithfully represent and recover the 3D information. In particular, we adopt the edge detection techniques in image processing for 3D shape visualization and present photic extremum lines (PELs) which emphasize significant variations of illumination over 3D surfaces. Comparing with the existing feature lines, PELs are more flexible and offer users more freedom to achieve desirable visualization effects. In addition, the user can easily control the shape visualization by changing the light position, the number of light sources, and choosing various light models. We compare PELs with the existing approaches and demonstrate that PEL is a flexible and effective tool to illustrate 3D surface and volume for visual computing.\\\",\\\"Authors\\\":\\\"Xuexiang Xie;Ying He;Feng Tian;Hock-Soon Seah;Xianfeng Gu;Hong Qin\\\",\\\"Clusters\\\":\\\"ContourCreasesRidgesValleys;GeometricModeling;Illumination;IllustrativeVisualization;LineBasedTechniquesAndApproaches;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70538\\\",\\\"Keywords\\\":\\\"illumination;suggestive contours;ridges and valleys;digital geometry processing;photic extremum lines;surface and volume illustration;silhouettes\\\",\\\"Keywords_Processed\\\":\\\"photic extremum line;ridge and valley;suggestive contour;silhouette;illumination;surface and volume illustration;digital geometry processing\\\",\\\"Title\\\":\\\"An Effective Illustrative Visualization Framework Based on Photic Extremum Lines (PELs)\\\"},\\\"793\\\":{\\\"Abstract\\\":\\\"Visualization algorithms can have a large number of parameters, making the space of possible rendering results rather high-dimensional. Only a systematic analysis of the perceived quality can truly reveal the optimal setting for each such parameter. However, an exhaustive search in which all possible parameter permutations are presented to each user within a study group would be infeasible to conduct. Additional complications may result from possible parameter co-dependencies. Here, we will introduce an efficient user study design and analysis strategy that is geared to cope with this problem. The user feedback is fast and easy to obtain and does not require exhaustive parameter testing. To enable such a framework we have modified a preference measuring methodology, conjoint analysis, that originated in psychology and is now also widely used in market research. We demonstrate our framework by a study that measures the perceived quality in volume rendering within the context of large parameter spaces.\\\",\\\"Authors\\\":\\\"Giesen, J.;Mueller, K.;Schuberth, E.;Lujin Wang;Zolliker, P.\\\",\\\"Clusters\\\":\\\"MachineLearningAndStatistics;Parameterization;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70542\\\",\\\"Keywords\\\":\\\"volume visualization;conjoint analysis;parameterized algorithms\\\",\\\"Keywords_Processed\\\":\\\"volume visualization;parameterize algorithm;conjoint analysis\\\",\\\"Title\\\":\\\"Conjoint Analysis to Measure the Perceived Quality in Volume Rendering\\\"},\\\"794\\\":{\\\"Abstract\\\":\\\"We present a method for extracting boundary surfaces from segmented cross-section image data. We use a constrained Potts model to interpolate an arbitrary number of region boundaries between segmented images. This produces a segmented volume from which we extract a triangulated boundary surface using well-known marching tetrahedra methods. This surface contains staircase-like artifacts and an abundance of unnecessary triangles. We describe an approach that addresses these problems with a voxel-accurate simplification algorithm that reduces surface complexity by an order of magnitude. Our boundary interpolation and simplification methods are novel contributions to the study of surface extraction from segmented cross-sections. We have applied our method to construct polycrystal grain boundary surfaces from micrographs of a sample of the metal tantalum.\\\",\\\"Authors\\\":\\\"Dillard, S.E.;Bingert, J.F.;Thoma, D.;Hamann, B.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices;PhysicsAndPhysicalSciences\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70543\\\",\\\"Keywords\\\":\\\"surface extraction;life sciences and engineering;visualization in physical sciences;polygonal meshes\\\",\\\"Keywords_Processed\\\":\\\"life science and engineering;visualization in physical science;surface extraction;polygonal mesh\\\",\\\"Title\\\":\\\"Construction of Simplified Boundary Surfaces from Serial-sectioned Metal Micrographs\\\"},\\\"795\\\":{\\\"Abstract\\\":\\\"Multiple spatially-related videos are increasingly used in security, communication, and other applications. Since it can be difficult to understand the spatial relationships between multiple videos in complex environments (e.g. to predict a person's path through a building), some visualization techniques, such as video texture projection, have been used to aid spatial understanding. In this paper, we identify and begin to characterize an overall class of visualization techniques that combine video with 3D spatial context. This set of techniques, which we call contextualized videos, forms a design palette which must be well understood so that designers can select and use appropriate techniques that address the requirements of particular spatial video tasks. In this paper, we first identify user tasks in video surveillance that are likely to benefit from contextualized videos and discuss the video, model, and navigation related dimensions of the contextualized video design space. We then describe our contextualized video testbed which allows us to explore this design space and compose various video visualizations for evaluation. Finally, we describe the results of our process to identify promising design patterns through user selection of visualization features from the design space, followed by user interviews.\\\",\\\"Authors\\\":\\\"Yi Wang;Krum, D.;Coelho, E.M.;Bowman, D.A.\\\",\\\"Clusters\\\":\\\"Cognition;DesignMethodologiesAndInteractionDesign;EvaluationGeneral;ImmersiveAndVirtualEnvironments;MultimediaImageVideoMusic\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70544\\\",\\\"Keywords\\\":\\\"design space;testbed design and evaluation;situation awareness;videos;virtual environment models\\\",\\\"Keywords_Processed\\\":\\\"virtual environment model;design space;situation awareness;video;testbed design and evaluation\\\",\\\"Title\\\":\\\"Contextualized Videos: Combining Videos with Environment Models to Support Situational Understanding\\\"},\\\"796\\\":{\\\"Abstract\\\":\\\"In nature and in flow experiments particles form patterns of swirling motion in certain locations. Existing approaches identify these structures by considering the behavior of stream lines. However, in unsteady flows particle motion is described by path lines which generally gives different swirling patterns than stream lines. We introduce a novel mathematical characterization of swirling motion cores in unsteady flows by generalizing the approach of Sujudi/Haimes to path lines. The cores of swirling particle motion are lines sweeping over time, i.e., surfaces in the space-time domain. They occur at locations where three derived 4D vectors become coplanar. To extract them, we show how to re-formulate the problem using the parallel vectors operator. We apply our method to a number of unsteady flow fields.\\\",\\\"Authors\\\":\\\"Weinkauf, T.;Sahner, J.;Theisel, H.;Hege, H.-C.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;ParticleVisualizationAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70545\\\",\\\"Keywords\\\":\\\"unsteady flow visualization;feature extraction;particle motion\\\",\\\"Keywords_Processed\\\":\\\"feature extraction;particle motion;unsteady flow visualization\\\",\\\"Title\\\":\\\"Cores of Swirling Particle Motion in Unsteady Flows\\\"},\\\"797\\\":{\\\"Abstract\\\":\\\"We present novel, comprehensive visualization techniques for the diagnosis of patients with coronary artery disease using segmented cardiac MRI data. We extent an accepted medical visualization technique called the bull's eye plot by removing discontinuities, preserving the volumetric nature of the left ventricular wall and adding anatomical context. The resulting volumetric bull's eye plot can be used for the assessment of transmurality. We link these visualizations to a 3D view that presents viability information in a detailed anatomical context. We combine multiple MRI scans (whole heart anatomical data, late enhancement data) and multiple segmentations (polygonal heart model, late enhancement contours, coronary artery tree). By selectively combining different rendering techniques we obtain comprehensive yet intuitive visualizations of the various data sources.\\\",\\\"Authors\\\":\\\"Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, E.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;ChartsDiagramsPlots;DataAcquisitionAndManagement;EvaluationMetricsAndBenchmarks\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70550\\\",\\\"Keywords\\\":\\\"viability;late enhancement;bull's eye plot;cardiac mri\\\",\\\"Keywords_Processed\\\":\\\"bull eye plot;late enhancement;cardiac mri;viability\\\",\\\"Title\\\":\\\"CoViCAD: Comprehensive Visualization of Coronary Artery Disease\\\"},\\\"798\\\":{\\\"Abstract\\\":\\\"The recently introduced notion of Finite-Time Lyapunov Exponent to characterize Coherent Lagrangian Structures provides a powerful framework for the visualization and analysis of complex technical flows. Its definition is simple and intuitive, and it has a deep theoretical foundation. While the application of this approach seems straightforward in theory, the associated computational cost is essentially prohibitive. Due to the Lagrangian nature of this technique, a huge number of particle paths must be computed to fill the space-time flow domain. In this paper, we propose a novel scheme for the adaptive computation of FTLE fields in two and three dimensions that significantly reduces the number of required particle paths. Furthermore, for three-dimensional flows, we show on several examples that meaningful results can be obtained by restricting the analysis to a well-chosen plane intersecting the flow domain. Finally, we examine some of the visualization aspects of FTLE-based methods and introduce several new variations that help in the analysis of specific aspects of a flow.\\\",\\\"Authors\\\":\\\"Garth, C.;Gerhardt, F.;Tricoche, X.;Hagen, H.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70551\\\",\\\"Keywords\\\":\\\"flow visualization;3d vector field visualization;feature detection\\\",\\\"Keywords_Processed\\\":\\\"3d vector field visualization;feature detection;flow visualization\\\",\\\"Title\\\":\\\"Efficient Computation and Visualization of Coherent Structures in Fluid Flow Applications\\\"},\\\"799\\\":{\\\"Abstract\\\":\\\"We propose a novel, geometrically adaptive method for surface reconstruction from noisy and sparse point clouds, without orientation information. The method employs a fast convection algorithm to attract the evolving surface towards the data points. The force field in which the surface is convected is based on generalized Coulomb potentials evaluated on an adaptive grid (i.e., an octree) using a fast, hierarchical algorithm. Formulating reconstruction as a convection problem in a velocity field generated by Coulomb potentials offers a number of advantages. Unlike methods which compute the distance from the data set to the implicit surface, which are sensitive to noise due to the very reliance on the distance transform, our method is highly resilient to shot noise since global, generalized Coulomb potentials can be used to disregard the presence of outliers due to noise. Coulomb potentials represent long-range interactions that consider all data points at once, and thus they convey global information which is crucial in the fitting process. Both the spatial and temporal complexities of our spatially-adaptive method are proportional to the size of the reconstructed object, which makes our method compare favorably with respect to previous approaches in terms of speed and flexibility. Experiments with sparse as well as noisy data sets show that the method is capable of delivering crisp and detailed yet smooth surfaces.\\\",\\\"Authors\\\":\\\"Jalba, A.C.;Roerdink, J.B.T.\\\",\\\"Clusters\\\":\\\"MeshesGridsAndLattices;MolecularScienceAndChemistry;ProgrammingAlgorithmsAndDataStructures;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70553\\\",\\\"Keywords\\\":\\\"polygonization;octree;generalized coulomb potentials;implicit surfaces;surface reconstruction\\\",\\\"Keywords_Processed\\\":\\\"implicit surface;polygonization;octree;surface reconstruction;generalize coulomb potential\\\",\\\"Title\\\":\\\"Efficient Surface Reconstruction using Generalized Coulomb Potentials\\\"},\\\"800\\\":{\\\"Abstract\\\":\\\"This paper presents a method for filtered ridge extraction based on adaptive mesh refinement. It is applicable in situations where the underlying scalar field can be refined during ridge extraction. This requirement is met by the concept of Lagrangian coherent structures which is based on trajectories started at arbitrary sampling grids that are independent of the underlying vector field. The Lagrangian coherent structures are extracted as ridges in finite Lyapunov exponent fields computed from these grids of trajectories. The method is applied to several variants of finite Lyapunov exponents, one of which is newly introduced. High computation time due to the high number of required trajectories is a main drawback when computing Lyapunov exponents of 3-dimensional vector fields. The presented method allows a substantial speed-up by avoiding the seeding of trajectories in regions where no ridges are present or do not satisfy the prescribed filter criteria such as a minimum finite Lyapunov exponent.\\\",\\\"Authors\\\":\\\"Sadlo, F.;Peikert, R.\\\",\\\"Clusters\\\":\\\"ContourCreasesRidgesValleys;FlowVisualizationDataAndTechniques;VectorFieldsDataAndTechniques;VisualPatternFeatureDetectionAndTracking\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70554\\\",\\\"Keywords\\\":\\\"flow visualization;vector field topology;unsteady vector fields;coherent structures;ridge extraction\\\",\\\"Keywords_Processed\\\":\\\"vector field topology;flow visualization;coherent structure;unsteady vector field;ridge extraction\\\",\\\"Title\\\":\\\"Efficient Visualization of Lagrangian Coherent Structures by filtered AMR Ridge Extraction\\\"},\\\"801\\\":{\\\"Abstract\\\":\\\"Volumetric data commonly has high depth complexity which makes it difficult to judge spatial relationships accurately. There are many different ways to enhance depth perception, such as shading, contours, and shadows. Artists and illustrators frequently employ halos for this purpose. In this technique, regions surrounding the edges of certain structures are darkened or brightened which makes it easier to judge occlusion. Based on this concept, we present a flexible method for enhancing and highlighting structures of interest using GPU-based direct volume rendering. Our approach uses an interactively defined halo transfer function to classify structures of interest based on data value, direction, and position. A feature-preserving spreading algorithm is applied to distribute seed values to neighboring locations, generating a controllably smooth field of halo intensities. These halo intensities are then mapped to colors and opacities using a halo profile function. Our method can be used to annotate features at interactive frame rates.\\\",\\\"Authors\\\":\\\"Bruckner, S.;Groller, E.\\\",\\\"Clusters\\\":\\\"IllustrativeVisualization;Rendering;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70555\\\",\\\"Keywords\\\":\\\"illustrative visualization;volume rendering;halos\\\",\\\"Keywords_Processed\\\":\\\"volume render;illustrative visualization;halos\\\",\\\"Title\\\":\\\"Enhancing Depth-Perception with Flexible Volumetric Halos\\\"},\\\"802\\\":{\\\"Abstract\\\":\\\"We present a method to extract and visualize vortices that originate from bounding walls of three-dimensional time- dependent flows. These vortices can be detected using their footprint on the boundary, which consists of critical points in the wall shear stress vector field. In order to follow these critical points and detect their transformations, affected regions of the surface are parameterized. Thus, an existing singularity tracking algorithm devised for planar settings can be applied. The trajectories of the singularities are used as a basis for seeding particles. This leads to a new type of streak line visualization, in which particles are released from a moving source. These generalized streak lines visualize the particles that are ejected from the wall. We demonstrate the usefulness of our method on several transient fluid flow datasets from computational fluid dynamics simulations.\\\",\\\"Authors\\\":\\\"Wiebel, A.;Tricoche, X.;Schneider, D.;Jnicke, H.;Scheuermann, G.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;StreamlinesPathlinesStreaklines;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70557\\\",\\\"Keywords\\\":\\\"flow visualization;skin friction;vortex;singularity tracking;time-dependent vector fields;generalized streak line\\\",\\\"Keywords_Processed\\\":\\\"vortex;singularity tracking;time dependent vector field;generalized streak line;skin friction;flow visualization\\\",\\\"Title\\\":\\\"Generalized Streak Lines: Analysis and Visualization of Boundary Induced Vortices\\\"},\\\"803\\\":{\\\"Abstract\\\":\\\"We present the results of two controlled studies comparing layered surface visualizations under various texture conditions. The task was to estimate surface normals, measured by accuracy of a hand-set surface normal probe. A single surface visualization was compared with the two-surfaces case under conditions of no texture and with projected grid textures. Variations in relative texture spacing on top and bottom surfaces were compared, as well as opacity of the top surface. Significant improvements are found for the textured cases over non-textured surfaces. Either larger or thinner top-surface textures, and lower top surface opacities are shown to give less bottom surface error. Top surface error appears to be highly resilient to changes in texture. Given the results we also present an example of how appropriate textures might be useful in volume visualization.\\\",\\\"Authors\\\":\\\"Bair, A.;House, D.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;Perception;SurfaceRelatedDataAndTechniques;Textures\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70559\\\",\\\"Keywords\\\":\\\"texturing;perception;layered surfaces;optimal visualization\\\",\\\"Keywords_Processed\\\":\\\"optimal visualization;layer surface;perception;texture\\\",\\\"Title\\\":\\\"Grid With a View: Optimal Texturing for Perception of Layered Surface Shape\\\"},\\\"804\\\":{\\\"Abstract\\\":\\\"Surgical approaches tailored to an individual patient's anatomy and pathology have become standard in neurosurgery. Precise preoperative planning of these procedures, however, is necessary to achieve an optimal therapeutic effect. Therefore, multiple radiological imaging modalities are used prior to surgery to delineate the patient's anatomy, neurological function, and metabolic processes. Developing a three-dimensional perception of the surgical approach, however, is traditionally still done by mentally fusing multiple modalities. Concurrent 3D visualization of these datasets can, therefore, improve the planning process significantly. In this paper we introduce an application for planning of individual neurosurgical approaches with high-quality interactive multimodal volume rendering. The application consists of three main modules which allow to (1) plan the optimal skin incision and opening of the skull tailored to the underlying pathology; (2) visualize superficial brain anatomy, function and metabolism; and (3) plan the patient-specific approach for surgery of deep-seated lesions. The visualization is based on direct multi-volume raycasting on graphics hardware, where multiple volumes from different modalities can be displayed concurrently at interactive frame rates. Graphics memory limitations are avoided by performing raycasting on bricked volumes. For preprocessing tasks such as registration or segmentation, the visualization modules are integrated into a larger framework, thus supporting the entire workflow of preoperative planning.\\\",\\\"Authors\\\":\\\"Beyer, J.;Hadwiger, M.;Wolfsberger, S.;Buhler, K.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;HardwareAccellerationAndComputationGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70560\\\",\\\"Keywords\\\":\\\"surgery planning;hardware assisted raycasting;multimodal volume rendering\\\",\\\"Keywords_Processed\\\":\\\"surgery planning;multimodal volume render;hardware assist raycasting\\\",\\\"Title\\\":\\\"High-Quality Multimodal Volume Rendering for Preoperative Planning of Neurosurgical Interventions\\\"},\\\"805\\\":{\\\"Abstract\\\":\\\"Much of the visualization research has focused on improving the rendering quality and speed, and enhancing the perceptibility of features in the data. Recently, significant emphasis has been placed on focus+context (F+C) techniques (e.g., fisheye views and magnification lens) for data exploration in addition to viewing transformation and hierarchical navigation. However, most of the existing data exploration techniques rely on the manipulation of viewing attributes of the rendering system or optical attributes of the data objects, with users being passive viewers. In this paper, we propose a more active approach to data exploration, which attempts to mimic how we would explore data if we were able to hold it and interact with it in our hands. This involves allowing the users to physically or actively manipulate the geometry of a data object. While this approach has been traditionally used in applications, such as surgical simulation, where the original geometry of the data objects is well understood by the users, there are several challenges when this approach is generalized for applications, such as flow and information visualization, where there is no common perception as to the normal or natural geometry of a data object. We introduce a taxonomy and a set of transformations especially for illustrative deformation of general data exploration. We present combined geometric or optical illustration operators for focus+context visualization, and examine the best means for preventing the deformed context from being misperceived. We demonstrated the feasibility of this generalization with examples of flow, information and video visualization.\\\",\\\"Authors\\\":\\\"Correa, C.;Silver, D.;Chen, M.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;InteractionTechniquesGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70565\\\",\\\"Keywords\\\":\\\"volume deformation;focus+context visualization;interaction\\\",\\\"Keywords_Processed\\\":\\\"volume deformation;focus context visualization;interaction\\\",\\\"Title\\\":\\\"Illustrative Deformation for Data Exploration\\\"},\\\"806\\\":{\\\"Abstract\\\":\\\"We describe a system for interactively rendering isosurfaces of tetrahedral finite-element scalar fields using coherent ray tracing techniques on the CPU. By employing state-of-the art methods in polygonal ray tracing, namely aggressive packet/frustum traversal of a bounding volume hierarchy, we can accommodate large and time-varying unstructured data. In conjunction with this efficiency structure, we introduce a novel technique for intersecting ray packets with tetrahedral primitives. Ray tracing is flexible, allowing for dynamic changes in isovalue and time step, visualization of multiple isosurfaces, shadows, and depth-peeling transparency effects. The resulting system offers the intuitive simplicity of isosurfacing, guaranteed-correct visual results, and ultimately a scalable, dynamic and consistently interactive solution for visualizing unstructured volumes.\\\",\\\"Authors\\\":\\\"Wald, I.;Friedrich, H.;Knoll, A.;Hansen, C.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices;RaytracingRaycasting;ScalarFieldDataTechniques;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70566\\\",\\\"Keywords\\\":\\\"time-varying data;raytracing;isosurface;tetrahedra;unstructured meshes;scalar fields\\\",\\\"Keywords_Processed\\\":\\\"time vary datum;tetrahedra;unstructured mesh;scalar field;isosurface;raytrace\\\",\\\"Title\\\":\\\"Interactive Isosurface Ray Tracing of Time-Varying Tetrahedral Volumes\\\"},\\\"807\\\":{\\\"Abstract\\\":\\\"We present a new approach for real-time sound rendering in complex, virtual scenes with dynamic sources and objects. Our approach combines the efficiency of interactive ray tracing with the accuracy of tracing a volumetric representation. We use a four-sided convex frustum and perform clipping and intersection tests using ray packet tracing. A simple and efficient formulation is used to compute secondary frusta and perform hierarchical traversal. We demonstrate the performance of our algorithm in an interactive system for complex environments and architectural models with tens or hundreds of thousands of triangles. Our algorithm can perform real-time simulation and rendering on a high-end PC.\\\",\\\"Authors\\\":\\\"Lauterbach, C.;Chandak, A.;Manocha, D.\\\",\\\"Clusters\\\":\\\"AcousticsSoundSonification;InteractionTechniquesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70567\\\",\\\"Keywords\\\":\\\"interactive system;acoustic propagation\\\",\\\"Keywords_Processed\\\":\\\"acoustic propagation;interactive system\\\",\\\"Title\\\":\\\"Interactive sound rendering in complex and dynamic scenes using frustum tracing\\\"},\\\"808\\\":{\\\"Abstract\\\":\\\"Perfusion data are dynamic medical image data which characterize the regional blood flow in human tissue. These data bear a great potential in medical diagnosis, since diseases can be better distinguished and detected at an earlier stage compared to static image data. The wide-spread use of perfusion data is hampered by the lack of efficient evaluation methods. For each voxel, a time-intensity curve characterizes the enhancement of a contrast agent. Parameters derived from these curves characterize the perfusion and have to be integrated for diagnosis. The diagnostic evaluation of this multi-field data is challenging and time-consuming due to its complexity. For the visual analysis of such datasets, feature-based approaches allow to reduce the amount of data and direct the user to suspicious areas. We present an interactive visual analysis approach for the evaluation of perfusion data. For this purpose, we integrate statistical methods and interactive feature specification. Correlation analysis and Principal Component Analysis (PCA) are applied for dimension reduction and to achieve a better understanding of the inter-parameter relations. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The specification result is linked to all views establishing a focus+context style of visualization in 3D. We discuss our approach with respect to clinical datasets from the three major application areas: ischemic stroke diagnosis, breast tumor diagnosis, as well as the diagnosis of the coronary heart disease (CHD). It turns out that the significance of perfusion parameters strongly depends on the individual patient, scanning parameters, and data pre-processing.\\\",\\\"Authors\\\":\\\"Oeltze, S.;Doleisch, H.;Hauser, H.;Muigg, P.;Preim, B.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;IntegratingSpatialAndNonSpatialDataVisualization;MultidimensionalMultivariateMultifieldDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70569\\\",\\\"Keywords\\\":\\\"visual data mining;time-varying volumes;multi-field visualization;integrating infovis/scivis\\\",\\\"Keywords_Processed\\\":\\\"multi field visualization;integrate infovis scivi;time vary volume;visual datum mining\\\",\\\"Title\\\":\\\"Interactive Visual Analysis of Perfusion Data\\\"},\\\"809\\\":{\\\"Abstract\\\":\\\"In this paper we present a method to compute and visualize volumetric white matter connectivity in diffusion tensor magnetic resonance imaging (DT-MRI) using a Hamilton-Jacobi (H-J) solver on the GPU (graphics processing unit). Paths through the volume are assigned costs that are lower if they are consistent with the preferred diffusion directions. The proposed method finds a set of voxels in the DTI volume that contain paths between two regions whose costs are within a threshold of the optimal path. The result is a volumetric optimal path analysis, which is driven by clinical and scientific questions relating to the connectivity between various known anatomical regions of the brain. To solve the minimal path problem quickly, we introduce a novel numerical algorithm for solving H-J equations, which we call the fast iterative method (FIM). This algorithm is well-adapted to parallel architectures, and we present a GPU-based implementation, which runs roughly 50-100 times faster than traditional CPU-based solvers for anisotropic H-J equations. The proposed system allows users to freely change the endpoints of interesting pathways and to visualize the optimal volumetric path between them at an interactive rate. We demonstrate the proposed method on some synthetic and real DT-MRI datasets and compare the performance with existing methods.\\\",\\\"Authors\\\":\\\"Jeong, W.-K.;Fletcher, P.T.;Ran Tao;Whitaker, R.T.\\\",\\\"Clusters\\\":\\\"InputAndOutputDevicesGeneral;InteractionTechniquesGeneral;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70571\\\",\\\"Keywords\\\":\\\"diffusion tensor visualization;interactivity;graphics hardware\\\",\\\"Keywords_Processed\\\":\\\"interactivity;diffusion tensor visualization;graphic hardware\\\",\\\"Title\\\":\\\"Interactive Visualization of Volumetric White Matter Connectivity in DT-MRI Using a Parallel-Hardware Hamilton-Jacobi Solver\\\"},\\\"810\\\":{\\\"Abstract\\\":\\\"Topology has been an important tool for analyzing scalar data and flow fields in visualization. In this work, we analyze the topology of multivariate image and volume data sets with discontinuities in order to create an efficient, raster-based representation we call IStar. Specifically, the topology information is used to create a dual structure that contains nodes and connectivity information for every segmentable region in the original data set. This graph structure, along with a sampled representation of the segmented data set, is embedded into a standard raster image which can then be substantially downsampled and compressed. During rendering, the raster image is upsampled and the dual graph is used to reconstruct the original function. Unlike traditional raster approaches, our representation can preserve sharp discontinuities at any level of magnification, much like scalable vector graphics. However, because our representation is raster-based, it is well suited to the real-time rendering pipeline. We demonstrate this by reconstructing our data sets on graphics hardware at real-time rates.\\\",\\\"Authors\\\":\\\"Kniss, J.;Hunt, W.;Potter, K.;Sen, P.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;ImageBasedDataImageSignalProcessing;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70572\\\",\\\"Keywords\\\":\\\"compression;topology;image representation\\\",\\\"Keywords_Processed\\\":\\\"image representation;topology;compression\\\",\\\"Title\\\":\\\"IStar: A Raster Representation for Scalable Image and Volume Data\\\"},\\\"811\\\":{\\\"Abstract\\\":\\\"We describe a novel volumetric global illumination framework based on the face-centered cubic (FCC) lattice. An FCC lattice has important advantages over a Cartesian lattice. It has higher packing density in the frequency domain, which translates to better sampling efficiency. Furthermore, it has the maximal possible kissing number (equivalent to the number of nearest neighbors of each site), which provides optimal 3D angular discretization among all lattices. We employ a new two-pass (illumination and rendering) global illumination scheme on an FCC lattice. This scheme exploits the angular discretization to greatly simplify the computation in multiple scattering and to minimize illumination information storage. The GPU has been utilized to further accelerate the rendering stage. We demonstrate our new framework with participating media and volume rendering with multiple scattering, where both are significantly faster than traditional techniques with comparable quality.\\\",\\\"Authors\\\":\\\"Feng Qiu;Fang Xu;Zhe Fan;Neophytos, N.;Kaufman, A.;Mueller, K.\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;Illumination;MeshesGridsAndLattices;Sampling;SocialNetworksAndSocialMedia;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70573\\\",\\\"Keywords\\\":\\\"volume rendering;multiple scattering;sampling;volume visualization;gpu;face-centered cubic lattice;lattice;participating media\\\",\\\"Keywords_Processed\\\":\\\"volume render;multiple scattering;lattice;participate medium;sample;face center cubic lattice;volume visualization;gpu\\\",\\\"Title\\\":\\\"Lattice-Based Volumetric Global Illumination\\\"},\\\"812\\\":{\\\"Abstract\\\":\\\"Acoustic quality in room acoustics is measured by well defined quantities, like definition, which can be derived from simulated impulse response filters or measured values. These take into account the intensity and phase shift of multiple reflections due to a wave front emanating from a sound source. Definition (D50) and clarity (C50) for example correspond to the fraction of the energy received in total to the energy received in the first 50 ms at a certain listener position. Unfortunately, the impulse response measured at a single point does not provide any information about the direction of reflections, and about the reflection surfaces which contribute to this measure. For the visualization of room acoustics, however, this information is very useful since it allows to discover regions with high contribution and provides insight into the influence of all reflecting surfaces to the quality measure. We use the phonon tracing method to calculate the contribution of the reflection surfaces to the impulse response for different listener positions. This data is used to compute importance values for the geometry taking a certain acoustic metric into account. To get a visual insight into the directional aspect, we map the importance to the reflecting surfaces of the geometry. This visualization indicates which parts of the surfaces need to be changed to enhance the chosen acoustic quality measure. We apply our method to the acoustic improvement of a lecture hall by means of enhancing the overall speech comprehensibility (clarity) and evaluate the results using glyphs to visualize the clarity (C50) values at listener positions throughout the room.\\\",\\\"Authors\\\":\\\"Michel, F.;Deines, E.;Hering-Bertram, M.;Garth, C.;Hagen, H.\\\",\\\"Clusters\\\":\\\"AcousticsSoundSonification;ApplicationsGeneralAndOther\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70575\\\",\\\"Keywords\\\":\\\"sound analytics;applications of visualization;room acoustics;acoustic metric;phonon tracing\\\",\\\"Keywords_Processed\\\":\\\"acoustic metric;application of visualization;phonon tracing;sound analytic;room acoustic\\\",\\\"Title\\\":\\\"Listener-based Analysis of Surface Importance for Acoustic Metrics\\\"},\\\"813\\\":{\\\"Abstract\\\":\\\"Although real-time interactive volume rendering is available even for very large data sets, this visualization method is used quite rarely in the clinical practice. We suspect this is because it is very complicated and time consuming to adjust the parameters to achieve meaningful results. The clinician has to take care of the appropriate viewpoint, zooming, transfer function setup, clipping planes and other parameters. Because of this, most often only 2D slices of the data set are examined. Our work introduces LiveSync, a new concept to synchronize 2D slice views and volumetric views of medical data sets. Through intuitive picking actions on the slice, the users define the anatomical structures they are interested in. The 3D volumetric view is updated automatically with the goal that the users are provided with expressive result images. To achieve this live synchronization we use a minimal set of derived information without the need for segmented data sets or data-specific pre-computations. The components we consider are the picked point, slice view zoom, patient orientation, viewpoint history, local object shape and visibility. We introduce deformed viewing spheres which encode the viewpoint quality for the components. A combination of these deformed viewing spheres is used to estimate a good viewpoint. Our system provides the physician with synchronized views which help to gain deeper insight into the medical data with minimal user interaction.\\\",\\\"Authors\\\":\\\"Kohlmann, P.;Bruckner, S.;Kanitsar, A.;Kanitsar, A.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;CamerasCameraViewsAndProjections;InteractionTechniquesGeneral;MultipleLinkedCoordinatedViews;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70576\\\",\\\"Keywords\\\":\\\"navigation;medical visualization;linked views;viewpoint selection;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;navigation;viewpoint selection;link view;medical visualization\\\",\\\"Title\\\":\\\"LiveSync: Deformed Viewing Spheres for Knowledge-Based Navigation\\\"},\\\"814\\\":{\\\"Abstract\\\":\\\"In this paper we introduce a visualization technique that provides an abstracted view of the shape and spatio-physico-chemical properties of complex molecules. Unlike existing molecular viewing methods, our approach suppresses small details to facilitate rapid comprehension, yet marks the location of significant features so they remain visible. Our approach uses a combination of filters and mesh restructuring to generate a simplified representation that conveys the overall shape and spatio-physico-chemical properties (e.g. electrostatic charge). Surface markings are then used in the place of important removed details, as well as to supply additional information. These simplified representations are amenable to display using stylized rendering algorithms to further enhance comprehension. Our initial experience suggests that our approach is particularly useful in browsing collections of large molecules and in readily making comparisons between them.\\\",\\\"Authors\\\":\\\"Cipriano, G.;Gleicher, M.\\\",\\\"Clusters\\\":\\\"Labeling;MolecularScienceAndChemistry;SurfaceRelatedDataAndTechniques;Textures\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70578\\\",\\\"Keywords\\\":\\\"molecular visualization;cartographic labeling;surfaces;molecular surfaces;texture\\\",\\\"Keywords_Processed\\\":\\\"texture;surface;molecular visualization;molecular surface;cartographic labeling\\\",\\\"Title\\\":\\\"Molecular Surface Abstraction\\\"},\\\"815\\\":{\\\"Abstract\\\":\\\"We present a novel approach for analyzing two-dimensional (2D) flow field data based on the idea of invariant moments. Moment invariants have traditionally been used in computer vision applications, and we have adapted them for the purpose of interactive exploration of flow field data. The new class of moment invariants we have developed allows us to extract and visualize 2D flow patterns, invariant under translation, scaling, and rotation. With our approach one can study arbitrary flow patterns by searching a given 2D flow data set for any type of pattern as specified by a user. Further, our approach supports the computation of moments at multiple scales, facilitating fast pattern extraction and recognition. This can be done for critical point classification, but also for patterns with greater complexity. This multi-scale moment representation is also valuable for the comparative visualization of flow field data. The specific novel contributions of the work presented are the mathematical derivation of the new class of moment invariants, their analysis regarding critical point features, the efficient computation of a novel feature space representation, and based upon this the development of a fast pattern recognition algorithm for complex flow structures.\\\",\\\"Authors\\\":\\\"Schlemmer, M.;Heringer, M.;Morr, F.;Hotz, I.;Bertam, M.;Garth, C.;Kollmann, W.;Hamann, B.;Hagen, H.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;ImageBasedDataImageSignalProcessing;VisualPatternFeatureDetectionAndTracking\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70579\\\",\\\"Keywords\\\":\\\"flow visualization;pattern recognition;image processing;feature detection;pattern extraction\\\",\\\"Keywords_Processed\\\":\\\"pattern recognition;image processing;feature detection;pattern extraction;flow visualization\\\",\\\"Title\\\":\\\"Moment Invariants for the Analysis of 2D Flow fields\\\"},\\\"816\\\":{\\\"Abstract\\\":\\\"Modern unsteady (multi-)field visualizations require an effective reduction of the data to be displayed. From a huge amount of information the most informative parts have to be extracted. Instead of the fuzzy application dependent notion of feature, a new approach based on information theoretic concepts is introduced in this paper to detect important regions. This is accomplished by extending the concept of local statistical complexity from finite state cellular automata to discretized (multi-)fields. Thus, informative parts of the data can be highlighted in an application-independent, purely mathematical sense. The new measure can be applied to unsteady multifields on regular grids in any application domain. The ability to detect and visualize important parts is demonstrated using diffusion, flow, and weather simulations.\\\",\\\"Authors\\\":\\\"Jnicke, H.;Wiebel, A.;Scheuermann, G.;Kollmann, W.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;InformationTheory;MachineLearningAndStatistics;MultidimensionalMultivariateMultifieldDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques;VisualPatternFeatureDetectionAndTracking\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70615\\\",\\\"Keywords\\\":\\\"flow visualization;information theory;time-dependent;local statistical complexity;coherent structures;multi-field visualization;feature detection\\\",\\\"Keywords_Processed\\\":\\\"local statistical complexity;information theory;feature detection;flow visualization;time dependent;multi field visualization;coherent structure\\\",\\\"Title\\\":\\\"Multifield Visualization Using Local Statistical Complexity\\\"},\\\"817\\\":{\\\"Abstract\\\":\\\"New product development involves people with different backgrounds. Designers, engineers, and consumers all have different design criteria, and these criteria interact. Early concepts evolve in this kind of collaborative context, and there is a need for dynamic visualization of the interaction between design shape and other shape-related design criteria. In this paper, a morphable model is defined from simplified representations of suitably chosen real cars, providing a continuous shape space to navigate, manipulate and visualize. Physical properties and consumer-provided scores for the real cars (such as 'weight' and 'sportiness') are estimated for new designs across the shape space. This coupling allows one to manipulate the shape directly while reviewing the impact on estimated criteria, or conversely, to manipulate the criterial values of the current design to produce a new shape with more desirable attributes.\\\",\\\"Authors\\\":\\\"Smith, R.C.;Pawlicki, R.;Kokai, I.R.;Finger, J.;Vetter, T.\\\",\\\"Clusters\\\":\\\"DesignMethodologiesAndInteractionDesign;GeometricModeling;ShapeRelatedTechniques;TransitionsAndMorphing\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70581\\\",\\\"Keywords\\\":\\\"design space;shape space;barycentric coordinates;morphable model\\\",\\\"Keywords_Processed\\\":\\\"design space;shape space;morphable model;barycentric coordinate\\\",\\\"Title\\\":\\\"Navigating in a Shape Space of Registered Models\\\"},\\\"818\\\":{\\\"Abstract\\\":\\\"While there have been advances in visualization systems, particularly in multi-view visualizations and visual exploration, the process of building visualizations remains a major bottleneck in data exploration. We show that provenance metadata collected during the creation of pipelines can be reused to suggest similar content in related visualizations and guide semi-automated changes. We introduce the idea of query-by-example in the context of an ensemble of visualizations, and the use of analogies as first-class operations in a system to guide scalable interactions. We describe an implementation of these techniques in VisTrails, a publicly-available, open-source system.\\\",\\\"Authors\\\":\\\"Scheidegger, C.E.;Vo, H.T.;Koop, D.;Freire, J.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"QueriesAndSearch;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70584\\\",\\\"Keywords\\\":\\\"query-by-example;analogy;visualization systems\\\",\\\"Keywords_Processed\\\":\\\"analogy;visualization system;query by example\\\",\\\"Title\\\":\\\"Querying and Creating Visualizations by Analogy\\\"},\\\"819\\\":{\\\"Abstract\\\":\\\"With the exponential growth in size of geometric data, it is becoming increasingly important to make effective use of multilevel caches, limited disk storage, and bandwidth. As a result, recent work in the visualization community has focused either on designing sequential access compression schemes or on producing cache-coherent layouts of (uncompressed) meshes for random access. Unfortunately combining these two strategies is challenging as they fundamentally assume conflicting modes of data access. In this paper, we propose a novel order-preserving compression method that supports transparent random access to compressed triangle meshes. Our decompression method selectively fetches from disk, decodes, and caches in memory requested parts of a mesh. We also provide a general mesh access API for seamless mesh traversal and incidence queries. While the method imposes no particular mesh layout, it is especially suitable for cache-oblivious layouts, which minimize the number of decompression I/O requests and provide high cache utilization during access to decompressed, in-memory portions of the mesh. Moreover, the transparency of our scheme enables improved performance without the need for application code changes. We achieve compression rates on the order of 20:1 and significantly improved I/O performance due to reduced data transfer. To demonstrate the benefits of our method, we implement two common applications as benchmarks. By using cache-oblivious layouts for the input models, we observe 2-6 times overall speedup compared to using uncompressed meshes.\\\",\\\"Authors\\\":\\\"Sung-Eui Yoon;Lindstrom, P.\\\",\\\"Clusters\\\":\\\"CompressionTechniques;DatabasesAndDataMining;HardwareAccellerationAndComputationGeneral;ProgrammingAlgorithmsAndDataStructures;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70585\\\",\\\"Keywords\\\":\\\"random access;mesh data structures;external memory algorithms;mesh compression;cache-coherent layouts\\\",\\\"Keywords_Processed\\\":\\\"mesh data structure;cache coherent layout;mesh compression;external memory algorithm;random access\\\",\\\"Title\\\":\\\"Random-Accessible Compressed Triangle Meshes\\\"},\\\"820\\\":{\\\"Abstract\\\":\\\"Multi-projector displays today are automatically registered, both geometrically and photometrically, using cameras. Existing registration techniques assume pre-calibrated projectors and cameras that are devoid of imperfections such as lens distortion. In practice, however, these devices are usually imperfect and uncalibrated. Registration of each of these devices is often more challenging than the multi-projector display registration itself. To make tiled projection-based displays accessible to a layman user we should allow the use of uncalibrated inexpensive devices that are prone to imperfections. In this paper, we make two important advances in this direction. First, we present a new geometric registration technique that can achieve geometric alignment in the presence of severe projector lens distortion using a relatively inexpensive low-resolution camera. This is achieved via a closed-form model that relates the projectors to cameras, in planar multi-projector displays, using rational Bezier patches. This enables us to geometrically calibrate a 3000 times 2500 resolution planar multi-projector display made of 3 times 3 array of nine severely distorted projectors using a low resolution (640 times 480) VGA camera. Second, we present a photometric self-calibration technique for a projector-camera pair. This allows us to photometrically calibrate the same display made of nine projectors using a photometrically uncalibrated camera. To the best of our knowledge, this is the first work that allows geometrically imperfect projectors and photometrically uncalibrated cameras in calibrating multi-projector displays.\\\",\\\"Authors\\\":\\\"Bhasker, E.;Juang, R.;Majumder, A.\\\",\\\"Clusters\\\":\\\"DisplaysGeneral;GeometricModeling;LargeAndHighResDisplays\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70586\\\",\\\"Keywords\\\":\\\"tiled displays;photometric calibration;geometric calibration\\\",\\\"Keywords_Processed\\\":\\\"geometric calibration;photometric calibration;tile display\\\",\\\"Title\\\":\\\"Registration Techniques for Using Imperfect and Par tially Calibrated Devices in Planar Multi-Projector Displays\\\"},\\\"821\\\":{\\\"Abstract\\\":\\\"This paper presents a scalable framework for real-time raycasting of large unstructured volumes that employs a hybrid bricking approach. It adaptively combines original unstructured bricks in important (focus) regions, with structured bricks that are resampled on demand in less important (context) regions. The basis of this focus+context approach is interactive specification of a scalar degree of interest (DOI) function. Thus, rendering always considers two volumes simultaneously: a scalar data volume, and the current DOI volume. The crucial problem of visibility sorting is solved by raycasting individual bricks and compositing in visibility order from front to back. In order to minimize visual errors at the grid boundary, it is always rendered accurately, even for resampled bricks. A variety of different rendering modes can be combined, including contour enhancement. A very important property of our approach is that it supports a variety of cell types natively, i.e., it is not constrained to tetrahedral grids, even when interpolation within cells is used. Moreover, our framework can handle multi-variate data, e.g., multiple scalar channels such as temperature or pressure, as well as time-dependent data. The combination of unstructured and structured bricks with different quality characteristics such as the type of interpolation or resampling resolution in conjunction with custom texture memory management yields a very scalable system.\\\",\\\"Authors\\\":\\\"Muigg, P.;Hadwiger, M.;Doleisch, H.;Hauser, H.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;HardwareAccellerationAndComputationGeneral;MeshesGridsAndLattices\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70588\\\",\\\"Keywords\\\":\\\"focus+context technique;hardware assisted volume rendering;volume rendering of unstructured grids\\\",\\\"Keywords_Processed\\\":\\\"hardware assist volume render;focus context technique;volume render of unstructured grid\\\",\\\"Title\\\":\\\"Scalable Hybrid Unstructured and Structured Grid Raycasting\\\"},\\\"822\\\":{\\\"Abstract\\\":\\\"We have combined methods from volume visualization and data analysis to support better diagnosis and treatment of human retinal diseases. Many diseases can be identified by abnormalities in the thicknesses of various retinal layers captured using optical coherence tomography (OCT). We used a support vector machine (SVM) to perform semi-automatic segmentation of retinal layers for subsequent analysis including a comparison of layer thicknesses to known healthy parameters. We have extended and generalized an older SVM approach to support better performance in a clinical setting through performance enhancements and graceful handling of inherent noise in OCT data by considering statistical characteristics at multiple levels of resolution. The addition of the multi-resolution hierarchy extends the SVM to have \\\\\\\"global awareness\\\\\\\". A feature, such as a retinal layer, can therefore be modeled within the SVM as a combination of statistical characteristics across all levels; thus capturing high- and low-frequency information. We have compared our semi-automatically generated segmentations to manually segmented layers for verification purposes. Our main goals were to provide a tool that could (i) be used in a clinical setting; (ii) operate on noisy OCT data; and (iii) isolate individual or multiple retinal layers in both healthy and disease cases that contain structural deformities.\\\",\\\"Authors\\\":\\\"Fuller, A.R.;Zawadzki, R.J.;Choi, S.;Wiley, D.F.;Werner, J.S.;Hamann, B.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;ImageBasedDataImageSignalProcessing;MachineLearningAndStatistics;Perception;SegmentationAndClassification;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70590\\\",\\\"Keywords\\\":\\\"retinal;image analysis;support vector machine;image processing;volume visualization;segmentation;optical coherence tomography\\\",\\\"Keywords_Processed\\\":\\\"image processing;segmentation;optical coherence tomography;image analysis;support vector machine;volume visualization;retinal\\\",\\\"Title\\\":\\\"Segmentation of Three-dimensional Retinal Image Data\\\"},\\\"823\\\":{\\\"Abstract\\\":\\\"Direct volume rendering techniques map volumetric attributes (e.g., density, gradient magnitude, etc.) to visual styles. Commonly this mapping is specified by a transfer function. The specification of transfer functions is a complex task and requires expert knowledge about the underlying rendering technique. In the case of multiple volumetric attributes and multiple visual styles the specification of the multi-dimensional transfer function becomes more challenging and non-intuitive. We present a novel methodology for the specification of a mapping from several volumetric attributes to multiple illustrative visual styles. We introduce semantic layers that allow a domain expert to specify the mapping in the natural language of the domain. A semantic layer defines the mapping of volumetric attributes to one visual style. Volumetric attributes and visual styles are represented as fuzzy sets. The mapping is specified by rules that are evaluated with fuzzy logic arithmetics. The user specifies the fuzzy sets and the rules without special knowledge about the underlying rendering technique. Semantic layers allow for a linguistic specification of the mapping from attributes to visual styles replacing the traditional transfer function specification.\\\",\\\"Authors\\\":\\\"Rautek, P.;Bruckner, S.;Groller, E.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;IllustrativeVisualization;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70591\\\",\\\"Keywords\\\":\\\"focus+context technique;volume visualization;illustrative visualization\\\",\\\"Keywords_Processed\\\":\\\"focus context technique;illustrative visualization;volume visualization\\\",\\\"Title\\\":\\\"Semantic Layers for Illustrative Volume Rendering\\\"},\\\"824\\\":{\\\"Abstract\\\":\\\"Just as we can work with two-dimensional floor plans to communicate 3D architectural design, we can exploit reduced- dimension shadows to manipulate the higher-dimensional objects generating the shadows. In particular, by taking advantage of physically reactive 3D shadow-space controllers, we can transform the task of interacting with 4D objects to a new level of physical reality. We begin with a teaching tool that uses 2D knot diagrams to manipulate the geometry of 3D mathematical knots via their projections; our unique 2D haptic interface allows the user to become familiar with sketching, editing, exploration, and manipulation of 3D knots rendered as projected images on a 2D shadow space. By combining graphics and collision-sensing haptics, we can enhance the 2D shadow-driven editing protocol to successfully leverage 2D pen-and-paper or blackboard skills. Building on the reduced-dimension 2D editing tool for manipulating 3D shapes, we develop the natural analogy to produce a reduced-dimension 3D tool for manipulating 4D shapes. By physically modeling the correct properties of 4D surfaces, their bending forces, and their collisions in the 3D haptic controller interface, we can support full-featured physical exploration of 4D mathematical objects in a manner that is otherwise far beyond the experience accessible to human beings. As far as we are aware, this paper reports the first interactive system with force-feedback that provides \\\\\\\"4D haptic visualization\\\\\\\" permitting the user to model and interact with 4D cloth-like objects.\\\",\\\"Authors\\\":\\\"Hui Zhang;Hanson, A.J.\\\",\\\"Clusters\\\":\\\"InputAndOutputDevicesGeneral;NumericalMethodsMathematics;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70593\\\",\\\"Keywords\\\":\\\"visualization;haptics;knot theory\\\",\\\"Keywords_Processed\\\":\\\"visualization;knot theory;haptic\\\",\\\"Title\\\":\\\"Shadow-Driven 4D Haptic Visualization\\\"},\\\"825\\\":{\\\"Abstract\\\":\\\"Most streamline generation algorithms either provide a particular density of streamlines across the domain or explicitly detect features, such as critical points, and follow customized rules to emphasize those features. However, the former generally includes many redundant streamlines, and the latter requires Boolean decisions on which points are features (and may thus suffer from robustness problems for real-world data). We take a new approach to adaptive streamline placement for steady vector fields in 2D and 3D. We define a metric for local similarity among streamlines and use this metric to grow streamlines from a dense set of candidate seed points. The metric considers not only Euclidean distance, but also a simple statistical measure of shape and directional similarity. Without explicit feature detection, our method produces streamlines that naturally accentuate regions of geometric interest. In conjunction with this method, we also propose a quantitative error metric for evaluating a streamline representation based on how well it preserves the information from the original vector field. This error metric reconstructs a vector field from points on the streamline representation and computes a difference of the reconstruction from the original vector field.\\\",\\\"Authors\\\":\\\"Yuan Chen;Cohen, J.D.;Krolik, J.H.\\\",\\\"Clusters\\\":\\\"ShapeRelatedTechniques;StreamlinesPathlinesStreaklines;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70595\\\",\\\"Keywords\\\":\\\"shape matching;vector field reconstruction;adaptive streamlines\\\",\\\"Keywords_Processed\\\":\\\"adaptive streamline;shape matching;vector field reconstruction\\\",\\\"Title\\\":\\\"Similarity-Guided Streamline Placement with Error Evaluation\\\"},\\\"826\\\":{\\\"Abstract\\\":\\\"We present a method for stochastic fiber tract mapping from diffusion tensor MRI (DT-MRI) implemented on graphics hardware. From the simulated fibers we compute a connectivity map that gives an indication of the probability that two points in the dataset are connected by a neuronal fiber path. A Bayesian formulation of the fiber model is given and it is shown that the inversion method can be used to construct plausible connectivity. An implementation of this fiber model on the graphics processing unit (GPU) is presented. Since the fiber paths can be stochastically generated independently of one another, the algorithm is highly parallelizable. This allows us to exploit the data-parallel nature of the GPU fragment processors. We also present a framework for the connectivity computation on the GPU. Our implementation allows the user to interactively select regions of interest and observe the evolving connectivity results during computation. Results are presented from the stochastic generation of over 250,000 fiber steps per iteration at interactive frame rates on consumer-grade graphics hardware.\\\",\\\"Authors\\\":\\\"McGraw, T.;Nadar, M.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;TensorDataAndTechniques;Tractography\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70597\\\",\\\"Keywords\\\":\\\"magnetic resonance imaging;stochastic tractography;diffusion tensor\\\",\\\"Keywords_Processed\\\":\\\"stochastic tractography;diffusion tensor;magnetic resonance imaging\\\",\\\"Title\\\":\\\"Stochastic DT-MRI Connectivity Mapping on the GPU\\\"},\\\"827\\\":{\\\"Abstract\\\":\\\"This paper describes a novel method for creating surface models of multi-material components using dual energy computed tomography (DECT). The application scenario is metrology and dimensional measurement in industrial high resolution 3D X-ray computed tomography (3DCT). Based on the dual source / dual exposure technology this method employs 3DCT scans of a high precision micro-focus and a high energy macro-focus X-ray source. The presented work makes use of the advantages of dual X-ray exposure technology in order to facilitate dimensional measurements of multi-material components with high density material within low density material. We propose a workflow which uses image fusion and local surface extraction techniques: a prefiltering step reduces noise inherent in the data. For image fusion the datasets have to be registered. In the fusion step the benefits of both scans are combined. The structure of the specimen is taken from the low precision, blurry, high energy dataset while the sharp edges are adopted and fused into the resulting image from the high precision, crisp, low energy dataset. In the final step a reliable surface model is extracted from the fused dataset using a local adaptive technique. The major contribution of this paper is the development of a specific workflow for dimensional measurements of multi-material industrial components, which takes two X-ray CT datasets with complementary strengths and weaknesses into account. The performance of the workflow is discussed using a test specimen as well as two real world industrial parts. As result, a significant improvement in overall measurement precision, surface geometry and mean deviation to reference measurement compared to single exposure scans was facilitated.\\\",\\\"Authors\\\":\\\"Heinzl, C.;Kastner, J.;Groller, E.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;ComparisonComparativeVisualizationAndSimilarity;EarthSpaceAndEnvironmentalSciences;IsosurfaceAndSurfaceExtractionTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70598\\\",\\\"Keywords\\\":\\\"dual energy computed tomography image fusion;local surface extraction;metrology;dimensional measurement;variance comparison;dual energy ct\\\",\\\"Keywords_Processed\\\":\\\"metrology;local surface extraction;variance comparison;dimensional measurement;dual energy compute tomography image fusion;dual energy ct\\\",\\\"Title\\\":\\\"Surface Extraction from Multi-Material Components for Metrology using Dual Energy CT\\\"},\\\"828\\\":{\\\"Abstract\\\":\\\"Analyzing, visualizing, and illustrating changes within time-varying volumetric data is challenging due to the dynamic changes occurring between timesteps. The changes and variations in computational fluid dynamic volumes and atmospheric 3D datasets do not follow any particular transformation. Features within the data move at different speeds and directions making the tracking and visualization of these features a difficult task. We introduce a texture-based feature tracking technique to overcome some of the current limitations found in the illustration and visualization of dynamic changes within time-varying volumetric data. Our texture-based technique tracks various features individually and then uses the tracked objects to better visualize structural changes. We show the effectiveness of our texture-based tracking technique with both synthetic and real world time-varying data. Furthermore, we highlight the specific visualization, annotation, registration, and feature isolation benefits of our technique. For instance, we show how our texture-based tracking can lead to insightful visualizations of time-varying data. Such visualizations, more than traditional visualization techniques, can assist domain scientists to explore and understand dynamic changes.\\\",\\\"Authors\\\":\\\"Caban, J.J.;Joshi, A.;Rheingans, P.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;Textures;TimeseriesTimeVaryingDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70599\\\",\\\"Keywords\\\":\\\"flow visualization;time-varying data;feature tracking;visualization;texture-based analysis\\\",\\\"Keywords_Processed\\\":\\\"visualization;time vary datum;texture base analysis;feature tracking;flow visualization\\\",\\\"Title\\\":\\\"Texture-based feature tracking for effective time-varying data visualization\\\"},\\\"829\\\":{\\\"Abstract\\\":\\\"Today's PCs incorporate multiple CPUs and GPUs and are easily arranged in clusters for high-performance, interactive graphics. We present an approach based on hierarchical, screen-space tiles to parallelizing rendering with level of detail. Adapt tiles, render tiles, and machine tiles are associated with CPUs, GPUs, and PCs, respectively, to efficiently parallelize the workload with good resource utilization. Adaptive tile sizes provide load balancing while our level of detail system allows total and independent management of the load on CPUs and GPUs. We demonstrate our approach on parallel configurations consisting of both single PCs and a cluster of PCs.\\\",\\\"Authors\\\":\\\"Niski, K.;Cohen, J.D.\\\",\\\"Clusters\\\":\\\"DisplaysGeneral;GeometricModeling;LargeAndHighResDisplays\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70587\\\",\\\"Keywords\\\":\\\"tiled displays;photometric calibration;geometric calibration\\\",\\\"Keywords_Processed\\\":\\\"geometric calibration;photometric calibration;tile display\\\",\\\"Title\\\":\\\"Tile-based Level of Detail for the Parallel Age \\\"},\\\"830\\\":{\\\"Abstract\\\":\\\"Pipeline architectures provide a versatile and efficient mechanism for constructing visualizations, and they have been implemented in numerous libraries and applications over the past two decades. In addition to allowing developers and users to freely combine algorithms, visualization pipelines have proven to work well when streaming data and scale well on parallel distributed- memory computers. However, current pipeline visualization frameworks have a critical flaw: they are unable to manage time varying data. As data flows through the pipeline, each algorithm has access to only a single snapshot in time of the data. This prevents the implementation of algorithms that do any temporal processing such as particle tracing; plotting over time; or interpolation, fitting, or smoothing of time series data. As data acquisition technology improves, as simulation time-integration techniques become more complex, and as simulations save less frequently and regularly, the ability to analyze the time-behavior of data becomes more important. This paper describes a modification to the traditional pipeline architecture that allows it to accommodate temporal algorithms. Furthermore, the architecture allows temporal algorithms to be used in conjunction with algorithms expecting a single time snapshot, thus simplifying software design and allowing adoption into existing pipeline frameworks. Our architecture also continues to work well in parallel distributed-memory environments. We demonstrate our architecture by modifying the popular VTK framework and exposing the functionality to the ParaView application. We use this framework to apply time-dependent algorithms on large data with a parallel cluster computer and thereby exercise a functionality that previously did not exist.\\\",\\\"Authors\\\":\\\"Biddiscombe, J.;Geveci, B.;Martin, K.;Moreland, K.;Thompson, D.\\\",\\\"Clusters\\\":\\\"TimeseriesTimeVaryingDataAndTechniques;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70600\\\",\\\"Keywords\\\":\\\"time-varying data;data-parallel visualization pipeline\\\",\\\"Keywords_Processed\\\":\\\"time vary datum;datum parallel visualization pipeline\\\",\\\"Title\\\":\\\"Time Dependent Processing in a Parallel Pipeline Architecture\\\"},\\\"831\\\":{\\\"Abstract\\\":\\\"Scientific visualization and illustration tools are designed to help people understand the structure and complexity of scientific data with images that are as informative and intuitive as possible. In this context the use of metaphors plays an important role since they make complex information easily accessible by using commonly known concepts. In this paper we propose a new metaphor, called \\\\\\\"topological landscapes,\\\\\\\" which facilitates understanding the topological structure of scalar functions. The basic idea is to construct a terrain with the same topology as a given dataset and to display the terrain as an easily understood representation of the actual input data. In this projection from an n-dimensional scalar function to a two-dimensional (2D) model we preserve function values of critical points, the persistence (function span) of topological features, and one possible additional metric property (in our examples volume). By displaying this topologically equivalent landscape together with the original data we harness the natural human proficiency in understanding terrain topography and make complex topological information easily accessible.\\\",\\\"Authors\\\":\\\"Weber, G.H.;Bremer, P.-T.;Pascucci, V.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;GeographyGeospatialVisCartographyTerrainVis;PhysicsAndPhysicalSciences;TopologyBasedTechniques;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70601\\\",\\\"Keywords\\\":\\\"user interface;contour tree;visual analytics;soar;feature detection;terrain;topology\\\",\\\"Keywords_Processed\\\":\\\"contour tree;terrain;user interface;topology;soar;feature detection;visual analytic\\\",\\\"Title\\\":\\\"Topological Landscapes: A Terrain Metaphor for Scientific Data\\\"},\\\"832\\\":{\\\"Abstract\\\":\\\"Topological methods give concise and expressive visual representations of flow fields. The present work suggests a comparable method for the visualization of human brain diffusion MRI data. We explore existing techniques for the topological analysis of generic tensor fields, but find them inappropriate for diffusion MRI data. Thus, we propose a novel approach that considers the asymptotic behavior of a probabilistic fiber tracking method and define analogs of the basic concepts of flow topology, like critical points, basins, and faces, with interpretations in terms of brain anatomy. The resulting features are fuzzy, reflecting the uncertainty inherent in any connectivity estimate from diffusion imaging. We describe an algorithm to extract the new type of features, demonstrate its robustness under noise, and present results for two regions in a diffusion MRI dataset to illustrate that the method allows a meaningful visual analysis of probabilistic fiber tracking results.\\\",\\\"Authors\\\":\\\"Schultz, T.;Theisel, H.;Seidel, H.-P.\\\",\\\"Clusters\\\":\\\"TensorDataAndTechniques;Tractography;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70602\\\",\\\"Keywords\\\":\\\"tensor topology;probabilistic fiber tracking;diffusion tensor;uncertainty visualization\\\",\\\"Keywords_Processed\\\":\\\"probabilistic fiber tracking;diffusion tensor;tensor topology;uncertainty visualization\\\",\\\"Title\\\":\\\"Topological Visualization of Brain Diffusion MRI Data\\\"},\\\"833\\\":{\\\"Abstract\\\":\\\"Analysis of the results obtained from material simulations is important in the physical sciences. Our research was motivated by the need to investigate the properties of a simulated porous solid as it is hit by a projectile. This paper describes two techniques for the generation of distance fields containing a minimal number of topological features, and we use them to identify features of the material. We focus on distance fields defined on a volumetric domain considering the distance to a given surface embedded within the domain. Topological features of the field are characterized by its critical points. Our first method begins with a distance field that is computed using a standard approach, and simplifies this field using ideas from Morse theory. We present a procedure for identifying and extracting a feature set through analysis of the MS complex, and apply it to find the invariants in the clean distance field. Our second method proceeds by advancing a front, beginning at the surface, and locally controlling the creation of new critical points. We demonstrate the value of topologically clean distance fields for the analysis of filament structures in porous solids. Our methods produce a curved skeleton representation of the filaments that helps material scientists to perform a detailed qualitative and quantitative analysis of pores, and hence infer important material properties. Furthermore, we provide a set of criteria for finding the \\\\\\\"difference\\\\\\\" between two skeletal structures, and use this to examine how the structure of the porous solid changes over several timesteps in the simulation of the particle impact.\\\",\\\"Authors\\\":\\\"Gyulassy, A.;Duchaineau, M.;Vijay Natarajan;Pascucci, V.;Bringa, E.M.;Higginbotham, A.;Hamann, B.\\\",\\\"Clusters\\\":\\\"MaterialScience;TopologyBasedTechniques;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70603\\\",\\\"Keywords\\\":\\\"wavefront;distance field;morse theory;critical points;porous solid;morse-smale complex;material science;topological simplification\\\",\\\"Keywords_Processed\\\":\\\"distance field;material science;morse smale complex;topological simplification;critical point;wavefront;morse theory;porous solid\\\",\\\"Title\\\":\\\"Topologically Clean Distance fields\\\"},\\\"834\\\":{\\\"Abstract\\\":\\\"This paper describes a method for constructing isosurface triangulations of sampled, volumetric, three-dimensional scalar fields. The resulting meshes consist of triangles that are of consistently high quality, making them well suited for accurate interpolation of scalar and vector-valued quantities, as required for numerous applications in visualization and numerical simulation. The proposed method does not rely on a local construction or adjustment of triangles as is done, for instance, in advancing wavefront or adaptive refinement methods. Instead, a system of dynamic particles optimally samples an implicit function such that the particles' relative positions can produce a topologically correct Delaunay triangulation. Thus, the proposed method relies on a global placement of triangle vertices. The main contributions of the paper are the integration of dynamic particles systems with surface sampling theory and PDE-based methods for controlling the local variability of particle densities, as well as detailing a practical method that accommodates Delaunay sampling requirements to generate sparse sets of points for the production of high-quality tessellations.\\\",\\\"Authors\\\":\\\"Meyer, M.;Kirby, R.M.;Whitaker, R.T.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices;ParticleVisualizationAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70604\\\",\\\"Keywords\\\":\\\"isosurface extraction;delaunay triangulation;particle systems\\\",\\\"Keywords_Processed\\\":\\\"delaunay triangulation;particle system;isosurface extraction\\\",\\\"Title\\\":\\\"Topology, Accuracy, and Quality of Isosurface Meshes Using Dynamic Particles\\\"},\\\"835\\\":{\\\"Abstract\\\":\\\"Hardware-accelerated volume rendering using the GPU is now the standard approach for real-time volume rendering, although limited graphics memory can present a problem when rendering large volume data sets. Volumetric compression in which the decompression is coupled to rendering has been shown to be an effective solution to this problem; however, most existing techniques were developed in the context of software volume rendering, and all but the simplest approaches are prohibitive in a real-time hardware-accelerated volume rendering context. In this paper we present a novel block-based transform coding scheme designed specifically with real-time volume rendering in mind, such that the decompression is fast without sacrificing compression quality. This is made possible by consolidating the inverse transform with dequantization in such a way as to allow most of the reprojection to be precomputed. Furthermore, we take advantage of the freedom afforded by offline compression in order to optimize the encoding as much as possible while hiding this complexity from the decoder. In this context we develop a new block classification scheme which allows us to preserve perceptually important features in the compression. The result of this work is an asymmetric transform coding scheme that allows very large volumes to be compressed and then decompressed in real-time while rendering on the GPU.\\\",\\\"Authors\\\":\\\"Fout, N.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"CompressionTechniques;HardwareAccellerationAndComputationGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70516\\\",\\\"Keywords\\\":\\\"compressed volume rendering;hardware accelerated volume rendering;volume compression;transform coding\\\",\\\"Keywords_Processed\\\":\\\"compress volume render;volume compression;transform coding;hardware accelerate volume render\\\",\\\"Title\\\":\\\"Transform Coding for Hardware-accelerated Volume Rendering\\\"},\\\"836\\\":{\\\"Abstract\\\":\\\"Proteins are highly flexible and large amplitude deformations of their structure, also called slow dynamics, are often decisive to their function. We present a two-level rendering approach that enables visualization of slow dynamics of large protein assemblies. Our approach is aligned with a hierarchical model of large scale molecules. Instead of constantly updating positions of large amounts of atoms, we update the position and rotation of residues, i.e., higher level building blocks of a protein. Residues are represented by one vertex only indicating its position and additional information defining the rotation. The atoms in the residues are generated on-the-fly on the GPU, exploiting the new graphics hardware geometry shader capabilities. Moreover, we represent the atoms by billboards instead of tessellated spheres. Our representation is then significantly faster and pixel precise. We demonstrate the usefulness of our new approach in the context of our collaborative bioinformatics project.\\\",\\\"Authors\\\":\\\"Lampe, O.D.;Viola, I.;Reuter, N.;Hauser, H.\\\",\\\"Clusters\\\":\\\"HardwareAccellerationAndComputationGeneral;MolecularScienceAndChemistry\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70517\\\",\\\"Keywords\\\":\\\"molecular visualization;hardware acceleration;protein dynamics\\\",\\\"Keywords_Processed\\\":\\\"molecular visualization;protein dynamic;hardware acceleration\\\",\\\"Title\\\":\\\"Two-Level Approach to Efficient Visualization of Protein Dynamics\\\"},\\\"837\\\":{\\\"Abstract\\\":\\\"Direct volume rendering has proved to be an effective visualization method for medical data sets and has reached wide-spread clinical use. The diagnostic exploration, in essence, corresponds to a tissue classification task, which is often complex and time-consuming. Moreover, a major problem is the lack of information on the uncertainty of the classification, which can have dramatic consequences for the diagnosis. In this paper this problem is addressed by proposing animation methods to convey uncertainty in the rendering. The foundation is a probabilistic Transfer Function model which allows for direct user interaction with the classification. The rendering is animated by sampling the probability domain over time, which results in varying appearance for uncertain regions. A particularly promising application of this technique is a \\\\\\\"sensitivity lens\\\\\\\" applied to focus regions in the data set. The methods have been evaluated by radiologists in a study simulating the clinical task of stenosis assessment, in which the animation technique is shown to outperform traditional rendering in terms of assessment accuracy.\\\",\\\"Authors\\\":\\\"Lundstrom, C.;Ljung, P.;Persson, A.;Ynnerman, A.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;MachineLearningAndStatistics;UncertaintyTechniquesAndVisualization;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70518\\\",\\\"Keywords\\\":\\\"volume rendering;medical visualization;uncertainty;transfer function;probability\\\",\\\"Keywords_Processed\\\":\\\"volume render;uncertainty;transfer function;probability;medical visualization\\\",\\\"Title\\\":\\\"Uncertainty Visualization in Medical Volume Rendering Using Probabilistic Animation\\\"},\\\"838\\\":{\\\"Abstract\\\":\\\"Our ability to generate ever-larger, increasingly-complex data, has established the need for scalable methods that identify, and provide insight into, important variable trends and interactions. Query-driven methods are among the small subset of techniques that are able to address both large and highly complex datasets. This paper presents a new method that increases the utility of query-driven techniques by visually conveying statistical information about the trends that exist between variables in a query. In this method, correlation fields, created between pairs of variables, are used with the cumulative distribution functions of variables expressed in a users query. This integrated use of cumulative distribution functions and correlation fields visually reveals, with respect to the solution space of the query, statistically important interactions between any three variables, and allows for trends between these variables to be readily identified. We demonstrate our method by analyzing interactions between variables in two flame-front simulations.\\\",\\\"Authors\\\":\\\"Gosink, L.;Anderson, J.C.;Wes Bethel, E.;Joy, K.I.\\\",\\\"Clusters\\\":\\\"MultidimensionalMultivariateMultifieldDataAndTechniques;QueriesAndSearch\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70519\\\",\\\"Keywords\\\":\\\"multivariate data;query-driven visualization\\\",\\\"Keywords_Processed\\\":\\\"multivariate datum;query drive visualization\\\",\\\"Title\\\":\\\"Variable Interactions in Query-Driven Visualization\\\"},\\\"839\\\":{\\\"Abstract\\\":\\\"Physics-based flow visualization techniques seek to mimic laboratory flow visualization methods with virtual analogues. In this work we describe the rendering of a virtual rheoscopic fluid to produce images with results strikingly similar to laboratory experiments with real-world rheoscopic fluids using products such as Kalliroscope. These fluid additives consist of microscopic, anisotropic particles which, when suspended in the flow, align with both the flow velocity and the local shear to produce high-quality depictions of complex flow structures. Our virtual rheoscopic fluid is produced by defining a closed-form formula for the orientation of shear layers in the flow and using this orientation to volume render the flow as a material with anisotropic reflectance and transparency. Examples are presented for natural convection, thermocapillary convection, and Taylor-Couette flow simulations. The latter agree well with photographs of experimental results of Taylor-Couette flows from the literature.\\\",\\\"Authors\\\":\\\"Barth, W.L.;Burns, C.A.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70610\\\",\\\"Keywords\\\":\\\"flow visualization;rheoscopic fluids\\\",\\\"Keywords_Processed\\\":\\\"rheoscopic fluid;flow visualization\\\",\\\"Title\\\":\\\"Virtual Rheoscopic Fluids for Flow Visualization\\\"},\\\"840\\\":{\\\"Abstract\\\":\\\"We present a comprehensive system for weather data visualization. Weather data are multivariate and contain vector fields formed by wind speed and direction. Several well-established visualization techniques such as parallel coordinates and polar systems are integrated into our system. We also develop various novel methods, including circular pixel bar charts embedded into polar systems, enhanced parallel coordinates with S-shape axis, and weighted complete graphs. Our system was used to analyze the air pollution problem in Hong Kong and some interesting patterns have been found.\\\",\\\"Authors\\\":\\\"Huamin Qu;Wing-Yi Chan;Anbang Xu;Kai-Lun Chung;Kai-Hon Lau;Ping Guo\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;GeometricModeling;ParallelCoordinates;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70523\\\",\\\"Keywords\\\":\\\"air pollution;polar system;visual analytics;weather visualization;parallel coordinates\\\",\\\"Keywords_Processed\\\":\\\"parallel coordinate;polar system;weather visualization;visual analytic;air pollution\\\",\\\"Title\\\":\\\"Visual Analysis of the Air Pollution Problem in Hong Kong\\\"},\\\"841\\\":{\\\"Abstract\\\":\\\"A current research topic in molecular thermodynamics is the condensation of vapor to liquid and the investigation of this process at the molecular level. Condensation is found in many physical phenomena, e.g. the formation of atmospheric clouds or the processes inside steam turbines, where a detailed knowledge of the dynamics of condensation processes will help to optimize energy efficiency and avoid problems with droplets of macroscopic size. The key properties of these processes are the nucleation rate and the critical cluster size. For the calculation of these properties it is essential to make use of a meaningful definition of molecular clusters, which currently is a not completely resolved issue. In this paper a framework capable of interactively visualizing molecular datasets of such nucleation simulations is presented, with an emphasis on the detected molecular clusters. To check the quality of the results of the cluster detection, our framework introduces the concept of flow groups to highlight potential cluster evolution over time which is not detected by the employed algorithm. To confirm the findings of the visual analysis, we coupled the rendering view with a schematic view of the clusters' evolution. This allows to rapidly assess the quality of the molecular cluster detection algorithm and to identify locations in the simulation data in space as well as in time where the cluster detection fails. Thus, thermodynamics researchers can eliminate weaknesses in their cluster detection algorithms. Several examples for the effective and efficient usage of our tool are presented.\\\",\\\"Authors\\\":\\\"Grottel, S.;Reina, G.;Vrabec, J.;Ertl, T.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;GlyphsGlyphBasedTechniques;GraphNetworkDataAndTechniques;MolecularScienceAndChemistry;OutOfCoreProcessing;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70614\\\",\\\"Keywords\\\":\\\"evolution graph view;glyph-based visualization;time-dependent scattered data;out-of-core techniques;molecular dynamics visualization;cluster detection analysis\\\",\\\"Keywords_Processed\\\":\\\"cluster detection analysis;evolution graph view;glyph base visualization;out of core technique;time dependent scatter datum;molecular dynamic visualization\\\",\\\"Title\\\":\\\"Visual Verification and Analysis of Cluster Detection for Molecular Dynamics\\\"},\\\"842\\\":{\\\"Abstract\\\":\\\"We describe our visualization process for a particle-based simulation of the formation of the first stars and their impact on cosmic history. The dataset consists of several hundred time-steps of point simulation data, with each time-step containing approximately two million point particles. For each time-step, we interpolate the point data onto a regular grid using a method taken from the radiance estimate of photon mapping [21]. We import the resulting regular grid representation into ParaView [24], with which we extract isosurfaces across multiple variables. Our images provide insights into the evolution of the early universe, tracing the cosmic transition from an initially homogeneous state to one of increasing complexity. Specifically, our visualizations capture the build-up of regions of ionized gas around the first stars, their evolution, and their complex interactions with the surrounding matter. These observations will guide the upcoming James Webb Space Telescope, the key astronomy mission of the next decade.\\\",\\\"Authors\\\":\\\"Navratil, P.A.;Johnson, J.L.;Bromm, V.\\\",\\\"Clusters\\\":\\\"AstronomyAstrophysics;Interpolation;IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70526\\\",\\\"Keywords\\\":\\\"isosurface;astronomy;interpolation;cosmology\\\",\\\"Keywords_Processed\\\":\\\"astronomy;interpolation;isosurface;cosmology\\\",\\\"Title\\\":\\\"Visualization of Cosmological Particle-Based Datasets\\\"},\\\"843\\\":{\\\"Abstract\\\":\\\"Visualization of uncertainty or error in astrophysical data is seldom available in simulations of astronomical phenomena, and yet almost all rendered attributes possess some degree of uncertainty due to observational error. Uncertainties associated with spatial location typically vary significantly with scale and thus introduce further complexity in the interpretation of a given visualization. This paper introduces effective techniques for visualizing uncertainty in large-scale virtual astrophysical environments. Building upon our previous transparently scalable visualization architecture, we develop tools that enhance the perception and comprehension of uncertainty across wide scale ranges. Our methods include a unified color-coding scheme for representing log-scale distances and percentage errors, an ellipsoid model to represent positional uncertainty, an ellipsoid envelope model to expose trajectory uncertainty, and a magic-glass design supporting the selection of ranges of log-scale distance and uncertainty parameters, as well as an overview mode and a scalable WIM tool for exposing the magnitudes of spatial context and uncertainty.\\\",\\\"Authors\\\":\\\"Hongwei Li;Chi-Wing Fu;Yinggang Li;Hanson, A.J.\\\",\\\"Clusters\\\":\\\"AstronomyAstrophysics;LargeScaleDataAndScalability;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70530\\\",\\\"Keywords\\\":\\\"uncertainty visualization;interstellar data;astronomy;large spatial scale\\\",\\\"Keywords_Processed\\\":\\\"large spatial scale;uncertainty visualization;astronomy;interstellar datum\\\",\\\"Title\\\":\\\"Visualizing Large-Scale Uncertainty in Astrophysical Data\\\"},\\\"844\\\":{\\\"Abstract\\\":\\\"Diffusion tensor imaging (DTI) of the human brain, coupled with tractography techniques, enable the extraction of large- collections of three-dimensional tract pathways per subject. These pathways and pathway bundles represent the connectivity between different brain regions and are critical for the understanding of brain related diseases. A flexible and efficient GPU-based rendering technique for DTI tractography data is presented that addresses common performance bottlenecks and image-quality issues, allowing interactive render rates to be achieved on commodity hardware. An occlusion query-based pathway LoD management system for streamlines/streamtubes/tuboids is introduced that optimizes input geometry, vertex processing, and fragment processing loads, and helps reduce overdraw. The tuboid, a fully-shaded streamtube impostor constructed entirely on the GPU from streamline vertices, is also introduced. Unlike full streamtubes and other impostor constructs, tuboids require little to no preprocessing or extra space over the original streamline data. The supported fragment processing levels of detail range from texture-based draft shading to full raycast normal computation, Phong shading, environment mapping, and curvature-correct text labeling. The presented text labeling technique for tuboids provides adaptive, aesthetically pleasing labels that appear attached to the surface of the tubes. Furthermore, an occlusion query aggregating and scheduling scheme for tuboids is described that reduces the query overhead. Results for a tractography dataset are presented, and demonstrate that LoD-managed tuboids offer benefits over traditional streamtubes both in performance and appearance.\\\",\\\"Authors\\\":\\\"Petrovic, V.;Fallon, J.;Kuester, F.\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;NeurosciencesAndBrainVisualization;StreamlinesPathlinesStreaklines;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2007.70532\\\",\\\"Keywords\\\":\\\"neuronal pathways;streamtubes;tuboids;interactive gpu-centric rendering\\\",\\\"Keywords_Processed\\\":\\\"neuronal pathway;interactive gpu centric rendering;tuboid;streamtube\\\",\\\"Title\\\":\\\"Visualizing Whole-Brain DTI Tractography with GPU-based Tuboids and LoD Management\\\"},\\\"845\\\":{\\\"Abstract\\\":\\\"In this paper, we present a system to analyze activities and detect anomalies in a surveillance application, which exploits the intuition and experience of security and surveillance experts through an easy- to-use visual feedback loop. The multi-scale and location specific nature of behavior patterns in space and time is captured using a wavelet-based feature descriptor. The system learns the fundamental descriptions of the behavior patterns in a semi-supervised fashion by the higher order singular value decomposition of the space described by the training data. This training process is guided and refined by the users in an intuitive fashion. Anomalies are detected by projecting the test data into this multi-linear space and are visualized by the system to direct the attention of the user to potential problem spots. We tested our system on real-world surveillance data, and it satisfied the security concerns of the environment.\\\",\\\"Authors\\\":\\\"Janoos, F.;Singh, S.;Irfanoglu, O.;Machiraju, R.;Parent, R.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;DimensionalityReduction;EventsTrendsOutlierDetectionAnalysisAndVisualization;NumericalMethodsMathematics;PrivacySecurityIntelligenceAnalysis\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4388990\\\",\\\"Keywords\\\":\\\"higher-order singular value decomposition;surveillance;wavelets;anomaly detection;trajectory\\\",\\\"Keywords_Processed\\\":\\\"trajectory;high order singular value decomposition;surveillance;wavelet;anomaly detection\\\",\\\"Title\\\":\\\"Activity Analysis Using Spatio-Temporal Trajectory Volumes in Surveillance Applications\\\"},\\\"846\\\":{\\\"Abstract\\\":\\\"An architecture for visualizing information extracted from text documents is proposed. In conformance with this architecture, a toolkit, FemaRepViz, has been implemented to extract and visualize temporal, geospatial, and summarized information from FEMA national update reports. Preliminary tests have shown satisfactory accuracy for FEMARepViz. A central component of the architecture is an entity extractor that extracts named entities like person names, location names, temporal references, etc. FEMARepViz is based on FactXtractor, an entity-extractor that works on text documents. The information extracted using FactXtractor is processed using GeoTagger, a geographical name disambiguation tool based on a novel clustering-based disambiguation algorithm. To extract relationships among entities, we propose a machine-learning based algorithm that uses a novel stripped dependency tree kernel. We illustrate and evaluate the usefulness of our system on the FEMA National Situation Updates. Daily reports are fetched by FEMARepViz from the FEMA website, segmented into coherent sections and each section is classified into one of several known incident types. We use concept Vista, Google maps and Google earth to visualize the events extracted from the text reports and allow the user to interactively filter the topics, locations, and time-periods of interest to create a visual analytics toolkit that is useful for rapid analysis of events reported in a large set of text documents.\\\",\\\"Authors\\\":\\\"Chi-Chun Pan;Mitra, P.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;KnowledgeDiscovery;SpatiotemporalDataAndTechniques;TextDocumentTopicAnalysisDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4388991\\\",\\\"Keywords\\\":\\\"text processing;knowledge discovery;visual analytics;geospatial analytics;geo-temporal visualization\\\",\\\"Keywords_Processed\\\":\\\"geospatial analytic;text processing;knowledge discovery;visual analytic;geo temporal visualization\\\",\\\"Title\\\":\\\"FemaRepViz: Automatic Extraction and Geo-Temporal Visualization of FEMA National Situation Updates\\\"},\\\"847\\\":{\\\"Abstract\\\":\\\"A story is a powerful abstraction used by intelligence analysts to conceptualize threats and understand patterns as part of the analytical process. This paper demonstrates a system that detects geo-temporal patterns and integrates story narration to increase analytic sense-making cohesion in GeoTime. The GeoTime geo-temporal event visualization tool was augmented with a story system that uses narratives, hypertext linked visualizations, visual annotations, and pattern detection to create an environment for analytic exploration and communication, thereby assisting the analyst in identifying, extracting, arranging and presenting stories within the data The story system lets analysts operate at the story level with higher-level abstractions of data, such as behaviors and events, while staying connected to the evidence. The story system was developed and evaluated in collaboration with analysts.\\\",\\\"Authors\\\":\\\"Eccles, R.;Kapler, T.;Harper, R.;Wright, W.\\\",\\\"Clusters\\\":\\\"Cognition;HumanComputerInteractionHumanFactors;Storytelling;VisualPatternFeatureDetectionAndTracking\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4388992\\\",\\\"Keywords\\\":\\\"pattern detection;sensemaking;visual analytics;narrative;story making;storytelling;human-information interaction\\\",\\\"Keywords_Processed\\\":\\\"storytelle;human information interaction;pattern detection;narrative;sensemake;story make;visual analytic\\\",\\\"Title\\\":\\\"Stories in GeoTime\\\"},\\\"848\\\":{\\\"Abstract\\\":\\\"Using mobile devices for visualization provides a ubiquitous environment for accessing information and effective decision making. These visualizations are critical in satisfying the knowledge needs of operators in areas as diverse as education, business, law enforcement, protective services, medical services, scientific discovery, and homeland security. In this paper, we present an efficient and interactive mobile visual analytic system for increased situational awareness and decision making in emergency response and training situations. Our system provides visual analytics with locational scene data within a simple interface tailored to mobile device capabilities. In particular, we focus on processing and displaying sensor network data for first responders. To verify our system, we have used simulated data of The Station nightclub fire evacuation.\\\",\\\"Authors\\\":\\\"SungYe Kim;Yun Jang;Mellema, A.;Ebert, D.S.;Collins, T.\\\",\\\"Clusters\\\":\\\"EmergencyDisasterManagement;SmallMobileUbiquitousDevicesDisplays;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4388994\\\",\\\"Keywords\\\":\\\"emergency response;visual analytics;mobile visualization\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;mobile visualization;emergency response\\\",\\\"Title\\\":\\\"Visual Analytics on Mobile Devices for Emergency Response\\\"},\\\"849\\\":{\\\"Abstract\\\":\\\"Application of the ideas of visual analytics is a promising approach to supporting decision making, in particular, where the problems have geographic (or spatial) and temporal aspects. Visual analytics may be especially helpful in time-critical applications, which pose hard challenges to decision support. We have designed a suite of tools to support transportation-planning tasks such as emergency evacuation of people from a disaster- affected area. The suite combines a tool for automated scheduling based on a genetic algorithm with visual analytics techniques allowing the user to evaluate tool results and direct its work. A transportation schedule, which is generated by the tool, is a complex construct involving geographical space, time, and heterogeneous objects (people and vehicles) with states and positions varying in time. We apply task-analytical approach to design techniques that could effectively support a human planner in the analysis of this complex information H. 1.2 [User/Machine Systems]: Human information processing - Visual Analytics; 1.6.9 [Visualization]: information visualization.\\\",\\\"Authors\\\":\\\"Andrienko, G.;Andrienko, N.;Bartling, U.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;MultipleLinkedCoordinatedViews;TasksTaskRequirementsAnalysis;Traffic\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4388995\\\",\\\"Keywords\\\":\\\"task-centered design;vehicle scheduling;transportation planning;coordinated & multiple views;geovisualization\\\",\\\"Keywords_Processed\\\":\\\"transportation planning;vehicle scheduling;task center design;geovisualization;coordinate multiple view\\\",\\\"Title\\\":\\\"Visual Analytics Approach to User-Controlled Evacuation Scheduling\\\"},\\\"850\\\":{\\\"Abstract\\\":\\\"We have developed a Web 2.0 thin client visualization framework called GeoBoosttrade. Our framework focuses on geospatial visualization and using scalable vector graphics (SVG), AJAX, RSS and GeoRSS we have built a complete thin client component set. Our component set provides a rich user experience that is completely browser based. It includes maps, standard business charts, graphs, and time-oriented components. The components are live, interactive, linked, and support real time collaboration.\\\",\\\"Authors\\\":\\\"Eick, S.G.;Eick, M.A.;Fugitt, J.;Horst, B.;Khailo, M.;Lankenau, R.A.\\\",\\\"Clusters\\\":\\\"InternetWebVisualizationForTheMasses;MultipleLinkedCoordinatedViews;ProgrammingAlgorithmsAndDataStructures;VisualDesignDesignGuidelines\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4388996\\\",\\\"Keywords\\\":\\\"web 2.0;javascript;linked view visual analytics;svg;visualization components\\\",\\\"Keywords_Processed\\\":\\\"link view visual analytic;web;visualization component;svg;javascript\\\",\\\"Title\\\":\\\"Thin Client Visualization\\\"},\\\"851\\\":{\\\"Abstract\\\":\\\"This paper introduces a new Visual Analysis tool named IMAS (Interactive Multigenomic Analysis System), which combines common analysis tools such as Glimmer, BLAST, and Clustal-W into a unified Visual Analytic framework. IMAS displays the primary DNA sequence being analyzed by the biologist in a highly interactive, zoomable visual display. The user may analyze the sequence in a number of ways, and visualize these analyses in a coherent, sequence aligned form, with all related analysis products grouped together. This enables the user to rapidly perform analyses of DNA sequences without the need for tedious and error-prone cutting and pasting of sequence data from text files to and from web-based databases and data analysis services, as is now common practice.\\\",\\\"Authors\\\":\\\"Shaw, C.;Dasch, G.A.;Eremeeva, M.E.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4388997\\\",\\\"Keywords\\\":\\\"visual analytics;bioinformatics\\\",\\\"Keywords_Processed\\\":\\\"bioinformatic;visual analytic\\\",\\\"Title\\\":\\\"IMAS: The Interactive Multigenomic Analysis System\\\"},\\\"852\\\":{\\\"Abstract\\\":\\\"Designing a visualization system capable of processing, managing, and presenting massive data sets while maximizing the user's situational awareness (SA) is a challenging, but important, research question in visual analytics. Traditional data management and interactive retrieval approaches have often focused on solving the data overload problem at the expense of the user's SA. This paper discusses various data management strategies and the strengths and limitations of each approach in providing the user with SA. A new data management strategy, coined Smart Aggregation, is presented as a powerful approach to overcome the challenges of both massive data sets and maintaining SA. By combining automatic data aggregation with user-defined controls on what, how, and when data should be aggregated, we present a visualization system that can handle massive amounts of data while affording the user with the best possible SA. This approach ensures that a system is always usable in terms of both system resources and human perceptual resources. We have implemented our Smart Aggregation approach in a visual analytics system called VIAssist (Visual Assistant for Information Assurance Analysis) to facilitate exploration, discovery, and SA in the domain of Information Assurance.\\\",\\\"Authors\\\":\\\"Tesone, D.R.;Goodall, J.R.\\\",\\\"Clusters\\\":\\\"Cognition;DataAcquisitionAndManagement;DataClusteringAndAggregation;DatabasesAndDataMining;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4388998\\\",\\\"Keywords\\\":\\\"information visualization;situation awareness;data retrieval;visual analytics;data management;smart aggregation\\\",\\\"Keywords_Processed\\\":\\\"information visualization;smart aggregation;visual analytic;situation awareness;datum retrieval;data management\\\",\\\"Title\\\":\\\"Balancing Interactive Data Management of Massive Data with Situational Awareness through Smart Aggregation\\\"},\\\"853\\\":{\\\"Abstract\\\":\\\"Cluster analysis (CA) is a powerful strategy for the exploration of high-dimensional data in the absence of a-priori hypotheses or data classification models, and the results of CA can then be used to form such models. But even though formal models and classification rules may not exist in these data exploration scenarios, domain scientists and experts generally have a vast amount of non-compiled knowledge and intuition that they can bring to bear in this effort. In CA, there are various popular mechanisms to generate the clusters, however, the results from their non- supervised deployment rarely fully agree with this expert knowledge and intuition. To this end, our paper describes a comprehensive and intuitive framework to aid scientists in the derivation of classification hierarchies in CA, using k-means as the overall clustering engine, but allowing them to tune its parameters interactively based on a non-distorted compact visual presentation of the inherent characteristics of the data in high- dimensional space. These include cluster geometry, composition, spatial relations to neighbors, and others. In essence, we provide all the tools necessary for a high-dimensional activity we call cluster sculpting, and the evolving hierarchy can then be viewed in a space-efficient radial dendrogram. We demonstrate our system in the context of the mining and classification of a large collection of millions of data items of aerosol mass spectra, but our framework readily applies to any high-dimensional CA scenario.\\\",\\\"Authors\\\":\\\"Eun Ju Nam;Han, Y.;Mueller, K.;Zelenyuk, A.;Imre, D.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;EarthSpaceAndEnvironmentalSciences;MultidimensionalMultivariateMultifieldDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4388999\\\",\\\"Keywords\\\":\\\"visualization in earth/space/ and environmental science;high-dimensional data;visual data mining;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;high dimensional datum;visualization in earth space and environmental science;visual datum mining\\\",\\\"Title\\\":\\\"ClusterSculptor: A Visual Analytics Tool for High-Dimensional Data\\\"},\\\"854\\\":{\\\"Abstract\\\":\\\"Visualization systems traditionally focus on graphical representation of information. They tend not to provide integrated analytical services that could aid users in tackling complex knowledge discovery tasks. Users' exploration in such environments is usually impeded due to several problems: 1) valuable information is hard to discover when too much data is visualized on the screen; 2) Users have to manage and organize their discoveries off line, because no systematic discovery management mechanism exists; 3) their discoveries based on visual exploration alone may lack accuracy; 4) and they have no convenient access to the important knowledge learned by other users. To tackle these problems, it has been recognized that analytical tools must be introduced into visualization systems. In this paper, we present a novel analysis-guided exploration system, called the nugget management system (NMS). It leverages the collaborative effort of human comprehensibility and machine computations to facilitate users' visual exploration processes. Specifically, NMS first extracts the valuable information (nuggets) hidden in datasets based on the interests of users. Given that similar nuggets may be re-discovered by different users, NMS consolidates the nugget candidate set by clustering based on their semantic similarity. To solve the problem of inaccurate discoveries, localized data mining techniques are applied to refine the nuggets to best represent the captured patterns in datasets. Lastly, the resulting well-organized nugget pool is used to guide users' exploration. To evaluate the effectiveness of NMS, we integrated NMS into Xmd- vTool, a freeware multivariate visualization system. User studies were performed to compare the users' efficiency and accuracy in finishing tasks on real datasets, with and without the help of NMS. Our user studies confirmed the effectiveness of NMS.\\\",\\\"Authors\\\":\\\"Di Yang;Rundensteiner, E.A.;Ward, M.O.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;KnowledgeDiscovery;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4389000\\\",\\\"Keywords\\\":\\\"analysis guided exploration;discovery management;visual knowledge discovery;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;analysis guide exploration;discovery management;visual knowledge discovery\\\",\\\"Title\\\":\\\"Analysis Guided Visual Exploration of Multivariate Data\\\"},\\\"855\\\":{\\\"Abstract\\\":\\\"Visualizations of large multi-dimensional data sets, occurring in scientific and commercial applications, often reveal interesting local patterns. Analysts want to identify the causes and impacts of these interesting areas, and they also want to search for similar patterns occurring elsewhere in the data set. In this paper we introduce the Intelligent Visual Analytics Query (IVQuery) concept that combines visual interaction with automated analytical methods to support analysts in discovering the special properties and relations of identified patterns. The idea of IVQuery is to interactively select focus areas in the visualization. Then, according to the characteristics of the selected areas, such as the data dimensions and records, IVQuery employs analytical methods to identify the relationships to other portions of the data set. Finally, IVQuery generates visual representations for analysts to view and refine the results. IVQuery has been applied successfully to different real-world data sets, such as data warehouse performance, product sales, and sever performance analysis, and demonstrates the benefits of this technique over traditional filtering and zooming techniques. The visual analytics query technique can be used with many different types of visual representation. In this paper we show how to use IVQuery with parallel coordinates, visual maps, and scatter plots.\\\",\\\"Authors\\\":\\\"Hao, M.C.;Dayal, U.;Keim, D.A.;Morent, D.;Schneidewind, J.\\\",\\\"Clusters\\\":\\\"ComparisonComparativeVisualizationAndSimilarity;QueriesAndSearch\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4389001\\\",\\\"Keywords\\\":\\\"similarity queries;visual analytics query;interactive queries\\\",\\\"Keywords_Processed\\\":\\\"similarity query;visual analytic query;interactive query\\\",\\\"Title\\\":\\\"Intelligent Visual Analytics Queries\\\"},\\\"856\\\":{\\\"Abstract\\\":\\\"The task of building effective representations to visualize and explore collections with moderate to large number of documents is hard. It depends on the evaluation of some distance measure among texts and also on the representation of such relationships in bi- dimensional spaces. In this paper we introduce an alternative approach for building visual maps of documents based on their content similarity, through reconstruction of phylogenetic trees. The tree is capable of representing relationships that allows the user to quickly recover information detected by the similarity metric. For a variety of text collections of different natures we show that we can achieve improved exploration capability and more clear visualization of relationships amongst documents.\\\",\\\"Authors\\\":\\\"Cuadros, A.M.;Paulovich, F.V.;Minghim, R.;Telles, G.P.\\\",\\\"Clusters\\\":\\\"HierarchicalTreeDataAndTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4389002\\\",\\\"Keywords\\\":\\\"phylogenetic trees;text analytics;document visualization;multi-dimensional visualization;document analysis\\\",\\\"Keywords_Processed\\\":\\\"document visualization;multi dimensional visualization;document analysis;text analytic;phylogenetic tree\\\",\\\"Title\\\":\\\"Point Placement by Phylogenetic Trees and its Application to Visual Analysis of Document Collections\\\"},\\\"857\\\":{\\\"Abstract\\\":\\\"In this paper, we have developed a novel framework to enable more effective investigation of large-scale news video database via knowledge visualization. To relieve users from the burdensome exploration of well-known and uninteresting knowledge of news reports, a novel interestingness measurement for video news reports is presented to enable users to find news stories of interest at first glance and capture the relevant knowledge in large-scale video news databases efficiently. Our framework takes advantage of both automatic semantic video analysis and human intelligence by integrating with visualization techniques on semantic video retrieval systems. Our techniques on intelligent news video analysis and knowledge discovery have the capacity to enable more effective visualization and exploration of large-scale news video collections. In addition, news video visualization and exploration can provide valuable feedback to improve our techniques for intelligent news video analysis and knowledge discovery.\\\",\\\"Authors\\\":\\\"Hangzai Luo;Jianping Fan;Jing Yang;Ribarsky, W.;Satoh, S.\\\",\\\"Clusters\\\":\\\"KnowledgeDiscovery;MultimediaImageVideoMusic;VisualKnowledgeRepresentationAndExternalization\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4389003\\\",\\\"Keywords\\\":\\\"semantic video classification;knowledge visualization;knowledge discovery\\\",\\\"Keywords_Processed\\\":\\\"knowledge discovery;semantic video classification;knowledge visualization\\\",\\\"Title\\\":\\\"Analyzing Large-Scale News Video Databases to Support Knowledge Visualization and Intuitive Retrieval\\\"},\\\"858\\\":{\\\"Abstract\\\":\\\"In computer-based literary analysis different types of features are used to characterize a text. Usually, only a single feature value or vector is calculated for the whole text. In this paper, we combine automatic literature analysis methods with an effective visualization technique to analyze the behavior of the feature values across the text. For an interactive visual analysis, we calculate a sequence of feature values per text and present them to the user as a characteristic fingerprint. The feature values may be calculated on different hierarchy levels, allowing the analysis to be done on different resolution levels. A case study shows several successful applications of our new method to known literature problems and demonstrates the advantage of our new visual literature fingerprinting.\\\",\\\"Authors\\\":\\\"Keim, D.A.;Oelke, D.\\\",\\\"Clusters\\\":\\\"TextDocumentTopicAnalysisDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4389004\\\",\\\"Keywords\\\":\\\"visual literature analysis;literature fingerprinting;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;visual literature analysis;literature fingerprint\\\",\\\"Title\\\":\\\"Literature Fingerprinting: A New Method for Visual Literary Analysis\\\"},\\\"859\\\":{\\\"Abstract\\\":\\\"In this paper, we introduce NewsLab, an exploratory visualization approach for the analysis of large scale broadcast news video collections containing many thousands of news stories over extended periods of time. A river metaphor is used to depict the thematic changes of the news over time. An interactive lens metaphor allows the playback of fine-grained video segments selected through the river overview. Multi-resolution navigation is supported via a hierarchical time structure as well as a hierarchical theme structure. Themes can be explored hierarchically according to their thematic structure, or in an unstructured fashion using various ranking criteria. A rich set of interactions such as filtering, drill-down/roll-up navigation, history animation, and keyword based search are also provided. Our case studies show how this set of tools can be used to find emerging topics in the news, compare different broadcasters, or mine the news for topics of interest.\\\",\\\"Authors\\\":\\\"Ghoniem, M.;Dongning Luo;Jing Yang;Ribarsky, W.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;ComparisonComparativeVisualizationAndSimilarity;DataClusteringAndAggregation;LargeScaleDataAndScalability;MultimediaImageVideoMusic;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4389005\\\",\\\"Keywords\\\":\\\"clustering;large data exploration;time filtering;comparative analysis;broadcast video analysis;animation\\\",\\\"Keywords_Processed\\\":\\\"comparative analysis;animation;time filter;clustering;large datum exploration;broadcast video analysis\\\",\\\"Title\\\":\\\"NewsLab: Exploratory Broadcast News Video Analysis\\\"},\\\"860\\\":{\\\"Abstract\\\":\\\"Investigative analysts who work with collections of text documents connect embedded threads of evidence in order to formulate hypotheses about plans and activities of potential interest. As the number of documents and the corresponding number of concepts and entities within the documents grow larger, sense-making processes become more and more difficult for the analysts. We have developed a visual analytic system called Jigsaw that represents documents and their entities visually in order to help analysts examine reports more efficiently and develop theories about potential actions more quickly. Jigsaw provides multiple coordinated views of document entities with a special emphasis on visually illustrating connections between entities across the different documents.\\\",\\\"Authors\\\":\\\"Stasko, J.;Gorg, C.;Zhicheng Liu;Singhal, K.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;MultipleLinkedCoordinatedViews;PrivacySecurityIntelligenceAnalysis;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4389006\\\",\\\"Keywords\\\":\\\"information visualization;intelligence analysis;multiple views;investigative analysis;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"investigative analysis;intelligence analysis;information visualization;visual analytic;multiple view\\\",\\\"Title\\\":\\\"Jigsaw: Supporting Investigative Analysis through Interactive Visualization\\\"},\\\"861\\\":{\\\"Abstract\\\":\\\"This article presents SpiralView, a visualization tool for helping system administrators to assess network policies. The tool is meant to be a complementary support to the routine activity of network monitoring, enabling a retrospective view on the alarms generated during and extended period of time. The tool permits to reason about how alarms distribute over time and how they correlate with network resources (e.g., users, IPs, applications, etc.), supporting the analysts in understanding how the network evolves and thus in devising new security policies for the future. The spiral visualization plots alarms in time, and, coupled with interactive bar charts and a users/applications graph view, is used to present network data and perform queries. The user is able to segment the data in meaningful subsets, zoom on specific related information, and inspect for relationships between alarms, users, and applications. In designing the visualizations and their interaction, and through tests with security experts, several ameliorations over the standard techniques have been provided.\\\",\\\"Authors\\\":\\\"Bertini, E.;Hertzog, P.;Lalanne, D.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;ComputerNetworksNetworkSecurity;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4389007\\\",\\\"Keywords\\\":\\\"intrusion detection;data exploration;network security;visualization\\\",\\\"Keywords_Processed\\\":\\\"visualization;network security;intrusion detection;datum exploration\\\",\\\"Title\\\":\\\"SpiralView: Towards Security Policies Assessment through Visual Correlation of Network Resources with Evolution of Alarms\\\"},\\\"862\\\":{\\\"Abstract\\\":\\\"Large-scale session log analysis typically includes statistical methods and detailed log examinations. While both methods have merits, statistical methods can miss previously unknown sub- populations in the data and detailed analyses may have selection biases. We therefore built Session Viewer, a visualization tool to facilitate and bridge between statistical and detailed analyses. Taking a multiple-coordinated view approach, Session Viewer shows multiple session populations at the Aggregate, Multiple, and Detail data levels to support different analysis styles. To bridge between the statistical and the detailed analysis levels, Session Viewer provides fluid traversal between data levels and side-by-side comparison at all data levels. We describe an analysis of a large-scale web usage study to demonstrate the use of Session Viewer, where we quantified the importance of grouping sessions based on task type.\\\",\\\"Authors\\\":\\\"Lam, H.;Russell, D.;Tang, D.;Munzner, T.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;InternetWebVisualizationForTheMasses;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4389008\\\",\\\"Keywords\\\":\\\"information visualization;visual exploratory data analysis;web session log analysis\\\",\\\"Keywords_Processed\\\":\\\"web session log analysis;information visualization;visual exploratory datum analysis\\\",\\\"Title\\\":\\\"Session Viewer: Visual Exploratory Analysis of Web Session Logs\\\"},\\\"863\\\":{\\\"Abstract\\\":\\\"Large financial institutions such as Bank of America handle hundreds of thousands of wire transactions per day. Although most transactions are legitimate, these institutions have legal and financial obligations in discovering those that are suspicious. With the methods of fraudulent activities ever changing, searching on predefined patterns is often insufficient in detecting previously undiscovered methods. In this paper, we present a set of coordinated visualizations based on identifying specific keywords within the wire transactions. The different views used in our system depict relationships among keywords and accounts over time. Furthermore, we introduce a search-by-example technique which extracts accounts that show similar transaction patterns. In collaboration with the Anti-Money Laundering division at Bank of America, we demonstrate that using our tool, investigators are able to detect accounts and transactions that exhibit suspicious behaviors.\\\",\\\"Authors\\\":\\\"Chang, R.;Ghoniem, M.;Kosara, R.;Ribarsky, W.;Jing Yang;Suma, E.;Ziemkiewicz, C.;Kern, D.;Sudjianto, A.\\\",\\\"Clusters\\\":\\\"BusinessFinanceEconomyManufacturing;CategoricalDataAndTechniques;PrivacySecurityIntelligenceAnalysis\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4389009\\\",\\\"Keywords\\\":\\\"categorial and time-varying data;financial visualization;fraud detection\\\",\\\"Keywords_Processed\\\":\\\"financial visualization;categorial and time vary datum;fraud detection\\\",\\\"Title\\\":\\\"WireVis: Visualization of Categorical, Time-Varying Data From Financial Transactions\\\"},\\\"864\\\":{\\\"Abstract\\\":\\\"Wikipedia is a wiki-based encyclopedia that has become one of the most popular collaborative on-line knowledge systems. As in any large collaborative system, as Wikipedia has grown, conflicts and coordination costs have increased dramatically. Visual analytic tools provide a mechanism for addressing these issues by enabling users to more quickly and effectively make sense of the status of a collaborative environment. In this paper we describe a model for identifying patterns of conflicts in Wikipedia articles. The model relies on users' editing history and the relationships between user edits, especially revisions that void previous edits, known as \\\\\\\"reverts\\\\\\\". Based on this model, we constructed Revert Graph, a tool that visualizes the overall conflict patterns between groups of users. It enables visual analysis of opinion groups and rapid interactive exploration of those relationships via detail drill- downs. We present user patterns and case studies that show the effectiveness of these techniques, and discuss how they could generalize to other systems.\\\",\\\"Authors\\\":\\\"Suh, B.;Chi, E.H.;Pendleton, B.A.;Kittur, A.\\\",\\\"Clusters\\\":\\\"CollaborativeVisualization;GraphNetworkDataAndTechniques;InternetWebVisualizationForTheMasses;TasksTaskRequirementsAnalysis;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4389010\\\",\\\"Keywords\\\":\\\"wiki;revert;collaboration;visualization;user model;graph;wikipedia\\\",\\\"Keywords_Processed\\\":\\\"visualization;collaboration;graph;wiki;revert;wikipedia;user model\\\",\\\"Title\\\":\\\"Us vs. Them: Understanding Social Dynamics in Wikipedia with Revert Graph Visualizations\\\"},\\\"865\\\":{\\\"Abstract\\\":\\\"Information visualization leverages the human visual system to support the process of sensemaking, in which information is collected, organized, and analyzed to generate knowledge and inform action. Though most research to date assumes a single-user focus on perceptual and cognitive processes, in practice, sensemaking is often a social process involving parallelization of effort, discussion, and consensus building. This suggests that to fully support sensemaking, interactive visualization should also support social interaction. However, the most appropriate collaboration mechanisms for supporting this interaction are not immediately clear. In this article, we present design considerations for asynchronous collaboration in visual analysis environments, highlighting issues of work parallelization, communication, and social organization. These considerations provide a guide for the design and evaluation of collaborative visualization systems.\\\",\\\"Authors\\\":\\\"Heer, J.;Agrawala, M.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;CollaborativeVisualization;VisualDesignDesignGuidelines\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4389011\\\",\\\"Keywords\\\":\\\"computer-supported cooperative work;collaboration;visualization;analysis;design\\\",\\\"Keywords_Processed\\\":\\\"visualization;computer support cooperative work;collaboration;design;analysis\\\",\\\"Title\\\":\\\"Design Considerations for Collaborative Visual Analytics\\\"},\\\"866\\\":{\\\"Abstract\\\":\\\"Wikipedia is a large and rapidly growing Web-based collaborative authoring environment, where anyone on the Internet can create, modify, and delete pages about encyclopedic topics. A remarkable property of some Wikipedia pages is that they are written by up to thousands of authors who may have contradicting opinions. In this paper we show that a visual analysis of the \\\\\\\"who revises whom\\\\\\\"- network gives deep insight into controversies. We propose a set of analysis and visualization techniques that reveal the dominant authors of a page, the roles they play, and the alters they confront. Thereby we provide tools to understand how Wikipedia authors collaborate in the presence of controversy.\\\",\\\"Authors\\\":\\\"Brandes, U.;Lerner, J.\\\",\\\"Clusters\\\":\\\"InternetWebVisualizationForTheMasses;SocialNetworksAndSocialMedia;Storytelling\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4389012\\\",\\\"Keywords\\\":\\\"wikipedia;controversy;social network analysis\\\",\\\"Keywords_Processed\\\":\\\"social network analysis;controversy;wikipedia\\\",\\\"Title\\\":\\\"Visual Analysis of Controversy in User-generated Encyclopedias\\\"},\\\"867\\\":{\\\"Abstract\\\":\\\"Supporting visual analytics of multiple large-scale multidimensional datasets requires a high degree of interactivity and user control beyond the conventional challenges of visualizing such datasets. We present the DataMeadow, a visual canvas providing rich interaction for constructing visual queries using graphical set representations called DataRoses. A DataRose is essentially a starplot of selected columns in a dataset displayed as multivariate visualizations with dynamic query sliders integrated into each axis. The purpose of the DataMeadow is to allow users to create advanced visual queries by iteratively selecting and filtering into the multidimensional data. Furthermore, the canvas provides a clear history of the analysis that can be annotated to facilitate dissemination of analytical results to outsiders. Towards this end, the DataMeadow has a direct manipulation interface for selection, filtering, and creation of sets, subsets, and data dependencies using both simple and complex mouse gestures. We have evaluated our system using a qualitative expert review involving two researchers working in the area. Results from this review are favorable for our new method.\\\",\\\"Authors\\\":\\\"Elmqvist, N.;Stasko, J.;Tsigas, P.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;ChartsDiagramsPlots;MultidimensionalMultivariateMultifieldDataAndTechniques;ParallelCoordinates;QueriesAndSearch;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/VAST.2007.4389013\\\",\\\"Keywords\\\":\\\"iterative analysis;star plot;dynamic query;small multiples;visual analytics;multivariate data;parallel coordinates\\\",\\\"Keywords_Processed\\\":\\\"multivariate datum;parallel coordinate;star plot;dynamic query;visual analytic;small multiple;iterative analysis\\\",\\\"Title\\\":\\\"DataMeadow: A Visual Canvas for Analysis of Large-Scale Multivariate Data\\\"},\\\"868\\\":{\\\"Abstract\\\":\\\"We describe ASK-GraphView, a node-link-based graph visualization system that allows clustering and interactive navigation of large graphs, ranging in size up to 16 million edges. The system uses a scalable architecture and a series of increasingly sophisticated clustering algorithms to construct a hierarchy on an arbitrary, weighted undirected input graph. By lowering the interactivity requirements we can scale to substantially bigger graphs. The user is allowed to navigate this hierarchy in a top down manner by interactively expanding individual clusters. ASK-GraphView also provides facilities for filtering and coloring, annotation and cluster labeling\\\",\\\"Authors\\\":\\\"Abello, J.;van Ham, F.;Neeraj Krishnan\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;GraphNetworkDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.120\\\",\\\"Keywords\\\":\\\"information visualization;graph clustering;graph visualization\\\",\\\"Keywords_Processed\\\":\\\"graph clustering;graph visualization;information visualization\\\",\\\"Title\\\":\\\"ASK-graphView: a large scale graph visualization system\\\"},\\\"869\\\":{\\\"Abstract\\\":\\\"Social network analysis (SNA) has emerged as a powerful method for understanding the importance of relationships in networks. However, interactive exploration of networks is currently challenging because: (1) it is difficult to find patterns and comprehend the structure of networks with many nodes and links, and (2) current systems are often a medley of statistical methods and overwhelming visual output which leaves many analysts uncertain about how to explore in an orderly manner. This results in exploration that is largely opportunistic. Our contributions are techniques to help structural analysts understand social networks more effectively. We present SocialAction, a system that uses attribute ranking and coordinated views to help users systematically examine numerous SNA measures. Users can (1) flexibly iterate through visualizations of measures to gain an overview, filter nodes, and find outliers, (2) aggregate networks using link structure, find cohesive subgroups, and focus on communities of interest, and (3) untangle networks by viewing different link types separately, or find patterns across different link types using a matrix overview. For each operation, a stable node layout is maintained in the network visualization so users can make comparisons. SocialAction offers analysts a strategy beyond opportunism, as it provides systematic, yet flexible, techniques for exploring social networks\\\",\\\"Authors\\\":\\\"Perer, A.;Shneiderman, B.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;GraphNetworkDataAndTechniques;MultipleLinkedCoordinatedViews;Ranking;SocialNetworksAndSocialMedia\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.122\\\",\\\"Keywords\\\":\\\"exploratory data analysis;interactive graph visualization;attribute ranking;coordinated views;social networks\\\",\\\"Keywords_Processed\\\":\\\"attribute ranking;interactive graph visualization;social network;coordinated view;exploratory datum analysis\\\",\\\"Title\\\":\\\"Balancing Systematic and Flexible Exploration of Social Networks\\\"},\\\"870\\\":{\\\"Abstract\\\":\\\"Commonly known detail in context techniques for the two-dimensional Euclidean space enlarge details and shrink their context using mapping functions that introduce geometrical compression. This makes it difficult or even impossible to recognize shapes for large differences in magnification factors. In this paper we propose to use the complex logarithm and the complex root functions to show very small details even in very large contexts. These mappings are conformal, which means they only locally rotate and scale, thus keeping shapes intact and recognizable. They allow showing details that are orders of magnitude smaller than their surroundings in combination with their context in one seamless visualization. We address the utilization of this universal technique for the interaction with complex two-dimensional data considering the exploration of large graphs and other examples\\\",\\\"Authors\\\":\\\"Bottger, J.;Balzer, M.;Deussen, O.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;InteractionTechniquesGeneral;Interpolation;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.126\\\",\\\"Keywords\\\":\\\"conformal mapping;detail in context;analytic functions;complex logarithm;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;complex logarithm;detail in context;conformal mapping;analytic function\\\",\\\"Title\\\":\\\"Complex Logarithmic Views for Small Details in Large Contexts\\\"},\\\"871\\\":{\\\"Abstract\\\":\\\"We address the problem of filtering, selecting and placing labels on a dynamic map, which is characterized by continuous zooming and panning capabilities. This consists of two interrelated issues. The first is to avoid label popping and other artifacts that cause confusion and interrupt navigation, and the second is to label at interactive speed. In most formulations the static map labeling problem is NP-hard, and a fast approximation might have O(n log n) complexity. Even this is too slow during interaction, when the number of labels shown can be several orders of magnitude less than the number in the map. In this paper we introduce a set of desiderata for \\\\\\\"consistent\\\\\\\" dynamic map labeling, which has qualities desirable for navigation. We develop a new framework for dynamic labeling that achieves the desiderata and allows for fast interactive display by moving all of the selection and placement decisions into the preprocessing phase. This framework is general enough to accommodate a variety of selection and placement algorithms. It does not appear possible to achieve our desiderata using previous frameworks. Prior to this paper, there were no formal models of dynamic maps or of dynamic labels; our paper introduces both. We formulate a general optimization problem for dynamic map labeling and give a solution to a simple version of the problem. The simple version is based on label priorities and a versatile and intuitive class of dynamic label placements we call \\\\\\\"invariant point placements\\\\\\\". Despite these restrictions, our approach gives a useful and practical solution. Our implementation is incorporated into the G-Vis system which is a full-detail dynamic map of the continental USA. This demo is available through any browser\\\",\\\"Authors\\\":\\\"Been, K.;Daiches, E.;Yap, C.\\\",\\\"Clusters\\\":\\\"DataAcquisitionAndManagement;GeographyGeospatialVisCartographyTerrainVis;HumanComputerInteractionHumanFactors;Labeling;Maps;RealtimeProcessingRenderingAndVisualizationGeneral;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.136\\\",\\\"Keywords\\\":\\\"human-computer interface;preprocessing;label filtering;label consistency;geographic information systems;computational cartography;dynamic maps;realtime;label placement;human-computer interaction;map labeling;label selection\\\",\\\"Keywords_Processed\\\":\\\"realtime;computational cartography;label selection;label consistency;label placement;preprocesse;human computer interaction;geographic information system;dynamic map;human computer interface;map labeling;label filtering\\\",\\\"Title\\\":\\\"Dynamic Map Labeling\\\"},\\\"872\\\":{\\\"Abstract\\\":\\\"We have previously shown that random sampling is an effective clutter reduction technique and that a sampling lens can facilitate focus+context viewing of particular regions. This demands an efficient method of estimating the overlap or occlusion of large numbers of intersecting lines in order to automatically adjust the sampling rate within the lens. This paper proposes several ways for measuring occlusion in parallel coordinate plots. An empirical study into the accuracy and efficiency of the occlusion measures show that a probabilistic approach combined with a 'binning' technique is very fast and yet approaches the accuracy of the more expensive 'true' complete measurement\\\",\\\"Authors\\\":\\\"Ellis, G.;Dix, A.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;FocusContextTechniques;OcclusionProblemsTechniques;ParallelCoordinates;Sampling;VisualClutterAndItsReduction\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.138\\\",\\\"Keywords\\\":\\\"lens;information visualization;density reduction;clutter;occlusion;random sampling;sampling;overplotting;parallel coordinates\\\",\\\"Keywords_Processed\\\":\\\"parallel coordinate;random sampling;clutter;density reduction;information visualization;sample;lens;overplotte;occlusion\\\",\\\"Title\\\":\\\"Enabling Automatic Clutter Reduction in Parallel Coordinate Plots\\\"},\\\"873\\\":{\\\"Abstract\\\":\\\"The dominant paradigm for searching and browsing large data stores is text-based: presenting a scrollable list of search results in response to textual search term input. While this works well for the Web, there is opportunity for improvement in the domain of personal information stores, which tend to have more heterogeneous data and richer metadata. In this paper, we introduce FacetMap, an interactive, query-driven visualization, generalizable to a wide range of metadata-rich data stores. FacetMap uses a visual metaphor for both input (selection of metadata facets as filters) and output. Results of a user study provide insight into tradeoffs between FacetMap's graphical approach and the traditional text-oriented approach\\\",\\\"Authors\\\":\\\"Smith, G.;Czerwinski, M.;Meyers, B.Robbins.;Robertson, G.;Tan, D.S.\\\",\\\"Clusters\\\":\\\"DataFacetsAndTechniques;DatabasesAndDataMining;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.142\\\",\\\"Keywords\\\":\\\"faceted metadata;graphical visualization;interactive information retrieval\\\",\\\"Keywords_Processed\\\":\\\"graphical visualization;faceted metadata;interactive information retrieval\\\",\\\"Title\\\":\\\"FacetMap: A Scalable Search and Browse Visualization\\\"},\\\"874\\\":{\\\"Abstract\\\":\\\"A compound graph is a frequently encountered type of data set. Relations are given between items, and a hierarchy is defined on the items as well. We present a new method for visualizing such compound graphs. Our approach is based on visually bundling the adjacency edges, i.e., non-hierarchical edges, together. We realize this as follows. We assume that the hierarchy is shown via a standard tree visualization method. Next, we bend each adjacency edge, modeled as a B-spline curve, toward the polyline defined by the path via the inclusion edges from one node to another. This hierarchical bundling reduces visual clutter and also visualizes implicit adjacency edges between parent nodes that are the result of explicit adjacency edges between their respective child nodes. Furthermore, hierarchical edge bundling is a generic method which can be used in conjunction with existing tree visualization techniques. We illustrate our technique by providing example visualizations and discuss the results based on an informal evaluation provided by potential users of such visualizations\\\",\\\"Authors\\\":\\\"Holten, D.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;CurvesAndCurvature;DataClusteringAndAggregation;GraphNetworkDataAndTechniques;HierarchicalTreeDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.147\\\",\\\"Keywords\\\":\\\"edge aggregation;hierarchy;node-link diagrams;tree visualization;graph visualization;treemap;edge concentration;curves;edge bundling;network visualization\\\",\\\"Keywords_Processed\\\":\\\"hierarchy;edge aggregation;treemap;edge bundling;network visualization;tree visualization;edge concentration;graph visualization;curve;node link diagram\\\",\\\"Title\\\":\\\"Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data\\\"},\\\"875\\\":{\\\"Abstract\\\":\\\"Existing information-visualization techniques that target small screens are usually limited to exploring a few hundred items. In this article we present a scatterplot tool for personal digital assistants that allows the handling of many thousands of items. The application's scalability is achieved by incorporating two alternative interaction techniques: a geometric-semantic zoom that provides smooth transition between overview and detail, and a fisheye distortion that displays the focus and context regions of the scatterplot in a single view. A user study with 24 participants was conducted to compare the usability and efficiency of both techniques when searching a book database containing 7500 items. The study was run on a pen-driven Wacom board simulating a PDA interface. While the results showed no significant difference in task-completion times, a clear majority of 20 users preferred the fisheye view over the zoom interaction. In addition, other dependent variables such as user satisfaction and subjective rating of orientation and navigation support revealed a preference for the fisheye distortion. These findings partly contradict related research and indicate that, when using a small screen, users place higher value on the ability to preserve navigational context than they do on the ease of use of a simplistic, metaphor-based interaction style\\\",\\\"Authors\\\":\\\"Buring, T.;Gerken, J.;Reiterer, H.\\\",\\\"Clusters\\\":\\\"DataFeaturesAndAttributes;DimensionalityReduction;GraphNetworkDataAndTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.156\\\",\\\"Keywords\\\":\\\"multi-dimensional scaling;graph drawing;constraints;stress majorization;force-directed algorithm\\\",\\\"Keywords_Processed\\\":\\\"graph drawing;constraint;stress majorization;force direct algorithm;multi dimensional scaling\\\",\\\"Title\\\":\\\"IPSep-CoLa: An Incremental Procedure for Separation Constraint Layout of Graphs\\\"},\\\"876\\\":{\\\"Abstract\\\":\\\"MatrixExplorer is a network visualization system that uses two representations: node-link diagrams and matrices. Its design comes from a list of requirements formalized after several interviews and a participatory design session conducted with social science researchers. Although matrices are commonly used in social networks analysis, very few systems support the matrix-based representations to visualize and analyze networks. MatrixExplorer provides several novel features to support the exploration of social networks with a matrix-based representation, in addition to the standard interactive filtering and clustering functions. It provides tools to reorder (layout) matrices, to annotate and compare findings across different layouts and find consensus among several clusterings. MatrixExplorer also supports node-link diagram views which are familiar to most users and remain a convenient way to publish or communicate exploration results. Matrix and node-link representations are kept synchronized at all stages of the exploration process\\\",\\\"Authors\\\":\\\"Henry, N.;Fekete, J.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;CollaborativeVisualization;DataClusteringAndAggregation;GraphNetworkDataAndTechniques;MatrixRelatedTechniques;SocialNetworksAndSocialMedia\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.160\\\",\\\"Keywords\\\":\\\"exploratory process;node-link diagrams;matrix ordering;social networks visualization;interactive clustering;consensus;matrix-based representations\\\",\\\"Keywords_Processed\\\":\\\"consensus;exploratory process;matrix base representation;social network visualization;matrix ordering;interactive clustering;node link diagram\\\",\\\"Title\\\":\\\"MatrixExplorer: a Dual-Representation System to Explore Social Networks\\\"},\\\"877\\\":{\\\"Abstract\\\":\\\"Data abstraction techniques are widely used in multiresolution visualization systems to reduce visual clutter and facilitate analysis from overview to detail. However, analysts are usually unaware of how well the abstracted data represent the original dataset, which can impact the reliability of results gleaned from the abstractions. In this paper, we define two data abstraction quality measures for computing the degree to which the abstraction conveys the original dataset: the histogram difference measure and the nearest neighbor measure. They have been integrated within XmdvTool, a public-domain multiresolution visualization system for multivariate data analysis that supports sampling as well as clustering to simplify data. Several interactive operations are provided, including adjusting the data abstraction level, changing selected regions, and setting the acceptable data abstraction quality level. Conducting these operations, analysts can select an optimal data abstraction level. Also, analysts can compare different abstraction methods using the measures to see how well relative data density and outliers are maintained, and then select an abstraction method that meets the requirement of their analytic tasks\\\",\\\"Authors\\\":\\\"Cui, Q.;Ward, M.O.;Rundensteiner, E.A.;Jing Yang\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;EvaluationMetricsAndBenchmarks;MultiresolutionTechniques;Sampling\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.161\\\",\\\"Keywords\\\":\\\"multi-resoution visualization;clustering;metrics;sampling\\\",\\\"Keywords_Processed\\\":\\\"clustering;sample;metric;multi resoution visualization\\\",\\\"Title\\\":\\\"Measuring Data Abstraction Quality in Multiresolution Visualizations\\\"},\\\"878\\\":{\\\"Abstract\\\":\\\"In his text Visualizing Data, William Cleveland demonstrates how the aspect ratio of a line chart can affect an analyst's perception of trends in the data. Cleveland proposes an optimization technique for computing the aspect ratio such that the average absolute orientation of line segments in the chart is equal to 45 degrees. This technique, called banking to 45deg, is designed to maximize the discriminability of the orientations of the line segments in the chart. In this paper, we revisit this classic result and describe two new extensions. First, we propose alternate optimization criteria designed to further improve the visual perception of line segment orientations. Second, we develop multi-scale banking, a technique that combines spectral analysis with banking to 45deg. Our technique automatically identifies trends at various frequency scales and then generates a banked chart for each of these scales. We demonstrate the utility of our techniques in a range of visualization tools and analysis examples\\\",\\\"Authors\\\":\\\"Heer, J.;Agrawala, M.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;Perception;TimeseriesTimeVaryingDataAndTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.163\\\",\\\"Keywords\\\":\\\"information visualization;sparklines;time-series;graphical perception;line charts;banking to 45 degrees\\\",\\\"Keywords_Processed\\\":\\\"sparkline;time series;information visualization;line chart;graphical perception;banking to 45 degree\\\",\\\"Title\\\":\\\"Multi-Scale Banking to 45 Degrees\\\"},\\\"879\\\":{\\\"Abstract\\\":\\\"Networks have remained a challenge for information visualization designers because of the complex issues of node and link layout coupled with the rich set of tasks that users present. This paper offers a strategy based on two principles: (1) layouts are based on user-defined semantic substrates, which are non-overlapping regions in which node placement is based on node attributes, (2) users interactively adjust sliders to control link visibility to limit clutter and thus ensure comprehensibility of source and destination. Scalability is further facilitated by user control of which nodes are visible. We illustrate our semantic substrates approach as implemented in NVSS 1.0 with legal precedent data for up to 1122 court cases in three regions with 7645 legal citations\\\",\\\"Authors\\\":\\\"Shneiderman, B.;Aris, A.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;SemanticsSemioticsRelatedTechniques;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.166\\\",\\\"Keywords\\\":\\\"semantic substrate;information visualization;graphical user interface;network visualization\\\",\\\"Keywords_Processed\\\":\\\"semantic substrate;graphical user interface;information visualization;network visualization\\\",\\\"Title\\\":\\\"Network Visualization by Semantic Substrates\\\"},\\\"880\\\":{\\\"Abstract\\\":\\\"Quasi-trees, namely graphs with tree-like structure, appear in many application domains, including bioinformatics and computer networks. Our new SPF approach exploits the structure of these graphs with a two-level approach to drawing, where the graph is decomposed into a tree of biconnected components. The low-level biconnected components are drawn with a force-directed approach that uses a spanning tree skeleton as a starting point for the layout. The higher-level structure of the graph is a true tree with meta-nodes of variable size that contain each biconnected component. That tree is drawn with a new area-aware variant of a tree drawing algorithm that handles high-degree nodes gracefully, at the cost of allowing edge-node overlaps. SPF performs an order of magnitude faster than the best previous approaches, while producing drawings of commensurate or improved quality.\\\",\\\"Authors\\\":\\\"Archambault, D.;Munzner, T.;Auber, D.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.177\\\",\\\"Keywords\\\":\\\"quasi-tree;graph and network visualization\\\",\\\"Keywords_Processed\\\":\\\"quasi tree;graph and network visualization\\\",\\\"Title\\\":\\\"Smashing Peacocks Further: Drawing Quasi-Trees from Biconnected Components\\\"},\\\"881\\\":{\\\"Abstract\\\":\\\"Despite a diversity of software architectures supporting information visualization, it is often difficult to identify, evaluate, and re-apply the design solutions implemented within such frameworks. One popular and effective approach for addressing such difficulties is to capture successful solutions in design patterns, abstract descriptions of interacting software components that can be customized to solve design problems within a particular context. Based upon a review of existing frameworks and our own experiences building visualization software, we present a series of design patterns for the domain of information visualization. We discuss the structure, context of use, and interrelations of patterns spanning data representation, graphics, and interaction. By representing design knowledge in a reusable form, these patterns can be used to facilitate software design, implementation, and evaluation, and improve developer education and communication\\\",\\\"Authors\\\":\\\"Heer, J.;Agrawala, M.\\\",\\\"Clusters\\\":\\\"DesignMethodologiesAndInteractionDesign;ProgrammingAlgorithmsAndDataStructures;SoftwareVisualization;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.178\\\",\\\"Keywords\\\":\\\"design patterns;software engineering;information visualization;object-oriented programming\\\",\\\"Keywords_Processed\\\":\\\"object orient programming;software engineering;information visualization;design pattern\\\",\\\"Title\\\":\\\"Software Design Patterns for Information Visualization\\\"},\\\"882\\\":{\\\"Abstract\\\":\\\"People in different places talk about different things. This interest distribution is reflected by the newspaper articles circulated in a particular area. We use data from our large-scale newspaper analysis system (Lydia) to make entity datamaps, a spatial visualization of the interest in a given named entity. Our goal is to identify entities which display regional biases. We develop a model of estimating the frequency of reference of an entity in any given city from the reference frequency centered in surrounding cities, and techniques for evaluating the spatial significance of this distribution\\\",\\\"Authors\\\":\\\"Mehler, A.;Bao, Y.;Li, X.;Wang, Y.;Skiena, S.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;GeographyGeospatialVisCartographyTerrainVis;InternetWebVisualizationForTheMasses;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.179\\\",\\\"Keywords\\\":\\\"information analytics;text and document visualization;geographic visualization;geographic information systems;newspapers;web visualization;spidering\\\",\\\"Keywords_Processed\\\":\\\"newspaper;text and document visualization;geographic information system;geographic visualization;information analytic;spidere;web visualization\\\",\\\"Title\\\":\\\"Spatial Analysis of News Sources\\\"},\\\"883\\\":{\\\"Abstract\\\":\\\"Larger, higher resolution displays can be used to increase the scalability of information visualizations. But just how much can scalability increase using larger displays before hitting human perceptual or cognitive limits? Are the same visualization techniques that are good on a single monitor also the techniques that are best when they are scaled up using large, high-resolution displays? To answer these questions we performed a controlled experiment on user performance time, accuracy, and subjective workload when scaling up data quantity with different space-time-attribute visualizations using a large, tiled display. Twelve college students used small multiples, embedded bar matrices, and embedded time-series graphs either on a 2 megapixel (Mp) display or with data scaled up using a 32 Mp tiled display. Participants performed various overview and detail tasks on geospatially-referenced multidimensional time-series data. Results showed that current designs are perceptually scalable because they result in a decrease in task completion time when normalized per number of data attributes along with no decrease in accuracy. It appears that, for the visualizations selected for this study, the relative comparison between designs is generally consistent between display sizes. However, results also suggest that encoding is more important on a smaller display while spatial grouping is more important on a larger display. Some suggestions for designers are provided based on our experience designing visualizations for large displays.\\\",\\\"Authors\\\":\\\"Yost, B.;North, C.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;LargeAndHighResDisplays;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.184\\\",\\\"Keywords\\\":\\\"information visualization;empirical evaluation;large displays\\\",\\\"Keywords_Processed\\\":\\\"large display;empirical evaluation;information visualization\\\",\\\"Title\\\":\\\"The Perceptual Scalability of Visualization\\\"},\\\"884\\\":{\\\"Abstract\\\":\\\"We propose a new metaphor for the visualization of prefixes propagation in the Internet. Such a metaphor is based on the concept of topographic map and allows to put in evidence the relative importance of the Internet Service Providers (ISPs) involved in the routing of the prefix. Based on the new metaphor we propose an algorithm for computing layouts and experiment with such algorithm on a test suite taken from the real Internet. The paper extends the visualization approach of the BGPlay service, which is an Internet routing monitoring tool widely used by ISP operators\\\",\\\"Authors\\\":\\\"Cortese, P.F.;Di Battista, G.;Moneta, A.;Patrignani, M.;Pizzonia, M.\\\",\\\"Clusters\\\":\\\"ComputerNetworksNetworkSecurity;GraphNetworkDataAndTechniques;InternetWebVisualizationForTheMasses;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.185\\\",\\\"Keywords\\\":\\\"interdomain routing;internet visualization;spring embedder;graph drawing\\\",\\\"Keywords_Processed\\\":\\\"internet visualization;interdomain route;spring embedder;graph drawing\\\",\\\"Title\\\":\\\"Topographic Visualization of Prefix Propagation in the Internet\\\"},\\\"885\\\":{\\\"Abstract\\\":\\\"Larger, higher resolution displays can be used to increase the scalability of information visualizations. But just how much can scalability increase using larger displays before hitting human perceptual or cognitive limits? Are the same visualization techniques that are good on a single monitor also the techniques that are best when they are scaled up using large, high-resolution displays? To answer these questions we performed a controlled experiment on user performance time, accuracy, and subjective workload when scaling up data quantity with different space-time-attribute visualizations using a large, tiled display. Twelve college students used small multiples, embedded bar matrices, and embedded time-series graphs either on a 2 megapixel (Mp) display or with data scaled up using a 32 Mp tiled display. Participants performed various overview and detail tasks on geospatially-referenced multidimensional time-series data. Results showed that current designs are perceptually scalable because they result in a decrease in task completion time when normalized per number of data attributes along with no decrease in accuracy. It appears that, for the visualizations selected for this study, the relative comparison between designs is generally consistent between display sizes. However, results also suggest that encoding is more important on a smaller display while spatial grouping is more important on a larger display. Some suggestions for designers are provided based on our experience designing visualizations for large displays\\\",\\\"Authors\\\":\\\"Yost, B.;North, C.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;DisplaysGeneral;FocusContextTechniques;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.187\\\",\\\"Keywords\\\":\\\"small screen;scatterplot;pda;focus+context;fisheye;zooming\\\",\\\"Keywords_Processed\\\":\\\"zooming;scatterplot;small screen;pda;focus context;fisheye\\\",\\\"Title\\\":\\\"User Interaction with Scatterplots on Small Screens - A Comparative Evaluation of Geometric-Semantic Zoom and fisheye Distortion\\\"},\\\"886\\\":{\\\"Abstract\\\":\\\"We present a new approach for the visual analysis of state transition graphs. We deal with multivariate graphs where a number of attributes are associated with every node. Our method provides an interactive attribute-based clustering facility. Clustering results in metric, hierarchical and relational data, represented in a single visualization. To visualize hierarchically structured quantitative data, we introduce a novel technique: the bar tree. We combine this with a node-link diagram to visualize the hierarchy and an arc diagram to visualize relational data. Our method enables the user to gain significant insight into large state transition graphs containing tens of thousands of nodes. We illustrate the effectiveness of our approach by applying it to a real-world use case. The graph we consider models the behavior of an industrial wafer stepper and contains 55 043 nodes and 289 443 edges\\\",\\\"Authors\\\":\\\"Pretorius, A.J.;van Wijk, J.J.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;GraphNetworkDataAndTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;StateRelatedDataTechniques;TransitionsAndMorphing\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.192\\\",\\\"Keywords\\\":\\\"graph visualization;interactive clustering;transition systems;multivariate visualization;state spaces;finite state machines\\\",\\\"Keywords_Processed\\\":\\\"interactive clustering;transition system;state space;finite state machine;multivariate visualization;graph visualization\\\",\\\"Title\\\":\\\"Visual Analysis of Multivariate State Transition Graphs\\\"},\\\"887\\\":{\\\"Abstract\\\":\\\"Quasi-trees, namely graphs with tree-like structure, appear in many application domains, including bioinformatics and computer networks. Our new SPF approach exploits the structure of these graphs with a two-level approach to drawing, where the graph is decomposed into a tree of biconnected components. The low-level biconnected components are drawn with a force-directed approach that uses a spanning tree skeleton as a starting point for the layout. The higher-level structure of the graph is a true tree with meta-nodes of variable size that contain each biconnected component. That tree is drawn with a new area-aware variant of a tree drawing algorithm that handles high-degree nodes gracefully, at the cost of allowing edge-node overlaps. SPF performs an order of magnitude faster than the best previous approaches, while producing drawings of commensurate or improved quality\\\",\\\"Authors\\\":\\\"Archambault, D.;Munzner, T.;Auber, D.\\\",\\\"Clusters\\\":\\\"BusinessFinanceEconomyManufacturing;GraphNetworkDataAndTechniques;HierarchicalTreeDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.193\\\",\\\"Keywords\\\":\\\"time-series data;financial visualization;hierarchy visualization;graph and network visualization\\\",\\\"Keywords_Processed\\\":\\\"financial visualization;time series datum;hierarchy visualization;graph and network visualization\\\",\\\"Title\\\":\\\"Visual Exploration of Complex Time-Varying Graphs\\\"},\\\"888\\\":{\\\"Abstract\\\":\\\"Dynamical models that explain the formation of spatial structures of RNA molecules have reached a complexity that requires novel visualization methods that help to analyze the validity of these models. We focus on the visualization of so-called folding landscapes of a growing RNA molecule. Folding landscapes describe the energy of a molecule as a function of its spatial configuration; thus they are huge and high dimensional. Their most salient features, however, are encapsulated by their so-called barrier tree that reflects the local minima and their connecting saddle points. For each length of the growing RNA chain there exists a folding landscape. We visualize the sequence of folding landscapes by an animation of the corresponding barrier trees. To generate the animation, we adapt the foresight layout with tolerance algorithm for general dynamic graph layout problems. Since it is very general, we give a detailed description of each phase: constructing a supergraph for the trees, layout of that supergraph using a modified DOT algorithm, and presentation techniques for the final animation\\\",\\\"Authors\\\":\\\"Heine, C.;Scheuermann, G.;Flamm, C.;Hofacker, I.L.;Stadler, P.F.\\\",\\\"Clusters\\\":\\\"DynamicDataAndTechniques;EarthSpaceAndEnvironmentalSciences;GraphNetworkDataAndTechniques;HierarchicalTreeDataAndTechniques;MachineLearningAndStatistics;MolecularScienceAndChemistry\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.196\\\",\\\"Keywords\\\":\\\"dynamic graph;energy landscape;rna folding;graph drawing;barrier tree;fitness landscape\\\",\\\"Keywords_Processed\\\":\\\"graph drawing;rna fold;barrier tree;fitness landscape;energy landscape;dynamic graph\\\",\\\"Title\\\":\\\"Visualization of Barrier Tree Sequences\\\"},\\\"889\\\":{\\\"Abstract\\\":\\\"In many applications, data is collected and indexed by geo-spatial location. Discovering interesting patterns through visualization is an important way of gaining insight about such data. A previously proposed approach is to apply local placement functions such as PixelMaps that transform the input data set into a solution set that preserves certain constraints while making interesting patterns more obvious and avoid data loss from overplotting. In experience, this family of spatial transformations can reveal fine structures in large point sets, but it is sometimes difficult to relate those structures to basic geographic features such as cities and regional boundaries. Recent information visualization research has addressed other types of transformation functions that make spatially-transformed maps with recognizable shapes. These types of spatial-transformation are called global shape functions. In particular, cartogram-based map distortion has been studied. On the other hand, cartogram-based distortion does not handle point sets readily. In this study, we present a framework that allows the user to specify a global shape function and a local placement function. We combine cartogram-based layout (global shape) with PixelMaps (local placement), obtaining some of the benefits of each toward improved exploration of dense geo-spatial data sets\\\",\\\"Authors\\\":\\\"Panse, C.;Sips, M.;Keim, D.A.;North, S.C.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;Maps;PixelOrientedEncodings;ShapeRelatedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.198\\\",\\\"Keywords\\\":\\\"cartogram;pixel visualization;geospatial data;shape transformation\\\",\\\"Keywords_Processed\\\":\\\"geospatial datum;pixel visualization;cartogram;shape transformation\\\",\\\"Title\\\":\\\"Visualization of Geo-spatial Point Sets via Global Shape Transformation and Local Pixel Placement\\\"},\\\"890\\\":{\\\"Abstract\\\":\\\"Business data is often presented using simple business graphics. These familiar visualizations are effective for providing overviews, but fall short for the presentation of large amounts of detailed information. Treemaps can provide such detail, but are often not easy to understand. We present how standard treemap algorithms can be adapted such that the results mimic familiar business graphics. Specifically, we present the use of different layout algorithms per level, a number of variations of the squarified algorithm, the use of variable borders, and the use of non-rectangular shapes. The combined use of these leads to histograms, pie charts and a variety of other styles\\\",\\\"Authors\\\":\\\"Vliegen, R.;van Wijk, J.J.;van der Linden, E.-J.\\\",\\\"Clusters\\\":\\\"BusinessFinanceEconomyManufacturing;HierarchicalTreeDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.200\\\",\\\"Keywords\\\":\\\"information visualization;business graphics;hierarchical data;treemap\\\",\\\"Keywords_Processed\\\":\\\"business graphic;information visualization;hierarchical datum;treemap\\\",\\\"Title\\\":\\\"Visualizing Business Data with Generalized Treemaps\\\"},\\\"891\\\":{\\\"Abstract\\\":\\\"This paper describes the Worldmapper project, which makes use of novel visualization techniques to represent a broad variety of social and economic data about the countries of the world. The goal of the project is to use the map projections known as cartograms to depict comparisons and relations between different territories, and its execution raises many interesting design challenges that were not all apparent at the outset. We discuss the approaches taken towards these challenges, some of which may have considerably broad application. We conclude by commenting on the positive initial response to the Worldmapper images published on the Web, which we believe is due, at least in part, to the particular effectiveness of the cartogram as a tool for communicating quantitative geographic data\\\",\\\"Authors\\\":\\\"Dorling, D.;Barford, A.;Newman, M.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;GeographyGeospatialVisCartographyTerrainVis;Maps;SocialNetworksAndSocialMedia;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.202\\\",\\\"Keywords\\\":\\\"geographic visualization;social visualization;worldmapper;computer graphics;cartogram;visualization\\\",\\\"Keywords_Processed\\\":\\\"visualization;computer graphic;cartogram;geographic visualization;worldmapper;social visualization\\\",\\\"Title\\\":\\\"Worldmapper: The World as You've Never Seen it Before\\\"},\\\"892\\\":{\\\"Abstract\\\":\\\"Recent advances in algorithms and graphics hardware have opened the possibility to render tetrahedral grids at interactive rates on commodity PCs. This paper extends on this work in that it presents a direct volume rendering method for such grids which supports both current and upcoming graphics hardware architectures, large and deformable grids, as well as different rendering options. At the core of our method is the idea to perform the sampling of tetrahedral elements along the view rays entirely in local barycentric coordinates. Then, sampling requires minimum GPU memory and texture access operations, and it maps efficiently onto a feed-forward pipeline of multiple stages performing computation and geometry construction. We propose to spawn rendered elements from one single vertex. This makes the method amenable to upcoming Direct3D 10 graphics hardware which allows to create geometry on the GPU. By only modifying the algorithm slightly it can be used to render per-pixel iso-surfaces and to perform tetrahedral cell projection. As our method neither requires any pre-processing nor an intermediate grid representation it can efficiently deal with dynamic and large 3D meshes\\\",\\\"Authors\\\":\\\"Georgii, J.;Westermann, R.\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;MeshesGridsAndLattices;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.110\\\",\\\"Keywords\\\":\\\"direct volume rendering;unstructured grid;programmable graphics hardware\\\",\\\"Keywords_Processed\\\":\\\"programmable graphic hardware;unstructured grid;direct volume render\\\",\\\"Title\\\":\\\"A Generic and Scalable Pipeline for GPU Tetrahedral Grid Rendering\\\"},\\\"893\\\":{\\\"Abstract\\\":\\\"This paper presents an interactive visualization system, named WebSearchViz, for visualizing the Web search results and facilitating users' navigation and exploration. The metaphor in our model is the solar system with its planets and asteroids revolving around the sun. Location, color, movement, and spatial distance of objects in the visual space are used to represent the semantic relationships between a query and relevant Web pages. Especially, the movement of objects and their speeds add a new dimension to the visual space, illustrating the degree of relevance among a query and Web search results in the context of users' subjects of interest. By interacting with the visual space, users are able to observe the semantic relevance between a query and a resulting Web page with respect to their subjects of interest, context information, or concern. Users' subjects of interest can be dynamically changed, redefined, added, or deleted from the visual space\\\",\\\"Authors\\\":\\\"Nguyen, T.;Zhang, J.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;InternetWebVisualizationForTheMasses;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.111\\\",\\\"Keywords\\\":\\\"movement;speed;web search results;visualization models\\\",\\\"Keywords_Processed\\\":\\\"speed;visualization model;movement;web search result\\\",\\\"Title\\\":\\\"A Novel Visualization Model for Web Search Results\\\"},\\\"894\\\":{\\\"Abstract\\\":\\\"We present a novel pipeline for computer-aided detection (CAD) of colonic polyps by integrating texture and shape analysis with volume rendering and conformal colon flattening. Using our automatic method, the 3D polyp detection problem is converted into a 2D pattern recognition problem. The colon surface is first segmented and extracted from the CT data set of the patient's abdomen, which is then mapped to a 2D rectangle using conformal mapping. This flattened image is rendered using a direct volume rendering technique with a translucent electronic biopsy transfer function. The polyps are detected by a 2D clustering method on the flattened image. The false positives are further reduced by analyzing the volumetric shape and texture features. Compared with shape based methods, our method is much more efficient without the need of computing curvature and other shape parameters for the whole colon surface. The final detection results are stored in the 2D image, which can be easily incorporated into a virtual colonoscopy (VC) system to highlight the polyp locations. The extracted colon surface mesh can be used to accelerate the volumetric ray casting algorithm used to generate the VC endoscopic view. The proposed automatic CAD pipeline is incorporated into an interactive VC system, with a goal of helping radiologists detect polyps faster and with higher accuracy\\\",\\\"Authors\\\":\\\"Hong, W.;Feng Qiu;Kaufman, A.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;Textures;VisualPatternFeatureDetectionAndTracking;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.112\\\",\\\"Keywords\\\":\\\"computer-aided detection;virtual colonoscopy;texture analysis;volume rendering\\\",\\\"Keywords_Processed\\\":\\\"texture analysis;volume render;computer aid detection;virtual colonoscopy\\\",\\\"Title\\\":\\\"A Pipeline for Computer Aided Polyp Detection\\\"},\\\"895\\\":{\\\"Abstract\\\":\\\"In this paper we investigate the effects of function composition in the form g(f(x)) = h(x) by means of a spectral analysis of h. We decompose the spectral description of h(x) into a scalar product of the spectral description of g(x) and a term that solely depends on f(x) and that is independent of g(x). We then use the method of stationary phase to derive the essential maximum frequency of g(f(x)) bounding the main portion of the energy of its spectrum. This limit is the product of the maximum frequency of g(x) and the maximum derivative of f(x). This leads to a proper sampling of the composition h of the two functions g and f. We apply our theoretical results to a fundamental open problem in volume rendering - the proper sampling of the rendering integral after the application of a transfer function. In particular, we demonstrate how the sampling criterion can be incorporated in adaptive ray integration, visualization with multi-dimensional transfer functions, and pre-integrated volume rendering\\\",\\\"Authors\\\":\\\"Bergner, S.;Moller, T.;Weiskopf, D.;Muraki, D.J.\\\",\\\"Clusters\\\":\\\"ImageBasedDataImageSignalProcessing;NumericalMethodsMathematics;Sampling;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.113\\\",\\\"Keywords\\\":\\\"volume rendering;adaptive sampling;fourier transform;transfer function;signal processing\\\",\\\"Keywords_Processed\\\":\\\"volume render;adaptive sampling;signal processing;transfer function;fouri transform\\\",\\\"Title\\\":\\\"A Spectral Analysis of Function Composition and its Implications for Sampling in Direct Volume Visualization\\\"},\\\"896\\\":{\\\"Abstract\\\":\\\"In the past decade, a lot of research work has been conducted to support collaborative visualization among remote users over the networks, allowing them to visualize and manipulate shared data for problem solving. There are many applications of collaborative visualization, such as oceanography, meteorology and medical science. To facilitate user interaction, a critical system requirement for collaborative visualization is to ensure that remote users would perceive a synchronized view of the shared data. Failing this requirement, the user's ability in performing the desirable collaborative tasks would be affected. In this paper, we propose a synchronization method to support collaborative visualization. It considers how interaction with dynamic objects is perceived by application participants under the existence of network latency, and remedies the motion trajectory of the dynamic objects. It also handles the false positive and false negative collision detection problems. The new method is particularly well designed for handling content changes due to unpredictable user interventions or object collisions. We demonstrate the effectiveness of our method through a number of experiments\\\",\\\"Authors\\\":\\\"Li, L.W.F.;Li, F.W.B.;Lau, R.W.H.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;CollaborativeVisualization;ComputerNetworksNetworkSecurity;DistributedSystemsAndGridEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.114\\\",\\\"Keywords\\\":\\\"network latency;motion synchronization;collaborative visualization;distributed synchronization\\\",\\\"Keywords_Processed\\\":\\\"collaborative visualization;motion synchronization;network latency;distribute synchronization\\\",\\\"Title\\\":\\\"A Trajectory-Preserving Synchronization Method for Collaborative Visualization\\\"},\\\"897\\\":{\\\"Abstract\\\":\\\"This paper presents an advanced evenly-spaced streamline placement algorithm for fast, high-quality, and robust layout of flow lines. A fourth-order Runge-Kutta integrator with adaptive step size and error control is employed for rapid accurate streamline advection. Cubic Hermite polynomial interpolation with large sample-spacing is adopted to create fewer evenly-spaced samples along each streamline to reduce the amount of distance checking. We propose two methods to enhance placement quality. Double queues are used to prioritize topological seeding and to favor long streamlines to minimize discontinuities. Adaptive distance control based on the local flow variance is explored to reduce cavities. Furthermore, we propose a universal, effective, fast, and robust loop detection strategy to address closed and spiraling streamlines. Our algorithm is an order-of-magnitude faster than Jobard and Lefer's algorithm with better placement quality and over 5 times faster than Mebarki et al.'s algorithm with comparable placement quality, but with a more robust solution to loop detection\\\",\\\"Authors\\\":\\\"Liu, Z.;Moorhead, R.J.;Groner, J.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;ParticleVisualizationAndTechniques;StreamlinesPathlinesStreaklines\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.116\\\",\\\"Keywords\\\":\\\"flow visualization;streamline placement;seeding strategy;evenly-spaced streamlines;closed streamlines\\\",\\\"Keywords_Processed\\\":\\\"evenly space streamline;closed streamline;seed strategy;streamline placement;flow visualization\\\",\\\"Title\\\":\\\"An Advanced Evenly-Spaced Streamline Placement Algorithm\\\"},\\\"898\\\":{\\\"Abstract\\\":\\\"Topological methods are often used to describe flow structures in fluid dynamics and topological flow field analysis usually relies on the invariants of the associated tensor fields. A visual impression of the local properties of tensor fields is often complex and the search of a suitable technique for achieving this is an ongoing topic in visualization. This paper introduces and assesses a method of representing the topological properties of tensor fields and their respective flow patterns with the use of colors. First, a tensor norm is introduced, which preserves the properties of the tensor and assigns the tensor invariants to values of the RGB color space. Secondly, the RGB colors of the tensor invariants are transferred to corresponding hue values as an alternative color representation. The vectorial tensor invariants field is reduced to a scalar hue field and visualization of iso-surfaces of this hue value field allows us to identify locations with equivalent flow topology. Additionally highlighting by the maximum of the eigenvalue difference field reflects the magnitude of the structural change of the flow. The method is applied on a vortex breakdown flow structure inside a cylinder with a rotating lid\\\",\\\"Authors\\\":\\\"Rutten, M.;Chong, M.S.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;NumericalMethodsMathematics;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.119\\\",\\\"Keywords\\\":\\\"flow visualization;tensor field topology;invariants\\\",\\\"Keywords_Processed\\\":\\\"tensor field topology;invariant;flow visualization\\\",\\\"Title\\\":\\\"Analyzing Vortex Breakdown Flow Structures by Assignment of Colors to Tensor Invariants\\\"},\\\"899\\\":{\\\"Abstract\\\":\\\"Centralized techniques have been used until now when automatically calibrating (both geometrically and photometrically) large high-resolution displays created by tiling multiple projectors in a 2D array. A centralized server managed all the projectors and also the camera(s) used to calibrate the display. In this paper, we propose an asynchronous distributed calibration methodology via a display unit called the plug-and-play projector (PPP). The PPP consists of a projector, camera, computation and communication unit, thus creating a self-sufficient module that enables an asynchronous distributed architecture for multi-projector displays. We present a single-program-multiple-data (SPMD) calibration algorithm that runs on each PPP and achieves a truly scalable and reconfigurable display without any input from the user. It instruments novel capabilities like adding/removing PPPs from the display dynamically, detecting faults, and reshaping the display to a reasonable rectangular shape to react to the addition/removal/faults. To the best of our knowledge, this is the first attempt to realize a completely asynchronous and distributed calibration architecture and methodology for multi-projector displays\\\",\\\"Authors\\\":\\\"Bhasker, E.;Sinha, P.;Majumder, A.\\\",\\\"Clusters\\\":\\\"DisplaysGeneral;DistributedSystemsAndGridEnvironments;GeometricModeling\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.121\\\",\\\"Keywords\\\":\\\"projector-camera systems;geometric and color calibration;multi-projector displays;distributed algorithms\\\",\\\"Keywords_Processed\\\":\\\"distribute algorithm;geometric and color calibration;projector camera system;multi projector display\\\",\\\"Title\\\":\\\"Asynchronous Distributed Calibration for Scalable and Reconfigurable Multi-Projector Displays\\\"},\\\"900\\\":{\\\"Abstract\\\":\\\"Caricatures are pieces of art depicting persons or sociological conditions in a non-veridical way. In both cases caricatures are referring to a reference model. The deviations from the reference model are the characteristic features of the depicted subject. Good caricatures exaggerate the characteristics of a subject in order to accent them. The concept of caricaturistic visualization is based on the caricature metaphor. The aim of caricaturistic visualization is an illustrative depiction of characteristics of a given dataset by exaggerating deviations from the reference model. We present the general concept of caricaturistic visualization as well as a variety of examples. We investigate different visual representations for the depiction of caricatures. Further, we present the caricature matrix, a technique to make differences between datasets easily identifiable\\\",\\\"Authors\\\":\\\"Rautek, P.;Viola, I.;Groller, E.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;IllustrativeVisualization;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.123\\\",\\\"Keywords\\\":\\\"focus+context technique;volume visualization;illustrative visualization\\\",\\\"Keywords_Processed\\\":\\\"focus context technique;illustrative visualization;volume visualization\\\",\\\"Title\\\":\\\"Caricaturistic Visualization\\\"},\\\"901\\\":{\\\"Abstract\\\":\\\"Volume rendered imagery often includes a barrage of 3D information like shape, appearance and topology of complex structures, and it thus quickly overwhelms the user. In particular, when focusing on a specific region a user cannot observe the relationship between various structures unless he has a mental picture of the entire data. In this paper we present ClearView, a GPU-based, interactive framework for texture-based volume ray-casting that allows users which do not have the visualization skills for this mental exercise to quickly obtain a picture of the data in a very intuitive and user-friendly way. ClearView is designed to enable the user to focus on particular areas in the data while preserving context information without visual clutter. ClearView does not require additional feature volumes as it derives any features in the data from image information only. A simple point-and-click interface enables the user to interactively highlight structures in the data. ClearView provides an easy to use interface to complex volumetric data as it only uses transparency in combination with a few specific shaders to convey focus and context information\\\",\\\"Authors\\\":\\\"Kruger, J.;Schneider, J.;Westermann, R.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;GpuBasedTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.124\\\",\\\"Keywords\\\":\\\"volume raycasting;gpu rendering;focus+context\\\",\\\"Keywords_Processed\\\":\\\"volume raycasting;focus context;gpu render\\\",\\\"Title\\\":\\\"ClearView: An Interactive Context Preserving Hotspot Visualization Technique\\\"},\\\"902\\\":{\\\"Abstract\\\":\\\"We present a comparative visualization of the acoustic simulation results obtained by two different approaches that were combined into a single simulation algorithm. The first method solves the wave equation on a volume grid based on finite elements. The second method, phonon tracing, is a geometric approach that we have previously developed for interactive simulation, visualization and modeling of room acoustics. Geometric approaches of this kind are more efficient than FEM in the high and medium frequency range. For low frequencies they fail to represent diffraction, which on the other hand can be simulated properly by means of FEM. When combining both methods we need to calibrate them properly and estimate in which frequency range they provide comparable results. For this purpose we use an acoustic metric called gain and display the resulting error. Furthermore we visualize interference patterns, since these depend not only on diffraction, but also exhibit phase-dependent amplification and neutralization effects\\\",\\\"Authors\\\":\\\"Deines, E.;Bertram, M.;Mohring, J.;Jegorovs, J.;Michel, F.;Hagen, H.;Nielson, G.M.\\\",\\\"Clusters\\\":\\\"AcousticsSoundSonification;ComparisonComparativeVisualizationAndSimilarity;NumericalMethodsMathematics;RaytracingRaycasting\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.125\\\",\\\"Keywords\\\":\\\"finite element method;phonon map;comparative visualization;raytracing;acoustic simulation\\\",\\\"Keywords_Processed\\\":\\\"phonon map;acoustic simulation;comparative visualization;finite element method;raytrace\\\",\\\"Title\\\":\\\"Comparative Visualization for Wave-based and Geometric Acoustics\\\"},\\\"903\\\":{\\\"Abstract\\\":\\\"We present the first scalable algorithm that supports the composition of successive rectilinear deformations. Earlier systems that provided stretch and squish navigation could only handle small datasets. More recent work featuring rubber sheet navigation for large datasets has focused on rendering and on application-specific issues. However, no algorithm has yet been presented for carrying out such navigation methods; our paper addresses this problem. For maximum flexibility with large datasets, a stretch and squish navigation algorithm should allow for millions of potentially deformable regions. However, typical usage only changes the extents of a small subset k of these n regions at a time. The challenge is to avoid computations that are linear in n, because a single deformation can affect the absolute screen-space location of every deformable region. We provide an O(klogn) algorithm that supports any application that can lay out a dataset on a generic grid, and show an implementation that allows navigation of trees and gene sequences with millions of items in sub-millisecond time\\\",\\\"Authors\\\":\\\"Slack, J.;Munzner, T.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;RealtimeProcessingRenderingAndVisualizationGeneral;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.127\\\",\\\"Keywords\\\":\\\"navigation;information visualization;focus+context;realtime rendering\\\",\\\"Keywords_Processed\\\":\\\"navigation;realtime render;information visualization;focus context\\\",\\\"Title\\\":\\\"Composite Rectilinear Deformation for Stretch and Squish Navigation\\\"},\\\"904\\\":{\\\"Abstract\\\":\\\"We describe a concurrent visualization pipeline designed for operation in a production supercomputing environment. The facility was initially developed on the NASA Ames \\\\\\\"Columbia\\\\\\\" supercomputer for a massively parallel forecast model (GEOS4). During the 2005 Atlantic hurricane season, GEOS4 was run 4 times a day under tight time constraints so that its output could be included in an ensemble prediction that was made available to forecasters at the National Hurricane Center. Given this time-critical context, we designed a configurable concurrent pipeline to visualize multiple global fields without significantly affecting the runtime model performance or reliability. We use MPEG compression of the accruing images to facilitate live low-bandwidth distribution of multiple visualization streams to remote sites. We also describe the use of our concurrent visualization framework with a global ocean circulation model, which provides a 864-fold increase in the temporal resolution of practically achievable animations. In both the atmospheric and oceanic circulation models, the application scientists gained new insights into their model dynamics, due to the high temporal resolution animations attainable\\\",\\\"Authors\\\":\\\"Ellsworth, D.;Green, B.;Henze, C.;Moran, P.J.;Sandstrom, T.\\\",\\\"Clusters\\\":\\\"ComputerNetworksNetworkSecurity;EarthSpaceAndEnvironmentalSciences;InputAndOutputDevicesGeneral;InteractionTechniquesGeneral;TimeseriesTimeVaryingDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.128\\\",\\\"Keywords\\\":\\\"ocean modeling;concurrent visualization;hurricane visualization;ecco;time-varying data;geos4 global climate model;supercomputing;high temporal resolution visualization;interactive visual computing\\\",\\\"Keywords_Processed\\\":\\\"time vary datum;interactive visual computing;supercompute;geos4 global climate model;hurricane visualization;concurrent visualization;high temporal resolution visualization;ecco;ocean modeling\\\",\\\"Title\\\":\\\"Concurrent Visualization in a Production Supercomputing Environment\\\"},\\\"905\\\":{\\\"Abstract\\\":\\\"A method for the semi-automatic detection and visualization of defects in models of nematic liquid crystals (NLCs) is introduced; this method is suitable for unstructured models, a previously unsolved problem. The detected defects - also known as disclinations - are regions were the alignment of the liquid crystal rapidly changes over space; these defects play a large role in the physical behavior of the NLC substrate. Defect detection is based upon a measure of total angular change of crystal orientation (the director) over a node neighborhood via the use of a nearest neighbor path. Visualizations based upon the detection algorithm clearly identify complete defect regions as opposed to incomplete visual descriptions provided by cutting-plane and isosurface approaches. The introduced techniques are currently in use by scientists studying the dynamics of defect change\\\",\\\"Authors\\\":\\\"Mehta, K.;Jankun-Kelly, T.J.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;CurvesAndCurvature;MaterialScience;MeshesGridsAndLattices;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.133\\\",\\\"Keywords\\\":\\\"disclination;defects;scientific visualization;nematic liquid crystal;unstructured grid;feature extraction\\\",\\\"Keywords_Processed\\\":\\\"nematic liquid crystal;disclination;feature extraction;unstructured grid;scientific visualization;defect\\\",\\\"Title\\\":\\\"Detection and Visualization of Defects in 3D Unstructured Models of Nematic Liquid Crystals\\\"},\\\"906\\\":{\\\"Abstract\\\":\\\"A common goal of multivariate visualization is to enable data inspection at discrete points, while also illustrating larger-scale continuous structures. In diffusion tensor visualization, glyphs are typically used to meet the first goal, and methods such as texture synthesis or fiber tractography can address the second. We adapt particle systems originally developed for surface modeling and anisotropic mesh generation to enhance the utility of glyph-based tensor visualizations. By carefully distributing glyphs throughout the field (either on a slice, or in the volume) into a dense packing, using potential energy profiles shaped by the local tensor value, we remove undue visual emphasis of the regular sampling grid of the data, and the underlying continuous features become more apparent. The method is demonstrated on a DT-MRI scan of a patient with a brain tumor\\\",\\\"Authors\\\":\\\"Kindlmann, G.;Westin, C.-F.\\\",\\\"Clusters\\\":\\\"GlyphsGlyphBasedTechniques;ParticleVisualizationAndTechniques;Sampling;TensorDataAndTechniques;Tractography\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.134\\\",\\\"Keywords\\\":\\\"glyph;fiber tractography;anisotropic sampling;diffusion tensor;particle systems\\\",\\\"Keywords_Processed\\\":\\\"diffusion tensor;anisotropic sampling;fiber tractography;particle system;glyph\\\",\\\"Title\\\":\\\"Diffusion Tensor Visualization with Glyph Packing\\\"},\\\"907\\\":{\\\"Abstract\\\":\\\"We present a cluster-based volume rendering system for roaming very large volumes. This system allows to move a gigabyte-sized probe inside a total volume of several tens or hundreds of gigabytes in real-time. While the size of the probe is limited by the total amount of texture memory on the cluster, the size of the total data set has no theoretical limit. The cluster is used as a distributed graphics processing unit that both aggregates graphics power and graphics memory. A hardware-accelerated volume renderer runs in parallel on the cluster nodes and the final image compositing is implemented using a pipelined sort-last rendering algorithm. Meanwhile, volume bricking and volume paging allow efficient data caching. On each rendering node, a distributed hierarchical cache system implements a global software-based distributed shared memory on the cluster. In case of a cache miss, this system first checks page residency on the other cluster nodes instead of directly accessing local disks. Using two gigabit Ethernet network interfaces per node, we accelerate data fetching by a factor of 4 compared to directly accessing local disks. The system also implements asynchronous disk access and texture loading, which makes it possible to overlap data loading, volume slicing and rendering for optimal volume roaming\\\",\\\"Authors\\\":\\\"Castanie, L.;Mion, C.;Cavin, X.;Levy, B.\\\",\\\"Clusters\\\":\\\"CpuAndGpuClusters;DistributedSystemsAndGridEnvironments;HardwareAccellerationAndComputationGeneral;InputAndOutputDevicesGeneral;OutOfCoreProcessing;ParallelSystemsAndParallelProcessing;ProgrammingAlgorithmsAndDataStructures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.135\\\",\\\"Keywords\\\":\\\"graphics cluster;volume roaming;graphics hardware;hierarchical caching;large volumes;hardware accelerated volume visualization;out-of-core;parallel rendering;distributed shared memory\\\",\\\"Keywords_Processed\\\":\\\"large volume;distribute share memory;hierarchical caching;graphic hardware;graphic cluster;parallel rendering;hardware accelerate volume visualization;out of core;volume roam\\\",\\\"Title\\\":\\\"Distributed Shared Memory for Roaming Large Volumes\\\"},\\\"908\\\":{\\\"Abstract\\\":\\\"Animation is an effective way to show how time-varying phenomena evolve over time. A key issue of generating a good animation is to select ideal views through which the user can perceive the maximum amount of information from the time-varying dataset. In this paper, we first propose an improved view selection method for static data. The method measures the quality of a static view by analyzing the opacity, color and curvature distributions of the corresponding volume rendering images from the given view. Our view selection metric prefers an even opacity distribution with a larger projection area, a larger area of salient features' colors with an even distribution among the salient features, and more perceived curvatures. We use this static view selection method and a dynamic programming approach to select time-varying views. The time-varying view selection maximizes the information perceived from the time-varying dataset based on the constraints that the time-varying view should show smooth changes of direction and near-constant speed. We also introduce a method that allows the user to generate a smooth transition between any two views in a given time step, with the perceived information maximized as well. By combining the static and dynamic view selection methods, the users are able to generate a time-varying view that shows the maximum amount of information from a time-varying data set\\\",\\\"Authors\\\":\\\"Guangfeng Ji;Han-Wei Shen\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;ImageBasedDataImageSignalProcessing;InformationTheory;Optimization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.137\\\",\\\"Keywords\\\":\\\"optimization;static view selection;image-based method;information entropy;dynamic view selection\\\",\\\"Keywords_Processed\\\":\\\"optimization;static view selection;image base method;dynamic view selection;information entropy\\\",\\\"Title\\\":\\\"Dynamic View Selection for Time-Varying Volumes\\\"},\\\"909\\\":{\\\"Abstract\\\":\\\"We present empirical studies that consider the effects of stereopsis and simulated aerial perspective on depth perception in translucent volumes. We consider a purely absorptive lighting model, in which light is not scattered or reflected, but is simply absorbed as it passes through the volume. A purely absorptive lighting model is used, for example, when rendering digitally reconstructed radiographs (DRRs), which are synthetic X-ray images reconstructed from CT volumes. Surgeons make use of DRRs in planning and performing operations, so an improvement of depth perception in DRRs may help diagnosis and surgical planning\\\",\\\"Authors\\\":\\\"Kersten, M.A.;Stewart, A.J.;Troje, N.;Ellis, R.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DisplaysGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.139\\\",\\\"Keywords\\\":\\\"x-ray;volume rendering;stereo;stereopsis;radiograph\\\",\\\"Keywords_Processed\\\":\\\"volume render;stereopsis;radiograph;ray;stereo\\\",\\\"Title\\\":\\\"Enhancing Depth Perception in Translucent Volumes\\\"},\\\"910\\\":{\\\"Abstract\\\":\\\"Exploded views are an illustration technique where an object is partitioned into several segments. These segments are displaced to reveal otherwise hidden detail. In this paper we apply the concept of exploded views to volumetric data in order to solve the general problem of occlusion. In many cases an object of interest is occluded by other structures. While transparency or cutaways can be used to reveal a focus object, these techniques remove parts of the context information. Exploded views, on the other hand, do not suffer from this drawback. Our approach employs a force-based model: the volume is divided into a part configuration controlled by a number of forces and constraints. The focus object exerts an explosion force causing the parts to arrange according to the given constraints. We show that this novel and flexible approach allows for a wide variety of explosion-based visualizations including view-dependent explosions. Furthermore, we present a high-quality GPU-based volume ray casting algorithm for exploded views which allows rendering and interaction at several frames per second\\\",\\\"Authors\\\":\\\"Bruckner, S.;Groller, E.\\\",\\\"Clusters\\\":\\\"IllustrativeVisualization;VisualEncodingAndLayoutGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.140\\\",\\\"Keywords\\\":\\\"exploded views;volume rendering;illustrative visualization\\\",\\\"Keywords_Processed\\\":\\\"volume render;illustrative visualization;explode view\\\",\\\"Title\\\":\\\"Exploded Views for Volume Data\\\"},\\\"911\\\":{\\\"Abstract\\\":\\\"In this article we propose a box spline and its variants for reconstructing volumetric data sampled on the Cartesian lattice. In particular we present a tri-variate box spline reconstruction kernel that is superior to tensor product reconstruction schemes in terms of recovering the proper Cartesian spectrum of the underlying function. This box spline produces a C2 reconstruction that can be considered as a three dimensional extension of the well known Zwart-Powell element in 2D. While its smoothness and approximation power are equivalent to those of the tri-cubic B-spline, we illustrate the superiority of this reconstruction on functions sampled on the Cartesian lattice and contrast it to tensor product B-splines. Our construction is validated through a Fourier domain analysis of the reconstruction behavior of this box spline. Moreover, we present a stable method for evaluation of this box spline by means of a decomposition. Through a convolution, this decomposition reduces the problem to evaluation of a four directional box spline that we previously published in its explicit closed form.\\\",\\\"Authors\\\":\\\"Entezari, A.;Mller, T.\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;Interpolation\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.141\\\",\\\"Keywords\\\":\\\"volumetric data interpolation;box spline;reconstruction\\\",\\\"Keywords_Processed\\\":\\\"box spline;volumetric datum interpolation;reconstruction\\\",\\\"Title\\\":\\\"Extensions of the Zwart-Powell Box Spline for Volumetric Data Reconstruction on the Cartesian Lattice\\\"},\\\"912\\\":{\\\"Abstract\\\":\\\"Large scale scientific simulation codes typically run on a cluster of CPUs that write/read time steps to/from a single file system. As data sets are constantly growing in size, this increasingly leads to I/O bottlenecks. When the rate at which data is produced exceeds the available I/O bandwidth, the simulation stalls and the CPUs are idle. Data compression can alleviate this problem by using some CPU cycles to reduce the amount of data needed to be transfered. Most compression schemes, however, are designed to operate offline and seek to maximize compression, not throughput. Furthermore, they often require quantizing floating-point values onto a uniform integer grid, which disqualifies their use in applications where exact values must be retained. We propose a simple scheme for lossless, online compression of floating-point data that transparently integrates into the I/O of many applications. A plug-in scheme for data-dependent prediction makes our scheme applicable to a wide variety of data used in visualization, such as unstructured meshes, point sets, images, and voxel grids. We achieve state-of-the-art compression rates and speeds, the latter in part due to an improved entropy coder. We demonstrate that this significantly accelerates I/O throughput in real simulation runs. Unlike previous schemes, our method also adapts well to variable-precision floating-point and integer data\\\",\\\"Authors\\\":\\\"Lindstrom, P.;Isenburg, M.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;CompressionTechniques;InformationTheory;ProgrammingAlgorithmsAndDataStructures;Simulation\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.143\\\",\\\"Keywords\\\":\\\"lossless compression;range coder;predictive coding;file compaction for i/o efficiency;large-scale simulation and visualization;fast entropy coding;high-throughput\\\",\\\"Keywords_Processed\\\":\\\"high throughput;predictive coding;fast entropy coding;range coder;lossless compression;file compaction for efficiency;large scale simulation and visualization\\\",\\\"Title\\\":\\\"Fast and Efficient Compression of Floating-Point Data\\\"},\\\"913\\\":{\\\"Abstract\\\":\\\"In this paper we describe a GPU-based technique for creating illustrative visualization through interactive manipulation of volumetric models. It is partly inspired by medical illustrations, where it is common to depict cuts and deformation in order to provide a better understanding of anatomical and biological structures or surgical processes, and partly motivated by the need for a real-time solution that supports the specification and visualization of such illustrative manipulation. We propose two new feature aligned techniques, namely surface alignment and segment alignment, and compare them with the axis-aligned techniques which were reported in previous work on volume manipulation. We also present a mechanism for defining features using texture volumes, and methods for computing correct normals for the deformed volume in respect to different alignments. We describe a GPU-based implementation to achieve real-time performance of the techniques and a collection of manipulation operators including peelers, retractors, pliers and dilators which are adaptations of the metaphors and tools used in surgical procedures and medical illustrations. Our approach is directly applicable in medical and biological illustration, and we demonstrate how it works as an interactive tool for focus+context visualization, as well as a generic technique for volume graphics\\\",\\\"Authors\\\":\\\"Correa, C.;Silver, D.;Chen, M.\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;IllustrativeVisualization;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.144\\\",\\\"Keywords\\\":\\\"computer-assisted medical illustration;gpu computing;volume deformation;volume rendering;illustrative visualization;illustrative manipulation\\\",\\\"Keywords_Processed\\\":\\\"volume render;illustrative visualization;gpu computing;volume deformation;illustrative manipulation;computer assist medical illustration\\\",\\\"Title\\\":\\\"Feature Aligned Volume Manipulation for Illustration and Visualization\\\"},\\\"914\\\":{\\\"Abstract\\\":\\\"The pipeline model in visualization has evolved from a conceptual model of data processing into a widely used architecture for implementing visualization systems. In the process, a number of capabilities have been introduced, including streaming of data in chunks, distributed pipelines, and demand-driven processing. Visualization systems have invariably built on stateful programming technologies, and these capabilities have had to be implemented explicitly within the lower layers of a complex hierarchy of services. The good news for developers is that applications built on top of this hierarchy can access these capabilities without concern for how they are implemented. The bad news is that by freezing capabilities into low-level services expressive power and flexibility is lost. In this paper we express visualization systems in a programming language that more naturally supports this kind of processing model. Lazy functional languages support fine-grained demand-driven processing, a natural form of streaming, and pipeline-like function composition for assembling applications. The technology thus appears well suited to visualization applications. Using surface extraction algorithms as illustrative examples, and the lazy functional language Haskell, we argue the benefits of clear and concise expression combined with fine-grained, demand-driven computation. Just as visualization provides insight into data, functional abstraction provides new insight into visualization\\\",\\\"Authors\\\":\\\"Duke, D.;Wallace, M.;Borgo, R.;Runciman, C.\\\",\\\"Clusters\\\":\\\"ProgrammingAlgorithmsAndDataStructures;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.145\\\",\\\"Keywords\\\":\\\"pipeline model;laziness;functional programming\\\",\\\"Keywords_Processed\\\":\\\"laziness;functional programming;pipeline model\\\",\\\"Title\\\":\\\"fine-grained Visualization Pipelines and Lazy Functional Languages\\\"},\\\"915\\\":{\\\"Abstract\\\":\\\"This paper presents a procedure for virtual autopsies based on interactive 3D visualizations of large scale, high resolution data from CT-scans of human cadavers. The procedure is described using examples from forensic medicine and the added value and future potential of virtual autopsies is shown from a medical and forensic perspective. Based on the technical demands of the procedure state-of-the-art volume rendering techniques are applied and refined to enable real-time, full body virtual autopsies involving gigabyte sized data on standard GPUs. The techniques applied include transfer function based data reduction using level-of-detail selection and multi-resolution rendering techniques. The paper also describes a data management component for large, out-of-core data sets and an extension to the GPU-based raycaster for efficient dual TF rendering. Detailed benchmarks of the pipeline are presented using data sets from forensic cases\\\",\\\"Authors\\\":\\\"Ljung, P.;Winskog, C.;Persson, A.;Lundstrom, C.;Ynnerman, A.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;BiomedicalScienceAndMedicine;LargeScaleDataAndScalability;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.146\\\",\\\"Keywords\\\":\\\"volume rendering;medical visualization;forensics;autopsies;large-scale data\\\",\\\"Keywords_Processed\\\":\\\"volume render;forensic;autopsy;large scale datum;medical visualization\\\",\\\"Title\\\":\\\"Full Body Virtual Autopsies using a State-of-the-art Volume Rendering Pipeline\\\"},\\\"916\\\":{\\\"Abstract\\\":\\\"Many sophisticated techniques for the visualization of volumetric data such as medical data have been published. While existing techniques are mature from a technical point of view, managing the complexity of visual parameters is still difficult for nonexpert users. To this end, this paper presents new ideas to facilitate the specification of optical properties for direct volume rendering. We introduce an additional level of abstraction for parametric models of transfer functions. The proposed framework allows visualization experts to design high-level transfer function models which can intuitively be used by non-expert users. The results are user interfaces which provide semantic information for specialized visualization problems. The proposed method is based on principal component analysis as well as on concepts borrowed from computer animation\\\",\\\"Authors\\\":\\\"Salama, C.R.;Keller, M.;Kohlmann, P.\\\",\\\"Clusters\\\":\\\"SemanticsSemioticsRelatedTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.148\\\",\\\"Keywords\\\":\\\"volume rendering;semantic models;transfer function design\\\",\\\"Keywords_Processed\\\":\\\"volume render;transfer function design;semantic model\\\",\\\"Title\\\":\\\"High-Level User Interfaces for Transfer Function Design with Semantics\\\"},\\\"917\\\":{\\\"Abstract\\\":\\\"Isosurfaces are ubiquitous in many fields, including visualization, graphics, and vision. They are often the main computational component of important processing pipelines (e.g., surface reconstruction), and are heavily used in practice. The classical approach to compute isosurfaces is to apply the Marching Cubes algorithm, which although robust and simple to implement, generates surfaces that require additional processing steps to improve triangle quality and mesh size. An important issue is that in some cases, the surfaces generated by Marching Cubes are irreparably damaged, and important details are lost which can not be recovered by subsequent processing. The main motivation of this work is to develop a technique capable of constructing high-quality and high-fidelity isosurfaces. We propose a new advancing front technique that is capable of creating high-quality isosurfaces from regular and irregular volumetric datasets. Our work extends the guidance field framework of Schreiner et al. to implicit surfaces, and improves it in significant ways. In particular, we describe a set of sampling conditions that guarantee that surface features will be captured by the algorithm. We also describe an efficient technique to compute a minimal guidance field, which greatly improves performance. Our experimental results show that our technique can generate high-quality meshes from complex datasets\\\",\\\"Authors\\\":\\\"Schreiner, J.;Scheidegger, C.E.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;IsosurfaceAndSurfaceExtractionTechniques;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.149\\\",\\\"Keywords\\\":\\\"isosurface extraction;curvature;advancing front\\\",\\\"Keywords_Processed\\\":\\\"curvature;isosurface extraction;advance front\\\",\\\"Title\\\":\\\"High-Quality Extraction of Isosurfaces from Regular and Irregular Grids\\\"},\\\"918\\\":{\\\"Abstract\\\":\\\"The Network for computational nanotechnology (NCN) has developed a science gateway at nanoHUB.org for nanotechnology education and research. Remote users can browse through online seminars and courses, and launch sophisticated nanotechnology simulation tools, all within their Web browser. Simulations are supported by a middleware that can route complex jobs to grid supercomputing resources. But what is truly unique about the middleware is the way that it uses hardware accelerated graphics to support both problem setup and result visualization. This paper describes the design and integration of a remote visualization framework into the nanoHUB for interactive visual analytics of nanotechnology simulations. Our services flexibly handle a variety of nanoscience simulations, render them utilizing graphics hardware acceleration in a scalable manner, and deliver them seamlessly through the middleware to the user. Rendering is done only on-demand, as needed, so each graphics hardware unit can simultaneously support many user sessions. Additionally, a novel node distribution scheme further improves our system's scalability. Our approach is not only efficient but also cost-effective. Only half-dozen render nodes are anticipated to support hundreds of active tool sessions on the nanoHUB. Moreover, this architecture and visual analytics environment provides capabilities that can serve many areas of scientific simulation and analysis beyond nanotechnology with its ability to interactively analyze and visualize multivariate scalar and vector fields\\\",\\\"Authors\\\":\\\"Wei Qiao;McLennan, M.;Kennell, R.;Ebert, D.S.;Klimeck, G.\\\",\\\"Clusters\\\":\\\"DistributedSystemsAndGridEnvironments;FlowVisualizationDataAndTechniques;InputAndOutputDevicesGeneral;MaterialScience;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.150\\\",\\\"Keywords\\\":\\\"flow visualization;remote visualization;graphics hardware;volume visualization;nanotechnology simulation\\\",\\\"Keywords_Processed\\\":\\\"graphic hardware;nanotechnology simulation;flow visualization;volume visualization;remote visualization\\\",\\\"Title\\\":\\\"Hub-based Simulation and Graphics Hardware Accelerated Visualization for Nanotechnology Applications\\\"},\\\"919\\\":{\\\"Abstract\\\":\\\"Diffusion tensor imaging is of high value in neurosurgery, providing information about the location of white matter tracts in the human brain. For their reconstruction, streamline techniques commonly referred to as fiber tracking model the underlying fiber structures and have therefore gained interest. To meet the requirements of surgical planning and to overcome the visual limitations of line representations, a new real-time visualization approach of high visual quality is introduced. For this purpose, textured triangle strips and point sprites are combined in a hybrid strategy employing GPU programming. The triangle strips follow the fiber streamlines and are textured to obtain a tube-like appearance. A vertex program is used to orient the triangle strips towards the camera. In order to avoid triangle flipping in case of fiber segments where the viewing and segment direction are parallel, a correct visual representation is achieved in these areas by chains of point sprites. As a result, high quality visualization similar to tubes is provided allowing for interactive multimodal inspection. Overall, the presented approach is faster than existing techniques of similar visualization quality and at the same time allows for real-time rendering of dense bundles encompassing a high number of fibers, which is of high importance for diagnosis and surgical planning\\\",\\\"Authors\\\":\\\"Merhof, D.;Sonntag, M.;Enders, F.;Nimsky, C.;Hastreiter, P.;Greiner, G.\\\",\\\"Clusters\\\":\\\"StreamlinesPathlinesStreaklines;TensorDataAndTechniques;Tractography\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.151\\\",\\\"Keywords\\\":\\\"diffusion tensor data;streamline visualization;fiber tracking\\\",\\\"Keywords_Processed\\\":\\\"fiber tracking;diffusion tensor datum;streamline visualization\\\",\\\"Title\\\":\\\"Hybrid Visualization for White Matter Tracts using Triangle Strips and Point Sprites\\\"},\\\"920\\\":{\\\"Abstract\\\":\\\"This paper introduces a concept for automatic focusing on features within a volumetric data set. The user selects a focus, i.e., object of interest, from a set of pre-defined features. Our system automatically determines the most expressive view on this feature. A characteristic viewpoint is estimated by a novel information-theoretic framework which is based on the mutual information measure. Viewpoints change smoothly by switching the focus from one feature to another one. This mechanism is controlled by changes in the importance distribution among features in the volume. The highest importance is assigned to the feature in focus. Apart from viewpoint selection, the focusing mechanism also steers visual emphasis by assigning a visually more prominent representation. To allow a clear view on features that are normally occluded by other parts of the volume, the focusing for example incorporates cut-away views\\\",\\\"Authors\\\":\\\"Viola, I.;Feixas, M.;Sbert, M.;Groller, E.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;FocusContextTechniques;IllustrativeVisualization;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.152\\\",\\\"Keywords\\\":\\\"illustrative visualization;focus+context technique;interacting with volumetric datasets;characteristic viewpoint estimation;volume visualization\\\",\\\"Keywords_Processed\\\":\\\"illustrative visualization;interact with volumetric dataset;characteristic viewpoint estimation;focus context technique;volume visualization\\\",\\\"Title\\\":\\\"Importance-Driven Focus of Attention\\\"},\\\"921\\\":{\\\"Abstract\\\":\\\"We present an efficient point-based isosurface exploration system with high quality rendering. Our system incorporates two point-based isosurface extraction and visualization methods: edge splatting and the edge kernel method. In a volume, two neighboring voxels define an edge. The intersection points between the active edges and the isosurface are used for exact isosurface representation. The point generation is incorporated in the GPU-based hardware-accelerated rendering, thus avoiding any overhead when changing the isovalue in the exploration. We call this method edge splatting. In order to generate high quality isosurface rendering regardless of the volume resolution and the view, we introduce an edge kernel method. The edge kernel upsamples the isosurface by subdividing every active cell of the volume data. Enough sample points are generated to preserve the exact shape of the isosurface defined by the trilinear interpolation of the volume data. By employing these two methods, we can achieve interactive isosurface exploration with high quality rendering\\\",\\\"Authors\\\":\\\"Zhang, H.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;HardwareAccellerationAndComputationGeneral;IsosurfaceAndSurfaceExtractionTechniques;PointBasedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.153\\\",\\\"Keywords\\\":\\\"isosurface;isosurface extraction;hardware acceleration;gpu acceleration;point-based visualization\\\",\\\"Keywords_Processed\\\":\\\"hardware acceleration;isosurface extraction;point base visualization;isosurface;gpu acceleration\\\",\\\"Title\\\":\\\"Interactive Point-based Isosurface Exploration and High-quality Rendering\\\"},\\\"922\\\":{\\\"Abstract\\\":\\\"Computational simulations frequently generate solutions defined over very large tetrahedral volume meshes containing many millions of elements. Furthermore, such solutions may often be expressed using non-linear basis functions. Certain solution techniques, such as discontinuous Galerkin methods, may even produce non-conforming meshes. Such data is difficult to visualize interactively, as it is far too large to fit in memory and many common data reduction techniques, such as mesh simplification, cannot be applied to non-conforming meshes. We introduce a point-based visualization system for interactive rendering of large, potentially non-conforming, tetrahedral meshes. We propose methods for adaptively sampling points from non-linear solution data and for decimating points at run time to fit GPU memory limits. Because these are streaming processes, memory consumption is independent of the input size. We also present an order-independent point rendering method that can efficiently render volumes on the order of 20 million tetrahedra at interactive rates\\\",\\\"Authors\\\":\\\"Zhou, Y.;Garland, M.\\\",\\\"Clusters\\\":\\\"PointBasedDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.154\\\",\\\"Keywords\\\":\\\"point-based visualization;interactive large higher-order tetrahedral volume visualization\\\",\\\"Keywords_Processed\\\":\\\"interactive large high order tetrahedral volume visualization;point base visualization\\\",\\\"Title\\\":\\\"Interactive Point-Based Rendering of Higher-Order Tetrahedral Data\\\"},\\\"923\\\":{\\\"Abstract\\\":\\\"We present GyVe, an interactive visualization tool for understanding structure in sparse three-dimensional (3D) point data. The scientific goal driving the tool's development is to determine the presence of filaments and voids as defined by inferred 3D galaxy positions within the horologium-reticulum supercluster (HRS). GyVe provides visualization techniques tailored to examine structures defined by the intercluster galaxies. Specific techniques include: interactive user control to move between a global overview and local viewpoints, labelled axes and curved drop lines to indicate positions in the astronomical RA-DEC-cz coordinate system, torsional rocking and stereo to enhance 3D perception, and geometrically distinct glyphs to show potential correlation between intercluster galaxies and known clusters. We discuss the rationale for each design decision and review the success of the techniques in accomplishing the scientific goals. In practice, GyVe has been useful for gaining intuition about structures that were difficult to perceive with 2D projection techniques alone. For example, during their initial session with GyVe, our collaborators quickly confirmed scientific conclusions regarding the large-scale structure of the HRS previously obtained over months of study with 2D projections and statistical techniques. Further use of GyVe revealed the spherical shape of voids and showed that a presumed filament was actually two disconnected structures\\\",\\\"Authors\\\":\\\"Miller, J.;Quammen, C.W.;Fleenor, M.C.\\\",\\\"Clusters\\\":\\\"AstronomyAstrophysics;PointBasedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.155\\\",\\\"Keywords\\\":\\\"astronomy;sparse point visualization;cosmology\\\",\\\"Keywords_Processed\\\":\\\"sparse point visualization;cosmology;astronomy\\\",\\\"Title\\\":\\\"Interactive Visualization of Intercluster Galaxy Structures in the Horologium-Reticulum Supercluster\\\"},\\\"924\\\":{\\\"Abstract\\\":\\\"We propose a novel persistent octree (POT) indexing structure for accelerating isosurface extraction and spatial filtering from volumetric data. This data structure efficiently handles a wide range of visualization problems such as the generation of view-dependent isosurfaces, ray tracing, and isocontour slicing for high dimensional data. POT can be viewed as a hybrid data structure between the interval tree and the branch-on-need octree (BONO) in the sense that it achieves the asymptotic bound of the interval tree for identifying the active cells corresponding to an isosurface and is more efficient than BONO for handling spatial queries. We encode a compact octree for each isovalue. Each such octree contains only the corresponding active cells, in such a way that the combined structure has linear space. The inherent hierarchical structure associated with the active cells enables very fast filtering of the active cells based on spatial constraints. We demonstrate the effectiveness of our approach by performing view-dependent isosurfacing on a wide variety of volumetric data sets and 4D isocontour slicing on the time-varying Richtmyer-Meshkov instability dataset\\\",\\\"Authors\\\":\\\"Shi, Q.;JaJa, J.\\\",\\\"Clusters\\\":\\\"DataAcquisitionAndManagement;IsosurfaceAndSurfaceExtractionTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.157\\\",\\\"Keywords\\\":\\\"isosurface extraction;scientific visualization;indexing\\\",\\\"Keywords_Processed\\\":\\\"scientific visualization;indexing;isosurface extraction\\\",\\\"Title\\\":\\\"Isosurface Extraction and Spatial filtering using Persistent Octree (POT)\\\"},\\\"925\\\":{\\\"Abstract\\\":\\\"Computer-aided diagnosis (CAD) is a helpful addition to laborious visual inspection for preselection of suspected colonic polyps in virtual colonoscopy. Most of the previous work on automatic polyp detection makes use of indicators based on the scalar curvature of the colon wall and can result in many false-positive detections. Our work tries to reduce the number of false-positive detections in the preselection of polyp candidates. Polyp surface shape can be characterized and visualized using lines of curvature. In this paper, we describe techniques for generating and rendering lines of curvature on surfaces and we show that these lines can be used as part of a polyp detection approach. We have adapted existing approaches on explicit triangular surface meshes, and developed a new algorithm on implicit surfaces embedded in 3D volume data. The visualization of shaded colonic surfaces can be enhanced by rendering the derived lines of curvature on these surfaces. Features strongly correlated with true-positive detections were calculated on lines of curvature and used for the polyp candidate selection. We studied the performance of these features on 5 data sets that included 331 pre-detected candidates, of which 50 sites were true polyps. The winding angle had a significant discriminating power for true-positive detections, which was demonstrated by a Wilcoxon rank sum test with p<0.001. The median winding angle and inter-quartile range (IQR) for true polyps were 7.817 and 6.770-9.288 compared to 2.954 and 1.995-3.749 for false-positive detections\\\",\\\"Authors\\\":\\\"Zhao, L.;Botha, C.P.;Bescos, J.O.;Truyen, R.;Vos, F.M.;Post, F.H.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;CurvesAndCurvature;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.158\\\",\\\"Keywords\\\":\\\"line of curvature;medical visualization;virtual colonoscopy;polyp detection;implicit surfaces\\\",\\\"Keywords_Processed\\\":\\\"implicit surface;virtual colonoscopy;polyp detection;line of curvature;medical visualization\\\",\\\"Title\\\":\\\"Lines of Curvature for Polyp Detection in Virtual Colonoscopy\\\"},\\\"926\\\":{\\\"Abstract\\\":\\\"In multiresolution volume visualization, a visual representation of level-of-detail (LOD) quality is important for us to examine, compare, and validate different LOD selection algorithms. While traditional methods rely on ultimate images for quality measurement, we introduce the LOD map - an alternative representation of LOD quality and a visual interface for navigating multiresolution data exploration. Our measure for LOD quality is based on the formulation of entropy from information theory. The measure takes into account the distortion and contribution of multiresolution data blocks. A LOD map is generated through the mapping of key LOD ingredients to a treemap representation. The ordered treemap layout is used for relative stable update of the LOD map when the view or LOD changes. This visual interface not only indicates the quality of LODs in an intuitive way, but also provides immediate suggestions for possible LOD improvement through visually-striking features. It also allows us to compare different views and perform rendering budget control. A set of interactive techniques is proposed to make the LOD adjustment a simple and easy task. We demonstrate the effectiveness and efficiency of our approach on large scientific and medical data sets\\\",\\\"Authors\\\":\\\"Chaoli Wang;Han-Wei Shen\\\",\\\"Clusters\\\":\\\"LevelOfDetail;Perception;Rendering;VisualKnowledgeRepresentationAndExternalization;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.159\\\",\\\"Keywords\\\":\\\"knowledge representation;multi-resolution rendering;perceptual reasoning;level-of-detail map;large volume visualization\\\",\\\"Keywords_Processed\\\":\\\"multi resolution render;level of detail map;perceptual reasoning;knowledge representation;large volume visualization\\\",\\\"Title\\\":\\\"LOD Map - A Visual Interface for Navigating Multiresolution Volume Visualization\\\"},\\\"927\\\":{\\\"Abstract\\\":\\\"Current computer architectures employ caching to improve the performance of a wide variety of applications. One of the main characteristics of such cache schemes is the use of block fetching whenever an uncached data element is accessed. To maximize the benefit of the block fetching mechanism, we present novel cache-aware and cache-oblivious layouts of surface and volume meshes that improve the performance of interactive visualization and geometric processing algorithms. Based on a general I/O model, we derive new cache-aware and cache-oblivious metrics that have high correlations with the number of cache misses when accessing a mesh. In addition to guiding the layout process, our metrics can be used to quantify the quality of a layout, e.g. for comparing different layouts of the same mesh and for determining whether a given layout is amenable to significant improvement. We show that layouts of unstructured meshes optimized for our metrics result in improvements over conventional layouts in the performance of visualization applications such as isosurface extraction and view-dependent rendering. Moreover, we improve upon recent cache-oblivious mesh layouts in terms of performance, applicability, and accuracy\\\",\\\"Authors\\\":\\\"Yoon, S.-E.;Lindstrom, P.\\\",\\\"Clusters\\\":\\\"EvaluationMetricsAndBenchmarks;HardwareAccellerationAndComputationGeneral;ProgrammingAlgorithmsAndDataStructures;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.162\\\",\\\"Keywords\\\":\\\"data locality;mesh and graph layouts;metrics for cache coherence;cache-aware and cache-oblivious layouts\\\",\\\"Keywords_Processed\\\":\\\"mesh and graph layout;cache aware and cache oblivious layout;datum locality;metric for cache coherence\\\",\\\"Title\\\":\\\"Mesh Layouts for Block-Based Caches\\\"},\\\"928\\\":{\\\"Abstract\\\":\\\"Time-varying, multi-variate, and comparative data sets are not easily visualized due to the amount of data that is presented to the user at once. By combining several volumes together with different operators into one visualized volume, the user is able to compare values from different data sets in space over time, run, or field without having to mentally switch between different renderings of individual data sets. In this paper, we propose using a volume shader where the user is given the ability to easily select and operate on many data volumes to create comparison relationships. The user specifies an expression with set and numerical operations and her data to see relationships between data fields. Furthermore, we render the contextual information of the volume shader by converting it to a volume tree. We visualize the different levels and nodes of the volume tree so that the user can see the results of suboperations. This gives the user a deeper understanding of the final visualization, by seeing how the parts of the whole are operationally constructed\\\",\\\"Authors\\\":\\\"Woodring, J.;Shen, H.-W.\\\",\\\"Clusters\\\":\\\"ComparisonComparativeVisualizationAndSimilarity;FocusContextTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.164\\\",\\\"Keywords\\\":\\\"multivariate;comparative;time-varying;focus+context\\\",\\\"Keywords_Processed\\\":\\\"comparative;time vary;focus context;multivariate\\\",\\\"Title\\\":\\\"Multi-variate, Time Varying, and Comparative Visualization with Contextual Cues\\\"},\\\"929\\\":{\\\"Abstract\\\":\\\"We present an approach to visualizing correlations in 3D multifield scalar data. The core of our approach is the computation of correlation fields, which are scalar fields containing the local correlations of subsets of the multiple fields. While the visualization of the correlation fields can be done using standard 3D volume visualization techniques, their huge number makes selection and handling a challenge. We introduce the multifield-graph to give an overview of which multiple fields correlate and to show the strength of their correlation. This information guides the selection of informative correlation fields for visualization. We use our approach to visually analyze a number of real and synthetic multifield datasets\\\",\\\"Authors\\\":\\\"Sauber, N.;Theisel, H.;Seidel, H.-P.\\\",\\\"Clusters\\\":\\\"MachineLearningAndStatistics;MultidimensionalMultivariateMultifieldDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.165\\\",\\\"Keywords\\\":\\\"visualization;correlation;multi-field\\\",\\\"Keywords_Processed\\\":\\\"visualization;correlation;multi field\\\",\\\"Title\\\":\\\"Multifield-Graphs: An Approach to Visualizing Correlations in Multifield Scalar Data\\\"},\\\"930\\\":{\\\"Abstract\\\":\\\"This paper presents a method for occlusion-free animation of geographical landmarks, and its application to a new type of car navigation system in which driving routes of interest are always visible. This is achieved by animating a nonperspective image where geographical landmarks such as mountain tops and roads are rendered as if they are seen from different viewpoints. The technical contribution of this paper lies in formulating the nonperspective terrain navigation as an inverse problem of continuously deforming a 3D terrain surface from the 2D screen arrangement of its associated geographical landmarks. The present approach provides a perceptually reasonable compromise between the navigation clarity and visual realism where the corresponding nonperspective view is fully augmented by assigning appropriate textures and shading effects to the terrain surface according to its geometry. An eye tracking experiment is conducted to prove that the present approach actually exhibits visually-pleasing navigation frames while users can clearly recognize the shape of the driving route without occlusion, together with the spatial configuration of geographical landmarks in its neighborhood\\\",\\\"Authors\\\":\\\"Takahashi, S.;Yoshida, K.;Nishita, T.;Shimada, K.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;OcclusionProblemsTechniques;Perception;TimeseriesTimeVaryingDataAndTechniques;Traffic\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.167\\\",\\\"Keywords\\\":\\\"nonperspective projection;visual perception;occlusion-free animation;temporal coherence;car navigation systems\\\",\\\"Keywords_Processed\\\":\\\"visual perception;car navigation system;nonperspective projection;occlusion free animation;temporal coherence\\\",\\\"Title\\\":\\\"Occlusion-Free Animation of Driving Routes for Car Navigation Systems\\\"},\\\"931\\\":{\\\"Abstract\\\":\\\"In this paper, we show that histograms represent spatial function distributions with a nearest neighbour interpolation. We confirm that this results in systematic underrepresentation of transitional features of the data, and provide new insight why this occurs. We further show that isosurface statistics, which use higher quality interpolation, give better representations of the function distribution. We also use our experimentally collected isosurface statistics to resolve some questions as to the formal complexity of isosurfaces\\\",\\\"Authors\\\":\\\"Carr, H.;Duffy, B.;Denby, B.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;IsosurfaceAndSurfaceExtractionTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.168\\\",\\\"Keywords\\\":\\\"isosurface;isosurface statistics;histogram\\\",\\\"Keywords_Processed\\\":\\\"isosurface statistic;histogram;isosurface\\\",\\\"Title\\\":\\\"On Histograms and Isosurface Statistics\\\"},\\\"932\\\":{\\\"Abstract\\\":\\\"We propose an out-of-core method for creating semi-regular surface representations from large input surface meshes. Our approach is based on a streaming implementation of the MAPS remesher of Lee et al. Our remeshing procedure consists of two stages. First, a simplification process is used to obtain the base domain. During simplification, we maintain the mapping information between the input and the simplified meshes. The second stage of remeshing uses the mapping information to produce samples of the output semi-regular mesh. The out-of-core operation of our method is enabled by the synchronous streaming of a simplified mesh and the mapping information stored at the original vertices. The synchronicity of two streaming buffers is maintained using a specially designed write strategy for each buffer. Experimental results demonstrate the remeshing performance of the proposed method, as well as other applications that use the created mapping between the simplified and the original surface representations\\\",\\\"Authors\\\":\\\"Minsu Ahn;Guskov, I.;Seungyong Lee\\\",\\\"Clusters\\\":\\\"CompressionTechniques;MeshesGridsAndLattices;OutOfCoreProcessing\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.169\\\",\\\"Keywords\\\":\\\"semi-regular remeshing;out-of-core algorithm;shape compression\\\",\\\"Keywords_Processed\\\":\\\"out of core algorithm;semi regular remeshing;shape compression\\\",\\\"Title\\\":\\\"Out-of-Core Remeshing of Large Polygonal Meshes\\\"},\\\"933\\\":{\\\"Abstract\\\":\\\"Focus+context visualization integrates a visually accentuated representation of selected data items in focus (more details, more opacity, etc.) with a visually deemphasized representation of the rest of the data, i.e., the context. The role of context visualization is to provide an overview of the data for improved user orientation and improved navigation. A good overview comprises the representation of both outliers and trends. Up to now, however, context visualization not really treated outliers sufficiently. In this paper we present a new approach to focus+context visualization in parallel coordinates which is truthful to outliers in the sense that small-scale features are detected before visualization and then treated specially during context visualization. Generally, we present a solution which enables context visualization at several levels of abstraction, both for the representation of outliers and trends. We introduce outlier detection and context generation to parallel coordinates on the basis of a binned data representation. This leads to an output-oriented visualization approach which means that only those parts of the visualization process are executed which actually affect the final rendering. Accordingly, the performance of this solution is much more dependent on the visualization size than on the data size which makes it especially interesting for large datasets. Previous approaches are outperformed, the new solution was successfully applied to datasets with up to 3 million data records and up to 50 dimensions\\\",\\\"Authors\\\":\\\"Novotny, M.;Hauser, H.\\\",\\\"Clusters\\\":\\\"EventsTrendsOutlierDetectionAnalysisAndVisualization;FocusContextTechniques;LargeScaleDataAndScalability;ParallelCoordinates\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.170\\\",\\\"Keywords\\\":\\\"outliers & trends;focus+context visualization;parallel coordinates;large data visualization\\\",\\\"Keywords_Processed\\\":\\\"focus context visualization;parallel coordinate;large datum visualization;outlier trend\\\",\\\"Title\\\":\\\"Outlier-Preserving Focus+Context Visualization in Parallel Coordinates\\\"},\\\"934\\\":{\\\"Abstract\\\":\\\"We describe a new progressive technique that allows real-time rendering of extremely large tetrahedral meshes. Our approach uses a client-server architecture to incrementally stream portions of the mesh from a server to a client which refines the quality of the approximate rendering until it converges to a full quality rendering. The results of previous steps are re-used in each subsequent refinement, thus leading to an efficient rendering. Our novel approach keeps very little geometry on the client and works by refining a set of rendered images at each step. Our interactive representation of the dataset is efficient, light-weight, and high quality. We present a framework for the exploration of large datasets stored on a remote server with a thin client that is capable of rendering and managing full quality volume visualizations\\\",\\\"Authors\\\":\\\"Callahan, S.P.;Bavoil, L.;Pascucci, V.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"DistributedSystemsAndGridEnvironments;LevelOfDetail;MeshesGridsAndLattices;Rendering;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.171\\\",\\\"Keywords\\\":\\\"large unstructured grids;volume rendering;level-of-detail;progressive rendering;client-server\\\",\\\"Keywords_Processed\\\":\\\"volume render;client server;progressive rendering;level of detail;large unstructured grid\\\",\\\"Title\\\":\\\"Progressive Volume Rendering of Large Unstructured Grids\\\"},\\\"935\\\":{\\\"Abstract\\\":\\\"We present real-time vascular visualization methods, which extend on illustrative rendering techniques to particularly accentuate spatial depth and to improve the perceptive separation of important vascular properties such as branching level and supply area. The resulting visualization can and has already been used for direct projection on a patient's organ in the operation theater where the varying absorption and reflection characteristics of the surface limit the use of color. The important contributions of our work are a GPU-based hatching algorithm for complex tubular structures that emphasizes shape and depth as well as GPU-accelerated shadow-like depth indicators, which enable reliable comparisons of depth distances in a static monoscopic 3D visualization. In addition, we verify the expressiveness of our illustration methods in a large, quantitative study with 160 subjects\\\",\\\"Authors\\\":\\\"Ritter, F.;Hansen, C.;Dicken, V.;Konrad, O.;Preim, B.;Peitgen, H.-O.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;EvaluationGeneral;IllustrativeVisualization;Perception;SocialScienceAndHumanities\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.172\\\",\\\"Keywords\\\":\\\"vessel visualization;spatial perception;illustrative rendering;functional realism;evaluation\\\",\\\"Keywords_Processed\\\":\\\"functional realism;illustrative render;spatial perception;vessel visualization;evaluation\\\",\\\"Title\\\":\\\"Real-Time Illustration of Vascular Structures\\\"},\\\"936\\\":{\\\"Abstract\\\":\\\"Accurately representing higher-order singularities of vector fields defined on piecewise linear surfaces is a non-trivial problem. In this work, we introduce a concise yet complete interpolation scheme of vector fields on arbitrary triangulated surfaces. The scheme enables arbitrary singularities to be represented at vertices. The representation can be considered as a facet-based \\\\\\\"encoding\\\\\\\" of vector fields on piecewise linear surfaces. The vector field is described in polar coordinates over each facet, with a facet edge being chosen as the reference to define the angle. An integer called the period jump is associated to each edge of the triangulation to remove the ambiguity when interpolating the direction of the vector field between two facets that share an edge. To interpolate the vector field, we first linearly interpolate the angle of rotation of the vectors along the edges of the facet graph. Then, we use a variant of Nielson's side-vertex scheme to interpolate the vector field over the entire surface. With our representation, we remove the bound imposed on the complexity of singularities that a vertex can represent by its connectivity. This bound is a limitation generally exists in vertex-based linear schemes. Furthermore, using our data structure, the index of a vertex of a vector field can be combinatorily determined\\\",\\\"Authors\\\":\\\"Li, W.-C.;Vallet, B.;Ray, N.;Levy, B.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;GpuBasedTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.173\\\",\\\"Keywords\\\":\\\"line integral convolution;vector field visualization;higher-order singularities;gpu\\\",\\\"Keywords_Processed\\\":\\\"line integral convolution;gpu;high order singularity;vector field visualization\\\",\\\"Title\\\":\\\"Representing Higher-Order Singularities in Vector fields on Piecewise Linear Surfaces\\\"},\\\"937\\\":{\\\"Abstract\\\":\\\"Recent research in visual saliency has established a computational measure of perceptual importance. In this paper we present a visual-saliency-based operator to enhance selected regions of a volume. We show how we use such an operator on a user-specified saliency field to compute an emphasis field. We further discuss how the emphasis field can be integrated into the visualization pipeline through its modifications of regional luminance and chrominance. Finally, we validate our work using an eye-tracking-based user study and show that our new saliency enhancement operator is more effective at eliciting viewer attention than the traditional Gaussian enhancement operator\\\",\\\"Authors\\\":\\\"Youngmin Kim;Varshney, A.\\\",\\\"Clusters\\\":\\\"Cognition;DataFeaturesAndAttributes;IllustrativeVisualization;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.174\\\",\\\"Keywords\\\":\\\"volume rendering;non-photorealistic rendering;perceptual enhancement;visual attention;saliency\\\",\\\"Keywords_Processed\\\":\\\"volume render;non photorealistic rendering;perceptual enhancement;visual attention;saliency\\\",\\\"Title\\\":\\\"Saliency-guided Enhancement for Volume Visualization\\\"},\\\"938\\\":{\\\"Abstract\\\":\\\"Volumetric datasets with multiple variables on each voxel over multiple time steps are often complex, especially when considering the exponentially large attribute space formed by the variables in combination with the spatial and temporal dimensions. It is intuitive, practical, and thus often desirable, to interactively select a subset of the data from within that high-dimensional value space for efficient visualization. This approach is straightforward to implement if the dataset is small enough to be stored entirely in-core. However, to handle datasets sized at hundreds of gigabytes and beyond, this simplistic approach becomes infeasible and thus, more sophisticated solutions are needed. In this work, we developed a system that supports efficient visualization of an arbitrary subset, selected by range-queries, of a large multivariate time-varying dataset. By employing specialized data structures and schemes of data distribution, our system can leverage a large number of networked computers as parallel data servers, and guarantees a near optimal load-balance. We demonstrate our system of scalable data servers using two large time-varying simulation datasets\\\",\\\"Authors\\\":\\\"Glatter, M.;Mollenhour, C.;Huang, J.;Gao, J.\\\",\\\"Clusters\\\":\\\"LargeScaleDataAndScalability;MultidimensionalMultivariateMultifieldDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.175\\\",\\\"Keywords\\\":\\\"parallel and distributed volume visualization;large data set visualization;multivariate visualization;volume visualization\\\",\\\"Keywords_Processed\\\":\\\"volume visualization;parallel and distribute volume visualization;multivariate visualization;large datum set visualization\\\",\\\"Title\\\":\\\"Scalable Data Servers for Large Multivariate Volume Visualization\\\"},\\\"939\\\":{\\\"Abstract\\\":\\\"Navigating through large-scale virtual environments such as simulations of the astrophysical Universe is difficult. The huge spatial range of astronomical models and the dominance of empty space make it hard for users to travel across cosmological scales effectively, and the problem of wayfinding further impedes the user's ability to acquire reliable spatial knowledge of astronomical contexts. We introduce a new technique called the scalable world-in-miniature (WIM) map as a unifying interface to facilitate travel and wayfinding in a virtual environment spanning gigantic spatial scales: power-law spatial seating enables rapid and accurate transitions among widely separated regions; logarithmically mapped miniature spaces offer a global overview mode when the full context is too large; 3D landmarks represented in the WIM are enhanced by scale, positional, and directional cues to augment spatial context awareness; a series of navigation models are incorporated into the scalable WIM to improve the performance of travel tasks posed by the unique characteristics of virtual cosmic exploration. The scalable WIM user interface supports an improved physical navigation experience and assists pragmatic cognitive understanding of a visualization context that incorporates the features of large-scale astronomy\\\",\\\"Authors\\\":\\\"Li, Y.;Chi-Wing Fu;Hanson, A.J.\\\",\\\"Clusters\\\":\\\"AstronomyAstrophysics;InteractionTechniquesGeneral;LargeScaleDataAndScalability\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.176\\\",\\\"Keywords\\\":\\\"interaction;large-scale exploration;world-in-miniature (wim);astrophysical visualization\\\",\\\"Keywords_Processed\\\":\\\"interaction;large scale exploration;world in miniature wim;astrophysical visualization\\\",\\\"Title\\\":\\\"Scalable WIM: Effective Exploration in Large-scale Astrophysical Environments\\\"},\\\"940\\\":{\\\"Abstract\\\":\\\"We present an evaluation of a parameterized set of 2D icon-based visualization methods where we quantified how perceptual interactions among visual elements affect effective data exploration. During the experiment, subjects quantified three different design factors for each method: the spatial resolution it could represent, the number of data values it could display at each point, and the degree to which it is visually linear. The class of visualization methods includes Poisson-disk distributed icons where icon size, icon spacing, and icon brightness can be set to a constant or coupled to data values from a 2D scalar field. By only coupling one of those visual components to data, we measured filtering interference for all three design factors. Filtering interference characterizes how different levels of the constant visual elements affect the evaluation of the data-coupled element. Our novel experimental methodology allowed us to generalize this perceptual information, gathered using ad-hoc artificial datasets, onto quantitative rules for visualizing real scientific datasets. This work also provides a framework for evaluating visualizations of multi-valued data that incorporate additional visual cues, such as icon orientation or color\\\",\\\"Authors\\\":\\\"Acevedo, D.;Laidlaw, D.H.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;Perception;VisualDesignDesignGuidelines;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.180\\\",\\\"Keywords\\\":\\\"visual design;2d visualization methods;visualization evaluation;perception models;perceptual interactions\\\",\\\"Keywords_Processed\\\":\\\"perceptual interaction;perception model;2d visualization method;visual design;visualization evaluation\\\",\\\"Title\\\":\\\"Subjective Quantification of Perceptual Interactions among some 2D Scientific Visualization Methods\\\"},\\\"941\\\":{\\\"Abstract\\\":\\\"A glyph-based method for visualizing the nematic liquid crystal alignment tensor is introduced. Unlike previous approaches, the glyph is based upon physically-linked metrics, not offsets of the eigenvalues. These metrics, combined with a set of superellipsoid shapes, communicate both the strength of the crystal's uniaxial alignment and the amount of biaxiality. With small modifications, our approach can visualize any real symmetric traceless tensor\\\",\\\"Authors\\\":\\\"Jankun-Kelly, T.J.;Ketan Mehta\\\",\\\"Clusters\\\":\\\"MaterialScience;TensorDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.181\\\",\\\"Keywords\\\":\\\"symmetric traceless tensor;scientific visualization;nematic liquid crystal;tensor visualization\\\",\\\"Keywords_Processed\\\":\\\"scientific visualization;tensor visualization;symmetric traceless tensor;nematic liquid crystal\\\",\\\"Title\\\":\\\"Superellipsoid-based, Real Symmetric Traceless Tensor Glyphs Motivated by Nematic Liquid Crystal Alignment Visualization\\\"},\\\"942\\\":{\\\"Abstract\\\":\\\"We present visualization tools for analyzing molecular simulations of liquid crystal (LC) behavior. The simulation data consists of terabytes of data describing the position and orientation of every molecule in the simulated system over time. Condensed matter physicists study the evolution of topological defects in these data, and our visualization tools focus on that goal. We first convert the discrete simulation data to a sampled version of a continuous second-order tensor field and then use combinations of visualization methods to simultaneously display combinations of contractions of the tensor data, providing an interactive environment for exploring these complicated data. The system, built using AVS, employs colored cutting planes, colored isosurfaces, and colored integral curves to display fields of tensor contractions including Westin's scalar cl, cp , and cs metrics and the principal eigenvector. Our approach has been in active use in the physics lab for over a year. It correctly displays structures already known; it displays the data in a spatially and temporally smoother way than earlier approaches, avoiding confusing grid effects and facilitating the study of multiple time steps; it extends the use of tools developed for visualizing diffusion tensor data, re-interpreting them in the context of molecular simulations; and it has answered long-standing questions regarding the orientation of molecules around defects and the conformational changes of the defects.\\\",\\\"Authors\\\":\\\"Slavin, V.A.;Pelcovits, R.;Loriot, G.;Callan-Jones, A.;Laidlaw, D.H.\\\",\\\"Clusters\\\":\\\"DesignStudiesAndCaseStudies;MaterialScience;MolecularScienceAndChemistry;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.182\\\",\\\"Keywords\\\":\\\"molecular modeling;tensor visualization;liquid crystals;case study\\\",\\\"Keywords_Processed\\\":\\\"molecular modeling;case study;tensor visualization;liquid crystal\\\",\\\"Title\\\":\\\"Techniques for the Visualization of Topological Defect Behavior in Nematic Liquid Crystals\\\"},\\\"943\\\":{\\\"Abstract\\\":\\\"This paper is a contribution to the literature on perceptually optimal visualizations of layered three-dimensional surfaces. Specifically, we develop guidelines for generating texture patterns, which, when tiled on two overlapped surfaces, minimize confusion in depth-discrimination and maximize the ability to localize distinct features. We design a parameterized texture space and explore this texture space using a \\\\\\\"human in the loop\\\\\\\" experimental approach. Subjects are asked to rate their ability to identify Gaussian bumps on both upper and lower surfaces of noisy terrain fields. Their ratings direct a genetic algorithm, which selectively searches the texture parameter space to find fruitful areas. Data collected from these experiments are analyzed to determine what combinations of parameters work well and to develop texture generation guidelines. Data analysis methods include ANOVA, linear discriminant analysis, decision trees, and parallel coordinates. To confirm the guidelines, we conduct a post-analysis experiment, where subjects rate textures following our guidelines against textures violating the guidelines. Across all subjects, textures following the guidelines consistently produce high rated textures on an absolute scale, and are rated higher than those that did not follow the guidelines\\\",\\\"Authors\\\":\\\"Bair, A.;House, D.;Ware, C.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;DimensionalityReduction;EvaluationGeneral;Genetics;HumanComputerInteractionHumanFactors;MachineLearningAndStatistics;ParallelCoordinates;Perception;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.183\\\",\\\"Keywords\\\":\\\"layered surfaces;data mining;perception;genetic algorithm;linear discriminant analysis;human-in-the-loop;decision trees;optimal visualization;parallel coordinates\\\",\\\"Keywords_Processed\\\":\\\"parallel coordinate;decision tree;perception;human in the loop;linear discriminant analysis;optimal visualization;datum mining;genetic algorithm;layer surface\\\",\\\"Title\\\":\\\"Texturing of Layered Surfaces for Optimal Viewing\\\"},\\\"944\\\":{\\\"Abstract\\\":\\\"When a heavy fluid is placed above a light fluid, tiny vertical perturbations in the interface create a characteristic structure of rising bubbles and falling spikes known as Rayleigh-Taylor instability. Rayleigh-Taylor instabilities have received much attention over the past half-century because of their importance in understanding many natural and man-made phenomena, ranging from the rate of formation of heavy elements in supernovae to the design of capsules for Inertial Confinement Fusion. We present a new approach to analyze Rayleigh-Taylor instabilities in which we extract a hierarchical segmentation of the mixing envelope surface to identify bubbles and analyze analogous segmentations of fields on the original interface plane. We compute meaningful statistical information that reveals the evolution of topological features and corroborates the observations made by scientists. We also use geometric tracking to follow the evolution of single bubbles and highlight merge/split events leading to the formation of the large and complex structures characteristic of the later stages. In particular we (i) Provide a formal definition of a bubble; (ii) Segment the envelope surface to identify bubbles; (iii) Provide a multi-scale analysis technique to produce statistical measures of bubble growth; (iv) Correlate bubble measurements with analysis of fields on the interface plane; (v) Track the evolution of individual bubbles over time. Our approach is based on the rigorous mathematical foundations of Morse theory and can be applied to a more general class of applications\\\",\\\"Authors\\\":\\\"Laney, D.;Bremer, P.-T.;Mascarenhas, A.;Miller, P.;Pascucci, V.\\\",\\\"Clusters\\\":\\\"MultiresolutionTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.186\\\",\\\"Keywords\\\":\\\"multi-resolution;topology;morse theory\\\",\\\"Keywords_Processed\\\":\\\"multi resolution;morse theory;topology\\\",\\\"Title\\\":\\\"Understanding the Structure of the Turbulent Mixing Layer in Hydrodynamic Instabilities\\\"},\\\"945\\\":{\\\"Abstract\\\":\\\"We present a novel approach to out-of-core time-varying isosurface visualization. We attempt to interactively visualize time-varying datasets which are too large to fit into main memory using a technique which is dramatically different from existing algorithms. Inspired by video encoding techniques, we examine the data differences between time steps to extract isosurface information. We exploit span space extraction techniques to retrieve operations necessary to update isosurface geometry from neighboring time steps. Because only the changes between time steps need to be retrieved from disk, I/O bandwidth requirements are minimized. We apply temporal compression to further reduce disk access and employ a point-based previewing technique that is refined in idle interaction cycles. Our experiments on computational simulation data indicate that this method is an extremely viable solution to large time-varying isosurface visualization. Our work advances the state-of-the-art by enabling all isosurfaces to be represented by a compact set of operations\\\",\\\"Authors\\\":\\\"Waters, K.W.;Co, C.S.;Joy, K.I.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;OutOfCoreProcessing;PointBasedDataAndTechniques;SpaceRelatedSpatialDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.188\\\",\\\"Keywords\\\":\\\"time-varying;span space;point-based rendering;isosurface;out-of-core\\\",\\\"Keywords_Processed\\\":\\\"time vary;span space;isosurface;out of core;point base render\\\",\\\"Title\\\":\\\"Using Difference Intervals for Time-Varying Isosurface Visualization\\\"},\\\"946\\\":{\\\"Abstract\\\":\\\"This paper describes a set of visual cues of contact designed to improve the interactive manipulation of virtual objects in industrial assembly/maintenance simulations. These visual cues display information of proximity, contact and effort between virtual objects when the user manipulates a part inside a digital mock-up. The set of visual cues encloses the apparition of glyphs (arrow, disk, or sphere) when the manipulated object is close or in contact with another part of the virtual environment. Light sources can also be added at the level of contact points. A filtering technique is proposed to decrease the number of glyphs displayed at the same time. Various effects - such as change in color, change in size, and deformation of shape - can be applied to the glyphs as a function of proximity with other objects or amplitude of the contact forces. A preliminary evaluation was conducted to gather the subjective preference of a group of participants during the simulation of an automotive assembly operation. The collected questionnaires showed that participants globally appreciated our visual cues of contact. The changes in color appeared to be preferred concerning the display of distances and proximity information. Size changes and deformation effects appeared to be preferred in terms of perception of contact forces between the parts. Last, light sources were selected to focus the attention of the user on the contact areas\\\",\\\"Authors\\\":\\\"Sreng, J.;Lecuyer, A.;Megard, C.;Andriot, C.\\\",\\\"Clusters\\\":\\\"DataAndAnalysisMetrics;GlyphsGlyphBasedTechniques;Illumination;ImmersiveAndVirtualEnvironments;InputAndOutputDevicesGeneral;Perception;PhysicsAndPhysicalSciences;Simulation\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.189\\\",\\\"Keywords\\\":\\\"glyph;light;proximity;virtual prototyping;force;contact;assembly/maintenance simulation;visual cues\\\",\\\"Keywords_Processed\\\":\\\"force;proximity;visual cue;contact;light;assembly maintenance simulation;virtual prototyping;glyph\\\",\\\"Title\\\":\\\"Using Visual Cues of Contact to Improve Interactive Manipulation of Virtual Objects in Industrial Assembly/Maintenance Simulations\\\"},\\\"947\\\":{\\\"Abstract\\\":\\\"Video visualization is a computation process that extracts meaningful information from original video data sets and conveys the extracted information to users in appropriate visual representations. This paper presents a broad treatment of the subject, following a typical research pipeline involving concept formulation, system development, a path-finding user study, and a field trial with real application data. In particular, we have conducted a fundamental study on the visualization of motion events in videos. We have, for the first time, deployed flow visualization techniques in video visualization. We have compared the effectiveness of different abstract visual representations of videos. We have conducted a user study to examine whether users are able to learn to recognize visual signatures of motions, and to assist in the evaluation of different visualization techniques. We have applied our understanding and the developed techniques to a set of application video clips. Our study has demonstrated that video visualization is both technically feasible and cost-effective. It has provided the first set of evidence confirming that ordinary users can be accustomed to the visual features depicted in video visualizations, and can learn to recognize visual signatures of a variety of motion events\\\",\\\"Authors\\\":\\\"Chen, M.;Hashim, R.R.;Botchen, R.P.;Weiskopf, D.;Ertl, T.;Thornton, I.M.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;FlowVisualizationDataAndTechniques;GpuBasedTechniques;HumanComputerInteractionHumanFactors;ImageBasedDataImageSignalProcessing;MultimediaImageVideoMusic;VisualEncodingAndLayoutGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.194\\\",\\\"Keywords\\\":\\\"flow visualization;user study;video visualization;optical flow;visual signatures;video processing;volume visualization;gpu rendering;human factors\\\",\\\"Keywords_Processed\\\":\\\"user study;human factor;optical flow;gpu render;volume visualization;visual signature;video visualization;video processing;flow visualization\\\",\\\"Title\\\":\\\"Visual Signatures in Video Visualization\\\"},\\\"948\\\":{\\\"Abstract\\\":\\\"In this paper we propose an approach in which interactive visualization and analysis are combined with batch tools for the processing of large data collections. Large and heterogeneous data collections are difficult to analyze and pose specific problems to interactive visualization. Application of the traditional interactive processing and visualization approaches as well as batch processing encounter considerable drawbacks for such large and heterogeneous data collections due to the amount and type of data. Computing resources are not sufficient for interactive exploration of the data and automated analysis has the disadvantage that the user has only limited control and feedback on the analysis process. In our approach, an analysis procedure with features and attributes of interest for the analysis is defined interactively. This procedure is used for offline processing of large collections of data sets. The results of the batch process along with \\\\\\\"visual summaries\\\\\\\" are used for further analysis. Visualization is not only used for the presentation of the result, but also as a tool to monitor the validity and quality of the operations performed during the batch process. Operations such as feature extraction and attribute calculation of the collected data sets are validated by visual inspection. This approach is illustrated by an extensive case study, in which a collection of confocal microscopy data sets is analyzed\\\",\\\"Authors\\\":\\\"de Leeuw, W.;Verschure, P.J.;van Liere, R.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DataFeaturesAndAttributes;LargeScaleDataAndScalability\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.195\\\",\\\"Keywords\\\":\\\"biomedical visualization;features in volume data sets;large data set visualization\\\",\\\"Keywords_Processed\\\":\\\"feature in volume datum set;large datum set visualization;biomedical visualization\\\",\\\"Title\\\":\\\"Visualization and Analysis of Large Data Collections: a Case Study Applied to Confocal Microscopy Data\\\"},\\\"949\\\":{\\\"Abstract\\\":\\\"Thread-like structures are becoming more common in modern volumetric data sets as our ability to image vascular and neural tissue at higher resolutions improves. The thread-like structures of neurons and micro-vessels pose a unique problem in visualization since they tend to be densely packed in small volumes of tissue. This makes it difficult for an observer to interpret useful patterns from the data or trace individual fibers. In this paper we describe several methods for dealing with large amounts of thread-like data, such as data sets collected using knife-edge scanning microscopy (KESM) and serial block-face scanning electron microscopy (SBF-SEM). These methods allow us to collect volumetric data from embedded samples of whole-brain tissue. The neuronal and microvascular data that we acquire consists of thin, branching structures extending over very large regions. Traditional visualization schemes are not sufficient to make sense of the large, dense, complex structures encountered. In this paper, we address three methods to allow a user to explore a fiber network effectively. We describe interactive techniques for rendering large sets of neurons using self-orienting surfaces implemented on the GPU. We also present techniques for rendering fiber networks in a way that provides useful information about flow and orientation. Third, a global illumination framework is used to create high-quality visualizations that emphasize the underlying fiber structure. Implementation details, performance, and advantages and disadvantages of each approach are discussed\\\",\\\"Authors\\\":\\\"Melek, Z.;Mayerich, D.;Yuksel, C.;Keyser, J.\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;Illumination;NeurosciencesAndBrainVisualization;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.197\\\",\\\"Keywords\\\":\\\"gpu acceleration;global illumination;neuron visualization;orientation filtering\\\",\\\"Keywords_Processed\\\":\\\"orientation filtering;neuron visualization;gpu acceleration;global illumination\\\",\\\"Title\\\":\\\"Visualization of fibrous and Thread-like Data\\\"},\\\"950\\\":{\\\"Abstract\\\":\\\"Vortices are undesirable in many applications while indispensable in others. It is therefore of common interest to understand their mechanisms of creation. This paper aims at analyzing the transport of vorticity inside incompressible flow. The analysis is based on the vorticity equation and is performed along pathlines which are typically started in upstream direction from vortex regions. Different methods for the quantitative and explorative analysis of vorticity transport are presented and applied to CFD simulations of water turbines. Simulation quality is accounted for by including the errors of meshing and convergence into analysis and visualization. The obtained results are discussed and interpretations with respect to engineering questions are given\\\",\\\"Authors\\\":\\\"Sadlo, F.;Peikert, R.;Sick, M.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;MultipleLinkedCoordinatedViews\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.199\\\",\\\"Keywords\\\":\\\"flow visualization;vorticity transport;linked views;unsteady flow\\\",\\\"Keywords_Processed\\\":\\\"link view;unsteady flow;vorticity transport;flow visualization\\\",\\\"Title\\\":\\\"Visualization Tools for Vorticity Transport Analysis in Incompressible Flow\\\"},\\\"951\\\":{\\\"Abstract\\\":\\\"In order to understand complex vortical flows in large data sets, we must be able to detect and visualize vortices in an automated fashion. In this paper, we present a feature-based vortex detection and visualization technique that is appropriate for large computational fluid dynamics data sets computed on unstructured meshes. In particular, we focus on the application of this technique to visualization of the flow over a serrated wing and the flow field around a spinning missile with dithering canards. We have developed a core line extraction technique based on the observation that vortex cores coincide with local extrema in certain scalar fields. We also have developed a novel technique to handle complex vortex topology that is based on k-means clustering. These techniques facilitate visualization of vortices in simulation data that may not be optimally resolved or sampled. Results are included that highlight the strengths and weaknesses of our approach. We conclude by describing how our approach can be improved to enhance robustness and expand its range of applicability\\\",\\\"Authors\\\":\\\"Jankun-Kelly, M.;Jiang, M.;Thompson, D.;Machiraju, R.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/TVCG.2006.201\\\",\\\"Keywords\\\":\\\"vortex detection;feature mining;vortex visualization\\\",\\\"Keywords_Processed\\\":\\\"vortex detection;vortex visualization;feature mining\\\",\\\"Title\\\":\\\"Vortex Visualization for Practical Engineering Applications\\\"},\\\"952\\\":{\\\"Abstract\\\":\\\"Intelligence analysis often involves the task of gathering information about an organization. Knowledge about individuals in an organization and their relationships, often represented as a hierarchical organization chart, is crucial for understanding the organization. However, it is difficult for intelligence analysts to follow all individuals in an organization. Existing hierarchy visualizations have largely focused on the visualization of fixed structures and can not effectively depict the evolution of a hierarchy over time. We introduce TimeTree, a novel visualization tool designed to enable exploration of a changing hierarchy. TimeTree enables analysts to navigate the history of an organization, identify events associated with a specific entity (visualized on a TimeSlider), and explore an aggregate view of an individual's career path (a CareerTree). We demonstrate the utility of TimeTree by investigating a set of scenarios developed by an expert intelligence analyst. The scenarios are evaluated using a real dataset composed of eighteen thousand career events from more than eight thousand individuals. Insights gained from this analysis are presented\\\",\\\"Authors\\\":\\\"Card, S.K.;Suh, B.;Pendleton, B.A.;Heer, J.;Bodnar, J.W.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots;HierarchicalTreeDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261450\\\",\\\"Keywords\\\":\\\"doi tree;time-series data;tree visualization;timetree;organizational chart;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"organizational chart;doi tree;tree visualization;timetree;visual analytic;time series datum\\\",\\\"Title\\\":\\\"Time Tree: Exploring Time Changing Hierarchies\\\"},\\\"953\\\":{\\\"Abstract\\\":\\\"Spatio-temporal relationships among features extracted from temporally-varying scientific datasets can provide useful information about the evolution of an individual feature and its interactions with other features. However, extracting such useful relationships without user guidance is cumbersome and often an error prone process. In this paper, we present a visual analysis system that interactively discovers such relationships from the trajectories of derived features. We describe analysis algorithms to derive various spatial and spatio-temporal relationships. A visual interface is presented using which the user can interactively select spatial and temporal extents to guide the knowledge discovery process. We show the usefulness of our proposed algorithms on datasets originating from computational fluid dynamics. We also demonstrate how the derived relationships can help in explaining the occurrence of critical events like merging and bifurcation of the vortices\\\",\\\"Authors\\\":\\\"Mehta, S.;Parthasarathy, S.;Machiraju, R.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;AnalysisProcessGeneral;AnimationAndMotion;KnowledgeDiscovery;SpatiotemporalDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261451\\\",\\\"Keywords\\\":\\\"knowledge discovery;scientific analytics;trajectory analysis;visual analytics;feature extraction;spatio-temporal predicates\\\",\\\"Keywords_Processed\\\":\\\"trajectory analysis;feature extraction;knowledge discovery;visual analytic;spatio temporal predicate;scientific analytic\\\",\\\"Title\\\":\\\"Visual Exploration of Spatio-temporal Relationships for Scientific Data\\\"},\\\"954\\\":{\\\"Abstract\\\":\\\"Decade scale oceanic phenomena like El Nino are correlated with weather anomalies all over the globe. Only by understanding the events that produced the climatic conditions in the past will it be possible to forecast abrupt climate changes and prevent disastrous consequences for human beings and their environment. Paleoceanography research is a collaborative effort that requires the analysis of paleo time-series, which are obtained from a number of independent techniques and instruments and produced by a variety of different researchers and/or laboratories. The complexity of these phenomena that consist of massive, dynamic and often conflicting data can only be faced by means of analytical reasoning supported by a highly interactive visual interface. This paper presents an interactive visual analysis environment for paleoceanography that permits to gain insight into the paleodata and allow the control and steering of the analytical methods involved in the reconstruction of the climatic conditions of the past\\\",\\\"Authors\\\":\\\"Theron, R.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;MultipleLinkedCoordinatedViews;ParallelCoordinates;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261452\\\",\\\"Keywords\\\":\\\"multiple linked views;exploratory data analysis;information visualization;parallel coordinates\\\",\\\"Keywords_Processed\\\":\\\"parallel coordinate;exploratory datum analysis;information visualization;multiple link view\\\",\\\"Title\\\":\\\"Visual Analytics of Paleoceanographic Conditions\\\"},\\\"955\\\":{\\\"Abstract\\\":\\\"Understanding the space and time characteristics of human interaction in complex social networks is a critical component of visual tools for intelligence analysis, consumer behavior analysis, and human geography. Visual identification and comparison of patterns of recurring events is an essential feature of such tools. In this paper, we describe a tool for exploring hotel visitation patterns in and around Rebersburg, Pennsylvania from 1898-1900. The tool uses a wrapping spreadsheet technique, called reruns, to display cyclic patterns of geographic events in multiple overlapping natural and artificial calendars. Implemented as an improvise visualization, the tool is in active development through a iterative process of data collection, hypothesis, design, discovery, and evaluation in close collaboration with historical geographers. Several discoveries have inspired ongoing data collection and plans to expand exploration to include historic weather records and railroad schedules. Distributed online evaluations of usability and usefulness have resulted in numerous feature and design recommendations\\\",\\\"Authors\\\":\\\"Weaver, C.;Fyfe, D.;Robinson, A.;Holdsworth, D.;Peuquet, D.;MacEachren, A.M.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;ApplicationsGeneralAndOther;GeographyGeospatialVisCartographyTerrainVis;MultipleLinkedCoordinatedViews\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261428\\\",\\\"Keywords\\\":\\\"exploratory visualization;travel pattern analysis;historical geography;coordinated & multiple views;geovisualization\\\",\\\"Keywords_Processed\\\":\\\"historical geography;geovisualization;exploratory visualization;coordinate multiple view;travel pattern analysis\\\",\\\"Title\\\":\\\"Visual Analysis of Historic Hotel Visitation Patterns\\\"},\\\"956\\\":{\\\"Abstract\\\":\\\"Visualizing and analyzing social networks is a challenging problem that has been receiving growing attention. An important first step, before analysis can begin, is ensuring that the data is accurate. A common data quality problem is that the data may inadvertently contain several distinct references to the same underlying entity; the process of reconciling these references is called entity-resolution. D-Dupe is an interactive tool that combines data mining algorithms for entity resolution with a task-specific network visualization. Users cope with complexity of cleaning large networks by focusing on a small subnetwork containing a potential duplicate pair. The subnetwork highlights relationships in the social network, making the common relationships easy to visually identify. D-Dupe users resolve ambiguities either by merging nodes or by marking them distinct. The entity resolution process is iterative: as pairs of nodes are resolved, additional duplicates may be revealed; therefore, resolution decisions are often chained together. We give examples of how users can flexibly apply sequences of actions to produce a high quality entity resolution result. We illustrate and evaluate the benefits of D-Dupe on three bibliographic collections. Two of the datasets had already been cleaned, and therefore should not have contained duplicates; despite this fact, many duplicates were rapidly identified using D-Dupe's unique combination of entity resolution algorithms within a task-specific visual interface\\\",\\\"Authors\\\":\\\"Bilgic, M.;Licamele, L.;Getoor, L.;Shneiderman, B.\\\",\\\"Clusters\\\":\\\"DataCleaningAndSmoothing;DatabasesAndDataMining;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261429\\\",\\\"Keywords\\\":\\\"visual data mining;user interface;data cleaning and integration;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;datum cleaning and integration;visual datum mining;user interface\\\",\\\"Title\\\":\\\"D-Dupe: An Interactive Tool for Entity Resolution in Social Networks\\\"},\\\"957\\\":{\\\"Abstract\\\":\\\"A visual investigation involves both the examination of existing information and the synthesis of new analytic knowledge. This is a progressive process in which newly synthesized knowledge becomes the foundation for future discovery. In this paper, we present a novel system supporting interactive, progressive synthesis of analytic knowledge. Here we use the term \\\\\\\"analytic knowledge\\\\\\\" to refer to concepts that a user derives from existing data along with the evidence supporting such concepts. Unlike existing visual analytic-tools, which typically support only exploration of existing information, our system offers two unique features. First, we support user-system cooperative visual synthesis of analytic knowledge from existing data. Specifically, users can visually define new concepts by annotating existing information, and refine partially formed concepts by linking additional evidence or manipulating related concepts. In response to user actions, our system can automatically manage the evolving corpus of synthesized knowledge and its corresponding evidence. Second, we support progressive visual analysis of synthesized knowledge. This feature allows analysts to visually explore both existing knowledge and synthesized knowledge, dynamically incorporating earlier analytic conclusions into the ensuing discovery process. We have applied our system to two complex but very different analytic applications. Our preliminary evaluation shows the promise of our work\\\",\\\"Authors\\\":\\\"Gotz, D.;Zhou, M.X.;Aggarwal, V.\\\",\\\"Clusters\\\":\\\"KnowledgeDiscovery;PrivacySecurityIntelligenceAnalysis;ReasoningProblemSolvingAndDecisionMaking;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261430\\\",\\\"Keywords\\\":\\\"visual knowledge discovery;intelligence analysis;visual analytics;problem solving environments\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;visual knowledge discovery;problem solve environment;intelligence analysis\\\",\\\"Title\\\":\\\"Interactive Visual Synthesis of Analytic Knowledge\\\"},\\\"958\\\":{\\\"Abstract\\\":\\\"Understanding the nature and dynamics of conflicting opinions is a profound and challenging issue. In this paper we address several aspects of the issue through a study of more than 3,000 Amazon customer reviews of the controversial bestseller The Da Vinci Code, including 1,738 positive and 918 negative reviews. The study is motivated by critical questions such as: what are the differences between positive and negative reviews? What is the origin of a particular opinion? How do these opinions change over time? To what extent can differentiating features be identified from unstructured text? How accurately can these features predict the category of a review? We first analyze terminology variations in these reviews in terms of syntactic, semantic, and statistic associations identified by TermWatch and use term variation patterns to depict underlying topics. We then select the most predictive terms based on log likelihood tests and demonstrate that this small set of terms classifies over 70% of the conflicting reviews correctly. This feature selection process reduces the dimensionality of the feature space from more than 20,000 dimensions to a couple of hundreds. We utilize automatically generated decision trees to facilitate the understanding of conflicting opinions in terms of these highly predictive terms. This study also uses a number of visualization and modeling tools to identify not only what positive and negative reviews have in common, but also they differ and evolve over time\\\",\\\"Authors\\\":\\\"Chen, C.;Ibekwe-SanJuan, F.;SanJuan, E.;Weaver, C.\\\",\\\"Clusters\\\":\\\"KnowledgeDiscovery;PrivacySecurityIntelligenceAnalysis;ReasoningProblemSolvingAndDecisionMaking;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261431\\\",\\\"Keywords\\\":\\\"visual knowledge discovery;intelligence analysis;visual analytics;problem solving environments\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;visual knowledge discovery;problem solve environment;intelligence analysis\\\",\\\"Title\\\":\\\"Visual Analysis of Conflicting Opinions\\\"},\\\"959\\\":{\\\"Abstract\\\":\\\"A semantic graph is a network of heterogeneous nodes and links annotated with a domain ontology. In intelligence analysis, investigators use semantic graphs to organize concepts and relationships as graph nodes and links in hopes of discovering key trends, patterns, and insights. However, as new information continues to arrive from a multitude of sources, the size and complexity of the semantic graphs will soon overwhelm an investigator's cognitive capacity to carry out significant analyses. We introduce a powerful visual analytics framework designed to enhance investigators' natural analytical capabilities to comprehend and analyze large semantic graphs. The paper describes the overall framework design, presents major development accomplishments to date, and discusses future directions of a new visual analytics system known as Have Green\\\",\\\"Authors\\\":\\\"Pak Chung Wong;Chin, G.;Foote, H.;Mackey, P.;Thomas, J.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;GraphNetworkDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261432\\\",\\\"Keywords\\\":\\\"information visualization;information analytics;graph and network visualization;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;information analytic;information visualization;graph and network visualization\\\",\\\"Title\\\":\\\"Have Green - A Visual Analytics Framework for Large Semantic Graphs\\\"},\\\"960\\\":{\\\"Abstract\\\":\\\"In this paper, we have developed a novel visualization framework to enable more effective visual analysis of large-scale news videos, where keyframes and keywords are automatically extracted from news video clips and visually represented according to their interestingness measurement to help audiences rind news stories of interest at first glance. A computational approach is also developed to quantify the interestingness measurement of video clips. Our experimental results have shown that our techniques for intelligent news video analysis have the capacity to enable more effective visualization of large-scale news videos. Our news video visualization system is very useful for security applications and for general audiences to quickly find news topics of interest from among many channels\\\",\\\"Authors\\\":\\\"Hangzai Luo;Jianping Fan;Jing Yang;Ribarsky, W.;Satoh, S.\\\",\\\"Clusters\\\":\\\"MultimediaImageVideoMusic;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261433\\\",\\\"Keywords\\\":\\\"news visualization;semantic video classification\\\",\\\"Keywords_Processed\\\":\\\"semantic video classification;news visualization\\\",\\\"Title\\\":\\\"Exploring Large-Scale Video News via Interactive Visualization\\\"},\\\"961\\\":{\\\"Abstract\\\":\\\"Mobile devices are rapidly gaining popularity due to their small size and their wide range of functionality. With the constant improvement in wireless network access, they are an attractive option not only for day to day use. but also for in-field analytics by first responders in widespread areas. However, their limited processing, display, graphics and power resources pose a major challenge in developing effective applications. Nevertheless, they are vital for rapid decision making in emergencies when combined with appropriate analysis tools. In this paper, we present an efficient, interactive visual analytic system using a PDA to visualize network information from Purdue's Ross-Ade Stadium during football games as an example of in-held data analytics combined with text and video analysis. With our system, we can monitor the distribution of attendees with mobile devices throughout the stadium through their access of information and association/disassociation from wireless access points, enabling the detection of crowd movement and event activity. Through correlative visualization and analysis of synchronized video (instant replay video) and text information (play statistics) with the network activity, we can provide insightful information to network monitoring personnel, safety personnel and analysts. This work provides a demonstration and testbed for mobile sensor analytics that will help to improve network performance and provide safety personnel with information for better emergency planning and guidance\\\",\\\"Authors\\\":\\\"Pattath, A.;Bue, B.;Yun Jang;Ebert, D.S.;Xuan Zhong;Aulf, A.;Coyle, E.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;SmallMobileUbiquitousDevicesDisplays;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261434\\\",\\\"Keywords\\\":\\\"mobile visualization;visual analytics;network visualization\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;mobile visualization;network visualization\\\",\\\"Title\\\":\\\"Interactive Visualization and Analysis of Network and Sensor Data on Mobile Devices\\\"},\\\"962\\\":{\\\"Abstract\\\":\\\"Networks have remained a challenge for information retrieval and visualization because of the rich set of tasks that users want to accomplish. This paper offers an abstract content-actor network data model, a classification of tasks, and a tool to support them. The NetLens interface was designed around the abstract content-actor network data model to allow users to pose a series of elementary queries and iteratively refine visual overviews and sorted lists. This enables the support of complex queries that are traditionally hard to specify. NetLens is general and scalable in that it applies to any dataset that can be represented with our abstract data model. This paper describes NetLens applying a subset of the ACM Digital Library consisting of about 4,000 papers from the CM I conference written by about 6,000 authors. In addition, we are now working on a collection of half a million emails, and a dataset of legal cases\\\",\\\"Authors\\\":\\\"Hyunmo Kang;Plaisant, C.;Bongshin Lee;Bederson, B.B.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;GraphNetworkDataAndTechniques;HumanComputerInteractionHumanFactors;QueriesAndSearch;TextDocumentTopicAnalysisDataAndTechniques;UserInterfacesGeneral;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261426\\\",\\\"Keywords\\\":\\\"information visualization;user interface;iterative query refinement;digital library;piccolo;incremental data exploration;human-computer interaction;content-actor network data;network visualization\\\",\\\"Keywords_Processed\\\":\\\"content actor network datum;network visualization;digital library;user interface;human computer interaction;information visualization;incremental datum exploration;iterative query refinement;piccolo\\\",\\\"Title\\\":\\\"NetLens: Iterative Exploration of Content-Actor Network Data\\\"},\\\"963\\\":{\\\"Abstract\\\":\\\"Wormhole attacks in wireless networks can severely deteriorate the network performance and compromise the security through spoiling the routing protocols and weakening the security enhancements. This paper develops an approach, interactive visualization of wormholes (IVoW), to monitor and detect such attacks in large scale wireless networks in real time. We characterize the topology features of a network under wormhole attacks through the node position changes and visualize the information at dynamically adjusted scales. We integrate an automatic detection algorithm with appropriate user interactions to handle complicated scenarios that include a large number of moving nodes and multiple worm-hole attackers. Various visual forms have been adopted to assist the understanding and analysis of the reconstructed network topology and improve the detection accuracy. Extended simulation has demonstrated that the proposed approach can effectively locate the fake neighbor connections without introducing many false alarms. IVoW does not require the wireless nodes to be equipped with any special hardware, thus avoiding any additional cost. The proposed approach demonstrates that interactive visualization can be successfully combined with network security mechanisms to greatly improve the intrusion detection capabilities\\\",\\\"Authors\\\":\\\"Weichao Wang;Aidong Lu\\\",\\\"Clusters\\\":\\\"ComputerNetworksNetworkSecurity;InteractionTechniquesGeneral;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261435\\\",\\\"Keywords\\\":\\\"interactive detection;wireless networks;wormhole attacks;visualization on network security;topology visualization\\\",\\\"Keywords_Processed\\\":\\\"wormhole attack;visualization on network security;topology visualization;wireless network;interactive detection\\\",\\\"Title\\\":\\\"Interactive Wormhole Detection in Large Scale Wireless Networks\\\"},\\\"964\\\":{\\\"Abstract\\\":\\\"This paper presents a network traffic analysis system that couples visual analysis with a declarative knowledge representation. The system supports multiple iterations of the sense-making loop of analytic reasoning by allowing users to save discoveries as they are found and to reuse them in future iterations. We show how the knowledge representation can be used to improve both the visual representations and the basic analytical tasks of filtering and changing level of detail. We describe how the system can be used to produce models of network patterns, and show results from classifying one day of network traffic in our laboratory\\\",\\\"Authors\\\":\\\"Ling Xiao;Gerth, J.;Hanrahan, P.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;ComputerNetworksNetworkSecurity\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261436\\\",\\\"Keywords\\\":\\\"network traffic visualization;visual analysis\\\",\\\"Keywords_Processed\\\":\\\"visual analysis;network traffic visualization\\\",\\\"Title\\\":\\\"Enhancing Visual Analysis of Network Traffic Using a Knowledge Representation\\\"},\\\"965\\\":{\\\"Abstract\\\":\\\"Realizing operational analytics solutions where large and complex data must be analyzed in a time-critical fashion entails integrating many different types of technology. This paper focuses on an interdisciplinary combination of scientific data management and visualization/analysis technologies targeted at reducing the time required for data filtering, querying, hypothesis testing and knowledge discovery in the domain of network connection data analysis. We show that use of compressed bitmap indexing can quickly answer queries in an interactive visual data analysis application, and compare its performance with two alternatives for serial and parallel filtering/querying on 2.5 billion records' worth of network connection data collected over a period of 42 weeks. Our approach to visual network connection data exploration centers on two primary factors: interactive ad-hoc and multiresolution query formulation and execution over n dimensions and visual display of the n-dimensional histogram results. This combination is applied in a case study to detect a distributed network scan and to then identify the set of remote hosts participating in the attack. Our approach is sufficiently general to be applied to a diverse set of data understanding problems as well as used in conjunction with a diverse set of analysis and visualization tools\\\",\\\"Authors\\\":\\\"Bethel, E.W.;Campbell, S.;Dart, E.;Stockinger, K.;Kesheng Wu\\\",\\\"Clusters\\\":\\\"ComputerNetworksNetworkSecurity;DatabasesAndDataMining;QueriesAndSearch;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261437\\\",\\\"Keywords\\\":\\\"data mining;network security;query-driven visualization;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;query drive visualization;network security;datum mining\\\",\\\"Title\\\":\\\"Accelerating Network Traffic Analytics Using Query-Driven Visualization\\\"},\\\"966\\\":{\\\"Abstract\\\":\\\"Extensive spread of malicious code on the Internet and also within intranets has risen the user's concern about what kind of data is transferred between her or his computer and other hosts on the network. Visual analysis of this kind of information is a challenging task, due to the complexity and volume of the data type considered, and requires special design of appropriate visualization techniques. In this paper, we present a scalable visualization toolkit for analyzing network activity of computer hosts on a network. The visualization combines network packet volume and type distribution information with geographic information, enabling the analyst to use geographic distortion techniques such as the HistoMap technique to become aware of the traffic components in the course of the analysis. The presented analysis tool is especially useful to compare important network load characteristics in a geographically aware display, to relate communication partners, and to identify the type of network traffic occurring. The results of the analysis are helpful in understanding typical network communication activities, and in anticipating potential performance bottlenecks or problems. It is suited for both off-line analysis of historic data, and via animation for on-line monitoring of packet-based network traffic in real time\\\",\\\"Authors\\\":\\\"Keim, D.A.;Mansmann, F.;Schneidewind, J.;Schreck, T.\\\",\\\"Clusters\\\":\\\"ComputerNetworksNetworkSecurity;GeographyGeospatialVisCartographyTerrainVis;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261438\\\",\\\"Keywords\\\":\\\"network traffic monitoring;visual analytics;information visualization and geography-based solu\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;network traffic monitoring;information visualization and geography base solution\\\",\\\"Title\\\":\\\"Monitoring Network Traffic with Radial Traffic Analyzer\\\"},\\\"967\\\":{\\\"Abstract\\\":\\\"We describe a framework for the display of complex, multidimensional data, designed to facilitate exploration, analysis, and collaboration among multiple analysts. This framework aims to support human collaboration by making it easier to share representations, to translate from one point of view to another, to explain arguments, to update conclusions when underlying assumptions change, and to justify or account for decisions or actions. Multidimensional visualization techniques are used with interactive, context-sensitive, and tunable graphs. Visual representations are flexibly generated using a knowledge representation scheme based on annotated logic; this enables not only tracking and fusing different viewpoints, but also unpacking them. Fusing representations supports the creation of multidimensional meta-displays as well as the translation or mapping from one point of view to another. At the same time, analysts also need to be able to unpack one another's complex chains of reasoning, especially if they have reached different conclusions, and to determine the implications, if any, when underlying assumptions or evidence turn out to be false. The framework enables us to support a variety of scenarios as well as to systematically generate and test experimental hypotheses about the impact of different kinds of visual representations upon interactive collaboration by teams of distributed analysts\\\",\\\"Authors\\\":\\\"Brennan, S.E.;Mueller, K.;Zelinsky, G.;Ramakrishnan, I.;Warren, D.S.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"CollaborativeVisualization;DataAcquisitionAndManagement;KnowledgeDiscovery;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261439\\\",\\\"Keywords\\\":\\\"visual analytics;visual knowledge discovery;collaborative and distributed visualization;data management and knowledge representation\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;visual knowledge discovery;collaborative and distribute visualization;data management and knowledge representation\\\",\\\"Title\\\":\\\"Toward a Multi-Analyst, Collaborative Framework for Visual Analytics\\\"},\\\"968\\\":{\\\"Abstract\\\":\\\"We introduce a visual analytics environment for the support of remote-collaborative sense-making activities. Team members use their individual graphical interfaces to collect, organize and comprehend task-relevant information relative to their areas of expertise. A system of computational agents infers possible relationships among information items through the analysis of the spatial and temporal organization and collaborative use of information. The computational agents support the exchange of information among team members to converge their individual contributions. Our system allows users to navigate vast amounts of shared information effectively and remotely dispersed team members to work independently without diverting from common objectives as well as to minimize the necessary amount of verbal communication\\\",\\\"Authors\\\":\\\"Keel, P.E.\\\",\\\"Clusters\\\":\\\"Cognition;CollaborativeVisualization;HumanComputerInteractionHumanFactors;Simulation;SpaceRelatedSpatialDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261415\\\",\\\"Keywords\\\":\\\"spatial information organization;indirect collaboration;sensemaking;agents;visual analytics;indirect human-computer interaction\\\",\\\"Keywords_Processed\\\":\\\"sensemake;visual analytic;indirect collaboration;spatial information organization;agent;indirect human computer interaction\\\",\\\"Title\\\":\\\"Collaborative Visual Analytics: Inferring from the Spatial Organization and Collaborative Use of Information\\\"},\\\"969\\\":{\\\"Abstract\\\":\\\"A new field of research, visual analytics, has been introduced. This has been defined as \\\\\\\"the science of analytical reasoning facilitated by interactive visual interfaces\\\\\\\" (Thomas and Cook, 2005). Visual analytic environments, therefore, support analytical reasoning using visual representations and interactions, with data representations and transformation capabilities, to support production, presentation, and dissemination. As researchers begin to develop visual analytic environments, it is advantageous to develop metrics and methodologies to help researchers measure the progress of their work and understand the impact their work has on the users who work in such environments. This paper presents five areas or aspects of visual analytic environments that should be considered as metrics and methodologies for evaluation are developed. Evaluation aspects need to include usability, but it is necessary to go beyond basic usability. The areas of situation awareness, collaboration, interaction, creativity, and utility are proposed as the five evaluation areas for initial consideration. The steps that need to be undertaken to develop systematic evaluation methodologies and metrics for visual analytic environments are outlined\\\",\\\"Authors\\\":\\\"Scholtz, J.\\\",\\\"Clusters\\\":\\\"EvaluationMetricsAndBenchmarks;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261416\\\",\\\"Keywords\\\":\\\"visualization;metrics;analytic environments\\\",\\\"Keywords_Processed\\\":\\\"visualization;analytic environment;metric\\\",\\\"Title\\\":\\\"Beyond Usability: Evaluation Aspects of Visual Analytic Environments\\\"},\\\"970\\\":{\\\"Abstract\\\":\\\"We have built a visualization system and analysis portal for evaluating the performance of computational linguistics algorithms. Our system focuses on algorithms that classify and cluster documents by assigning weights to words and scoring each document against high dimensional reference concept vectors. The visualization and algorithm analysis techniques include confusion matrices, ROC curves, document visualizations showing word importance, and interactive reports. One of the unique aspects of our system is that the visualizations are thin-client Web-based components built using SVG visualization components\\\",\\\"Authors\\\":\\\"Eick, S.G.;Mauger, J.;Ratner, A.\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;EvaluationGeneral;HardwareAccellerationAndComputationGeneral;InternetWebVisualizationForTheMasses;ProgrammingAlgorithmsAndDataStructures;TextDocumentTopicAnalysisDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261417\\\",\\\"Keywords\\\":\\\"confusion matrices;document categorization;svg;ajax;roc curves;thin-client\\\",\\\"Keywords_Processed\\\":\\\"confusion matrix;roc curve;thin client;document categorization;svg;ajax\\\",\\\"Title\\\":\\\"Visualizing the Performance of Computational Linguistics Algorithms\\\"},\\\"971\\\":{\\\"Abstract\\\":\\\"A great deal of analytical work is done in the context of reading, in digesting the semantics of the material, the identification of important entities, and capturing the relationship between entities. Visual analytic environments, therefore, must encompass reading tools that enable the rapid digestion of large amount of reading material. Other than plain text search, subject indexes, and basic highlighting, tools are needed for rapid foraging of text. In this paper, we describe a technique that presents an enhanced subject index for a book by conceptually reorganizing it to suit particular expressed user information needs. Users first enter information needs via keywords describing the concepts they are trying to retrieve and comprehend. Then our system, called ScentIndex, computes what index entries are conceptually related and reorganizes and displays these index entries on a single page. We also provide a number of navigational cues to help users peruse over this list of index entries and find relevant passages quickly. Compared to regular reading of a paper book, our study showed that users are more efficient and more accurate in finding, comparing, and comprehending material in our system\\\",\\\"Authors\\\":\\\"Chi, E.H.;Lichan Hong;Heiser, J.;Card, S.K.\\\",\\\"Clusters\\\":\\\"HumanComputerInteractionHumanFactors;TextDocumentTopicAnalysisDataAndTechniques;UserInterfacesGeneral;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261418\\\",\\\"Keywords\\\":\\\"ebooks;personalized information access;contextualization;information scent;book index\\\",\\\"Keywords_Processed\\\":\\\"contextualization;information scent;ebook;book index;personalized information access\\\",\\\"Title\\\":\\\"Scentindex: Conceptually Reorganizing Subject Indexes for Reading\\\"},\\\"972\\\":{\\\"Abstract\\\":\\\"Finding patterns of events over time is important in searching patient histories, Web logs, news stories, and criminal activities. This paper presents PatternFinder, an integrated interface for query and result-set visualization for search and discovery of temporal patterns within multivariate and categorical data sets. We define temporal patterns as sequences of events with inter-event time spans. PatternFinder allows users to specify the attributes of events and time spans to produce powerful pattern queries that are difficult to express with other formalisms. We characterize the range of queries PatternFinder supports as users vary the specificity at which events and time spans are defined. Pattern Finder's query capabilities together with coupled ball-and-chain and tabular visualizations enable users to effectively query, explore and analyze event patterns both within and across data entities (e.g. patient histories, terrorist groups, Web logs, etc.)\\\",\\\"Authors\\\":\\\"Fails, J.A.;Karlson, A.;Shahamat, L.;Shneiderman, B.\\\",\\\"Clusters\\\":\\\"QueriesAndSearch;UserInterfacesGeneral\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261421\\\",\\\"Keywords\\\":\\\"temporal query;information visualization;user interface\\\",\\\"Keywords_Processed\\\":\\\"temporal query;information visualization;user interface\\\",\\\"Title\\\":\\\"A Visual Interface for Multivariate Temporal Data: Finding Patterns of Events across Multiple Histories\\\"},\\\"973\\\":{\\\"Abstract\\\":\\\"A variety of user interfaces have been developed to support the querying of hierarchical multi-dimensional data in an OLAP setting such as pivot tables and Polaris. They are used to regularly check portions of a dataset and to explore a new dataset for the first time. In this paper, we establish criteria for OLAP user interface capabilities to facilitate comparison. Two criteria are the number of displayed dimensions along which comparisons can be made and the number of dimensions that are viewable at once - visual comparison depth and width. We argue that interfaces with greater visual comparison depth support regular checking of known data by users that know roughly where to look, while interfaces with greater comparison width support exploration of new data by users that have no a priori starting point and need to scan all dimensions. Pivot tables and Polaris are examples of the former. The main contribution of this paper is to introduce a new scalable interface that uses parallel dimension axis which supports the latter, greater visual comparison width. We compare our approach to both table based and parallel coordinate based interfaces. We present an implementation of our interface SGViewer, user scenarios and provide an evaluation that supports the usability of our interface\\\",\\\"Authors\\\":\\\"Sifer, M.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;ParallelCoordinates;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261422\\\",\\\"Keywords\\\":\\\"visualization;data exploration;parallel coordinates;online analytic processing\\\",\\\"Keywords_Processed\\\":\\\"visualization;parallel coordinate;online analytic processing;datum exploration\\\",\\\"Title\\\":\\\"User Interfaces for the Exploration of Hierarchical Multi-dimensional Data\\\"},\\\"974\\\":{\\\"Abstract\\\":\\\"Real-world data is known to be imperfect, suffering from various forms of defects such as sensor variability, estimation errors, uncertainty, human errors in data entry, and gaps in data gathering. Analysis conducted on variable quality data can lead to inaccurate or incorrect results. An effective visualization system must make users aware of the quality of their data by explicitly conveying not only the actual data content, but also its quality attributes. While some research has been conducted on visualizing uncertainty in spatio-temporal data and univariate data, little work has been reported on extending this capability into multivariate data visualization. In this paper we describe our approach to the problem of visually exploring multivariate data with variable quality. As a foundation, we propose a general approach to defining quality measures for tabular data, in which data may experience quality problems at three granularities: individual data values, complete records, and specific dimensions. We then present two approaches to visual mapping of quality information into display space. In particular, one solution embeds the quality measures as explicit values into the original dataset by regarding value quality and record quality as new data dimensions. The other solution is to superimpose the quality information within the data visualizations using additional visual variables. We also report on user studies conducted to assess alternate mappings of quality attributes to visual variables for the second method. In addition, we describe case studies that expose some of the advantages and disadvantages of these two approaches\\\",\\\"Authors\\\":\\\"Xie Zaixian;Huang Shiping;Ward, M.O.;Rundensteiner, E.A.\\\",\\\"Clusters\\\":\\\"DataCleaningAndSmoothing;MultidimensionalMultivariateMultifieldDataAndTechniques;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261424\\\",\\\"Keywords\\\":\\\"uncertainty visualization;multivariate visualization;data quality\\\",\\\"Keywords_Processed\\\":\\\"multivariate visualization;uncertainty visualization;data quality\\\",\\\"Title\\\":\\\"Exploratory Visualization of Multivariate Data with Variable Quality\\\"},\\\"975\\\":{\\\"Abstract\\\":\\\"Browsing and retrieving images from large image collections are becoming common and important activities. Semantic image analysis techniques, which automatically detect high level semantic contents of images for annotation, are promising solutions toward this problem. However, few efforts have been made to convey the annotation results to users in an intuitive manner to enable effective image browsing and retrieval. There is also a lack of methods to monitor and evaluate the automatic image analysis algorithms due to the high dimensional nature of image data, features, and contents. In this paper, we propose a novel, scalable semantic image browser by applying existing information visualization techniques to semantic image analysis. This browser not only allows users to effectively browse and search in large image databases according to the semantic content of images, but also allows analysts to evaluate their annotation process through interactive visual exploration. The major visualization components of this browser are multi-dimensional scaling (MDS) based image layout, the value and relation (VaR) display that allows effective high dimensional visualization without dimension reduction, and a rich set of interaction tools such as search by sample images and content relationship detection. Our preliminary user study showed that the browser was easy to use and understand, and effective in supporting image browsing and retrieval tasks\\\",\\\"Authors\\\":\\\"Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.O.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;ImageBasedDataImageSignalProcessing;MultidimensionalMultivariateMultifieldDataAndTechniques;SegmentationAndClassification;\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261425\\\",\\\"Keywords\\\":\\\"multi-dimensional visualization;visual analytics;semantic image classification;image layout;image retrieval\\\",\\\"Keywords_Processed\\\":\\\"multi dimensional visualization;semantic image classification;visual analytic;image layout;image retrieval\\\",\\\"Title\\\":\\\"Semantic Image Browser: Bridging Information Visualization with Automated Intelligent Image Analysis\\\"},\\\"976\\\":{\\\"Abstract\\\":\\\"During the last two decades a wide variety of advanced methods for the visual exploration of large data sets have been proposed. For most of these techniques user interaction has become a crucial element, since there are many situations in which a user or an analyst has to select the right parameter settings from among many or select a subset of the available attribute space for the visualization process, in order to construct valuable visualizations that provide insight, into the data and reveal interesting patterns. The right choice of input parameters is often essential, since suboptimal parameter settings or the investigation of irrelevant data dimensions make the exploration process more time consuming and may result in wrong conclusions. In this paper we propose a novel method for automatically determining meaningful parameter- and attribute settings based on the information content of the resulting visualizations. Our technique called Pixnostics, in analogy to Scagnostics (Wilkinson et al., 2005), automatically analyses pixel images resulting from diverse parameter mappings and ranks them according to the potential value for the user. This allows a more effective and more efficient visual data analysis process, since the attribute/parameter space is reduced to meaningful selections and thus the analyst obtains faster insight into the data. Real world applications are provided to show the benefit of the proposed approach\\\",\\\"Authors\\\":\\\"Schneidewind, J.;Sips, M.;Keim, D.A.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VAST.2006.261423\\\",\\\"Keywords\\\":\\\"visualization technique;visual data exploration;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"visual analytic;visualization technique;visual datum exploration\\\",\\\"Title\\\":\\\"Pixnostics: Towards Measuring the Value of Visualization\\\"},\\\"977\\\":{\\\"Abstract\\\":\\\"A recent line of treemap research has focused on layout algorithms that optimize properties such as stability, preservation of ordering information, and aspect ratio of rectangles. No ideal treemap layout algorithm has been found, and so it is natural to explore layouts that produce nonrectangular regions. This note describes a connection between space-filling visualizations and the mathematics of space-filling curves, and uses that connection to characterize a family of layout algorithms which produce nonrectangular regions but enjoy geometric continuity under changes to the data and legibility even for highly unbalanced trees.\\\",\\\"Authors\\\":\\\"Wattenberg, M.\\\",\\\"Clusters\\\":\\\"HierarchicalTreeDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532145\\\",\\\"Keywords\\\":\\\"hierarchy visualization\\\",\\\"Keywords_Processed\\\":\\\"hierarchy visualization\\\",\\\"Title\\\":\\\"A note on space-filling visualizations and space-filling curves\\\"},\\\"978\\\":{\\\"Abstract\\\":\\\"It has long been known that ancient temples were frequently oriented along the cardinal directions or to certain points along the horizon where Sun or Moon rise or set on special days of the year. In the last decades, archaeologists have found evidence of even older building structures buried in the soil, with doorways that also appear to have distinct orientations. This paper presents a novel diagram combining archaeological maps with a folded-apart, flattened view of the whole sky, showing the local horizon and the daily paths of Sun, Moon and brighter stars. By use of this diagram, interesting groupings of astronomical orientation directions, e.g. to certain Sunrise and Sunset points could be identified, which were evidently used to mark certain days of the year. Orientations to a few significant stars very likely indicated the beginning of the agricultural year in the middle neolithic period\\\",\\\"Authors\\\":\\\"Zotti, G.;Groller, E.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;AstronomyAstrophysics;DatabasesAndDataMining\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532123\\\",\\\"Keywords\\\":\\\"archaeology;astronomy;data mining\\\",\\\"Keywords_Processed\\\":\\\"astronomy;archaeology;datum mining\\\",\\\"Title\\\":\\\"A sky dome visualisation for identification of astronomical orientations\\\"},\\\"979\\\":{\\\"Abstract\\\":\\\"Space-filling visualizations, such as the TreeMap, are well suited for displaying the properties of nodes in hierarchies. To browse the contents of the hierarchy, the primary mode of interaction is by drilling down through many successive layers. In this paper we introduce a distortion algorithm based on fisheye and continuous zooming techniques for browsing data in the TreeMap representation. The motivation behind the distortion approach is for assisting users to rapidly browse information displayed in the TreeMap without opening successive layers of the hierarchy. Two experiments were conducted to evaluate the new approach. In the first experiment (N=20) the distortion approach is compared to the drill down method. Results show that subjects are quicker and more accurate in locating targets of interest using the distortion method. The second experiment (N=12) evaluates the effectiveness of the two approaches in a task requiring context, we define as the context browsing task. The results show that subjects are quicker and more accurate in locating targets with the distortion technique in the context browsing task.\\\",\\\"Authors\\\":\\\"Kang Shi;Irani, P.;Li, B.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;HierarchicalTreeDataAndTechniques;InteractionTechniquesGeneral;VisualEncodingAndLayoutGeneral;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532132\\\",\\\"Keywords\\\":\\\"browsing;semantic zoom;space-filling visualization;hierarchy navigation;focus+context;treemap;distortion;drill-down\\\",\\\"Keywords_Processed\\\":\\\"treemap;semantic zoom;hierarchy navigation;distortion;browse;drill down;space fill visualization;focus context\\\",\\\"Title\\\":\\\"An evaluation of content browsing techniques for hierarchical space-filling visualizations\\\"},\\\"980\\\":{\\\"Abstract\\\":\\\"Parallel coordinates are a powerful method for visualizing multidimensional data but, when applied to large data sets, they become cluttered and difficult to read. Star glyphs, on the other hand, can be used to display either the attributes of a data item or the values across all items for a single attribute. Star glyphs may readily provide a quick impression; however, since the full data set require multiple glyphs, overall readings are more difficult. We present parallel glyphs, an interactive integration of the visual representations of parallel coordinates and star glyphs that utilizes the advantages of both representations to offset the disadvantages they have separately. We discuss the role of uniform and stepped colour scales in the visual comparison of non-adjacent items and star glyphs. Parallel glyphs provide capabilities for focus-in-context exploration using two types of lenses and interactions specific to the 3D space.\\\",\\\"Authors\\\":\\\"Fanea, E.;Carpendale, S.;Isenberg, T.\\\",\\\"Clusters\\\":\\\"GlyphsGlyphBasedTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;ParallelCoordinates;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532141\\\",\\\"Keywords\\\":\\\"multi-dimensional data;3d visualization;star glyphs;parallel glyphs;parallel coordinates\\\",\\\"Keywords_Processed\\\":\\\"parallel coordinate;star glyph;multi dimensional datum;parallel glyph;3d visualization\\\",\\\"Title\\\":\\\"An interactive 3D integration of parallel coordinates and star glyphs\\\"},\\\"981\\\":{\\\"Abstract\\\":\\\"We are building an intelligent multimodal conversation system to aid users in exploring large and complex data sets. To tailor to diverse user queries introduced during a conversation, we automate the generation of system responses, including both spoken and visual outputs. In this paper, we focus on the problem of visual context management, a process that dynamically updates an existing visual display to effectively incorporate new information requested by subsequent user queries. Specifically, we develop an optimization based approach to visual context management. Compared to existing approaches, which normally handle predictable visual context updates, our work offers two unique contributions. First, we provide a general computational framework that can effectively manage a visual context for diverse, unanticipated situations encountered in a user system conversation. Moreover, we optimize the satisfaction of both semantic and visual constraints, which otherwise are difficult to balance using simple heuristics. Second, we present an extensible representation model that uses feature based metrics to uniformly define all constraints. We have applied our work to two different applications and our evaluation has shown the promise of this work.\\\",\\\"Authors\\\":\\\"Zhen Wen;Zhou, M.X.;Aggarwal, V.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;AnimationAndMotion;AutomaticAnalysisVisualizationTechniques;InputAndOutputDevicesGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532146\\\",\\\"Keywords\\\":\\\"visual context management;visual momentum;automated generation of visualization;intelligent multimodal interfaces\\\",\\\"Keywords_Processed\\\":\\\"automate generation of visualization;intelligent multimodal interface;visual momentum;visual context management\\\",\\\"Title\\\":\\\"An optimization-based approach to dynamic visual context management\\\"},\\\"982\\\":{\\\"Abstract\\\":\\\"The Name Voyager, a Web based visualization of historical trends in baby naming, has proven remarkably popular. This paper discusses the interaction techniques it uses for smooth visual exploration of thousands of time series. We also describe design decisions behind the application and lessons learned in creating an application that makes do-it-yourself data mining popular. The prime lesson, it is hypothesized, is that an information visualization tool may be fruitfully viewed not as a tool but as part of an online social environment. In other words, to design a successful exploratory data analysis tool, one good strategy is to create a system that enables \\\\\\\"social\\\\\\\" data analysis\\\",\\\"Authors\\\":\\\"Wattenberg, M.\\\",\\\"Clusters\\\":\\\"DesignStudiesAndCaseStudies;HumanComputerInteractionHumanFactors;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532122\\\",\\\"Keywords\\\":\\\"time-varying visualization;design study;human-computer interaction\\\",\\\"Keywords_Processed\\\":\\\"time vary visualization;human computer interaction;design study\\\",\\\"Title\\\":\\\"Baby names, visualization, and social data analysis\\\"},\\\"983\\\":{\\\"Abstract\\\":\\\"The paper describes a novel technique to visualize graphs with extended node and link labels. The lengths of these labels range from a short phrase to a full sentence to an entire paragraph and beyond. Our solution is different from all the existing approaches that almost always rely on intensive computational effort to optimize the label placement problem. Instead, we share the visualization resources with the graph and present the label information in static, interactive, and dynamic modes without the requirement for tackling the intractability issues. This allows us to reallocate the computational resources for dynamic presentation of real time information. The paper includes a user study to evaluate the effectiveness and efficiency of the visualization technique.\\\",\\\"Authors\\\":\\\"Pak Chung Wong;Mackey, P.;Perrine, K.;Eagan, J.;Foote, H.;Thomas, J.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;GraphNetworkDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532131\\\",\\\"Keywords\\\":\\\"information visualization;graph label placement;dynamic animation;graph visualization\\\",\\\"Keywords_Processed\\\":\\\"graph visualization;dynamic animation;information visualization;graph label placement\\\",\\\"Title\\\":\\\"Dynamic visualization of graphs with extended labels\\\"},\\\"984\\\":{\\\"Abstract\\\":\\\"We investigate the use of elastic hierarchies for representing trees, where a single graphical depiction uses a hybrid mixture, or \\\\\\\"interleaving\\\\\\\", of more basic forms at different nodes of the tree. In particular, we explore combinations of node link and treemap forms, to combine the space efficiency of treemaps with the structural clarity of node link diagrams. A taxonomy is developed to characterize the design space of such hybrid combinations. A software prototype is described, which we used to explore various techniques for visualizing, browsing and interacting with elastic hierarchies, such as side by side overview and detail views, highlighting and rubber banding across views, visualization of multiple foci, and smooth animations across transitions. The paper concludes with a discussion of the characteristics of elastic hierarchies and suggestions for research on their properties and uses.\\\",\\\"Authors\\\":\\\"Shengdong Zhao;McGuffin, M.J.;Chignell, M.H.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;GraphNetworkDataAndTechniques;HierarchicalTreeDataAndTechniques;InteractionTechniquesGeneral;MultipleLinkedCoordinatedViews;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532129\\\",\\\"Keywords\\\":\\\"interactive visualization;node-link diagrams;hybrid;overview+detail;combinations;multiple views;treemap;tree;elastic hierarchies;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;treemap;combination;overview detail;multiple view;tree;hybrid;elastic hierarchy;interactive visualization;node link diagram\\\",\\\"Title\\\":\\\"Elastic hierarchies: combining treemaps and node-link diagrams\\\"},\\\"985\\\":{\\\"Abstract\\\":\\\"Cartographers have long used flow maps to show the movement of objects from one location to another, such as the number of people in a migration, the amount of goods being traded, or the number of packets in a network. The advantage of flow maps is that they reduce visual clutter by merging edges. Most flow maps are drawn by hand and there are few computer algorithms available. We present a method for generating flow maps using hierarchical clustering given a set of nodes, positions, and flow data between the nodes. Our techniques are inspired by graph layout algorithms that minimize edge crossings and distort node positions while maintaining their relative position to one another. We demonstrate our technique by producing flow maps for network traffic, census data, and trade data.\\\",\\\"Authors\\\":\\\"Doantam Phan;Ling Xiao;Yeh, R.;Hanrahan, P.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;FlowVisualizationDataAndTechniques;GeographyGeospatialVisCartographyTerrainVis\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532150\\\",\\\"Keywords\\\":\\\"flow map;geographic information systems;hierarchical clustering\\\",\\\"Keywords_Processed\\\":\\\"flow map;hierarchical clustering;geographic information system\\\",\\\"Title\\\":\\\"Flow map layout\\\"},\\\"986\\\":{\\\"Abstract\\\":\\\"We introduce Tukey and Tukey scagnostics and develop graph-theoretic methods for implementing their procedure on large datasets.\\\",\\\"Authors\\\":\\\"Wilkinson, L.;Anand, A.;Grossman, R.\\\",\\\"Clusters\\\":\\\"MachineLearningAndStatistics;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532142\\\",\\\"Keywords\\\":\\\"visualization;statistical graphics\\\",\\\"Keywords_Processed\\\":\\\"visualization;statistical graphic\\\",\\\"Title\\\":\\\"Graph-theoretic scagnostics\\\"},\\\"987\\\":{\\\"Abstract\\\":\\\"We present a method for visual summary of bilateral conflict structures embodied in event data. Such data consists of actors linked by time stamped events, and may be extracted from various sources such as news reports and dossiers. When analyzing political events, it is of particular importance to be able to recognize conflicts and actors involved in them. By projecting actors into a conflict space, we are able to highlight the main opponents in a series of tens of thousands of events, and provide a graphic overview of the conflict structure. Moreover, our method allows for smooth animation of the dynamics of a conflict.\\\",\\\"Authors\\\":\\\"Brandes, U.;Fleischer, D.;Lerner, J.\\\",\\\"Clusters\\\":\\\"EventsTrendsOutlierDetectionAnalysisAndVisualization;TextDocumentTopicAnalysisDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532135\\\",\\\"Keywords\\\":\\\"information visualization;time-dependent visualization;text mining;event analysis\\\",\\\"Keywords_Processed\\\":\\\"event analysis;time dependent visualization;text mining;information visualization\\\",\\\"Title\\\":\\\"Highlighting conflict dynamics in event data\\\"},\\\"988\\\":{\\\"Abstract\\\":\\\"Time series are an important type of data with applications in virtually every aspect of the real world. Often a large number of time series have to be monitored and analyzed in parallel. Sets of time series may show intrinsic hierarchical relationships and varying degrees of importance among the individual time series. Effective techniques for visually analyzing large sets of time series should encode the relative importance and hierarchical ordering of the time series data by size and position, and should also provide a high degree of regularity in order to support comparability by the analyst. In this paper, we present a framework for visualizing large sets of time series. Based on the notion of inter time series importance relationships, we define a set of objective functions that space-filling layout schemes for time series data should obey. We develop an efficient algorithm addressing the identified problems by generating layouts that reflect hierarchy and importance based relationships in a regular layout with favorable aspect ratios. We apply our technique to a number of real world data sets including sales and stock data, and we compare our technique with an aspect ratio aware variant of the well known TreeMap algorithm. The examples show the advantages and practical usefulness of our layout algorithm.\\\",\\\"Authors\\\":\\\"Hao, M.C.;Dayal, U.;Keim, D.A.;Schreck, T.\\\",\\\"Clusters\\\":\\\"TimeseriesTimeVaryingDataAndTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532148\\\",\\\"Keywords\\\":\\\"information visualization;time-series;space-filling layout generation\\\",\\\"Keywords_Processed\\\":\\\"space fill layout generation;time series;information visualization\\\",\\\"Title\\\":\\\"Importance-driven visualization layouts for large time series data\\\"},\\\"989\\\":{\\\"Abstract\\\":\\\"We present a system that allows users to interactively explore complex flow scenarios represented as Sankey diagrams. Our system provides an overview of the flow graph and allows users to zoom in and explore details on demand. The support for quantitative flow tracing across the flow graph as well as representations at different levels of detail facilitate the understanding of complex flow situations. The energy flow in a city serves as a sample scenario for our system. Different forms of energy are distributed within the city and they are transformed into heat, electricity, or other forms of energy. These processes are visualized and interactively explored. In addition our system can be used as a planning tool for the exploration of alternative scenarios by interactively manipulating different parameters in the energy flow network.\\\",\\\"Authors\\\":\\\"Riehmann, P.;Hanfler, M.;Froehlich, B.\\\",\\\"Clusters\\\":\\\"ChartsDiagramsPlots\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532152\\\",\\\"Keywords\\\":\\\"flow diagram;sankey diagram\\\",\\\"Keywords_Processed\\\":\\\"flow diagram;sankey diagram\\\",\\\"Title\\\":\\\"Interactive Sankey diagrams\\\"},\\\"990\\\":{\\\"Abstract\\\":\\\"The general problem of visualizing \\\\\\\"family trees\\\\\\\", or genealogical graphs, in 2D, is considered. A graph theoretic analysis is given, which identifies why genealogical graphs can be difficult to draw. This motivates some novel graphical representations, including one based on a dual tree, a subgraph formed by the union of two trees. Dual trees can be drawn in various styles, including an indented outline style, and allow users to browse general multitrees in addition to genealogical graphs, by transitioning between different dual tree views. A software prototype for such browsing is described, that supports smoothly animated transitions, automatic camera framing, rotation of subtrees, and a novel interaction technique for expanding or collapsing subtrees to any depth with a single mouse drag\\\",\\\"Authors\\\":\\\"McGuffin, M.J.;Balakrishnan, R.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;GraphNetworkDataAndTechniques;HierarchicalTreeDataAndTechniques;SocialScienceAndHumanities;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532124\\\",\\\"Keywords\\\":\\\"kinship;graph drawing;multi-trees;graph browsing and navigation;graph theory;family trees;genealogy\\\",\\\"Keywords_Processed\\\":\\\"graph drawing;kinship;graph browsing and navigation;genealogy;multi tree;graph theory;family tree\\\",\\\"Title\\\":\\\"Interactive visualization of genealogical graphs\\\"},\\\"991\\\":{\\\"Abstract\\\":\\\"Existing system level taxonomies of visualization tasks are geared more towards the design of particular representations than the facilitation of user analytic activity. We present a set of ten low level analysis tasks that largely capture people's activities while employing information visualization tools for understanding data. To help develop these tasks, we collected nearly 200 sample questions from students about how they would analyze five particular data sets from different domains. The questions, while not being totally comprehensive, illustrated the sheer variety of analytic questions typically posed by users when employing information visualization systems. We hope that the presented set of tasks is useful for information visualization system designers as a kind of common substrate to discuss the relative analytic capabilities of the systems. Further, the tasks may provide a form of checklist for system designers.\\\",\\\"Authors\\\":\\\"Amar, R.;Eagan, J.;Stasko, J.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;EvaluationGeneral;KnowledgeDiscovery;Taxonomies;VisualDesignDesignGuidelines\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532136\\\",\\\"Keywords\\\":\\\"analytic activity;knowledge discovery;taxonomy;design;evaluation\\\",\\\"Keywords_Processed\\\":\\\"knowledge discovery;design;taxonomy;evaluation;analytic activity\\\",\\\"Title\\\":\\\"Low-level components of analytic activity in information visualization\\\"},\\\"992\\\":{\\\"Abstract\\\":\\\"Aggregating items can simplify the display of huge quantities of data values at the cost of losing information about the attribute values of the individual items. We propose a distribution glyph, in both two- and three-dimensional forms, which specifically addresses the concept of how the aggregated data is distributed over the possible range of values. It is capable of displaying distribution, variability and extent information for up to four attributes at a time of multivariate, clustered data. User studies validate the concept, showing that both glyphs are just as good as raw data and the 3D glyph is better for answering some questions.\\\",\\\"Authors\\\":\\\"Chlan, E.B.;Rheingans, P.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;MultidimensionalMultivariateMultifieldDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532140\\\",\\\"Keywords\\\":\\\"information visualization;aggregated data;distribution;multivariate visualization\\\",\\\"Keywords_Processed\\\":\\\"aggregate datum;distribution;multivariate visualization;information visualization\\\",\\\"Title\\\":\\\"Multivariate glyphs for multi-object clusters\\\"},\\\"993\\\":{\\\"Abstract\\\":\\\"The discrete nature of categorical data makes it a particular challenge for visualization. Methods that work very well for continuous data are often hardly usable with categorical dimensions. Only few methods deal properly with such data, mostly because of the discrete nature of categorical data, which does not translate well into the continuous domains of space and color. Parallel sets is a new visualization method that adopts the layout of parallel coordinates, but substitutes the individual data points by a frequency based representation. This abstracted view, combined with a set of carefully designed interactions, supports visual data analysis of large and complex data sets. The technique allows efficient work with meta data, which is particularly important when dealing with categorical datasets. By creating new dimensions from existing ones, for example, the user can filter the data according to his or her current needs. We also present the results from an interactive analysis of CRM data using parallel sets. We demonstrate how the flexible layout eases the process of knowledge crystallization, especially when combined with a sophisticated interaction scheme.\\\",\\\"Authors\\\":\\\"Bendix, F.;Kosara, R.;Hauser, H.\\\",\\\"Clusters\\\":\\\"CategoricalDataAndTechniques;DataTypesGeneral;InteractionTechniquesGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532139\\\",\\\"Keywords\\\":\\\"meta information;categorical data;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;categorical datum;meta information\\\",\\\"Title\\\":\\\"Parallel sets: visual analysis of categorical data\\\"},\\\"994\\\":{\\\"Abstract\\\":\\\"We present PRISAD, the first generic rendering infrastructure for information visualization applications that use the accordion drawing technique: rubber sheet navigation with guaranteed visibility for marked areas of interest. Our new rendering algorithms are based on the partitioning of screen space, which allows us to handle dense dataset regions correctly. The algorithms in previous work led to incorrect visual representations because of overculling, and to inefficiencies due to overdrawing multiple items in the same region. Our pixel based drawing infrastructure guarantees correctness by eliminating overculling, and improves rendering performance with tight bounds on overdrawing. PRITree and PRISeq are applications built on PRISAD, with the feature sets of TreeJuxtaposer and SequenceJuxtaposer, respectively. We describe our PRITree and PRISeq dataset traversal algorithms, which are used for efficient rendering, culling, and layout of datasets within the PRISAD framework. We also discuss PRITree node marking techniques, which offer order-of-magnitude improvements to both memory and time performance versus previous range storage and retrieval techniques. Our PRITree implementation features a five fold increase in rendering speed for nontrivial tree structures, and also reduces memory requirements in some real world datasets by up to eight times, so we are able to handle trees of several million nodes. PRISeq renders fifteen times faster and handles datasets twenty times larger than previous work.\\\",\\\"Authors\\\":\\\"Slack, J.;Hildebrand, K.;Munzner, T.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;RealtimeProcessingRenderingAndVisualizationGeneral;Rendering;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532127\\\",\\\"Keywords\\\":\\\"information visualization;progressive rendering;focus+context;realtime rendering\\\",\\\"Keywords_Processed\\\":\\\"realtime render;progressive rendering;information visualization;focus context\\\",\\\"Title\\\":\\\"PRISAD: a partitioned rendering infrastructure for scalable accordion drawing\\\"},\\\"995\\\":{\\\"Abstract\\\":\\\"In order to gain insight into multivariate data, complex structures must be analysed and understood. Parallel coordinates is an excellent tool for visualizing this type of data but has its limitations. This paper deals with one of its main limitations - how to visualize a large number of data items without hiding the inherent structure they constitute. We solve this problem by constructing clusters and using high precision textures to represent them. We also use transfer functions that operate on the high precision textures in order to highlight different aspects of the cluster characteristics. Providing predefined transfer functions as well as the support to draw customized transfer functions makes it possible to extract different aspects of the data. We also show how feature animation can be used as guidance when simultaneously analysing several clusters. This technique makes it possible to visually represent statistical information about clusters and thus guides the user, making the analysis process more efficient.\\\",\\\"Authors\\\":\\\"Johansson, J.;Ljung, P.;Jern, M.;Cooper, M.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;DataClusteringAndAggregation;ParallelCoordinates;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532138\\\",\\\"Keywords\\\":\\\"parallel coordinates;clustering;feature animation;transfer function\\\",\\\"Keywords_Processed\\\":\\\"parallel coordinate;clustering;feature animation;transfer function\\\",\\\"Title\\\":\\\"Revealing structure within clustered parallel coordinates displays\\\"},\\\"996\\\":{\\\"Abstract\\\":\\\"We present an effort to evaluate the possible utility of a new type of 3D glyphs intended for visualizations of multivariate spatial data. They are based on results from vision research suggesting that our perception of metric 3D structure is distorted and imprecise relative to the actual scene before us (e.g., \\\\\\\"metric 3D structure in visualizations\\\\\\\" by M. Lind et al. (2003)); only a class of qualitative properties of the scene is perceived with accuracy. These properties are best characterized as being invariant over affine but not Euclidean transformations. They are related, but not identical to, the non-accidental properties (NAPs) described by Lowe in \\\\\\\"perceptual organization and visual recognition\\\\\\\" (1984) on which the notion of geons is based in \\\\\\\"recognition by components - a theory of image understanding\\\\\\\" by I. Biederman (1987). A large number of possible 3D glyphs for the visualization of spatial data can be constructed using such properties. One group is based on the local sign of surface curvature. We investigated these properties in a visualization experiment. The results are promising and the implications for visualization are discussed.\\\",\\\"Authors\\\":\\\"Forsell, C.;Seipel, S.;Lind, M.\\\",\\\"Clusters\\\":\\\"GlyphsGlyphBasedTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;Perception\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532137\\\",\\\"Keywords\\\":\\\"perception;3d glyphs;multi-dimensional visualization\\\",\\\"Keywords_Processed\\\":\\\"multi dimensional visualization;perception;3d glyph\\\",\\\"Title\\\":\\\"Simple 3D glyphs for spatial multivariate data\\\"},\\\"997\\\":{\\\"Abstract\\\":\\\"Partitioning of geo-spatial data for efficient allocation of resources such as schools and emergency health care services is driven by a need to provide better and more effective services. Partitioning of spatial data is a complex process that depends on numerous factors such as population, costs incurred in deploying or utilizing resources and target capacity of a resource. Moreover, complex data such as population distributions are dynamic i.e. they may change over time. Simple animation may not effectively show temporal changes in spatial data. We propose the use of three temporal visualization techniques -wedges, rings and time slices - to display the nature of change in temporal data in a single view. Along with maximizing resource utilization and minimizing utilization costs, a partition should also ensure the long term effectiveness of the plan. We use multi-attribute visualization techniques to highlight the strengths and identify the weaknesses of a partition. Comparative visualization techniques allow multiple partitions to be viewed simultaneously. Users can make informed decisions about how to partition geo spatial data by using a combination of our techniques for multi-attribute visualization, temporal visualization and comparative visualization.\\\",\\\"Authors\\\":\\\"Poonam Shanbhag;Rheingans, P.;desJardins, M.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;MultidimensionalMultivariateMultifieldDataAndTechniques;SpaceRelatedSpatialDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532149\\\",\\\"Keywords\\\":\\\"temporal visualization;multi-attribute visualization;time-dependent attributes;spatial data;resource allocation\\\",\\\"Keywords_Processed\\\":\\\"multi attribute visualization;temporal visualization;spatial datum;time dependent attribute;resource allocation\\\",\\\"Title\\\":\\\"Temporal visualization of planning polygons for efficient partitioning of geo-spatial data\\\"},\\\"998\\\":{\\\"Abstract\\\":\\\"We present the Visual Code Navigator, a set of three interrelated visual tools that we developed for exploring large source code software projects from three different perspectives, or views: the syntactic view shows the syntactic constructs in the source code. The symbol view shows the objects a file makes available after compilation, such as function signatures, variables, and namespaces. The evolution view looks at different versions in a project lifetime of a number of selected source files. The views share one code model, which combines hierarchical syntax based and line based information from multiple source files versions. We render this code model using a visual model that extends the pixel-filling, space partitioning properties of shaded cushion treemaps with novel techniques. We discuss how our views allow users to interactively answer complex questions on various code elements by simple mouse clicks. We validate the efficiency and effectiveness of our toolset by an informal user study on the source code of VTK, a large, industry-size C++ code base\\\",\\\"Authors\\\":\\\"Lommerse, G.;Nossin, F.;Voinea, L.;Telea, A.\\\",\\\"Clusters\\\":\\\"HierarchicalTreeDataAndTechniques;MultipleLinkedCoordinatedViews;PixelOrientedEncodings;SoftwareVisualization\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532125\\\",\\\"Keywords\\\":\\\"pixel-filling displays;source code visualization;treemap;source code analysis;multiple views\\\",\\\"Keywords_Processed\\\":\\\"pixel filling display;treemap;source code analysis;multiple view;source code visualization\\\",\\\"Title\\\":\\\"The visual code navigator: an interactive toolset for source code investigation\\\"},\\\"999\\\":{\\\"Abstract\\\":\\\"Many visual analysis tools operate on a fixed set of data. However, professional information analysts follow issues over a period of time and need to be able to easily add new documents to an ongoing exploration. Some analysts handle documents in a moving window of time, with new documents constantly added and old ones aging out. This paper describes both the user interaction and the technical implementation approach for a visual analysis system designed to support constantly evolving text collections.\\\",\\\"Authors\\\":\\\"Hetzler, E.;Crow, V.;Payne, D.A.;Turner, A.E.\\\",\\\"Clusters\\\":\\\"DesignMethodologiesAndInteractionDesign;DynamicVisualizationVisualizationOfChange;RealtimeProcessingRenderingAndVisualizationGeneral;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532133\\\",\\\"Keywords\\\":\\\"user interaction design;realtime updating;information visualization;dynamic visualization\\\",\\\"Keywords_Processed\\\":\\\"realtime updating;dynamic visualization;user interaction design;information visualization\\\",\\\"Title\\\":\\\"Turning the bucket of text into a pipe\\\"},\\\"1000\\\":{\\\"Abstract\\\":\\\"A new pseudo coloring technique for large scale one-dimensional datasets is proposed. For visualization of a large scale dataset, user interaction is indispensable for selecting focus areas in the dataset. However, excessive switching of the visualized image makes it difficult for the user to recognize overview/ detail and detail/ detail relationships. The goal of this research is to develop techniques for visualizing details as precisely as possible in overview display. In this paper, visualization of a one-dimensional but very large dataset is considered. The proposed method is based on pseudo coloring, however, each scalar value corresponds to two discrete colors. By painting with two colors at each value, users can read out the value precisely. This method has many advantages: it requires little image space for visualization; both the overview and details of the dataset are visible in one image without distortion; and implementation is very simple. Several application examples, such as meteorological observation data and train convenience evaluation data, show the effectiveness of the method.\\\",\\\"Authors\\\":\\\"Saito, T.;Miyamura, H.N.;Yamamoto, M.;Saito, H.;Hoshiya, Y.;Kaseda, T.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;DataAcquisitionAndManagement;FocusContextTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532144\\\",\\\"Keywords\\\":\\\"data density;pseudo color;focus+context;detail;overview\\\",\\\"Keywords_Processed\\\":\\\"detail;pseudo color;data density;overview;focus context\\\",\\\"Title\\\":\\\"Two-tone pseudo coloring: compact visualization for one-dimensional data\\\"},\\\"1001\\\":{\\\"Abstract\\\":\\\"We present a novel visual correlation paradigm for situational awareness (SA) and suggest its usage in a diverse set of applications that require a high level of SA. Our approach is based on a concise and scalable representation, which leads to a flexible visualization tool that is both clear and intuitive to use. Situational awareness is the continuous extraction of environmental information, its integration with previous knowledge to form a coherent mental picture, and the use of that picture in anticipating future events. In this paper we build on our previous work on visualization for network intrusion detection and show how that approach can be generalized to encompass a much broader class of SA systems. We first propose a generalization that is based on what we term, the w3 premise, namely that each event must have at least the what, when and where attributes. We also present a second generalization, which increases flexibility and facilitates complex visual correlations. Finally, we demonstrate the generality of our approaches by applying our visualization paradigm in a collection of diverse SA areas.\\\",\\\"Authors\\\":\\\"Livnat, Y.;Agutter, J.;Shaun Moon;Foresti, S.\\\",\\\"Clusters\\\":\\\"Cognition;ComputerNetworksNetworkSecurity;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532134\\\",\\\"Keywords\\\":\\\"visualization;situation awareness;network intrusion\\\",\\\"Keywords_Processed\\\":\\\"visualization;situation awareness;network intrusion\\\",\\\"Title\\\":\\\"Visual correlation for situational awareness\\\"},\\\"1002\\\":{\\\"Abstract\\\":\\\"The most common approach to support analysis of graphs with associated time series data include: overlay of data on graph vertices for one timepoint at a time by manipulating a visual property (e.g. color) of the vertex, along with sliders or some such mechanism to animate the graph for other timepoints. Alternatively, data from all the timepoints can be overlaid simultaneously by embedding small charts into graph vertices. These graph visualizations may also be linked to other visualizations (e.g., parallel co-ordinates) using brushing and linking. This paper describes a study performed to evaluate and rank graph+timeseries visualization options based on users' performance time and accuracy of responses on predefined tasks. The results suggest that overlaying data on graph vertices one timepoint at a time may lead to more accurate performance for tasks involving analysis of a graph at a single timepoint, and comparisons between graph vertices for two distinct timepoints. Overlaying data simultaneously for all the timepoints on graph vertices may lead to more accurate and faster performance for tasks involving searching for outlier vertices displaying different behavior than the rest of the graph vertices for all timepoints. Single views have advantage over multiple views on tasks that require topological information. Also, the number of attributes displayed on nodes has a non trivial influence on accuracy of responses, whereas the number of visualizations affect the performance time.\\\",\\\"Authors\\\":\\\"Saraiya, P.;Lee, P.;North, C.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques;UsabilityStudies;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532151\\\",\\\"Keywords\\\":\\\"time-series analysis;usability experiments;data overlay;graph visualization\\\",\\\"Keywords_Processed\\\":\\\"usability experiment;graph visualization;datum overlay;time series analysis\\\",\\\"Title\\\":\\\"Visualization of graphs with associated timeseries data\\\"},\\\"1003\\\":{\\\"Abstract\\\":\\\"Exploratory visualization environments allow users to build and browse coordinated multiview visualizations interactively. As the number of views and amount of coordination increases, conceptualizing coordination structure becomes more and more important for successful data exploration. Integrated metavisualization is exploratory visualization of coordination and other interactive structure directly inside a visualization's own user interface. This paper presents a model of integrated metavisualization, describes the problem of capturing dynamic interface structure as visualizable data, and outlines three general approaches to integration. Metavisualization has been implemented in improvise, using views, lenses, and embedding to reveal the dynamic structure of its own highly coordinated visualizations.\\\",\\\"Authors\\\":\\\"Weaver, C.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;CollaborativeVisualization;MultipleLinkedCoordinatedViews;SoftwareVisualization;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532143\\\",\\\"Keywords\\\":\\\"exploratory visualization;coordination;linked views;software visualization;meta-visualization\\\",\\\"Keywords_Processed\\\":\\\"meta visualization;link view;coordination;exploratory visualization;software visualization\\\",\\\"Title\\\":\\\"Visualizing coordination in situ\\\"},\\\"1004\\\":{\\\"Abstract\\\":\\\"Recent years have witnessed the dramatic popularity of online social networking services, in which millions of members publicly articulate mutual \\\\\\\"friendship\\\\\\\" relations. Guided by ethnographic research of these online communities, we have designed and implemented a visualization system for playful end-user exploration and navigation of large scale online social networks. Our design builds upon familiar node link network layouts to contribute customized techniques for exploring connectivity in large graph structures, supporting visual search and analysis, and automatically identifying and visualizing community structures. Both public installation and controlled studies of the system provide evidence of the system's usability, capacity for facilitating discovery, and potential for fun and engaged social activity\\\",\\\"Authors\\\":\\\"Heer, J.;Boyd, D.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;DatabasesAndDataMining;GraphNetworkDataAndTechniques;InteractionTechniquesGeneral;SocialNetworksAndSocialMedia;SocialScienceAndHumanities;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532126\\\",\\\"Keywords\\\":\\\"community;data mining;exploration;social networks;visualization;graph;play\\\",\\\"Keywords_Processed\\\":\\\"visualization;graph;social network;community;exploration;datum mining;play\\\",\\\"Title\\\":\\\"Vizster: visualizing online social networks\\\"},\\\"1005\\\":{\\\"Abstract\\\":\\\"Treemaps are a well known method for the visualization of attributed hierarchical data. Previously proposed treemap layout algorithms are limited to rectangular shapes, which cause problems with the aspect ratio of the rectangles as well as with identifying the visualized hierarchical structure. The approach of Voronoi treemaps presented in this paper eliminates these problems through enabling subdivisions of and in polygons. Additionally, this allows for creating treemap visualizations within areas of arbitrary shape, such as triangles and circles, thereby enabling a more flexible adaptation of treemaps for a wider range of applications.\\\",\\\"Authors\\\":\\\"Balzer, M.;Deussen, O.\\\",\\\"Clusters\\\":\\\"HierarchicalTreeDataAndTechniques;VoronoiBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2005.1532128\\\",\\\"Keywords\\\":\\\"information visualization;hierarchy;treemap;voronoi treemaps;tree;voronoi tessellations\\\",\\\"Keywords_Processed\\\":\\\"hierarchy;treemap;information visualization;voronoi tessellation;tree;voronoi treemap\\\",\\\"Title\\\":\\\"Voronoi treemaps\\\"},\\\"1006\\\":{\\\"Abstract\\\":\\\"Analysis of degenerate tensors is a fundamental step in finding the topological structures and separatrices in tensor fields. Previous work in this area have been limited to analyzing symmetric second order tensor fields. In this paper, we extend the topological analysis to 2D general (asymmetric) second order tensor fields. We show that it is not sufficient to define degeneracies based on eigenvalues alone, but one must also include the eigenvectors in the analysis. We also study the behavior of these eigenvectors as they cross from one topological region into another.\\\",\\\"Authors\\\":\\\"Zheng, X.;Pang, A.\\\",\\\"Clusters\\\":\\\"StreamlinesPathlinesStreaklines;TensorDataAndTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532770\\\",\\\"Keywords\\\":\\\"hyperstreamlines;degenerate tensors;critical points;symmetric tensors;tensor topology;general tensors;topological line\\\",\\\"Keywords_Processed\\\":\\\"hyperstreamline;tensor topology;topological line;general tensor;critical point;symmetric tensor;degenerate tensor\\\",\\\"Title\\\":\\\"2D asymmetric tensor analysis\\\"},\\\"1007\\\":{\\\"Abstract\\\":\\\"VisIt is a richly featured visualization tool that is used to visualize some of the largest simulations ever run. The scale of these simulations requires that optimizations are incorporated into every operation VisIt performs. But the set of applicable optimizations that VisIt can perform is dependent on the types of operations being done. Complicating the issue, VisIt has a plugin capability that allows new, unforeseen components to be added, making it even harder to determine which optimizations can be applied. We introduce the concept of a contract to the standard data flow network design. This contract enables each component of the data flow network to modify the set of optimizations used. In addition, the contract allows for new components to be accommodated gracefully within VisIt's data flow network system.\\\",\\\"Authors\\\":\\\"Childs, H.;Brugger, E.;Bonnell, K.;Meredith, J.;Miller, M.;Whitlock, B.;Max, N.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;LargeScaleDataAndScalability;ProgrammingAlgorithmsAndDataStructures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532795\\\",\\\"Keywords\\\":\\\"large data set visualization;contract-based system;data flow networks\\\",\\\"Keywords_Processed\\\":\\\"contract base system;data flow network;large datum set visualization\\\",\\\"Title\\\":\\\"A contract based system for large data visualization\\\"},\\\"1008\\\":{\\\"Abstract\\\":\\\"Optimal viewpoint selection is an important task because it considerably influences the amount of information contained in the 2D projected images of 3D objects, and thus dominates their first impressions from a psychological point of view. Although several methods have been proposed that calculate the optimal positions of viewpoints especially for 3D surface meshes, none has been done for solid objects such as volumes. This paper presents a new method of locating such optimal viewpoints when visualizing volumes using direct volume rendering. The major idea behind our method is to decompose an entire volume into a set of feature components, and then find a globally optimal viewpoint by finding a compromise between locally optimal viewpoints for the components. As the feature components, the method employs interval volumes and their combinations that characterize the topological transitions of isosurfaces according to the scalar field. Furthermore, opacity transfer functions are also utilized to assign different weights to the decomposed components so that users can emphasize features of specific interest in the volumes. Several examples of volume datasets together with their optimal positions of viewpoints are exhibited in order to demonstrate that the method can effectively guide naive users to find optimal projections of volumes.\\\",\\\"Authors\\\":\\\"Takahashi, S.;Fujishiro, I.;Takeshima, Y.;Nishita, T.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;NumericalMethodsMathematics;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532834\\\",\\\"Keywords\\\":\\\"viewpoint entropy;level set graphs;direct volume rendering;viewpoint selection;interval volume\\\",\\\"Keywords_Processed\\\":\\\"viewpoint entropy;viewpoint selection;direct volume render;interval volume;level set graph\\\",\\\"Title\\\":\\\"A feature-driven approach to locating optimal viewpoints for volume visualization\\\"},\\\"1009\\\":{\\\"Abstract\\\":\\\"A new close range virtual reality system is introduced that allows intuitive and immersive user interaction with computer generated objects. A projector with a special spherical lens is combined with a flexible, tracked rear projection screen that users hold in their hands. Unlike normal projectors, the spherical lens allows for a 180 degree field of view and nearly infinite depth of focus. This allows the user to move the screen around the environment and use it as a virtual \\\\\\\"slice\\\\\\\" to examine the interior of 3D volumes. This provides a concrete correspondence between the virtual representation of the 3D volume and how that volume would actually appear if its real counterpart was sliced open. The screen can also be used as a \\\\\\\"magic window\\\\\\\" to view the mesh of the volume from different angles prior to taking cross sections of it. Real time rendering of the desired 3D volume or mesh is accomplished using current graphics hardware. Additional applications of the system are also discussed.\\\",\\\"Authors\\\":\\\"Konieczny, J.;Shimizu, C.;Meyer, G.;Colucci, D.\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;DisplaysGeneral;ImmersiveAndVirtualEnvironments;UserInterfacesGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532846\\\",\\\"Keywords\\\":\\\"volume rendering;virtual reality;user interface;visualization;projectors;curved sections\\\",\\\"Keywords_Processed\\\":\\\"visualization;volume render;user interface;curve section;virtual reality;projector\\\",\\\"Title\\\":\\\"A handheld flexible display system\\\"},\\\"1010\\\":{\\\"Abstract\\\":\\\"Existing parallel or remote rendering solutions rely on communicating pixels, OpenGL commands, scene-graph changes or application-specific data. We propose an intermediate solution based on a set of independent graphics primitives that use hardware shaders to specify their visual appearance. Compared to an OpenGL based approach, it reduces the complexity of the model by eliminating most fixed function parameters while giving access to the latest functionalities of graphics cards. It also suppresses the OpenGL state machine that creates data dependencies making primitive re-scheduling difficult. Using a retained-mode communication protocol transmitting changes between each frame, combined with the possibility to use shaders to implement interactive data processing operations instead of sending final colors and geometry, we are able to optimize the network load. High level information such as bounding volumes is used to setup advanced schemes where primitives are issued in parallel, routed according to their visibility, merged and re-ordered when received for rendering. Different optimization algorithms can be efficiently implemented, saving network bandwidth or reducing texture switches for instance. We present performance results based on two VTK applications, a parallel iso-surface extraction and a parallel volume renderer. We compare our approach with Chromium. Results show that our approach leads to significantly better performance and scalability, while offering easy access to hardware accelerated rendering algorithms.\\\",\\\"Authors\\\":\\\"Allard, J.;Raffin, B.\\\",\\\"Clusters\\\":\\\"DistributedSystemsAndGridEnvironments;GpuBasedTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532787\\\",\\\"Keywords\\\":\\\"distributed rendering;volume rendering;shader\\\",\\\"Keywords_Processed\\\":\\\"volume render;distribute render;shader\\\",\\\"Title\\\":\\\"A shader-based parallel rendering framework\\\"},\\\"1011\\\":{\\\"Abstract\\\":\\\"Sort-last parallel rendering is an efficient technique to visualize huge datasets on COTS clusters. The dataset is subdivided and distributed across the cluster nodes. For every frame, each node renders a full resolution image of its data using its local GPU, and the images are composited together using a parallel image compositing algorithm. In this paper, we present a performance evaluation of standard sort-last parallel rendering methods and of the different improvements proposed in the literature. This evaluation is based on a detailed analysis of the different hardware and software components. We present a new implementation of sort-last rendering that fully overlaps CPU(s), GPU and network usage all along the algorithm. We present experiments on a 3 years old 32-node PC cluster and on a 1.5 years old 5-node PC cluster, both with Gigabit interconnect, showing volume rendering at respectively 13 and 31 frames per second and polygon rendering at respectively 8 and 17 frames per second on a 1024 x 768 render area, and we show that our implementation outperforms or equals many other implementations and specialized visualization clusters.\\\",\\\"Authors\\\":\\\"Cavin, X.;Mion, C.;Filbois, A.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;ImageBasedDataImageSignalProcessing;Rendering\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532785\\\",\\\"Keywords\\\":\\\"sort-last rendering;cluster-based visualization;parallel image compositing\\\",\\\"Keywords_Processed\\\":\\\"parallel image compositing;cluster base visualization;sort last rendering\\\",\\\"Title\\\":\\\"COTS cluster-based sort-last rendering: performance evaluation and pipelined implementation\\\"},\\\"1012\\\":{\\\"Abstract\\\":\\\"Curve-skeletons are a 1D subset of the medial surface of a 3D object and are useful for many visualization tasks including virtual navigation, reduced-model formulation, visualization improvement, mesh repair, animation, etc. There are many algorithms in the literature describing extraction methodologies for different applications; however, it is unclear how general and robust they are. In this paper, we provide an overview of many curve-skeleton applications and compile a set of desired properties of such representations. We also give a taxonomy of methods and analyze the advantages and drawbacks of each class of algorithms.\\\",\\\"Authors\\\":\\\"Cornea, N.D.;Silver, D.;Min, P.\\\",\\\"Clusters\\\":\\\"TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532783\\\",\\\"Keywords\\\":\\\"skeleton;curve-skeleton\\\",\\\"Keywords_Processed\\\":\\\"curve skeleton;skeleton\\\",\\\"Title\\\":\\\"Curve-skeleton applications\\\"},\\\"1013\\\":{\\\"Abstract\\\":\\\"In this paper, we describe a methodology and implementation for interactive dataset traversal using motion-controlled transfer functions. Dataset traversal here refers lo the process of translating a transfer function along a specific path. In scientific visualization, it is often necessary to manipulate transfer functions in order to visualize datasets more effectively. This manipulation of transfer functions is usually performed globally, i.e., a new transfer function is applied to the entire dataset. Our approach allows one to locally manipulate transfer functions while controling its movement along a traversal path. The method we propose allows the user to select a traversal path within the dataset, based on the shape of the volumetric model and manipulate a transfer function along this path. Examples of dataset traversal include the animation of transfer functions along a pre-defined path, the simulation of flow in vascular structures, and the visualization of convoluted shapes. For example, this type of traversal is often used in medical illustration to highlight flow in blood vessels. We present an interactive implementation of our method using graphics hardware, based on the decomposition of the volume. We show examples of our approach using a variety of volumetric datasets, and we also demonstrate that with our novel decomposition, the rendering process is faster.\\\",\\\"Authors\\\":\\\"Correa, C.;Silver, D.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;DataAcquisitionAndManagement;IllustrativeVisualization;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532817\\\",\\\"Keywords\\\":\\\"illustrative visualization;transfer function;volume manipulation;animation;dataset traversal\\\",\\\"Keywords_Processed\\\":\\\"illustrative visualization;dataset traversal;animation;volume manipulation;transfer function\\\",\\\"Title\\\":\\\"Dataset traversal with motion-controlled transfer functions\\\"},\\\"1014\\\":{\\\"Abstract\\\":\\\"Differential protein expression analysis is one of the main challenges in proteomics. It denotes the search for proteins, whose encoding genes are differentially expressed under a given experimental setup. An important task in this context is to identify the differentially expressed proteins or, more generally, all proteins present in the sample. One of the most promising and recently widely used approaches for protein identification is to cleave proteins into peptides, separate the peptides using liquid chromatography, and determine the masses of the separated peptides using mass spectrometry. The resulting data needs to be analyzed and matched against protein sequence databases. The analysis step is typically done by searching for intensity peaks in a large number of 2D graphs. We present an interactive visualization tool for the exploration of liquid-chromatography/mass-spectrometry data in a 3D space, which allows for the understanding of the data in its entirety and a detailed analysis of regions of interest. We compute differential expression over the liquid-chromatography/mass-spectrometry domain and embed it visually in our system. Our exploration tool can treat single liquid-chromatography/mass-spectrometry data sets as well as data acquired using multi-dimensional protein identification technology. For efficiency purposes we perform a peak-preserving data resampling and multiresolution hierarchy generation prior to visualization.\\\",\\\"Authors\\\":\\\"Linsen, L.;Locherbach, J.;Berth, M.;Bernhardt, J.;Becher, D.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;BiologyAndBioinformatics;HierarchicalTreeDataAndTechniques;MolecularScienceAndChemistry\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532828\\\",\\\"Keywords\\\":\\\"proteomics;visualization in bioinformatics;interactive visual exploration;hierarchical data representation\\\",\\\"Keywords_Processed\\\":\\\"interactive visual exploration;proteomic;visualization in bioinformatic;hierarchical datum representation\\\",\\\"Title\\\":\\\"Differential protein expression analysis via liquid-chromatography/mass-spectrometry data visualization\\\"},\\\"1015\\\":{\\\"Abstract\\\":\\\"We propose a distributed data management scheme for large data visualization that emphasizes efficient data sharing and access. To minimize data access time and support users with a variety of local computing capabilities, we introduce an adaptive data selection method based on an \\\\\\\"enhanced time-space partitioning\\\\\\\" (ETSP) tree that assists with effective visibility culling, as well as multiresolution data selection. By traversing the tree, our data management algorithm can quickly identify the visible regions of data, and, for each region, adaptively choose the lowest resolution satisfying user-specified error tolerances. Only necessary data elements are accessed and sent to the visualization pipeline. To further address the issue of sharing large-scale data among geographically distributed collaborative teams, we have designed an infrastructure for integrating our data management technique with a distributed data storage system provided by logistical networking (LoN). Data sets at different resolutions are generated and uploaded to LoN for wide-area access. We describe a parallel volume rendering system that verifies the effectiveness of our data storage, selection and access scheme.\\\",\\\"Authors\\\":\\\"Gao, J.;Huang, J.;Johnson, C.R.;Atchley, S.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;CamerasCameraViewsAndProjections;DistributedSystemsAndGridEnvironments;LargeScaleDataAndScalability;Rendering;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532794\\\",\\\"Keywords\\\":\\\"distributed storage;volume rendering;large data visualization;logistical networking;visibility culling;multi-resolution rendering\\\",\\\"Keywords_Processed\\\":\\\"volume render;multi resolution render;large datum visualization;distribute storage;visibility cull;logistical networking\\\",\\\"Title\\\":\\\"Distributed data management for large volume visualization\\\"},\\\"1016\\\":{\\\"Abstract\\\":\\\"We study the problem of visualizing large networks and develop techniques for effectively abstracting a network and reducing the size to a level that can be clearly viewed. Our size reduction techniques are based on sampling, where only a sample instead of the full network is visualized. We propose a randomized notion of \\\\\\\"focus\\\\\\\" that specifies a part of the network and the degree to which it needs to be magnified. Visualizing a sample allows our method to overcome the scalability issues inherent in visualizing massive networks. We report some characteristics that frequently occur in large networks and the conditions under which they are preserved when sampling from a network. This can be useful in selecting a proper sampling scheme that yields a sample with similar characteristics as the original network. Our method is built on top of a relational database, thus it can be easily and efficiently implemented using any off-the-shelf database software. As a proof of concept, we implement our methods and report some of our experiments over the movie database and the connectivity graph of the Web.\\\",\\\"Authors\\\":\\\"Rafiei, D.\\\",\\\"Clusters\\\":\\\"GraphNetworkDataAndTechniques;InternetWebVisualizationForTheMasses\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532819\\\",\\\"Keywords\\\":\\\"visualizing the web;large network visualization;network sampling\\\",\\\"Keywords_Processed\\\":\\\"network sampling;visualize the web;large network visualization\\\",\\\"Title\\\":\\\"Effectively visualizing large networks through sampling\\\"},\\\"1017\\\":{\\\"Abstract\\\":\\\"Fiber tracking is a standard approach for the visualization of the results of diffusion tensor imaging (DTI). If fibers are reconstructed and visualized individually through the complete white matter, the display gets easily cluttered making it difficult to get insight in the data. Various clustering techniques have been proposed to automatically obtain bundles that should represent anatomical structures, but it is unclear which clustering methods and parameter settings give the best results. We propose a framework to validate clustering methods for white-matter fibers. Clusters are compared with a manual classification which is used as a ground truth. For the quantitative evaluation of the methods, we developed a new measure to assess the difference between the ground truth and the clusterings. The measure was validated and calibrated by presenting different clusterings to physicians and asking them for their judgement. We found that the values of our new measure for different clusterings match well with the opinions of physicians. Using this framework, we have evaluated different clustering algorithms, including shared nearest neighbor clustering, which has not been used before for this purpose. We found that the use of hierarchical clustering using single-link and a fiber similarity measure based on the mean distance between fibers gave the best results.\\\",\\\"Authors\\\":\\\"Moberts, B.;Vilanova, A.;van Wijk, J.J.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;TensorDataAndTechniques;Tractography\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532779\\\",\\\"Keywords\\\":\\\"clustering;clustering validation;fiber tracking;diffusion tensor imaging;external indices\\\",\\\"Keywords_Processed\\\":\\\"fiber tracking;diffusion tensor imaging;clustering validation;clustering;external index\\\",\\\"Title\\\":\\\"Evaluation of fiber clustering methods for diffusion tensor imaging\\\"},\\\"1018\\\":{\\\"Abstract\\\":\\\"Scientific illustrations use accepted conventions and methodologies to effectively convey object properties and improve our understanding. We present a method to illustrate volume datasets by emulating example illustrations. As with technical illustrations, our volume illustrations more clearly delineate objects, enrich details, and artistically visualize volume datasets. For both color and scalar 3D volumes, we have developed an automatic color transfer method based on the clustering and similarities in the example illustrations and volume sources. As an extension to 2D Wang tiles, we provide a new, general texture synthesis method for Wang cubes that solves the edge discontinuity problem. We have developed a 2D illustrative slice viewer and a GPU-based direct volume rendering system that uses these non-periodic 3D textures to generate illustrative results similar to the 2D examples. Both applications simulate scientific illustrations to provide more information than the original data and visualize objects more effectively, while only requiring simple user interaction.\\\",\\\"Authors\\\":\\\"Lu, A.;Ebert, D.S.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;IllustrativeVisualization;NumericalMethodsMathematics;Rendering;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532854\\\",\\\"Keywords\\\":\\\"example-based rendering;texture synthesis;wang cubes;volume illustration;color transfer\\\",\\\"Keywords_Processed\\\":\\\"example base render;color transfer;wang cube;texture synthesis;volume illustration\\\",\\\"Title\\\":\\\"Example-based volume illustrations\\\"},\\\"1019\\\":{\\\"Abstract\\\":\\\"In this article we describe stress nets, a technique for exploring 2D tensor fields. Our method allows a user to examine simultaneously the tensors' eigenvectors (both major and minor) as well as scalar-valued tensor invariants. By avoiding noise-advection techniques, we are able to display both principal directions of the tensor field as well as the derived scalars without cluttering the display. We present a CPU-only implementation of stress nets as well as a hybrid CPU/GPU approach and discuss the relative strengths and weaknesses of each. Stress nets have been used as part of an investigation into crack propagation. They were used to display the directions of maximum shear in a slab of material under tension as well as the magnitude of the shear forces acting on each point. Our methods allowed users to find new features in the data that were not visible on standard plots of tensor invariants. These features disagree with commonly accepted analytical crack propagation solutions and have sparked renewed investigation. Though developed for a materials mechanics problem, our method applies equally well to any 2D tensor field having unique characteristic directions.\\\",\\\"Authors\\\":\\\"Wilson, A.;Brannon, R.\\\",\\\"Clusters\\\":\\\"MaterialScience;StreamlinesPathlinesStreaklines;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532771\\\",\\\"Keywords\\\":\\\"controlled density streamlines;tensor field;stress tensor;streamlines;crack propagation\\\",\\\"Keywords_Processed\\\":\\\"streamline;control density streamline;stress tensor;crack propagation;tensor field\\\",\\\"Title\\\":\\\"Exploring 2D tensor fields using stress nets\\\"},\\\"1020\\\":{\\\"Abstract\\\":\\\"We introduce an approach to tracking vortex core lines in time-dependent 3D flow fields which are defined by the parallel vectors approach. They build surface structures in the 4D space-time domain. To extract them, we introduce two 4D vector fields which act as feature flow fields, i.e., their integration gives the vortex core structures. As part of this approach, we extract and classify local bifurcations of vortex core lines in space-time. Based on a 4D stream surface integration, we provide an algorithm to extract the complete vortex core structure. We apply our technique to a number of test data sets.\\\",\\\"Authors\\\":\\\"Theisel, H.;Sahner, J.;Weinkauf, T.;Hege, H.-C.;Seidel, H.-P.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532851\\\",\\\"Keywords\\\":\\\"flow visualization;vortex core lines;bifurcations\\\",\\\"Keywords_Processed\\\":\\\"vortex core line;bifurcation;flow visualization\\\",\\\"Title\\\":\\\"Extraction of parallel vector surfaces in 3D time-dependent fields and application to vortex core line tracking\\\"},\\\"1021\\\":{\\\"Abstract\\\":\\\"Displays combining both 2D and 3D views have been shown to support higher performance on certain visualization tasks. However, it is not clear how best to arrange a combination of 2D and 3D views spatially in a display. In this study, we analyzed the eyegaze strategies of participants using two arrangements of 2D and 3D views to estimate the relative position of objects in a 3D scene. Our results show that the 3D view was used significantly more often than individual 2D views in both displays, indicating the importance of the 3D view for successful task completion. However, viewing patterns were significantly different between the two displays: transitions through centrally-placed views were always more frequent, and users avoided saccades between views that were far apart. Although the change in viewing strategy did not result in significant performance differences, error analysis indicates that a 3D overview in the center may reduce the number of serious errors compared to a 3D overview placed off to the side.\\\",\\\"Authors\\\":\\\"Tory, M.;Atkins, M.S.;Kirkpatrick, A.E.;Nicolaou, M.;Guang-Zhong Yang\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532837\\\",\\\"Keywords\\\":\\\"2d and 3d visualization;user study;visualization;eye gaze analysis;experiment\\\",\\\"Keywords_Processed\\\":\\\"visualization;user study;eye gaze analysis;experiment;2d and 3d visualization\\\",\\\"Title\\\":\\\"Eyegaze analysis of displays with combined 2D and 3D views\\\"},\\\"1022\\\":{\\\"Abstract\\\":\\\"It is a challenging task to visualize the behavior of time-dependent 3D vector fields. Most of the time an overview of unsteady fields is provided via animations, but, unfortunately, animations provide only transient impressions of momentary flow. In this paper we present two approaches to visualize time varying fields with fixed geometry. Path lines and streak lines represent such a steady visualization of unsteady vector fields, but because of occlusion and visual clutter it is useless to draw them all over the spatial domain. A selection is needed. We show how bundles of streak lines and path lines, running at different times through one point in space, like through an eyelet, yield an insightful visualization of flow structure (\\\\\\\"eyelet lines\\\\\\\"). To provide a more intuitive and appealing visualization we also explain how to construct a surface from these lines. As second approach, we use a simple measurement of local changes of a field over time to determine regions with strong changes. We visualize these regions with isosurfaces to give an overview of the activity in the dataset. Finally we use the regions as a guide for placing eyelets.\\\",\\\"Authors\\\":\\\"Wiebel, A.;Scheuermann, G.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;TensorDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532848\\\",\\\"Keywords\\\":\\\"flow visualization;3d vector field visualization;time-varying visualization;vector/tensor visualization\\\",\\\"Keywords_Processed\\\":\\\"time vary visualization;3d vector field visualization;vector tensor visualization;flow visualization\\\",\\\"Title\\\":\\\"Eyelet particle tracing - steady visualization of unsteady flow\\\"},\\\"1023\\\":{\\\"Abstract\\\":\\\"We propose a novel algorithm for placement of streamlines from two-dimensional steady vector or direction fields. Our method consists of placing one streamline at a time by numerical integration starting at the furthest away from all previously placed streamlines. Such a farthest point seeding strategy leads to high quality placements by favoring long streamlines, while retaining uniformity with the increasing density. Our greedy approach generates placements of comparable quality with respect to the optimization approach from Turk and Banks, while being 200 times faster. Simplicity, robustness as well as efficiency is achieved through the use of a Delaunay triangulation to model the streamlines, address proximity queries and determine the biggest voids by exploiting the empty circle property. Our method handles variable density and extends to multiresolution.\\\",\\\"Authors\\\":\\\"Mebarki, A.;Alliez, P.;Devillers, O.\\\",\\\"Clusters\\\":\\\"DataFeaturesAndAttributes;MeshesGridsAndLattices;MultiresolutionTechniques;PointBasedDataAndTechniques;StreamlinesPathlinesStreaklines\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532832\\\",\\\"Keywords\\\":\\\"variable density;farthest point seeding;streamline placement;multi-resolution;delaunay triangulation\\\",\\\"Keywords_Processed\\\":\\\"multi resolution;delaunay triangulation;streamline placement;variable density;farth point seeding\\\",\\\"Title\\\":\\\"Farthest point seeding for efficient placement of streamlines\\\"},\\\"1024\\\":{\\\"Abstract\\\":\\\"Diffusion tensor imaging (DTI) is an MRI-based technique for quantifying water diffusion in living tissue. In the white matter of the brain, water diffuses more rapidly along the neuronal axons than in the perpendicular direction. By exploiting this phenomenon, DTI can be used to determine trajectories of fiber bundles, or neuronal connections between regions, in the brain. The resulting bundles can be visualized. However, the resulting visualizations can be complex and difficult to interpret. An effective approach is to pre-determine trajectories from a large number of positions throughout the white matter (full brain fiber tracking) and to offer facilities to aid the user in selecting fiber bundles of interest. Two factors are crucial for the use and acceptance of this technique in clinical studies: firstly, the selection of the bundles by brain experts should be interactive, supported by real-time visualization of the trajectories registered with anatomical MRI scans. Secondly, the fiber selections should be reproducible, so that different experts will achieve the same results. In this paper we present a practical technique for the interactive selection of fiber-bundles using multiple convex objects that is an order of magnitude faster than similar techniques published earlier. We also present the results of a clinical study with ten subjects that show that our selection approach is highly reproducible for fractional anisotropy (FA) calculated over the selected fiber bundles.\\\",\\\"Authors\\\":\\\"Blaas, J.;Botha, C.P.;Peters, B.;Vos, F.M.;Post, F.H.\\\",\\\"Clusters\\\":\\\"NeurosciencesAndBrainVisualization;TensorDataAndTechniques;Tractography\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532778\\\",\\\"Keywords\\\":\\\"white matter;tractography;diffusion tensor imaging\\\",\\\"Keywords_Processed\\\":\\\"tractography;diffusion tensor imaging;white matter\\\",\\\"Title\\\":\\\"Fast and reproducible fiber bundle selection in DTI visualization\\\"},\\\"1025\\\":{\\\"Abstract\\\":\\\"We develop the first approach Tor interactive volume visualization based on a sophisticated rendering method of shear-warp type, wavelet data encoding techniques, and a trivariate spline model, which has been introduced recently. As a first step of our algorithm, we apply standard wavelet expansions to represent and decimate the given gridded three-dimensional data. Based on this data encoding, we give a sophisticated version of the shear-warp based volume rendering method. Our new algorithm visits each voxel only once taking advantage of the particular data organization of octrees. In addition, the hierarchies of the data guide the local (re)construction of the quadratic super-spline models, which we apply as a pure visualization tool. The low total degree of the polynomial pieces allows to numerically approximate the volume rendering integral efficiently. Since the coefficients of the splines are almost immediately available from the given data, Bernstein-Bezier techniques can be fully employed in our algorithms. In this way, we demonstrate that these models can be successfully applied to full volume rendering of hierarchically organized data. Our computational results show that (even when hierarchical approximations are used) the new approach leads to almost artifact-free visualizations of high quality for complicated and noise-contaminated volume data sets, while the computational effort is considerable low, i.e. our current implementation yields 1-2 frames per second for parallel perspective rendering a 2563 volume data set (using simple opacity transfer functions) in a 5122 view-port.\\\",\\\"Authors\\\":\\\"Schlosser, G.;Hesser, J.;Zeilfelder, F.;Rossl, C.;Nurnberger, G.;Seidel, H.-P.;Mnner, R.\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;HierarchicalTreeDataAndTechniques;ProgrammingAlgorithmsAndDataStructures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532816\\\",\\\"Keywords\\\":\\\"quadratic super-splines;volume rendering;hierarchical data encoding;shear-warp algorithm\\\",\\\"Keywords_Processed\\\":\\\"volume render;hierarchical datum encoding;shear warp algorithm;quadratic super spline\\\",\\\"Title\\\":\\\"Fast visualization by shear-warp on quadratic super-spline models using wavelet data decompositions\\\"},\\\"1026\\\":{\\\"Abstract\\\":\\\"Techniques in numerical simulation such as the finite element method depend on basis functions for approximating the geometry and variation of the solution over discrete regions of a domain. Existing visualization systems can visualize these basis functions if they are linear, or for a small set of simple non-linear bases. However, newer numerical approaches often use basis functions of elevated and mixed order or complex form; hence existing visualization systems cannot directly process them. In this paper we describe an approach that supports automatic, adaptive tessellation of general basis functions using a flexible and extensible software architecture in conjunction with an on demand, edge-based recursive subdivision algorithm. The framework supports the use of functions implemented in external simulation packages, eliminating the need to reimplement the bases within the visualization system. We demonstrate our method on several examples, and have implemented the framework in the open-source visualization system VTK.\\\",\\\"Authors\\\":\\\"Schroeder, W.J.;Bertel, F.;Malaterre, M.;Thompson, D.;Pebay, P.P.;O'Bara, R.;Saurabh Tendulkar\\\",\\\"Clusters\\\":\\\"MeshesGridsAndLattices;NumericalMethodsMathematics;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532776\\\",\\\"Keywords\\\":\\\"finite elements;basis function;framework;tessellation\\\",\\\"Keywords_Processed\\\":\\\"tessellation;basis function;framework;finite element\\\",\\\"Title\\\":\\\"Framework for visualizing higher-order basis functions\\\"},\\\"1027\\\":{\\\"Abstract\\\":\\\"We present a system for three-dimensional visualization of complex liquid chromatography-mass spectrometry (LCMS) data. Every LCMS data point has three attributes: time, mass, and intensity. Instead of the traditional visualization of two-dimensional subsets of the data, we visualize it as a height field or terrain in 3D. Unlike traditional terrains, LCMS data has non-linear sampling and consists mainly of tall needle-like features. We adapt the level-of-detail techniques of geometry clipmaps for hardware-accelerated rendering of LCMS data. The data is cached in video memory as a set of nested rectilinear grids centered about the view frustum. We introduce a simple compression scheme and dynamically stream data from the CPU to the GPU as the viewpoint moves. Our system allows interactive investigation of complex LCMS data with close to one billion data points at up to 130 frames per second, depending on the view conditions.\\\",\\\"Authors\\\":\\\"de Corral, J.;Pfister, H.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;GpuBasedTechniques;PhysicsAndPhysicalSciences\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532827\\\",\\\"Keywords\\\":\\\"terrain rendering;gpu rendering;mass spectrometry\\\",\\\"Keywords_Processed\\\":\\\"mass spectrometry;gpu render;terrain render\\\",\\\"Title\\\":\\\"Hardware-accelerated 3D visualization of mass spectrometry data\\\"},\\\"1028\\\":{\\\"Abstract\\\":\\\"We present the application of hardware accelerated volume rendering algorithms to the simulation of radiographs as an aid to scientists designing experiments, validating simulation codes, and understanding experimental data. The techniques presented take advantage of 32-bit floating point texture capabilities to obtain solutions to the radiative transport equation for X-rays. The hardware accelerated solutions are accurate enough to enable scientists to explore the experimental design space with greater efficiency than the methods currently in use. An unsorted hexahedron projection algorithm is presented for curvilinear hexahedral meshes that produces simulated radiographs in the absorption-only regime. A sorted tetrahedral projection algorithm is presented that simulates radiographs of emissive materials. We apply the tetrahedral projection algorithm to the simulation of experimental diagnostics for inertial confinement fusion experiments on a laser at the University of Rochester.\\\",\\\"Authors\\\":\\\"Laney, D.;Callahan, S.P.;Max, N.;Silva, C.T.;Langer, S.;Frank, R.\\\",\\\"Clusters\\\":\\\"HardwareAccellerationAndComputationGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532815\\\",\\\"Keywords\\\":\\\"volume rendering;hardware acceleration\\\",\\\"Keywords_Processed\\\":\\\"volume render;hardware acceleration\\\",\\\"Title\\\":\\\"Hardware-accelerated simulated radiography\\\"},\\\"1029\\\":{\\\"Abstract\\\":\\\"High resolution volumes require high precision compositing to preserve detailed structures. This is even more desirable for volumes with high dynamic range values. After the high precision intermediate image has been computed, simply rounding up pixel values to regular display scales loses the computed details. In this paper, we present a novel high dynamic range volume visualization method for rendering volume data with both high spatial and intensity resolutions. Our method performs high precision volume rendering followed by dynamic tone mapping to preserve details on regular display devices. By leveraging available high dynamic range image display algorithms, this dynamic tone mapping can be automatically adjusted to enhance selected features for the final display. We also present a novel transfer function design interface with nonlinear magnification of the density range and logarithmic scaling of the color/opacity range to facilitate high dynamic range volume visualization. By leveraging modern commodity graphics hardware and out-of-core acceleration, our system can produce an effective visualization of huge volume data.\\\",\\\"Authors\\\":\\\"Xiaoru Yuan;Nguyen, M.Z.;Baoquan Chen;Porter, D.H.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;InformationProcessingAndHandling;UserInterfacesGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532812\\\",\\\"Keywords\\\":\\\"volume rendering;user interface;transfer function design;focus+context technique;high dynamic range;non-linear magnification\\\",\\\"Keywords_Processed\\\":\\\"volume render;high dynamic range;user interface;non linear magnification;focus context technique;transfer function design\\\",\\\"Title\\\":\\\"High dynamic range volume visualization\\\"},\\\"1030\\\":{\\\"Abstract\\\":\\\"A new technique is presented to increase the performance of volume splatting by using hardware accelerated point sprites. This allows creating screen aligned elliptical splats for high quality volume splatting at very low cost on the GPU. Only one vertex per splat is stored on the graphics card. GPU generated point sprite texture coordinates are used for computing splats and per-fragment 3D-texture coordinates on the fly. Thus, only 6 bytes per splat are stored on the GPU and vertex shader load is 25% in comparison to applying textured quads. For eight predefined viewing directions, depth-sorting of the splats is performed in a pre-processing step where the resulting indices are stored on the GPU. Thereby, there is no data transfer between CPU and GPU during rendering. Post-classificative two dimensional transfer functions with lighting for scalar data and tagged volumes were implemented. Thereby, we focused on the visualization of neurovascular structures, where typically no more than 2% of the voxels contribute to the resulting 3D-representation. A comparison with a 3D-texture-based slicing algorithm showed frame rates up to 11 times higher for the presented approach on current CPUs. The presented technique was evaluated with a broad medical database and its value for highly sparse volume visualization is shown.\\\",\\\"Authors\\\":\\\"Vega-Higuera, F.;Hastreiter, P.;Fahlbusch, R.;Greiner, G.\\\",\\\"Clusters\\\":\\\"NeurosciencesAndBrainVisualization;SegmentationAndClassification;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532805\\\",\\\"Keywords\\\":\\\"neurovascular structures;volume splatting;segmented data;volume visualization\\\",\\\"Keywords_Processed\\\":\\\"neurovascular structure;volume splatte;volume visualization;segmented datum\\\",\\\"Title\\\":\\\"High performance volume splatting for visualization of neurovascular data\\\"},\\\"1031\\\":{\\\"Abstract\\\":\\\"Tensors occur in many areas of science and engineering. Especially, they are used to describe charge, mass and energy transport (i.e. electrical conductivity tensor, diffusion tensor, thermal conduction tensor resp.) If the locale transport pattern is complicated, usual second order tensor representation is not sufficient. So far, there are no appropriate visualization methods for this case. We point out similarities of symmetric higher order tensors and spherical harmonics. A spherical harmonic representation is used to improve tensor glyphs. This paper unites the definition of streamlines and tensor lines and generalizes tensor lines to those applications where second order tensors representations fail. The algorithm is tested on the tractography problem in diffusion tensor magnetic resonance imaging (DT-MRI) and improved for this special application.\\\",\\\"Authors\\\":\\\"Hlawitschka, M.;Scheuermann, G.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;NumericalMethodsMathematics;TensorDataAndTechniques;Tractography\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532773\\\",\\\"Keywords\\\":\\\"higher-order tensor;tensor lines;tractography;diffusion tensor mri;visualization in medicine;spherical harmonics;vector/tensor visualization\\\",\\\"Keywords_Processed\\\":\\\"tensor line;tractography;diffusion tensor mri;vector tensor visualization;visualization in medicine;high order tensor;spherical harmonic\\\",\\\"Title\\\":\\\"HOT-lines: tracking lines in higher order tensor fields\\\"},\\\"1032\\\":{\\\"Abstract\\\":\\\"For the rendering of vector and tensor fields, several texture-based volumetric rendering methods were presented in recent years. While they have indisputable merits, the classical vertex-based rendering of integral curves has the advantage of better zooming capabilities as it is not bound to a fixed resolution. It has been shown that lighting can improve spatial perception of lines significantly, especially if lines appear in bundles. Although OpenGL does not directly support lighting of lines, fast rendering of illuminated lines can be achieved by using basic texture mapping. This existing technique is based on a maximum principle which gives a good approximation of specular reflection. Diffuse reflection however is essentially limited to bidirectional lights at infinity. We show how the realism can be further increased by improving diffuse reflection. We present simplified expressions for the Phong/Blinn lighting of infinitesimally thin cylindrical tubes. Based on these, we propose a fast rendering technique with diffuse and specular reflection for orthographic and perspective views and for multiple local and infinite lights. The method requires commonly available programmable vertex and fragment shaders and only two-dimensional lookup textures.\\\",\\\"Authors\\\":\\\"Mallo, O.;Peikert, R.;Sigg, C.;Sadlo, F.\\\",\\\"Clusters\\\":\\\"Illumination;InputAndOutputDevicesGeneral;LineBasedTechniquesAndApproaches;Textures;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532772\\\",\\\"Keywords\\\":\\\"illumination;graphics hardware;vector field visualization;field lines;texture mapping\\\",\\\"Keywords_Processed\\\":\\\"field line;graphic hardware;illumination;texture mapping;vector field visualization\\\",\\\"Title\\\":\\\"Illuminated lines revisited\\\"},\\\"1033\\\":{\\\"Abstract\\\":\\\"Understanding and analyzing complex volumetrically varying data is a difficult problem. Many computational visualization techniques have had only limited success in succinctly portraying the structure of three-dimensional turbulent flow. Motivated by both the extensive history and success of illustration and photographic flow visualization techniques, we have developed a new interactive volume rendering and visualization system for flows and volumes that simulates and enhances traditional illustration, experimental advection, and photographic flow visualization techniques. Our system uses a combination of varying focal and contextual illustrative styles, new advanced two-dimensional transfer functions, enhanced Schlieren and shadowgraphy shaders, and novel oriented structure enhancement techniques to allow interactive visualization, exploration, and comparative analysis of scalar, vector, and time-varying volume datasets. Both traditional illustration techniques and photographic flow visualization techniques effectively reduce visual clutter by using compact oriented structure information to convey three-dimensional structures. Therefore, a key to the effectiveness of our system is using one-dimensional (Schlieren and shadowgraphy) and two-dimensional (silhouette) oriented structural information to reduce visual clutter, while still providing enough three-dimensional structural information for the user's visual system to understand complex three-dimensional flow data. By combining these oriented feature visualization techniques with flexible transfer function controls, we can visualize scalar and vector data, allow comparative visualization of flow properties in a succinct, informative manner, and provide continuity for visualizing time-varying datasets.\\\",\\\"Authors\\\":\\\"Svakhine, N.;Yun Jang;Ebert, D.S.;Gaither, K.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;IllustrativeVisualization;Rendering;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532858\\\",\\\"Keywords\\\":\\\"flow visualization;photographic techniques;interactive volume illustration;non-photorealistic rendering\\\",\\\"Keywords_Processed\\\":\\\"non photorealistic rendering;photographic technique;interactive volume illustration;flow visualization\\\",\\\"Title\\\":\\\"Illustration and photography inspired visualization of flows and volumes\\\"},\\\"1034\\\":{\\\"Abstract\\\":\\\"Traditionally, time-varying data has been visualized using snapshots of the individual time steps or an animation of the snapshots shown in a sequential manner. For larger datasets with many time-varying features, animation can be limited in its use, as an observer can only track a limited number of features over the last few frames. Visually inspecting each snapshot is not practical either for a large number of time-steps. We propose new techniques inspired from the illustration literature to convey change over time more effectively in a time-varying dataset. Speedlines are used extensively by cartoonists to convey motion, speed, or change over different panels. Flow ribbons are another technique used by cartoonists to depict motion in a single frame. Strobe silhouettes are used to depict previous positions of an object to convey the previous positions of the object to the user. These illustration-inspired techniques can be used in conjunction with animation to convey change over time.\\\",\\\"Authors\\\":\\\"Joshi, A.;Rheingans, P.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;IllustrativeVisualization;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532857\\\",\\\"Keywords\\\":\\\"flow visualization;illustration;time-varying data;non-photorealistic rendering\\\",\\\"Keywords_Processed\\\":\\\"illustration;time vary datum;non photorealistic rendering;flow visualization\\\",\\\"Title\\\":\\\"Illustration-inspired techniques for visualizing time-varying data\\\"},\\\"1035\\\":{\\\"Abstract\\\":\\\"Indirect volume rendering is a widespread method for the display of volume datasets. It is based on the extraction of polygonal iso-surfaces from volumetric data, which are then rendered using conventional rasterization methods. Whereas this rendering approach is fast and relatively easy to implement, it cannot easily provide an understandable display of structures occluded by the directly visible iso-surface. Simple approaches like alpha-blending for transparency when drawing the iso-surface often generate a visually complex output, which is difficult to interpret. Moreover, such methods can significantly increase the computational complexity of the rendering process. In this paper, we therefore propose a new approach for the illustrative indirect rendering of volume data in real-time. This algorithm emphasizes the silhouette of objects represented by the iso-surface. Additionally, shading intensities on objects are reproduced with a monochrome hatching technique. Using a specially designed two-pass rendering process, structures behind the front layer of the iso-surface are automatically extracted with a depth peeling method. The shapes of these hidden structures are also displayed as silhouette outlines. As an additional option, the geometry of explicitly specified inner objects can be displayed with constant translucency. Although these inner objects always remain visible, a specific shading and depth attenuation method is used to convey the depth relationships. We describe the implementation of the algorithm, which exploits the programmability of state-of-the-art graphics processing units (GPUs). The algorithm described in this paper does not require any preprocessing of the input data or a manual definition of inner structures. Since the presented method works on iso-surfaces, which are stored as polygonal datasets, it can also be applied to other types of polygonal models.\\\",\\\"Authors\\\":\\\"Fischer, J.;Bartz, D.;Strasser, W.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;IllustrativeVisualization;ProgrammingAlgorithmsAndDataStructures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532855\\\",\\\"Keywords\\\":\\\"shading language;hatching;non-photorealistic rendering;indirect volume rendering;transparency;illustrative rendering\\\",\\\"Keywords_Processed\\\":\\\"transparency;non photorealistic rendering;indirect volume render;illustrative render;shade language;hatching\\\",\\\"Title\\\":\\\"Illustrative display of hidden iso-surface structures\\\"},\\\"1036\\\":{\\\"Abstract\\\":\\\"We describe a new dynamic level-of-detail (LOD) technique that allows real-time rendering of large tetrahedral meshes. Unlike approaches that require hierarchies of tetrahedra, our approach uses a subset of the faces that compose the mesh. No connectivity is used for these faces so our technique eliminates the need for topological information and hierarchical data structures. By operating on a simple set of triangular faces, our algorithm allows a robust and straightforward graphics hardware (GPU) implementation. Because the subset of faces processed can be constrained to arbitrary size, interactive rendering is possible for a wide range of data sets and hardware configurations.\\\",\\\"Authors\\\":\\\"Callahan, S.P.;Comba, J.L.D.;Shirley, P.;Silva, C.T.\\\",\\\"Clusters\\\":\\\"LevelOfDetail;MeshesGridsAndLattices;MultiresolutionTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532796\\\",\\\"Keywords\\\":\\\"level-of-detail;multi-resolution;interactive volume rendering;tetrahedral meshes\\\",\\\"Keywords_Processed\\\":\\\"interactive volume render;multi resolution;level of detail;tetrahedral mesh\\\",\\\"Title\\\":\\\"Interactive rendering of large unstructured grids using dynamic level-of-detail\\\"},\\\"1037\\\":{\\\"Abstract\\\":\\\"Simulations often generate large amounts of data that require use of SciVis techniques for effective exploration of simulation results. In some cases, like 1D theory of fluid dynamics, conventional SciVis techniques are not very useful. One such example is a simulation of injection systems that is becoming more and more important due to an increasingly restrictive emission regulations. There are many parameters and correlations among them that influence the simulation results. We describe how basic information visualization techniques can help in visualizing, understanding and analyzing this kind of data. The Com Vis tool is developed and used to analyze and explore the data. Com Vis supports multiple linked views and common information visualization displays such as 2D and 3D scatter-plot, histogram, parallel coordinates, pie-chart, etc. A diesel common rail injector with 2/2 way valve is used for a case study. Data sets were generated using a commercially available AVL HYDSIM simulation tool for dynamic analysis of hydraulic and hydro-mechanical systems, with the main application area in the simulation of fuel injection systems.\\\",\\\"Authors\\\":\\\"Matkovic, K.;Jelovic, M.;Juric, J.;Konyha, Z.;Gracanin, D.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;Engineering;Simulation;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532821\\\",\\\"Keywords\\\":\\\"visual exploration;information visualization;simulation;injection system\\\",\\\"Keywords_Processed\\\":\\\"injection system;simulation;information visualization;visual exploration\\\",\\\"Title\\\":\\\"Interactive visual analysis and exploration of injection systems simulations\\\"},\\\"1038\\\":{\\\"Abstract\\\":\\\"Doppler radars are useful facilities for weather forecasting. The data sampled by using Doppler radars are used to measure the distributions and densities of rain drops, snow crystals, hail stones, or even insects in the atmosphere. In this paper, we propose to build up a graphics-based software system for visualizing Doppler radar data. In the system, the reflectivity data gathered by using Doppler radars are post-processed to generate virtual cloud images which reveal the densities of precipitation in the air. An optical flow based method is adopted to compute the velocities of clouds, advected by winds. Therefore, the movement of clouds is depicted. The cloud velocities are also used to interpolate reflectivities for arbitrary time steps. Therefore, the reflectivities at any time can be produced. Our system composes of three stages. At the first stage, the raw radar data are re-sampled and filtered to create a multiple resolution data structure, based on a pyramid structure. At the second stage, a numeric method is employed to compute cloud velocities in the air and to interpolate radar reflectivity data at given time steps. The radar reflectivity data and cloud velocities are displayed at the last stage. The reflectivities are rendered by using splatting methods to produce semi-transparent cloud images. Two kinds of media are created for analyzing the reflectivity data. The first kind media consists of a group of still images of clouds which displays the distribution and density of water in the air. The second type media is a short animation of cloud images to show the formation and movement of the clouds. To show the advection of clouds, the cloud velocities are displayed by using two dimensional images. In these images, the velocities are represented by arrows and superimposed on cloud images. To enhance image quality, gradients and diffusion of the radar data are computed and used in the rendering process. Therefore the cloud structures are better portrayed. In order to achieve interactive visualization, our system is also comprised with a view-dependent visualization module. The radar data at far distance are rendered in lower resolutions, while the data closer to the eye position is rendered in details.\\\",\\\"Authors\\\":\\\"Shyh-Kuang Ueng;Sheng-Chuan Wang\\\",\\\"Clusters\\\":\\\"ImageBasedDataImageSignalProcessing;LevelOfDetail;PhysicsAndPhysicalSciences;VectorFieldsDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532849\\\",\\\"Keywords\\\":\\\"volume rendering;doppler radar;optical flow;level-of-detail;vector field visualization\\\",\\\"Keywords_Processed\\\":\\\"volume render;optical flow;doppler radar;level of detail;vector field visualization\\\",\\\"Title\\\":\\\"Interpolation and visualization for advected scalar fields\\\"},\\\"1039\\\":{\\\"Abstract\\\":\\\"We present a higher-order approach to the extraction of isosurfaces from unstructured meshes. Existing methods use linear interpolation along each mesh edge to find isosurface intersections. In contrast, our method determines intersections by performing barycentric interpolation over diamonds formed by the tetrahedra incident to each edge. Our method produces smoother, more accurate isosurfaces. Additionally, interpolating over diamonds, rather than linearly interpolating edge endpoints. enables us to identify up to two isosurface intersections per edge. This paper details how our new technique extracts isopoints, and presents a simple connection strategy for forming a triangle mesh isosurface.\\\",\\\"Authors\\\":\\\"Anderson, J.C.;Bennett, J.C.;Joy, K.I.\\\",\\\"Clusters\\\":\\\"Interpolation;IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532825\\\",\\\"Keywords\\\":\\\"isosurface extraction;unstructured mesh;interpolation\\\",\\\"Keywords_Processed\\\":\\\"interpolation;unstructured mesh;isosurface extraction\\\",\\\"Title\\\":\\\"Marching diamonds for unstructured meshes\\\"},\\\"1040\\\":{\\\"Abstract\\\":\\\"We present a multimodal paradigm for exploring topological surfaces embedded in four dimensions; we exploit haptic methods in particular to overcome the intrinsic limitations of 3D graphics images and 3D physical models. The basic problem is that, just as 2D shadows of 3D curves lose structure where lines cross, 3D graphics projections of smooth 4D topological surfaces are interrupted where one surface intersects another. Furthermore, if one attempts to trace real knotted ropes or a plastic models of self-intersecting surfaces with a fingertip, one inevitably collides with parts of the physical artifact. In this work, we exploit the free motion of a computer-based haptic probe to support a continuous motion that follows the local continuity of the object being explored. For our principal test case of 4D-embedded surfaces projected to 3D, this permits us to follow the full local continuity of the surface as though in fact we were touching an actual 4D object. We exploit additional sensory cues to provide supplementary or redundant information. For example, we can use audio tags to note the relative 4D depth of illusory 3D surface intersections produced by projection from 4D, as well as providing automated refinement of the tactile exploration path to eliminate jitter and snagging, resulting in a much cleaner exploratory motion than a bare uncorrected motion. Visual enhancements provide still further improvement to the feedback: by opening a view-direction-defined cutaway into the interior of the 3D surface projection, we allow the viewer to keep the haptic probe continuously in view as it traverses any touchable part of the object. Finally, we extend the static tactile exploration framework using a dynamic mode that links each stylus motion to a change in orientation that creates at each instant a maximal-area screen projection of a neighborhood of the current point of interest. This minimizes 4D distortion and permits true metric sizes to be deduced locally at any point. All these methods combine to reveal the full richness of the complex spatial relationships of the target shapes, and to overcome many expected perceptual limitations in 4D visualization.\\\",\\\"Authors\\\":\\\"Hanson, A.J.;Hui Zhang\\\",\\\"Clusters\\\":\\\"InputAndOutputDevicesGeneral;MultimodalDataTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532804\\\",\\\"Keywords\\\":\\\"visualization;haptics;multimodal\\\",\\\"Keywords_Processed\\\":\\\"visualization;multimodal;haptic\\\",\\\"Title\\\":\\\"Multimodal exploration of the fourth dimension\\\"},\\\"1041\\\":{\\\"Abstract\\\":\\\"The problem of perceptually optimizing complex visualizations is a difficult one, involving perceptual as well as aesthetic issues. In our experience, controlled experiments are quite limited in their ability to uncover interrelationships among visualization parameters, and thus may not be the most useful way to develop rules-of-thumb or theory to guide the production of high-quality visualizations. In this paper, we propose a new experimental approach to optimizing visualization quality that integrates some of the strong points of controlled experiments with methods more suited to investigating complex highly-coupled phenomena. We use human-in-the-loop experiments to search through visualization parameter space, generating large databases of rated visualization solutions. This is followed by data mining to extract results such as exemplar visualizations, guidelines for producing visualizations, and hypotheses about strategies leading to strong visualizations. The approach can easily address both perceptual and aesthetic concerns, and can handle complex parameter interactions. We suggest a genetic algorithm as a valuable way of guiding the human-in-the-loop search through visualization parameter space. We describe our methods for using clustering, histogramming, principal component analysis, and neural networks for data mining. The experimental approach is illustrated with a study of the problem of optimal texturing for viewing layered surfaces so that both surfaces are maximally observable.\\\",\\\"Authors\\\":\\\"House, D.;Bair, A.;Ware, C.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;DimensionalityReduction;EvaluationGeneral;Genetics;MachineLearningAndStatistics;Perception;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532782\\\",\\\"Keywords\\\":\\\"layered surfaces;data mining;perception;genetic algorithm;neural networks;visualization evaluation;principal component analysis\\\",\\\"Keywords_Processed\\\":\\\"perception;principal component analysis;neural network;datum mining;visualization evaluation;genetic algorithm;layer surface\\\",\\\"Title\\\":\\\"On the optimization of visualizations of complex phenomena\\\"},\\\"1042\\\":{\\\"Abstract\\\":\\\"We describe OpenGL multipipe SDK (MPK), a toolkit for scalable parallel rendering based on OpenGL. MPK provides a uniform application programming interface (API) to manage scalable graphics applications across many different graphics subsystems. MPK-based applications run seamlessly from single-processor, single-pipe desktop systems to large multi-processor, multipipe scalable graphics systems. The application is oblivious of the system configuration, which can be specified through a configuration file at run time. To scale application performance, MPK uses a decomposition system that supports different modes for task partitioning and implements optimized CPU-based composition algorithms. MPK also provides a customizable image composition interface, which can be used to apply post-processing algorithms on raw pixel data obtained from executing sub-tasks on multiple graphics pipes in parallel. This can be used to implement parallel versions of any CPU-based algorithm, not necessarily used for rendering. In this paper, we motivate the need for a scalable graphics API and discuss the architecture of MPK. We present MPK's graphics configuration interface, introduce the notion of compound-based decomposition schemes and describe our implementation. We present some results from our work on a couple of target system architectures and conclude with future directions of research in this area.\\\",\\\"Authors\\\":\\\"Bhaniramka, P.;Robert, P.C.D.;Eilemann, S.\\\",\\\"Clusters\\\":\\\"ImmersiveAndVirtualEnvironments;InputAndOutputDevicesGeneral;ParallelSystemsAndParallelProcessing;Rendering\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532786\\\",\\\"Keywords\\\":\\\"scalable rendering;parallel rendering;immersive environments;scalable graphics hardware\\\",\\\"Keywords_Processed\\\":\\\"parallel rendering;scalable graphic hardware;scalable rendering;immersive environment\\\",\\\"Title\\\":\\\"OpenGL multipipe SDK: a toolkit for scalable parallel rendering\\\"},\\\"1043\\\":{\\\"Abstract\\\":\\\"Artificial neural networks are computer software or hardware models inspired by the structure and behavior of neurons in the human nervous system. As a powerful learning tool, increasingly neural networks have been adopted by many large-scale information processing applications but there is no a set of well defined criteria for choosing a neural network. The user mostly treats a neural network as a black box and cannot explain how learning from input data was done nor how performance can be consistently ensured. We have experimented with several information visualization designs aiming to open the black box to possibly uncover underlying dependencies between the input data and the output data of a neural network. In this paper, we present our designs and show that the visualizations not only help us design more efficient neural networks, but also assist us in the process of using neural networks for problem solving such as performing a classification task.\\\",\\\"Authors\\\":\\\"Tzeng, F.-Y.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;MachineLearningAndStatistics;SegmentationAndClassification;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532820\\\",\\\"Keywords\\\":\\\"information visualization;machine learning;visualization application;classification;artificial neural network\\\",\\\"Keywords_Processed\\\":\\\"machine learning;artificial neural network;information visualization;classification;visualization application\\\",\\\"Title\\\":\\\"Opening the black box - data driven visualization of neural networks\\\"},\\\"1044\\\":{\\\"Abstract\\\":\\\"Gaining a comprehensive understanding of turbulent flows still poses one of the great challenges in fluid dynamics. A well-established approach to advance this research is the analysis of the vortex structures contained in the flow. In order to be able to perform this analysis efficiently, supporting visualization tools with clearly defined requirements are needed. In this paper, we present a visualization system which matches these requirements to a large extent. The system consists of two components. The first component analyzes the flow by means of a novel combination of vortex core line detection and the 2 method. The second component is a vortex browser which allows for an interactive exploration and manipulation of the vortices detected and separated during the first phase. Our system improves the reliability and applicability of existing vortex detection methods and allows for a more efficient study of vortical flows which is demonstrated in an evaluation performed by experts.\\\",\\\"Authors\\\":\\\"Stegmaier, S.;Rist, U.;Ertl, T.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;ManipulationAndDeformation;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532830\\\",\\\"Keywords\\\":\\\"3d vector field visualization;flow features;interactive manipulation;vortex detection\\\",\\\"Keywords_Processed\\\":\\\"vortex detection;flow feature;3d vector field visualization;interactive manipulation\\\",\\\"Title\\\":\\\"Opening the can of worms: an exploration tool for vortical flows\\\"},\\\"1045\\\":{\\\"Abstract\\\":\\\"We propose a hybrid particle and texture based approach for the visualization of time-dependent vector fields. The underlying space-time framework builds a dense vector field representation in a two-step process: 1) particle-based forward integration of trajectories in spacetime for temporal coherence, and 2) texture-based convolution along another set of paths through the spacetime for spatially correlated patterns. Particle density is controlled by stochastically injecting and removing particles, taking into account the divergence of the vector field. Alternatively, a uniform density can be maintained by placing exactly one particle in each cell of a uniform grid, which leads to particle-in-cell forward advection. Moreover, we discuss strategies of previous visualization methods for unsteady flow and show how they address issues of spatiotemporal coherence and dense visual representations. We demonstrate how our framework is capable of realizing several of these strategies. Finally, we present an efficient GPU implementation that facilitates an interactive visualization of unsteady 2D flow on Shader Model 3 compliant graphics hardware.\\\",\\\"Authors\\\":\\\"Weiskopf, D.;Schramm, F.;Erlebacher, G.;Ertl, T.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;GpuBasedTechniques;ParticleVisualizationAndTechniques;Textures;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532852\\\",\\\"Keywords\\\":\\\"unsteady flow visualization;gpu methods;visualization framework;line integral convolution;particle systems;texture advection\\\",\\\"Keywords_Processed\\\":\\\"visualization framework;particle system;line integral convolution;texture advection;unsteady flow visualization;gpu method\\\",\\\"Title\\\":\\\"Particle and texture based spatiotemporal visualization of time-dependent vector fields\\\"},\\\"1046\\\":{\\\"Abstract\\\":\\\"We present a new particle tracing approach for the simulation of mid- and high-frequency sound. Inspired by the photorealism obtained by methods like photon mapping, we develop a similar method for the physical simulation of sound within rooms. For given source and listener positions, our method computes a finite-response filter accounting for the different reflections at various surfaces with frequency-dependent absorption coefficients. Convoluting this filter with an anechoic input signal reproduces a realistic aural impression of the simulated room. We do not consider diffraction effects due to low frequencies, since these can be better computed by finite elements. Our method allows the visualization of a wave front propagation using color-coded blobs traversing the paths of individual phonons.\\\",\\\"Authors\\\":\\\"Bertram, M.;Deines, E.;Mohring, J.;Jegorovs, J.;Hagen, H.\\\",\\\"Clusters\\\":\\\"AcousticsSoundSonification;Illumination;RaytracingRaycasting\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532790\\\",\\\"Keywords\\\":\\\"raytracing;photon mapping;acoustics;auralization\\\",\\\"Keywords_Processed\\\":\\\"auralization;acoustic;raytrace;photon mapping\\\",\\\"Title\\\":\\\"Phonon tracing for auralization and visualization of sound\\\"},\\\"1047\\\":{\\\"Abstract\\\":\\\"In this paper a novel high-quality reconstruction scheme is presented. Although our method is mainly proposed to reconstruct volumetric data sampled on an optimal body-centered cubic (BCC) grid, it can be easily adapted lo the conventional regular rectilinear grid as well. The reconstruction process is decomposed into two steps. The first step, which is considered to be a preprocessing, is a discrete Gaussian deconvolution performed only once in the frequency domain. Afterwards, the second step is a spatial-domain convolution with a truncated Gaussian kernel, which is used to interpolate arbitrary samples for ray casting. Since the preprocessing is actually a discrete prefiltering, we call our technique prefiltered Gaussian reconstruction (PGR). It is shown that the impulse response of PGR well approximates the ideal reconstruction kernel. Therefore the quality of PGR is much higher than that of previous reconstruction techniques proposed for optimally sampled data, which are based on linear and cubic box splines adapted to the BCC grid. Concerning the performance, PGR is slower than linear box-spline reconstruction but significantly faster than cubic box-spline reconstruction.\\\",\\\"Authors\\\":\\\"Csebfalvi, B.\\\",\\\"Clusters\\\":\\\"Interpolation;MeshesGridsAndLattices;Sampling\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532810\\\",\\\"Keywords\\\":\\\"optimal regular volume sampling;reconstruction;radial basis function interpolation;body-centered cubic grid\\\",\\\"Keywords_Processed\\\":\\\"body center cubic grid;reconstruction;optimal regular volume sample;radial basis function interpolation\\\",\\\"Title\\\":\\\"Prefiltered Gaussian reconstruction for high-quality rendering of volumetric data sampled on a body-centered cubic grid\\\"},\\\"1048\\\":{\\\"Abstract\\\":\\\"This paper describes a tool for the visualization of T2 maps of knee cartilage. Given the anatomical scan, and the T2 map of the cartilage, we combine the information on the shape and the quality of the cartilage in a single image. The Profile Flag is an intuitive 3D glyph for probing and annotating of the underlying data. It comprises a bulletin board pin-like shape with a small flag on top of it. While moving the glyph along the reconstructed surface of an object, the curve data measured along the pin's needle and in its neighborhood are shown on the flag. The application area of the Profile Flag is manifold, enabling the visualization of profile data of dense but in-homogeneous objects. Furthermore, it extracts the essential part of the data without removing or even reducing the context information. By sticking Profile Flags into the investigated structure, one or more significant locations can be annotated by showing the local characteristics of the data at that locations. In this paper we are demonstrating the properties of the tool by visualizing T2 maps of knee cartilage.\\\",\\\"Authors\\\":\\\"Mlejnek, M.;Ermest, P.;Vilanova, A.;van der Rijt, R.;van den Bosch, H.;Gerritsen, F.;Groller, E.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;BiomedicalScienceAndMedicine\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532847\\\",\\\"Keywords\\\":\\\"applications of visualization;visualization in medicine\\\",\\\"Keywords_Processed\\\":\\\"visualization in medicine;application of visualization\\\",\\\"Title\\\":\\\"Profile Flags: a novel metaphor for probing of T<sub>2</sub> maps\\\"},\\\"1049\\\":{\\\"Abstract\\\":\\\"Quality surface meshes for molecular models are desirable in the studies of protein shapes and functionalities. However, there is still no robust software that is capable to generate such meshes with good quality. In this paper, we present a Delaunay-based surface triangulation algorithm generating quality surface meshes for the molecular skin model. We expand the restricted union of balls along the surface and generate an -sampling of the skin surface incrementally. At the same time, a quality surface mesh is extracted from the Delaunay triangulation of the sample points. The algorithm supports robust and efficient implementation and guarantees the mesh quality and topology as well. Our results facilitate molecular visualization and have made a contribution towards generating quality volumetric tetrahedral meshes for the macromolecules.\\\",\\\"Authors\\\":\\\"Cheng, H.-L.;Shi, X.\\\",\\\"Clusters\\\":\\\"MeshesGridsAndLattices;SurfaceRelatedDataAndTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532822\\\",\\\"Keywords\\\":\\\"restricted union of balls;smooth surfaces;delaunay triangulation;meshing;guaranteed quality triangulation;homeomorphism\\\",\\\"Keywords_Processed\\\":\\\"homeomorphism;delaunay triangulation;restrict union of ball;mesh;smooth surface;guarantee quality triangulation\\\",\\\"Title\\\":\\\"Quality mesh generation for molecular skin surfaces using restricted union of balls\\\"},\\\"1050\\\":{\\\"Abstract\\\":\\\"We present a practical and general-purpose approach to large and complex visual data analysis where visualization processing, rendering and subsequent human interpretation is constrained to the subset of data deemed interesting by the user. In many scientific data analysis applications, interesting data can be defined by compound Boolean range queries of the form (temperature > 1000) AND (70 < pressure < 90). As data sizes grow larger, a central challenge is to answer such queries as efficiently as possible. Prior work in the visualization community has focused on answering range queries for scalar fields within the context of accelerating the search phase of isosurface algorithms. In contrast, our work describes an approach that leverages state-of-the-art indexing technology from the scientific data management community called bitmap indexing. Our implementation, which we call DEX (short for dextrous data explorer), uses bitmap indexing to efficiently answer multivariate, multidimensional data queries to provide input to a visualization pipeline. We present an analysis overview and benchmark results that show bitmap indexing offers significant storage and performance improvements when compared to previous approaches for accelerating the search phase of isosurface algorithms. More importantly, since bitmap indexing supports complex multidimensional, multivariate range queries, it is more generally applicable to scientific data visualization and analysis problems. In addition to benchmark performance and analysis, we apply DEX to a typical scientific visualization problem encountered in combustion simulation data analysis.\\\",\\\"Authors\\\":\\\"Stockinger, K.;Shalf, J.;Kesheng Wu;Bethel, E.W.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;DataAcquisitionAndManagement;ImageBasedDataImageSignalProcessing;LargeScaleDataAndScalability;MultidimensionalMultivariateMultifieldDataAndTechniques;QueriesAndSearch;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532792\\\",\\\"Keywords\\\":\\\"bitmap index;large data visualization;scientific data management;query-driven visualization;data analysis;multivariate visualization;visual analytics\\\",\\\"Keywords_Processed\\\":\\\"scientific data management;query drive visualization;large datum visualization;multivariate visualization;visual analytic;datum analysis;bitmap index\\\",\\\"Title\\\":\\\"Query-driven visualization of large data sets\\\"},\\\"1051\\\":{\\\"Abstract\\\":\\\"This paper presents a novel approach for surface reconstruction from point clouds. The proposed technique is general in the sense that it naturally handles both manifold and non-manifold surfaces, providing a consistent way for reconstructing closed surfaces as well as surfaces with boundaries. It is also robust in the presence of noise, irregular sampling and surface gaps. Furthermore, it is fast, parallelizable and easy to implement because it is based on simple local operations. In this approach, surface reconstruction consists of three major steps: first, the space containing the point cloud is subdivided, creating a voxel representation. Then, a voxel surface is computed using gap filling and topological thinning operations. Finally, the resulting voxel surface is converted into a polygonal mesh. We demonstrate the effectiveness of our approach by reconstructing polygonal models from range scans of real objects as well as from synthetic data.\\\",\\\"Authors\\\":\\\"Wang, J.;Oliveira, M.M.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"SurfaceRelatedDataAndTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532824\\\",\\\"Keywords\\\":\\\"topological thinning;non-manifold surfaces;surface reconstruction\\\",\\\"Keywords_Processed\\\":\\\"non manifold surface;topological thinning;surface reconstruction\\\",\\\"Title\\\":\\\"Reconstructing manifold and non-manifold surfaces from point clouds\\\"},\\\"1052\\\":{\\\"Abstract\\\":\\\"Stars form in dense clouds of interstellar gas and dust. The residual dust surrounding a young star scatters and diffuses its light, making the star's \\\\\\\"cocoon\\\\\\\" of dust observable from Earth. The resulting structures, called reflection nebulae, are commonly very colorful in appearance due to wavelength-dependent effects in the scattering and extinction of light. The intricate interplay of scattering and extinction cause the color hues, brightness distributions, and the apparent shapes of such nebulae to vary greatly with viewpoint. We describe an interactive visualization tool for realistically rendering the appearance of arbitrary 3D dust distributions surrounding one or more illuminating stars. Our rendering algorithm is based on the physical models used in astrophysics research. The tool can be used to create virtual fly-throughs of reflection nebulae for interactive desktop visualizations, or to produce scientifically accurate animations for educational purposes, e.g., in planetarium shows. The algorithm is also applicable to investigate on-the-fly the visual effects of physical parameter variations, exploiting visualization technology to help gain a deeper and more intuitive understanding of the complex interaction of light and dust in real astrophysical settings.\\\",\\\"Authors\\\":\\\"Magnor, M.;Hildebrand, K.;Lintu, A.;Hanson, A.J.\\\",\\\"Clusters\\\":\\\"AstronomyAstrophysics;Illumination;MaterialScience;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532803\\\",\\\"Keywords\\\":\\\"astronomy;volume rendering;nebula;global illumination;dust\\\",\\\"Keywords_Processed\\\":\\\"volume render;global illumination;astronomy;nebula;dust\\\",\\\"Title\\\":\\\"Reflection nebula visualization\\\"},\\\"1053\\\":{\\\"Abstract\\\":\\\"This paper presents a novel method for computing simulated x-ray images, or DRRs (digitally reconstructed radiographs), of tetrahedral meshes with higher-order attenuation functions. DRRs are commonly used in computer assisted surgery (CAS), with the attenuation function consisting of a voxelized CT study, which is viewed from different directions. Our application of DRRs is in intra-operative \\\\\\\"2D-3D\\\\\\\" registration, i.e., finding the pose of the CT dataset given a small number of patient radiographs. We register 2D patient images with a statistical tetrahedral model, which encodes the CT intensity numbers as Bernstein polynomials, and includes knowledge about typical shape variation modes. The unstructured grid is more suitable for applying deformations than a rectilinear grid, and the higher-order polynomials provide a better approximation of the actual density than constant or linear models. The infra-operative environment demands a fast method for creating the DRRs, which we present here. We demonstrate this application through the creation and use of a deformable atlas of human pelvis bones. Compared with other works on rendering unstructured grids, the main contributions of this work are: 1) Simple and perspective-correct interpolation of the thickness of a tetrahedral cell. 2) Simple and perspective-correct interpolation of front and back barycentric coordinates with respect to the cell. 3) Computing line integrals of higher-order functions. 4) Capability of applying shape deformations and variations in the attenuation function without significant performance loss. The method does not depend on for pre-integration, and does not require depth-sorting of the visualized cells. We present imaging and timing results of implementing the algorithm, and discuss the impact of using higher-order functions on the quality of the result and the performance.\\\",\\\"Authors\\\":\\\"Sadowsky, O.;Cohen, J.D.;Taylor, R.H.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;MeshesGridsAndLattices;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532809\\\",\\\"Keywords\\\":\\\"volume rendering;higher-order volumetric functions;digital radiograph reconstruction;unstructured grid;projected tetrahedra\\\",\\\"Keywords_Processed\\\":\\\"volume render;project tetrahedra;digital radiograph reconstruction;unstructured grid;high order volumetric function\\\",\\\"Title\\\":\\\"Rendering tetrahedral meshes with higher-order attenuation functions for digital radiograph reconstruction\\\"},\\\"1054\\\":{\\\"Abstract\\\":\\\"As standard volume rendering is based on an integral in physical space (or \\\\\\\"coordinate space\\\\\\\"), it is inherently dependent on the scaling of this space. Although this dependency is appropriate for the realistic rendering of semitransparent volumetric objects, it has several unpleasant consequences for volume visualization. In order to overcome these disadvantages, a new variant of the volume rendering integral is proposed, which is defined in data space instead of physical space. Apart from achieving scale invariance, this new method supports the rendering of isosurfaces of uniform opacity and color, independently of the local gradient or\\\\\\\" the visualized scalar field. Moreover, it reveals certain structures in scalar fields even with constant transfer functions. Furthermore, it can be defined as the limit of infinitely many semitransparent isosurfaces, and is therefore based on an intuitive and at the same time precise definition. In addition to the discussion of these features of scale-invariant volume rendering, efficient adaptations of existing volume rendering algorithms and extensions for silhouette enhancement and local illumination by transmitted light are presented.\\\",\\\"Authors\\\":\\\"Kraus, M.\\\",\\\"Clusters\\\":\\\"IllustrativeVisualization;IsosurfaceAndSurfaceExtractionTechniques;OcclusionProblemsTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532808\\\",\\\"Keywords\\\":\\\"volume rendering;translucence;volume visualization;isosurface;volume shading;silhouette enhancement\\\",\\\"Keywords_Processed\\\":\\\"volume render;volume shade;translucence;silhouette enhancement;isosurface;volume visualization\\\",\\\"Title\\\":\\\"Scale-invariant volume rendering\\\"},\\\"1055\\\":{\\\"Abstract\\\":\\\"Traditionally, sort-middle is a technique that has been difficult to attain on clusters because of the tight coupling of geometry and rasterization processes on commodity graphics hardware. In this paper, we describe the implementation of a new sort-middle approach for performing immediate-mode rendering in Chromium. The Chromium Rendering System is used extensively to drive multi-projector displays on PC clusters with inexpensive commodity graphics components. By default, Chromium uses a sort-first approach to distribute rendering work to individual nodes in a PC cluster. While this sort-first approach works effectively in retained-mode rendering, it suffers from various network bottlenecks when rendering in immediate-mode. Current techniques avoid these bottlenecks by sorting vertex data as a pre-processing step and grouping vertices into specific bounding boxes, using Chromium's bounding box extension. These steps may be expensive, especially if the dataset is dynamic. In our approach, we utilize standard programmable graphics hardware and extend standard APIs to achieve a separation in the rendering pipeline. The pre-processing of vertex data or the grouping of vertices into bounding boxes are not required. Additionally, the amount of OpenGL state commands transmitted through the network are reduced. Our results indicate that the approach can attain twice the frame rates as compared to Chromium's sort-first approach when rendering in immediate-mode.\\\",\\\"Authors\\\":\\\"Williams, J.L.;Hiromoto, R.E.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;DisplaysGeneral;LargeAndHighResDisplays;ProgrammingAlgorithmsAndDataStructures;Rendering\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532784\\\",\\\"Keywords\\\":\\\"multi-projector;cluster rendering;immediate-mode rendering;sort-middle;tiled displays\\\",\\\"Keywords_Processed\\\":\\\"cluster render;multi projector;immediate mode render;tile display;sort middle\\\",\\\"Title\\\":\\\"Sort-middle multi-projector immediate-mode rendering in Chromium\\\"},\\\"1056\\\":{\\\"Abstract\\\":\\\"Visualization users are increasingly in need of techniques for assessing quantitative uncertainty and error in the images produced. Statistical segmentation algorithms compute these quantitative results, yet volume rendering tools typically produce only qualitative imagery via transfer function-based classification. This paper presents a visualization technique that allows users to interactively explore the uncertainty, risk, and probabilistic decision of surface boundaries. Our approach makes it possible to directly visualize the combined \\\\\\\"fuzzy\\\\\\\" classification results from multiple segmentations by combining these data into a unified probabilistic data space. We represent this unified space, the combination of scalar volumes from numerous segmentations, using a novel graph-based dimensionality reduction scheme. The scheme both dramatically reduces the dataset size and is suitable for efficient, high quality, quantitative visualization. Lastly, we show that the statistical risk arising from overlapping segmentations is a robust measure for visualizing features and assigning optical properties.\\\",\\\"Authors\\\":\\\"Kniss, J.;Van Uitert, R.;Stephens, A.;Li, G.-S.;Tasdizen, T.;Hansen, C.\\\",\\\"Clusters\\\":\\\"SegmentationAndClassification;UncertaintyTechniquesAndVisualization;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532807\\\",\\\"Keywords\\\":\\\"classification;volume visualization;risk analysis;uncertainty\\\",\\\"Keywords_Processed\\\":\\\"uncertainty;volume visualization;risk analysis;classification\\\",\\\"Title\\\":\\\"Statistically quantitative volume visualization\\\"},\\\"1057\\\":{\\\"Abstract\\\":\\\"This paper presents a strategy for seeding streamlines in 3D flow fields. Its main goal is to capture the essential flow patterns and to provide sufficient coverage in the field while reducing clutter. First, critical points of the flow field are extracted to identify regions with important flow patterns that need to be presented. Different seeding templates are then used around the vicinity of the different critical points. Because there is significant variability in the flow pattern even for the same type of critical point, our template can change shape depending on how far the critical point is from transitioning into another type of critical point. To accomplish this, we introduce the - map of 3D critical points. Next, we use Poisson seeding to populate the empty regions. Finally, we filter the streamlines based on their geometric and spatial properties. Altogether, this multi-step strategy reduces clutter and yet captures the important 3D flow features.\\\",\\\"Authors\\\":\\\"Xiangong Ye;Kao, D.;Pang, A.\\\",\\\"Clusters\\\":\\\"DataFeaturesAndAttributes;FilteringTechniques;FlowVisualizationDataAndTechniques;ProgrammingAlgorithmsAndDataStructures;StreamlinesPathlinesStreaklines;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532831\\\",\\\"Keywords\\\":\\\"critical points;streamlines;flow-guided;feature-based;variable templates;filtering\\\",\\\"Keywords_Processed\\\":\\\"streamline;variable template;critical point;filter;feature base;flow guide\\\",\\\"Title\\\":\\\"Strategy for seeding 3D streamlines\\\"},\\\"1058\\\":{\\\"Abstract\\\":\\\"With the growing size of captured 3D models it has become increasingly important to provide basic efficient processing methods for large unorganized raw surface-sample point data sets. In this paper we introduce a novel stream-based (and out-of-core) point processing framework. The proposed approach processes points in an orderly sequential way by sorting them and sweeping along a spatial dimension. The major advantages of this new concept are: (1) support of extensible and concatenate local operators called stream operators, (2) low main-memory usage and (3) applicability to process very large data sets out-of-core.\\\",\\\"Authors\\\":\\\"Pajarola, R.\\\",\\\"Clusters\\\":\\\"CurvesAndCurvature;DataAcquisitionAndManagement;GeometricModeling;Interpolation;PointBasedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532801\\\",\\\"Keywords\\\":\\\"curvature estimation;sequential processing;normal estimation;fairing;point processing\\\",\\\"Keywords_Processed\\\":\\\"curvature estimation;sequential processing;point processing;fair;normal estimation\\\",\\\"Title\\\":\\\"Stream-processing points\\\"},\\\"1059\\\":{\\\"Abstract\\\":\\\"We present a robust method for 3D reconstruction of closed surfaces from sparsely sampled parallel contours. A solution to this problem is especially important for medical segmentation, where manual contouring of 2D imaging scans is still extensively used. Our proposed method is based on a morphing process applied to neighboring contours that sweeps out a 3D surface. Our method is guaranteed to produce closed surfaces that exactly pass through the input contours, regardless of the topology of the reconstruction. Our general approach consecutively morphs between sets of input contours using an Eulerian formulation (i.e. fixed grid) augmented with Lagrangian particles (i.e. interface tracking). This is numerically accomplished by propagating the input contours as 2D level sets with carefully constructed continuous speed functions. Specifically this involves particle advection to estimate distances between the contours, monotonicity constrained spline interpolation to compute continuous speed functions without overshooting, and state-of-the-art numerical techniques for solving the level set equations. We demonstrate the robustness of our method on a variety of medical, topographic and synthetic data sets.\\\",\\\"Authors\\\":\\\"Nilsson, O.;Breen, D.;Museth, K.\\\",\\\"Clusters\\\":\\\"ContourCreasesRidgesValleys;NumericalMethodsMathematics;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532823\\\",\\\"Keywords\\\":\\\"level sets;contours;3d reconstruction\\\",\\\"Keywords_Processed\\\":\\\"level set;contour;3d reconstruction\\\",\\\"Title\\\":\\\"Surface reconstruction via contour metamorphosis: an Eulerian approach with Lagrangian particle tracking\\\"},\\\"1060\\\":{\\\"Abstract\\\":\\\"We present a new method for guiding virtual colonoscopic navigation and registration by using teniae coli as anatomical landmarks. As most existing protocols require a patient to be scanned in both supine and prone positions to increase sensitivity in detecting colonic polyps, reference and registration between scans are necessary. However, the conventional centerline approach, generating only the longitudinal distance along the colon, lacks the necessary orientation information to synchronize the virtual navigation cameras in both scanned positions. In this paper we describe a semi-automatic method to detect teniae coli from a colonic surface model reconstructed from CT colonography. Teniae coli are three bands of longitudinal smooth muscle on the surface of the colon. They form a triple helix structure from the appendix to the sigmoid colon and are ideal references for virtual navigation. Our method was applied to 3 patients resulting in 6 data sets (supine and prone scans). The detected teniae coli matched well with our visual inspection. In addition, we demonstrate that polyps visible on both scans can be located and matched more efficiently with the aid of a teniae coli guided navigation implementation.\\\",\\\"Authors\\\":\\\"Huang, A.;Roy, D.;Franaszek, M.;Summers, R.M.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;CamerasCameraViewsAndProjections;Parameterization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532806\\\",\\\"Keywords\\\":\\\"colon flattening;computed tomography colonography;parameterization;virtual colonoscopy;computer-aided diagnosis;virtual endoscopy;camera control\\\",\\\"Keywords_Processed\\\":\\\"camera control;virtual colonoscopy;virtual endoscopy;colon flatten;computer aid diagnosis;parameterization;compute tomography colonography\\\",\\\"Title\\\":\\\"Teniae coli guided navigation and registration for virtual colonoscopy\\\"},\\\"1061\\\":{\\\"Abstract\\\":\\\"In this paper, we present two novel texture-based techniques to visualize uncertainty in time-dependent 2D flow fields. Both methods use semi-Lagrangian texture advection to show flow direction by streaklines and convey uncertainty by blurring these streaklines. The first approach applies a cross advection perpendicular to the flow direction. The second method employs isotropic diffusion that can be implemented by Gaussian filtering. Both methods are derived from a generic filtering process that is incorporated into the traditional texture advection pipeline. Our visualization methods allow for a continuous change of the density of flow representation by adapting the density of particle injection. All methods can be mapped to efficient GPU implementations. Therefore, the user can interactively control all important characteristics of the system like particle density, error influence, or dye injection to create meaningful illustrations of the underlying uncertainty. Even though there are many sources of uncertainties, we focus on uncertainty that occurs during data acquisition. We demonstrate the usefulness of our methods for the example of real-world fluid flow data measured with the particle image velocimetry (PIV) technique. Furthermore, we compare these techniques with an adapted multi-frequency noise approach.\\\",\\\"Authors\\\":\\\"Botchen, R.P.;Weiskopf, D.;Ertl, T.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;GpuBasedTechniques;Textures;UncertaintyTechniquesAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532853\\\",\\\"Keywords\\\":\\\"unsteady flow visualization;texture advection;gpu programming;uncertainty visualization\\\",\\\"Keywords_Processed\\\":\\\"texture advection;uncertainty visualization;gpu programming;unsteady flow visualization\\\",\\\"Title\\\":\\\"Texture-based visualization of uncertainty in flow fields\\\"},\\\"1062\\\":{\\\"Abstract\\\":\\\"In this paper we introduce GPU particle tracing for the visualization of 3D diffusion tensor fields. For about half a million particles, reconstruction of diffusion directions from the tensor field, time integration and rendering can be done at interactive rates. Different visualization options like oriented particles of diffusion-dependent shape, stream lines or stream tubes facilitate the use of particle tracing for diffusion tensor visualization. The proposed methods provide efficient and intuitive means to show the dynamics in diffusion tensor fields, and they accommodate the exploration of the diffusion properties of biological tissue.\\\",\\\"Authors\\\":\\\"Kondratieva, P.;Kruger, J.;Westermann, R.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DynamicVisualizationVisualizationOfChange;GpuBasedTechniques;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532780\\\",\\\"Keywords\\\":\\\"gpu particle tracing and streamlines;medical visualization;dynamic visualization;diffusion tensor\\\",\\\"Keywords_Processed\\\":\\\"diffusion tensor;dynamic visualization;gpu particle tracing and streamline;medical visualization\\\",\\\"Title\\\":\\\"The application of GPU particle tracing to diffusion tensor field visualization\\\"},\\\"1063\\\":{\\\"Abstract\\\":\\\"The size and resolution of volume datasets in science and medicine are increasing at a rate much greater than the resolution of the screens used to view them. This limits the amount of data that can be viewed simultaneously, potentially leading to a loss of overall context of the data when the user views or zooms into a particular area of interest. We propose a focus+context framework that uses various standard and advanced magnification lens rendering techniques to magnify the features of interest, while compressing the remaining volume regions without clipping them away completely. Some of these lenses can be interactively configured by the user to specify the desired magnification patterns, while others are feature-adaptive. All our lenses are accelerated on the GPU. They allow the user to interactively manage the available screen area, dedicating more area to the more resolution-important features.\\\",\\\"Authors\\\":\\\"Lujin Wang;Ye Zhao;Mueller, K.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;HardwareAccellerationAndComputationGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532818\\\",\\\"Keywords\\\":\\\"focus+context technique;volume rendering;hardware assisted volume rendering;lens\\\",\\\"Keywords_Processed\\\":\\\"hardware assist volume render;volume render;focus context technique;lens\\\",\\\"Title\\\":\\\"The magic volume lens: an interactive focus+context technique for volume rendering\\\"},\\\"1064\\\":{\\\"Abstract\\\":\\\"We have developed a real-time experiment-control and data-display system for a novel microscope, the 3D-force microscope (3DFM), which is designed for nanometer-scale and nanoNewton-force biophysical experiments. The 3DFM software suite synthesizes the several data sources from the 3DFM into a coherent view and provides control over data collection and specimen manipulation. Herein, we describe the system architecture designed to handle the several feedback loops and data flows present in the microscope and its control system. We describe the visualization techniques used in the 3DFM software suite, where used, and on which types of data. We present feedback from our scientist-users regarding the usefulness of these techniques, and we also present lessons learned from our successive implementations.\\\",\\\"Authors\\\":\\\"Marshburn, D.;Weigle, C.;Wilde, B.G.;Taylor, R.M.;Desai, K.;Fisher, J.K.;Cribb, J.;O'Brien, E.T.;Superfine, R.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;ImmersiveAndVirtualEnvironments;InputAndOutputDevicesGeneral;InteractionTechniquesGeneral;Microscopy;MultimodalDataTechniques;PhysicsAndPhysicalSciences;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532829\\\",\\\"Keywords\\\":\\\"virtual worlds;haptics;multimodal visualization;applications of visualization;scientific visualization;interactive graphics;force;microscopy\\\",\\\"Keywords_Processed\\\":\\\"force;microscopy;application of visualization;scientific visualization;virtual world;interactive graphic;haptic;multimodal visualization\\\",\\\"Title\\\":\\\"The software interface to the 3D-force microscope\\\"},\\\"1065\\\":{\\\"Abstract\\\":\\\"The field of visualization is getting mature. Many problems have been solved, and new directions are sought for. In order to make good choices, an understanding of the purpose and meaning of visualization is needed. Especially, it would be nice if we could assess what a good visualization is. In this paper an attempt is made to determine the value of visualization. A technological viewpoint is adopted, where the value of visualization is measured based on effectiveness and efficiency. An economic model of visualization is presented, and benefits and costs are established. Next, consequences (brand limitations of visualization are discussed (including the use of alternative methods, high initial costs, subjective/less, and the role of interaction), as well as examples of the use of the model for the judgement of existing classes of methods and understanding why they are or are not used in practice. Furthermore, two alternative views on visualization are presented and discussed: viewing visualization as an art or as a scientific discipline. Implications and future directions are identified.\\\",\\\"Authors\\\":\\\"van Wijk, J.J.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532781\\\",\\\"Keywords\\\":\\\"visualization;evaluation\\\",\\\"Keywords_Processed\\\":\\\"visualization;evaluation\\\",\\\"Title\\\":\\\"The value of visualization\\\"},\\\"1066\\\":{\\\"Abstract\\\":\\\"In this case study, a data-oriented approach is used to visualize a complex digital signal processing pipeline. The pipeline implements a frequency modulated (FM) software-defined radio (SDR). SDR is an emerging technology where portions of the radio hardware, such as filtering and modulation, are replaced by software components. We discuss how an SDR implementation is instrumented to illustrate the processes involved in FM transmission and reception. By using audio-encoded images, we illustrate the processes involved in radio, such as how filters are used to reduce noise, the nature of a carrier wave, and how frequency modulation acts on a signal. The visualization approach used in this work is very effective in demonstrating advanced topics in digital signal processing and is a useful tool for experimenting with the software radio design.\\\",\\\"Authors\\\":\\\"Hall, M.;Betts, A.;Cox, D.;Pointer, D.;Kindratenko, V.\\\",\\\"Clusters\\\":\\\"Engineering;Mathematics;PhysicsAndPhysicalSciences;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532791\\\",\\\"Keywords\\\":\\\"visualization metaphor;radio;mathematical visualization;software-defined radio\\\",\\\"Keywords_Processed\\\":\\\"mathematical visualization;software define radio;radio;visualization metaphor\\\",\\\"Title\\\":\\\"The visible radio: process visualization of a software-defined radio\\\"},\\\"1067\\\":{\\\"Abstract\\\":\\\"Tensor topology is useful in providing a simplified and yet detailed representation of a tensor field. Recently the field of 3D tensor topology is advanced by the discovery that degenerate tensors usually form lines in their most basic configurations. These lines form the backbone for further topological analysis. A number of ways for extracting and tracing the degenerate tensor lines have also been proposed. In this paper, we complete the previous work by studying the behavior and extracting the separating surfaces emanating from these degenerate lines. First, we show that analysis of eigenvectors around a 3D degenerate tensor can be reduced to 2D. That is, in most instances, the 3D separating surfaces are just the trajectory of the individual 2D separatrices which includes trisectors and wedges. But the proof is by no means trivial since it is closely related to perturbation theory around a pair of singular slate. Such analysis naturally breaks down at the tangential points where the degenerate lines pass through the plane spanned by the eigenvectors associated with the repeated eigenvalues. Second, we show that the separatrices along a degenerate line may switch types (e.g. trisectors to wedges) exactly at the points where the eigenplane is tangential to the degenerate curve. This property leads to interesting and yet complicated configuration of surfaces around such transition points. Finally, we apply the technique to several common data sets to verify its correctness.\\\",\\\"Authors\\\":\\\"Zheng, X.;Parlett, B.;Pang, A.\\\",\\\"Clusters\\\":\\\"StreamlinesPathlinesStreaklines;SurfaceRelatedDataAndTechniques;TensorDataAndTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532841\\\",\\\"Keywords\\\":\\\"hyperstreamlines;wedges;degenerate tensors;symmetric tensors;tensor topology;trisectors;topological line;separating surfaces\\\",\\\"Keywords_Processed\\\":\\\"hyperstreamline;tensor topology;topological line;separate surface;trisector;symmetric tensor;wedge;degenerate tensor\\\",\\\"Title\\\":\\\"Topological structures of 3D tensor fields\\\"},\\\"1068\\\":{\\\"Abstract\\\":\\\"In this paper, we present a topological approach for simplifying continuous functions defined on volumetric domains. We introduce two atomic operations that remove pairs of critical points of the function and design a combinatorial algorithm that simplifies the Morse-Smale complex by repeated application of these operations. The Morse-Smale complex is a topological data structure that provides a compact representation of gradient flow between critical points of a function. Critical points paired by the Morse-Smale complex identify topological features and their importance. The simplification procedure leaves important critical points untouched, and is therefore useful for extracting desirable features. We also present a visualization of the simplified topology.\\\",\\\"Authors\\\":\\\"Gyulassy, A.;Vijay Natarajan\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;AlgorithmicPatternFeatureDetectionTracking;MultiresolutionTechniques;ScalarFieldDataTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532839\\\",\\\"Keywords\\\":\\\"3d scalar fields;morse theory;multi-resolution;morse-smale complex;computational topology;feature detection;simplification\\\",\\\"Keywords_Processed\\\":\\\"multi resolution;morse smale complex;feature detection;simplification;3d scalar field;computational topology;morse theory\\\",\\\"Title\\\":\\\"Topology-based simplification for feature extraction from 3D scalar fields\\\"},\\\"1069\\\":{\\\"Abstract\\\":\\\"Topological concepts and techniques have been broadly applied in computer graphics and geometric modeling. However, the homotopy type of a mapping between two surfaces has not been addressed before. In this paper, we present a novel solution to the problem of computing continuous maps with different homotopy types between two arbitrary triangle meshes with the same topology. Inspired by the rich theory of topology as well as the existing body of work on surface mapping, our newly-developed mapping techniques are both fundamental and unique, offering many attractive advantages. First, our method allows the user to change the homotopy type or global structure of the mapping with minimal intervention. Moreover, to locally affect shape correspondence, we articulate a new technique that robustly satisfies hard feature constraints, without the use of heuristics to ensure validity. In addition to acting as a useful tool for computer graphics applications, our method can be used as a rigorous and practical mechanism for the visualization of abstract topological concepts such as homotopy type of surface mappings, homology basis, fundamental domain, and universal covering space. At the core of our algorithm is a procedure for computing the canonical homology basis and using it as a common cut graph for any surface with the same topology. We demonstrate our results by applying our algorithm to shape morphing in this paper.\\\",\\\"Authors\\\":\\\"Garner, C.;Miao Jin;Xianfeng Gu;Hong Qin\\\",\\\"Clusters\\\":\\\"ShapeRelatedTechniques;SurfaceRelatedDataAndTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532840\\\",\\\"Keywords\\\":\\\"computational topology;surface parameterization;riemannian surface structure;shape morphing\\\",\\\"Keywords_Processed\\\":\\\"shape morphing;surface parameterization;computational topology;riemannian surface structure\\\",\\\"Title\\\":\\\"Topology-driven surface mappings with robust feature alignment\\\"},\\\"1070\\\":{\\\"Abstract\\\":\\\"Little is known about the cognitive abilities which influence the comprehension of scientific and information visualizations and what properties of the visualization affect comprehension. Our goal in this paper is to understand what makes visualizations difficult. We address this goal by examining the spatial ability differences in a diverse population selected for spatial ability variance. For example, how is, spatial ability related to visualization comprehension? What makes a particular visualization difficult or time intensive for specific groups of subjects? In this paper, we present the results of an experiment designed to answer these questions. Fifty-six subjects were tested on a basic visualization task and given standard paper tests of spatial abilities. An equal number of males and females were recruited in this study in order to increase spatial ability variance. Our results show that high spatial ability is correlated with accuracy on our three-dimensional visualization test, but not with time. High spatial ability subjects also had less difficulty with object complexity and the hidden properties of an object.\\\",\\\"Authors\\\":\\\"Velez, M.C.;Silver, D.;Tremaine, M.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;Cognition;EvaluationGeneral;HumanComputerInteractionHumanFactors\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532836\\\",\\\"Keywords\\\":\\\"standardized testing;orthogonal projections;spatial ability;gender differences\\\",\\\"Keywords_Processed\\\":\\\"gender difference;spatial ability;orthogonal projection;standardized testing\\\",\\\"Title\\\":\\\"Understanding visualization through spatial ability differences\\\"},\\\"1071\\\":{\\\"Abstract\\\":\\\"In a visualization of a three-dimensional dataset, the insights gained are dependent on what is occluded and what is not. Suggestion of interesting viewpoints can improve both the speed and efficiency of data understanding. This paper presents a view selection method designed for volume rendering. It can be used to find informative views for a given scene, or to find a minimal set of representative views which capture the entire scene. It becomes particularly useful when the visualization process is non-interactive - for example, when visualizing large datasets or time-varying sequences. We introduce a viewpoint \\\\\\\"goodness\\\\\\\" measure based on the formulation of entropy from information theory. The measure takes into account the transfer function, the data distribution and the visibility of the voxels. Combined with viewpoint properties like view-likelihood and view-stability, this technique can be used as a guide, which suggests \\\\\\\"interesting\\\\\\\" viewpoints for further exploration. Domain knowledge is incorporated into the algorithm via an importance transfer function or volume. This allows users to obtain view selection behaviors tailored to their specific situations. We generate a view space partitioning, and select one representative view for each partition. Together, this set of views encapsulates the \\\\\\\"interesting\\\\\\\" and distinct views of the data. Viewpoints in this set can be used as starting points for interactive exploration of the data, thus reducing the human effort in visualization. In non-interactive situations, such a set can be used as a representative visualization of the dataset from all directions.\\\",\\\"Authors\\\":\\\"Bordoloi, U.D.;Han-Wei Shen\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;InformationTheory;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532833\\\",\\\"Keywords\\\":\\\"visibility;volume rendering;entropy;view space partitioning;viewpoint selection\\\",\\\"Keywords_Processed\\\":\\\"entropy;volume render;viewpoint selection;visibility;view space partitioning\\\",\\\"Title\\\":\\\"View selection for volume rendering\\\"},\\\"1072\\\":{\\\"Abstract\\\":\\\"Real-time rendering of massively textured 3D scenes usually involves two major problems: Large numbers of texture switches are a well-known performance bottleneck and the set of simultaneously visible textures is limited by the graphics memory. This paper presents a level-of-detail texturing technique that overcomes both problems. In a preprocessing step, the technique creates a hierarchical data structure for all textures used by scene objects, and it derives texture atlases at different resolutions. At runtime, our texturing technique requires only a small set of these texture atlases, which represent scene textures in an appropriate size depending on the current camera position and screen resolution. Independent of the number and total size of all simultaneously visible textures, the achieved frame rates are similar to that of rendering the scene without any texture switches. Since the approach includes dynamic texture loading, the total size of the textures is only limited by the hard disk capacity. The technique is applicable for any 3D scenes whose scene objects are primarily distributed in a plane, such as in the case of 3D city models or outdoor scenes in computer games. Our approach has been successfully applied to massively textured, large-scale 3D city models.\\\",\\\"Authors\\\":\\\"Buchholz, H.;Dollner, J.\\\",\\\"Clusters\\\":\\\"RealtimeProcessingRenderingAndVisualizationGeneral;Textures;ViewDependentVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532798\\\",\\\"Keywords\\\":\\\"view-dependent rendering;realtime rendering;texture level-of-detail;multi-resolution textures\\\",\\\"Keywords_Processed\\\":\\\"realtime render;view dependent rendering;texture level of detail;multi resolution texture\\\",\\\"Title\\\":\\\"View-dependent rendering of multiresolution texture-atlases\\\"},\\\"1073\\\":{\\\"Abstract\\\":\\\"VisTrails is a new system that enables interactive multiple-view visualizations by simplifying the creation and maintenance of visualization pipelines, and by optimizing their execution. It provides a general infrastructure that can be combined with existing visualization systems and libraries. A key component of VisTrails is the visualization trail (vistrail), a formal specification of a pipeline. Unlike existing dataflow-based systems, in VisTrails there is a clear separation between the specification of a pipeline and its execution instances. This separation enables powerful scripting capabilities and provides a scalable mechanism for generating a large number of visualizations. VisTrails also leverages the vistrail specification to identify and avoid redundant operations. This optimization is especially useful while exploring multiple visualizations. When variations of the same pipeline need to be executed, substantial speedups can be obtained by caching the results of overlapping subsequences of the pipelines. In this paper, we describe the design and implementation of VisTrails, and show its effectiveness in different application scenarios.\\\",\\\"Authors\\\":\\\"Bavoil, L.;Callahan, S.P.;Crossno, P.;Freire, J.;Scheidegger, C.E.;Silva, C.T.;Vo, H.T.\\\",\\\"Clusters\\\":\\\"DataAcquisitionAndManagement;HardwareAccellerationAndComputationGeneral;MultipleLinkedCoordinatedViews;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532788\\\",\\\"Keywords\\\":\\\"coordinated views;interrogative visualization;caching;data-flow\\\",\\\"Keywords_Processed\\\":\\\"interrogative visualization;cache;coordinated view;datum flow\\\",\\\"Title\\\":\\\"VisTrails: enabling interactive multiple-view visualizations\\\"},\\\"1074\\\":{\\\"Abstract\\\":\\\"We present a visual analysis and exploration of fluid flow through a cooling jacket. Engineers invest a large amount of time and serious effort to optimize the flow through this engine component because of its important role in transferring heat away from the engine block. In this study we examine the design goals that engineers apply in order to construct an ideal-as-possible cooling jacket geometry and use a broad range of visualization tools in order to analyze, explore, and present the results. We systematically employ direct, geometric, and texture-based flow visualization techniques as well as automatic feature extraction and interactive feature-based methodology. And we discuss the relative advantages and disadvantages of these approaches as well as the challenges, both technical and perceptual with this application. The result is a feature-rich state-of-the-art flow visualization analysis applied to an important and complex data set from real-world computational fluid dynamics simulations.\\\",\\\"Authors\\\":\\\"Laramee, R.S.;Garth, C.;Doleisch, H.;Schneider, J.;Hauser, H.;Hagen, H.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;ApplicationsGeneralAndOther;DataFeaturesAndAttributes;Engineering;FlowVisualizationDataAndTechniques;PhysicsAndPhysicalSciences;VectorFieldsDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532850\\\",\\\"Keywords\\\":\\\"flow visualization;visualization systems;feature-based visualization;computational fluid dynamics;vector field visualization;engine simulation;heat transfer;cooling jacket;feature extraction\\\",\\\"Keywords_Processed\\\":\\\"heat transfer;feature extraction;visualization system;engine simulation;feature base visualization;cool jacket;computational fluid dynamic;vector field visualization;flow visualization\\\",\\\"Title\\\":\\\"Visual analysis and exploration of fluid flow in a cooling jacket\\\"},\\\"1075\\\":{\\\"Abstract\\\":\\\"In this application paper, we report on over fifteen years of experience with relativistic and astrophysical visualization, which has been culminating in a substantial engagement for visualization in the Einstein Year 2005 - the 100th anniversary of Einstein's publications on special relativity, the photoelectric effect, and Brownian motion. This paper focuses on explanatory and illustrative visualizations used to communicate aspects of the difficult theories of special and general relativity, their geometric structure, and of the related fields of cosmology and astrophysics. We discuss visualization strategies, motivated by physics education and didactics of mathematics, and describe what kind of visualization methods have proven to be useful for different types of media, such as still images in popular-science magazines, film contributions to TV shows, oral presentations, or interactive museum installations. Although our visualization tools build upon existing methods and implementations, these techniques have been improved by several novel technical contributions like image-based special relativistic rendering on GPUs, an extension of general relativistic ray tracing to manifolds described by multiple charts, GPU-based interactive visualization of gravitational light deflection, as well as planetary terrain rendering. The usefulness and effectiveness of our visualizations are demonstrated by reporting on experiences with, and feedback from, recipients of visualizations and collaborators.\\\",\\\"Authors\\\":\\\"Weiskopf, D.;Borchers, M.;Ertl, T.;Falk, M.;Fechtig, O.;Frank, R.;Grave, F.;King, A.;Kraus, U.;Muller, T.;Nollert, H.-P.;Mendez, I.R.;Ruder, H.;Schafhitzel, T.;Schar, S.;Zahn, C.;Zatloukal, M.\\\",\\\"Clusters\\\":\\\"AstronomyAstrophysics;ComputerGraphicsTechniquesGeneral;GeographyGeospatialVisCartographyTerrainVis;IllustrativeVisualization;Mathematics;PhysicsAndPhysicalSciences;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532845\\\",\\\"Keywords\\\":\\\"illustrative visualization;explanatory computer graphics;terrain rendering;mathematical visualization;visualization;astrophysics;special relativity;general relativity\\\",\\\"Keywords_Processed\\\":\\\"visualization;illustrative visualization;terrain render;astrophysic;special relativity;mathematical visualization;explanatory computer graphic;general relativity\\\",\\\"Title\\\":\\\"Visualization in the Einstein Year 2005: a case study on explanatory and illustrative visualization of relativity and astrophysics\\\"},\\\"1076\\\":{\\\"Abstract\\\":\\\"The genus of a knot or link can be defined via Seifert surfaces. A Seifert surface of a knot or link is an oriented surface whose boundary coincides with that, knot or link. Schematic images of these surfaces are shown in every text book on knot theory, but from these it is hard to understand their shape and structure. In this paper the visualization of such surfaces is discussed. A method is presented to produce different styles of surfaces for knots and links, starting from the so-called braid representation. Also, it is shown how closed oriented surfaces can be generated in which the knot is embedded, such that the knot subdivides the surface into two parts. These closed surfaces provide a direct visualization of the genus of a knot.\\\",\\\"Authors\\\":\\\"van Wijk, J.J.;Cohen, A.M.\\\",\\\"Clusters\\\":\\\"NumericalMethodsMathematics;Taxonomies;TopologyBasedTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532843\\\",\\\"Keywords\\\":\\\"seifert surfaces;knot theory;visualization;genus;topology\\\",\\\"Keywords_Processed\\\":\\\"visualization;seifert surface;topology;genus;knot theory\\\",\\\"Title\\\":\\\"Visualization of the genus of knots\\\"},\\\"1077\\\":{\\\"Abstract\\\":\\\"Analysis of phenomena that simultaneously occur on different spatial and temporal scales requires adaptive, hierarchical schemes to reduce computational and storage demands. Adaptive mesh refinement (AMR) schemes support both refinement in space that results in a time-dependent grid topology, as well as refinement in time that results in updates at higher rates for refined levels. Visualization of AMR data requires generating data for absent refinement levels at specific time steps. We describe a solution starting from a given set of \\\\\\\"key frames\\\\\\\" with potentially different grid topologies. The presented work was developed in a project involving several research institutes that collaborate in the field of cosmology and numerical relativity. AMR data results from simulations that are run on dedicated compute machines and is thus stored centrally, whereas the analysis of the data is performed on the local computers of the scientists. We built a distributed solution using remote procedure calls (RPC). To keep the application responsive, we split the bulk data transfer from the RPC response and deliver it asynchronously as a binary stream. The number of network round-trips is minimized by using high level operations. In summary, we provide an application for exploratory visualization of remotely stored AMR data.\\\",\\\"Authors\\\":\\\"Kaehler, R.;Prohaska, S.;Hutanu, A.;Hege, H.-C.\\\",\\\"Clusters\\\":\\\"DistributedSystemsAndGridEnvironments;MultiresolutionTechniques;TimeseriesTimeVaryingDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532793\\\",\\\"Keywords\\\":\\\"visualization over networks;time-varying visualization;multi-resoution visualization\\\",\\\"Keywords_Processed\\\":\\\"visualization over network;time vary visualization;multi resoution visualization\\\",\\\"Title\\\":\\\"Visualization of time-dependent remote adaptive mesh refinement data\\\"},\\\"1078\\\":{\\\"Abstract\\\":\\\"Diffusion tensor imaging is a magnetic resonance imaging method which has gained increasing importance in neuroscience and especially in neurosurgery. It acquires diffusion properties represented by a symmetric 2nd order tensor for each voxel in the gathered dataset. From the medical point of view, the data is of special interest due lo different diffusion characteristics of varying brain tissue allowing conclusions about the underlying structures such as while matter tracts. An obvious way to visualize this data is to focus on the anisotropic areas using the major eigenvector for tractography and rendering lines for visualization of the simulation results. Our approach extends this technique to avoid line representation since lines lead 10 very complex illustrations and furthermore are mistakable. Instead, we generate surfaces wrapping bundles of lines. Thereby, a more intuitive representation of different tracts is achieved.\\\",\\\"Authors\\\":\\\"Enders, F.;Sauber, N.;Merhof, D.;Hastreiter, P.;Nimsky, C.;Stamminger, M.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;TensorDataAndTechniques;Tractography\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532777\\\",\\\"Keywords\\\":\\\"tractography;white matter tracts;clustering;diffusion tensor imaging\\\",\\\"Keywords_Processed\\\":\\\"tractography;diffusion tensor imaging;white matter tract;clustering\\\",\\\"Title\\\":\\\"Visualization of white matter tracts with wrapped streamlines\\\"},\\\"1079\\\":{\\\"Abstract\\\":\\\"Line primitives are a very powerful visual attribute used for scientific visualization and in particular for 3D vector-field visualization. We extend the basic line primitives with additional visual attributes including color, line width, texture and orientation. To implement the visual attributes we represent the stylized line primitives as generalized cylinders. One important contribution of our work is an efficient rendering algorithm for stylized lines, which is hybrid in the sense that it uses both CPU and GPU based rendering. We improve the depth perception with a shadow algorithm. We present several applications for the visualization with stylized lines among which are the visualizations of 3D vector fields and molecular structures.\\\",\\\"Authors\\\":\\\"Stoll, C.;Gumhold, S.;Seidel, H.-P.\\\",\\\"Clusters\\\":\\\"Rendering;StreamlinesPathlinesStreaklines;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532859\\\",\\\"Keywords\\\":\\\"rendering;vector field;streamlines\\\",\\\"Keywords_Processed\\\":\\\"render;vector field;streamline\\\",\\\"Title\\\":\\\"Visualization with stylized line primitives\\\"},\\\"1080\\\":{\\\"Abstract\\\":\\\"This paper describes an experimental study of three perceptual properties of motion: flicker, direction, and velocity. Our goal is to understand how to apply these properties to represent data in a visualization environment. Results from our experiments show that all three properties can encode multiple data values, but that minimum visual differences are needed to ensure rapid and accurate target detection: flicker must be coherent and must have a cycle length of 120 milliseconds or greater, direction must differ by at least 20, and velocity must differ by at least 0.43 of subtended visual angle. We conclude with an overview of how we are applying our results to real-world data, and then discuss future work we plan to pursue.\\\",\\\"Authors\\\":\\\"Huber, D.E.;Healey, C.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;MultidimensionalMultivariateMultifieldDataAndTechniques;Perception;SocialNetworksAndSocialMedia;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532838\\\",\\\"Keywords\\\":\\\"perception;velocity;visualization;direction;motion;multi-dimensional;flicker\\\",\\\"Keywords_Processed\\\":\\\"visualization;direction;perception;velocity;multi dimensional;motion;flicker\\\",\\\"Title\\\":\\\"Visualizing data with motion\\\"},\\\"1081\\\":{\\\"Abstract\\\":\\\"This paper describes the adaptation and evaluation of existing nested-surface visualization techniques for the problem of displaying intersecting surfaces. For this work, we collaborated with a neurosurgeon who is comparing multiple tumor segmentations with the goal of increasing the segmentation accuracy and reliability. A second collaborator, a physicist, aims to validate geometric models of specimens against atomic-force microscope images of actual specimens. These collaborators are interested in comparing both surface shape and inter-surface distances. Many commonly employed techniques for visually comparing multiple surfaces (side-by-side, wireframe, colormaps, uniform translucence) do not simultaneously convey inter-surface distance and the shapes of two or more surfaces. This paper describes a simple geometric partitioning of intersecting surfaces that enables the application of existing nested-surface techniques, such as texture-modulated translucent rendering of exteriors, to a broader range of visualization problems. Three user studies investigate the performance of existing techniques and a new shadow-casting glyph technique. The results of the first user study show that texture glyphs on partitioned, intersecting surfaces can convey inter-surface distance better than directly mapping distance to a red-gray-blue color scale on a single surface. The results of the second study show similar results for conveying local surface orientation. The results of the third user study show that adding cast shadows to texture glyphs can increase the understanding of inter-surface distance in static images, but can be overpowered by the shape cues from a simple rocking motion.\\\",\\\"Authors\\\":\\\"Weigle, C.;Taylor, R.M.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;Perception;SurfaceRelatedDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532835\\\",\\\"Keywords\\\":\\\"user study;two-surface visualization;scientific visualization;perception;nested surfaces;intersecting surfaces;transparent surfaces\\\",\\\"Keywords_Processed\\\":\\\"user study;perception;two surface visualization;transparent surface;scientific visualization;nested surface;intersect surface\\\",\\\"Title\\\":\\\"Visualizing intersecting surfaces with nested-surface techniques\\\"},\\\"1082\\\":{\\\"Abstract\\\":\\\"The study of stress and strains in soils and structures (solids) help us gain a better understanding of events such as failure of bridges, dams and buildings, or accumulated stresses and strains in geological subduction zones that could trigger earthquakes and subsequently tsunamis. In such domains, the key feature of interest is the location and orientation of maximal shearing planes. This paper describes a method that highlights this feature in stress tensor fields. It uses a plane-in-a-box glyph which provides a global perspective of shearing planes based on local analysis of tensors. The analysis can be performed over the entire domain, or the user can interactively specify where to introduce these glyphs. Alternatively, they can also be placed depending on the threshold level of several physical relevant parameters such as double couple and compensated linear vector dipole. Both methods are tested on stress tensor fields from geomechanics.\\\",\\\"Authors\\\":\\\"Neeman, A.;Jeremic, B.;Pang, A.\\\",\\\"Clusters\\\":\\\"DataFeaturesAndAttributes;EarthSpaceAndEnvironmentalSciences;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532774\\\",\\\"Keywords\\\":\\\"seismic moment tensor;stress tensor;deviatoric;double couple;anisotropic;symmetric tensors;compensated linear vector dipole\\\",\\\"Keywords_Processed\\\":\\\"anisotropic;stress tensor;seismic moment tensor;double couple;deviatoric;symmetric tensor;compensate linear vector dipole\\\",\\\"Title\\\":\\\"Visualizing tensor fields in geomechanics\\\"},\\\"1083\\\":{\\\"Abstract\\\":\\\"The study of physical models for knots has recently received much interest in the mathematics community. In this paper, we consider the ropelength model, which considers knots tied in an idealized rope. This model is interesting in pure mathematics, and has been applied to the study of a variety of problems in the natural sciences as well. Modeling and visualizing the tightening of knots in this idealized rope poses some interesting challenges in computer graphics. In particular, self-contact in a deformable rope model is a difficult problem which cannot be handled by standard techniques. In this paper, we describe a solution based on reformulating the contact problem and using constrained-gradient techniques from nonlinear optimization. The resulting animations reveal new properties of the tightening flow and provide new insights into the geometric structure of tight knots and links.\\\",\\\"Authors\\\":\\\"Cantarella, J.;Piatek, M.;Rawdon, E.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;GeometricModeling;InputAndOutputDevicesGeneral;NumericalMethodsMathematics;Optimization;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532844\\\",\\\"Keywords\\\":\\\"non-linear optimization;constrained least squares;flexible models;contact;tight knots;collision detection;ropelength;ideal knots\\\",\\\"Keywords_Processed\\\":\\\"non linear optimization;flexible model;tight knot;ropelength;contact;ideal knot;constrain least square;collision detection\\\",\\\"Title\\\":\\\"Visualizing the tightening of knots\\\"},\\\"1084\\\":{\\\"Abstract\\\":\\\"In this work we present a hardware-accelerated direct volume rendering system for visualizing multivariate wave functions in semiconducting quantum dot (QD) simulations. The simulation data contains the probability density values of multiple electron orbitals for up to tens of millions of atoms, computed by the NEMO3-D quantum device simulator software run on large-scale cluster architectures. These atoms form two interpenetrating crystalline face centered cubic lattices (FCC), where each FCC cell comprises the eight corners of a cubic cell and six additional face centers. We have developed compact representation techniques for the FCC lattice within PC graphics hardware texture memory, hardware-accelerated linear and cubic reconstruction schemes, and new multi-field rendering techniques utilizing logarithmic scale transfer functions. Our system also enables the user to drill down through the simulation data and execute statistical queries using general-purpose computing on the GPU (GPGPU).\\\",\\\"Authors\\\":\\\"Wei Qiao;Ebert, D.S.;Entezari, A.;Korkusinski, M.;Klimeck, G.\\\",\\\"Clusters\\\":\\\"FilteringTechniques;GpuBasedTechniques;MeshesGridsAndLattices;PhysicsAndPhysicalSciences;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532811\\\",\\\"Keywords\\\":\\\"reconstruction filter;volume rendering;atomistic simulation;quantum dots;volume visualization;programmable graphics hardware;face-centered cubic lattice\\\",\\\"Keywords_Processed\\\":\\\"volume render;programmable graphic hardware;atomistic simulation;reconstruction filter;face center cubic lattice;quantum dot;volume visualization\\\",\\\"Title\\\":\\\"VolQD: direct volume rendering of multi-million atom quantum dot simulations\\\"},\\\"1085\\\":{\\\"Abstract\\\":\\\"The evacuation of buildings in the event of a fire requires careful planning of ventilation and evacuation routes during early architectural design stages. Different designs are evaluated by simulating smoke propagation using computational fluid dynamics (CFD). Visibility plays a decisive role in finding the nearest fire exit. This paper presents real-time volume rendering of transient smoke propagation conforming to standardized visibility distances. We visualize time dependent smoke particle concentration on unstructured tetrahedral meshes using a direct volume rendering approach. Due to the linear transfer function of the optical model commonly used in fire protection engineering, accurate pre-integration of diffuse color across tetrahedra can be carried out with a single 2D texture lookup. We reduce rounding errors during frame buffer blending by applying randomized dithering if high accuracy frame buffers are unavailable on the target platform. A simple absorption-based lighting model is evaluated in a preprocessing step using the same rendering approach. Back-illuminated exit signs are commonly used to indicate the escape route. As light emitting objects are visible further than reflective objects, the transfer function in front of illuminated exit signs must be adjusted with a deferred rendering pass.\\\",\\\"Authors\\\":\\\"Staubli, O.;Sigg, C.;Peikert, R.;Gubler, D.;Gross, M.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532813\\\",\\\"Keywords\\\":\\\"flow visualization;volume rendering\\\",\\\"Keywords_Processed\\\":\\\"volume render;flow visualization\\\",\\\"Title\\\":\\\"Volume rendering of smoke propagation CFD data\\\"},\\\"1086\\\":{\\\"Abstract\\\":\\\"In this paper, we present a volume roaming system dedicated to oil and gas exploration. Our system combines probe-based volume rendering with data processing and computing. The daily oil production and the estimation of the world proven-reserves directly affect the barrel price and have a strong impact on the economy. Among others, production and correct estimation are linked to the accuracy of the sub-surface model used for predicting oil reservoirs shape and size. Geoscientists build this model from the interpretation of seismic data, i.e. 3D images of the subsurface obtained from geophysical surveys. Our system couples visualization and data processing for the interpretation of seismic data. It is based on volume roaming along with efficient volume paging to manipulate the multi-gigabyte data sets commonly acquired during seismic surveys. Our volume rendering lenses implement high quality pre-integrated volume rendering with accurate lighting. They use a generic multi-modal volume rendering system that blends several volumes in the spirit of the \\\\\\\"stencil\\\\\\\" paradigm used in 2D painting programs. In addition, our system can interactively display non-polygonal isosurfaces painted with an attribute. Beside the visualization algorithms, automatic extraction of local features of the subsurface model also take full advantage of the volume paging.\\\",\\\"Authors\\\":\\\"Castanie, L.;Levy, B.;Bosquet, F.\\\",\\\"Clusters\\\":\\\"EarthSpaceAndEnvironmentalSciences;GpuBasedTechniques;OutOfCoreProcessing;ProgrammingAlgorithmsAndDataStructures;Rendering;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532802\\\",\\\"Keywords\\\":\\\"seismic interpretation;volume roaming;paging;large volumes;texture-based volume visualization;programmable graphics hardware;oil and gas exploration;out-of-core;volume bricking;multimodal rendering\\\",\\\"Keywords_Processed\\\":\\\"large volume;oil and gas exploration;texture base volume visualization;programmable graphic hardware;page;seismic interpretation;multimodal render;out of core;volume bricke;volume roam\\\",\\\"Title\\\":\\\"VolumeExplorer: roaming large volumes to couple visualization and data processing for oil and gas exploration\\\"},\\\"1087\\\":{\\\"Abstract\\\":\\\"Illustrations play a major role in the education process. Whether used to teach a surgical or radiologic procedure, to illustrate normal or aberrant anatomy, or to explain the functioning of a technical device, illustration significantly impacts learning. Although many specimens are readily available as volumetric data sets, particularly in medicine, illustrations are commonly produced manually as static images in a time-consuming process. Our goal is to create a fully dynamic three-dimensional illustration environment which directly operates on volume data. Single images have the aesthetic appeal of traditional illustrations, but can be interactively altered and explored. In this paper we present methods to realize such a system which combines artistic visual styles and expressive visualization techniques. We introduce a novel concept for direct multi-object volume visualization which allows control of the appearance of inter-penetrating objects via two-dimensional transfer functions. Furthermore, a unifying approach to efficiently integrate many non-photorealistic rendering models is presented. We discuss several illustrative concepts which can be realized by combining cutaways, ghosting, and selective deformation. Finally, we also propose a simple interface to specify objects of interest through three-dimensional volumetric painting. All presented methods are integrated into VolumeShop, an interactive hardware-accelerated application for direct volume illustration.\\\",\\\"Authors\\\":\\\"Bruckner, S.;Groller, E.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;IllustrativeVisualization;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2005.1532856\\\",\\\"Keywords\\\":\\\"focus+context technique;volume rendering;illustrative visualization\\\",\\\"Keywords_Processed\\\":\\\"volume render;focus context technique;illustrative visualization\\\",\\\"Title\\\":\\\"VolumeShop: an interactive system for direct volume illustration\\\"},\\\"1088\\\":{\\\"Abstract\\\":\\\"Diffusion tensor imaging (DTI) is a magnetic resonance imaging method that can be used to measure local information about the structure of white matter within the human brain. Combining DTI data with the computational methods of MR tractography, neuroscientists can estimate the locations and sizes of nerve bundles (white matter pathways) that course through the human brain. Neuroscientists have used visualization techniques to better understand tractography data, but they often struggle with the abundance and complexity of the pathways. We describe a novel set of interaction techniques that make it easier to explore and interpret such pathways. Specifically, our application allows neuroscientists to place and interactively manipulate box-shaped regions (or volumes of interest) to selectively display pathways that pass through specific anatomical areas. A simple and flexible query language allows for arbitrary combinations of these queries using Boolean logic operators. Queries can be further restricted by numerical path properties such as length, mean fractional anisotropy, and mean curvature. By precomputing the pathways and their statistical properties, we obtain the speed necessary for interactive question-and-answer sessions with brain researchers. We survey some questions that researchers have been asking about tractography data and show how our system can be used to answer these questions efficiently.\\\",\\\"Authors\\\":\\\"Akers, D.;Sherbondy, A.;Mackenzie, R.;Dougherty, R.;Wandell, B.\\\",\\\"Clusters\\\":\\\"TensorDataAndTechniques;Tractography;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.30\\\",\\\"Keywords\\\":\\\"visualization;mr tractography;diffusion tensor imaging\\\",\\\"Keywords_Processed\\\":\\\"visualization;diffusion tensor imaging;mr tractography\\\",\\\"Title\\\":\\\"Exploration of the brain's white matter pathways with dynamic queries\\\"},\\\"1089\\\":{\\\"Abstract\\\":\\\"In this paper, we describe a taxonomy of generic graph related tasks and an evaluation aiming at assessing the readability of two representations of graphs: matrix-based representations and node-link diagrams. This evaluation bears on seven generic tasks and leads to important recommendations with regard to the representation of graphs according to their size and density. For instance, we show that when graphs are bigger than twenty vertices, the matrix-based visualization performs better than node-link diagrams on most tasks. Only path finding is consistently in favor of node-link diagrams throughout the evaluation\\\",\\\"Authors\\\":\\\"Ghoniem, M.;Fekete, J.;Castagliola, P.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;EvaluationMetricsAndBenchmarks;GraphNetworkDataAndTechniques;MatrixRelatedTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.1\\\",\\\"Keywords\\\":\\\"node-link representation;readability;graph visualization;adjacency matrix;evaluation\\\",\\\"Keywords_Processed\\\":\\\"readability;adjacency matrix;node link representation;graph visualization;evaluation\\\",\\\"Title\\\":\\\"A Comparison of the Readability of Graphs Using Node-Link and Matrix-Based Representations\\\"},\\\"1090\\\":{\\\"Abstract\\\":\\\"Feature detection in flow fields is a well-researched area, but practical application is often difficult due to the numerical complexity of the algorithms preventing interactive use and due to noise in experimental or high-resolution simulation data sets. We present an integrated system that provides interactive denoising, vortex detection, and visualisation of vector data on Cartesian grids. All three major phases are implemented in such a way that the system runs completely on a modern GPU once the vector field is downloaded into graphics memory. The application aspect of our paper is twofold. First, we show how recently presented, prototypical GPU-based algorithms for filtering, numerical computation, and volume rendering can be combined into one productive system by handling all idiosyncrasies of a chosen graphics card. Second, we demonstrate that the significant speedup achieved compared to an optimized software implementation now allows interactive exploration of characteristic structures in turbulent flow fields.\\\",\\\"Authors\\\":\\\"Stegmaier, S.;Ertl, T.\\\",\\\"Clusters\\\":\\\"DataFeaturesAndAttributes;FlowVisualizationDataAndTechniques;HardwareAccellerationAndComputationGeneral;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.3\\\",\\\"Keywords\\\":\\\"flow visualization;3d vector field visualization;features in volume data sets;hardware acceleration\\\",\\\"Keywords_Processed\\\":\\\"feature in volume datum set;3d vector field visualization;hardware acceleration;flow visualization\\\",\\\"Title\\\":\\\"A graphics hardware-based vortex detection and visualization system\\\"},\\\"1091\\\":{\\\"Abstract\\\":\\\"A major challenge of current visualization and visual data mining (VDM) frameworks is to support users in the orientation in complex visual mining scenarios. An important aspect to increase user support and user orientation is to use a history mechanism that, first of all, provides un- and redoing functionality. In this paper, we present a new approach to include such history functionality into a VDM framework. Therefore, we introduce the theoretical background, outline design and implementation aspects of a history management unit, and conclude with a discussion showing the usefulness of our history management in a VDM framework\\\",\\\"Authors\\\":\\\"Kreuseler, M.;Nocke, T.;Schumann, H.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;InteractionTechniquesGeneral;ProvenanceAndHistory;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.2\\\",\\\"Keywords\\\":\\\"visualization;history;visual data mining;undo/redo\\\",\\\"Keywords_Processed\\\":\\\"visualization;history;undo redo;visual datum mining\\\",\\\"Title\\\":\\\"A History Mechanism for Visual Data Mining\\\"},\\\"1092\\\":{\\\"Abstract\\\":\\\"We address the texture level-of-detail problem for extremely large surfaces such as terrain during realtime, view-dependent rendering. A novel texture hierarchy is introduced based on 4-8 refinements of raster tiles, in which the texture grids in effect rotate 45 degrees for each level of refinement. This hierarchy provides twice as many levels of detail as conventional quadtree-style refinement schemes such as mipmaps, and thus provides per-pixel view-dependent filtering that is twice as close to the ideal cutoff frequency for an average pixel. Because of this more gradual change in low-pass filtering, and due to the more precise emulation of the ideal cutoff frequency, we find in practice that the transitions between texture levels of detail are not perceptible. This allows rendering systems to avoid the complexity and performance costs of per-pixel blending between texture levels of detail. The 4-8 texturing scheme is integrated into a variant of the real-time optimally adapting meshes (ROAM) algorithm for view-dependent multiresolution mesh generation. Improvements to ROAM included here are: the diamond data structure as a streamlined replacement for the triangle bintree elements, the use of low-pass-filtered geometry patches in place of individual triangles, integration of 4-8 textures, and a simple out-of-core data access mechanism for texture and geometry tiles.\\\",\\\"Authors\\\":\\\"Hwa, L.M.;Duchaineau, M.;Joy, K.I.\\\",\\\"Clusters\\\":\\\"LargeScaleDataAndScalability;LevelOfDetail;OutOfCoreProcessing;Textures;ViewDependentVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.4\\\",\\\"Keywords\\\":\\\"out-of-core algorithm;level-of-detail techniques;adaptive textures;large data set visualization;view-dependent visualization\\\",\\\"Keywords_Processed\\\":\\\"out of core algorithm;view dependent visualization;level of detail technique;adaptive texture;large datum set visualization\\\",\\\"Title\\\":\\\"Adaptive 4-8 texture hierarchies\\\"},\\\"1093\\\":{\\\"Abstract\\\":\\\"High-throughput experiments such as gene expression microarrays in the life sciences result in large datasets. In response, a wide variety of visualization tools have been created to facilitate data analysis. Biologists often face a dilemma in choosing the best tool for their situation. The tool that works best for one biologist may not work well for another due to differences in the type of insight they seek from their data. A primary purpose of a visualization tool is to provide domain-relevant insight into the data. Ideally, any user wants maximum information in the least possible time. In this paper we identify several distinct characteristics of insight that enable us to recognize and quantify it. Based on this, we empirically evaluate five popular microarray visualization tools. Our conclusions can guide biologists in selecting the best tool for their data, and computer scientists in developing and evaluating visualizations\\\",\\\"Authors\\\":\\\"Saraiya, P.;North, C.;Duca, K.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;ApplicationsGeneralAndOther;BiologyAndBioinformatics;EvaluationGeneral;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.5\\\",\\\"Keywords\\\":\\\"microarray data;bioinformatics;visualization;high-throughput experiments;insight;empirical evaluation\\\",\\\"Keywords_Processed\\\":\\\"visualization;high throughput experiment;insight;microarray datum;empirical evaluation;bioinformatic\\\",\\\"Title\\\":\\\"An Evaluation of Microarray Visualization Tools for Biological Insight\\\"},\\\"1094\\\":{\\\"Abstract\\\":\\\"Many large scale physics-based simulations which take place on PC clusters or supercomputers produce huge amounts of data including vector fields. While these vector data such as electromagnetic fields, fluid flow fields, or particle paths can be represented by lines, the sheer number of the lines overwhelms the memory and computation capability of a high-end PC used for visualization. Further, very dense or intertwined lines, rendered with traditional visualization techniques, can produce unintelligible results with unclear depth relationships between the lines and no sense of global structure. Our approach is to apply a lighting model to the lines and sample them into an anisotropic voxel representation based on spherical harmonics as a preprocessing step. Then we evaluate and render these voxels for a given view using traditional volume rendering. For extremely large line based datasets, conversion to anisotropic voxels reduces the overall storage and rendering for O(n) lines to O(1) with a large constant that is still small enough to allow meaningful visualization of the entire dataset at nearly interactive rates on a single commodity PC.\\\",\\\"Authors\\\":\\\"Schussman, G.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"Illumination;LineBasedTechniquesAndApproaches;VectorFieldsDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.5\\\",\\\"Keywords\\\":\\\"volume rendering;scientific visualization;vector field;line data;anisotropic lighting\\\",\\\"Keywords_Processed\\\":\\\"volume render;vector field;anisotropic lighting;line datum;scientific visualization\\\",\\\"Title\\\":\\\"Anisotropic volume rendering for extremely dense, thin line data\\\"},\\\"1095\\\":{\\\"Abstract\\\":\\\"We present Artifacts of the Presence Era, a digital installation that uses a geological metaphor to visualize the events in a physical space over time. The piece captures video and audio from a museum and constructs an impressionistic visualization of the evolving history in the space. Instead of creating a visualization tool for data analysis, we chose to produce a piece that functions as a souvenir of a particular time and place. We describe the design choices we made in creating this installation, the visualization techniques we developed, and the reactions we observed from users and the media. We suggest that the same approach can be applied to a more general set of visualization contexts, ranging from email archives to newsgroups conversations\\\",\\\"Authors\\\":\\\"Viegas, F.B.;Perry, E.;Howe, E.;Donath, J.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;ProvenanceAndHistory;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.8\\\",\\\"Keywords\\\":\\\"visualization;history;public space\\\",\\\"Keywords_Processed\\\":\\\"visualization;history;public space\\\",\\\"Title\\\":\\\"Artifacts of the Presence Era: Using Information Visualization to Create an Evocative Souvenir\\\"},\\\"1096\\\":{\\\"Abstract\\\":\\\"The evolving technology of computer auto-fabrication (\\\\\\\"3D printing\\\\\\\") now makes it possible to produce physical models for complex biological molecules and assemblies. We report on an application that demonstrates the use of auto-fabricated tangible models and augmented reality for research and education in molecular biology, and for enhancing the scientific environment for collaboration and exploration. We have adapted an augmented reality system to allow virtual 3D representations (generated by the Python Molecular Viewer) to be overlaid onto a tangible molecular model. Users can easily change the overlaid information, switching between different representations of the molecule, displays of molecular properties such as electrostatics, or dynamic information. The physical model provides a powerful, intuitive interface for manipulating the computer models, streamlining the interface between human intent, the physical model, and the computational activity.\\\",\\\"Authors\\\":\\\"Gillet, A.;Sanner, M.;Stoffler, D.;Goodsell, D.;Olson, A.\\\",\\\"Clusters\\\":\\\"ImmersiveAndVirtualEnvironments;MolecularScienceAndChemistry\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.7\\\",\\\"Keywords\\\":\\\"molecular visualization;augmented reality;molecular modeling\\\",\\\"Keywords_Processed\\\":\\\"molecular modeling;molecular visualization;augmented reality\\\",\\\"Title\\\":\\\"Augmented reality with tangible auto-fabricated models for molecular biology applications\\\"},\\\"1097\\\":{\\\"Abstract\\\":\\\"The design and evaluation of most current information visualization systems descend from an emphasis on a user's ability to \\\\\\\"unpack\\\\\\\" the representations of data of interest and operate on them independently. Too often, successful decision-making and analysis are more a matter of serendipity and user experience than of intentional design and specific support for such tasks; although humans have considerable abilities in analyzing relationships from data, the utility of visualizations remains relatively variable across users, data sets, and domains. In this paper, we discuss the notion of analytic gaps, which represent obstacles faced by visualizations in facilitating higher-level analytic tasks, such as decision-making and learning. We discuss support for bridging the analytic gap, propose a framework for design and evaluation of information visualization systems, and demonstrate its use\\\",\\\"Authors\\\":\\\"Amar, R.;Stasko, J.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;EvaluationGeneral;TasksTaskRequirementsAnalysis;VisualizationSystemsToolkitsAndEnvironments;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.10\\\",\\\"Keywords\\\":\\\"information visualization;theory;knowledge tasks;framework;evaluation;analytic gap\\\",\\\"Keywords_Processed\\\":\\\"knowledge task;framework;information visualization;analytic gap;evaluation;theory\\\",\\\"Title\\\":\\\"A Knowledge Task-Based Framework for Design and Evaluation of Information Visualizations\\\"},\\\"1098\\\":{\\\"Abstract\\\":\\\"Improvise is a fully-implemented system in which users build and browse multiview visualizations interactively using a simple shared-object coordination mechanism coupled with a flexible, expression-based visual abstraction language. By coupling visual abstraction with coordination, users gain precise control over how navigation and selection in the visualization affects the appearance of data in individual views. As a result, it is practical to build visualizations with more views and richer coordination in Improvise than in other visualization systems. Building and browsing activities are integrated in a single, live user interface that lets users alter visualizations quickly and incrementally during data exploration\\\",\\\"Authors\\\":\\\"Weaver, C.\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;AnalysisProcessGeneral;CollaborativeVisualization;MultipleLinkedCoordinatedViews;QueriesAndSearch\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.12\\\",\\\"Keywords\\\":\\\"exploratory visualization;coordination;visual abstraction language;multiple views;coordinated queries\\\",\\\"Keywords_Processed\\\":\\\"visual abstraction language;coordinated query;coordination;exploratory visualization;multiple view\\\",\\\"Title\\\":\\\"Building Highly-Coordinated Visualizations in Improvise\\\"},\\\"1099\\\":{\\\"Abstract\\\":\\\"A new method for the simplification and the visualization of vector fields is presented based on the notion of centroidal Voronoi tessellations (CVT's). A CVT is a special Voronoi tessellation for which the generators of the Voronoi regions in the tessellation are also the centers of mass (or means) with respect to a prescribed density. A distance function in both the spatial and vector spaces is introduced to measure the similarity of the spatially distributed vector fields. Based on such a distance, vector fields are naturally clustered and their simplified representations are obtained. Our method combines simple geometric intuitions with the rigorously established optimality properties of the CVTs. It is simple to describe, easy to understand and implement. Numerical examples are also provided to illustrate the effectiveness and competitiveness of the CVT-based vector simplification and visualization methodology.\\\",\\\"Authors\\\":\\\"Qiang Du;Xiaoquiang Wang\\\",\\\"Clusters\\\":\\\"AbstractionSimplificationApproximation;DataClusteringAndAggregation;FlowVisualizationDataAndTechniques;SegmentationAndClassification;VectorFieldsDataAndTechniques;VoronoiBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.13\\\",\\\"Keywords\\\":\\\"flow visualization;clustering;centroidal voronoi tessellation;vector field;segmentation;simplification\\\",\\\"Keywords_Processed\\\":\\\"vector field;segmentation;centroidal voronoi tessellation;clustering;simplification;flow visualization\\\",\\\"Title\\\":\\\"Centroidal Voronoi tessellation based algorithms for vector fields visualization and segmentation\\\"},\\\"1100\\\":{\\\"Abstract\\\":\\\"Visual clutter denotes a disordered collection of graphical entities in information visualization. Clutter can obscure the structure present in the data. Even in a small dataset, clutter can make it hard for the viewer to find patterns, relationships and structure. In this paper, we define visual clutter as any aspect of the visualization that interferes with the viewer's understanding of the data, and present the concept of clutter-based dimension reordering. Dimension order is an attribute that can significantly affect a visualization's expressiveness. By varying the dimension order in a display, it is possible to reduce clutter without reducing information content or modifying the data in any way. Clutter reduction is a display-dependent task. In this paper, we follow a three-step procedure for four different visualization techniques. For each display technique, first, we determine what constitutes clutter in terms of display properties; then we design a metric to measure visual clutter in this display; finally we search for an order that minimizes the clutter in a display\\\",\\\"Authors\\\":\\\"Peng, W.;Ward, M.O.;Rundensteiner, E.A.\\\",\\\"Clusters\\\":\\\"MultidimensionalMultivariateMultifieldDataAndTechniques;VisualClutterAndItsReduction;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.15\\\",\\\"Keywords\\\":\\\"visual clutter;dimension order;multi-dimensional visualization;visual structure\\\",\\\"Keywords_Processed\\\":\\\"dimension order;visual clutter;multi dimensional visualization;visual structure\\\",\\\"Title\\\":\\\"Clutter Reduction in Multi-Dimensional Data Visualization Using Dimension Reordering\\\"},\\\"1101\\\":{\\\"Abstract\\\":\\\"Determining the three-dimensional structure of distant astronomical objects is a challenging task, given that terrestrial observations provide only one viewpoint. For this task, bipolar planetary nebulae are interesting objects of study because of their pronounced axial symmetry due to fundamental physical processes. Making use of this symmetry constraint, we present a technique to automatically recover the axisymmetric structure of bipolar planetary nebulae from two-dimensional images. With GPU-based volume rendering driving a nonlinear optimization, we estimate the nebula's local emission density as a function of its radial and axial coordinates, and we recover the orientation of the nebula relative to Earth. The optimization refines the nebula model and its orientation by minimizing the differences between the rendered image and the original astronomical image. The resulting model enables realistic 3D visualizations of planetary nebulae, e.g. for educational purposes in planetarium shows. In addition, the recovered spatial distribution of the emissive gas allows validating computer simulation results of the astrophysical formation processes of planetary nebulae.\\\",\\\"Authors\\\":\\\"Magnor, M.;Kindlmann, G.;Duric, N.;Hansen, C.\\\",\\\"Clusters\\\":\\\"AstronomyAstrophysics;Rendering;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.18\\\",\\\"Keywords\\\":\\\"volume rendering;planetary nebulae;inverse rendering;volume reconstruction;volume modeling\\\",\\\"Keywords_Processed\\\":\\\"volume reconstruction;volume render;inverse render;planetary nebulae;volume model\\\",\\\"Title\\\":\\\"Constrained inverse volume rendering for planetary nebulae\\\"},\\\"1102\\\":{\\\"Abstract\\\":\\\"We explore techniques to detect and visualize features in data from molecular dynamics (MD) simulations. Although the techniques proposed are general, we focus on silicon (Si) atomic systems. The first set of methods use 3D location of atoms. Defects are detected and categorized using local operators and statistical modeling. Our second set of exploratory techniques employ electron density data. This data is visualized to glean the defects. We describe techniques to automatically detect the salient isovalues for isosurface extraction and designing transfer functions. We compare and contrast the results obtained from both sources of data. Essentially, we find that the methods of defect (feature) detection are at least as robust as those based on the exploration of electron density for Si systems.\\\",\\\"Authors\\\":\\\"Mehta, S.;Hazzard, K.;Machiraju, R.;Parthasarathy, S.;Wilkins, J.\\\",\\\"Clusters\\\":\\\"AlgorithmicPatternFeatureDetectionTracking;DatabasesAndDataMining;IsosurfaceAndSurfaceExtractionTechniques;MolecularScienceAndChemistry;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.23\\\",\\\"Keywords\\\":\\\"data mining;scientific visualization;transfer function;molecular dynamics;isosurface;feature extraction\\\",\\\"Keywords_Processed\\\":\\\"molecular dynamic;feature extraction;scientific visualization;transfer function;isosurface;datum mining\\\",\\\"Title\\\":\\\"Detection and visualization of anomalous structures in molecular dynamics simulation data\\\"},\\\"1103\\\":{\\\"Abstract\\\":\\\"We present a system for simulating and visualizing the propagation of dispersive contaminants with an application to urban security. In particular, we simulate airborne contaminant propagation in open environments characterised by sky-scrapers and deep urban canyons. Our approach is based on the multiple relaxation time lattice Boltzmann model (MRTLBM), which can efficiently handle complex boundary conditions such as buildings. In addition, we model thermal effects on the flow field using the hybrid thermal MRTLBM. Our approach can also accommodate readings from various sensors distributed in the environment and adapt the simulation accordingly. We accelerate the computation and efficiently render many buildings with small textures on the GPU. We render streamlines and the contaminant smoke with self-shadowing composited with the textured buildings.\\\",\\\"Authors\\\":\\\"Feng Qiu;Ye Zhao;Zhe Fan;Xiaoming Wei;Lorenz, H.;Jianning Wang;Yoakum-Stover, S.;Kaufman, A.;Mueller, K.\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;MeshesGridsAndLattices;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.24\\\",\\\"Keywords\\\":\\\"visualization;lattice boltzmann model;gpu\\\",\\\"Keywords_Processed\\\":\\\"visualization;lattice boltzmann model;gpu\\\",\\\"Title\\\":\\\"Dispersion simulation and visualization for urban security\\\"},\\\"1104\\\":{\\\"Abstract\\\":\\\"Effective visualization of vector fields relies on the ability to control the size and density of the underlying mapping to visual cues used to represent the field. In this paper we introduce the use of a reaction-diffusion model, already well known for its ability to form irregular spatio-temporal patters, to control the size, density, and placement of the vector field representation. We demonstrate that it is possible to encode vector field information (orientation and magnitude) into the parameters governing a reaction-diffusion model to form a spot pattern with the correct orientation, size, and density, creating an effective visualization. To encode direction we texture the spots using a light to dark fading texture. We also show that it is possible to use the reaction-diffusion model to visualize an additional scalar value, such as the uncertainty in the orientation of the vector field. An additional benefit of the reaction-diffusion visualization technique arises from its automatic density distribution. This benefit suggests using the technique to augment other vector visualization techniques. We demonstrate this utility by augmenting a LIC visualization with a reaction-diffusion visualization. Finally, the reaction-diffusion visualization method provides a technique that can be used for streamline and glyph placement.\\\",\\\"Authors\\\":\\\"Sanderson, A.;Johnson, C.R.;Kirby, R.M.\\\",\\\"Clusters\\\":\\\"DiffusionRelatedTechniques;FlowVisualizationDataAndTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.25\\\",\\\"Keywords\\\":\\\"flow visualization;reaction-diffusion;vector field visualization;vector field\\\",\\\"Keywords_Processed\\\":\\\"reaction diffusion;vector field;vector field visualization;flow visualization\\\",\\\"Title\\\":\\\"Display of vector fields using a reaction-diffusion model\\\"},\\\"1105\\\":{\\\"Abstract\\\":\\\"We present the definition and computational algorithms for a new class of surfaces which are dual to the isosurface produced by the widely used marching cubes (MC) algorithm. These new isosurfaces have the same separating properties as the MC surfaces but they are comprised of quad patches that tend to eliminate the common negative aspect of poorly shaped triangles of the MC isosurfaces. Based upon the concept of this new dual operator, we describe a simple, but rather effective iterative scheme for producing smooth separating surfaces for binary, enumerated volumes which are often produced by segmentation algorithms. Both the dual surface algorithm and the iterative smoothing scheme are easily implemented.\\\",\\\"Authors\\\":\\\"Nielson, G.M.\\\",\\\"Clusters\\\":\\\"DataCleaningAndSmoothing;GraphNetworkDataAndTechniques;IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices;SegmentationAndClassification\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.28\\\",\\\"Keywords\\\":\\\"segmented data;dual graph;triangular mesh;marching cubes;isosurface;smoothing\\\",\\\"Keywords_Processed\\\":\\\"segmented datum;march cube;dual graph;smooth;triangular mesh;isosurface\\\",\\\"Title\\\":\\\"Dual marching cubes\\\"},\\\"1106\\\":{\\\"Abstract\\\":\\\"This paper presents an algorithm for drawing a sequence of graphs that contain an inherent grouping of their vertex set into clusters. It differs from previous work on dynamic graph drawing in the emphasis that is put on maintaining the clustered structure of the graph during incremental layout. The algorithm works online and allows arbitrary modifications to the graph. It is generic and can be implemented using a wide range of static force-directed graph layout tools. The paper introduces several metrics for measuring layout quality of dynamic clustered graphs. The performance of our algorithm is analyzed using these metrics. The algorithm has been successfully applied to visualizing mobile object software\\\",\\\"Authors\\\":\\\"Frishman, Y.;Tal, A.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;DynamicDataAndTechniques;GraphNetworkDataAndTechniques;SoftwareVisualization\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.18\\\",\\\"Keywords\\\":\\\"software visualization;mobile objects;graph drawing;dynamic layout\\\",\\\"Keywords_Processed\\\":\\\"graph drawing;dynamic layout;mobile object;software visualization\\\",\\\"Title\\\":\\\"Dynamic Drawing of Clustered Graphs\\\"},\\\"1107\\\":{\\\"Abstract\\\":\\\"Many tree browsers allow subtrees under a node to be collapsed or expanded, enabling the user to control screen space usage and selectively drill-down. However, explicit expansion of nodes can be tedious. Expand-ahead is a space-filling strategy by which some nodes are automatically expanded to fill available screen space, without expanding so far that nodes are shown at a reduced size or outside the viewport. This often allows a user exploring the tree to see further down the tree without the effort required in a traditional browser. It also means the user can sometimes drill-down a path faster, by skipping over levels of the tree that are automatically expanded for them. Expand-ahead differs from many detail-in-context techniques in that there is no scaling or distortion involved. We present 1D and 2D prototype implementations of expand-ahead, and identify various design issues and possible enhancements to our designs. Our prototypes support smooth, animated transitions between different views of a tree. We also present the results of a controlled experiment which show that, under certain conditions, users are able to drill-down faster with expand-ahead than without\\\",\\\"Authors\\\":\\\"McGuffin, M.J.;Davison, G.;Balakrishnan, R.\\\",\\\"Clusters\\\":\\\"AutomaticAnalysisVisualizationTechniques;FocusContextTechniques;HierarchicalTreeDataAndTechniques;InteractionTechniquesGeneral;UserInterfacesGeneral;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.21\\\",\\\"Keywords\\\":\\\"expand-ahead;adaptive user interfaces;tree browsing and navigation;focus+context;space-filling;automatic expansion\\\",\\\"Keywords_Processed\\\":\\\"adaptive user interface;space filling;expand ahead;automatic expansion;tree browsing and navigation;focus context\\\",\\\"Title\\\":\\\"Expand-Ahead: A Space-Filling Strategy for Browsing Trees\\\"},\\\"1108\\\":{\\\"Abstract\\\":\\\"In this paper we present EZEL, a visual tool we developed for the performance assessment of peer-to-peer file-sharing networks. We start by identifying the relevant data transferred in this kind of networks and the main performance assessment questions. Then we describe the visualization of data from two different points of view. First we take servers as focal points and we introduce a new technique, faded cushioning, which allows visualizing the same data from different perspectives. Secondly, we present the viewpoint of files, and we expose the correlations with the server stance via a special scatter plot. Finally, we discuss how our tool, based on the described techniques, is effective in the performance assessment of peer-to-peer file-sharing networks\\\",\\\"Authors\\\":\\\"Voinea, L.;Telea, A.;van Wijk, J.J.\\\",\\\"Clusters\\\":\\\"ComputerNetworksNetworkSecurity;DistributedSystemsAndGridEnvironments;SmallMobileUbiquitousDevicesDisplays;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.25\\\",\\\"Keywords\\\":\\\"p2p file-sharing networks visualization;small displays;process visualization;distributed file systems visualization\\\",\\\"Keywords_Processed\\\":\\\"distribute file system visualization;process visualization;p2p file sharing network visualization;small display\\\",\\\"Title\\\":\\\"EZEL: a Visual Tool for Performance Assessment of Peer-to-Peer File-Sharing Network\\\"},\\\"1109\\\":{\\\"Abstract\\\":\\\"We present a novel multiscale approach for flow visualization. We define a local alignment tensor that encodes a measure for alignment to the direction of a given flow field. This tensor induces an anisotropic differential operator on the flow domain, which is discretized with a standard finite element technique. The entries of the corresponding stiffness matrix represent the anisotropically weighted couplings of adjacent nodes of the domain mesh. We use an algebraic multigrid algorithm to generate a hierarchy of fine to coarse descriptions for the above coupling data. This hierarchy comprises a set of coarse grid nodes, a multiscale of basis functions and their corresponding supports. We use these supports to obtain a multilevel decomposition of the flow structure. Standard streamline icons are used to visualize this decomposition at any user-selected level of detail. The method provides a single framework for vector field decomposition independent on the domain dimension or mesh type. Applications are shown in 2D, for flow fields on curved surfaces, and for 3D volumetric flow fields.\\\",\\\"Authors\\\":\\\"Griebel, M.;Preusser, T.;Rumpf, M.;Schweitzer, M.A.;Telea, A.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;MeshesGridsAndLattices;MultiScaleDataTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.32\\\",\\\"Keywords\\\":\\\"flow visualization;algebraic multigrid;multi-scale visualization\\\",\\\"Keywords_Processed\\\":\\\"algebraic multigrid;multi scale visualization;flow visualization\\\",\\\"Title\\\":\\\"Flow field clustering via algebraic multigrid\\\"},\\\"1110\\\":{\\\"Abstract\\\":\\\"Most data used in the study of seafloor hydrothermal plumes consists of sonar (acoustic) scans and sensor readings. Visual data captures only a portion of the sonar data range due to the prohibitive cost and physical infeasibility of taking sufficient lighting and video equipment to such extreme depths. However, visual images are available from research dives and from the recent IMAX movie, volcanoes of the deep sea. In this application paper, we apply existing lighting models with forward scattering and light attenuation to the 3D sonar data in order to mimic the visual images available. These generated images are compared to existing visual images. This can help the geoscientists understand the relationship between these different data modalities and elucidate some of the mechanisms used to capture the data.\\\",\\\"Authors\\\":\\\"Santilli, K.;Bemis, K.;Silver, D.;Dastur, J.;Rona, P.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;EarthSpaceAndEnvironmentalSciences;HardwareAccellerationAndComputationGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.34\\\",\\\"Keywords\\\":\\\"earth / space / and environmental sciences visualization;pc-based volume graphics;volume rendering;applications of volume graphics and volume visualization\\\",\\\"Keywords_Processed\\\":\\\"volume render;pc base volume graphic;application of volume graphic and volume visualization;earth space and environmental science visualization\\\",\\\"Title\\\":\\\"Generating realistic images from hydrothermal plume data\\\"},\\\"1111\\\":{\\\"Abstract\\\":\\\"A common deficiency of discretized datasets is that detail beyond the resolution of the dataset has been irrecoverably lost. This lack of detail becomes immediately apparent once one attempts to zoom into the dataset and only recovers blur. We describe a method that generates the missing detail from any available and plausible high-resolution data, using texture synthesis. Since the detail generation process is guided by the underlying image or volume data and is designed to fill in plausible detail in accordance with the coarse structure and properties of the zoomed-in neighborhood, we refer to our method as constrained texture synthesis. Regular zooms become \\\\\\\"semantic zooms\\\\\\\", where each level of detail stems from a data source attuned to that resolution. We demonstrate our approach by a medical application - the visualization of a human liver - but its principles readily apply to any scenario, as long as data at all resolutions are available. We first present a 2D viewing application, called the \\\\\\\"virtual microscope\\\\\\\", and then extend our technique to 3D volumetric viewing.\\\",\\\"Authors\\\":\\\"Lujin Wang;Mueller, K.\\\",\\\"Clusters\\\":\\\"Textures;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.35\\\",\\\"Keywords\\\":\\\"texture synthesis;semantic zoom\\\",\\\"Keywords_Processed\\\":\\\"texture synthesis;semantic zoom\\\",\\\"Title\\\":\\\"Generating sub-resolution detail in images and volumes using constrained texture synthesis\\\"},\\\"1112\\\":{\\\"Abstract\\\":\\\"Analyzing observations over time and geography is a common task but typically requires multiple, separate tools. The objective of our research has been to develop a method to visualize, and work with, the spatial interconnectedness of information over time and geography within a single, highly interactive 3D view. A novel visualization technique for displaying and tracking events, objects and activities within a combined temporal and geospatial display has been developed. This technique has been implemented as a demonstratable prototype called GeoTime in order to determine potential utility. Initial evaluations have been with military users. However, we believe the concept is applicable to a variety of government and business analysis tasks\\\",\\\"Authors\\\":\\\"Kapler, T.;Wright, W.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;GeographyGeospatialVisCartographyTerrainVis;InteractionTechniquesGeneral;SpatiotemporalDataAndTechniques;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.27\\\",\\\"Keywords\\\":\\\"interactive visualization;spatio-temporal;3d visualization;visual data analysis;geospatial;link analysis\\\",\\\"Keywords_Processed\\\":\\\"visual datum analysis;geospatial;spatio temporal;link analysis;3d visualization;interactive visualization\\\",\\\"Title\\\":\\\"GeoTime Information Visualization\\\"},\\\"1113\\\":{\\\"Abstract\\\":\\\"We present an efficient algorithm to mesh the macromolecules surface model represented by the skin surface defined by Edelsbrunner. Our algorithm overcomes several challenges residing in current surface meshing methods. First, we guarantee the mesh quality with a provable lower bound of 21 on its minimum angle. Second, we ensure the triangulation is homeomorphic to the original surface. Third, we improve the efficiency of constructing the restricted Delaunay triangulation (RDT) of smooth surfaces. We achieve this by constructing the RDT using the advancing front method without computing the Delaunay tetrahedrization of the sample points on the surfaces. The difficulty of handling the front collision problem is tackled by employing the Morse theory. In particular, we construct the Morse-Smale complex to simplify the topological changes of the front. Our implementation results suggest that the algorithm decrease the time of generating high quality homeomorphic skin mesh from hours to a few minutes.\\\",\\\"Authors\\\":\\\"Cheng, H.-L.;Shi, X.\\\",\\\"Clusters\\\":\\\"MeshesGridsAndLattices;SurfaceRelatedDataAndTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.36\\\",\\\"Keywords\\\":\\\"smooth surfaces;morse-smale complex;meshing;guaranteed quality triangulation;homeomorphism\\\",\\\"Keywords_Processed\\\":\\\"homeomorphism;morse smale complex;mesh;smooth surface;guarantee quality triangulation\\\",\\\"Title\\\":\\\"Guaranteed quality triangulation of molecular skin surfaces\\\"},\\\"1114\\\":{\\\"Abstract\\\":\\\"Surface texture is among the most salient haptic characteristics of objects; it can induce vibratory contact forces that lead to perception of roughness. We present a new algorithm to display haptic texture information resulting from the interaction between two textured objects. We compute contact forces and torques using low-resolution geometric representations along with texture images that encode surface details. We also introduce a novel force model based on directional penetration depth and describe an efficient implementation on programmable graphics hardware that enables interactive haptic texture rendering of complex models. Our force model takes into account important factors identified by psychophysics studies and is able to haptically display interaction due to fine surface textures that previous algorithms do not capture.\\\",\\\"Authors\\\":\\\"Otaduy, M.A.;Jain, N.;Sud, A.;Lin, M.C.\\\",\\\"Clusters\\\":\\\"InputAndOutputDevicesGeneral;Textures\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.37\\\",\\\"Keywords\\\":\\\"texture;haptics;graphics hardware\\\",\\\"Keywords_Processed\\\":\\\"graphic hardware;texture;haptic\\\",\\\"Title\\\":\\\"Haptic display of interaction between textured models\\\"},\\\"1115\\\":{\\\"Abstract\\\":\\\"We present a hardware-accelerated adaptive EWA (elliptical weighted average) volume splatting algorithm. EWA splatting combines a Gaussian reconstruction kernel with a low-pass image filter for high image quality without aliasing artifacts or excessive blurring. We introduce a novel adaptive filtering scheme to reduce the computational cost of EWA splatting. We show how this algorithm can be efficiently implemented on modern graphics processing units (GPUs). Our implementation includes interactive classification and fast lighting. To accelerate the rendering we store splat geometry and 3D volume data locally in GPU memory. We present results for several rectilinear volume datasets that demonstrate the high image quality and interactive rendering speed of our method.\\\",\\\"Authors\\\":\\\"Wei Chen;Liu Ren;Zwicker, M.;Pfister, H.\\\",\\\"Clusters\\\":\\\"FilteringTechniques;HardwareAccellerationAndComputationGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.38\\\",\\\"Keywords\\\":\\\"direct volume rendering;volume splatting;elliptical weighted average filter;hardware acceleration\\\",\\\"Keywords_Processed\\\":\\\"elliptical weight average filter;volume splatte;hardware acceleration;direct volume render\\\",\\\"Title\\\":\\\"Hardware-accelerated adaptive EWA volume splatting\\\"},\\\"1116\\\":{\\\"Abstract\\\":\\\"ImageSurfer is a tool designed to explore correlations between two 3D scalar fields. Our scientific goal was to determine where a protein is located, and how much its concentration varies along the membrane of a neuronal dendrite. The 3D scalar field data sets fall into two categories: dendritic plasma membranes (defining the structure) and immunofluorescent staining (defining protein concentration along the structure). ImageSurfer enables scientists to analyze relationships between multiple data sets obtained with confocal microscopy by providing 3D surface view, height field, and graphing tools. Each tool reduces the complexity of the problem by extracting a restricted subset of data: finding a region of interest in 3D; getting a sense of relative concentrations in 2D, and getting exact concentration values in 1D. The current design is presented, along with the rationale for each design decision. The tool is already proving useful for data exploration, analysis, and presentation.\\\",\\\"Authors\\\":\\\"Jen, D.;Parente, P.;Robbins, J.;Weigle, C.;Taylor, R.M.;Burette, A.;Weinberg, R.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;BiologyAndBioinformatics;Microscopy;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.46\\\",\\\"Keywords\\\":\\\"data exploration;scientific visualization;immunofluorescence;biology;volume visualization;confocal microscopy\\\",\\\"Keywords_Processed\\\":\\\"immunofluorescence;confocal microscopy;biology;scientific visualization;volume visualization;datum exploration\\\",\\\"Title\\\":\\\"ImageSurfer: a tool for visualizing correlations between two volume scalar fields\\\"},\\\"1117\\\":{\\\"Abstract\\\":\\\"This work presents an experimental immersive interface for designing DNA components for application in nanotechnology. While much research has been done on immersive visualization, this is one of the first systems to apply advanced interface techniques to a scientific design problem. This system uses tangible 3D input devices (tongs, a raygun, and a multipurpose handle tool) to create and edit a purely digital representation of DNA. The tangible controllers are associated with functions (not data) while a virtual display is used to render the model. This interface was built in collaboration with a research group investigating the design of DNA tiles. A user study shows that scientists find the immersive interface more satisfying than a 2D interface due to the enhanced understanding gained by directly interacting with molecules in 3D space.\\\",\\\"Authors\\\":\\\"Schkolne, S.;Ishii, H.;Schroder, P.\\\",\\\"Clusters\\\":\\\"Genetics;ImmersiveAndVirtualEnvironments;MolecularScienceAndChemistry;SpaceRelatedSpatialDataAndTechniques;UserInterfacesGeneral;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.47\\\",\\\"Keywords\\\":\\\"props;spatial construction;virtual reality;molecular visualization;dna design;tangible user interface;responsive workbench;augmented reality;molecular modeling\\\",\\\"Keywords_Processed\\\":\\\"augmented reality;molecular visualization;dna design;prop;molecular modeling;spatial construction;virtual reality;tangible user interface;responsive workbench\\\",\\\"Title\\\":\\\"Immersive design of DMA molecules with a tangible interface\\\"},\\\"1118\\\":{\\\"Abstract\\\":\\\"This work introduces importance-driven volume rendering as a novel technique for automatic focus and context display of volumetric data. Our technique is a generalization of cut-away views, which - depending on the viewpoint - remove or suppress less important parts of a scene to reveal more important underlying information. We automatize and apply this idea to volumetric data. Each part of the volumetric data is assigned an object importance, which encodes visibility priority. This property determines which structures should be readily discernible and which structures are less important. In those image regions, where an object occludes more important structures it is displayed more sparsely than in those areas where no occlusion occurs. Thus the objects of interest are clearly visible. For each object several representations, i.e., levels of sparseness, are specified. The display of an individual object may incorporate different levels of sparseness. The goal is to emphasize important structures and to maximize the information content in the final image. This work also discusses several possible schemes for level of sparseness specification and different ways how object importance can be composited to determine the final appearance of a particular object.\\\",\\\"Authors\\\":\\\"Viola, I.;Kanitsar, A.;Groller, E.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;IllustrativeVisualization;LevelOfDetail;ViewDependentVisualization;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.48\\\",\\\"Keywords\\\":\\\"volume rendering;focus+context technique;level-of-detail techniques;non-photorealistic techniques;view-dependent visualization\\\",\\\"Keywords_Processed\\\":\\\"volume render;non photorealistic technique;view dependent visualization;focus context technique;level of detail technique\\\",\\\"Title\\\":\\\"Importance-driven volume rendering\\\"},\\\"1119\\\":{\\\"Abstract\\\":\\\"Multiperspective images are a useful way to visualize extended, roughly planar scenes such as landscapes or city blocks. However, constructing effective multiperspective images is something of an art. We describe an interactive system for creating multiperspective images composed of serially blended cross-slits images. Beginning with a sideways-looking video of the scene as might be captured from a moving vehicle, we allow the user to interactively specify a set of cross-slits cameras, possibly with gaps between them. In each camera, one of the slits is defined to be the camera path, which is typically horizontal, and the user is left to choose the second slit, which is typically vertical. The system then generates intermediate views between these cameras using a novel interpolation scheme, thereby producing a multiperspective image with no seams. The user can also choose the picture surface in space onto which viewing rays are projected, thereby establishing a parameterization for the image. We show how the choice of this surface can be used to create interesting visual effects. We demonstrate our system by constructing multiperspective images that summarize city blocks, including corners, blocks with deep plazas and other challenging urban situations.\\\",\\\"Authors\\\":\\\"Roman, A.;Garg, G.;Levoy, M.\\\",\\\"Clusters\\\":\\\"GeographyGeospatialVisCartographyTerrainVis;ImageBasedDataImageSignalProcessing\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.50\\\",\\\"Keywords\\\":\\\"multi-perspective image;cross-slits image;city block\\\",\\\"Keywords_Processed\\\":\\\"city block;cross slit image;multi perspective image\\\",\\\"Title\\\":\\\"Interactive design of multi-perspective images for visualizing urban landscapes\\\"},\\\"1120\\\":{\\\"Abstract\\\":\\\"Datasets of tens of gigabytes are becoming common in computational and experimental science. This development is driven by advances in imaging technology, producing detectors with growing resolutions, as well as availability of cheap processing power and memory capacity in commodity-based computing clusters. We describe the design of a visualization system that allows scientists to interactively explore large remote data sets in an efficient and flexible way. The system is broadly applicable and currently used by medical scientists conducting an osteoporosis research project. Human vertebral bodies are scanned using a high resolution microCT scanner producing scans of roughly 8 GB size each. All participating research groups require access to the centrally stored data. Due to the rich internal bone structure, scientists need to interactively explore the full dataset at coarse levels, as well as visualize subvolumes of interest at the highest resolution. Our solution is based on HDF5 and GridFTP. When accessing data remotely, the HDF5 data processing pipeline is modified to support efficient retrieval of subvolumes. We reduce the overall latency and optimize throughput by executing high-level operations on the remote side. The GridFTP protocol is used to pass the HDF5 requests to a customized server. The approach takes full advantage of local graphics hardware for rendering. Interactive visualization is accomplished using a background thread to access the datasets stored in a multiresolution format. A hierarchical volume tenderer provides seamless integration of high resolution details with low resolution overviews.\\\",\\\"Authors\\\":\\\"Prohaska, S.;Hutanu, A.;Kahler, R.;Hege, H.-C.\\\",\\\"Clusters\\\":\\\"DistributedSystemsAndGridEnvironments;LargeScaleDataAndScalability;MultiresolutionTechniques;OutOfCoreProcessing\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.51\\\",\\\"Keywords\\\":\\\"large data;remote visualization;multi-resoution visualization;out-of-core methods\\\",\\\"Keywords_Processed\\\":\\\"large datum;out of core method;multi resoution visualization;remote visualization\\\",\\\"Title\\\":\\\"Interactive exploration of large remote micro-CT scans\\\"},\\\"1121\\\":{\\\"Abstract\\\":\\\"We propose a novel point-based approach to view dependent isosurface extraction. We introduce a fast visibility query system for the view dependent traversal, which exhibits moderate memory requirements. This technique allows for an interactive interrogation of the full visible woman dataset (1GB) at four to fifteen frames per second on a desktop computer. The point-based approach is built on an extraction scheme that classifies different sections of the isosurface into four categories, depending on the size of the geometry when projected onto the screen. In particular, we use points to represent small and subpixel triangles, as well as larger sections of the isosurface whose projection has subpixel size. To assign consistent and robust normals to individual points representing such regions, we propose to compute them during post processing of the extracted isosurface and provide the corresponding hardware implementation.\\\",\\\"Authors\\\":\\\"Livnat, Y.;Tricoche, X.\\\",\\\"Clusters\\\":\\\"InteractionTechniquesGeneral;IsosurfaceAndSurfaceExtractionTechniques;LargeScaleDataAndScalability;PointBasedDataAndTechniques;ViewDependentVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.52\\\",\\\"Keywords\\\":\\\"large data;interactive;isosurface;view-dependent;point-based\\\",\\\"Keywords_Processed\\\":\\\"point base;isosurface;interactive;view dependent;large datum\\\",\\\"Title\\\":\\\"Interactive point-based isosurface extraction\\\"},\\\"1122\\\":{\\\"Abstract\\\":\\\"This work describes the methods used to produce an interactive visualization of a 2 TB computational fluid dynamics (CFD) data set using particle tracing (streaklines). We use the method introduced by Bruckschen el al. (2001) that precomputes a large number of particles, stores them on disk using a space-filling curve ordering that minimizes seeks, then retrieves and displays the particles according to the user's command. We describe how the particle computation can be performed using a PC cluster, how the algorithm can be adapted to work with a multiblock curvilinear mesh, how scalars can be extracted and used to color the particles, and how the out-of-core visualization can be scaled to 293 billion particles while still achieving interactive performance on PC hardware. Compared to the earlier work, our data set size and total number of particles are an order of magnitude larger. We also describe a new compression technique that losslessly reduces the amount of particle storage by 41% and speeds the particle retrieval by about 20%.\\\",\\\"Authors\\\":\\\"Ellsworth, D.;Green, B.;Moran, P.J.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;FlowVisualizationDataAndTechniques;InputAndOutputDevicesGeneral;LargeScaleDataAndScalability;OutOfCoreProcessing;ParticleVisualizationAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.55\\\",\\\"Keywords\\\":\\\"large data;pc hardware;computational fluid dynamics;visualization;particle tracing;out-of-core;clusters\\\",\\\"Keywords_Processed\\\":\\\"visualization;pc hardware;cluster;particle tracing;out of core;large datum;computational fluid dynamic\\\",\\\"Title\\\":\\\"Interactive terascale particle visualization\\\"},\\\"1123\\\":{\\\"Abstract\\\":\\\"This work describes a method to visualize the thickness of curved thin objects. Given the MRI volume data of articular cartilage, medical doctors investigate pathological changes of the thickness. Since the tissue is very thin, it is impossible to reliably map the thickness information by direct volume rendering. Our idea is based on unfolding of such structures preserving their thickness. This allows to perform anisotropic geometrical operations (e.g., scaling the thickness). However, flattening of a curved structure implies a distortion of its surface. The distortion problem is alleviated through a focus-and-context minimization approach. Distortion is smallest close to a focal point which can be interactively selected by the user.\\\",\\\"Authors\\\":\\\"Mlejnek, M.;Vilanova, A.;Groller, E.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;BiomedicalScienceAndMedicine\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.56\\\",\\\"Keywords\\\":\\\"applications of visualization;visualization in medicine\\\",\\\"Keywords_Processed\\\":\\\"visualization in medicine;application of visualization\\\",\\\"Title\\\":\\\"Interactive thickness visualization of articular cartilage\\\"},\\\"1124\\\":{\\\"Abstract\\\":\\\"Many real world graphs have small world characteristics, that is, they have a small diameter compared to the number of nodes and exhibit a local cluster structure. Examples are social networks, software structures, bibliographic references and biological neural nets. Their high connectivity makes both finding a pleasing layout and a suitable clustering hard. In this paper we present a method to create scalable, interactive visualizations of small world graphs, allowing the user to inspect local clusters while maintaining a global overview of the entire structure. The visualization method uses a combination of both semantical and geometrical distortions, while the layout is generated by a spring embedder algorithm using recently developed force model. We use a cross referenced database of 500 artists as a running example\\\",\\\"Authors\\\":\\\"van Ham, F.;van Wijk, J.J.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;GraphNetworkDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.43\\\",\\\"Keywords\\\":\\\"small world graphs;clustering;graph drawing;graph visualization\\\",\\\"Keywords_Processed\\\":\\\"small world graph;graph visualization;graph drawing;clustering\\\",\\\"Title\\\":\\\"Interactive Visualization of Small World Graphs\\\"},\\\"1125\\\":{\\\"Abstract\\\":\\\"Virtual prototyping is increasingly replacing real mock-ups and experiments in industrial product development. Part of this process is the simulation of structural and functional properties, which is in many cases based on finite element analysis (FEA). One prominent example from the automotive industry is the safety improvement resulting from crash worthiness simulations. A simulation model for this purpose usually consists of up to one million finite elements and is assembled from many parts, which are individually meshed out of their CAD representation. In order to accelerate the development cycle, simulation engineers want to be able to modify their FE models without going back to the CAD department. Furthermore, valid CAD models might even not be available in preliminary design stages. However, in contrast to CAD, there is a lack of tools that offer the possibility of modification and processing of finite element components while maintaining the properties relevant to the simulation. In this application paper we present interactive algorithms for intuitive and fast editing of FE models and appropriate visualization techniques to support engineers in understating these models. This includes new kinds of manipulators, feedback mechanisms and facilities for virtual reality and immersion at the workplace, e.g. autostereoscopic displays and haptic devices.\\\",\\\"Authors\\\":\\\"Rose, D.;Bidmon, K.;Ertl, T.\\\",\\\"Clusters\\\":\\\"DisplaysGeneral;InteractionTechniquesGeneral;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.58\\\",\\\"Keywords\\\":\\\"manipulators;autostereoscopy;finite element modeling;interaction\\\",\\\"Keywords_Processed\\\":\\\"interaction;autostereoscopy;finite element modeling;manipulator\\\",\\\"Title\\\":\\\"Intuitive and interactive modification of large finite element models\\\"},\\\"1126\\\":{\\\"Abstract\\\":\\\"We investigate two important, common fluid flow patterns from computational fluid dynamics (CFD) simulations, namely, swirl and tumble motion typical of automotive engines. We study and visualize swirl and tumble flow using three different flow visualization techniques: direct, geometric, and texture-based. When illustrating these methods side-by-side, we describe the relative strengths and weaknesses of each approach within a specific spatial dimension and across multiple spatial dimensions typical of an engineer's analysis. Our study is focused on steady-state flow. Based on this investigation we offer perspectives on where and when these techniques are best applied in order to visualize the behavior of swirl and tumble motion.\\\",\\\"Authors\\\":\\\"Laramee, R.S.;Weiskopf, D.;Schneider, J.;Hauser, H.\\\",\\\"Clusters\\\":\\\"Engineering;FlowVisualizationDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.59\\\",\\\"Keywords\\\":\\\"flow visualization;visualization systems;computational fluid dynamics;in-cylinder flow;engine simulation;swirl flow;tumble flow\\\",\\\"Keywords_Processed\\\":\\\"in cylinder flow;swirl flow;visualization system;engine simulation;tumble flow;computational fluid dynamic;flow visualization\\\",\\\"Title\\\":\\\"Investigating swirl and tumble flow with a comparison of visualization techniques\\\"},\\\"1127\\\":{\\\"Abstract\\\":\\\"We introduce Light Collages - a lighting design system for effective visualization based on principles of human perception. Artists and illustrators enhance perception of features with lighting that is locally consistent and globally inconsistent. Inspired by these techniques, we design the placement of light sources to convey a greater sense of realism and better perception of shape with globally inconsistent lighting. Our algorithm segments the objects into local surface patches and uses a number of perceptual heuristics, such as highlights, shadows, and silhouettes, to enhance the perception of shape. We show our results on scientific and sculptured datasets.\\\",\\\"Authors\\\":\\\"Lee, C.H.;Hao, X.;Varshney, A.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;Illumination;IllustrativeVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.62\\\",\\\"Keywords\\\":\\\"light placement;scientific illustration;inconsistent lighting;proximity shadows;lighting design;silhouette enhancement\\\",\\\"Keywords_Processed\\\":\\\"proximity shadow;inconsistent lighting;light placement;silhouette enhancement;lighting design;scientific illustration\\\",\\\"Title\\\":\\\"Light Collages: lighting design for effective visualization\\\"},\\\"1128\\\":{\\\"Abstract\\\":\\\"We present a space leaping technique for accelerating volume rendering with very low space and run-time complexity. Our technique exploits the ray coherence during ray casting by using the distance a ray traverses in empty space to leap its neighboring rays. Our technique works with parallel as well as perspective volume rendering, does not require any preprocessing or 3D data structures, and is independent of the transfer function. Being an image-space technique, it is independent of the complexity of the data being rendered. It can be used to accelerate both time-coherent and noncoherent animation sequences.\\\",\\\"Authors\\\":\\\"Lakare, S.;Kaufman, A.\\\",\\\"Clusters\\\":\\\"HardwareAccellerationAndComputationGeneral;RaytracingRaycasting;Rendering;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.63\\\",\\\"Keywords\\\":\\\"empty space skipping;ray coherence;direct volume rendering;volume rendering acceleration;space leaping\\\",\\\"Keywords_Processed\\\":\\\"space leap;volume render acceleration;direct volume render;empty space skipping;ray coherence\\\",\\\"Title\\\":\\\"Light weight space leaping using ray coherence\\\"},\\\"1129\\\":{\\\"Abstract\\\":\\\"An important task in volume rendering is the visualization of boundaries between materials. This is typically accomplished using transfer functions that increase opacity based on a voxel's value and gradient. Lighting also plays a crucial role in illustrating surfaces. In this paper we present a multi-dimensional transfer function method for enhancing surfaces, not through the variation of opacity, but through the modification of surface shading. The technique uses a lighting transfer function that takes into account the distribution of values along a material boundary and features a novel interface for visualizing and specifying these transfer functions. With our method, the user is given a means of visualizing boundaries without modifying opacity, allowing opacity to be used for illustrating the thickness of homogeneous materials through the absorption of light.\\\",\\\"Authors\\\":\\\"Lum, E.B.;Kwan-Liu Ma\\\",\\\"Clusters\\\":\\\"Rendering;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.64\\\",\\\"Keywords\\\":\\\"shading;transfer function;direct volume rendering;multi-dimensional transfer function;volume visualization\\\",\\\"Keywords_Processed\\\":\\\"shade;multi dimensional transfer function;direct volume render;transfer function;volume visualization\\\",\\\"Title\\\":\\\"Lighting transfer functions using gradient aligned sampling\\\"},\\\"1130\\\":{\\\"Abstract\\\":\\\"We derive piecewise linear and piecewise cubic box spline reconstruction filters for data sampled on the body centered cubic (BCC) lattice. We analytically derive a time domain representation of these reconstruction filters and using the Fourier slice-projection theorem we derive their frequency responses. The quality of these filters, when used in reconstructing BCC sampled volumetric data, is discussed and is demonstrated with a raycaster. Moreover, to demonstrate the superiority of the BCC sampling, the resulting reconstructions are compared with those produced from similar filters applied to data sampled on the Cartesian lattice.\\\",\\\"Authors\\\":\\\"Entezari, A.;Dyer, R.;Moller, T.\\\",\\\"Clusters\\\":\\\"Interpolation;MeshesGridsAndLattices;Sampling\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.65\\\",\\\"Keywords\\\":\\\"body-centered cubic lattice;reconstruction;optimal regular sampling\\\",\\\"Keywords_Processed\\\":\\\"optimal regular sampling;body center cubic lattice;reconstruction\\\",\\\"Title\\\":\\\"Linear and cubic box splines for the body centered cubic lattice\\\"},\\\"1131\\\":{\\\"Abstract\\\":\\\"We introduce local and global comparison measures for a collection of k /spl les/ d real-valued smooth functions on a common d-dimensional Riemannian manifold. For k = d = 2 we relate the measures to the set of critical points of one function restricted to the level sets of the other. The definition of the measures extends to piecewise linear functions for which they are easy to compute. The computation of the measures forms the centerpiece of a software tool which we use to study scientific datasets.\\\",\\\"Authors\\\":\\\"Edelsbrunner, H.;Harer, J.;Natarajan, V.;Pascucci, V.\\\",\\\"Clusters\\\":\\\"ComparisonComparativeVisualizationAndSimilarity;NumericalMethodsMathematics;TimeseriesTimeVaryingDataAndTechniques;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.68\\\",\\\"Keywords\\\":\\\"comparison measure;riemannian manifolds;time-varying data;differential forms;visualization;smooth functions\\\",\\\"Keywords_Processed\\\":\\\"visualization;time vary datum;differential form;smooth function;comparison measure;riemannian manifold\\\",\\\"Title\\\":\\\"Local and global comparison of continuous functions\\\"},\\\"1132\\\":{\\\"Abstract\\\":\\\"A new multiple resolution volume rendering method for finite element analysis (FEA) data is presented. Our method is composed of three stages: in the first stage, the Gauss points of the FEA cells are calculated. The function values, gradients, diffusions, and influence scopes of the Gauss points are computed. By representing the Gauss points as graph vertices and connecting adjacent Gauss points with edges, an adjacency graph is created. The adjacency graph is used to represent the FEA data in the subsequent computation. In the second stage, a hierarchical structure is established upon the adjacency graph. Any two neighboring vertices with similar function values are merged into a new vertex. The similarity is measured by using a user-defined threshold. Consequently, a new adjacency graph is constructed. Then the threshold is increased, and the graph reduction is triggered again to generate another adjacency graph. By repeating the processing, multiple adjacency graphs are computed, and a level of detail (LoD) representation of the FEA data is established. In the third stage, the LoD structure is rendered by using a splatting method. At first, a level of adjacency graph is selected by users. The graph vertices arc sorted based on their visibility orders and projected onto the image plane in back-to-front order. Billboards are used to render the vertices in the projection. The function values, gradients, and influence scopes of the vertices are utilized to decide the colors, opacities, orientations, and shapes of the billboards. The billboards are then modulated with texture maps to generate the footprints of the vertices. Finally, these footprints are composited to produce the volume rendering image.\\\",\\\"Authors\\\":\\\"Shyh-Kuang Ueng;Yan-Jen Su;Chi-Tang Chang\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;DataTypesGeneral;LevelOfDetail;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.69\\\",\\\"Keywords\\\":\\\"volume rendering;scientific visualization;level-of-detail;splatting method;unstructured data\\\",\\\"Keywords_Processed\\\":\\\"volume render;unstructured datum;scientific visualization;level of detail;splatte method\\\",\\\"Title\\\":\\\"LoD volume rendering of FEA data\\\"},\\\"1133\\\":{\\\"Abstract\\\":\\\"In Web data, telecommunications traffic and in epidemiological studies, dense subgraphs correspond to subsets of subjects (i.e. users, patients) that share a collection of attributes values (i.e. accessed Web pages, email-calling patterns or disease diagnostic profiles). Visual and computational identification of these \\\\\\\"clusters\\\\\\\" becomes useful when domain experts desire to determine those factors of major influence in the formation of access and communication clusters or in the detection and contention of disease spread. With the current increases in graphic hardware capabilities and RAM sizes, it is more useful to relate graph sizes to the available screen real estate S and the amount of available RAM M, instead of the number of edges or nodes in the graph. We offer a visual interface that is parameterized by M and S and is particularly suited for navigation tasks that require the identification of subgraphs whose edge density is above certain threshold. This is achieved by providing a zoomable matrix view of the underlying data. This view is strongly coupled to a hierarchical view of the essential information elements present in the data domain. We illustrate the applicability of this work to the visual navigation of cancer incidence data and to an aggregated sample of phone call traffic\\\",\\\"Authors\\\":\\\"Abello, J.;van Ham, F.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;BiomedicalScienceAndMedicine;DataClusteringAndAggregation;GraphNetworkDataAndTechniques;HardwareAccellerationAndComputationGeneral;HierarchicalTreeDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.46\\\",\\\"Keywords\\\":\\\"cancer data;clustering;hierarchy trees;external memory algorithms;graph visualization;phone traffic\\\",\\\"Keywords_Processed\\\":\\\"external memory algorithm;phone traffic;cancer datum;clustering;graph visualization;hierarchy tree\\\",\\\"Title\\\":\\\"Matrix Zoom: A Visual Interface to Semi-External Graphs\\\"},\\\"1134\\\":{\\\"Abstract\\\":\\\"Resampling is a frequent task in visualization and medical imaging. It occurs whenever images or volumes are magnified, rotated, translated, or warped. Resampling is also an integral procedure in the registration of multimodal datasets, such as CT, PET, and MRI, in the correction of motion artifacts in MRI, and in the alignment of temporal volume sequences in fMRI. It is well known that the quality of the resampling result depends heavily on the quality of the interpolation filter used. However, high-quality filters are rarely employed in practice due to their large spatial extents. We explore a new resampling technique that operates in the frequency-domain where high-quality filtering is feasible. Further, unlike previous methods of this kind, our technique is not limited to integer-ratio scaling factors, but can resample image and volume datasets at any rate. This would usually require the application of slow discrete Fourier transforms (DFT) to return the data to the spatial domain. We studied two methods that successfully avoid these delays: the chirp-z transform and the FFTW package. We also outline techniques to avoid the ringing artifacts that may occur with frequency-domain filtering. Thus, our method can achieve high-quality interpolation at speeds that are usually associated with spatial filters of far lower quality.\\\",\\\"Authors\\\":\\\"Li, A.;Mueller, K.;Ernst, T.\\\",\\\"Clusters\\\":\\\"FilteringTechniques;NumericalMethodsMathematics;Sampling\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.70\\\",\\\"Keywords\\\":\\\"fourier transform;filters;resampling\\\",\\\"Keywords_Processed\\\":\\\"fouri transform;resample;filter\\\",\\\"Title\\\":\\\"Methods for efficient, high quality volume resampling in the frequency domain\\\"},\\\"1135\\\":{\\\"Abstract\\\":\\\"We describe an exploratory technique based on the direct interaction with a 2D modified scatterplot computed from two different metrics calculated over the elements of a network. The scatterplot is transformed into an image by applying standard image processing techniques resulting into blurring effects. Segmentation of the image allow to easily select patches on the image as a way to extract subnetworks. We were inspired by the work of Wattenberg and Fisher [M. Wattenberg et al. (2003)] showing that the blurring process builds into a multiscale perceptual scheme, making this type of interaction intuitive to the user. We explain how the exploration of the network can be guided by the visual analysis of the blurred scatterplot and by its possible interpretations\\\",\\\"Authors\\\":\\\"Chiricota, Y.;Jourdan, F.;Melancon, G.\\\",\\\"Clusters\\\":\\\"AnalysisProcessGeneral;ChartsDiagramsPlots;DataClusteringAndAggregation;FilteringTechniques;ImageBasedDataImageSignalProcessing;Perception;ZoomingAndNavigationTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.47\\\",\\\"Keywords\\\":\\\"multi-scale perceptual organization;clustering;scatterplot;exploration;graph navigation;blurring;filtering\\\",\\\"Keywords_Processed\\\":\\\"multi scale perceptual organization;scatterplot;blur;graph navigation;exploration;clustering;filter\\\",\\\"Title\\\":\\\"Metric-Based Network Exploration and Multiscale Scatterplot\\\"},\\\"1136\\\":{\\\"Abstract\\\":\\\"We present a method by which force-directed algorithms for graph layouts can be generalized to calculate the layout of a graph in an arbitrary Riemannian geometry. The method relies on extending the Euclidean notions of distance, angle, and force-interactions to smooth nonEuclidean geometries via projections to and from appropriately chosen tangent spaces. In particular, we formally describe the calculations needed to extend such algorithms to hyperbolic and spherical geometries\\\",\\\"Authors\\\":\\\"Kobourov, S.;Wampler, K.\\\",\\\"Clusters\\\":\\\"GeometryBasedTechniques;GraphNetworkDataAndTechniques;SpaceRelatedSpatialDataAndTechniques;VisualEncodingAndLayoutGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.49\\\",\\\"Keywords\\\":\\\"spring embedder;information visualization;graph drawing;force-directed algorithm;non-euclidean geometry;hyperbolic space;spherical space\\\",\\\"Keywords_Processed\\\":\\\"graph drawing;hyperbolic space;spring embedder;information visualization;force direct algorithm;spherical space;non euclidean geometry\\\",\\\"Title\\\":\\\"Non-Euclidean Spring Embedders\\\"},\\\"1137\\\":{\\\"Abstract\\\":\\\"Although luminance contrast plays a predominant role in motion perception, significant additional effects are introduced by chromatic contrasts. In this paper, relevant results from psychophysical and physiological research are described to clarify the role of color in motion detection. Interpreting these psychophysical experiments, we propose guidelines for the design of animated visualizations, and a calibration procedure that improves the reliability of visual motion representation. The guidelines are applied to examples from texture-based flow visualization, as well as graph and tree visualisation.\\\",\\\"Authors\\\":\\\"Weiskopf, D.\\\",\\\"Clusters\\\":\\\"ColorColorPerception;FlowVisualizationDataAndTechniques;Perception;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.73\\\",\\\"Keywords\\\":\\\"color;flow visualization;information visualization;human visual system;motion detection;perception;luminance\\\",\\\"Keywords_Processed\\\":\\\"motion detection;human visual system;perception;information visualization;color;luminance;flow visualization\\\",\\\"Title\\\":\\\"On the role of color in the perception of motion in animated visualizations\\\"},\\\"1138\\\":{\\\"Abstract\\\":\\\"All orientable metric surfaces are Riemann surfaces and admit global conformal parameterizations. Riemann surface structure is a fundamental structure and governs many natural physical phenomena, such as heat diffusion and electro-magnetic fields on the surface. A good parameterization is crucial for simulation and visualization. This paper provides an explicit method for finding optimal global conformal parameterizations of arbitrary surfaces. It relies on certain holomorphic differential forms and conformal mappings from differential geometry and Riemann surface theories. Algorithms are developed to modify topology, locate zero points, and determine cohomology types of differential forms. The implementation is based on a finite dimensional optimization method. The optimal parameterization is intrinsic to the geometry, preserves angular structure, and can play an important role in various applications including texture mapping, remeshing, morphing and simulation. The method is demonstrated by visualizing the Riemann surface structure of real surfaces represented as triangle meshes.\\\",\\\"Authors\\\":\\\"Miao Jin;Yalin Wang;Shing-Tung Yau;Gu, X.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;GeometricModeling;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.75\\\",\\\"Keywords\\\":\\\"computational geometry and object modeling;surface parameterization;curve / surface / solid and object representations\\\",\\\"Keywords_Processed\\\":\\\"surface parameterization;curve surface solid and object representation;computational geometry and object modeling\\\",\\\"Title\\\":\\\"Optimal global conformal surface parameterization\\\"},\\\"1139\\\":{\\\"Abstract\\\":\\\"Color is often used to convey information, and color compositing is often required while visualizing multiattribute information. This paper proposes an alternative method for color compositing. In order to present understandable color blending to the general public, several techniques are proposed. First, a paint-inspired RYB color space is used. In addition, noise patterns are employed to produce subregions of pure color within an overlapped region. We show examples to demonstrate the effectiveness of our technique for visualization\\\",\\\"Authors\\\":\\\"Gossett, N.;Baoquan Chen\\\",\\\"Clusters\\\":\\\"ColorColorPerception;Perception\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.52\\\",\\\"Keywords\\\":\\\"ryb;perception;color mixing\\\",\\\"Keywords_Processed\\\":\\\"ryb;color mixing;perception\\\",\\\"Title\\\":\\\"Paint Inspired Color Mixing and Compositing for Visualization\\\"},\\\"1140\\\":{\\\"Abstract\\\":\\\"The physical interpretation of mathematical features of tensor fields is highly application-specific. Existing visualization methods for tensor fields only cover a fraction of the broad application areas. We present a visualization method tailored specifically to the class of tensor field exhibiting properties similar to stress and strain tensors, which are commonly encountered in geomechanics. Our technique is a global method that represents the physical meaning of these tensor fields with their central features: regions of compression or expansion. The method is based on two steps: first, we define a positive definite metric, with the same topological structure as the tensor field; second, we visualize the resulting metric. The eigenvector fields are represented using a texture-based approach resembling line integral convolution (LIC) methods. The eigenvalues of the metric are encoded in free parameters of the texture definition. Our method supports an intuitive distinction between positive and negative eigenvalues. We have applied our method to synthetic and some standard data sets, and \\\\\\\"real\\\\\\\" data from earth science and mechanical engineering application.\\\",\\\"Authors\\\":\\\"Hotz, I.;Feng, L.;Hagen, H.;Hamann, B.;Joy, K.I.;Jeremic, B.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.80\\\",\\\"Keywords\\\":\\\"tensor field;stress tensor;strain tensor;line integral convolution\\\",\\\"Keywords_Processed\\\":\\\"line integral convolution;tensor field;strain tensor;stress tensor\\\",\\\"Title\\\":\\\"Physically based methods for tensor field visualization\\\"},\\\"1141\\\":{\\\"Abstract\\\":\\\"Computational simulation of time-varying physical processes is of fundamental importance for many scientific and engineering applications. Most frequently, time-varying simulations are performed over multiple spatial grids at discrete points in time. We investigate a new approach to time-varying simulation: spacetime discontinuous Galerkin finite element methods. The result of this simulation method is a simplicial tessellation of spacetime with per-element polynomial solutions for physical quantities such as strain, stress, and velocity. To provide accurate visualizations of the resulting solutions, we have developed a method for per-pixel evaluation of solution data on the GPU. We demonstrate the importance of per-pixel rendering versus simple linear interpolation for producing high quality visualizations. We also show that our system can accommodate reasonably large datasets - spacetime meshes containing up to 20 million tetrahedra are not uncommon in this domain.\\\",\\\"Authors\\\":\\\"Zhou, Y.;Garland, M.;Haber, R.\\\",\\\"Clusters\\\":\\\"GpuBasedTechniques;NumericalMethodsMathematics;PixelOrientedEncodings;SpatiotemporalDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.81\\\",\\\"Keywords\\\":\\\"pixel shader;space-time finite elements;pixel-exact visualization;discontinuous galerkin methods\\\",\\\"Keywords_Processed\\\":\\\"pixel exact visualization;space time finite element;discontinuous galerkin method;pixel shader\\\",\\\"Title\\\":\\\"Pixel-exact rendering of spacetime finite element solutions\\\"},\\\"1142\\\":{\\\"Abstract\\\":\\\"New high-throughput proteomic techniques generate data faster than biologists can analyze it. Hidden within this massive and complex data are answers to basic questions about how cells function. The data afford an opportunity to take a global or systems approach studying whole proteomes comprising all the proteins in an organism. However, the tremendous size and complexity of the high-throughput data make it difficult to process and interpret. Existing tools for studying a few proteins at a time are not suitable for global analysis. Visualization provides powerful analysis capabilities for enormous, complex data at multiple resolutions. We developed a novel interactive visualization tool, PQuad, for the visual analysis of proteins and peptides identified from high-throughput data on biological samples. PQuad depicts the peptides in the context of their source protein and DNA, thereby integrating proteomic and genomic information. A wrapped line metaphor is applied across key resolutions of the data, from a compressed view of an entire chromosome to the actual nucleotide sequence. PQuad provides a difference visualization for comparing peptides from samples prepared under different experimental conditions. We describe the requirements for such a visual analysis tool, the design decisions, and the novel aspects of PQuad.\\\",\\\"Authors\\\":\\\"Havre, S.;Singhal, M.;Payne, D.A.;Webb-Robertson, B.-J.M.\\\",\\\"Clusters\\\":\\\"ComparisonComparativeVisualizationAndSimilarity;FocusContextTechniques;MolecularScienceAndChemistry;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.82\\\",\\\"Keywords\\\":\\\"difference visualization;proteomics;context;differential proteomics;visualization;metaphors\\\",\\\"Keywords_Processed\\\":\\\"visualization;proteomic;differential proteomic;context;metaphor;difference visualization\\\",\\\"Title\\\":\\\"PQuad: visualization of predicted peptides and proteins\\\"},\\\"1143\\\":{\\\"Abstract\\\":\\\"Hardware-accelerated direct volume rendering of unstructured volumetric meshes is often based on tetrahedral cell projection, in particular, the projected tetrahedra (PT) algorithm and its variants. Unfortunately, even implementations of the most advanced variants of the PT algorithm are very prone to rendering artifacts. In this work, we identify linear interpolation in screen coordinates as a cause for significant rendering artifacts and implement the correct perspective interpolation for the PT algorithm with programmable graphics hardware. We also demonstrate how to use features of modern graphics hardware to improve the accuracy of the coloring of individual tetrahedra and the compositing of the resulting colors, in particular, by employing a logarithmic scale for the preintegrated color lookup table, using textures with high color resolution, rendering to floating-point color buffers, and alpha dithering. Combined with a correct visibility ordering, these techniques result in the first implementation of the PT algorithm without objectionable rendering artifacts. Apart from the important improvement in rendering quality, our approach also provides a test bed for different implementations of the PT algorithm that allows us to study the particular rendering artifacts introduced by these variants.\\\",\\\"Authors\\\":\\\"Kraus, M.;Wei Qiao;Ebert, D.S.\\\",\\\"Clusters\\\":\\\"BiologyAndBioinformatics;GpuBasedTechniques;ImageBasedDataImageSignalProcessing;Interpolation;MeshesGridsAndLattices;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.85\\\",\\\"Keywords\\\":\\\"cell projection;volume rendering;dithering;volume visualization;programmable graphics hardware;perspective interpolation;projected tetrahedra\\\",\\\"Keywords_Processed\\\":\\\"volume render;project tetrahedra;programmable graphic hardware;perspective interpolation;dither;volume visualization;cell projection\\\",\\\"Title\\\":\\\"Projecting tetrahedra without rendering artifacts\\\"},\\\"1144\\\":{\\\"Abstract\\\":\\\"We present a novel approach for interactive view-dependent rendering of massive models. Our algorithm combines view-dependent simplification, occlusion culling, and out-of-core rendering. We represent the model as a clustered hierarchy of progressive meshes (CHPM). We use the cluster hierarchy for coarse-grained selective refinement and progressive meshes for fine-grained local refinement. We present an out-of-core algorithm for computation of a CHPM that includes cluster decomposition, hierarchy generation, and simplification. We make use of novel cluster dependencies in preprocess to generate crack-free, drastic simplifications at runtime. The clusters are used for occlusion culling and out-of-core rendering. We add a frame of latency to the rendering pipeline to fetch newly visible clusters from the disk and to avoid stalls. The CHPM reduces the refinement cost for view-dependent rendering by more than an order of magnitude as compared to a vertex hierarchy. We have implemented our algorithm on a desktop PC. We can render massive CAD, isosurface, and scanned models, consisting of tens or a few hundreds of millions of triangles at 10-35 frames per second with little loss in image quality.\\\",\\\"Authors\\\":\\\"Yoon, S.-E.;Salomon, B.;Gayle, R.;Manocha, D.\\\",\\\"Clusters\\\":\\\"DesignMethodologiesAndInteractionDesign;HardwareAccellerationAndComputationGeneral;LevelOfDetail;OcclusionProblemsTechniques;ViewDependentVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.86\\\",\\\"Keywords\\\":\\\"external memory algorithms;level-of-detail;view-dependent rendering;occlusion culling;interactive display\\\",\\\"Keywords_Processed\\\":\\\"occlusion cull;view dependent rendering;external memory algorithm;interactive display;level of detail\\\",\\\"Title\\\":\\\"Quick-VDR: interactive view-dependent rendering of massive models\\\"},\\\"1145\\\":{\\\"Abstract\\\":\\\"We describe a new technique for fitting scattered point cloud data. Given a scattered point cloud of 3D data points and associated normal vectors, our new method produces an implicit volume model whose zero level isosurface interpolates the given points and associated normal vectors. We concentrate on certain application of these new volume modeling techniques. We take existing polygon mesh surfaces and use the present methods to construct implicit volume models for these surfaces. Implicit models allow for the application of Boolean operations on these surfaces through the techniques of constructive solid geometry. Also, standard wavelet and filter operators can be applied to the implicit volume model leading to effective smoothing and filtering algorithms, which are simple to implement.\\\",\\\"Authors\\\":\\\"Nielson, G.M.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;MeshesGridsAndLattices;PointBasedDataAndTechniques;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.87\\\",\\\"Keywords\\\":\\\"isosurface;polygonal meshes;surface reconstruction;point clouds\\\",\\\"Keywords_Processed\\\":\\\"surface reconstruction;point cloud;isosurface;polygonal mesh\\\",\\\"Title\\\":\\\"Radial hermite operators for scattered point cloud data with normal vectors and applications to implicitizing polygon mesh surfaces for generalized CSG operations and smoothing\\\"},\\\"1146\\\":{\\\"Abstract\\\":\\\"We present a tool for real-time visualization of motion features in 2D image sequences. The motion is estimated through an eigenvector analysis of the spatio-temporal structure tensor at every pixel location. This approach is computationally demanding but allows reliable velocity estimates as well as quality indicators for the obtained results. We use a 2D color map and a region of interest selector for the visualization of the velocities. On the selected velocities we apply a hierarchical smoothing scheme which allows the choice of the desired scale of the motion field. We demonstrate several examples of test sequences in which some persons are moving with different velocities than others. These persons are visually marked in the real-time display of the image sequence. The tool is also applied to angiography sequences to emphasize the blood flow and its distribution. An efficient processing of the data streams is achieved by mapping the operations onto the stream architecture of standard graphics cards. The card receives the images and performs both the motion estimation and visualization, taking advantage of the parallelism in the graphics processor and the superior memory bandwidth. The integration of data processing and visualization also saves on unnecessary data transfers and thus allows the real-time analysis of 320240 images. We expect that on the newest generation of graphics hardware our tool could run in real time for the standard VGA format.\\\",\\\"Authors\\\":\\\"Strzodka, R.;Garbe, C.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;InputAndOutputDevicesGeneral;NumericalMethodsMathematics;RealtimeProcessingRenderingAndVisualizationGeneral;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.88\\\",\\\"Keywords\\\":\\\"eigenvector analysis;motion visualization;graphics hardware;motion estimation;realtime processing;structure tensor\\\",\\\"Keywords_Processed\\\":\\\"structure tensor;realtime processing;graphic hardware;motion estimation;motion visualization;eigenvector analysis\\\",\\\"Title\\\":\\\"Real-time motion estimation and visualization on graphics cards\\\"},\\\"1147\\\":{\\\"Abstract\\\":\\\"In many application domains, data is collected and referenced by its geospatial location. Nowadays, different kinds of maps are used to emphasize the spatial distribution of one or more geospatial attributes. The nature of geospatial statistical data is the highly nonuniform distribution in the real world data sets. This has several impacts on the resulting map visualizations. Classical area maps tend to highlight patterns in large areas, which may, however, be of low importance. Cartographers and geographers used cartograms or value-by-area maps to address this problem long before computers were available. Although many automatic techniques have been developed, most of the value-by-area cartograms are generated manually via human interaction. In this paper, we propose a novel visualization technique for geospatial data sets called RecMap. Our technique approximates a rectangular partition of the (rectangular) display area into a number of map regions preserving important geospatial constraints. It is a fully automatic technique with explicit user control over all exploration constraints within the exploration process. Experiments show that our technique produces visualizations of geospatial data sets, which enhance the discovery of global and local correlations, and demonstrate its performance in a variety of applications\\\",\\\"Authors\\\":\\\"Heilmann, R.;Keim, D.A.;Panse, C.;Sips, M.\\\",\\\"Clusters\\\":\\\"DatabasesAndDataMining;GeographyGeospatialVisCartographyTerrainVis;\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.57\\\",\\\"Keywords\\\":\\\"information visualization;database and data mining visualization;geographic visualization\\\",\\\"Keywords_Processed\\\":\\\"geographic visualization;database and datum mining visualization;information visualization\\\",\\\"Title\\\":\\\"RecMap: Rectangular Map Approximations\\\"},\\\"1148\\\":{\\\"Abstract\\\":\\\"Traditional flow volumes construct an explicit geometrical or parametrical representation from the vector field. The geometry is updated interactively and then rendered using an unstructured volume rendering technique. Unless a detailed refinement of the flow volume is specified for the interior, information inside the underlying flow volume is lost in the linear interpolation. These disadvantages can be avoided and/or alleviated using an implicit flow model. An implicit flow is a scalar field constructed such that any point in the field is associated with a termination surface using an advection operator on the flow. We present two techniques, a slice-based three-dimensional texture mapping and an interval volume segmentation coupled with a tetrahedron projection-based renderer, to render implicit stream flows. In the first method, the implicit flow representation is loaded as a 3D texture and manipulated using a dynamic texture operation that allows the flow to be investigated interactively. In our second method, a geometric flow volume is extracted from the implicit flow using a high dimensional isocontouring or interval volume routine. This provides a very detailed flow volume or set of flow volumes that can easily change topology, while retaining accurate characteristics within the flow volume. The advantages and disadvantages of these two techniques are compared with traditional explicit flow volumes.\\\",\\\"Authors\\\":\\\"Xue, D.;Zhang, C.;Crawfis, R.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;InputAndOutputDevicesGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.90\\\",\\\"Keywords\\\":\\\"flow visualization;interval volume rendering;implicit stream flow;graphics hardware\\\",\\\"Keywords_Processed\\\":\\\"interval volume render;implicit stream flow;graphic hardware;flow visualization\\\",\\\"Title\\\":\\\"Rendering implicit flow volumes\\\"},\\\"1149\\\":{\\\"Abstract\\\":\\\"Coloring higher order scientific data is problematic using standard linear methods as found in OpenGL. The visual results are inaccurate when there is a large scalar gradient over an element or when the scalar field is nonlinear. In addition to shading nonlinear data, last and accurate rendering of planar cuts through parametric elements can be implemented using programmable shaders on current graphics hardware. The intersection of a planar cut with geometrically curved volume elements can be rendered using a combination of selective refinement and programmable shaders. This hybrid algorithm also handles curved 2D planar triangles.\\\",\\\"Authors\\\":\\\"Brasher, M.;Haimes, R.\\\",\\\"Clusters\\\":\\\"CuttingPlanes;GpuBasedTechniques;NumericalMethodsMathematics\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.91\\\",\\\"Keywords\\\":\\\"programmable shader;higher-order elements;cut-planes\\\",\\\"Keywords_Processed\\\":\\\"programmable shader;cut plane;high order element\\\",\\\"Title\\\":\\\"Rendering planar cuts through quadratic and cubic finite elements\\\"},\\\"1150\\\":{\\\"Abstract\\\":\\\"We present the novel high-level visualization taxonomy. Our taxonomy classifies visualization algorithms rather than data. Algorithms are categorized based on the assumptions they make about the data being visualized; we call this set of assumptions the design model. Because our taxonomy is based on design models, it is more flexible than existing taxonomies and considers the user's conceptual model, emphasizing the human aspect of visualization. Design models are classified according to whether they are discrete or continuous and by how much the algorithm designer chooses display attributes such as spatialization, timing, colour, and transparency. This novel approach provides an alternative view of the visualization field that helps explain how traditional divisions (e.g., information and scientific visualization) relates and overlap, and that may inspire research ideas in hybrid visualization areas\\\",\\\"Authors\\\":\\\"Tory, M.;Moller, T.\\\",\\\"Clusters\\\":\\\"DesignMethodologiesAndInteractionDesign;SegmentationAndClassification;TasksTaskRequirementsAnalysis;Taxonomies;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.59\\\",\\\"Keywords\\\":\\\"visualization;conceptual model;classification;user model;taxonomy;design model\\\",\\\"Keywords_Processed\\\":\\\"visualization;conceptual model;classification;taxonomy;design model;user model\\\",\\\"Title\\\":\\\"Rethinking Visualization: A High-Level Taxonomy\\\"},\\\"1151\\\":{\\\"Abstract\\\":\\\"We present a new level set method for reconstructing interfaces from point aggregations. Although level-set-based methods are advantageous because they can handle complicated topologies and noisy data, most tend to smooth the inherent roughness of the original data. Our objective is to enhance the quality of a reconstructed surface by preserving certain roughness-related characteristics of the original dataset. Our formulation employs the total variation of the surface as a roughness measure. The algorithm consists of two steps: a roughness-capturing flow and a roughness-preserving flow. The roughness capturing step attempts to construct a surface for which the original roughness is captured - distance flow is well suited for roughness capturing. Surface reconstruction is enhanced by using a total variation preserving (TVP) scheme for the roughness-preserving flow. The shock filter formulation of Osher and Rudin is exploited to achieve this goal. In practice, we have found that better results arc obtained by balancing the TVP term with a smoothing term based on curvature. The algorithm is applied to both fractal surface growth simulations and scanned data sets to demonstrate the efficacy of our approach.\\\",\\\"Authors\\\":\\\"Kim, Y.;Machiraju, R.;Thompson, D.\\\",\\\"Clusters\\\":\\\"DataAcquisitionAndManagement;FilteringTechniques;NumericalMethodsMathematics;PointBasedDataAndTechniques;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.94\\\",\\\"Keywords\\\":\\\"point sampled data;shock filter;total variation preserving;level set method;rough surface;surface reconstruction\\\",\\\"Keywords_Processed\\\":\\\"shock filter;surface reconstruction;total variation preserve;point sample datum;rough surface;level set method\\\",\\\"Title\\\":\\\"Rough interface reconstruction using the level set method\\\"},\\\"1152\\\":{\\\"Abstract\\\":\\\"Quantitative techniques for visualization are critical to the successful analysis of both acquired and simulated scientific data. Many visualization techniques rely on indirect mappings, such as transfer functions, to produce the final imagery. In many situations, it is preferable and more powerful to express these mappings as mathematical expressions, or queries, that can then be directly applied to the data. We present a hardware-accelerated system that provides such capabilities and exploits current graphics hardware for portions of the computational tasks that would otherwise be executed on the CPU. In our approach, the direct programming of the graphics processor using a concise data parallel language, gives scientists the capability to efficiently explore and visualize data sets.\\\",\\\"Authors\\\":\\\"McCormick, P.;Inman, J.;Ahrens, J.;Hansen, C.;Roth, G.\\\",\\\"Clusters\\\":\\\"HardwareAccellerationAndComputationGeneral;MultidimensionalMultivariateMultifieldDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.95\\\",\\\"Keywords\\\":\\\"visualization systems;volume rendering;hardware acceleration;multivariate visualization\\\",\\\"Keywords_Processed\\\":\\\"multivariate visualization;volume render;visualization system;hardware acceleration\\\",\\\"Title\\\":\\\"Scout: a hardware-accelerated system for quantitatively driven visualization and analysis\\\"},\\\"1153\\\":{\\\"Abstract\\\":\\\"The contour tree, an abstraction of a scalar field that encodes the nesting relationships of isosurfaces, can be used to accelerate isosurface extraction, to identify important isovalues for volume-rendering transfer functions, and to guide exploratory visualization through a flexible isosurface interface. Many real-world data sets produce unmanageably large contour trees which require meaningful simplification. We define local geometric measures for individual contours, such as surface area and contained volume, and provide an algorithm to compute these measures in a contour tree. We then use these geometric measures to simplify the contour trees, suppressing minor topological features of the data. We combine this with a flexible isosurface interface to allow users to explore individual contours of a dataset interactively.\\\",\\\"Authors\\\":\\\"Carr, H.;Snoeyink, J.;van de Panne, M.\\\",\\\"Clusters\\\":\\\"IsosurfaceAndSurfaceExtractionTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.96\\\",\\\"Keywords\\\":\\\"contour tree;isosurface;topological simplification\\\",\\\"Keywords_Processed\\\":\\\"contour tree;topological simplification;isosurface\\\",\\\"Title\\\":\\\"Simplifying flexible isosurfaces using local geometric measures\\\"},\\\"1154\\\":{\\\"Abstract\\\":\\\"Current implementations of multidimensional scaling (MDS), an approach that attempts to best represent data point similarity in a low-dimensional representation, are not suited for many of today's large-scale datasets. We propose an extension to the spring model approach that allows the user to interactively explore datasets that are far beyond the scale of previous implementations of MDS. We present MDSteer, a steerable MDS computation engine and visualization tool that progressively computes an MDS layout and handles datasets of over one million points. Our technique employs hierarchical data structures and progressive layouts to allow the user to steer the computation of the algorithm to the interesting areas of the dataset. The algorithm iteratively alternates between a layout stage in which a subselection of points are added to the set of active points affected by the MDS iteration, and a binning stage which increases the depth of the bin hierarchy and organizes the currently unplaced points into separate spatial regions. This binning strategy allows the user to select onscreen regions of the layout to focus the MDS computation into the areas of the dataset that are assigned to the selected bins. We show both real and common synthetic benchmark datasets with dimensionalities ranging from 3 to 300 and cardinalities of over one million points\\\",\\\"Authors\\\":\\\"Williams, M.;Munzner, T.\\\",\\\"Clusters\\\":\\\"DimensionalityReduction\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.60\\\",\\\"Keywords\\\":\\\"dimension reduction;multi-dimensional scaling\\\",\\\"Keywords_Processed\\\":\\\"dimension reduction;multi dimensional scaling\\\",\\\"Title\\\":\\\"Steerable, Progressive Multidimensional Scaling\\\"},\\\"1155\\\":{\\\"Abstract\\\":\\\"Endonasal transsphenoidal pituitary surgery is a minimally invasive endoscopic procedure, applied to remove various kinds of pituitary tumors. To reduce the risk associated with this treatment, the surgeon must be skilled and well-prepared. Virtual endoscopy can be beneficial as a tool for training, preoperative planning and intraoperative support. This work introduces STEPS, a virtual endoscopy system designed to aid surgeons in getting acquainted with the endoscopic view, the handling of instruments, the transsphenoidal approach and challenges associated with the procedure. STEPS also assists experienced surgeons in planning a real endoscopic intervention by getting familiar with the individual patient anatomy, identifying landmarks, planning the approach and deciding upon the ideal target position of the actual surgical activity. Besides interactive visualization using two different first-hit ray casting techniques, the application provides navigation and perception aids and the possibility to simulate the procedure, including haptic feedback and simulation of surgical instruments.\\\",\\\"Authors\\\":\\\"Neubauer, A.;Mroz, L.;Wolfsberger, S.;Wegenkittl, R.;Forster, M.-T.;Buhler, K.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;IsosurfaceAndSurfaceExtractionTechniques;RaytracingRaycasting\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.98\\\",\\\"Keywords\\\":\\\"isosurface;pituitary surgery;virtual endoscopy;raycasting\\\",\\\"Keywords_Processed\\\":\\\"virtual endoscopy;pituitary surgery;isosurface;raycaste\\\",\\\"Title\\\":\\\"STEPS - an application for simulation of transsphenoidal endonasal pituitary surgery\\\"},\\\"1156\\\":{\\\"Abstract\\\":\\\"Topological methods aim at the segmentation of a vector field into areas of different flow behavior. For 2D time-dependent vector fields, two such segmentations are possible: either concerning the behavior of stream lines, or of path lines. While stream line oriented topology is well established, we introduce path line oriented topology as a new visualization approach in this paper. As a contribution to stream line oriented topology we introduce new methods to detect global bifurcations like saddle connections and cyclic fold bifurcations. To get the path line oriented topology we segment the vector field into areas of attracting, repelling and saddle-like behavior of the path lines. We compare both kinds of topologies and apply them to a number of data sets.\\\",\\\"Authors\\\":\\\"Theisel, H.;Weinkauf, T.;Hege, H.-C.;Seidel, H.-P.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;StreamlinesPathlinesStreaklines;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.99\\\",\\\"Keywords\\\":\\\"flow visualization;vector field topology;bifurcations;streamlines;pathlines\\\",\\\"Keywords_Processed\\\":\\\"vector field topology;streamline;pathline;bifurcation;flow visualization\\\",\\\"Title\\\":\\\"Stream line and path line oriented topology for 2D time-dependent vector fields\\\"},\\\"1157\\\":{\\\"Abstract\\\":\\\"We present a novel surface reconstruction algorithm that can recover high-quality surfaces from noisy and defective data sets without any normal or orientation information. A set of new techniques is introduced to afford extra noise tolerability, robust orientation alignment, reliable outlier removal, and satisfactory feature recovery. In our algorithm, sample points are first organized by an octree. The points are then clustered into a set of monolithically singly-oriented groups. The inside/outside orientation of each group is determined through a robust voting algorithm. We locally fit an implicit quadric surface in each octree cell. The locally fitted implicit surfaces are then blended to produce a signed distance field using the modified Shepard's method. We develop sophisticated iterative fitting algorithms to afford improved noise tolerance both in topology recognition and geometry accuracy. Furthermore, this iterative fitting algorithm, coupled with a local model selection scheme, provides a reliable sharp feature recovery mechanism even in the presence of bad input.\\\",\\\"Authors\\\":\\\"Xie, H.;McDonnell, K.T.;Hong Qin\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;GeometricModeling;Interpolation;SurfaceRelatedDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.101\\\",\\\"Keywords\\\":\\\"computer graphics;modified shepard's method;mpu implicits;surface representation;surface reconstruction\\\",\\\"Keywords_Processed\\\":\\\"computer graphic;modify shepard method;surface representation;surface reconstruction;mpu implicit\\\",\\\"Title\\\":\\\"Surface reconstruction of noisy and defective data sets\\\"},\\\"1158\\\":{\\\"Abstract\\\":\\\"We present a novel approach to interactive visualization and exploration of large unstructured tetrahedral meshes. These massive 3D meshes are used in mission-critical CFD and structural mechanics simulations, and typically sample multiple field values on several millions of unstructured grid points. Our method relies on the preprocessing of the tetrahedral mesh to partition it into nonconvex boundaries and internal fragments that are subsequently encoded into compressed multiresolution data representations. These compact hierarchical data structures are then adaptively rendered and probed in real-time on a commodity PC. Our point-based rendering algorithm, which is inspired by QSplat, employs a simple but highly efficient splatting technique that guarantees interactive frame-rates regardless of the size of the input mesh and the available rendering hardware. It furthermore allows for real-time probing of the volumetric data-set through constructive solid geometry operations as well as interactive editing of color transfer functions for an arbitrary number of field values. Thus, the presented visualization technique allows end-users for the first time to interactively render and explore very large unstructured tetrahedral meshes on relatively inexpensive hardware.\\\",\\\"Authors\\\":\\\"Museth, K.;Lombeyda, S.\\\",\\\"Clusters\\\":\\\"GeometricModeling;MeshesGridsAndLattices;PointBasedDataAndTechniques;RealtimeProcessingRenderingAndVisualizationGeneral;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.102\\\",\\\"Keywords\\\":\\\"tetrahedral meshes;realtime visualization;large volumetric data;point-based rendering;constructive solid geometry\\\",\\\"Keywords_Processed\\\":\\\"constructive solid geometry;tetrahedral mesh;large volumetric datum;point base render;realtime visualization\\\",\\\"Title\\\":\\\"TetSplat: real-time rendering and volume clipping of large unstructured tetrahedral meshes\\\"},\\\"1159\\\":{\\\"Abstract\\\":\\\"While molecular visualization software has advanced over the years, today, most tools still operate on individual molecular structures with limited facility to manipulate large multicomponent complexes. We approach this problem by extending 3D image-based rendering via programmable graphics units, resulting in an order of magnitude speedup over traditional triangle-based rendering. By incorporating a biochemically sensitive level-of-detail hierarchy into our molecular representation, we communicate appropriate volume occupancy and shape while dramatically reducing the visual clutter that normally inhibits higher-level spatial comprehension. Our hierarchical, image based rendering also allows dynamically computed physical properties data (e.g. electrostatics potential) to be mapped onto the molecular surface, tying molecular structure to molecular function. Finally, we present another approach to interactive molecular exploration using volumetric and structural rendering in tandem to discover molecular properties that neither rendering mode alone could reveal. These visualization techniques are realized in a high-performance, interactive molecular exploration tool we call TexMol, short for Texture Molecular viewer.\\\",\\\"Authors\\\":\\\"Bajaj, C.L.;Djeu, P.;Siddavanahalli, V.;Thane, A.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;GpuBasedTechniques;HierarchicalTreeDataAndTechniques;ImageBasedDataImageSignalProcessing;LevelOfDetail;MolecularScienceAndChemistry;MultipleLinkedCoordinatedViews;MultiresolutionTechniques;Rendering;Textures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.103\\\",\\\"Keywords\\\":\\\"imposter rendering;volume rendering;hierarchy;molecular visualization;multi-resolution;level-of-detail;computer graphics;texture-based rendering;image-based rendering;synchronous view;programmable graphics hardware\\\",\\\"Keywords_Processed\\\":\\\"image base render;volume render;synchronous view;computer graphic;hierarchy;multi resolution;programmable graphic hardware;molecular visualization;imposter render;level of detail;texture base render\\\",\\\"Title\\\":\\\"TexMol: interactive visual exploration of large flexible multi-component molecular complexes\\\"},\\\"1160\\\":{\\\"Abstract\\\":\\\"This article presents the InfoVis toolkit, designed to support the creation, extension and integration of advanced 2D information visualization components into interactive Java swing applications. The InfoVis toolkit provides specific data structures to achieve a fast action/feedback loop required by dynamic queries. It comes with a large set of components such as range sliders and tailored control panels required to control and configure the visualizations. These components are integrated into a coherent framework that simplifies the management of rich data structures and the design and extension of visualizations. Supported data structures currently include tables, trees and graphs. Supported visualizations include scatter plots, time series, parallel coordinates, treemaps, icicle trees, node-link diagrams for trees and graphs and adjacency matrices for graphs. All visualizations can use fisheye lenses and dynamic labeling. The InfoVis toolkit supports hardware acceleration when available through Agile2D, an implementation of the Java graphics API based on OpenGL, achieving speedups of 10 to 200 times. The article also shows how new visualizations can be added and extended to become components, enriching visualizations as well as general applications\\\",\\\"Authors\\\":\\\"Fekete, J.\\\",\\\"Clusters\\\":\\\"ComputerGraphicsTechniquesGeneral;VisualizationSystemsToolkitsAndEnvironments\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.64\\\",\\\"Keywords\\\":\\\"information visualization;integration;toolkits;graphics\\\",\\\"Keywords_Processed\\\":\\\"graphic;toolkit;integration;information visualization\\\",\\\"Title\\\":\\\"The InfoVis Toolkit\\\"},\\\"1161\\\":{\\\"Abstract\\\":\\\"Accurate and reliable visualization of blood vessels is still a challenging problem, notably in the presence of morphologic changes resulting from atherosclerotic diseases. We take advantage of partially segmented data with approximately identified vessel centerlines to comprehensively visualize the diseased peripheral arterial tree. We introduce the VesselGlyph as an abstract notation for novel focus & context visualization techniques of tubular structures such as contrast-medium enhanced arteries in CT-angiography (CTA). The proposed techniques combine direct volume rendering (DVR) and curved planar reformation (CPR) within a single image. The VesselGlyph consists of several regions where different rendering methods are used. The region type, the used visualization method and the region parameters depend on the distance from the vessel centerline and on viewing parameters as well. By selecting proper rendering techniques for different regions, vessels are depicted in a naturally looking and undistorted anatomic context. This may facilitate the diagnosis and treatment planning of patients with peripheral arterial occlusive disease. In this paper we furthermore present a way of how to implement the proposed techniques in software and by means of modern 3D graphics accelerators.\\\",\\\"Authors\\\":\\\"Straka, M.;Cervenansky, M.;La Cruz, A.;Kochl, A.;Sramek, M.;Groller, E.;Fleischmann, D.\\\",\\\"Clusters\\\":\\\"BiomedicalScienceAndMedicine;DimensionalityReduction;FocusContextTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.104\\\",\\\"Keywords\\\":\\\"direct volume rendering;vessel visualization;curved planar reformation;focus+context technique\\\",\\\"Keywords_Processed\\\":\\\"curve planar reformation;vessel visualization;focus context technique;direct volume render\\\",\\\"Title\\\":\\\"The VesselGlyph: focus & context visualization in CT-angiography\\\"},\\\"1162\\\":{\\\"Abstract\\\":\\\"This research demonstrates how principles of self-organization and behavior simulation can be used to represent dynamic data evolutions by extending the concept of information flocking, originally introduced by Proctor & Winter (1998), to time-varying datasets. A rule-based behavior system continuously controls and updates the dynamic actions of individual, three-dimensional elements that represent the changing data values of reoccurring data objects. As a result, different distinguishable motion types emerge that are driven by local interactions between the spatial elements as well as the evolution of time-varying data values. Notably, this representation technique focuses on the representation of dynamic data alteration characteristics, or how reoccurring data objects change over time, instead of depicting the exact data values themselves. In addition, it demonstrates the potential of motion as a useful information visualization cue. The original information flocking approach is extended to incorporate time-varying datasets, live database querying, continuous data streaming, real-time data similarity evaluation, automatic shape generation and more stable flocking algorithms. Different experiments prove that information flocking is capable of representing short-term events as well as long-term temporal data evolutions of both individual and groups of time-dependent data objects. An historical stock market quote price dataset is used to demonstrate the algorithms and principles of time-varying information flocking\\\",\\\"Authors\\\":\\\"Moere, A.V.\\\",\\\"Clusters\\\":\\\"AnimationAndMotion;ApplicationsGeneralAndOther;Simulation;TimeseriesTimeVaryingDataAndTechniques;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.65\\\",\\\"Keywords\\\":\\\"boids;time-varying information visualization;artificial life;motion;3d information visualization\\\",\\\"Keywords_Processed\\\":\\\"artificial life;time vary information visualization;motion;boid;3d information visualization\\\",\\\"Title\\\":\\\"Time-Varying Data Visualization Using Information Flocking Boids\\\"},\\\"1163\\\":{\\\"Abstract\\\":\\\"Graph drawing is a basic visualization tool. For graphs of up to hundreds of nodes and edges, there are many effective techniques available. At greater scale, data density and occlusion problems often negate its effectiveness. Conventional pan-and-zoom, and multiscale and geometric fisheye views are not fully satisfactory solutions to this problem. As an alternative, we describe a topological zooming method. It is based on the precomputation of a hierarchy of coarsened graphs, which are combined on the fly into renderings with the level of detail dependent on the distance from one or more foci. We also discuss a related distortion method that allows our technique to achieve constant information density displays\\\",\\\"Authors\\\":\\\"Gansner, E.;Koren, Y.;North, S.C.\\\",\\\"Clusters\\\":\\\"FocusContextTechniques;GraphNetworkDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.66\\\",\\\"Keywords\\\":\\\"topological fisheye;large graph visualization\\\",\\\"Keywords_Processed\\\":\\\"large graph visualization;topological fisheye\\\",\\\"Title\\\":\\\"Topological Fisheye Views for Visualizing Large Graphs\\\"},\\\"1164\\\":{\\\"Abstract\\\":\\\"Visualization of 3D tensor fields continues to be a major challenge in terms of providing intuitive and uncluttered images that allow the users to better understand their data. The primary focus of this paper is on finding a formulation that lends itself to a stable numerical algorithm for extracting stable and persistent topological features from 2nd order real symmetric 3D tensors. While features in 2D tensors can be identified as either wedge or trisector points, in 3D, the corresponding stable features are lines, not just points. These topological feature lines provide a compact representation of the 3D tensor field and are essential in helping scientists and engineers understand their complex nature. Existing techniques work by finding degenerate points and are not numerically stable, and worse, produce both false positive and false negative feature points. This work seeks to address this problem with a robust algorithm that can extract these features in a numerically stable, accurate, and complete manner.\\\",\\\"Authors\\\":\\\"Zheng, X.;Pang, A.\\\",\\\"Clusters\\\":\\\"StreamlinesPathlinesStreaklines;TensorDataAndTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.105\\\",\\\"Keywords\\\":\\\"hyperstreamlines;degenerate tensors;tensor topology;real symmetric tensors;topological line\\\",\\\"Keywords_Processed\\\":\\\"hyperstreamline;real symmetric tensor;tensor topology;topological line;degenerate tensor\\\",\\\"Title\\\":\\\"Topological lines in 3D tensor fields\\\"},\\\"1165\\\":{\\\"Abstract\\\":\\\"An ideal visualization tool that has not been used before in studying the optical behavior of near-field apertures is three-dimensional vector field topology. The global view of the vector field structure is deduced by locating singularities (critical points) within the field and augmenting these points with nearby streamlines. We have used for the first time, to the best of our knowledge, three-dimensional topology to analyze the topological differences between a resonant C-shaped nano-aperture and various nonresonant conventional apertures. The topological differences between these apertures are related to the superiority in power throughput of the C-aperture versus conventional round and square sub-wavelength apertures. We demonstrate how topological visualization techniques provide significant insight into the energy enhancement mechanism of the C aperture, and also shed light on critical issues related to the interaction between multiple apertures located in close proximity to each other, which gives rise to cross-talk, for example as a function of distance. Topological techniques allow us to develop design rules for the geometry of these apertures and their desired spot sizes and brightness. The performance of various sub-wavelength apertures can also be compared quantitatively based on their topology. Since topological methods are generically applicable to tensor and vector fields, our approach can be readily extended to provide insight into the broader category of finite-difference-time-domain nano-photonics and nano-science problems.\\\",\\\"Authors\\\":\\\"Sun, L.;Batra, R.;Xiaolei Shi;Hesselink, L.\\\",\\\"Clusters\\\":\\\"Microscopy;NumericalMethodsMathematics;TopologyBasedTechniques;VectorFieldsDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.106\\\",\\\"Keywords\\\":\\\"vector field visualization;c-aperture;finite-difference-time-domain (fdtd);energy flow topology\\\",\\\"Keywords_Processed\\\":\\\"energy flow topology;aperture;finite difference time domain fdtd;vector field visualization\\\",\\\"Title\\\":\\\"Topology visualization of the optical power flow through a novel C-shaped nano-aperture\\\"},\\\"1166\\\":{\\\"Abstract\\\":\\\"We present an approach for monitoring the positions of vector field singularities and related structural changes in time-dependent datasets. The concept of singularity index is discussed and extended from the well-understood planar case to the more intricate three-dimensional setting. Assuming a tetrahedral grid with linear interpolation in space and time, vector field singularities obey rules imposed by fundamental invariants (Poincare index), which we use as a basis for an efficient tracking algorithm. We apply the presented algorithm to CFD datasets to illustrate its purpose. We examine structures that exhibit topological variations with time and describe some of the insight gained with our method. Examples are given that show a correlation in the evolution of physical quantities that play a role in vortex breakdown.\\\",\\\"Authors\\\":\\\"Garth, C.;Tricoche, X.;Scheuermann, G.\\\",\\\"Clusters\\\":\\\"FlowVisualizationDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques;TopologyBasedTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.107\\\",\\\"Keywords\\\":\\\"flow visualization;vortex breakdown;time-dependent data;topology tracking\\\",\\\"Keywords_Processed\\\":\\\"topology tracking;vortex breakdown;time dependent datum;flow visualization\\\",\\\"Title\\\":\\\"Tracking of vector field singularities in unstructured 3D time-dependent datasets\\\"},\\\"1167\\\":{\\\"Abstract\\\":\\\"The one-to-one strategy of mapping each single data item into a graphical marker adopted in many visualization techniques has limited usefulness when the number of records and/or the dimensionality of the data set are very high. In this situation, the strong overlapping of graphical markers severely hampers the user's ability to identify patterns in the data from its visual representation. We tackle this problem here with a strategy that computes frequency or density information from the data set, and uses such information in parallel coordinates visualizations to filter out the information to be presented to the user, thus reducing visual clutter and allowing the analyst to observe relevant patterns in the data. The algorithms to construct such visualizations, and the interaction mechanisms supported, inspired by traditional image processing techniques such as grayscale manipulation and thresholding are also presented. We also illustrate how such algorithms can assist users to effectively identify clusters in very noisy large data sets\\\",\\\"Authors\\\":\\\"Artero, A.O.;de Oliveira, M.C.F.;Levkowitz, H.\\\",\\\"Clusters\\\":\\\"DataClusteringAndAggregation;DatabasesAndDataMining;VisualizationTechniquesAndToolsGeneral\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.68\\\",\\\"Keywords\\\":\\\"information visualization;visual data mining;density-based visualization;visual clustering\\\",\\\"Keywords_Processed\\\":\\\"density base visualization;visual clustering;information visualization;visual datum mining\\\",\\\"Title\\\":\\\"Uncovering Clusters in Crowded Parallel Coordinates Visualizations\\\"},\\\"1168\\\":{\\\"Abstract\\\":\\\"This paper describes a comparative experiment with five well-known tree visualization systems, and Windows Explorer as a baseline system. Subjects performed tasks relating to the structure of a directory hierarchy, and to attributes of files and directories. Task completion times, correctness and user satisfaction were measured, and video recordings of subjects' interaction with the systems were made. Significant system and task type effects and an interaction between system and task type were found. Qualitative analyses of the video recordings were thereupon conducted to determine reasons for the observed differences, resulting in several findings and design recommendations as well as implications for future experiments with tree visualization systems\\\",\\\"Authors\\\":\\\"Kobsa, A.\\\",\\\"Clusters\\\":\\\"EvaluationGeneral;EvaluationMetricsAndBenchmarks;InteractionTechniquesGeneral;TasksTaskRequirementsAnalysis;VisualDesignDesignGuidelines\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.70\\\",\\\"Keywords\\\":\\\"user interaction;information visualization;experimental comparison;task performance;user satisfaction;design recommendations;accuracy\\\",\\\"Keywords_Processed\\\":\\\"user interaction;design recommendation;information visualization;user satisfaction;experimental comparison;accuracy;task performance\\\",\\\"Title\\\":\\\"User Experiments with Tree Visualization Systems\\\"},\\\"1169\\\":{\\\"Abstract\\\":\\\"Traditional multidimensional visualization techniques, such as glyphs, parallel coordinates and scatterplot matrices, suffer from clutter at the display level and difficult user navigation among dimensions when visualizing high dimensional datasets. In this paper, we propose a new multidimensional visualization technique named a value and relation (VaR) display, together with a rich set of navigation and selection tools, for interactive exploration of datasets with up to hundreds of dimensions. By explicitly conveying the relationships among the dimensions of a high dimensional dataset, the VaR display helps users grasp the associations among dimensions. By using pixel-oriented techniques to present values of the data items in a condensed manner, the VaR display reveals data patterns in the dataset using as little screen space as possible. The navigation and selection tools enable users to interactively reduce clutter, navigate within the dimension space, and examine data value details within context effectively and efficiently. The VaR display scales well to datasets with large numbers of data items by employing sampling and texture mapping. A case study on a real dataset, as well as the VaR displays of multiple real datasets throughout the paper, reveals how our proposed approach helps users interactively explore high dimensional datasets with large numbers of data items\\\",\\\"Authors\\\":\\\"Jing Yang;Anilkumar Patro;Huang Shiping;Nishant Mehta;Ward, M.O.;Rundensteiner, E.A.\\\",\\\"Clusters\\\":\\\"DimensionalityReduction;MultidimensionalMultivariateMultifieldDataAndTechniques;PixelOrientedEncodings\\\",\\\"DOI\\\":\\\"10.1109/INFVIS.2004.71\\\",\\\"Keywords\\\":\\\"pixel-oriented techniques;multi-dimensional scaling;high-dimensional data;multi-dimensional visualization\\\",\\\"Keywords_Processed\\\":\\\"high dimensional datum;pixel orient technique;multi dimensional scaling;multi dimensional visualization\\\",\\\"Title\\\":\\\"Value and Relation Display for Interactive Exploration of High Dimensional Datasets\\\"},\\\"1170\\\":{\\\"Abstract\\\":\\\"Typically there is a high coherence in data values between neighboring time steps in an iterative scientific software simulation; this characteristic similarly contributes to a corresponding coherence in the visibility of volume blocks when these consecutive time steps are rendered. Yet traditional visibility culling algorithms were mainly designed for static data, without consideration of such potential temporal coherency. We explore the use of temporal occlusion coherence (TOC) to accelerate visibility culling for time-varying volume rendering. In our algorithm, the opacity of volume blocks is encoded by means of plenoptic opacity functions (POFs). A coherence-based block fusion technique is employed to coalesce time-coherent data blocks over a span of time steps into a single, representative block. Then POFs need only be computed for these representative blocks. To quickly determine the subvolumes that do not require updates in their visibility status for each subsequent time step, a hierarchical \\\\\\\"TOC tree\\\\\\\" data structure is constructed to store the spans of coherent time steps. To achieve maximal culling potential, while remaining conservative, we have extended our previous POP into an optimized POP (OPOP) encoding scheme for this specific scenario. To test our general TOC and OPOF approach, we have designed a parallel time-varying volume rendering algorithm accelerated by visibility culling. Results from experimental runs on a 32-processor cluster confirm both the effectiveness and scalability of our approach.\\\",\\\"Authors\\\":\\\"Gao, J.;Han-Wei Shen;Huang, J.;Kohl, J.A.\\\",\\\"Clusters\\\":\\\"CamerasCameraViewsAndProjections;ColorColorPerception;LargeScaleDataAndScalability;TimeseriesTimeVaryingDataAndTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.110\\\",\\\"Keywords\\\":\\\"volume rendering;large data visualization;visibility culling;time-varying visualization;plenoptic opacity function\\\",\\\"Keywords_Processed\\\":\\\"volume render;large datum visualization;visibility cull;plenoptic opacity function;time vary visualization\\\",\\\"Title\\\":\\\"Visibility culling for time-varying volume rendering using temporal occlusion coherence\\\"},\\\"1171\\\":{\\\"Abstract\\\":\\\"Grid computing provides a challenge for visualization system designers. In this research, we evolve the dataflow concept to allow parts of the visualization process to be executed remotely in a secure and seamless manner. We see dataflow at three levels: an abstract specification of the intent of the visualization; a binding of these abstract modules to a specific software system; and then a binding of software to processing and other resources. We develop an XML application capable of describing visualization at the three levels. To complement this, we have implemented an extension to a popular visualization system, IRIS Explorer, which allows modules in a dataflow pipeline to run on a set of grid resources. For computational steering applications, we have developed a library that allows a visualization system front-end to connect to a simulation running remotely on a grid resource. We demonstrate the work in two applications: the dispersion of a pollutant under different wind conditions; and the solution of a challenging numerical problem in elastohydrodynamic lubrication.\\\",\\\"Authors\\\":\\\"Brodlie, K.;Duce, D.;Gallop, J.;Sagar, M.;Walton, J.;Wood, J.\\\",\\\"Clusters\\\":\\\"DistributedSystemsAndGridEnvironments;ProgrammingAlgorithmsAndDataStructures;Simulation;VisualizationSystemsToolkitsAndEnvironments;VisualizationTheoryModelsAndMethods\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.112\\\",\\\"Keywords\\\":\\\"visualization systems;xml;visualization reference models;computational steering;grid computing\\\",\\\"Keywords_Processed\\\":\\\"computational steering;visualization reference model;visualization system;grid computing;xml\\\",\\\"Title\\\":\\\"Visualization in grid computing environments\\\"},\\\"1172\\\":{\\\"Abstract\\\":\\\"Vortex breakdowns and flow recirculation are essential phenomena in aeronautics where they appear as a limiting factor in the design of modern aircrafts. Because of the inherent intricacy of these features, standard flow visualization techniques typically yield cluttered depictions. The paper addresses the challenges raised by the visual exploration and validation of two CFD simulations involving vortex breakdown. To permit accurate and insightful visualization we propose a new approach that unfolds the geometry of the breakdown region by letting a plane travel through the structure along a curve. We track the continuous evolution of the associated projected vector field using the theoretical framework of parametric topology. To improve the understanding of the spatial relationship between the resulting curves and lines we use direct volume rendering and multidimensional transfer functions for the display of flow-derived scalar quantities. This enriches the visualization and provides an intuitive context for the extracted topological information. Our results offer clear, synthetic depictions that permit new insight into the structural properties of vortex breakdowns.\\\",\\\"Authors\\\":\\\"Tricoche, X.;Garth, C.;Kindlmann, G.;Deines, E.;Scheuermann, G.;Ruetten, M.;Hansen, C.\\\",\\\"Clusters\\\":\\\"CuttingPlanes;FlowVisualizationDataAndTechniques;TopologyBasedTechniques;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.113\\\",\\\"Keywords\\\":\\\"flow visualization;parametric topology;volume rendering;cutting planes;vortex analysis\\\",\\\"Keywords_Processed\\\":\\\"volume render;cut plane;vortex analysis;parametric topology;flow visualization\\\",\\\"Title\\\":\\\"Visualization of intricate flow structures for vortex breakdown analysis\\\"},\\\"1173\\\":{\\\"Abstract\\\":\\\"An important challenge encountered during post-processing of finite element analyses is the visualizing of three-dimensional fields of real-valued second-order tensors. Namely, as finite element meshes become more complex and detailed, evaluation and presentation of the principal stresses becomes correspondingly problematic. In this paper, we describe techniques used to visualize simulations of perturbed in-situ stress fields associated with hypothetical salt bodies in the Gulf of Mexico. We present an adaptation of the Mohr diagram, a graphical paper and pencil method used by the material mechanics community for estimating coordinate transformations for stress tensors, as a new tensor glyph for dynamically exploring tensor variables within three-dimensional finite element models. This interactive glyph can be used as either a probe or a filter through brushing and linking.\\\",\\\"Authors\\\":\\\"Crossno, P.;Rogers, D.H.;Brannon, R.;Coblentz, D.\\\",\\\"Clusters\\\":\\\"ProgrammingAlgorithmsAndDataStructures;Simulation;TensorDataAndTechniques\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.115\\\",\\\"Keywords\\\":\\\"finite element codes and simulations;visual debugging;mohr's circles;tensor field visualization\\\",\\\"Keywords_Processed\\\":\\\"finite element code and simulation;tensor field visualization;mohr circle;visual debugging\\\",\\\"Title\\\":\\\"Visualization of salt-induced stress perturbations\\\"},\\\"1174\\\":{\\\"Abstract\\\":\\\"We present a system for enhancing observation of user interactions in virtual environments. In particular, we focus on analyzing behavior patterns in the popular team-based first-person perspective game Return to Castle Wolfenstein: Enemy Territory. This game belongs to a genre characterized by two moderate-sized teams (usually 6 to 12 players each) competing over a set of objectives. Our system allows spectators to visualize global features such as large-scale behaviors and team strategies, as opposed to the limited, local view that traditional spectating modes provide. We also add overlay visualizations of semantic information related to the action that might be important to a spectator in order to reduce the information overload that plagues traditional overview visualizations. These overlays can visualize information about abstract concepts such as player distribution over time and areas of intense combat activity, and also highlight important features like player paths, fire coverage, etc. This added information allows spectators to identify important game events more easily and reveals large-scale player behaviors that might otherwise be overlooked.\\\",\\\"Authors\\\":\\\"Hoobler, N.;Humphreys, G.;Agrawala, M.\\\",\\\"Clusters\\\":\\\"ApplicationsGeneralAndOther;\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.120\\\",\\\"Keywords\\\":\\\"visualization;spectating;games\\\",\\\"Keywords_Processed\\\":\\\"visualization;game;spectate\\\",\\\"Title\\\":\\\"Visualizing competitive behaviors in multi-user virtual environments\\\"},\\\"1175\\\":{\\\"Abstract\\\":\\\"Waves are a fundamental mechanism for conveying information in many physical problems. Direct visualization techniques are often used to display wave fronts. However, the information derived from such visualizations may not be as central to an investigation as an understanding of how the location, structure and time course of the wave change as key experimental parameters are varied. In experimental data, these questions are confounded by noise and incomplete data. Recognition of waves in networks of neurons is additionally complicated by the presence of long-range physical connections and recurrent excitation. This work applies visual techniques to analyze the structural details of waves in response data from the turtle visual cortex. We emphasize low-cost visualizations that allow comparisons across neural data sets and variables to reconstruct the choreography for a complex response.\\\",\\\"Authors\\\":\\\"Robbins, K.A.;Robinson, M.;Senseman, D.M.\\\",\\\"Clusters\\\":\\\"DimensionalityReduction;FlowVisualizationDataAndTechniques;InformationTheory;MachineLearningAndStatistics;PhysicsAndPhysicalSciences\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.121\\\",\\\"Keywords\\\":\\\"flow visualization;wave subspaces;kullback-leibler decomposition;neural networks;waves;principal component analysis\\\",\\\"Keywords_Processed\\\":\\\"wave subspace;wave;principal component analysis;neural network;kullback leibler decomposition;flow visualization\\\",\\\"Title\\\":\\\"Visualizing cortical waves and timing from data\\\"},\\\"1176\\\":{\\\"Abstract\\\":\\\"The continuing advancement of plasma science is central to realizing fusion as an inexpensive and safe energy source. Gryokinetic simulations of plasmas are fundamental to the understanding of turbulent transport in fusion plasma. This work discusses the visualization challenges presented by gyrokinetic simulations using magnetic field line following coordinates, and presents an effective solution exploiting programmable graphics hardware to enable interactive volume visualization of 3D plasma flow on a toroidal coordinate system. The new visualization capability can help scientists better understand three-dimensional structures of the modeled phenomena. Both the limitations and future promise of the hardware-accelerated approach are also discussed.\\\",\\\"Authors\\\":\\\"Crawford, D.;Kwan-Liu Ma;Min-Yu Huang;Klasky, S.;Ethier, S.\\\",\\\"Clusters\\\":\\\"InputAndOutputDevicesGeneral;MeshesGridsAndLattices;PhysicsAndPhysicalSciences;Textures;VolumeRenderingModelingAndVisualization\\\",\\\"DOI\\\":\\\"10.1109/VISUAL.2004.122\\\",\\\"Keywords\\\":\\\"plasma physics;graphics hardware;scientific visualization;texture methods;non-rectilinear mesh;volume visualization\\\",\\\"Keywords_Processed\\\":\\\"plasma physics;graphic hardware;volume visualization;scientific visualization;non rectilinear mesh;texture method\\\",\\\"Title\\\":\\\"Visualizing gyrokinetic simulations\\\"}}\");//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoiLi9kYXRhc2V0cy9vbGRfZGF0YS5qc29uLmpzIiwic291cmNlcyI6W10sIm1hcHBpbmdzIjoiIiwic291cmNlUm9vdCI6IiJ9\n//# sourceURL=webpack-internal:///./datasets/old_data.json\n");

/***/ }),

/***/ "./node_modules/moment/locale sync recursive ^\\.\\/.*$":
/*!**************************************************!*\
  !*** ./node_modules/moment/locale sync ^\.\/.*$ ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var map = {\n\t\"./af\": \"./node_modules/moment/locale/af.js\",\n\t\"./af.js\": \"./node_modules/moment/locale/af.js\",\n\t\"./ar\": \"./node_modules/moment/locale/ar.js\",\n\t\"./ar-dz\": \"./node_modules/moment/locale/ar-dz.js\",\n\t\"./ar-dz.js\": \"./node_modules/moment/locale/ar-dz.js\",\n\t\"./ar-kw\": \"./node_modules/moment/locale/ar-kw.js\",\n\t\"./ar-kw.js\": \"./node_modules/moment/locale/ar-kw.js\",\n\t\"./ar-ly\": \"./node_modules/moment/locale/ar-ly.js\",\n\t\"./ar-ly.js\": \"./node_modules/moment/locale/ar-ly.js\",\n\t\"./ar-ma\": \"./node_modules/moment/locale/ar-ma.js\",\n\t\"./ar-ma.js\": \"./node_modules/moment/locale/ar-ma.js\",\n\t\"./ar-sa\": \"./node_modules/moment/locale/ar-sa.js\",\n\t\"./ar-sa.js\": \"./node_modules/moment/locale/ar-sa.js\",\n\t\"./ar-tn\": \"./node_modules/moment/locale/ar-tn.js\",\n\t\"./ar-tn.js\": \"./node_modules/moment/locale/ar-tn.js\",\n\t\"./ar.js\": \"./node_modules/moment/locale/ar.js\",\n\t\"./az\": \"./node_modules/moment/locale/az.js\",\n\t\"./az.js\": \"./node_modules/moment/locale/az.js\",\n\t\"./be\": \"./node_modules/moment/locale/be.js\",\n\t\"./be.js\": \"./node_modules/moment/locale/be.js\",\n\t\"./bg\": \"./node_modules/moment/locale/bg.js\",\n\t\"./bg.js\": \"./node_modules/moment/locale/bg.js\",\n\t\"./bm\": \"./node_modules/moment/locale/bm.js\",\n\t\"./bm.js\": \"./node_modules/moment/locale/bm.js\",\n\t\"./bn\": \"./node_modules/moment/locale/bn.js\",\n\t\"./bn.js\": \"./node_modules/moment/locale/bn.js\",\n\t\"./bo\": \"./node_modules/moment/locale/bo.js\",\n\t\"./bo.js\": \"./node_modules/moment/locale/bo.js\",\n\t\"./br\": \"./node_modules/moment/locale/br.js\",\n\t\"./br.js\": \"./node_modules/moment/locale/br.js\",\n\t\"./bs\": \"./node_modules/moment/locale/bs.js\",\n\t\"./bs.js\": \"./node_modules/moment/locale/bs.js\",\n\t\"./ca\": \"./node_modules/moment/locale/ca.js\",\n\t\"./ca.js\": \"./node_modules/moment/locale/ca.js\",\n\t\"./cs\": \"./node_modules/moment/locale/cs.js\",\n\t\"./cs.js\": \"./node_modules/moment/locale/cs.js\",\n\t\"./cv\": \"./node_modules/moment/locale/cv.js\",\n\t\"./cv.js\": \"./node_modules/moment/locale/cv.js\",\n\t\"./cy\": \"./node_modules/moment/locale/cy.js\",\n\t\"./cy.js\": \"./node_modules/moment/locale/cy.js\",\n\t\"./da\": \"./node_modules/moment/locale/da.js\",\n\t\"./da.js\": \"./node_modules/moment/locale/da.js\",\n\t\"./de\": \"./node_modules/moment/locale/de.js\",\n\t\"./de-at\": \"./node_modules/moment/locale/de-at.js\",\n\t\"./de-at.js\": \"./node_modules/moment/locale/de-at.js\",\n\t\"./de-ch\": \"./node_modules/moment/locale/de-ch.js\",\n\t\"./de-ch.js\": \"./node_modules/moment/locale/de-ch.js\",\n\t\"./de.js\": \"./node_modules/moment/locale/de.js\",\n\t\"./dv\": \"./node_modules/moment/locale/dv.js\",\n\t\"./dv.js\": \"./node_modules/moment/locale/dv.js\",\n\t\"./el\": \"./node_modules/moment/locale/el.js\",\n\t\"./el.js\": \"./node_modules/moment/locale/el.js\",\n\t\"./en-SG\": \"./node_modules/moment/locale/en-SG.js\",\n\t\"./en-SG.js\": \"./node_modules/moment/locale/en-SG.js\",\n\t\"./en-au\": \"./node_modules/moment/locale/en-au.js\",\n\t\"./en-au.js\": \"./node_modules/moment/locale/en-au.js\",\n\t\"./en-ca\": \"./node_modules/moment/locale/en-ca.js\",\n\t\"./en-ca.js\": \"./node_modules/moment/locale/en-ca.js\",\n\t\"./en-gb\": \"./node_modules/moment/locale/en-gb.js\",\n\t\"./en-gb.js\": \"./node_modules/moment/locale/en-gb.js\",\n\t\"./en-ie\": \"./node_modules/moment/locale/en-ie.js\",\n\t\"./en-ie.js\": \"./node_modules/moment/locale/en-ie.js\",\n\t\"./en-il\": \"./node_modules/moment/locale/en-il.js\",\n\t\"./en-il.js\": \"./node_modules/moment/locale/en-il.js\",\n\t\"./en-nz\": \"./node_modules/moment/locale/en-nz.js\",\n\t\"./en-nz.js\": \"./node_modules/moment/locale/en-nz.js\",\n\t\"./eo\": \"./node_modules/moment/locale/eo.js\",\n\t\"./eo.js\": \"./node_modules/moment/locale/eo.js\",\n\t\"./es\": \"./node_modules/moment/locale/es.js\",\n\t\"./es-do\": \"./node_modules/moment/locale/es-do.js\",\n\t\"./es-do.js\": \"./node_modules/moment/locale/es-do.js\",\n\t\"./es-us\": \"./node_modules/moment/locale/es-us.js\",\n\t\"./es-us.js\": \"./node_modules/moment/locale/es-us.js\",\n\t\"./es.js\": \"./node_modules/moment/locale/es.js\",\n\t\"./et\": \"./node_modules/moment/locale/et.js\",\n\t\"./et.js\": \"./node_modules/moment/locale/et.js\",\n\t\"./eu\": \"./node_modules/moment/locale/eu.js\",\n\t\"./eu.js\": \"./node_modules/moment/locale/eu.js\",\n\t\"./fa\": \"./node_modules/moment/locale/fa.js\",\n\t\"./fa.js\": \"./node_modules/moment/locale/fa.js\",\n\t\"./fi\": \"./node_modules/moment/locale/fi.js\",\n\t\"./fi.js\": \"./node_modules/moment/locale/fi.js\",\n\t\"./fo\": \"./node_modules/moment/locale/fo.js\",\n\t\"./fo.js\": \"./node_modules/moment/locale/fo.js\",\n\t\"./fr\": \"./node_modules/moment/locale/fr.js\",\n\t\"./fr-ca\": \"./node_modules/moment/locale/fr-ca.js\",\n\t\"./fr-ca.js\": \"./node_modules/moment/locale/fr-ca.js\",\n\t\"./fr-ch\": \"./node_modules/moment/locale/fr-ch.js\",\n\t\"./fr-ch.js\": \"./node_modules/moment/locale/fr-ch.js\",\n\t\"./fr.js\": \"./node_modules/moment/locale/fr.js\",\n\t\"./fy\": \"./node_modules/moment/locale/fy.js\",\n\t\"./fy.js\": \"./node_modules/moment/locale/fy.js\",\n\t\"./ga\": \"./node_modules/moment/locale/ga.js\",\n\t\"./ga.js\": \"./node_modules/moment/locale/ga.js\",\n\t\"./gd\": \"./node_modules/moment/locale/gd.js\",\n\t\"./gd.js\": \"./node_modules/moment/locale/gd.js\",\n\t\"./gl\": \"./node_modules/moment/locale/gl.js\",\n\t\"./gl.js\": \"./node_modules/moment/locale/gl.js\",\n\t\"./gom-latn\": \"./node_modules/moment/locale/gom-latn.js\",\n\t\"./gom-latn.js\": \"./node_modules/moment/locale/gom-latn.js\",\n\t\"./gu\": \"./node_modules/moment/locale/gu.js\",\n\t\"./gu.js\": \"./node_modules/moment/locale/gu.js\",\n\t\"./he\": \"./node_modules/moment/locale/he.js\",\n\t\"./he.js\": \"./node_modules/moment/locale/he.js\",\n\t\"./hi\": \"./node_modules/moment/locale/hi.js\",\n\t\"./hi.js\": \"./node_modules/moment/locale/hi.js\",\n\t\"./hr\": \"./node_modules/moment/locale/hr.js\",\n\t\"./hr.js\": \"./node_modules/moment/locale/hr.js\",\n\t\"./hu\": \"./node_modules/moment/locale/hu.js\",\n\t\"./hu.js\": \"./node_modules/moment/locale/hu.js\",\n\t\"./hy-am\": \"./node_modules/moment/locale/hy-am.js\",\n\t\"./hy-am.js\": \"./node_modules/moment/locale/hy-am.js\",\n\t\"./id\": \"./node_modules/moment/locale/id.js\",\n\t\"./id.js\": \"./node_modules/moment/locale/id.js\",\n\t\"./is\": \"./node_modules/moment/locale/is.js\",\n\t\"./is.js\": \"./node_modules/moment/locale/is.js\",\n\t\"./it\": \"./node_modules/moment/locale/it.js\",\n\t\"./it-ch\": \"./node_modules/moment/locale/it-ch.js\",\n\t\"./it-ch.js\": \"./node_modules/moment/locale/it-ch.js\",\n\t\"./it.js\": \"./node_modules/moment/locale/it.js\",\n\t\"./ja\": \"./node_modules/moment/locale/ja.js\",\n\t\"./ja.js\": \"./node_modules/moment/locale/ja.js\",\n\t\"./jv\": \"./node_modules/moment/locale/jv.js\",\n\t\"./jv.js\": \"./node_modules/moment/locale/jv.js\",\n\t\"./ka\": \"./node_modules/moment/locale/ka.js\",\n\t\"./ka.js\": \"./node_modules/moment/locale/ka.js\",\n\t\"./kk\": \"./node_modules/moment/locale/kk.js\",\n\t\"./kk.js\": \"./node_modules/moment/locale/kk.js\",\n\t\"./km\": \"./node_modules/moment/locale/km.js\",\n\t\"./km.js\": \"./node_modules/moment/locale/km.js\",\n\t\"./kn\": \"./node_modules/moment/locale/kn.js\",\n\t\"./kn.js\": \"./node_modules/moment/locale/kn.js\",\n\t\"./ko\": \"./node_modules/moment/locale/ko.js\",\n\t\"./ko.js\": \"./node_modules/moment/locale/ko.js\",\n\t\"./ku\": \"./node_modules/moment/locale/ku.js\",\n\t\"./ku.js\": \"./node_modules/moment/locale/ku.js\",\n\t\"./ky\": \"./node_modules/moment/locale/ky.js\",\n\t\"./ky.js\": \"./node_modules/moment/locale/ky.js\",\n\t\"./lb\": \"./node_modules/moment/locale/lb.js\",\n\t\"./lb.js\": \"./node_modules/moment/locale/lb.js\",\n\t\"./lo\": \"./node_modules/moment/locale/lo.js\",\n\t\"./lo.js\": \"./node_modules/moment/locale/lo.js\",\n\t\"./lt\": \"./node_modules/moment/locale/lt.js\",\n\t\"./lt.js\": \"./node_modules/moment/locale/lt.js\",\n\t\"./lv\": \"./node_modules/moment/locale/lv.js\",\n\t\"./lv.js\": \"./node_modules/moment/locale/lv.js\",\n\t\"./me\": \"./node_modules/moment/locale/me.js\",\n\t\"./me.js\": \"./node_modules/moment/locale/me.js\",\n\t\"./mi\": \"./node_modules/moment/locale/mi.js\",\n\t\"./mi.js\": \"./node_modules/moment/locale/mi.js\",\n\t\"./mk\": \"./node_modules/moment/locale/mk.js\",\n\t\"./mk.js\": \"./node_modules/moment/locale/mk.js\",\n\t\"./ml\": \"./node_modules/moment/locale/ml.js\",\n\t\"./ml.js\": \"./node_modules/moment/locale/ml.js\",\n\t\"./mn\": \"./node_modules/moment/locale/mn.js\",\n\t\"./mn.js\": \"./node_modules/moment/locale/mn.js\",\n\t\"./mr\": \"./node_modules/moment/locale/mr.js\",\n\t\"./mr.js\": \"./node_modules/moment/locale/mr.js\",\n\t\"./ms\": \"./node_modules/moment/locale/ms.js\",\n\t\"./ms-my\": \"./node_modules/moment/locale/ms-my.js\",\n\t\"./ms-my.js\": \"./node_modules/moment/locale/ms-my.js\",\n\t\"./ms.js\": \"./node_modules/moment/locale/ms.js\",\n\t\"./mt\": \"./node_modules/moment/locale/mt.js\",\n\t\"./mt.js\": \"./node_modules/moment/locale/mt.js\",\n\t\"./my\": \"./node_modules/moment/locale/my.js\",\n\t\"./my.js\": \"./node_modules/moment/locale/my.js\",\n\t\"./nb\": \"./node_modules/moment/locale/nb.js\",\n\t\"./nb.js\": \"./node_modules/moment/locale/nb.js\",\n\t\"./ne\": \"./node_modules/moment/locale/ne.js\",\n\t\"./ne.js\": \"./node_modules/moment/locale/ne.js\",\n\t\"./nl\": \"./node_modules/moment/locale/nl.js\",\n\t\"./nl-be\": \"./node_modules/moment/locale/nl-be.js\",\n\t\"./nl-be.js\": \"./node_modules/moment/locale/nl-be.js\",\n\t\"./nl.js\": \"./node_modules/moment/locale/nl.js\",\n\t\"./nn\": \"./node_modules/moment/locale/nn.js\",\n\t\"./nn.js\": \"./node_modules/moment/locale/nn.js\",\n\t\"./pa-in\": \"./node_modules/moment/locale/pa-in.js\",\n\t\"./pa-in.js\": \"./node_modules/moment/locale/pa-in.js\",\n\t\"./pl\": \"./node_modules/moment/locale/pl.js\",\n\t\"./pl.js\": \"./node_modules/moment/locale/pl.js\",\n\t\"./pt\": \"./node_modules/moment/locale/pt.js\",\n\t\"./pt-br\": \"./node_modules/moment/locale/pt-br.js\",\n\t\"./pt-br.js\": \"./node_modules/moment/locale/pt-br.js\",\n\t\"./pt.js\": \"./node_modules/moment/locale/pt.js\",\n\t\"./ro\": \"./node_modules/moment/locale/ro.js\",\n\t\"./ro.js\": \"./node_modules/moment/locale/ro.js\",\n\t\"./ru\": \"./node_modules/moment/locale/ru.js\",\n\t\"./ru.js\": \"./node_modules/moment/locale/ru.js\",\n\t\"./sd\": \"./node_modules/moment/locale/sd.js\",\n\t\"./sd.js\": \"./node_modules/moment/locale/sd.js\",\n\t\"./se\": \"./node_modules/moment/locale/se.js\",\n\t\"./se.js\": \"./node_modules/moment/locale/se.js\",\n\t\"./si\": \"./node_modules/moment/locale/si.js\",\n\t\"./si.js\": \"./node_modules/moment/locale/si.js\",\n\t\"./sk\": \"./node_modules/moment/locale/sk.js\",\n\t\"./sk.js\": \"./node_modules/moment/locale/sk.js\",\n\t\"./sl\": \"./node_modules/moment/locale/sl.js\",\n\t\"./sl.js\": \"./node_modules/moment/locale/sl.js\",\n\t\"./sq\": \"./node_modules/moment/locale/sq.js\",\n\t\"./sq.js\": \"./node_modules/moment/locale/sq.js\",\n\t\"./sr\": \"./node_modules/moment/locale/sr.js\",\n\t\"./sr-cyrl\": \"./node_modules/moment/locale/sr-cyrl.js\",\n\t\"./sr-cyrl.js\": \"./node_modules/moment/locale/sr-cyrl.js\",\n\t\"./sr.js\": \"./node_modules/moment/locale/sr.js\",\n\t\"./ss\": \"./node_modules/moment/locale/ss.js\",\n\t\"./ss.js\": \"./node_modules/moment/locale/ss.js\",\n\t\"./sv\": \"./node_modules/moment/locale/sv.js\",\n\t\"./sv.js\": \"./node_modules/moment/locale/sv.js\",\n\t\"./sw\": \"./node_modules/moment/locale/sw.js\",\n\t\"./sw.js\": \"./node_modules/moment/locale/sw.js\",\n\t\"./ta\": \"./node_modules/moment/locale/ta.js\",\n\t\"./ta.js\": \"./node_modules/moment/locale/ta.js\",\n\t\"./te\": \"./node_modules/moment/locale/te.js\",\n\t\"./te.js\": \"./node_modules/moment/locale/te.js\",\n\t\"./tet\": \"./node_modules/moment/locale/tet.js\",\n\t\"./tet.js\": \"./node_modules/moment/locale/tet.js\",\n\t\"./tg\": \"./node_modules/moment/locale/tg.js\",\n\t\"./tg.js\": \"./node_modules/moment/locale/tg.js\",\n\t\"./th\": \"./node_modules/moment/locale/th.js\",\n\t\"./th.js\": \"./node_modules/moment/locale/th.js\",\n\t\"./tl-ph\": \"./node_modules/moment/locale/tl-ph.js\",\n\t\"./tl-ph.js\": \"./node_modules/moment/locale/tl-ph.js\",\n\t\"./tlh\": \"./node_modules/moment/locale/tlh.js\",\n\t\"./tlh.js\": \"./node_modules/moment/locale/tlh.js\",\n\t\"./tr\": \"./node_modules/moment/locale/tr.js\",\n\t\"./tr.js\": \"./node_modules/moment/locale/tr.js\",\n\t\"./tzl\": \"./node_modules/moment/locale/tzl.js\",\n\t\"./tzl.js\": \"./node_modules/moment/locale/tzl.js\",\n\t\"./tzm\": \"./node_modules/moment/locale/tzm.js\",\n\t\"./tzm-latn\": \"./node_modules/moment/locale/tzm-latn.js\",\n\t\"./tzm-latn.js\": \"./node_modules/moment/locale/tzm-latn.js\",\n\t\"./tzm.js\": \"./node_modules/moment/locale/tzm.js\",\n\t\"./ug-cn\": \"./node_modules/moment/locale/ug-cn.js\",\n\t\"./ug-cn.js\": \"./node_modules/moment/locale/ug-cn.js\",\n\t\"./uk\": \"./node_modules/moment/locale/uk.js\",\n\t\"./uk.js\": \"./node_modules/moment/locale/uk.js\",\n\t\"./ur\": \"./node_modules/moment/locale/ur.js\",\n\t\"./ur.js\": \"./node_modules/moment/locale/ur.js\",\n\t\"./uz\": \"./node_modules/moment/locale/uz.js\",\n\t\"./uz-latn\": \"./node_modules/moment/locale/uz-latn.js\",\n\t\"./uz-latn.js\": \"./node_modules/moment/locale/uz-latn.js\",\n\t\"./uz.js\": \"./node_modules/moment/locale/uz.js\",\n\t\"./vi\": \"./node_modules/moment/locale/vi.js\",\n\t\"./vi.js\": \"./node_modules/moment/locale/vi.js\",\n\t\"./x-pseudo\": \"./node_modules/moment/locale/x-pseudo.js\",\n\t\"./x-pseudo.js\": \"./node_modules/moment/locale/x-pseudo.js\",\n\t\"./yo\": \"./node_modules/moment/locale/yo.js\",\n\t\"./yo.js\": \"./node_modules/moment/locale/yo.js\",\n\t\"./zh-cn\": \"./node_modules/moment/locale/zh-cn.js\",\n\t\"./zh-cn.js\": \"./node_modules/moment/locale/zh-cn.js\",\n\t\"./zh-hk\": \"./node_modules/moment/locale/zh-hk.js\",\n\t\"./zh-hk.js\": \"./node_modules/moment/locale/zh-hk.js\",\n\t\"./zh-tw\": \"./node_modules/moment/locale/zh-tw.js\",\n\t\"./zh-tw.js\": \"./node_modules/moment/locale/zh-tw.js\"\n};\n\n\nfunction webpackContext(req) {\n\tvar id = webpackContextResolve(req);\n\treturn __webpack_require__(id);\n}\nfunction webpackContextResolve(req) {\n\tif(!__webpack_require__.o(map, req)) {\n\t\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\t\te.code = 'MODULE_NOT_FOUND';\n\t\tthrow e;\n\t}\n\treturn map[req];\n}\nwebpackContext.keys = function webpackContextKeys() {\n\treturn Object.keys(map);\n};\nwebpackContext.resolve = webpackContextResolve;\nmodule.exports = webpackContext;\nwebpackContext.id = \"./node_modules/moment/locale sync recursive ^\\\\.\\\\/.*$\";//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,{"version":3,"file":"./node_modules/moment/locale sync recursive ^\\.\\/.*$.js","sources":["webpack:///./node_modules/moment/locale sync ^\\.\\/.*$?fe16"],"sourcesContent":["var map = {\n\t\"./af\": \"./node_modules/moment/locale/af.js\",\n\t\"./af.js\": \"./node_modules/moment/locale/af.js\",\n\t\"./ar\": \"./node_modules/moment/locale/ar.js\",\n\t\"./ar-dz\": \"./node_modules/moment/locale/ar-dz.js\",\n\t\"./ar-dz.js\": \"./node_modules/moment/locale/ar-dz.js\",\n\t\"./ar-kw\": \"./node_modules/moment/locale/ar-kw.js\",\n\t\"./ar-kw.js\": \"./node_modules/moment/locale/ar-kw.js\",\n\t\"./ar-ly\": \"./node_modules/moment/locale/ar-ly.js\",\n\t\"./ar-ly.js\": \"./node_modules/moment/locale/ar-ly.js\",\n\t\"./ar-ma\": \"./node_modules/moment/locale/ar-ma.js\",\n\t\"./ar-ma.js\": \"./node_modules/moment/locale/ar-ma.js\",\n\t\"./ar-sa\": \"./node_modules/moment/locale/ar-sa.js\",\n\t\"./ar-sa.js\": \"./node_modules/moment/locale/ar-sa.js\",\n\t\"./ar-tn\": \"./node_modules/moment/locale/ar-tn.js\",\n\t\"./ar-tn.js\": \"./node_modules/moment/locale/ar-tn.js\",\n\t\"./ar.js\": \"./node_modules/moment/locale/ar.js\",\n\t\"./az\": \"./node_modules/moment/locale/az.js\",\n\t\"./az.js\": \"./node_modules/moment/locale/az.js\",\n\t\"./be\": \"./node_modules/moment/locale/be.js\",\n\t\"./be.js\": \"./node_modules/moment/locale/be.js\",\n\t\"./bg\": \"./node_modules/moment/locale/bg.js\",\n\t\"./bg.js\": \"./node_modules/moment/locale/bg.js\",\n\t\"./bm\": \"./node_modules/moment/locale/bm.js\",\n\t\"./bm.js\": \"./node_modules/moment/locale/bm.js\",\n\t\"./bn\": \"./node_modules/moment/locale/bn.js\",\n\t\"./bn.js\": \"./node_modules/moment/locale/bn.js\",\n\t\"./bo\": \"./node_modules/moment/locale/bo.js\",\n\t\"./bo.js\": \"./node_modules/moment/locale/bo.js\",\n\t\"./br\": \"./node_modules/moment/locale/br.js\",\n\t\"./br.js\": \"./node_modules/moment/locale/br.js\",\n\t\"./bs\": \"./node_modules/moment/locale/bs.js\",\n\t\"./bs.js\": \"./node_modules/moment/locale/bs.js\",\n\t\"./ca\": \"./node_modules/moment/locale/ca.js\",\n\t\"./ca.js\": \"./node_modules/moment/locale/ca.js\",\n\t\"./cs\": \"./node_modules/moment/locale/cs.js\",\n\t\"./cs.js\": \"./node_modules/moment/locale/cs.js\",\n\t\"./cv\": \"./node_modules/moment/locale/cv.js\",\n\t\"./cv.js\": \"./node_modules/moment/locale/cv.js\",\n\t\"./cy\": \"./node_modules/moment/locale/cy.js\",\n\t\"./cy.js\": \"./node_modules/moment/locale/cy.js\",\n\t\"./da\": \"./node_modules/moment/locale/da.js\",\n\t\"./da.js\": \"./node_modules/moment/locale/da.js\",\n\t\"./de\": \"./node_modules/moment/locale/de.js\",\n\t\"./de-at\": \"./node_modules/moment/locale/de-at.js\",\n\t\"./de-at.js\": \"./node_modules/moment/locale/de-at.js\",\n\t\"./de-ch\": \"./node_modules/moment/locale/de-ch.js\",\n\t\"./de-ch.js\": \"./node_modules/moment/locale/de-ch.js\",\n\t\"./de.js\": \"./node_modules/moment/locale/de.js\",\n\t\"./dv\": \"./node_modules/moment/locale/dv.js\",\n\t\"./dv.js\": \"./node_modules/moment/locale/dv.js\",\n\t\"./el\": \"./node_modules/moment/locale/el.js\",\n\t\"./el.js\": \"./node_modules/moment/locale/el.js\",\n\t\"./en-SG\": \"./node_modules/moment/locale/en-SG.js\",\n\t\"./en-SG.js\": \"./node_modules/moment/locale/en-SG.js\",\n\t\"./en-au\": \"./node_modules/moment/locale/en-au.js\",\n\t\"./en-au.js\": \"./node_modules/moment/locale/en-au.js\",\n\t\"./en-ca\": \"./node_modules/moment/locale/en-ca.js\",\n\t\"./en-ca.js\": \"./node_modules/moment/locale/en-ca.js\",\n\t\"./en-gb\": \"./node_modules/moment/locale/en-gb.js\",\n\t\"./en-gb.js\": \"./node_modules/moment/locale/en-gb.js\",\n\t\"./en-ie\": \"./node_modules/moment/locale/en-ie.js\",\n\t\"./en-ie.js\": \"./node_modules/moment/locale/en-ie.js\",\n\t\"./en-il\": \"./node_modules/moment/locale/en-il.js\",\n\t\"./en-il.js\": \"./node_modules/moment/locale/en-il.js\",\n\t\"./en-nz\": \"./node_modules/moment/locale/en-nz.js\",\n\t\"./en-nz.js\": \"./node_modules/moment/locale/en-nz.js\",\n\t\"./eo\": \"./node_modules/moment/locale/eo.js\",\n\t\"./eo.js\": \"./node_modules/moment/locale/eo.js\",\n\t\"./es\": \"./node_modules/moment/locale/es.js\",\n\t\"./es-do\": \"./node_modules/moment/locale/es-do.js\",\n\t\"./es-do.js\": \"./node_modules/moment/locale/es-do.js\",\n\t\"./es-us\": \"./node_modules/moment/locale/es-us.js\",\n\t\"./es-us.js\": \"./node_modules/moment/locale/es-us.js\",\n\t\"./es.js\": \"./node_modules/moment/locale/es.js\",\n\t\"./et\": \"./node_modules/moment/locale/et.js\",\n\t\"./et.js\": \"./node_modules/moment/locale/et.js\",\n\t\"./eu\": \"./node_modules/moment/locale/eu.js\",\n\t\"./eu.js\": \"./node_modules/moment/locale/eu.js\",\n\t\"./fa\": \"./node_modules/moment/locale/fa.js\",\n\t\"./fa.js\": \"./node_modules/moment/locale/fa.js\",\n\t\"./fi\": \"./node_modules/moment/locale/fi.js\",\n\t\"./fi.js\": \"./node_modules/moment/locale/fi.js\",\n\t\"./fo\": \"./node_modules/moment/locale/fo.js\",\n\t\"./fo.js\": \"./node_modules/moment/locale/fo.js\",\n\t\"./fr\": \"./node_modules/moment/locale/fr.js\",\n\t\"./fr-ca\": \"./node_modules/moment/locale/fr-ca.js\",\n\t\"./fr-ca.js\": \"./node_modules/moment/locale/fr-ca.js\",\n\t\"./fr-ch\": \"./node_modules/moment/locale/fr-ch.js\",\n\t\"./fr-ch.js\": \"./node_modules/moment/locale/fr-ch.js\",\n\t\"./fr.js\": \"./node_modules/moment/locale/fr.js\",\n\t\"./fy\": \"./node_modules/moment/locale/fy.js\",\n\t\"./fy.js\": \"./node_modules/moment/locale/fy.js\",\n\t\"./ga\": \"./node_modules/moment/locale/ga.js\",\n\t\"./ga.js\": \"./node_modules/moment/locale/ga.js\",\n\t\"./gd\": \"./node_modules/moment/locale/gd.js\",\n\t\"./gd.js\": \"./node_modules/moment/locale/gd.js\",\n\t\"./gl\": \"./node_modules/moment/locale/gl.js\",\n\t\"./gl.js\": \"./node_modules/moment/locale/gl.js\",\n\t\"./gom-latn\": \"./node_modules/moment/locale/gom-latn.js\",\n\t\"./gom-latn.js\": \"./node_modules/moment/locale/gom-latn.js\",\n\t\"./gu\": \"./node_modules/moment/locale/gu.js\",\n\t\"./gu.js\": \"./node_modules/moment/locale/gu.js\",\n\t\"./he\": \"./node_modules/moment/locale/he.js\",\n\t\"./he.js\": \"./node_modules/moment/locale/he.js\",\n\t\"./hi\": \"./node_modules/moment/locale/hi.js\",\n\t\"./hi.js\": \"./node_modules/moment/locale/hi.js\",\n\t\"./hr\": \"./node_modules/moment/locale/hr.js\",\n\t\"./hr.js\": \"./node_modules/moment/locale/hr.js\",\n\t\"./hu\": \"./node_modules/moment/locale/hu.js\",\n\t\"./hu.js\": \"./node_modules/moment/locale/hu.js\",\n\t\"./hy-am\": \"./node_modules/moment/locale/hy-am.js\",\n\t\"./hy-am.js\": \"./node_modules/moment/locale/hy-am.js\",\n\t\"./id\": \"./node_modules/moment/locale/id.js\",\n\t\"./id.js\": \"./node_modules/moment/locale/id.js\",\n\t\"./is\": \"./node_modules/moment/locale/is.js\",\n\t\"./is.js\": \"./node_modules/moment/locale/is.js\",\n\t\"./it\": \"./node_modules/moment/locale/it.js\",\n\t\"./it-ch\": \"./node_modules/moment/locale/it-ch.js\",\n\t\"./it-ch.js\": \"./node_modules/moment/locale/it-ch.js\",\n\t\"./it.js\": \"./node_modules/moment/locale/it.js\",\n\t\"./ja\": \"./node_modules/moment/locale/ja.js\",\n\t\"./ja.js\": \"./node_modules/moment/locale/ja.js\",\n\t\"./jv\": \"./node_modules/moment/locale/jv.js\",\n\t\"./jv.js\": \"./node_modules/moment/locale/jv.js\",\n\t\"./ka\": \"./node_modules/moment/locale/ka.js\",\n\t\"./ka.js\": \"./node_modules/moment/locale/ka.js\",\n\t\"./kk\": \"./node_modules/moment/locale/kk.js\",\n\t\"./kk.js\": \"./node_modules/moment/locale/kk.js\",\n\t\"./km\": \"./node_modules/moment/locale/km.js\",\n\t\"./km.js\": \"./node_modules/moment/locale/km.js\",\n\t\"./kn\": \"./node_modules/moment/locale/kn.js\",\n\t\"./kn.js\": \"./node_modules/moment/locale/kn.js\",\n\t\"./ko\": \"./node_modules/moment/locale/ko.js\",\n\t\"./ko.js\": \"./node_modules/moment/locale/ko.js\",\n\t\"./ku\": \"./node_modules/moment/locale/ku.js\",\n\t\"./ku.js\": \"./node_modules/moment/locale/ku.js\",\n\t\"./ky\": \"./node_modules/moment/locale/ky.js\",\n\t\"./ky.js\": \"./node_modules/moment/locale/ky.js\",\n\t\"./lb\": \"./node_modules/moment/locale/lb.js\",\n\t\"./lb.js\": \"./node_modules/moment/locale/lb.js\",\n\t\"./lo\": \"./node_modules/moment/locale/lo.js\",\n\t\"./lo.js\": \"./node_modules/moment/locale/lo.js\",\n\t\"./lt\": \"./node_modules/moment/locale/lt.js\",\n\t\"./lt.js\": \"./node_modules/moment/locale/lt.js\",\n\t\"./lv\": \"./node_modules/moment/locale/lv.js\",\n\t\"./lv.js\": \"./node_modules/moment/locale/lv.js\",\n\t\"./me\": \"./node_modules/moment/locale/me.js\",\n\t\"./me.js\": \"./node_modules/moment/locale/me.js\",\n\t\"./mi\": \"./node_modules/moment/locale/mi.js\",\n\t\"./mi.js\": \"./node_modules/moment/locale/mi.js\",\n\t\"./mk\": \"./node_modules/moment/locale/mk.js\",\n\t\"./mk.js\": \"./node_modules/moment/locale/mk.js\",\n\t\"./ml\": \"./node_modules/moment/locale/ml.js\",\n\t\"./ml.js\": \"./node_modules/moment/locale/ml.js\",\n\t\"./mn\": \"./node_modules/moment/locale/mn.js\",\n\t\"./mn.js\": \"./node_modules/moment/locale/mn.js\",\n\t\"./mr\": \"./node_modules/moment/locale/mr.js\",\n\t\"./mr.js\": \"./node_modules/moment/locale/mr.js\",\n\t\"./ms\": \"./node_modules/moment/locale/ms.js\",\n\t\"./ms-my\": \"./node_modules/moment/locale/ms-my.js\",\n\t\"./ms-my.js\": \"./node_modules/moment/locale/ms-my.js\",\n\t\"./ms.js\": \"./node_modules/moment/locale/ms.js\",\n\t\"./mt\": \"./node_modules/moment/locale/mt.js\",\n\t\"./mt.js\": \"./node_modules/moment/locale/mt.js\",\n\t\"./my\": \"./node_modules/moment/locale/my.js\",\n\t\"./my.js\": \"./node_modules/moment/locale/my.js\",\n\t\"./nb\": \"./node_modules/moment/locale/nb.js\",\n\t\"./nb.js\": \"./node_modules/moment/locale/nb.js\",\n\t\"./ne\": \"./node_modules/moment/locale/ne.js\",\n\t\"./ne.js\": \"./node_modules/moment/locale/ne.js\",\n\t\"./nl\": \"./node_modules/moment/locale/nl.js\",\n\t\"./nl-be\": \"./node_modules/moment/locale/nl-be.js\",\n\t\"./nl-be.js\": \"./node_modules/moment/locale/nl-be.js\",\n\t\"./nl.js\": \"./node_modules/moment/locale/nl.js\",\n\t\"./nn\": \"./node_modules/moment/locale/nn.js\",\n\t\"./nn.js\": \"./node_modules/moment/locale/nn.js\",\n\t\"./pa-in\": \"./node_modules/moment/locale/pa-in.js\",\n\t\"./pa-in.js\": \"./node_modules/moment/locale/pa-in.js\",\n\t\"./pl\": \"./node_modules/moment/locale/pl.js\",\n\t\"./pl.js\": \"./node_modules/moment/locale/pl.js\",\n\t\"./pt\": \"./node_modules/moment/locale/pt.js\",\n\t\"./pt-br\": \"./node_modules/moment/locale/pt-br.js\",\n\t\"./pt-br.js\": \"./node_modules/moment/locale/pt-br.js\",\n\t\"./pt.js\": \"./node_modules/moment/locale/pt.js\",\n\t\"./ro\": \"./node_modules/moment/locale/ro.js\",\n\t\"./ro.js\": \"./node_modules/moment/locale/ro.js\",\n\t\"./ru\": \"./node_modules/moment/locale/ru.js\",\n\t\"./ru.js\": \"./node_modules/moment/locale/ru.js\",\n\t\"./sd\": \"./node_modules/moment/locale/sd.js\",\n\t\"./sd.js\": \"./node_modules/moment/locale/sd.js\",\n\t\"./se\": \"./node_modules/moment/locale/se.js\",\n\t\"./se.js\": \"./node_modules/moment/locale/se.js\",\n\t\"./si\": \"./node_modules/moment/locale/si.js\",\n\t\"./si.js\": \"./node_modules/moment/locale/si.js\",\n\t\"./sk\": \"./node_modules/moment/locale/sk.js\",\n\t\"./sk.js\": \"./node_modules/moment/locale/sk.js\",\n\t\"./sl\": \"./node_modules/moment/locale/sl.js\",\n\t\"./sl.js\": \"./node_modules/moment/locale/sl.js\",\n\t\"./sq\": \"./node_modules/moment/locale/sq.js\",\n\t\"./sq.js\": \"./node_modules/moment/locale/sq.js\",\n\t\"./sr\": \"./node_modules/moment/locale/sr.js\",\n\t\"./sr-cyrl\": \"./node_modules/moment/locale/sr-cyrl.js\",\n\t\"./sr-cyrl.js\": \"./node_modules/moment/locale/sr-cyrl.js\",\n\t\"./sr.js\": \"./node_modules/moment/locale/sr.js\",\n\t\"./ss\": \"./node_modules/moment/locale/ss.js\",\n\t\"./ss.js\": \"./node_modules/moment/locale/ss.js\",\n\t\"./sv\": \"./node_modules/moment/locale/sv.js\",\n\t\"./sv.js\": \"./node_modules/moment/locale/sv.js\",\n\t\"./sw\": \"./node_modules/moment/locale/sw.js\",\n\t\"./sw.js\": \"./node_modules/moment/locale/sw.js\",\n\t\"./ta\": \"./node_modules/moment/locale/ta.js\",\n\t\"./ta.js\": \"./node_modules/moment/locale/ta.js\",\n\t\"./te\": \"./node_modules/moment/locale/te.js\",\n\t\"./te.js\": \"./node_modules/moment/locale/te.js\",\n\t\"./tet\": \"./node_modules/moment/locale/tet.js\",\n\t\"./tet.js\": \"./node_modules/moment/locale/tet.js\",\n\t\"./tg\": \"./node_modules/moment/locale/tg.js\",\n\t\"./tg.js\": \"./node_modules/moment/locale/tg.js\",\n\t\"./th\": \"./node_modules/moment/locale/th.js\",\n\t\"./th.js\": \"./node_modules/moment/locale/th.js\",\n\t\"./tl-ph\": \"./node_modules/moment/locale/tl-ph.js\",\n\t\"./tl-ph.js\": \"./node_modules/moment/locale/tl-ph.js\",\n\t\"./tlh\": \"./node_modules/moment/locale/tlh.js\",\n\t\"./tlh.js\": \"./node_modules/moment/locale/tlh.js\",\n\t\"./tr\": \"./node_modules/moment/locale/tr.js\",\n\t\"./tr.js\": \"./node_modules/moment/locale/tr.js\",\n\t\"./tzl\": \"./node_modules/moment/locale/tzl.js\",\n\t\"./tzl.js\": \"./node_modules/moment/locale/tzl.js\",\n\t\"./tzm\": \"./node_modules/moment/locale/tzm.js\",\n\t\"./tzm-latn\": \"./node_modules/moment/locale/tzm-latn.js\",\n\t\"./tzm-latn.js\": \"./node_modules/moment/locale/tzm-latn.js\",\n\t\"./tzm.js\": \"./node_modules/moment/locale/tzm.js\",\n\t\"./ug-cn\": \"./node_modules/moment/locale/ug-cn.js\",\n\t\"./ug-cn.js\": \"./node_modules/moment/locale/ug-cn.js\",\n\t\"./uk\": \"./node_modules/moment/locale/uk.js\",\n\t\"./uk.js\": \"./node_modules/moment/locale/uk.js\",\n\t\"./ur\": \"./node_modules/moment/locale/ur.js\",\n\t\"./ur.js\": \"./node_modules/moment/locale/ur.js\",\n\t\"./uz\": \"./node_modules/moment/locale/uz.js\",\n\t\"./uz-latn\": \"./node_modules/moment/locale/uz-latn.js\",\n\t\"./uz-latn.js\": \"./node_modules/moment/locale/uz-latn.js\",\n\t\"./uz.js\": \"./node_modules/moment/locale/uz.js\",\n\t\"./vi\": \"./node_modules/moment/locale/vi.js\",\n\t\"./vi.js\": \"./node_modules/moment/locale/vi.js\",\n\t\"./x-pseudo\": \"./node_modules/moment/locale/x-pseudo.js\",\n\t\"./x-pseudo.js\": \"./node_modules/moment/locale/x-pseudo.js\",\n\t\"./yo\": \"./node_modules/moment/locale/yo.js\",\n\t\"./yo.js\": \"./node_modules/moment/locale/yo.js\",\n\t\"./zh-cn\": \"./node_modules/moment/locale/zh-cn.js\",\n\t\"./zh-cn.js\": \"./node_modules/moment/locale/zh-cn.js\",\n\t\"./zh-hk\": \"./node_modules/moment/locale/zh-hk.js\",\n\t\"./zh-hk.js\": \"./node_modules/moment/locale/zh-hk.js\",\n\t\"./zh-tw\": \"./node_modules/moment/locale/zh-tw.js\",\n\t\"./zh-tw.js\": \"./node_modules/moment/locale/zh-tw.js\"\n};\n\n\nfunction webpackContext(req) {\n\tvar id = webpackContextResolve(req);\n\treturn __webpack_require__(id);\n}\nfunction webpackContextResolve(req) {\n\tif(!__webpack_require__.o(map, req)) {\n\t\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\t\te.code = 'MODULE_NOT_FOUND';\n\t\tthrow e;\n\t}\n\treturn map[req];\n}\nwebpackContext.keys = function webpackContextKeys() {\n\treturn Object.keys(map);\n};\nwebpackContext.resolve = webpackContextResolve;\nmodule.exports = webpackContext;\nwebpackContext.id = \"./node_modules/moment/locale sync recursive ^\\\\.\\\\/.*$\";"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sourceRoot":""}\n//# sourceURL=webpack-internal:///./node_modules/moment/locale sync recursive ^\\.\\/.*$\n");

/***/ }),

/***/ "./src/data-store.ts":
/*!***************************!*\
  !*** ./src/data-store.ts ***!
  \***************************/
/*! exports provided: DataStore */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DataStore\", function() { return DataStore; });\n/* harmony import */ var aurelia_dependency_injection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! aurelia-dependency-injection */ \"./node_modules/aurelia-dependency-injection/dist/native-modules/aurelia-dependency-injection.js\");\nvar __decorate = (undefined && undefined.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nvar __metadata = (undefined && undefined.__metadata) || function (k, v) {\n    if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(k, v);\n};\n\nvar DataStore = /** @class */ (function () {\n    function DataStore() {\n        var classes = __webpack_require__(/*! ../datasets/classes.json */ \"./datasets/classes.json\");\n        var mapping = __webpack_require__(/*! ../datasets/mapping.json */ \"./datasets/mapping.json\");\n        var new_data = __webpack_require__(/*! ../datasets/new_data.json */ \"./datasets/new_data.json\");\n        var old_data = __webpack_require__(/*! ../datasets/old_data.json */ \"./datasets/old_data.json\");\n        this.dataset_size = Object.keys(new_data).length;\n        this.classes = new Array();\n        this.keyword_propagation = new Array();\n        this.keyword_mapping = new Array();\n        this.data_new = new Array();\n        this.data_old = new Array();\n        for (var _i = 0, _a = Object.entries(mapping); _i < _a.length; _i++) {\n            var _b = _a[_i], key = _b[0], value = _b[1];\n            this.keyword_mapping[value[\"AuthorKeyword\"]] = value[\"ExpertKeyword\"];\n        }\n        for (var key in old_data) {\n            var update = old_data[key];\n            update[\"Done\"] = true;\n            update[\"Key\"] = parseInt(key);\n            this.data_old.push(update);\n        }\n        for (var key in new_data) {\n            var update = new_data[key];\n            update[\"Done\"] = false;\n            update[\"Key\"] = parseInt(key);\n            this.data_new.push(update);\n        }\n        for (var row in classes) {\n            this.classes.push(classes[row]);\n        }\n    }\n    DataStore.prototype.getClasses = function () {\n        return this.classes;\n    };\n    DataStore.prototype.getKeywordMapping = function (keyword) {\n        if (this.keyword_mapping.hasOwnProperty(keyword)) {\n            return this.keyword_mapping[keyword];\n        }\n        else {\n            return \"\";\n        }\n    };\n    DataStore.prototype.getMapping = function () {\n        return this.keyword_mapping;\n    };\n    DataStore.prototype.getMetaData = function (id) {\n        //return this.data_meta[id];\n        return this.data_new[id];\n    };\n    DataStore.prototype.getNew = function () {\n        //return this.data_meta;\n        return this.data_new;\n    };\n    DataStore.prototype.getLabeled = function () {\n        //return this.data_meta;\n        return this.data_old;\n    };\n    DataStore = __decorate([\n        Object(aurelia_dependency_injection__WEBPACK_IMPORTED_MODULE_0__[\"autoinject\"])(),\n        __metadata(\"design:paramtypes\", [])\n    ], DataStore);\n    return DataStore;\n}());\n\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,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\n//# sourceURL=webpack-internal:///./src/data-store.ts\n");

/***/ }),

/***/ "./src/environment.ts":
/*!****************************!*\
  !*** ./src/environment.ts ***!
  \****************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony default export */ __webpack_exports__[\"default\"] = ({\n    debug: true,\n    testing: true\n});\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoiLi9zcmMvZW52aXJvbm1lbnQudHMuanMiLCJzb3VyY2VzIjpbIndlYnBhY2s6Ly8vLi9zcmMvZW52aXJvbm1lbnQudHM/N2I2NCJdLCJzb3VyY2VzQ29udGVudCI6WyJleHBvcnQgZGVmYXVsdCB7XG4gIGRlYnVnOiB0cnVlLFxuICB0ZXN0aW5nOiB0cnVlXG59O1xuIl0sIm1hcHBpbmdzIjoiQUFBQTtBQUFBO0FBQ0E7QUFDQTtBQUNBOyIsInNvdXJjZVJvb3QiOiIifQ==\n//# sourceURL=webpack-internal:///./src/environment.ts\n");

/***/ }),

/***/ 0:
/*!*****************************************************************************************************************************!*\
  !*** multi aurelia-webpack-plugin/runtime/empty-entry aurelia-webpack-plugin/runtime/pal-loader-entry aurelia-bootstrapper ***!
  \*****************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

__webpack_require__(/*! aurelia-webpack-plugin/runtime/empty-entry */"./node_modules/aurelia-webpack-plugin/runtime/empty-entry.js");
__webpack_require__(/*! aurelia-webpack-plugin/runtime/pal-loader-entry */"./node_modules/aurelia-webpack-plugin/runtime/pal-loader-entry.js");
module.exports = __webpack_require__(/*! aurelia-bootstrapper */"./node_modules/aurelia-bootstrapper/dist/native-modules/aurelia-bootstrapper.js");


/***/ }),

/***/ "app":
/*!********************!*\
  !*** ./src/app.ts ***!
  \********************/
/*! exports provided: App */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"App\", function() { return App; });\n/* harmony import */ var aurelia_dependency_injection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! aurelia-dependency-injection */ \"./node_modules/aurelia-dependency-injection/dist/native-modules/aurelia-dependency-injection.js\");\nvar __decorate = (undefined && undefined.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\n\nvar App = /** @class */ (function () {\n    function App() {\n    }\n    App = __decorate([\n        Object(aurelia_dependency_injection__WEBPACK_IMPORTED_MODULE_0__[\"autoinject\"])()\n    ], App);\n    return App;\n}());\n\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoiYXBwLmpzIiwic291cmNlcyI6WyJ3ZWJwYWNrOi8vLy4vc3JjL2FwcC50cz8wNjZlIl0sInNvdXJjZXNDb250ZW50IjpbImltcG9ydCB7IGF1dG9pbmplY3QgfSBmcm9tICdhdXJlbGlhLWRlcGVuZGVuY3ktaW5qZWN0aW9uJztcbmltcG9ydCB7IERhdGFTdG9yZSB9IGZyb20gJ2RhdGEtc3RvcmUnO1xuXG5AYXV0b2luamVjdCgpXG5leHBvcnQgY2xhc3MgQXBwIHtcblxufVxuIl0sIm1hcHBpbmdzIjoiOzs7Ozs7Ozs7QUFBQTtBQUlBO0FBQUE7QUFFQTtBQUZBO0FBREE7QUFDQTtBQUVBO0FBQUE7QUFGQTsiLCJzb3VyY2VSb290IjoiIn0=\n//# sourceURL=webpack-internal:///app\n");

/***/ }),

/***/ "app.html":
/*!**********************!*\
  !*** ./src/app.html ***!
  \**********************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("module.exports = \"<template>\\r\\n  <require from=\\\"custom.css\\\"></require>\\r\\n  <require from=\\\"materialize-css/dist/css/materialize.css\\\"></require>\\r\\n  <compose view-model=\\\"./pages/p0\\\"></compose>\\r\\n\\r\\n</template>\";//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoiYXBwLmh0bWwuanMiLCJzb3VyY2VzIjpbIndlYnBhY2s6Ly8vLi9zcmMvYXBwLmh0bWw/NDVhYiJdLCJzb3VyY2VzQ29udGVudCI6WyJtb2R1bGUuZXhwb3J0cyA9IFwiPHRlbXBsYXRlPlxcclxcbiAgPHJlcXVpcmUgZnJvbT1cXFwiY3VzdG9tLmNzc1xcXCI+PC9yZXF1aXJlPlxcclxcbiAgPHJlcXVpcmUgZnJvbT1cXFwibWF0ZXJpYWxpemUtY3NzL2Rpc3QvY3NzL21hdGVyaWFsaXplLmNzc1xcXCI+PC9yZXF1aXJlPlxcclxcbiAgPGNvbXBvc2Ugdmlldy1tb2RlbD1cXFwiLi9wYWdlcy9wMFxcXCI+PC9jb21wb3NlPlxcclxcblxcclxcbjwvdGVtcGxhdGU+XCI7Il0sIm1hcHBpbmdzIjoiQUFBQSIsInNvdXJjZVJvb3QiOiIifQ==\n//# sourceURL=webpack-internal:///app.html\n");

/***/ }),

/***/ "custom.css":
/*!************************!*\
  !*** ./src/custom.css ***!
  \************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// Imports\nvar ___CSS_LOADER_API_IMPORT___ = __webpack_require__(/*! ../node_modules/css-loader/dist/runtime/api.js */ \"./node_modules/css-loader/dist/runtime/api.js\");\nexports = ___CSS_LOADER_API_IMPORT___(false);\n// Module\nexports.push([module.i, \".aut-sort::before {\\r\\n  font-family: \\\"Font Awesome 5 Pro\\\";\\r\\n  padding-right: 0.5em;\\r\\n  width: 1.28571429em;\\r\\n  display: inline-block;\\r\\n  text-align: center;\\r\\n}\\r\\n\\r\\n.aut-sortable::before {\\r\\n  content: \\\"\\\\f0dc\\\";\\r\\n}\\r\\n\\r\\n.aut-asc::before {\\r\\n  content: \\\"\\\\f160\\\";\\r\\n}\\r\\n\\r\\n.aut-desc::before {\\r\\n  content: \\\"\\\\f161\\\";\\r\\n}\\r\\n\\r\\n.au-target .highlight {\\r\\n  background-color: rgba(3, 155, 230, 0.20) !important;\\r\\n  color: #039be5;\\r\\n}\\r\\n\\r\\nmark {\\r\\n  background-color: rgba(3, 155, 230, 0.20) !important;\\r\\n  color: black;\\r\\n}\\r\\n\\r\\n[md-tabs] .waves-ripple {\\r\\n  position: static;\\r\\n}\\r\\n\\r\\n.small-bar {\\r\\n  fill: #108C0E;\\r\\n}\\r\\n\\r\\n.bColor {\\r\\n  background-color: #364652 !important;\\r\\n}\\r\\n\\r\\n/* #40798C */\\r\\n\\r\\n.row .selectionList {\\r\\n  margin-bottom: 0;\\r\\n}\\r\\n\\r\\n.one-page {\\r\\n  width: 100vw;\\r\\n  height: calc(100vh - 68px);\\r\\n}\\r\\n\\r\\n.areas {\\r\\n  height: 100%;\\r\\n  overflow-y: auto;\\r\\n  overflow-wrap: break-word;\\r\\n}\\r\\n\\r\\n.col m4>.class-selector {\\r\\n  width: 100%;\\r\\n}\\r\\n\\r\\n.class-selector {\\r\\n  height: 32px !important;\\r\\n  line-height: 32px !important;\\r\\n}\\r\\n\\r\\nmd-collection-selector>div>div {\\r\\n  position: relative !important;\\r\\n}\\r\\n\\r\\n.autocomplete-content {\\r\\n  width: 240px !important;\\r\\n}\\r\\n\\r\\n.sidenav-overlay {\\r\\n  height: 0px;\\r\\n  width: 0px;\\r\\n}\\r\\n\\r\\n.activeRow {\\r\\n  border-style: solid;\\r\\n  border-width: 2px;\\r\\n}\\r\\n\\r\\n.sidenav {\\r\\n  width: 40vw !important;\\r\\n}\\r\\n\\r\\n.hover:hover {\\r\\n  color: orange;\\r\\n}\\r\\n\\r\\n.deselected {\\r\\n  opacity: 0.3;\\r\\n}\\r\\n\\r\\n.table_cell {\\r\\n  padding: 0 0 0 10px;\\r\\n  margin: 0\\r\\n}\\r\\n\\r\\n.table_head {\\r\\n  padding: 0;\\r\\n  margin: 0 0 10px 0\\r\\n}\\r\\n\\r\\nmd-checkbox>label>span {\\r\\n  padding-left: 20px !important;\\r\\n  display: inline !important;\\r\\n}\", \"\"]);\n// Exports\nmodule.exports = exports;\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,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\n//# sourceURL=webpack-internal:///custom.css\n");

/***/ }),

/***/ "main":
/*!*********************!*\
  !*** ./src/main.ts ***!
  \*********************/
/*! exports provided: configure */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"configure\", function() { return configure; });\n/* harmony import */ var _environment__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./environment */ \"./src/environment.ts\");\n/* harmony import */ var aurelia_pal__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! aurelia-pal */ \"./node_modules/aurelia-pal/dist/native-modules/aurelia-pal.js\");\n/* harmony import */ var materialize_css__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! materialize-css */ \"./node_modules/materialize-css/dist/js/materialize.js\");\n/* harmony import */ var materialize_css__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(materialize_css__WEBPACK_IMPORTED_MODULE_2__);\n\n\n\n// remove out if you don't want a Promise polyfill (remove also from webpack.config.js)\n// Bluebird.config({ warnings: { wForgottenReturn: false } });\nfunction configure(aurelia) {\n    aurelia.use\n        .standardConfiguration()\n        .feature('resources/index')\n        .plugin('aurelia-materialize-bridge', function (b) { return b.useAll(); });\n    // Uncomment the line below to enable animation.\n    // aurelia.use.plugin(PLATFORM.moduleName('aurelia-animator-css'));\n    // if the css animator is enabled, add swap-order=\"after\" to all router-view elements\n    // Anyone wanting to use HTMLImports to load views, will need to install the following plugin.\n    // aurelia.use.plugin(PLATFORM.moduleName('aurelia-html-import-template-loader'));\n    aurelia.use.developmentLogging(_environment__WEBPACK_IMPORTED_MODULE_0__[\"default\"].debug ? 'debug' : 'warn');\n    if (_environment__WEBPACK_IMPORTED_MODULE_0__[\"default\"].testing) {\n        aurelia.use.plugin('aurelia-testing');\n    }\n    return aurelia.start().then(function () { return aurelia.setRoot('app'); });\n}\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,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\n//# sourceURL=webpack-internal:///main\n");

/***/ }),

/***/ "pages/p0":
/*!*************************!*\
  !*** ./src/pages/p0.ts ***!
  \*************************/
/*! exports provided: P0 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* WEBPACK VAR INJECTION */(function(Promise) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"P0\", function() { return P0; });\n/* harmony import */ var aurelia_dependency_injection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! aurelia-dependency-injection */ \"./node_modules/aurelia-dependency-injection/dist/native-modules/aurelia-dependency-injection.js\");\n/* harmony import */ var data_store__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! data-store */ \"./src/data-store.ts\");\n/* harmony import */ var lodash__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! lodash */ \"./node_modules/lodash/lodash.js\");\n/* harmony import */ var lodash__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(lodash__WEBPACK_IMPORTED_MODULE_2__);\n/* harmony import */ var tiny_tfidf__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! tiny-tfidf */ \"./node_modules/tiny-tfidf/index.js\");\n/* harmony import */ var wink_distance__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! wink-distance */ \"./node_modules/wink-distance/src/wink-distance.js\");\n/* harmony import */ var wink_distance__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(wink_distance__WEBPACK_IMPORTED_MODULE_4__);\nvar __decorate = (undefined && undefined.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nvar __metadata = (undefined && undefined.__metadata) || function (k, v) {\n    if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(k, v);\n};\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (undefined && undefined.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nvar __spreadArrays = (undefined && undefined.__spreadArrays) || function () {\n    for (var s = 0, i = 0, il = arguments.length; i < il; i++) s += arguments[i].length;\n    for (var r = Array(s), k = 0, i = 0; i < il; i++)\n        for (var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)\n            r[k] = a[j];\n    return r;\n};\n\n\n\n\n\nvar P0 = /** @class */ (function () {\n    function P0(store) {\n        var _this = this;\n        this.store = store;\n        this.autocompleteData = {};\n        // Filter\n        this.searchKeywordsTerm = \"\";\n        this.finishedKeywords = false;\n        this.searchLabelsTerm = \"\";\n        this.searchDocumentTerm = \"\";\n        // Selection\n        this.selected_document_list = [];\n        this.selected_additional_keywords = [];\n        this.last_selected_additional_keywords = [];\n        this.showDocuments = false;\n        this.selected_similarities = [];\n        this.selected_similar_keywords = [];\n        this.s_words = [];\n        // Similarity list\n        this.sim_property = \"text_similarity\";\n        this.key_property = \"highest_value\";\n        this.label_sort_property = \"total_similarity\";\n        this.label_sort_value = 0;\n        // Status variables\n        this.finished = false;\n        this.docs_todo = 0;\n        this.docs_done = 0;\n        this.docs_per = 0;\n        this.keywords_todo = 0;\n        this.keywords_done = 0;\n        this.keywords_per = 0;\n        this.tfidf_keywords = {};\n        // Time\n        this.time = 0;\n        this.keyword_time = 0;\n        this.timerActive = false;\n        // Temp variables\n        this.sort_property = \"descending\";\n        this.handleKeyInput = function (event) {\n            if (event.key == \"Enter\" && _this.selected_label) {\n                _this.throttled_applyLabel();\n            }\n            if (event.key == \"ArrowDown\" && _this.selected_label) {\n                var index = _this.label_docs.findIndex(function (x) { return x.label == _this.selected_label.label; });\n                _this.selectLabel(_this.label_docs[Math.min(index + 1, _this.label_docs.length - 1)]);\n            }\n            if (event.key == \"ArrowUp\" && _this.selected_label) {\n                var index = _this.label_docs.findIndex(function (x) { return x.label == _this.selected_label.label; });\n                _this.selectLabel(_this.label_docs[Math.max(index - 1, 0)]);\n            }\n            if (event.key == \"ArrowRight\" && _this.selected_label) {\n                _this.skipKeyword();\n            }\n            if (event.key == \"ArrowLeft\" && _this.selected_label) {\n                _this.undoKeyword();\n            }\n        };\n        // Sort Function\n        this.setSortProperty = function (property) { return _this.sim_property = property; };\n        this.setKeywordSortProperty = function (property) { return _this.key_property = property; };\n        this.setLabelSortProperty = function (property) { return _this.label_sort_property = property; };\n        this.setActiveKeyword = function (keyword) { return _this.selectKeyword(keyword); };\n        this.getMapping = function (keyword) { return _this.store.getKeywordMapping(keyword); };\n        this.checkMapping = function (keyword) { return keyword.mapping.length > 0 ? 1 : 0; };\n        this.throttled_applyLabel = lodash__WEBPACK_IMPORTED_MODULE_2__[\"throttle\"](function (x) { return _this.applyLabel(); }, 1000);\n        this.documents = store.getNew();\n        this.labeled_documents = store.getLabeled();\n        this.label_list = store.getClasses();\n        var mapping = store.getMapping();\n        this.label_docs = {};\n        this.keyword_mapping = {};\n        this.keyword_list = [];\n        // Initialize the label document mapping\n        for (var _i = 0, _a = this.label_list; _i < _a.length; _i++) {\n            var label = _a[_i];\n            this.label_docs[label[\"Cluster\"]] = [];\n        }\n        // Add missing unclear label\n        this.label_docs[\"Unclear\"] = [];\n        for (var _b = 0, _c = this.labeled_documents; _b < _c.length; _b++) {\n            var doc = _c[_b];\n            for (var _d = 0, _e = doc[\"Clusters\"].split(\";\"); _d < _e.length; _d++) {\n                var label = _e[_d];\n                if (this.label_docs.hasOwnProperty(label)) {\n                    var doc_list = this.label_docs[label];\n                    doc_list.push(doc);\n                    this.label_docs[label] = doc_list;\n                }\n            }\n            // TODO: fix casing in preprocessing\n            doc[\"Keywords_Processed\"] = doc[\"Keywords_Processed\"].toLowerCase().split(\";\");\n            for (var _f = 0, _g = doc[\"Keywords_Processed\"]; _f < _g.length; _f++) {\n                var author_key = _g[_f];\n                if (!this.keyword_mapping.hasOwnProperty(author_key)) {\n                    var mapping_1 = this.store.getKeywordMapping(author_key).replace(\",\", \"\");\n                    if (mapping_1.length > 0) {\n                        this.keyword_mapping[author_key] = {\n                            mapping: mapping_1,\n                            label: {},\n                            count: 1,\n                            isActive: false,\n                            docs: [doc],\n                            isDone: true,\n                            highest_property: \"\",\n                            highest_value: 0,\n                            sub_label: 0,\n                            sub_key: 0,\n                            sims: [],\n                            co_oc: [],\n                            source: \"db\",\n                            isNew: false,\n                        };\n                    }\n                    else {\n                        console.log(author_key);\n                        this.keyword_mapping[author_key] = {\n                            mapping: \"ERROR IN PREPROCEING\",\n                            label: {},\n                            count: 1,\n                            isActive: false,\n                            docs: [doc],\n                            isDone: true,\n                            highest_property: \"\",\n                            highest_value: 0,\n                            sub_label: 0,\n                            sub_key: 0,\n                            sims: [],\n                            co_oc: [],\n                            source: \"db\",\n                            isNew: false\n                        };\n                    }\n                }\n                else {\n                    var keyword = this.keyword_mapping[author_key];\n                    keyword.count++;\n                    keyword.docs.push(doc);\n                    this.keyword_mapping[author_key] = keyword;\n                }\n            }\n            doc[\"type\"] = \"old\";\n        }\n        var temp_labels = new Array();\n        var _loop_1 = function (key, value) {\n            var o = {};\n            var keywords = [];\n            o[\"label\"] = key;\n            o[\"docs\"] = value;\n            o[\"n_docs\"] = o[\"docs\"].length;\n            o[\"substring_similarity\"] = 0.0;\n            o[\"keyword_avg_similarity\"] = 0.0;\n            o[\"total_similarity\"] = 0.0;\n            o[\"isActive\"] = false;\n            for (var _i = 0, _a = Object.entries(lodash__WEBPACK_IMPORTED_MODULE_2__[\"pickBy\"](mapping, function (x) { return x === key; })); _i < _a.length; _i++) {\n                var _b = _a[_i], k = _b[0], l = _b[1];\n                keywords.push(k);\n            }\n            o[\"keywords\"] = keywords.join(\" \");\n            temp_labels.push(o);\n        };\n        for (var _h = 0, _j = Object.entries(this.label_docs); _h < _j.length; _h++) {\n            var _k = _j[_h], key = _k[0], value = _k[1];\n            _loop_1(key, value);\n        }\n        this.label_docs = temp_labels;\n        for (var _l = 0, _m = this.documents; _l < _m.length; _l++) {\n            var doc = _m[_l];\n            var unknown = 0;\n            // if (!doc[\"Keywords_Processed\"]) {\n            //     doc[\"Keywords_Processed\"] = \"\"\n            // }\n            doc[\"DOI\"] = \"https://doi.org/\" + doc[\"DOI\"];\n            doc[\"type\"] = \"new\";\n            // Create final keywords field\n            // TODO: fix casing in preprocessing\n            doc[\"Keywords_Processed\"] = doc[\"Keywords_Processed\"].toLowerCase().split(\";\");\n            // // Populate final keyword list\n            // let final = doc[\"Keywords_Processed\"]\n            //     // .map(x => this.store.getKeywordMapping(x).replace(/[^a-zA-Z]/g, \"\"))\n            //     .map(x => this.store.getKeywordMapping(x))\n            // // .filter(x => x !== \"unclear\");\n            // final = _.uniq(final);\n            for (var _o = 0, _p = doc[\"Keywords_Processed\"]; _o < _p.length; _o++) {\n                var author_key = _p[_o];\n                if (!this.keyword_mapping.hasOwnProperty(author_key)) {\n                    var mapping_2 = this.store.getKeywordMapping(author_key);\n                    var new_obj = {\n                        mapping: \"\",\n                        label: {},\n                        count: 1,\n                        isActive: false,\n                        docs: [doc],\n                        isDone: false,\n                        highest_property: \"\",\n                        highest_value: 0,\n                        sub_label: 0,\n                        sub_key: 0,\n                        sims: [],\n                        co_oc: [],\n                        source: \"new\",\n                        isNew: true\n                    };\n                    if (mapping_2.length > 0) {\n                        new_obj.isDone = true;\n                        new_obj.mapping = mapping_2;\n                    }\n                    else {\n                        new_obj.isDone = false;\n                        new_obj.mapping = \"\";\n                        unknown++;\n                    }\n                    this.keyword_mapping[author_key] = new_obj;\n                }\n                else {\n                    var keyword = this.keyword_mapping[author_key];\n                    keyword.count++;\n                    keyword.docs.push(doc);\n                    this.keyword_mapping[author_key] = keyword;\n                }\n            }\n            doc[\"Unknown\"] = unknown;\n            // let temp = new Array();\n            // for (const elem of final) {\n            //     if (elem.length > 0) temp.push({\n            //         tag: elem\n            //     })\n            // }\n            // doc[\"Final\"] = temp;\n        }\n        // Flatten keyword list\n        for (var _q = 0, _r = Object.entries(this.keyword_mapping); _q < _r.length; _q++) {\n            var _s = _r[_q], key = _s[0], value = _s[1];\n            value[\"keyword\"] = key;\n            this.keyword_list.push(value);\n        }\n        var _loop_2 = function (key) {\n            if (key.mapping) {\n                var label = this_1.label_docs.filter(function (x) { return x.label.toLowerCase() == key.mapping.replace(/[^\\w]*/g, \"\").toLowerCase(); });\n                key[\"label\"] = label[0];\n            }\n        };\n        var this_1 = this;\n        // Add label object to keywords\n        for (var _t = 0, _u = this.keyword_list; _t < _u.length; _t++) {\n            var key = _u[_t];\n            _loop_2(key);\n        }\n        // Replace keyword strings with objects\n        for (var _v = 0, _w = this.documents; _v < _w.length; _v++) {\n            var doc = _w[_v];\n            var temp = [];\n            var _loop_3 = function (keyword) {\n                temp.push(this_2.keyword_list.filter(function (e) { return e.keyword == keyword; })[0]);\n            };\n            var this_2 = this;\n            for (var _x = 0, _y = doc[\"Keywords_Processed\"]; _x < _y.length; _x++) {\n                var keyword = _y[_x];\n                _loop_3(keyword);\n            }\n            doc[\"Keywords_Processed\"] = temp;\n            // Check if doc is already done\n            if (temp.every(function (x) { return x[\"mapping\"].length > 0; }))\n                doc[\"isDone\"] = true;\n            var _loop_4 = function (keyword) {\n                for (var _i = 0, temp_3 = temp; _i < temp_3.length; _i++) {\n                    var co = temp_3[_i];\n                    if (keyword != co) {\n                        var found = co.co_oc.find(function (x) { return x.keyword.keyword == keyword.keyword; });\n                        if (found) {\n                            found.count = found.count + 1;\n                        }\n                        else {\n                            co.co_oc.push({\n                                keyword: keyword,\n                                count: 1\n                            });\n                        }\n                    }\n                }\n            };\n            // Build coocurrence information\n            for (var _z = 0, temp_1 = temp; _z < temp_1.length; _z++) {\n                var keyword = temp_1[_z];\n                _loop_4(keyword);\n            }\n        }\n        for (var _0 = 0, _1 = this.labeled_documents; _0 < _1.length; _0++) {\n            var doc = _1[_0];\n            var temp = [];\n            var _loop_5 = function (keyword) {\n                temp.push(this_3.keyword_list.filter(function (e) { return e.keyword == keyword; })[0]);\n            };\n            var this_3 = this;\n            for (var _2 = 0, _3 = doc[\"Keywords_Processed\"]; _2 < _3.length; _2++) {\n                var keyword = _3[_2];\n                _loop_5(keyword);\n            }\n            doc[\"Keywords_Processed\"] = temp;\n            var _loop_6 = function (keyword) {\n                for (var _i = 0, temp_4 = temp; _i < temp_4.length; _i++) {\n                    var co = temp_4[_i];\n                    if (keyword != co) {\n                        var found = co.co_oc.find(function (x) { return x.keyword.keyword == keyword.keyword; });\n                        if (found) {\n                            found.count = found.count + 1;\n                        }\n                        else {\n                            co.co_oc.push({\n                                keyword: keyword,\n                                count: 1\n                            });\n                        }\n                    }\n                }\n            };\n            // Build coocurrence information\n            for (var _4 = 0, temp_2 = temp; _4 < temp_2.length; _4++) {\n                var keyword = temp_2[_4];\n                _loop_6(keyword);\n            }\n        }\n        // Properly format label string\n        for (var _5 = 0, _6 = this.label_docs; _5 < _6.length; _5++) {\n            var label = _6[_5];\n            label.label = label.label.split(/(?=[A-Z])/).join(\" \");\n        }\n        // Properly format label string in keywords\n        for (var _7 = 0, _8 = this.keyword_list; _7 < _8.length; _7++) {\n            var keyword = _8[_7];\n            if (keyword.label.label) {\n                keyword.mapping = keyword.label.label;\n            }\n            else {\n                keyword.mapping = \"\";\n            }\n        }\n        // Precompute tfidf\n        var identifiers = {};\n        for (var _9 = 0, _10 = this.keyword_list; _9 < _10.length; _9++) {\n            var key = _10[_9];\n            var mapping_3 = key.label.label;\n            // let mapping = key.mapping.toLowerCase();\n            // let keyword = key.keyword.replace(\" \", \"SEP\")\n            var keyword = key.keyword;\n            if (identifiers.hasOwnProperty(mapping_3)) {\n                identifiers[mapping_3] = identifiers[mapping_3] + \" \" + keyword;\n            }\n            else {\n                identifiers[mapping_3] = keyword;\n            }\n        }\n        // Add label Terms to the tfidf corpus\n        for (var _11 = 0, _12 = this.label_docs; _11 < _12.length; _11++) {\n            var label = _12[_11];\n            var words = label.label.toLowerCase().split(\" \");\n            var mapping_4 = label.label;\n            for (var _13 = 0, words_1 = words; _13 < words_1.length; _13++) {\n                var keyword = words_1[_13];\n                if (identifiers.hasOwnProperty(mapping_4)) {\n                    identifiers[mapping_4] = identifiers[mapping_4] + \" \" + keyword;\n                }\n                else {\n                    identifiers[mapping_4] = keyword;\n                }\n            }\n        }\n        this.tfidf = new tiny_tfidf__WEBPACK_IMPORTED_MODULE_3__[\"Corpus\"](Object.keys(identifiers), Object.values(identifiers));\n        for (var _14 = 0, _15 = Object.keys(identifiers); _14 < _15.length; _14++) {\n            var key = _15[_14];\n            var terms = this.tfidf.getTopTermsForDocument(key);\n            for (var _16 = 0, terms_1 = terms; _16 < terms_1.length; _16++) {\n                var term = terms_1[_16];\n                var name_1 = term[0];\n                var value = term[1];\n                if (this.tfidf_keywords.hasOwnProperty(name_1)) {\n                    this.tfidf_keywords[name_1].push(value);\n                }\n                else {\n                    var temp = [];\n                    temp.push(value);\n                    this.tfidf_keywords[name_1] = temp;\n                }\n            }\n        }\n        var max_tfidf = 0;\n        for (var _17 = 0, _18 = Object.keys(this.tfidf_keywords); _17 < _18.length; _17++) {\n            var key = _18[_17];\n            var values = this.tfidf_keywords[key];\n            this.tfidf_keywords[key] = values.reduce(function (sum, x) { return sum + x; }) / values.length;\n            if (this.tfidf_keywords[key] > max_tfidf)\n                max_tfidf = this.tfidf_keywords[key];\n        }\n        for (var _19 = 0, _20 = Object.keys(this.tfidf_keywords); _19 < _20.length; _19++) {\n            var key = _20[_19];\n            var value = this.tfidf_keywords[key];\n            this.tfidf_keywords[key] = value / max_tfidf;\n        }\n        // for (const label of this.label_docs) {\n        //     label[\"top_words\"] = this.tfidf.getTopTermsForDocument(label.label.toLowerCase()).map(x => x[0])\n        // }\n        // let sim = new tfidf.Similarity(corpus).getDistanceMatrix()\n        // console.log(tfidf.Similarity.cosineSimilarity(corpus.getDocumentVector(\"document2\"), corpus.getDocumentVector(\"document3\")))\n        // // Distances\n        // console.log(distances.string.levenshtein(\"hamming\", \"haming\"))\n        // console.log(distances.string.jaroWinkler(\"hamming\", \"haming\"))\n        // console.log(distances.string.soundex(\"hamming\", \"haming\"))\n        // // Stemmer\n        // console.log(porter(\"running\"))\n        console.log(this.labeled_documents);\n        console.log(this.documents);\n        console.log(this.keyword_list);\n        console.log(this.label_docs);\n        console.log(this.tfidf_keywords);\n        this.updateDocumentStats();\n        this.updateKeywordStats();\n        this.selectKeyword(this.keyword_list.filter(function (x) { return !x.isDone; })[0]);\n    }\n    // Distance Metrics\n    // cosine_similarity(v1, v2) {\n    //     if (v1 && v2) {\n    //         return Math.abs(Math.dot(v1, v2) / (math.norm(v1) * math.norm(v2)))\n    //     } else {\n    //         return 0\n    //     }\n    // }\n    P0.prototype.jaccard_similarity = function (s1, s2) {\n        // return math.setIntersect(s1, s2).length / math.setUnion(s1, s2).length\n        return lodash__WEBPACK_IMPORTED_MODULE_2__[\"intersection\"](s1, s2).length / lodash__WEBPACK_IMPORTED_MODULE_2__[\"union\"](s1, s2).length;\n    };\n    P0.prototype.jaccard_similarityBy = function (s1, s2, property) {\n        // return math.setIntersect(s1, s2).length / math.setUnion(s1, s2).length\n        return lodash__WEBPACK_IMPORTED_MODULE_2__[\"intersectionBy\"](s1, s2, property).length / lodash__WEBPACK_IMPORTED_MODULE_2__[\"unionBy\"](s1, s2, property).length;\n    };\n    P0.prototype.activate = function () {\n        window.addEventListener('keydown', this.handleKeyInput, false);\n    };\n    P0.prototype.deactivate = function () {\n        window.removeEventListener('keydown', this.handleKeyInput);\n    };\n    P0.prototype.attached = function () {\n        this.selectLabel(this.label_docs[0]);\n    };\n    P0.prototype.selectDocument = function (doc) {\n        this.selected_document = doc;\n    };\n    P0.prototype.selectLabel = function (label) {\n        if (this.selected_label)\n            this.selected_label[\"isActive\"] = false;\n        this.selected_label = label;\n        this.selected_label[\"isActive\"] = true;\n        this.updateSelectedSimilarities(this.selected_keyword);\n        // Update graph\n        // this.createGraphData();\n    };\n    P0.prototype.selectLabelName = function (label_name) {\n        var index = this.label_docs.findIndex(function (x) { return x.label === label_name; });\n        if (index)\n            this.selectLabel(this.label_docs[index]);\n    };\n    P0.prototype.selectKeyword = function (key) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                // Set active keyword\n                if (this.selected_keyword)\n                    this.selected_keyword.isActive = false;\n                key.isActive = true;\n                this.last_selected_keyword = this.selected_keyword;\n                this.selected_keyword = key;\n                this.selected_document = key.docs[0];\n                // this.selected_document_list.push(key.docs[0])\n                this.updateSelectedSimilarities(this.selected_keyword);\n                // Update Labels List\n                this.computeLabelSimilarities(this.label_docs, this.selected_keyword);\n                // this.populateLabels(this.label_docs, this.selected_keyword);\n                // Update graph\n                // this.createGraphData();\n                this.s_words = key.co_oc.filter(function (x) { return !x.keyword.mapping; });\n                return [2 /*return*/];\n            });\n        });\n    };\n    P0.prototype.updateSelectedSimilarities = function (keyword) {\n        // Prepare Document List\n        this.selected_similarities.length = 0;\n        this.selected_similar_keywords = [];\n        var groups = {};\n        if (keyword) {\n            for (var _i = 0, _a = keyword.docs; _i < _a.length; _i++) {\n                var element = _a[_i];\n                this.selected_similarities.push({\n                    document: element,\n                    text_similarity: 0,\n                    hasKeywords: true,\n                    // text_similarity: this.cosine_similarity(this.selected_document[\"Abstract_Vector\"], element[\"Abstract_Vector\"]),\n                    //keyword_similarity: this.jaccard_similarity(this.selected_document[\"Keywords\"], element[\"Keywords\"])\n                    // keyword_similarity: this.cosine_similarity(this.selected_document[\"Keyword_Vector\"], element[\"Keyword_Vector\"])\n                    keyword_similarity: 0\n                });\n            }\n            // Populate similar keywords\n            for (var _b = 0, _c = keyword.co_oc; _b < _c.length; _b++) {\n                var element = _c[_b];\n                // this.selected_similar_keywords.push({\n                //     keyword: element.keyword,\n                //     count: element.keyword.count,\n                //     cooc_sim: this.jaccard_similarityBy(element.keyword.co_oc, this.selected_keyword.co_oc, \"keyword\")\n                // })\n                // Populate groups\n                if (groups.hasOwnProperty(element.keyword.mapping)) {\n                    groups[element.keyword.mapping].push(element.keyword);\n                }\n                else {\n                    var temp = [];\n                    temp.push(element.keyword);\n                    groups[element.keyword.mapping] = temp;\n                }\n            }\n            var _loop_7 = function (key, value) {\n                var norm_key = key; //.replace(/[^A-Za-z0-9]/g, \"\")\n                var label_obj = this_4.label_docs.find(function (x) { return x.label === norm_key; });\n                this_4.selected_similar_keywords.push({\n                    label: norm_key,\n                    label_object: label_obj,\n                    keywords: value,\n                });\n            };\n            var this_4 = this;\n            for (var _d = 0, _e = Object.entries(groups); _d < _e.length; _d++) {\n                var _f = _e[_d], key = _f[0], value = _f[1];\n                _loop_7(key, value);\n            }\n        }\n        // if (this.selected_label) {\n        //     for (const element of this.selected_label.docs) {\n        //         this.selected_similarities.push({\n        //             document: element,\n        //             text_similarity: 0,\n        //             // text_similarity: this.cosine_similarity(this.selected_document[\"Abstract_Vector\"], element[\"Abstract_Vector\"]),\n        //             //keyword_similarity: this.jaccard_similarity(this.selected_document[\"Keywords\"], element[\"Keywords\"])\n        //             // keyword_similarity: this.cosine_similarity(this.selected_document[\"Keyword_Vector\"], element[\"Keyword_Vector\"])\n        //             keyword_similarity: 0\n        //         })\n        //     }\n        // }\n    };\n    P0.prototype.computeKeywordSimilarity = function () {\n        this.label_list.forEach(function (element) {\n            // element[\"Similarity\"] = this.cosine_similarity(this.selected_document[\"Keyword_Vector\"], element[\"Vector\"])\n            element[\"Similarity\"] = 0;\n        });\n    };\n    P0.prototype.computeSimilarities = function () {\n        var _this = this;\n        this.selected_similarities.length = 0;\n        this.documents.forEach(function (element) {\n            _this.selected_similarities.push({\n                document: element,\n                // text_similarity: this.cosine_similarity(this.selected_document[\"Abstract_Vector\"], element[\"Abstract_Vector\"]),\n                text_similarity: 0,\n                hasKeywords: true,\n                //keyword_similarity: this.jaccard_similarity(this.selected_document[\"Keywords\"], element[\"Keywords\"])\n                // keyword_similarity: this.cosine_similarity(this.selected_document[\"Keyword_Vector\"], element[\"Keyword_Vector\"])\n                keyword_similarity: 0\n            });\n        });\n    };\n    P0.prototype.colorConverter = function (num) {\n        if (num > 0.5)\n            return \"#094D08\";\n        else if (num > 0.25)\n            return \"#108C0E\";\n        else if (num > 0)\n            return \"#7CC07B\";\n        else\n            return \"#D8DBDB\";\n    };\n    P0.prototype.colorConverterExplanation = function (num) {\n        if (num > 0.5)\n            return \"#094D08\";\n        else if (num > 0.25)\n            return \"#108C0E\";\n        else\n            return \"#7CC07B\";\n    };\n    P0.prototype.computeLabelSimilarities = function (labels, keyword) {\n        var _loop_8 = function (label) {\n            var substring_dist = 0;\n            var substring_ex = [];\n            var keyword_substring_dist = 0;\n            var keyword_ex = [];\n            var cooc_sim = 0;\n            var cooc_ex = [];\n            var edit_dist = 0;\n            var edit_ex = [];\n            var keywords = keyword.keyword.toLowerCase().split(\" \");\n            var lkw = label.keywords.split(\" \");\n            lkw.push.apply(lkw, label.label.toLowerCase().split(/(?=[A-Z])/));\n            var keyword_list = Array.from(new Set(lkw));\n            for (var _i = 0, keywords_1 = keywords; _i < keywords_1.length; _i++) {\n                var keyword_1 = keywords_1[_i];\n                // Label Substring\n                if (label.label.toLowerCase().includes(keyword_1)) {\n                    substring_dist = substring_dist + this_5.tfidf_keywords[keyword_1];\n                    substring_ex.push({\n                        keyword: keyword_1,\n                        strength: this_5.tfidf_keywords[keyword_1],\n                        color: this_5.colorConverterExplanation(this_5.tfidf_keywords[keyword_1])\n                    });\n                }\n                // Keyword Substring\n                if (label.keywords.toLowerCase().includes(keyword_1)) {\n                    keyword_substring_dist = keyword_substring_dist + this_5.tfidf_keywords[keyword_1];\n                    keyword_ex.push({\n                        keyword: keyword_1,\n                        strength: this_5.tfidf_keywords[keyword_1],\n                        color: this_5.colorConverterExplanation(this_5.tfidf_keywords[keyword_1])\n                    });\n                }\n                // Edit dist\n                for (var _a = 0, keywords_2 = keywords; _a < keywords_2.length; _a++) {\n                    var keyword_2 = keywords_2[_a];\n                    if (keyword_2.length > 3) {\n                        for (var _b = 0, keyword_list_1 = keyword_list; _b < keyword_list_1.length; _b++) {\n                            var kw = keyword_list_1[_b];\n                            var dist = wink_distance__WEBPACK_IMPORTED_MODULE_4__[\"string\"].levenshtein(keyword_2, kw);\n                            if (dist > 0 && dist < 2) {\n                                edit_dist = edit_dist + this_5.tfidf_keywords[keyword_2];\n                                edit_ex.push({\n                                    keyword: keyword_2,\n                                    strength: this_5.tfidf_keywords[keyword_2],\n                                    color: this_5.colorConverterExplanation(this_5.tfidf_keywords[keyword_2])\n                                });\n                            }\n                        }\n                    }\n                }\n            }\n            // Cooc dist\n            var cooc_keywords = keyword.co_oc.filter(function (x) { return x.keyword.label == label; });\n            if (cooc_keywords) {\n                cooc_sim = cooc_keywords.length;\n                for (var _c = 0, cooc_keywords_1 = cooc_keywords; _c < cooc_keywords_1.length; _c++) {\n                    var co = cooc_keywords_1[_c];\n                    cooc_ex.push({\n                        keyword: co.keyword.keyword,\n                        strength: 1 / keyword.co_oc.length,\n                        color: this_5.colorConverterExplanation(1 / keyword.co_oc.length)\n                    });\n                }\n            }\n            // Normalize all values\n            var substring_avg_dist = substring_dist / keywords.length;\n            var substring_avg_dist_keyword = keyword_substring_dist / keywords.length;\n            var edit_norm_sim = edit_dist / keywords.length;\n            var cooc_norm_sim = void 0;\n            if (keyword.co_oc) {\n                cooc_norm_sim = cooc_sim / keyword.co_oc.length;\n            }\n            else {\n                cooc_norm_sim = 0;\n            }\n            // Set all values\n            label[\"substring_similarity\"] = Math.min(substring_avg_dist * 2, 1);\n            label[\"keyword_substring_similarity\"] = Math.min(substring_avg_dist_keyword * 1.5, 1);\n            label[\"edit_distance_similarity\"] = edit_norm_sim;\n            label[\"cooc_similarity\"] = cooc_norm_sim;\n            var temp = [];\n            temp.push({\n                type: \"Label Substring\",\n                color: this_5.colorConverter(label[\"substring_similarity\"]),\n                value: label[\"substring_similarity\"],\n                explanation: substring_ex\n            });\n            temp.push({\n                type: \"Keyword Substring\",\n                color: this_5.colorConverter(label[\"keyword_substring_similarity\"]),\n                value: label[\"keyword_substring_similarity\"],\n                explanation: keyword_ex\n            });\n            temp.push({\n                type: \"Cooccurrent Keywords\",\n                color: this_5.colorConverter(label[\"cooc_similarity\"]),\n                value: label[\"cooc_similarity\"],\n                explanation: cooc_ex\n            });\n            temp.push({\n                type: \"Edit Distance\",\n                color: this_5.colorConverter(label[\"edit_distance_similarity\"]),\n                value: label[\"edit_distance_similarity\"],\n                explanation: edit_ex\n            });\n            label[\"similarities\"] = temp;\n            label[\"total_similarity\"] =\n                label[\"substring_similarity\"] +\n                    label[\"keyword_substring_similarity\"] +\n                    label[\"edit_distance_similarity\"] +\n                    label[\"cooc_similarity\"];\n        };\n        var this_5 = this;\n        // Only compute if not already computed\n        for (var _i = 0, labels_1 = labels; _i < labels_1.length; _i++) {\n            var label = labels_1[_i];\n            _loop_8(label);\n        }\n        // Sort labels list\n        this.label_sort_property = \"\";\n        this.label_sort_property = \"total_similarity\";\n    };\n    P0.prototype.removeAddKeyword = function (keyword) {\n        this.selected_additional_keywords.splice(this.selected_additional_keywords.indexOf(keyword), 1);\n    };\n    P0.prototype.selectAddKeyword = function (keyword) {\n        if (!keyword.isDone) {\n            if (this.selected_additional_keywords.includes(keyword)) {\n                this.removeAddKeyword(keyword);\n            }\n            else {\n                this.selected_additional_keywords.push(keyword);\n            }\n            this.checkKeywordsForDoc();\n        }\n    };\n    P0.prototype.checkKeywordsForDoc = function () {\n        var temp = [];\n        temp.push.apply(temp, __spreadArrays([this.selected_keyword], this.selected_additional_keywords));\n        var _loop_9 = function (doc) {\n            if (temp.every(function (r) { return doc.document[\"Keywords_Processed\"].includes(r); })) {\n                doc.hasKeywords = true;\n            }\n            else {\n                doc.hasKeywords = false;\n            }\n        };\n        for (var _i = 0, _a = this.selected_similarities; _i < _a.length; _i++) {\n            var doc = _a[_i];\n            _loop_9(doc);\n        }\n    };\n    P0.prototype.moveToKeyword = function (key) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.selectKeyword(key)];\n                    case 1:\n                        _a.sent();\n                        if (key.isDone) {\n                            this.selectLabel(key.label);\n                        }\n                        else {\n                            this.selectLabel(this.label_docs[0]);\n                        }\n                        // Reset filter\n                        this.searchDocumentTerm = \"\";\n                        this.searchKeywordsTerm = \"\";\n                        this.searchLabelsTerm = \"\";\n                        // Reset scrolling after applying\n                        this['labelsList'].scrollTop = 0;\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    P0.prototype.skipKeyword = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                // Move current element to the end of the array\n                this.keyword_list.splice(this.keyword_list.indexOf(this.selected_keyword), 1);\n                this.keyword_list.push(this.selected_keyword);\n                // Reset keyword\n                this.selected_keyword.mapping = \"\";\n                this.selected_keyword.label = {};\n                this.selected_keyword.isDone = false;\n                // Reset timing\n                this.keyword_time = 0;\n                // Select next element\n                this.moveToKeyword(this.keyword_list.filter(function (x) { return !x.isDone; })[0]);\n                return [2 /*return*/];\n            });\n        });\n    };\n    P0.prototype.undoKeyword = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var _i, _a, keyword;\n            return __generator(this, function (_b) {\n                // Reset last element\n                this.last_selected_keyword.mapping = \"\";\n                this.last_selected_keyword.label = {};\n                this.last_selected_keyword.isDone = false;\n                // Reset timing\n                this.keyword_time = 0;\n                // Reset additional keyword\n                if (this.last_selected_additional_keywords) {\n                    for (_i = 0, _a = this.last_selected_additional_keywords; _i < _a.length; _i++) {\n                        keyword = _a[_i];\n                        keyword.mapping = \"\";\n                        keyword.label = {};\n                        keyword.isDone = false;\n                    }\n                    this.last_selected_additional_keywords = [];\n                }\n                // Select last element\n                this.moveToKeyword(this.keyword_list.filter(function (x) { return !x.isDone; })[0]);\n                return [2 /*return*/];\n            });\n        });\n    };\n    P0.prototype.applyLabel = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var div, time_fraction, _i, _a, keyword, _b, _c, doc, _d, _e, doc;\n            return __generator(this, function (_f) {\n                this.selected_keyword.mapping = this.selected_label.label;\n                this.selected_keyword.label = this.selected_label;\n                this.selected_keyword.isDone = true;\n                this.last_selected_additional_keywords = [];\n                div = 0;\n                if (this.selected_additional_keywords)\n                    div = this.selected_additional_keywords.length;\n                time_fraction = Math.ceil(this.keyword_time / (div + 1));\n                this.selected_keyword[\"time\"] = time_fraction;\n                if (this.selected_additional_keywords) {\n                    for (_i = 0, _a = this.selected_additional_keywords; _i < _a.length; _i++) {\n                        keyword = _a[_i];\n                        keyword.mapping = this.selected_label.label;\n                        keyword.label = this.selected_label;\n                        keyword.isDone = true;\n                        keyword[\"time\"] = time_fraction;\n                        this.last_selected_additional_keywords.push(keyword);\n                    }\n                    this.selected_additional_keywords = [];\n                }\n                this.keyword_time = 0;\n                // Check if its done\n                if (this.keywords_todo <= 1) {\n                    this.finished = true;\n                    this.updateDocumentStats();\n                    for (_b = 0, _c = this.documents; _b < _c.length; _b++) {\n                        doc = _c[_b];\n                        if (doc[\"Keywords_Processed\"].every(function (x) { return x[\"isDone\"]; }))\n                            doc[\"isDone\"] = true;\n                    }\n                    this.updateKeywordStats();\n                }\n                // Update keyword list view\n                // this.finishedKeywords = !this.finishedKeywords;\n                // this.finishedKeywords = !this.finishedKeywords;\n                // this.selected_keyword = this.keyword_list.filter(x => !x.isDone)[0]\n                // let index = this.keyword_list.indexOf(this.selected_keyword)\n                this.moveToKeyword(this.keyword_list.filter(function (x) { return !x.isDone; })[0]);\n                // await this.selectKeyword(this.keyword_list.filter(x => !x.isDone)[0])\n                // this.selectLabel(this.label_docs[0])\n                this.updateKeywordStats();\n                // Check if some documents are now finished\n                for (_d = 0, _e = this.documents; _d < _e.length; _d++) {\n                    doc = _e[_d];\n                    if (doc[\"Keywords_Processed\"].every(function (x) { return x[\"isDone\"]; }))\n                        doc[\"isDone\"] = true;\n                }\n                this.updateDocumentStats();\n                return [2 /*return*/];\n            });\n        });\n    };\n    P0.prototype.download = function () {\n        this.downloadKeywords();\n        this.downloadData();\n    };\n    P0.prototype.downloadData = function () {\n        var rows = [\n            [\"title\", \"keywords\", \"authors\", \"doi\", \"labels\"]\n        ];\n        for (var _i = 0, _a = this.documents; _i < _a.length; _i++) {\n            var doc = _a[_i];\n            var labels = lodash__WEBPACK_IMPORTED_MODULE_2__[\"uniq\"](doc[\"Keywords_Processed\"].map(function (x) { return x.mapping; }).filter(function (x) { return x.length > 0; })).join(\";\").replace(/,/g, \";\");\n            var keywords = \"\";\n            if (doc[\"Keywords\"])\n                keywords = doc[\"Keywords\"].replace(/,/g, \";\");\n            rows.push([\n                \"\\\"\" + doc[\"Title\"].replace(/,/g, \";\") + \"\\\"\",\n                \"\\\"\" + keywords + \"\\\"\",\n                \"\\\"\" + doc[\"Authors\"].replace(/,/g, \";\") + \"\\\"\",\n                \"\\\"\" + doc[\"DOI\"] + \"\\\"\",\n                \"\\\"\" + labels + \"\\\"\"\n            ]);\n        }\n        var csvContent = \"data:text/csv;charset=utf-8,\"\n            + rows.map(function (e) { return e.join(\",\"); }).join(\"\\n\");\n        // var encodedUri = encodeURI(csvContent);\n        // window.open(encodedUri);\n        var encodedUri = encodeURI(csvContent);\n        var link = document.createElement(\"a\");\n        link.setAttribute(\"href\", encodedUri);\n        link.setAttribute(\"download\", \"labeled_data.csv\");\n        document.body.appendChild(link);\n        link.click();\n    };\n    P0.prototype.downloadKeywords = function () {\n        var rows = [\n            [\"keyword\", \"label\", \"time\"]\n        ];\n        for (var _i = 0, _a = this.keyword_list.filter(function (x) { return x[\"source\"] == \"new\"; }); _i < _a.length; _i++) {\n            var keyword = _a[_i];\n            rows.push([\n                \"\\\"\" + keyword.keyword + \"\\\"\",\n                \"\\\"\" + keyword.mapping + \"\\\"\",\n                keyword.time\n            ]);\n        }\n        var csvContent = \"data:text/csv;charset=utf-8,\"\n            + rows.map(function (e) { return e.join(\",\"); }).join(\"\\n\");\n        // var encodedUri = encodeURI(csvContent);\n        // window.open(encodedUri);\n        var encodedUri = encodeURI(csvContent);\n        var link = document.createElement(\"a\");\n        link.setAttribute(\"href\", encodedUri);\n        link.setAttribute(\"download\", \"keyword_data.csv\");\n        document.body.appendChild(link);\n        link.click();\n    };\n    P0.prototype.checkActiveKeyword = function (keyword) {\n        if (this.selected_keyword) {\n            if (this.selected_keyword === keyword)\n                return 0;\n            else\n                return 1;\n        }\n    };\n    P0.prototype.removeKeyword = function (keyword) {\n        this.selected_document[\"Final\"] = this.selected_document[\"Final\"]\n            .filter(function (item) { return item !== keyword; });\n    };\n    P0.prototype.addKeyword = function (keyword) {\n        this.selected_document[\"Final\"] = this.selected_document[\"Final\"]\n            .concat({\n            tag: keyword\n        });\n    };\n    P0.prototype.filterKeywordsFunc = function (searchExpression, value) {\n        var itemValue = value[\"keyword\"];\n        if (!searchExpression || !itemValue)\n            return false;\n        return itemValue.toUpperCase().indexOf(searchExpression.toUpperCase()) !== -1;\n    };\n    P0.prototype.filterLabelsFunc = function (searchExpression, value) {\n        var itemValue = value[\"label\"];\n        if (!searchExpression || !itemValue)\n            return false;\n        return itemValue.toUpperCase().indexOf(searchExpression.toUpperCase()) !== -1;\n    };\n    P0.prototype.filterDocumentsFunc = function (searchExpression, value) {\n        var itemValue = value.document[\"Title\"];\n        if (!searchExpression || !itemValue)\n            return false;\n        return itemValue.toUpperCase().indexOf(searchExpression.toUpperCase()) !== -1;\n    };\n    P0.prototype.updateDocumentStats = function () {\n        this.docs_todo = this.documents.filter(function (x) { return !x.isDone; }).length;\n        this.docs_done = this.documents.filter(function (x) { return x.isDone; }).length;\n        this.docs_per = 1 - (this.docs_todo / this.documents.length);\n    };\n    P0.prototype.updateKeywordStats = function () {\n        var ll = this.keyword_list.filter(function (x) { return x[\"source\"] == \"new\"; });\n        this.keywords_todo = ll.filter(function (x) { return !x[\"isDone\"]; }).length;\n        this.keywords_done = ll.filter(function (x) { return x[\"isDone\"]; }).length;\n        this.keywords_per = 1 - (this.keywords_todo / ll.length);\n    };\n    P0.prototype.startTimer = function () {\n        var _this = this;\n        if (!this.timerActive) {\n            this.timerActive = true;\n            // Call every second\n            this.timer = setInterval(function (x) {\n                _this.time++;\n                _this.keyword_time++;\n            }, 1000);\n        }\n    };\n    P0.prototype.endTimer = function () {\n        // Stop timer\n        clearInterval(this.timer);\n        this.timerActive = false;\n        this.time = 0;\n        this.keyword_time = 0;\n    };\n    P0 = __decorate([\n        Object(aurelia_dependency_injection__WEBPACK_IMPORTED_MODULE_0__[\"autoinject\"])(),\n        __metadata(\"design:paramtypes\", [data_store__WEBPACK_IMPORTED_MODULE_1__[\"DataStore\"]])\n    ], P0);\n    return P0;\n}());\n\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! bluebird */ \"./node_modules/bluebird/js/browser/bluebird.js-exposed\")))//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,{"version":3,"file":"pages/p0.js","sources":["webpack:///./src/pages/p0.ts?e519"],"sourcesContent":["import {\r\n    autoinject\r\n} from 'aurelia-dependency-injection';\r\nimport {\r\n    DataStore\r\n} from 'data-store';\r\nimport * as _ from 'lodash';\r\nimport { computedFrom } from 'aurelia-framework';\r\nimport * as tfidf from 'tiny-tfidf';\r\nimport * as porter from 'wink-porter2-stemmer';\r\nimport * as distances from 'wink-distance';\r\n\r\n@autoinject()\r\nexport class P0 {\r\n    public documents;\r\n    public labeled_documents;\r\n    public label_list;\r\n    public label_docs;\r\n    public keyword_list;\r\n    public keyword_mapping;\r\n    public autocompleteData = {};\r\n\r\n    // Filter\r\n    public searchKeywordsTerm = \"\";\r\n    public finishedKeywords = false;\r\n    public searchLabelsTerm = \"\";\r\n    public searchDocumentTerm = \"\";\r\n\r\n    // Selection\r\n    public selected_document_list = [];\r\n    public selected_document;\r\n    public selected_keyword;\r\n    public last_selected_keyword;\r\n    public selected_additional_keywords = [];\r\n    public last_selected_additional_keywords = [];\r\n    public selected_label;\r\n    public showDocuments = false;\r\n    public selected_similarities = [];\r\n    public selected_similar_keywords = [];\r\n    public s_words = [];\r\n\r\n    // Similarity list\r\n    public sim_property = \"text_similarity\";\r\n    public key_property = \"highest_value\";\r\n    public label_sort_property = \"total_similarity\";\r\n    public label_sort_value = 0;\r\n\r\n    // Status variables\r\n    public finished = false;\r\n    public docs_todo = 0;\r\n    public docs_done = 0;\r\n    public docs_per = 0;\r\n    public keywords_todo = 0;\r\n    public keywords_done = 0;\r\n    public keywords_per = 0;\r\n\r\n    // NLP\r\n    public tfidf;\r\n    public tfidf_keywords = {};\r\n\r\n    // Time\r\n    public time = 0;\r\n    public keyword_time = 0;\r\n    public timerActive = false;\r\n    public timer;\r\n\r\n    // Temp variables\r\n    public sort_property = \"descending\";\r\n    public graph_data;\r\n\r\n    // Distance Metrics\r\n    // cosine_similarity(v1, v2) {\r\n    //     if (v1 && v2) {\r\n    //         return Math.abs(Math.dot(v1, v2) / (math.norm(v1) * math.norm(v2)))\r\n    //     } else {\r\n    //         return 0\r\n    //     }\r\n    // }\r\n\r\n    jaccard_similarity(s1, s2) {\r\n        // return math.setIntersect(s1, s2).length / math.setUnion(s1, s2).length\r\n        return _.intersection(s1, s2).length / _.union(s1, s2).length\r\n    }\r\n\r\n    jaccard_similarityBy(s1, s2, property) {\r\n        // return math.setIntersect(s1, s2).length / math.setUnion(s1, s2).length\r\n        return _.intersectionBy(s1, s2, property).length / _.unionBy(s1, s2, property).length\r\n    }\r\n\r\n    activate() {\r\n        window.addEventListener('keydown', this.handleKeyInput, false);\r\n    }\r\n\r\n    deactivate() {\r\n        window.removeEventListener('keydown', this.handleKeyInput);\r\n    }\r\n\r\n    handleKeyInput = (event) => {\r\n        if (event.key == \"Enter\" && this.selected_label) {\r\n            this.throttled_applyLabel();\r\n        }\r\n\r\n        if (event.key == \"ArrowDown\" && this.selected_label) {\r\n            let index = this.label_docs.findIndex(x => x.label == this.selected_label.label)\r\n            this.selectLabel(this.label_docs[Math.min(index + 1, this.label_docs.length - 1)])\r\n        }\r\n\r\n        if (event.key == \"ArrowUp\" && this.selected_label) {\r\n            let index = this.label_docs.findIndex(x => x.label == this.selected_label.label)\r\n            this.selectLabel(this.label_docs[Math.max(index - 1, 0)])\r\n        }\r\n\r\n        if (event.key == \"ArrowRight\" && this.selected_label) {\r\n            this.skipKeyword();\r\n        }\r\n\r\n        if (event.key == \"ArrowLeft\" && this.selected_label) {\r\n            this.undoKeyword();\r\n        }\r\n    }\r\n\r\n    constructor(public store: DataStore) {\r\n        this.documents = store.getNew();\r\n        this.labeled_documents = store.getLabeled();\r\n        this.label_list = store.getClasses();\r\n        let mapping = store.getMapping();\r\n\r\n        this.label_docs = {}\r\n        this.keyword_mapping = {}\r\n        this.keyword_list = []\r\n\r\n        // Initialize the label document mapping\r\n        for (const label of this.label_list) {\r\n            this.label_docs[label[\"Cluster\"]] = []\r\n        }\r\n\r\n        // Add missing unclear label\r\n        this.label_docs[\"Unclear\"] = [];\r\n\r\n        for (const doc of this.labeled_documents) {\r\n            for (const label of doc[\"Clusters\"].split(\";\")) {\r\n                if (this.label_docs.hasOwnProperty(label)) {\r\n                    let doc_list = this.label_docs[label]\r\n                    doc_list.push(doc)\r\n                    this.label_docs[label] = doc_list\r\n                }\r\n            }\r\n\r\n            // TODO: fix casing in preprocessing\r\n            doc[\"Keywords_Processed\"] = doc[\"Keywords_Processed\"].toLowerCase().split(\";\");\r\n\r\n            for (const author_key of doc[\"Keywords_Processed\"]) {\r\n                if (!this.keyword_mapping.hasOwnProperty(author_key)) {\r\n                    let mapping = this.store.getKeywordMapping(author_key).replace(\",\", \"\");\r\n\r\n                    if (mapping.length > 0) {\r\n                        this.keyword_mapping[author_key] = {\r\n                            mapping: mapping,\r\n                            label: {},\r\n                            count: 1,\r\n                            isActive: false,\r\n                            docs: [doc],\r\n                            isDone: true,\r\n                            highest_property: \"\",\r\n                            highest_value: 0,\r\n                            sub_label: 0,\r\n                            sub_key: 0,\r\n                            sims: [],\r\n                            co_oc: [],\r\n                            source: \"db\",\r\n                            isNew: false,\r\n                        }\r\n                    }\r\n                    else {\r\n                        console.log(author_key)\r\n                        this.keyword_mapping[author_key] = {\r\n                            mapping: \"ERROR IN PREPROCEING\",\r\n                            label: {},\r\n                            count: 1,\r\n                            isActive: false,\r\n                            docs: [doc],\r\n                            isDone: true,\r\n                            highest_property: \"\",\r\n                            highest_value: 0,\r\n                            sub_label: 0,\r\n                            sub_key: 0,\r\n                            sims: [],\r\n                            co_oc: [],\r\n                            source: \"db\",\r\n                            isNew: false\r\n                        }\r\n                    }\r\n                } else {\r\n                    let keyword = this.keyword_mapping[author_key];\r\n                    keyword.count++;\r\n                    keyword.docs.push(doc)\r\n                    this.keyword_mapping[author_key] = keyword\r\n                }\r\n            }\r\n\r\n            doc[\"type\"] = \"old\";\r\n        }\r\n\r\n\r\n        let temp_labels = new Array();\r\n\r\n        for (let [key, value] of Object.entries(this.label_docs)) {\r\n            let o = {}\r\n            let keywords = []\r\n\r\n            o[\"label\"] = key\r\n            o[\"docs\"] = value\r\n            o[\"n_docs\"] = o[\"docs\"].length\r\n            o[\"substring_similarity\"] = 0.0\r\n            o[\"keyword_avg_similarity\"] = 0.0\r\n            o[\"total_similarity\"] = 0.0\r\n            o[\"isActive\"] = false\r\n\r\n\r\n            for (let [k, l] of Object.entries(_.pickBy(mapping, x => x === key))) {\r\n                keywords.push(k)\r\n            }\r\n\r\n            o[\"keywords\"] = keywords.join(\" \")\r\n\r\n            temp_labels.push(o)\r\n        }\r\n\r\n        this.label_docs = temp_labels\r\n\r\n        for (const doc of this.documents) {\r\n            let unknown = 0;\r\n\r\n            // if (!doc[\"Keywords_Processed\"]) {\r\n            //     doc[\"Keywords_Processed\"] = \"\"\r\n            // }\r\n\r\n            doc[\"DOI\"] = \"https://doi.org/\" + doc[\"DOI\"]\r\n            doc[\"type\"] = \"new\"\r\n\r\n            // Create final keywords field\r\n            // TODO: fix casing in preprocessing\r\n            doc[\"Keywords_Processed\"] = doc[\"Keywords_Processed\"].toLowerCase().split(\";\");\r\n\r\n            // // Populate final keyword list\r\n            // let final = doc[\"Keywords_Processed\"]\r\n            //     // .map(x => this.store.getKeywordMapping(x).replace(/[^a-zA-Z]/g, \"\"))\r\n            //     .map(x => this.store.getKeywordMapping(x))\r\n            // // .filter(x => x !== \"unclear\");\r\n\r\n            // final = _.uniq(final);\r\n\r\n            for (const author_key of doc[\"Keywords_Processed\"]) {\r\n                if (!this.keyword_mapping.hasOwnProperty(author_key)) {\r\n                    let mapping = this.store.getKeywordMapping(author_key);\r\n                    let new_obj = {\r\n                        mapping: \"\",\r\n                        label: {},\r\n                        count: 1,\r\n                        isActive: false,\r\n                        docs: [doc],\r\n                        isDone: false,\r\n                        highest_property: \"\",\r\n                        highest_value: 0,\r\n                        sub_label: 0,\r\n                        sub_key: 0,\r\n                        sims: [],\r\n                        co_oc: [],\r\n                        source: \"new\",\r\n                        isNew: true\r\n                    }\r\n\r\n                    if (mapping.length > 0) {\r\n                        new_obj.isDone = true\r\n                        new_obj.mapping = mapping\r\n                    }\r\n                    else {\r\n                        new_obj.isDone = false\r\n                        new_obj.mapping = \"\"\r\n                        unknown++;\r\n                    }\r\n\r\n                    this.keyword_mapping[author_key] = new_obj;\r\n\r\n                } else {\r\n                    let keyword = this.keyword_mapping[author_key];\r\n                    keyword.count++;\r\n                    keyword.docs.push(doc)\r\n                    this.keyword_mapping[author_key] = keyword\r\n                }\r\n            }\r\n\r\n            doc[\"Unknown\"] = unknown;\r\n\r\n            // let temp = new Array();\r\n\r\n            // for (const elem of final) {\r\n            //     if (elem.length > 0) temp.push({\r\n            //         tag: elem\r\n            //     })\r\n            // }\r\n\r\n            // doc[\"Final\"] = temp;\r\n        }\r\n\r\n        // Flatten keyword list\r\n        for (let [key, value] of Object.entries(this.keyword_mapping)) {\r\n            value[\"keyword\"] = key\r\n            this.keyword_list.push(value)\r\n        }\r\n\r\n        // Add label object to keywords\r\n        for (const key of this.keyword_list) {\r\n            if (key.mapping) {\r\n                let label = this.label_docs.filter(x => x.label.toLowerCase() == key.mapping.replace(/[^\\w]*/g, \"\").toLowerCase())\r\n\r\n                key[\"label\"] = label[0]\r\n            }\r\n        }\r\n\r\n        // Replace keyword strings with objects\r\n        for (const doc of this.documents) {\r\n            let temp = []\r\n            for (const keyword of doc[\"Keywords_Processed\"]) {\r\n                temp.push(this.keyword_list.filter(e => e.keyword == keyword)[0])\r\n            }\r\n            doc[\"Keywords_Processed\"] = temp\r\n\r\n            // Check if doc is already done\r\n            if (temp.every(x => x[\"mapping\"].length > 0)) doc[\"isDone\"] = true;\r\n\r\n            // Build coocurrence information\r\n            for (const keyword of temp) {\r\n                for (const co of temp) {\r\n                    if (keyword != co) {\r\n                        let found = co.co_oc.find(x => x.keyword.keyword == keyword.keyword)\r\n\r\n                        if (found) {\r\n                            found.count = found.count + 1\r\n                        }\r\n                        else {\r\n                            co.co_oc.push({\r\n                                keyword: keyword,\r\n                                count: 1\r\n                            })\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        for (const doc of this.labeled_documents) {\r\n            let temp = []\r\n            for (const keyword of doc[\"Keywords_Processed\"]) {\r\n                temp.push(this.keyword_list.filter(e => e.keyword == keyword)[0])\r\n            }\r\n            doc[\"Keywords_Processed\"] = temp\r\n\r\n            // Build coocurrence information\r\n            for (const keyword of temp) {\r\n                for (const co of temp) {\r\n                    if (keyword != co) {\r\n                        let found = co.co_oc.find(x => x.keyword.keyword == keyword.keyword)\r\n\r\n                        if (found) {\r\n                            found.count = found.count + 1\r\n                        }\r\n                        else {\r\n                            co.co_oc.push({\r\n                                keyword: keyword,\r\n                                count: 1\r\n                            })\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n\r\n        // Properly format label string\r\n        for (const label of this.label_docs) {\r\n            label.label = label.label.split(/(?=[A-Z])/).join(\" \")\r\n        }\r\n\r\n        // Properly format label string in keywords\r\n        for (const keyword of this.keyword_list) {\r\n            if (keyword.label.label) {\r\n                keyword.mapping = keyword.label.label\r\n            }\r\n            else {\r\n                keyword.mapping = \"\"\r\n            }\r\n        }\r\n\r\n        // Precompute tfidf\r\n        let identifiers = {}\r\n\r\n        for (const key of this.keyword_list) {\r\n            let mapping = key.label.label;\r\n            // let mapping = key.mapping.toLowerCase();\r\n            // let keyword = key.keyword.replace(\" \", \"SEP\")\r\n            let keyword = key.keyword\r\n\r\n            if (identifiers.hasOwnProperty(mapping)) {\r\n\r\n                identifiers[mapping] = identifiers[mapping] + \" \" + keyword\r\n            }\r\n            else {\r\n                identifiers[mapping] = keyword\r\n            }\r\n\r\n        }\r\n\r\n        // Add label Terms to the tfidf corpus\r\n        for (const label of this.label_docs) {\r\n            let words = label.label.toLowerCase().split(\" \")\r\n            let mapping = label.label;\r\n\r\n            for (const keyword of words) {\r\n                if (identifiers.hasOwnProperty(mapping)) {\r\n\r\n                    identifiers[mapping] = identifiers[mapping] + \" \" + keyword\r\n                }\r\n                else {\r\n                    identifiers[mapping] = keyword\r\n                }\r\n            }\r\n        }\r\n\r\n        this.tfidf = new tfidf.Corpus(\r\n            Object.keys(identifiers),\r\n            Object.values(identifiers),\r\n        );\r\n\r\n        for (const key of Object.keys(identifiers)) {\r\n            let terms = this.tfidf.getTopTermsForDocument(key)\r\n\r\n            for (const term of terms) {\r\n                let name = term[0]\r\n                let value = term[1]\r\n\r\n                if (this.tfidf_keywords.hasOwnProperty(name)) {\r\n                    this.tfidf_keywords[name].push(value)\r\n                } else {\r\n                    let temp = []\r\n                    temp.push(value)\r\n                    this.tfidf_keywords[name] = temp\r\n                }\r\n            }\r\n        }\r\n\r\n        let max_tfidf = 0;\r\n\r\n        for (const key of Object.keys(this.tfidf_keywords)) {\r\n            let values = this.tfidf_keywords[key]\r\n            this.tfidf_keywords[key] = values.reduce((sum, x) => sum + x) / values.length;\r\n\r\n            if (this.tfidf_keywords[key] > max_tfidf) max_tfidf = this.tfidf_keywords[key]\r\n        }\r\n\r\n        for (const key of Object.keys(this.tfidf_keywords)) {\r\n            let value = this.tfidf_keywords[key]\r\n            this.tfidf_keywords[key] = value / max_tfidf;\r\n        }\r\n\r\n        // for (const label of this.label_docs) {\r\n        //     label[\"top_words\"] = this.tfidf.getTopTermsForDocument(label.label.toLowerCase()).map(x => x[0])\r\n        // }\r\n\r\n        // let sim = new tfidf.Similarity(corpus).getDistanceMatrix()\r\n        // console.log(tfidf.Similarity.cosineSimilarity(corpus.getDocumentVector(\"document2\"), corpus.getDocumentVector(\"document3\")))\r\n\r\n\r\n        // // Distances\r\n        // console.log(distances.string.levenshtein(\"hamming\", \"haming\"))\r\n        // console.log(distances.string.jaroWinkler(\"hamming\", \"haming\"))\r\n        // console.log(distances.string.soundex(\"hamming\", \"haming\"))\r\n\r\n        // // Stemmer\r\n        // console.log(porter(\"running\"))\r\n\r\n        console.log(this.labeled_documents)\r\n        console.log(this.documents)\r\n        console.log(this.keyword_list)\r\n        console.log(this.label_docs)\r\n        console.log(this.tfidf_keywords)\r\n\r\n        this.updateDocumentStats();\r\n        this.updateKeywordStats();\r\n\r\n        this.selectKeyword(this.keyword_list.filter(x => !x.isDone)[0])\r\n    }\r\n\r\n    attached() {\r\n        this.selectLabel(this.label_docs[0])\r\n    }\r\n\r\n    selectDocument(doc) {\r\n        this.selected_document = doc;\r\n    }\r\n\r\n    selectLabel(label) {\r\n        if (this.selected_label) this.selected_label[\"isActive\"] = false;\r\n        this.selected_label = label\r\n        this.selected_label[\"isActive\"] = true\r\n\r\n        this.updateSelectedSimilarities(this.selected_keyword);\r\n\r\n        // Update graph\r\n        // this.createGraphData();\r\n    }\r\n\r\n    selectLabelName(label_name) {\r\n        let index = this.label_docs.findIndex(x => x.label === label_name)\r\n\r\n        if (index) this.selectLabel(this.label_docs[index])\r\n    }\r\n\r\n    async selectKeyword(key) {\r\n        // Set active keyword\r\n        if (this.selected_keyword) this.selected_keyword.isActive = false;\r\n        key.isActive = true;\r\n\r\n        this.last_selected_keyword = this.selected_keyword;\r\n        this.selected_keyword = key;\r\n        this.selected_document = key.docs[0]\r\n        // this.selected_document_list.push(key.docs[0])\r\n\r\n        this.updateSelectedSimilarities(this.selected_keyword);\r\n\r\n        // Update Labels List\r\n        this.computeLabelSimilarities(this.label_docs, this.selected_keyword);\r\n        // this.populateLabels(this.label_docs, this.selected_keyword);\r\n\r\n        // Update graph\r\n        // this.createGraphData();\r\n        this.s_words = key.co_oc.filter(x => !x.keyword.mapping)\r\n\r\n        // if (key.label) {\r\n        //     this.selectLabel(key.label)\r\n        // }\r\n        // else {\r\n        //     this.selectLabel(this.label_docs[0])\r\n        // }\r\n\r\n        // // Reset filter\r\n        // this.searchDocumentTerm = \"\"\r\n        // this.searchKeywordsTerm = \"\"\r\n        // this.searchLabelsTerm = \"\"\r\n\r\n        // // Reset scrolling after applying\r\n        // this['labelsList'].scrollTop = 0;\r\n    }\r\n\r\n    updateSelectedSimilarities(keyword) {\r\n        // Prepare Document List\r\n        this.selected_similarities.length = 0;\r\n        this.selected_similar_keywords = [];\r\n        let groups = {}\r\n\r\n        if (keyword) {\r\n            for (const element of keyword.docs) {\r\n                this.selected_similarities.push({\r\n                    document: element,\r\n                    text_similarity: 0,\r\n                    hasKeywords: true,\r\n                    // text_similarity: this.cosine_similarity(this.selected_document[\"Abstract_Vector\"], element[\"Abstract_Vector\"]),\r\n                    //keyword_similarity: this.jaccard_similarity(this.selected_document[\"Keywords\"], element[\"Keywords\"])\r\n                    // keyword_similarity: this.cosine_similarity(this.selected_document[\"Keyword_Vector\"], element[\"Keyword_Vector\"])\r\n                    keyword_similarity: 0\r\n                })\r\n            }\r\n\r\n            // Populate similar keywords\r\n            for (const element of keyword.co_oc) {\r\n                // this.selected_similar_keywords.push({\r\n                //     keyword: element.keyword,\r\n                //     count: element.keyword.count,\r\n                //     cooc_sim: this.jaccard_similarityBy(element.keyword.co_oc, this.selected_keyword.co_oc, \"keyword\")\r\n                // })\r\n\r\n                // Populate groups\r\n                if (groups.hasOwnProperty(element.keyword.mapping)) {\r\n                    groups[element.keyword.mapping].push(element.keyword)\r\n                }\r\n                else {\r\n                    let temp = []\r\n                    temp.push(element.keyword)\r\n                    groups[element.keyword.mapping] = temp\r\n                }\r\n            }\r\n\r\n            for (const [key, value] of Object.entries(groups)) {\r\n                let norm_key = key//.replace(/[^A-Za-z0-9]/g, \"\")\r\n                let label_obj = this.label_docs.find(x => x.label === norm_key)\r\n                this.selected_similar_keywords.push({\r\n                    label: norm_key,\r\n                    label_object: label_obj,\r\n                    keywords: value,\r\n                })\r\n            }\r\n        }\r\n\r\n        // if (this.selected_label) {\r\n        //     for (const element of this.selected_label.docs) {\r\n        //         this.selected_similarities.push({\r\n        //             document: element,\r\n        //             text_similarity: 0,\r\n        //             // text_similarity: this.cosine_similarity(this.selected_document[\"Abstract_Vector\"], element[\"Abstract_Vector\"]),\r\n        //             //keyword_similarity: this.jaccard_similarity(this.selected_document[\"Keywords\"], element[\"Keywords\"])\r\n        //             // keyword_similarity: this.cosine_similarity(this.selected_document[\"Keyword_Vector\"], element[\"Keyword_Vector\"])\r\n        //             keyword_similarity: 0\r\n        //         })\r\n        //     }\r\n        // }\r\n    }\r\n\r\n    computeKeywordSimilarity() {\r\n        this.label_list.forEach(element => {\r\n            // element[\"Similarity\"] = this.cosine_similarity(this.selected_document[\"Keyword_Vector\"], element[\"Vector\"])\r\n            element[\"Similarity\"] = 0\r\n        });\r\n    }\r\n\r\n    computeSimilarities() {\r\n        this.selected_similarities.length = 0;\r\n        this.documents.forEach(element => {\r\n            this.selected_similarities.push({\r\n                document: element,\r\n                // text_similarity: this.cosine_similarity(this.selected_document[\"Abstract_Vector\"], element[\"Abstract_Vector\"]),\r\n                text_similarity: 0,\r\n                hasKeywords: true,\r\n                //keyword_similarity: this.jaccard_similarity(this.selected_document[\"Keywords\"], element[\"Keywords\"])\r\n                // keyword_similarity: this.cosine_similarity(this.selected_document[\"Keyword_Vector\"], element[\"Keyword_Vector\"])\r\n                keyword_similarity: 0\r\n            })\r\n        });\r\n    }\r\n\r\n    colorConverter(num: number) {\r\n        if (num > 0.5) return \"#094D08\"\r\n        else if (num > 0.25) return \"#108C0E\"\r\n        else if (num > 0) return \"#7CC07B\"\r\n        else return \"#D8DBDB\"\r\n    }\r\n\r\n    colorConverterExplanation(num: number) {\r\n        if (num > 0.5) return \"#094D08\"\r\n        else if (num > 0.25) return \"#108C0E\"\r\n        else return \"#7CC07B\"\r\n    }\r\n\r\n    computeLabelSimilarities(labels, keyword) {\r\n        // Only compute if not already computed\r\n        for (let label of labels) {\r\n            let substring_dist = 0\r\n            let substring_ex = []\r\n            let keyword_substring_dist = 0\r\n            let keyword_ex = []\r\n            let cooc_sim = 0\r\n            let cooc_ex = []\r\n            let edit_dist = 0\r\n            let edit_ex = []\r\n\r\n            let keywords = keyword.keyword.toLowerCase().split(\" \");\r\n\r\n            let lkw = label.keywords.split(\" \")\r\n            lkw.push(...label.label.toLowerCase().split(/(?=[A-Z])/));\r\n\r\n            let keyword_list = Array.from(new Set(lkw))\r\n\r\n            for (const keyword of keywords) {\r\n                // Label Substring\r\n                if (label.label.toLowerCase().includes(keyword)) {\r\n                    substring_dist = substring_dist + this.tfidf_keywords[keyword]\r\n                    substring_ex.push({\r\n                        keyword: keyword,\r\n                        strength: this.tfidf_keywords[keyword],\r\n                        color: this.colorConverterExplanation(this.tfidf_keywords[keyword])\r\n                    })\r\n                }\r\n\r\n                // Keyword Substring\r\n                if (label.keywords.toLowerCase().includes(keyword)) {\r\n                    keyword_substring_dist = keyword_substring_dist + this.tfidf_keywords[keyword]\r\n                    keyword_ex.push({\r\n                        keyword: keyword,\r\n                        strength: this.tfidf_keywords[keyword],\r\n                        color: this.colorConverterExplanation(this.tfidf_keywords[keyword])\r\n                    })\r\n                }\r\n\r\n                // Edit dist\r\n                for (const keyword of keywords) {\r\n                    if (keyword.length > 3) {\r\n                        for (const kw of keyword_list) {\r\n                            let dist = distances.string.levenshtein(keyword, kw)\r\n\r\n                            if (dist > 0 && dist < 2) {\r\n                                edit_dist = edit_dist + this.tfidf_keywords[keyword]\r\n                                edit_ex.push({\r\n                                    keyword: keyword,\r\n                                    strength: this.tfidf_keywords[keyword],\r\n                                    color: this.colorConverterExplanation(this.tfidf_keywords[keyword])\r\n                                })\r\n                            }\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n\r\n            // Cooc dist\r\n            let cooc_keywords = keyword.co_oc.filter(x => x.keyword.label == label)\r\n            if (cooc_keywords) {\r\n                cooc_sim = cooc_keywords.length\r\n\r\n                for (const co of cooc_keywords) {\r\n                    cooc_ex.push({\r\n                        keyword: co.keyword.keyword,\r\n                        strength: 1 / keyword.co_oc.length,\r\n                        color: this.colorConverterExplanation(1 / keyword.co_oc.length)\r\n                    })\r\n                }\r\n            }\r\n\r\n            // Normalize all values\r\n            let substring_avg_dist = substring_dist / keywords.length;\r\n            let substring_avg_dist_keyword = keyword_substring_dist / keywords.length;\r\n            let edit_norm_sim = edit_dist / keywords.length;\r\n            let cooc_norm_sim\r\n            if (keyword.co_oc) {\r\n                cooc_norm_sim = cooc_sim / keyword.co_oc.length\r\n            }\r\n            else {\r\n                cooc_norm_sim = 0\r\n            }\r\n\r\n            // Set all values\r\n            label[\"substring_similarity\"] = Math.min(substring_avg_dist * 2, 1)\r\n            label[\"keyword_substring_similarity\"] = Math.min(substring_avg_dist_keyword * 1.5, 1)\r\n            label[\"edit_distance_similarity\"] = edit_norm_sim\r\n            label[\"cooc_similarity\"] = cooc_norm_sim\r\n\r\n            let temp = []\r\n            temp.push({\r\n                type: \"Label Substring\",\r\n                color: this.colorConverter(label[\"substring_similarity\"]),\r\n                value: label[\"substring_similarity\"],\r\n                explanation: substring_ex\r\n            })\r\n            temp.push({\r\n                type: \"Keyword Substring\",\r\n                color: this.colorConverter(label[\"keyword_substring_similarity\"]),\r\n                value: label[\"keyword_substring_similarity\"],\r\n                explanation: keyword_ex\r\n            })\r\n            temp.push({\r\n                type: \"Cooccurrent Keywords\",\r\n                color: this.colorConverter(label[\"cooc_similarity\"]),\r\n                value: label[\"cooc_similarity\"],\r\n                explanation: cooc_ex\r\n            })\r\n            temp.push({\r\n                type: \"Edit Distance\",\r\n                color: this.colorConverter(label[\"edit_distance_similarity\"]),\r\n                value: label[\"edit_distance_similarity\"],\r\n                explanation: edit_ex\r\n            })\r\n\r\n            label[\"similarities\"] = temp\r\n\r\n            label[\"total_similarity\"] =\r\n                label[\"substring_similarity\"] +\r\n                label[\"keyword_substring_similarity\"] +\r\n                label[\"edit_distance_similarity\"] +\r\n                label[\"cooc_similarity\"]\r\n        }\r\n\r\n        // Sort labels list\r\n        this.label_sort_property = \"\";\r\n        this.label_sort_property = \"total_similarity\"\r\n    }\r\n\r\n    // Sort Function\r\n    setSortProperty = (property) => this.sim_property = property;\r\n    setKeywordSortProperty = (property) => this.key_property = property;\r\n    setLabelSortProperty = (property) => this.label_sort_property = property;\r\n\r\n    setActiveKeyword = (keyword) => this.selectKeyword(keyword);\r\n    getMapping = (keyword) => this.store.getKeywordMapping(keyword);\r\n    checkMapping = (keyword) => keyword.mapping.length > 0 ? 1 : 0;\r\n\r\n    removeAddKeyword(keyword) {\r\n        this.selected_additional_keywords.splice(\r\n            this.selected_additional_keywords.indexOf(keyword), 1\r\n        );\r\n    }\r\n\r\n    selectAddKeyword(keyword) {\r\n        if (!keyword.isDone) {\r\n            if (this.selected_additional_keywords.includes(keyword)) {\r\n                this.removeAddKeyword(keyword)\r\n            }\r\n            else {\r\n                this.selected_additional_keywords.push(keyword)\r\n            }\r\n\r\n            this.checkKeywordsForDoc();\r\n        }\r\n    }\r\n\r\n    checkKeywordsForDoc() {\r\n        let temp = []\r\n        temp.push(this.selected_keyword, ...this.selected_additional_keywords)\r\n\r\n        for (const doc of this.selected_similarities) {\r\n            if (temp.every(r => doc.document[\"Keywords_Processed\"].includes(r))) {\r\n                doc.hasKeywords = true\r\n            }\r\n            else {\r\n                doc.hasKeywords = false\r\n            }\r\n        }\r\n    }\r\n\r\n    async moveToKeyword(key) {\r\n        await this.selectKeyword(key)\r\n\r\n        if (key.isDone) {\r\n            this.selectLabel(key.label)\r\n        }\r\n        else {\r\n            this.selectLabel(this.label_docs[0])\r\n        }\r\n\r\n        // Reset filter\r\n        this.searchDocumentTerm = \"\"\r\n        this.searchKeywordsTerm = \"\"\r\n        this.searchLabelsTerm = \"\"\r\n\r\n        // Reset scrolling after applying\r\n        this['labelsList'].scrollTop = 0;\r\n    }\r\n\r\n    async skipKeyword() {\r\n        // Move current element to the end of the array\r\n        this.keyword_list.splice(\r\n            this.keyword_list.indexOf(this.selected_keyword), 1\r\n        );\r\n        this.keyword_list.push(this.selected_keyword)\r\n\r\n        // Reset keyword\r\n        this.selected_keyword.mapping = \"\"\r\n        this.selected_keyword.label = {};\r\n        this.selected_keyword.isDone = false;\r\n\r\n        // Reset timing\r\n        this.keyword_time = 0\r\n\r\n        // Select next element\r\n        this.moveToKeyword(this.keyword_list.filter(x => !x.isDone)[0])\r\n        // await this.selectKeyword(this.keyword_list.filter(x => !x.isDone)[0])\r\n        // this.selectLabel(this.label_docs[0])\r\n\r\n        // // Reset filter\r\n        // this.searchDocumentTerm = \"\"\r\n        // this.searchKeywordsTerm = \"\"\r\n        // this.searchLabelsTerm = \"\"\r\n\r\n        // // Reset scrolling after applying\r\n        // this['labelsList'].scrollTop = 0;\r\n    }\r\n\r\n    async undoKeyword() {\r\n        // Reset last element\r\n        this.last_selected_keyword.mapping = \"\"\r\n        this.last_selected_keyword.label = {};\r\n        this.last_selected_keyword.isDone = false;\r\n\r\n        // Reset timing\r\n        this.keyword_time = 0\r\n\r\n        // Reset additional keyword\r\n        if (this.last_selected_additional_keywords) {\r\n            for (const keyword of this.last_selected_additional_keywords) {\r\n                keyword.mapping = \"\"\r\n                keyword.label = {}\r\n                keyword.isDone = false;\r\n            }\r\n\r\n            this.last_selected_additional_keywords = [];\r\n        }\r\n\r\n        // Select last element\r\n        this.moveToKeyword(this.keyword_list.filter(x => !x.isDone)[0])\r\n        // await this.selectKeyword(this.last_selected_keyword);\r\n        // this.selectLabel(this.label_docs[0])\r\n\r\n        // // Reset filter\r\n        // this.searchDocumentTerm = \"\"\r\n        // this.searchKeywordsTerm = \"\"\r\n        // this.searchLabelsTerm = \"\"\r\n\r\n        // // Reset scrolling after applying\r\n        // this['labelsList'].scrollTop = 0;\r\n    }\r\n\r\n    throttled_applyLabel = _.throttle(x => this.applyLabel(), 1000)\r\n\r\n    async applyLabel() {\r\n        this.selected_keyword.mapping = this.selected_label.label;\r\n        this.selected_keyword.label = this.selected_label;\r\n        this.selected_keyword.isDone = true;\r\n\r\n        this.last_selected_additional_keywords = []\r\n\r\n        // Handle timing\r\n        let div = 0\r\n        if (this.selected_additional_keywords) div = this.selected_additional_keywords.length\r\n\r\n        let time_fraction = Math.ceil(this.keyword_time / (div + 1))\r\n\r\n        this.selected_keyword[\"time\"] = time_fraction\r\n\r\n        if (this.selected_additional_keywords) {\r\n            for (const keyword of this.selected_additional_keywords) {\r\n                keyword.mapping = this.selected_label.label;\r\n                keyword.label = this.selected_label;\r\n                keyword.isDone = true;\r\n                keyword[\"time\"] = time_fraction;\r\n\r\n                this.last_selected_additional_keywords.push(keyword)\r\n            }\r\n\r\n            this.selected_additional_keywords = [];\r\n        }\r\n\r\n        this.keyword_time = 0\r\n\r\n        // Check if its done\r\n        if (this.keywords_todo <= 1) {\r\n            this.finished = true;\r\n            this.updateDocumentStats();\r\n            for (const doc of this.documents) {\r\n                if (doc[\"Keywords_Processed\"].every(x => x[\"isDone\"])) doc[\"isDone\"] = true;\r\n            }\r\n            this.updateKeywordStats();\r\n        }\r\n\r\n        // Update keyword list view\r\n        // this.finishedKeywords = !this.finishedKeywords;\r\n        // this.finishedKeywords = !this.finishedKeywords;\r\n\r\n        // this.selected_keyword = this.keyword_list.filter(x => !x.isDone)[0]\r\n        // let index = this.keyword_list.indexOf(this.selected_keyword)\r\n\r\n        this.moveToKeyword(this.keyword_list.filter(x => !x.isDone)[0])\r\n        // await this.selectKeyword(this.keyword_list.filter(x => !x.isDone)[0])\r\n        // this.selectLabel(this.label_docs[0])\r\n\r\n        this.updateKeywordStats();\r\n\r\n        // Check if some documents are now finished\r\n        for (const doc of this.documents) {\r\n            if (doc[\"Keywords_Processed\"].every(x => x[\"isDone\"])) doc[\"isDone\"] = true;\r\n        }\r\n\r\n        this.updateDocumentStats();\r\n\r\n        // // Reset filter\r\n        // this.searchDocumentTerm = \"\"\r\n        // this.searchKeywordsTerm = \"\"\r\n        // this.searchLabelsTerm = \"\"\r\n\r\n        // // Reset scrolling after applying\r\n        // this['labelsList'].scrollTop = 0;\r\n    }\r\n\r\n    download() {\r\n        this.downloadKeywords();\r\n        this.downloadData();\r\n    }\r\n\r\n    downloadData() {\r\n        let rows = [\r\n            [\"title\", \"keywords\", \"authors\", \"doi\", \"labels\"]\r\n        ];\r\n\r\n        for (const doc of this.documents) {\r\n            let labels = _.uniq(doc[\"Keywords_Processed\"].map(x => x.mapping).filter(x => x.length > 0)).join(\";\").replace(/,/g, \";\")\r\n\r\n            let keywords = \"\";\r\n            if (doc[\"Keywords\"]) keywords = doc[\"Keywords\"].replace(/,/g, \";\")\r\n\r\n            rows.push([\r\n                \"\\\"\" + doc[\"Title\"].replace(/,/g, \";\") + \"\\\"\",\r\n                \"\\\"\" + keywords + \"\\\"\",\r\n                \"\\\"\" + doc[\"Authors\"].replace(/,/g, \";\") + \"\\\"\",\r\n                \"\\\"\" + doc[\"DOI\"] + \"\\\"\",\r\n                \"\\\"\" + labels + \"\\\"\"\r\n            ])\r\n        }\r\n\r\n        let csvContent = \"data:text/csv;charset=utf-8,\"\r\n            + rows.map(e => e.join(\",\")).join(\"\\n\");\r\n\r\n        // var encodedUri = encodeURI(csvContent);\r\n        // window.open(encodedUri);\r\n        var encodedUri = encodeURI(csvContent);\r\n        var link = document.createElement(\"a\");\r\n        link.setAttribute(\"href\", encodedUri);\r\n        link.setAttribute(\"download\", \"labeled_data.csv\");\r\n        document.body.appendChild(link);\r\n\r\n        link.click();\r\n    }\r\n\r\n    downloadKeywords() {\r\n        let rows = [\r\n            [\"keyword\", \"label\", \"time\"]\r\n        ];\r\n\r\n        for (const keyword of this.keyword_list.filter(x => x[\"source\"] == \"new\")) {\r\n\r\n            rows.push([\r\n                \"\\\"\" + keyword.keyword + \"\\\"\",\r\n                \"\\\"\" + keyword.mapping + \"\\\"\",\r\n                keyword.time\r\n            ])\r\n        }\r\n\r\n        let csvContent = \"data:text/csv;charset=utf-8,\"\r\n            + rows.map(e => e.join(\",\")).join(\"\\n\");\r\n\r\n        // var encodedUri = encodeURI(csvContent);\r\n        // window.open(encodedUri);\r\n        var encodedUri = encodeURI(csvContent);\r\n        var link = document.createElement(\"a\");\r\n        link.setAttribute(\"href\", encodedUri);\r\n        link.setAttribute(\"download\", \"keyword_data.csv\");\r\n        document.body.appendChild(link);\r\n\r\n        link.click();\r\n    }\r\n\r\n    checkActiveKeyword(keyword) {\r\n        if (this.selected_keyword) {\r\n            if (this.selected_keyword === keyword) return 0\r\n            else return 1\r\n        }\r\n    }\r\n\r\n    removeKeyword(keyword) {\r\n        this.selected_document[\"Final\"] = this.selected_document[\"Final\"]\r\n            .filter(item => item !== keyword);\r\n    }\r\n\r\n    addKeyword(keyword) {\r\n        this.selected_document[\"Final\"] = this.selected_document[\"Final\"]\r\n            .concat({\r\n                tag: keyword\r\n            })\r\n    }\r\n\r\n\r\n    filterKeywordsFunc(searchExpression, value) {\r\n        let itemValue = value[\"keyword\"];\r\n        if (!searchExpression || !itemValue) return false;\r\n\r\n        return itemValue.toUpperCase().indexOf(searchExpression.toUpperCase()) !== -1;\r\n    }\r\n\r\n    filterLabelsFunc(searchExpression, value) {\r\n        let itemValue = value[\"label\"];\r\n        if (!searchExpression || !itemValue) return false;\r\n\r\n        return itemValue.toUpperCase().indexOf(searchExpression.toUpperCase()) !== -1;\r\n    }\r\n\r\n    filterDocumentsFunc(searchExpression, value) {\r\n        let itemValue = value.document[\"Title\"];\r\n        if (!searchExpression || !itemValue) return false;\r\n\r\n        return itemValue.toUpperCase().indexOf(searchExpression.toUpperCase()) !== -1;\r\n    }\r\n\r\n    updateDocumentStats() {\r\n        this.docs_todo = this.documents.filter(x => !x.isDone).length\r\n        this.docs_done = this.documents.filter(x => x.isDone).length\r\n\r\n        this.docs_per = 1 - (this.docs_todo / this.documents.length)\r\n    }\r\n\r\n    updateKeywordStats() {\r\n        let ll = this.keyword_list.filter(x => x[\"source\"] == \"new\")\r\n        this.keywords_todo = ll.filter(x => !x[\"isDone\"]).length\r\n        this.keywords_done = ll.filter(x => x[\"isDone\"]).length\r\n\r\n        this.keywords_per = 1 - (this.keywords_todo / ll.length)\r\n    }\r\n\r\n    startTimer() {\r\n        if (!this.timerActive) {\r\n            this.timerActive = true;\r\n\r\n            // Call every second\r\n            this.timer = setInterval(x => {\r\n                this.time++;\r\n                this.keyword_time++;\r\n            }, 1000)\r\n        }\r\n    }\r\n\r\n    endTimer() {\r\n        // Stop timer\r\n        clearInterval(this.timer);\r\n        this.timerActive = false;\r\n        this.time = 0;\r\n        this.keyword_time = 0;\r\n    }\r\n}"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAGA;AAGA;AAEA;AAEA;AAGA;AA4GA;AAAA;AAAA;AArGA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAIA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AAEA;AACA;AACA;AACA;AAGA;AACA;AA8BA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAupBA;AACA;AACA;AACA;AAEA;AACA;AACA;AAqHA;AAhxBA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AACA;AACA;AAEA;AACA;AAEA;AAAA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAGA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AAAA;AACA;AACA;AAEA;AAEA;;AAnBA;AAAA;AAAA;AAoBA;AAEA;AAEA;AAAA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAAA;AACA;AACA;AACA;AAGA;AACA;AACA;AAEA;AACA;;;AANA;AACA;AAAA;AAAA;AAMA;AAEA;AACA;AAAA;AACA;AACA;AACA;;;AADA;AAAA;AAAA;AAEA;AACA;AAEA;AACA;AAAA;AAGA;AACA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAhBA;AACA;AAAA;AAAA;AAgBA;AACA;AAEA;AAAA;AACA;AACA;AACA;;;AADA;AAAA;AAAA;AAEA;AACA;AAGA;AACA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAhBA;AACA;AAAA;AAAA;AAgBA;AACA;AAEA;AACA;AAAA;AACA;AACA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAAA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAAA;AACA;AACA;AAEA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAKA;AAAA;AACA;AAEA;AAAA;AACA;AACA;AAEA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAAA;AACA;AACA;AAEA;AAAA;AACA;AAEA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AApaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AA6YA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAAA;AACA;AAEA;;;AACA;AACA;AAAA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;;;;AAg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jlCA;AADA;AA6GA;AA5GA;AAklCA;AAAA;AAllCA;;A","sourceRoot":""}\n//# sourceURL=webpack-internal:///pages/p0\n");

/***/ }),

/***/ "pages/p0.html":
/*!***************************!*\
  !*** ./src/pages/p0.html ***!
  \***************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = \"<template>\\r\\n  <!-- <md-sidenav view-model.ref=\\\"sideNav\\\" edge=\\\"left\\\" close-on-click=\\\"true\\\">\\r\\n    <div style=\\\"overflow: scroll; height: 84vh;\\\">\\r\\n      <table>\\r\\n        <thead>\\r\\n          <tr>\\r\\n            <th>\\r\\n              Author Keywords\\r\\n            </th>\\r\\n            <th style=\\\"cursor: pointer\\\" click.delegate=\\\"setKeywordSortProperty('count')\\\">#</th>\\r\\n            <th>Mapping</th>\\r\\n            <th style=\\\"cursor: pointer\\\" click.delegate=\\\"setKeywordSortProperty('highest_value')\\\">Highest\\r\\n              Recommendation</th>\\r\\n          </tr>\\r\\n        </thead>\\r\\n        <tbody>\\r\\n          <tr\\r\\n            repeat.for=\\\"keyword of keyword_list | customSort: { propertyName: key_property, direction: 'descending' } | filter:searchKeywordsTerm:filterKeywordsFunc | filterProperty: finishedKeywords:'isDone'\\\"\\r\\n            click.delegate=\\\"selectKeyword(keyword)\\\"\\r\\n            css=\\\"cursor: pointer; background-color: ${keyword.isActive ? '#50c6f1' : keyword.isDone ? '#0df2c9' : None};\\\"\\r\\n            class=\\\"sidenav-close\\\">\\r\\n            <td>\\r\\n              ${keyword[\\\"keyword\\\"]}\\r\\n            </td>\\r\\n            <td>${keyword[\\\"count\\\"]}</td>\\r\\n            <td style=\\\"word-break: break-all;\\\">\\r\\n              ${keyword[\\\"mapping\\\"]}\\r\\n            </td>\\r\\n            <td as-element=\\\"small-bar\\\" percent=\\\"${keyword['highest_value']}\\\" orientation=\\\"horizontal\\\" xSize=\\\"60\\\"\\r\\n              ySize=\\\"20\\\">\\r\\n            </td>\\r\\n          </tr>\\r\\n        </tbody>\\r\\n      </table>\\r\\n    </div>\\r\\n  </md-sidenav> -->\\r\\n  <div class=\\\"row\\\" style=\\\"margin-bottom: 0px\\\">\\r\\n    <div class=\\\"col m4\\\">\\r\\n      <!-- <button md-sidenav-collapse=\\\"ref.bind: sideNav\\\" md-button md-waves>Show Keywords</button> -->\\r\\n      <button class=\\\"bColor\\\" md-button style=\\\"height: 35px; width: 50px;\\\" click.delegate=\\\"startTimer()\\\"\\r\\n        disabled.bind=\\\"timerActive\\\">\\r\\n        <i class=\\\"fas fa-play\\\"></i>\\r\\n      </button>\\r\\n      <button class=\\\"bColor\\\" md-button style=\\\"height: 35px; width: 50px;\\\" click.delegate=\\\"endTimer()\\\"\\r\\n        disabled.bind=\\\"!timerActive\\\">\\r\\n        <i class=\\\"fas fa-stop\\\"></i>\\r\\n      </button>\\r\\n      <span>\\r\\n        Time: ${time | timeFormat}\\r\\n        Keyword: ${keyword_time | timeFormat}\\r\\n      </span>\\r\\n    </div>\\r\\n    <div class=\\\"col m4\\\" style=\\\"text-align: center;\\\">\\r\\n      <span style=\\\"font-size: xx-large; font-style: italic; font-weight: 800;\\\">\\r\\n        LAssi\\r\\n      </span>\\r\\n      <i class=\\\"fad fa-glass\\\" style=\\\"color: orange; font-size: xx-large;\\\"></i>\\r\\n    </div>\\r\\n    <div class=\\\"col m4\\\">\\r\\n      Keywords:\\r\\n      <small-bar percent.bind=\\\"keywords_per\\\" orientation=\\\"horizontal\\\" xSize=40 ySize=13></small-bar>\\r\\n      ${keywords_done}/${keywords_todo}\\r\\n      <button class=\\\"bColor\\\" md-button style=\\\"float: right\\\" click.delegate=\\\"download()\\\"><i\\r\\n          class=\\\"fad fa-download\\\"></i></button>\\r\\n      <br>\\r\\n      Documents:\\r\\n      <small-bar percent.bind=\\\"docs_per\\\" orientation=\\\"horizontal\\\" xSize=40 ySize=13></small-bar>\\r\\n      ${docs_done}/${docs_todo}\\r\\n    </div>\\r\\n  </div>\\r\\n  <div class=\\\"row\\\" if.bind=\\\"finished\\\" style=\\\"width: 100%; text-align: center; height: 100px; margin-bottom: 0px\\\">\\r\\n    <div style=\\\"font-size: xx-large; font-weight: 400; margin-top: 40px\\\">\\r\\n      All Keywords Labeled!\\r\\n    </div>\\r\\n    <button class=\\\"bColor\\\" md-button click.delegate=\\\"download()\\\"><i class=\\\"fad fa-download\\\"></i>\\r\\n      Download Results</button>\\r\\n  </div>\\r\\n  <div class=\\\"row\\\" if.bind=\\\"!finished\\\" style=\\\"margin-bottom: 0px\\\">\\r\\n    <div class=\\\"col m3\\\">\\r\\n      <button class=\\\"bColor\\\" md-button style=\\\"height: 50px; width: 35%; padding: 0\\\" click.delegate=\\\"undoKeyword()\\\"\\r\\n        disabled.bind=\\\"!last_selected_keyword\\\">\\r\\n        <i class=\\\"fas fa-undo\\\"></i>\\r\\n      </button>\\r\\n      <button class=\\\"bColor\\\" md-button style=\\\"height: 50px; width: 60%; float: right\\\" click.delegate=\\\"skipKeyword()\\\">\\r\\n        <i class=\\\"fad fa-forward\\\"></i>\\r\\n      </button>\\r\\n      <button class=\\\"bColor\\\" md-button style=\\\"height: 50px; width: 100%; margin-top: 2px\\\"\\r\\n        click.delegate=\\\"applyLabel() & throttle: 1000\\\">\\r\\n        <i class=\\\"fad fa-plus\\\"></i>\\r\\n        Use\\r\\n      </button>\\r\\n    </div>\\r\\n    <div class=\\\"col m9\\\">\\r\\n      <span style=\\\"font-size: xx-large;\\\">\\r\\n        active keyword: <strong>${selected_keyword.keyword}</strong></span>\\r\\n      <!-- , ${selected_keyword.count} <i class=\\\"fad fa-file-alt\\\"></i> -->\\r\\n      <br>\\r\\n      <span style=\\\"font-size: smaller; margin-left: 20px\\\">\\r\\n        Additional keywords for labeling:\\r\\n      </span>\\r\\n      <!-- <i if.bind=\\\"!selected_additional_keywords.length\\\"> Select Co-Occurring Keywords </i> -->\\r\\n      <span repeat.for=\\\"keyword of selected_additional_keywords\\\" style=\\\"font-size: smaller\\\">\\r\\n        <strong>\\r\\n          ${keyword.keyword}\\r\\n          <i class=\\\"fad fa-trash-alt\\\" click.delegate=\\\"removeAddKeyword(keyword)\\\" style=\\\"cursor: pointer\\\"></i>\\r\\n        </strong>\\r\\n        <span>, </span>\\r\\n      </span>\\r\\n      <br>\\r\\n      <span style=\\\"font-size: x-large;\\\">\\r\\n        selected label:\\r\\n        <strong if.bind=\\\"!selected_label\\\"> Select a Label Below </strong>\\r\\n        <strong>${selected_label.label}</strong>\\r\\n      </span>\\r\\n      <!-- <span if.bind=\\\"selected_label\\\">, </span> ${selected_label.n_docs}el\\\" class=\\\"fad fa-file-alt\\\"></i> </div> -->\\r\\n    </div>\\r\\n  </div>\\r\\n  <div class=\\\"row\\\" style=\\\"margin:0\\\">\\r\\n\\r\\n    <!-- Labels View -->\\r\\n    <div class=\\\"col m12\\\">\\r\\n      <input type=\\\"text\\\" class=\\\"form-control search-box\\\" value.bind=\\\"searchLabelsTerm\\\"\\r\\n        placeholder=\\\"search Labels...\\\"></input>\\r\\n      <div class=\\\"row\\\" style=\\\"height: 40vh; margin-bottom: 0px;\\\">\\r\\n        <table>\\r\\n          <thead>\\r\\n            <tr style=\\\"border:none; display: block; height: 5vh; width: 100%\\\">\\r\\n              <th class=\\\"table_head\\\" style=\\\"width: 4%; display: inline-block\\\"></th>\\r\\n              <th class=\\\"table_head\\\" style=\\\"width: 30%; display: inline-block\\\">Label</th>\\r\\n              <!-- <th>Count</th> -->\\r\\n              <th style=\\\"width: 4%; display: inline-block\\\"></th>\\r\\n              <th class=\\\"table_head\\\" style=\\\"width: 60%; display: inline-block\\\">\\r\\n                Similarity Measures\\r\\n                <span style=\\\"float: right; font-weight: 200; margin-right: 5px\\\">\\r\\n                  Importance:\\r\\n                  High\\r\\n                  <i class=\\\"fad fa-circle\\\" style=\\\"color: #094D08; display: inline-block\\\"></i>\\r\\n                  <i class=\\\"fad fa-circle\\\" style=\\\"color: #108C0E; display: inline-block\\\"></i>\\r\\n                  <i class=\\\"fad fa-circle\\\" style=\\\"color: #7CC07B; display: inline-block\\\"></i>\\r\\n                  Low\\r\\n                  <i class=\\\"fad fa-circle\\\" style=\\\"color: #D8DBDB; display: inline-block\\\"></i>\\r\\n                  No\\r\\n                </span>\\r\\n              </th>\\r\\n            </tr>\\r\\n          </thead>\\r\\n          <tbody element.ref=\\\"labelsList\\\" style=\\\"display:block; overflow: auto; height: 35vh; width: 100%\\\">\\r\\n            <tr repeat.for=\\\"label_object of label_docs | customSort: { propertyName: label_sort_property,\\r\\n                direction: 'descending',\\r\\n              } | filter:searchLabelsTerm:filterLabelsFunc\\\">\\r\\n              <td class=\\\"table_cell\\\" style=\\\"width: 5%;\\\">\\r\\n                <md-checkbox checked.bind=\\\"label_object['isActive']\\\" click.delegate=\\\"selectLabel(label_object)\\\">\\r\\n              </td>\\r\\n              <td class=\\\"table_cell\\\" style=\\\"cursor: pointer; width: 30%\\\" click.delegate=\\\"selectLabel(label_object)\\\"\\r\\n                dblclick.delegate=\\\"applyLabel()\\\">\\r\\n                <span>\\r\\n                  ${label_object['label']}\\r\\n                  <!-- , ${label_object['n_docs']} <i class=\\\"fad fa-file-alt\\\"></i> -->\\r\\n                </span>\\r\\n              </td>\\r\\n              <!-- <td>${label_object['n_docs']}</td> -->\\r\\n              <td style=\\\"width: 5%\\\">\\r\\n                <small-bar percent=${label_object.total_similarity} orientation=\\\"vertical\\\" xSize=15 ySize=80>\\r\\n                </small-bar>\\r\\n              </td>\\r\\n              <td class=\\\"table_cell\\\">\\r\\n                <table>\\r\\n                  <thead>\\r\\n                    <tr style=\\\"border: none\\\">\\r\\n                      <th class=\\\"table_head\\\">Feature</th>\\r\\n                      <th class=\\\"table_head\\\">Explanation</th>\\r\\n                    </tr>\\r\\n                  </thead>\\r\\n                  <tbody>\\r\\n                    <tr repeat.for=\\\"sim of label_object.similarities | customSort: {\\r\\n                          propertyName: 'count', direction: 'descending'\\r\\n                        }\\\" style=\\\"border: none\\\">\\r\\n                      <td class=\\\"table_cell\\\" style=\\\"width: 200px;\\\">\\r\\n                        <i class=\\\"fad fa-circle\\\" css=\\\"color: ${sim['color']}; display: inline-block\\\"></i>\\r\\n                        <span style=\\\"display: inline-block;\\\">\\r\\n                          ${sim.type}\\r\\n                        </span>\\r\\n                      </td>\\r\\n                      <td class=\\\"table_cell\\\">\\r\\n                        <span repeat.for=\\\"ex of sim.explanation\\\">\\r\\n                          <i css=\\\"color: ${ex.color}\\\">\\r\\n                            ${ex.keyword},\\r\\n                          </i>\\r\\n                      </td>\\r\\n                    </tr>\\r\\n                  </tbody>\\r\\n                </table>\\r\\n                <!-- <span style=\\\"white-space: nowrap\\\" repeat.for=\\\"sim of label_object.similarities | customSort: {\\r\\n                  propertyName: 'count', direction: 'descending'\\r\\n                }\\\">\\r\\n                      <i class=\\\"fad fa-circle\\\" css=\\\"color: ${sim['color']}\\\"></i>\\r\\n                      ${sim.type} | ${sim.explanation}\\r\\n                      <br>\\r\\n                    </span> -->\\r\\n              </td>\\r\\n            </tr>\\r\\n          </tbody>\\r\\n        </table>\\r\\n      </div>\\r\\n    </div>\\r\\n  </div>\\r\\n  <hr style=\\\"padding: 0; margin: 0; border-top: 1px solid lightgrey;\\\">\\r\\n  <div class=\\\"row\\\">\\r\\n    <!-- Keyword View -->\\r\\n    <div class=\\\"col m4\\\">\\r\\n      <input type=\\\"text\\\" class=\\\"form-control search-box\\\" value.bind=\\\"searchCoocKeywordTerm\\\"\\r\\n        placeholder=\\\"search All Keywords...\\\"></input>\\r\\n      <div class=\\\"row\\\" style=\\\"overflow: scroll; height: 35vh;\\\">\\r\\n        <table>\\r\\n          <thead>\\r\\n            <tr style=\\\"border:none\\\">\\r\\n              <th class=\\\"table_head\\\">\\r\\n                Keyword\\r\\n              </th>\\r\\n              <!-- <th class=\\\"table_head\\\">#</th> -->\\r\\n              <th class=\\\"table_head\\\">Label</th>\\r\\n            </tr>\\r\\n          </thead>\\r\\n          <tbody>\\r\\n            <tr repeat.for=\\\"keyword of keyword_list | customSort: { propertyName: 'isDone', direction: 'ascending' } |\\r\\n              filter:searchCoocKeywordTerm:filterKeywordsFunc\\\" click.delegate=\\\"moveToKeyword(keyword)\\\"\\r\\n              style=\\\"cursor: pointer\\\">\\r\\n              <td class=\\\"table_cell\\\">\\r\\n                <!-- <md-checkbox show.bind=\\\"!keyword['isDone']\\\" model.bind=\\\"keyword\\\"\\r\\n                  checked.bind=\\\"selected_additional_keywords\\\" click.delegate=\\\"selectAddKeyword(keyword)\\\">\\r\\n                </md-checkbox> -->\\r\\n                <span style=\\\"margin-left: 2px;\\\">\\r\\n                  ${keyword[\\\"keyword\\\"]} <span style=\\\"color: orange;\\\" show.bind=\\\"keyword.isNew\\\">New</span>\\r\\n                </span>\\r\\n              </td>\\r\\n              <!-- <td class=\\\"table_cell\\\">${keyword[\\\"count\\\"]}</td> -->\\r\\n              <td class=\\\"table_cell\\\">\\r\\n                ${keyword[\\\"mapping\\\"]}\\r\\n              </td>\\r\\n            </tr>\\r\\n          </tbody>\\r\\n        </table>\\r\\n        <!-- <span class=\\\"fa-stack fa-2x hover\\\" show.bind=\\\"cooc['label_object']['isActive'] \\\"\\r\\n                  style=\\\"display: inline-block;\\\">\\r\\n                  <i class=\\\"fal fa-square fa-stack-2x\\\"></i>\\r\\n                  <i class=\\\"fad fa-layer-plus fa-stack-1x\\\"></i>\\r\\n                </span> -->\\r\\n        <!-- <table show.bind=\\\"!searchCoocKeywordTerm\\\">\\r\\n          <thead>\\r\\n            <tr style=\\\"border: none\\\">\\r\\n              <th class=\\\"table_head\\\"></th>\\r\\n              <th class=\\\"table_head\\\">Label</th>\\r\\n              <th class=\\\"table_head\\\">Co-Occurring Keywords</th>\\r\\n            </tr>\\r\\n          </thead>\\r\\n          <tbody>\\r\\n            <tr repeat.for=\\\"cooc of selected_similar_keywords\\r\\n            | customFilterSortLength: {\\r\\n              propertyName: 'keywords',\\r\\n              direction: 'descending',\\r\\n              filterName: 'label',\\r\\n              filterValue: ''\\r\\n            }\\\">\\r\\n              <td class=\\\"table_cell\\\">\\r\\n                <md-checkbox disabled.bind=\\\"!cooc.label\\\" checked.bind=\\\"cooc['label_object']['isActive']\\\">\\r\\n              </td>\\r\\n              <td class=\\\"table_cell\\\" style=\\\"cursor: pointer;\\\" click.delegate=\\\"selectLabelName(cooc.label)\\\"\\r\\n                click.delegate=\\\"selectLabel(cooc['label_object'])\\\">\\r\\n                <span style=\\\"display: inline-block;\\\">\\r\\n                  ${cooc.label}\\r\\n                </span>\\r\\n              </td>\\r\\n              <td class=\\\"table_cell\\\">\\r\\n                <div style=\\\"white-space: nowrap\\\" repeat.for=\\\"keyword of cooc.keywords | customSort: {\\r\\n                  propertyName: 'count', direction: 'descending'\\r\\n                }\\\">\\r\\n                  <md-checkbox show.bind=\\\"!keyword['isDone']\\\" model.bind=\\\"keyword\\\"\\r\\n                    checked.bind=\\\"selected_additional_keywords\\\" style=\\\"width: 19px\\\"></md-checkbox>\\r\\n        <span style=\\\"cursor: pointer;\\\" click.delegate=\\\"selectAddKeyword(keyword)\\\">\\r\\n          ${keyword.keyword}\\r\\n        </span>\\r\\n        <br>\\r\\n      </div>\\r\\n      </td>\\r\\n      </tr>\\r\\n      </tbody>\\r\\n      </table if.bind=\\\"searchCoocKeywordTerm\\\"> -->\\r\\n      </div>\\r\\n    </div>\\r\\n    <div class=\\\"col m8\\\">\\r\\n\\r\\n      <!-- Document View -->\\r\\n      <input type=\\\"text\\\" class=\\\"form-control search-box\\\" value.bind=\\\"searchDocumentTerm\\\"\\r\\n        placeholder=\\\"search Document titles...\\\"></input>\\r\\n      <!-- Document List View -->\\r\\n      <div class=\\\"row\\\" style=\\\"overflow: scroll; height: 35vh;\\\">\\r\\n        <table>\\r\\n          <thead>\\r\\n            <tr style=\\\"border: none\\\">\\r\\n              <th class=\\\"table_head\\\">Documents containing the active Keyword</th>\\r\\n            </tr>\\r\\n          </thead>\\r\\n          <tbody>\\r\\n            <tr repeat.for=\\\"sim of selected_similarities | customSort: { propertyName: sim_property, direction: sort_property }\\r\\n              | filter:searchDocumentTerm:filterDocumentsFunc\\\" click.delegate=\\\"selectDocument(sim.document)\\\"\\r\\n              style=\\\"border: none\\\" class=\\\"${sim.hasKeywords ? 'none': 'deselected'}\\\">\\r\\n              <td class=\\\"table_cell\\\">\\r\\n                <span style=\\\"font-size: x-large; font-weight: 400;\\\">\\r\\n                  ${sim.document[\\\"Title\\\"]}\\r\\n                </span>\\r\\n                <a style=\\\"font-size: small;\\\" href=${sim.document[\\\"DOI\\\"]}>Link</a>\\r\\n                <br>\\r\\n                <span style=\\\"font-size: small;\\\">\\r\\n                  ${sim.document[\\\"Authors\\\"]}\\r\\n                </span>\\r\\n                <br>\\r\\n                <span style=\\\"font-size: small;\\\">\\r\\n\\r\\n                  <strong>Keywords:</strong> ${sim.document[\\\"Keywords\\\"]}\\r\\n                </span>\\r\\n                <span repeat.for=\\\"keyword of sim.document['Keywords_Processed']\\\" style=\\\"font-size: smaller\\\">\\r\\n                  <md-checkbox disabled.bind=\\\"keyword.isDone\\\" class=\\\"inline_checkbox\\\" model.bind=\\\"keyword\\\"\\r\\n                    checked.bind=\\\"selected_additional_keywords\\\" click.delegate=\\\"selectAddKeyword(keyword)\\\">\\r\\n                  </md-checkbox>\\r\\n                  ${keyword.keyword}\\r\\n                  <!-- <i class=\\\"fad fa-trash-alt\\\" click.delegate=\\\"removeAddKeyword(keyword)\\\" style=\\\"cursor: pointer\\\"></i> -->\\r\\n                  <span>, </span>\\r\\n                </span>\\r\\n                <br>\\r\\n                <ul style=\\\"margin: 0; box-shadow: none; -webkit-box-shadow: none\\\"\\r\\n                  md-collapsible=\\\"accordion.bind: !accordion; popout: false;\\\">\\r\\n                  <li>\\r\\n                    <div style=\\\"padding: 0 0 0 10px;\\\" class=\\\"collapsible-header \\\"> Abstract...</div>\\r\\n                    <div class=\\\"collapsible-body\\\">\\r\\n                      <p>${sim.document[\\\"Abstract\\\"]}</p>\\r\\n                    </div>\\r\\n                  </li>\\r\\n                </ul>\\r\\n              </td>\\r\\n            </tr>\\r\\n          </tbody>\\r\\n        </table>\\r\\n      </div>\\r\\n    </div>\\r\\n  </div>\\r\\n</template>\";//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,{"version":3,"file":"pages/p0.html.js","sources":["webpack:///./src/pages/p0.html?5f55"],"sourcesContent":["module.exports = \"<template>\\r\\n  <!-- <md-sidenav view-model.ref=\\\"sideNav\\\" edge=\\\"left\\\" close-on-click=\\\"true\\\">\\r\\n    <div style=\\\"overflow: scroll; height: 84vh;\\\">\\r\\n      <table>\\r\\n        <thead>\\r\\n          <tr>\\r\\n            <th>\\r\\n              Author Keywords\\r\\n            </th>\\r\\n            <th style=\\\"cursor: pointer\\\" click.delegate=\\\"setKeywordSortProperty('count')\\\">#</th>\\r\\n            <th>Mapping</th>\\r\\n            <th style=\\\"cursor: pointer\\\" click.delegate=\\\"setKeywordSortProperty('highest_value')\\\">Highest\\r\\n              Recommendation</th>\\r\\n          </tr>\\r\\n        </thead>\\r\\n        <tbody>\\r\\n          <tr\\r\\n            repeat.for=\\\"keyword of keyword_list | customSort: { propertyName: key_property, direction: 'descending' } | filter:searchKeywordsTerm:filterKeywordsFunc | filterProperty: finishedKeywords:'isDone'\\\"\\r\\n            click.delegate=\\\"selectKeyword(keyword)\\\"\\r\\n            css=\\\"cursor: pointer; background-color: ${keyword.isActive ? '#50c6f1' : keyword.isDone ? '#0df2c9' : None};\\\"\\r\\n            class=\\\"sidenav-close\\\">\\r\\n            <td>\\r\\n              ${keyword[\\\"keyword\\\"]}\\r\\n            </td>\\r\\n            <td>${keyword[\\\"count\\\"]}</td>\\r\\n            <td style=\\\"word-break: break-all;\\\">\\r\\n              ${keyword[\\\"mapping\\\"]}\\r\\n            </td>\\r\\n            <td as-element=\\\"small-bar\\\" percent=\\\"${keyword['highest_value']}\\\" orientation=\\\"horizontal\\\" xSize=\\\"60\\\"\\r\\n              ySize=\\\"20\\\">\\r\\n            </td>\\r\\n          </tr>\\r\\n        </tbody>\\r\\n      </table>\\r\\n    </div>\\r\\n  </md-sidenav> -->\\r\\n  <div class=\\\"row\\\" style=\\\"margin-bottom: 0px\\\">\\r\\n    <div class=\\\"col m4\\\">\\r\\n      <!-- <button md-sidenav-collapse=\\\"ref.bind: sideNav\\\" md-button md-waves>Show Keywords</button> -->\\r\\n      <button class=\\\"bColor\\\" md-button style=\\\"height: 35px; width: 50px;\\\" click.delegate=\\\"startTimer()\\\"\\r\\n        disabled.bind=\\\"timerActive\\\">\\r\\n        <i class=\\\"fas fa-play\\\"></i>\\r\\n      </button>\\r\\n      <button class=\\\"bColor\\\" md-button style=\\\"height: 35px; width: 50px;\\\" click.delegate=\\\"endTimer()\\\"\\r\\n        disabled.bind=\\\"!timerActive\\\">\\r\\n        <i class=\\\"fas fa-stop\\\"></i>\\r\\n      </button>\\r\\n      <span>\\r\\n        Time: ${time | timeFormat}\\r\\n        Keyword: ${keyword_time | timeFormat}\\r\\n      </span>\\r\\n    </div>\\r\\n    <div class=\\\"col m4\\\" style=\\\"text-align: center;\\\">\\r\\n      <span style=\\\"font-size: xx-large; font-style: italic; font-weight: 800;\\\">\\r\\n        LAssi\\r\\n      </span>\\r\\n      <i class=\\\"fad fa-glass\\\" style=\\\"color: orange; font-size: xx-large;\\\"></i>\\r\\n    </div>\\r\\n    <div class=\\\"col m4\\\">\\r\\n      Keywords:\\r\\n      <small-bar percent.bind=\\\"keywords_per\\\" orientation=\\\"horizontal\\\" xSize=40 ySize=13></small-bar>\\r\\n      ${keywords_done}/${keywords_todo}\\r\\n      <button class=\\\"bColor\\\" md-button style=\\\"float: right\\\" click.delegate=\\\"download()\\\"><i\\r\\n          class=\\\"fad fa-download\\\"></i></button>\\r\\n      <br>\\r\\n      Documents:\\r\\n      <small-bar percent.bind=\\\"docs_per\\\" orientation=\\\"horizontal\\\" xSize=40 ySize=13></small-bar>\\r\\n      ${docs_done}/${docs_todo}\\r\\n    </div>\\r\\n  </div>\\r\\n  <div class=\\\"row\\\" if.bind=\\\"finished\\\" style=\\\"width: 100%; text-align: center; height: 100px; margin-bottom: 0px\\\">\\r\\n    <div style=\\\"font-size: xx-large; font-weight: 400; margin-top: 40px\\\">\\r\\n      All Keywords Labeled!\\r\\n    </div>\\r\\n    <button class=\\\"bColor\\\" md-button click.delegate=\\\"download()\\\"><i class=\\\"fad fa-download\\\"></i>\\r\\n      Download Results</button>\\r\\n  </div>\\r\\n  <div class=\\\"row\\\" if.bind=\\\"!finished\\\" style=\\\"margin-bottom: 0px\\\">\\r\\n    <div class=\\\"col m3\\\">\\r\\n      <button class=\\\"bColor\\\" md-button style=\\\"height: 50px; width: 35%; padding: 0\\\" click.delegate=\\\"undoKeyword()\\\"\\r\\n        disabled.bind=\\\"!last_selected_keyword\\\">\\r\\n        <i class=\\\"fas fa-undo\\\"></i>\\r\\n      </button>\\r\\n      <button class=\\\"bColor\\\" md-button style=\\\"height: 50px; width: 60%; float: right\\\" click.delegate=\\\"skipKeyword()\\\">\\r\\n        <i class=\\\"fad fa-forward\\\"></i>\\r\\n      </button>\\r\\n      <button class=\\\"bColor\\\" md-button style=\\\"height: 50px; width: 100%; margin-top: 2px\\\"\\r\\n        click.delegate=\\\"applyLabel() & throttle: 1000\\\">\\r\\n        <i class=\\\"fad fa-plus\\\"></i>\\r\\n        Use\\r\\n      </button>\\r\\n    </div>\\r\\n    <div class=\\\"col m9\\\">\\r\\n      <span style=\\\"font-size: xx-large;\\\">\\r\\n        active keyword: <strong>${selected_keyword.keyword}</strong></span>\\r\\n      <!-- , ${selected_keyword.count} <i class=\\\"fad fa-file-alt\\\"></i> -->\\r\\n      <br>\\r\\n      <span style=\\\"font-size: smaller; margin-left: 20px\\\">\\r\\n        Additional keywords for labeling:\\r\\n      </span>\\r\\n      <!-- <i if.bind=\\\"!selected_additional_keywords.length\\\"> Select Co-Occurring Keywords </i> -->\\r\\n      <span repeat.for=\\\"keyword of selected_additional_keywords\\\" style=\\\"font-size: smaller\\\">\\r\\n        <strong>\\r\\n          ${keyword.keyword}\\r\\n          <i class=\\\"fad fa-trash-alt\\\" click.delegate=\\\"removeAddKeyword(keyword)\\\" style=\\\"cursor: pointer\\\"></i>\\r\\n        </strong>\\r\\n        <span>, </span>\\r\\n      </span>\\r\\n      <br>\\r\\n      <span style=\\\"font-size: x-large;\\\">\\r\\n        selected label:\\r\\n        <strong if.bind=\\\"!selected_label\\\"> Select a Label Below </strong>\\r\\n        <strong>${selected_label.label}</strong>\\r\\n      </span>\\r\\n      <!-- <span if.bind=\\\"selected_label\\\">, </span> ${selected_label.n_docs}el\\\" class=\\\"fad fa-file-alt\\\"></i> </div> -->\\r\\n    </div>\\r\\n  </div>\\r\\n  <div class=\\\"row\\\" style=\\\"margin:0\\\">\\r\\n\\r\\n    <!-- Labels View -->\\r\\n    <div class=\\\"col m12\\\">\\r\\n      <input type=\\\"text\\\" class=\\\"form-control search-box\\\" value.bind=\\\"searchLabelsTerm\\\"\\r\\n        placeholder=\\\"search Labels...\\\"></input>\\r\\n      <div class=\\\"row\\\" style=\\\"height: 40vh; margin-bottom: 0px;\\\">\\r\\n        <table>\\r\\n          <thead>\\r\\n            <tr style=\\\"border:none; display: block; height: 5vh; width: 100%\\\">\\r\\n              <th class=\\\"table_head\\\" style=\\\"width: 4%; display: inline-block\\\"></th>\\r\\n              <th class=\\\"table_head\\\" style=\\\"width: 30%; display: inline-block\\\">Label</th>\\r\\n              <!-- <th>Count</th> -->\\r\\n              <th style=\\\"width: 4%; display: inline-block\\\"></th>\\r\\n              <th class=\\\"table_head\\\" style=\\\"width: 60%; display: inline-block\\\">\\r\\n                Similarity Measures\\r\\n                <span style=\\\"float: right; font-weight: 200; margin-right: 5px\\\">\\r\\n                  Importance:\\r\\n                  High\\r\\n                  <i class=\\\"fad fa-circle\\\" style=\\\"color: #094D08; display: inline-block\\\"></i>\\r\\n                  <i class=\\\"fad fa-circle\\\" style=\\\"color: #108C0E; display: inline-block\\\"></i>\\r\\n                  <i class=\\\"fad fa-circle\\\" style=\\\"color: #7CC07B; display: inline-block\\\"></i>\\r\\n                  Low\\r\\n                  <i class=\\\"fad fa-circle\\\" style=\\\"color: #D8DBDB; display: inline-block\\\"></i>\\r\\n                  No\\r\\n                </span>\\r\\n              </th>\\r\\n            </tr>\\r\\n          </thead>\\r\\n          <tbody element.ref=\\\"labelsList\\\" style=\\\"display:block; overflow: auto; height: 35vh; width: 100%\\\">\\r\\n            <tr repeat.for=\\\"label_object of label_docs | customSort: { propertyName: label_sort_property,\\r\\n                direction: 'descending',\\r\\n              } | filter:searchLabelsTerm:filterLabelsFunc\\\">\\r\\n              <td class=\\\"table_cell\\\" style=\\\"width: 5%;\\\">\\r\\n                <md-checkbox checked.bind=\\\"label_object['isActive']\\\" click.delegate=\\\"selectLabel(label_object)\\\">\\r\\n              </td>\\r\\n              <td class=\\\"table_cell\\\" style=\\\"cursor: pointer; width: 30%\\\" click.delegate=\\\"selectLabel(label_object)\\\"\\r\\n                dblclick.delegate=\\\"applyLabel()\\\">\\r\\n                <span>\\r\\n                  ${label_object['label']}\\r\\n                  <!-- , ${label_object['n_docs']} <i class=\\\"fad fa-file-alt\\\"></i> -->\\r\\n                </span>\\r\\n              </td>\\r\\n              <!-- <td>${label_object['n_docs']}</td> -->\\r\\n              <td style=\\\"width: 5%\\\">\\r\\n                <small-bar percent=${label_object.total_similarity} orientation=\\\"vertical\\\" xSize=15 ySize=80>\\r\\n                </small-bar>\\r\\n              </td>\\r\\n              <td class=\\\"table_cell\\\">\\r\\n                <table>\\r\\n                  <thead>\\r\\n                    <tr style=\\\"border: none\\\">\\r\\n                      <th class=\\\"table_head\\\">Feature</th>\\r\\n                      <th class=\\\"table_head\\\">Explanation</th>\\r\\n                    </tr>\\r\\n                  </thead>\\r\\n                  <tbody>\\r\\n                    <tr repeat.for=\\\"sim of label_object.similarities | customSort: {\\r\\n                          propertyName: 'count', direction: 'descending'\\r\\n                        }\\\" style=\\\"border: none\\\">\\r\\n                      <td class=\\\"table_cell\\\" style=\\\"width: 200px;\\\">\\r\\n                        <i class=\\\"fad fa-circle\\\" css=\\\"color: ${sim['color']}; display: inline-block\\\"></i>\\r\\n                        <span style=\\\"display: inline-block;\\\">\\r\\n                          ${sim.type}\\r\\n                        </span>\\r\\n                      </td>\\r\\n                      <td class=\\\"table_cell\\\">\\r\\n                        <span repeat.for=\\\"ex of sim.explanation\\\">\\r\\n                          <i css=\\\"color: ${ex.color}\\\">\\r\\n                            ${ex.keyword},\\r\\n                          </i>\\r\\n                      </td>\\r\\n                    </tr>\\r\\n                  </tbody>\\r\\n                </table>\\r\\n                <!-- <span style=\\\"white-space: nowrap\\\" repeat.for=\\\"sim of label_object.similarities | customSort: {\\r\\n                  propertyName: 'count', direction: 'descending'\\r\\n                }\\\">\\r\\n                      <i class=\\\"fad fa-circle\\\" css=\\\"color: ${sim['color']}\\\"></i>\\r\\n                      ${sim.type} | ${sim.explanation}\\r\\n                      <br>\\r\\n                    </span> -->\\r\\n              </td>\\r\\n            </tr>\\r\\n          </tbody>\\r\\n        </table>\\r\\n      </div>\\r\\n    </div>\\r\\n  </div>\\r\\n  <hr style=\\\"padding: 0; margin: 0; border-top: 1px solid lightgrey;\\\">\\r\\n  <div class=\\\"row\\\">\\r\\n    <!-- Keyword View -->\\r\\n    <div class=\\\"col m4\\\">\\r\\n      <input type=\\\"text\\\" class=\\\"form-control search-box\\\" value.bind=\\\"searchCoocKeywordTerm\\\"\\r\\n        placeholder=\\\"search All Keywords...\\\"></input>\\r\\n      <div class=\\\"row\\\" style=\\\"overflow: scroll; height: 35vh;\\\">\\r\\n        <table>\\r\\n          <thead>\\r\\n            <tr style=\\\"border:none\\\">\\r\\n              <th class=\\\"table_head\\\">\\r\\n                Keyword\\r\\n              </th>\\r\\n              <!-- <th class=\\\"table_head\\\">#</th> -->\\r\\n              <th class=\\\"table_head\\\">Label</th>\\r\\n            </tr>\\r\\n          </thead>\\r\\n          <tbody>\\r\\n            <tr repeat.for=\\\"keyword of keyword_list | customSort: { propertyName: 'isDone', direction: 'ascending' } |\\r\\n              filter:searchCoocKeywordTerm:filterKeywordsFunc\\\" click.delegate=\\\"moveToKeyword(keyword)\\\"\\r\\n              style=\\\"cursor: pointer\\\">\\r\\n              <td class=\\\"table_cell\\\">\\r\\n                <!-- <md-checkbox show.bind=\\\"!keyword['isDone']\\\" model.bind=\\\"keyword\\\"\\r\\n                  checked.bind=\\\"selected_additional_keywords\\\" click.delegate=\\\"selectAddKeyword(keyword)\\\">\\r\\n                </md-checkbox> -->\\r\\n                <span style=\\\"margin-left: 2px;\\\">\\r\\n                  ${keyword[\\\"keyword\\\"]} <span style=\\\"color: orange;\\\" show.bind=\\\"keyword.isNew\\\">New</span>\\r\\n                </span>\\r\\n              </td>\\r\\n              <!-- <td class=\\\"table_cell\\\">${keyword[\\\"count\\\"]}</td> -->\\r\\n              <td class=\\\"table_cell\\\">\\r\\n                ${keyword[\\\"mapping\\\"]}\\r\\n              </td>\\r\\n            </tr>\\r\\n          </tbody>\\r\\n        </table>\\r\\n        <!-- <span class=\\\"fa-stack fa-2x hover\\\" show.bind=\\\"cooc['label_object']['isActive'] \\\"\\r\\n                  style=\\\"display: inline-block;\\\">\\r\\n                  <i class=\\\"fal fa-square fa-stack-2x\\\"></i>\\r\\n                  <i class=\\\"fad fa-layer-plus fa-stack-1x\\\"></i>\\r\\n                </span> -->\\r\\n        <!-- <table show.bind=\\\"!searchCoocKeywordTerm\\\">\\r\\n          <thead>\\r\\n            <tr style=\\\"border: none\\\">\\r\\n              <th class=\\\"table_head\\\"></th>\\r\\n              <th class=\\\"table_head\\\">Label</th>\\r\\n              <th class=\\\"table_head\\\">Co-Occurring Keywords</th>\\r\\n            </tr>\\r\\n          </thead>\\r\\n          <tbody>\\r\\n            <tr repeat.for=\\\"cooc of selected_similar_keywords\\r\\n            | customFilterSortLength: {\\r\\n              propertyName: 'keywords',\\r\\n              direction: 'descending',\\r\\n              filterName: 'label',\\r\\n              filterValue: ''\\r\\n            }\\\">\\r\\n              <td class=\\\"table_cell\\\">\\r\\n                <md-checkbox disabled.bind=\\\"!cooc.label\\\" checked.bind=\\\"cooc['label_object']['isActive']\\\">\\r\\n              </td>\\r\\n              <td class=\\\"table_cell\\\" style=\\\"cursor: pointer;\\\" click.delegate=\\\"selectLabelName(cooc.label)\\\"\\r\\n                click.delegate=\\\"selectLabel(cooc['label_object'])\\\">\\r\\n                <span style=\\\"display: inline-block;\\\">\\r\\n                  ${cooc.label}\\r\\n                </span>\\r\\n              </td>\\r\\n              <td class=\\\"table_cell\\\">\\r\\n                <div style=\\\"white-space: nowrap\\\" repeat.for=\\\"keyword of cooc.keywords | customSort: {\\r\\n                  propertyName: 'count', direction: 'descending'\\r\\n                }\\\">\\r\\n                  <md-checkbox show.bind=\\\"!keyword['isDone']\\\" model.bind=\\\"keyword\\\"\\r\\n                    checked.bind=\\\"selected_additional_keywords\\\" style=\\\"width: 19px\\\"></md-checkbox>\\r\\n        <span style=\\\"cursor: pointer;\\\" click.delegate=\\\"selectAddKeyword(keyword)\\\">\\r\\n          ${keyword.keyword}\\r\\n        </span>\\r\\n        <br>\\r\\n      </div>\\r\\n      </td>\\r\\n      </tr>\\r\\n      </tbody>\\r\\n      </table if.bind=\\\"searchCoocKeywordTerm\\\"> -->\\r\\n      </div>\\r\\n    </div>\\r\\n    <div class=\\\"col m8\\\">\\r\\n\\r\\n      <!-- Document View -->\\r\\n      <input type=\\\"text\\\" class=\\\"form-control search-box\\\" value.bind=\\\"searchDocumentTerm\\\"\\r\\n        placeholder=\\\"search Document titles...\\\"></input>\\r\\n      <!-- Document List View -->\\r\\n      <div class=\\\"row\\\" style=\\\"overflow: scroll; height: 35vh;\\\">\\r\\n        <table>\\r\\n          <thead>\\r\\n            <tr style=\\\"border: none\\\">\\r\\n              <th class=\\\"table_head\\\">Documents containing the active Keyword</th>\\r\\n            </tr>\\r\\n          </thead>\\r\\n          <tbody>\\r\\n            <tr repeat.for=\\\"sim of selected_similarities | customSort: { propertyName: sim_property, direction: sort_property }\\r\\n              | filter:searchDocumentTerm:filterDocumentsFunc\\\" click.delegate=\\\"selectDocument(sim.document)\\\"\\r\\n              style=\\\"border: none\\\" class=\\\"${sim.hasKeywords ? 'none': 'deselected'}\\\">\\r\\n              <td class=\\\"table_cell\\\">\\r\\n                <span style=\\\"font-size: x-large; font-weight: 400;\\\">\\r\\n                  ${sim.document[\\\"Title\\\"]}\\r\\n                </span>\\r\\n                <a style=\\\"font-size: small;\\\" href=${sim.document[\\\"DOI\\\"]}>Link</a>\\r\\n                <br>\\r\\n                <span style=\\\"font-size: small;\\\">\\r\\n                  ${sim.document[\\\"Authors\\\"]}\\r\\n                </span>\\r\\n                <br>\\r\\n                <span style=\\\"font-size: small;\\\">\\r\\n\\r\\n                  <strong>Keywords:</strong> ${sim.document[\\\"Keywords\\\"]}\\r\\n                </span>\\r\\n                <span repeat.for=\\\"keyword of sim.document['Keywords_Processed']\\\" style=\\\"font-size: smaller\\\">\\r\\n                  <md-checkbox disabled.bind=\\\"keyword.isDone\\\" class=\\\"inline_checkbox\\\" model.bind=\\\"keyword\\\"\\r\\n                    checked.bind=\\\"selected_additional_keywords\\\" click.delegate=\\\"selectAddKeyword(keyword)\\\">\\r\\n                  </md-checkbox>\\r\\n                  ${keyword.keyword}\\r\\n                  <!-- <i class=\\\"fad fa-trash-alt\\\" click.delegate=\\\"removeAddKeyword(keyword)\\\" style=\\\"cursor: pointer\\\"></i> -->\\r\\n                  <span>, </span>\\r\\n                </span>\\r\\n                <br>\\r\\n                <ul style=\\\"margin: 0; box-shadow: none; -webkit-box-shadow: none\\\"\\r\\n                  md-collapsible=\\\"accordion.bind: !accordion; popout: false;\\\">\\r\\n                  <li>\\r\\n                    <div style=\\\"padding: 0 0 0 10px;\\\" class=\\\"collapsible-header \\\"> Abstract...</div>\\r\\n                    <div class=\\\"collapsible-body\\\">\\r\\n                      <p>${sim.document[\\\"Abstract\\\"]}</p>\\r\\n                    </div>\\r\\n                  </li>\\r\\n                </ul>\\r\\n              </td>\\r\\n            </tr>\\r\\n          </tbody>\\r\\n        </table>\\r\\n      </div>\\r\\n    </div>\\r\\n  </div>\\r\\n</template>\";"],"mappings":"AAAA","sourceRoot":""}\n//# sourceURL=webpack-internal:///pages/p0.html\n");

/***/ }),

/***/ "resources/converters/custom-filter-sort-length":
/*!***************************************************************!*\
  !*** ./src/resources/converters/custom-filter-sort-length.ts ***!
  \***************************************************************/
/*! exports provided: CustomFilterSortLengthValueConverter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CustomFilterSortLengthValueConverter\", function() { return CustomFilterSortLengthValueConverter; });\nvar CustomFilterSortLengthValueConverter = /** @class */ (function () {\n    function CustomFilterSortLengthValueConverter() {\n    }\n    CustomFilterSortLengthValueConverter.prototype.toView = function (array, config) {\n        var factor = (config.direction || \"ascending\") === \"ascending\" ? 1 : -1;\n        return array.sort(function (a, b) {\n            var first = a[config.filterName] === config.filterValue ? 0 : a[config.propertyName].length;\n            var second = b[config.filterName] === config.filterValue ? 0 : b[config.propertyName].length;\n            return (first - second) * factor;\n        });\n    };\n    return CustomFilterSortLengthValueConverter;\n}());\n\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoicmVzb3VyY2VzL2NvbnZlcnRlcnMvY3VzdG9tLWZpbHRlci1zb3J0LWxlbmd0aC5qcyIsInNvdXJjZXMiOlsid2VicGFjazovLy8uL3NyYy9yZXNvdXJjZXMvY29udmVydGVycy9jdXN0b20tZmlsdGVyLXNvcnQtbGVuZ3RoLnRzPzU5NGQiXSwic291cmNlc0NvbnRlbnQiOlsiZXhwb3J0IGNsYXNzIEN1c3RvbUZpbHRlclNvcnRMZW5ndGhWYWx1ZUNvbnZlcnRlciB7XHJcbiAgdG9WaWV3KGFycmF5LCBjb25maWcpIHtcclxuICAgIGxldCBmYWN0b3IgPSAoY29uZmlnLmRpcmVjdGlvbiB8fCBcImFzY2VuZGluZ1wiKSA9PT0gXCJhc2NlbmRpbmdcIiA/IDEgOiAtMTtcclxuICAgIHJldHVybiBhcnJheS5zb3J0KChhLCBiKSA9PiB7XHJcbiAgICAgIGxldCBmaXJzdCA9IGFbY29uZmlnLmZpbHRlck5hbWVdID09PSBjb25maWcuZmlsdGVyVmFsdWUgPyAwIDogYVtjb25maWcucHJvcGVydHlOYW1lXS5sZW5ndGg7XHJcbiAgICAgIGxldCBzZWNvbmQgPSBiW2NvbmZpZy5maWx0ZXJOYW1lXSA9PT0gY29uZmlnLmZpbHRlclZhbHVlID8gMCA6IGJbY29uZmlnLnByb3BlcnR5TmFtZV0ubGVuZ3RoO1xyXG5cclxuICAgICAgcmV0dXJuIChmaXJzdCAtIHNlY29uZCkgKiBmYWN0b3I7XHJcbiAgICB9KTtcclxuICB9XHJcbn1cclxuIl0sIm1hcHBpbmdzIjoiQUFBQTtBQUFBO0FBQUE7QUFBQTtBQVVBO0FBVEE7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUVBO0FBQ0E7QUFDQTtBQUNBO0FBQUE7OyIsInNvdXJjZVJvb3QiOiIifQ==\n//# sourceURL=webpack-internal:///resources/converters/custom-filter-sort-length\n");

/***/ }),

/***/ "resources/converters/custom-sort":
/*!*************************************************!*\
  !*** ./src/resources/converters/custom-sort.ts ***!
  \*************************************************/
/*! exports provided: CustomSortValueConverter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CustomSortValueConverter\", function() { return CustomSortValueConverter; });\nvar CustomSortValueConverter = /** @class */ (function () {\n    function CustomSortValueConverter() {\n    }\n    CustomSortValueConverter.prototype.toView = function (array, config) {\n        var factor = (config.direction || \"ascending\") === \"ascending\" ? 1 : -1;\n        return array.sort(function (a, b) {\n            return (a[config.propertyName] - b[config.propertyName]) * factor;\n        });\n    };\n    return CustomSortValueConverter;\n}());\n\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoicmVzb3VyY2VzL2NvbnZlcnRlcnMvY3VzdG9tLXNvcnQuanMiLCJzb3VyY2VzIjpbIndlYnBhY2s6Ly8vLi9zcmMvcmVzb3VyY2VzL2NvbnZlcnRlcnMvY3VzdG9tLXNvcnQudHM/NDczZSJdLCJzb3VyY2VzQ29udGVudCI6WyJleHBvcnQgY2xhc3MgQ3VzdG9tU29ydFZhbHVlQ29udmVydGVyIHtcbiAgdG9WaWV3KGFycmF5LCBjb25maWcpIHtcbiAgICBsZXQgZmFjdG9yID0gKGNvbmZpZy5kaXJlY3Rpb24gfHwgXCJhc2NlbmRpbmdcIikgPT09IFwiYXNjZW5kaW5nXCIgPyAxIDogLTE7XG4gICAgcmV0dXJuIGFycmF5LnNvcnQoKGEsIGIpID0+IHtcbiAgICAgIHJldHVybiAoYVtjb25maWcucHJvcGVydHlOYW1lXSAtIGJbY29uZmlnLnByb3BlcnR5TmFtZV0pICogZmFjdG9yO1xuICAgIH0pO1xuICB9XG59XG4iXSwibWFwcGluZ3MiOiJBQUFBO0FBQUE7QUFBQTtBQUFBO0FBT0E7QUFOQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUFBOzsiLCJzb3VyY2VSb290IjoiIn0=\n//# sourceURL=webpack-internal:///resources/converters/custom-sort\n");

/***/ }),

/***/ "resources/converters/custom-sort-length":
/*!********************************************************!*\
  !*** ./src/resources/converters/custom-sort-length.ts ***!
  \********************************************************/
/*! exports provided: CustomSortLengthValueConverter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CustomSortLengthValueConverter\", function() { return CustomSortLengthValueConverter; });\nvar CustomSortLengthValueConverter = /** @class */ (function () {\n    function CustomSortLengthValueConverter() {\n    }\n    CustomSortLengthValueConverter.prototype.toView = function (array, config) {\n        var factor = (config.direction || \"ascending\") === \"ascending\" ? 1 : -1;\n        return array.sort(function (a, b) {\n            return (a[config.propertyName].length - b[config.propertyName].length) * factor;\n        });\n    };\n    return CustomSortLengthValueConverter;\n}());\n\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoicmVzb3VyY2VzL2NvbnZlcnRlcnMvY3VzdG9tLXNvcnQtbGVuZ3RoLmpzIiwic291cmNlcyI6WyJ3ZWJwYWNrOi8vLy4vc3JjL3Jlc291cmNlcy9jb252ZXJ0ZXJzL2N1c3RvbS1zb3J0LWxlbmd0aC50cz9kOGRiIl0sInNvdXJjZXNDb250ZW50IjpbImV4cG9ydCBjbGFzcyBDdXN0b21Tb3J0TGVuZ3RoVmFsdWVDb252ZXJ0ZXIge1xyXG4gIHRvVmlldyhhcnJheSwgY29uZmlnKSB7XHJcbiAgICBsZXQgZmFjdG9yID0gKGNvbmZpZy5kaXJlY3Rpb24gfHwgXCJhc2NlbmRpbmdcIikgPT09IFwiYXNjZW5kaW5nXCIgPyAxIDogLTE7XHJcbiAgICByZXR1cm4gYXJyYXkuc29ydCgoYSwgYikgPT4ge1xyXG4gICAgICByZXR1cm4gKGFbY29uZmlnLnByb3BlcnR5TmFtZV0ubGVuZ3RoIC0gYltjb25maWcucHJvcGVydHlOYW1lXS5sZW5ndGgpICogZmFjdG9yO1xyXG4gICAgfSk7XHJcbiAgfVxyXG59XHJcbiJdLCJtYXBwaW5ncyI6IkFBQUE7QUFBQTtBQUFBO0FBQUE7QUFPQTtBQU5BO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBQUE7OyIsInNvdXJjZVJvb3QiOiIifQ==\n//# sourceURL=webpack-internal:///resources/converters/custom-sort-length\n");

/***/ }),

/***/ "resources/converters/filter":
/*!********************************************!*\
  !*** ./src/resources/converters/filter.ts ***!
  \********************************************/
/*! exports provided: FilterValueConverter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FilterValueConverter\", function() { return FilterValueConverter; });\nvar FilterValueConverter = /** @class */ (function () {\n    function FilterValueConverter() {\n    }\n    FilterValueConverter.prototype.toView = function (array, searchTerm, filterFunc) {\n        return array.filter(function (item) {\n            var matches = searchTerm && searchTerm.length > 0 ? filterFunc(searchTerm, item) : true;\n            return matches;\n        });\n    };\n    return FilterValueConverter;\n}());\n\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoicmVzb3VyY2VzL2NvbnZlcnRlcnMvZmlsdGVyLmpzIiwic291cmNlcyI6WyJ3ZWJwYWNrOi8vLy4vc3JjL3Jlc291cmNlcy9jb252ZXJ0ZXJzL2ZpbHRlci50cz9iNDhmIl0sInNvdXJjZXNDb250ZW50IjpbImV4cG9ydCBjbGFzcyBGaWx0ZXJWYWx1ZUNvbnZlcnRlciB7XG4gICAgdG9WaWV3KGFycmF5LCBzZWFyY2hUZXJtLCBmaWx0ZXJGdW5jKSB7XG4gICAgICAgIHJldHVybiBhcnJheS5maWx0ZXIoKGl0ZW0pID0+IHtcblxuICAgICAgICAgICAgbGV0IG1hdGNoZXMgPSBzZWFyY2hUZXJtICYmIHNlYXJjaFRlcm0ubGVuZ3RoID4gMCA/IGZpbHRlckZ1bmMoc2VhcmNoVGVybSwgaXRlbSkgOiB0cnVlO1xuXG4gICAgICAgICAgICByZXR1cm4gbWF0Y2hlcztcbiAgICAgICAgfSk7XG4gICAgfVxufSJdLCJtYXBwaW5ncyI6IkFBQUE7QUFBQTtBQUFBO0FBQUE7QUFTQTtBQVJBO0FBQ0E7QUFFQTtBQUVBO0FBQ0E7QUFDQTtBQUNBO0FBQUE7OyIsInNvdXJjZVJvb3QiOiIifQ==\n//# sourceURL=webpack-internal:///resources/converters/filter\n");

/***/ }),

/***/ "resources/converters/filter-property":
/*!*****************************************************!*\
  !*** ./src/resources/converters/filter-property.ts ***!
  \*****************************************************/
/*! exports provided: FilterPropertyValueConverter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FilterPropertyValueConverter\", function() { return FilterPropertyValueConverter; });\nvar FilterPropertyValueConverter = /** @class */ (function () {\n    function FilterPropertyValueConverter() {\n    }\n    FilterPropertyValueConverter.prototype.toView = function (array, active, property) {\n        return array.filter(function (item) {\n            var f = !active ? !item[property] : true;\n            return f;\n        });\n    };\n    return FilterPropertyValueConverter;\n}());\n\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoicmVzb3VyY2VzL2NvbnZlcnRlcnMvZmlsdGVyLXByb3BlcnR5LmpzIiwic291cmNlcyI6WyJ3ZWJwYWNrOi8vLy4vc3JjL3Jlc291cmNlcy9jb252ZXJ0ZXJzL2ZpbHRlci1wcm9wZXJ0eS50cz9hNWJlIl0sInNvdXJjZXNDb250ZW50IjpbImV4cG9ydCBjbGFzcyBGaWx0ZXJQcm9wZXJ0eVZhbHVlQ29udmVydGVyIHtcbiAgICB0b1ZpZXcoYXJyYXksIGFjdGl2ZSwgcHJvcGVydHkpIHtcbiAgICAgICAgcmV0dXJuIGFycmF5LmZpbHRlcigoaXRlbSkgPT4ge1xuICAgICAgICAgICAgbGV0IGYgPSAhYWN0aXZlID8gIWl0ZW1bcHJvcGVydHldIDogdHJ1ZTtcbiAgICAgICAgICAgIHJldHVybiBmXG4gICAgICAgIH0pO1xuICAgIH1cbn0iXSwibWFwcGluZ3MiOiJBQUFBO0FBQUE7QUFBQTtBQUFBO0FBT0E7QUFOQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUFBOzsiLCJzb3VyY2VSb290IjoiIn0=\n//# sourceURL=webpack-internal:///resources/converters/filter-property\n");

/***/ }),

/***/ "resources/converters/number-format":
/*!***************************************************!*\
  !*** ./src/resources/converters/number-format.ts ***!
  \***************************************************/
/*! exports provided: NumberFormatValueConverter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"NumberFormatValueConverter\", function() { return NumberFormatValueConverter; });\n/* harmony import */ var numeral__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! numeral */ \"./node_modules/numeral/numeral.js\");\n/* harmony import */ var numeral__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(numeral__WEBPACK_IMPORTED_MODULE_0__);\n\nvar NumberFormatValueConverter = /** @class */ (function () {\n    function NumberFormatValueConverter() {\n    }\n    NumberFormatValueConverter.prototype.toView = function (value, format) {\n        return numeral__WEBPACK_IMPORTED_MODULE_0___default()(value).format(format);\n    };\n    return NumberFormatValueConverter;\n}());\n\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoicmVzb3VyY2VzL2NvbnZlcnRlcnMvbnVtYmVyLWZvcm1hdC5qcyIsInNvdXJjZXMiOlsid2VicGFjazovLy8uL3NyYy9yZXNvdXJjZXMvY29udmVydGVycy9udW1iZXItZm9ybWF0LnRzP2M1YTMiXSwic291cmNlc0NvbnRlbnQiOlsiaW1wb3J0IG51bWVyYWwgZnJvbSAnbnVtZXJhbCc7XG5cbiBleHBvcnQgY2xhc3MgTnVtYmVyRm9ybWF0VmFsdWVDb252ZXJ0ZXIge1xuICAgdG9WaWV3KHZhbHVlLCBmb3JtYXQpIHtcbiAgICAgcmV0dXJuIG51bWVyYWwodmFsdWUpLmZvcm1hdChmb3JtYXQpO1xuICAgfVxuIH1cbiJdLCJtYXBwaW5ncyI6IkFBQUE7QUFBQTtBQUFBO0FBQUE7QUFBQTtBQUVBO0FBQUE7QUFJQTtBQUhBO0FBQ0E7QUFDQTtBQUNBO0FBQUE7OyIsInNvdXJjZVJvb3QiOiIifQ==\n//# sourceURL=webpack-internal:///resources/converters/number-format\n");

/***/ }),

/***/ "resources/converters/time-format":
/*!*************************************************!*\
  !*** ./src/resources/converters/time-format.ts ***!
  \*************************************************/
/*! exports provided: TimeFormatValueConverter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TimeFormatValueConverter\", function() { return TimeFormatValueConverter; });\n/* harmony import */ var moment__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! moment */ \"./node_modules/moment/moment.js\");\n/* harmony import */ var moment__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(moment__WEBPACK_IMPORTED_MODULE_0__);\n\nvar TimeFormatValueConverter = /** @class */ (function () {\n    function TimeFormatValueConverter() {\n    }\n    TimeFormatValueConverter.prototype.toView = function (value) {\n        return moment__WEBPACK_IMPORTED_MODULE_0__(\"2015-01-01\").startOf('day')\n            .seconds(value)\n            .format('H:mm:ss');\n    };\n    return TimeFormatValueConverter;\n}());\n\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoicmVzb3VyY2VzL2NvbnZlcnRlcnMvdGltZS1mb3JtYXQuanMiLCJzb3VyY2VzIjpbIndlYnBhY2s6Ly8vLi9zcmMvcmVzb3VyY2VzL2NvbnZlcnRlcnMvdGltZS1mb3JtYXQudHM/NGVhYyJdLCJzb3VyY2VzQ29udGVudCI6WyJpbXBvcnQgKiBhcyBtb21lbnQgZnJvbSAnbW9tZW50JztcclxuXHJcbmV4cG9ydCBjbGFzcyBUaW1lRm9ybWF0VmFsdWVDb252ZXJ0ZXIge1xyXG4gICAgdG9WaWV3KHZhbHVlKSB7XHJcbiAgICAgICAgcmV0dXJuIG1vbWVudChcIjIwMTUtMDEtMDFcIikuc3RhcnRPZignZGF5JylcclxuICAgICAgICAgICAgLnNlY29uZHModmFsdWUpXHJcbiAgICAgICAgICAgIC5mb3JtYXQoJ0g6bW06c3MnKTtcclxuICAgIH1cclxufVxyXG5cclxuXHJcbiJdLCJtYXBwaW5ncyI6IkFBQUE7QUFBQTtBQUFBO0FBQUE7QUFBQTtBQUVBO0FBQUE7QUFNQTtBQUxBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUFBOzsiLCJzb3VyY2VSb290IjoiIn0=\n//# sourceURL=webpack-internal:///resources/converters/time-format\n");

/***/ }),

/***/ "resources/elements/bar-chart":
/*!*********************************************!*\
  !*** ./src/resources/elements/bar-chart.ts ***!
  \*********************************************/
/*! exports provided: BarChartCustomElement */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"BarChartCustomElement\", function() { return BarChartCustomElement; });\n/* harmony import */ var d3__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! d3 */ \"./node_modules/d3/index.js\");\n/* harmony import */ var aurelia_framework__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! aurelia-framework */ \"aurelia-framework\");\nvar __decorate = (undefined && undefined.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nvar __metadata = (undefined && undefined.__metadata) || function (k, v) {\n    if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(k, v);\n};\n\n\nvar BarChartCustomElement = /** @class */ (function () {\n    function BarChartCustomElement(element) {\n        this.element = element;\n        this.bins = \"10\";\n        this.xSize = \"150\";\n        this.ySize = \"50\";\n        // D3 variables\n        this.isInitialized = false;\n        this.margin = { top: 5, right: 10, bottom: 20, left: 10 };\n    }\n    BarChartCustomElement.prototype.attached = function () {\n        this.width = parseInt(this.xSize) - this.margin.left - this.margin.right;\n        this.height = parseInt(this.ySize) - this.margin.top - this.margin.bottom;\n        this.initChart();\n        // this.updateChart();\n        this.isInitialized = true;\n    };\n    BarChartCustomElement.prototype.dataChanged = function (data) {\n        if (data.length) {\n            // Convert string to array of numbers\n            if (typeof data === \"string\") {\n                this.data = data.split(\",\").map(Number);\n            }\n            if (this.isInitialized) {\n                this.updateChart();\n            }\n        }\n    };\n    BarChartCustomElement.prototype.initChart = function () {\n        // append the svg object to the chart div of the page\n        // append a 'group' element to 'svg'\n        // moves the 'group' element to the top left margin\n        this.svg = d3__WEBPACK_IMPORTED_MODULE_0__[\"select\"](this.element)\n            .append(\"svg\")\n            .attr(\"width\", this.width + this.margin.left + this.margin.right)\n            .attr(\"height\", this.height + this.margin.top + this.margin.bottom)\n            .append(\"g\")\n            .attr(\"transform\", \"translate(\" + this.margin.left + \",\" + this.margin.top + \")\");\n        // set the ranges\n        this.x = d3__WEBPACK_IMPORTED_MODULE_0__[\"scaleLinear\"]()\n            .domain([0, 1])\n            .range([0, this.width]);\n        this.y = d3__WEBPACK_IMPORTED_MODULE_0__[\"scaleLinear\"]()\n            .range([this.height, 0]);\n        // add the x Axis\n        this.svg.append(\"g\")\n            .attr(\"transform\", \"translate(0,\" + this.height + \")\")\n            .attr(\"class\", \"xAxis\");\n        // add the y Axis\n        // this.svg.append(\"g\")\n        //   .attr(\"class\", \"yAxis\");\n    };\n    BarChartCustomElement.prototype.updateChart = function () {\n        var self = this;\n        // Compute histogram\n        var histogram = d3__WEBPACK_IMPORTED_MODULE_0__[\"histogram\"]()\n            .value(function (d) { return +d; })\n            .domain(self.x.domain())\n            .thresholds(self.x.ticks(parseInt(self.bins)));\n        var bins = histogram(self.data);\n        // Update domains\n        this.y.domain([0, d3__WEBPACK_IMPORTED_MODULE_0__[\"max\"](bins, function (d) { return d.length; })]);\n        this.svg.selectAll(\".xAxis\")\n            .call(d3__WEBPACK_IMPORTED_MODULE_0__[\"axisBottom\"](this.x).ticks(5));\n        var chart = this.svg.selectAll(\"rect\")\n            .data(bins);\n        // Select chart\n        // let chart = this.svg.selectAll(\"g.bar\")\n        //   .data(data)\n        //   .enter()\n        //   .append(\"g\")\n        //   .attr(\"class\", \"bar\")\n        //   .attr(\"transform\", function (d) {\n        //     return \"translate(\" + (self.x(d[\"party\"])) + \",0)\"\n        //   })\n        //   .on(\"click\", function (d) {\n        //   })\n        // Update axis\n        // this.svg.selectAll(\".yAxis\")\n        //   .call(d3.axisLeft(this.y));\n        // Add and update points\n        chart\n            .enter()\n            .append(\"rect\")\n            // .on(\"click\", function(d) {\n            //   // dispatchify(select)(d)\n            // })\n            .merge(chart)\n            .transition(1000)\n            .attr(\"x\", 1)\n            .attr(\"transform\", function (d) { return \"translate(\" + self.x(d.x0) + \",\" + self.y(d.length) + \")\"; })\n            .attr(\"width\", function (d) {\n            return self.x(d.x1) - self.x(d.x0);\n        })\n            .attr(\"height\", function (d) { return self.height - self.y(d.length); })\n            .style(\"fill\", \"steelblue\");\n        // chart.append(\"text\")\n        //   .merge(chart)\n        //   .transition(1000)\n        //   // .attr(\"width\", self.x.bandwidth())\n        //   .attr(\"y\", function (d) { return self.y(d[\"total\"]) - 3; })\n        //   // .attr(\"height\", function(d) { return self.height - self.y(d[\"total\"]); });\n        //   .text(function (d) { return d[\"total\"]; })\n        // Remove points\n        chart.exit().remove();\n    };\n    __decorate([\n        aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"bindable\"],\n        __metadata(\"design:type\", Array)\n    ], BarChartCustomElement.prototype, \"data\", void 0);\n    __decorate([\n        aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"bindable\"],\n        __metadata(\"design:type\", String)\n    ], BarChartCustomElement.prototype, \"property\", void 0);\n    __decorate([\n        aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"bindable\"],\n        __metadata(\"design:type\", String)\n    ], BarChartCustomElement.prototype, \"bins\", void 0);\n    __decorate([\n        aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"bindable\"],\n        __metadata(\"design:type\", String)\n    ], BarChartCustomElement.prototype, \"xSize\", void 0);\n    __decorate([\n        aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"bindable\"],\n        __metadata(\"design:type\", String)\n    ], BarChartCustomElement.prototype, \"ySize\", void 0);\n    BarChartCustomElement = __decorate([\n        Object(aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"inject\"])(Element),\n        Object(aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"noView\"])(),\n        __metadata(\"design:paramtypes\", [Element])\n    ], BarChartCustomElement);\n    return BarChartCustomElement;\n}());\n\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,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\n//# sourceURL=webpack-internal:///resources/elements/bar-chart\n");

/***/ }),

/***/ "resources/elements/graph-plot":
/*!**********************************************!*\
  !*** ./src/resources/elements/graph-plot.ts ***!
  \**********************************************/
/*! exports provided: GraphPlotCustomElement */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"GraphPlotCustomElement\", function() { return GraphPlotCustomElement; });\n/* harmony import */ var d3__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! d3 */ \"./node_modules/d3/index.js\");\n/* harmony import */ var aurelia_framework__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! aurelia-framework */ \"aurelia-framework\");\nvar __decorate = (undefined && undefined.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nvar __metadata = (undefined && undefined.__metadata) || function (k, v) {\n    if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(k, v);\n};\n\n\nvar GraphPlotCustomElement = /** @class */ (function () {\n    function GraphPlotCustomElement(element) {\n        this.element = element;\n        // set the dimensions and margins of the graph\n        this.margin = { top: 20, right: 20, bottom: 30, left: 40 };\n        this.width = 300 - this.margin.left - this.margin.right;\n        this.height = 300 - this.margin.top - this.margin.bottom;\n        this.initChart();\n        // https://github.com/wbkd/d3-extended\n        d3__WEBPACK_IMPORTED_MODULE_0__[\"selection\"].prototype.moveToFront = function () {\n            return this.each(function () {\n                this.parentNode.appendChild(this);\n            });\n        };\n        d3__WEBPACK_IMPORTED_MODULE_0__[\"selection\"].prototype.moveToBack = function () {\n            return this.each(function () {\n                var firstChild = this.parentNode.firstChild;\n                if (firstChild) {\n                    this.parentNode.insertBefore(this, firstChild);\n                }\n            });\n        };\n    }\n    GraphPlotCustomElement.prototype.dataChanged = function (data) {\n        this.svg.selectAll(\"line\").remove();\n        this.svg.selectAll(\"circle\").remove();\n        this.updateChart();\n    };\n    GraphPlotCustomElement.prototype.initChart = function () {\n        // append the svg object to the chart div of the page\n        // append a 'group' element to 'svg'\n        // moves the 'group' element to the top left margin\n        // this.svg = d3.create(\"svg\")\n        //   .attr(\"viewBox\", [-100 / 2, -100 / 2, 100, 100]);\n        this.svg = d3__WEBPACK_IMPORTED_MODULE_0__[\"select\"](this.element)\n            .append(\"svg\")\n            .attr(\"width\", this.width + this.margin.left + this.margin.right)\n            .attr(\"height\", this.height + this.margin.top + this.margin.bottom);\n        //   .append(\"g\")\n        //   .attr(\"transform\",\n        //     \"translate(\" + this.margin.left + \",\" + this.margin.top + \")\");\n    };\n    GraphPlotCustomElement.prototype.updateChart = function () {\n        var self = this;\n        var links = this.data[\"links\"].map(function (d) { return d; });\n        var nodes = this.data[\"nodes\"].map(function (d) { return d; });\n        var simulation = d3__WEBPACK_IMPORTED_MODULE_0__[\"forceSimulation\"](nodes)\n            // .force(\"link\", d3.forceLink(links).id(function (d) { return d[\"id\"]; }).strength(function (d) { return d[\"strength\"]; })\n            // .distance(100))\n            .force(\"links\", d3__WEBPACK_IMPORTED_MODULE_0__[\"forceLink\"](links))\n            .force(\"charge\", d3__WEBPACK_IMPORTED_MODULE_0__[\"forceManyBody\"]())\n            .force(\"center\", d3__WEBPACK_IMPORTED_MODULE_0__[\"forceCenter\"](this.width / 2, this.height / 2));\n        // .force(\"x\", d3.forceX())\n        // .force(\"y\", d3.forceY());\n        var link = this.svg.append(\"g\")\n            .attr(\"stroke\", \"#999\")\n            .attr(\"stroke-opacity\", 0.6)\n            .selectAll(\"line\")\n            .data(links)\n            .join(\"line\")\n            .attr(\"stroke-width\", function (d) { return d.strength * 10; });\n        // .attr(\"stroke-width\", d => Math.sqrt(d.value));\n        var node = this.svg.append(\"g\")\n            .attr(\"stroke\", \"#fff\")\n            .attr(\"stroke-width\", 1.5)\n            .selectAll(\"circle\")\n            .data(nodes)\n            .join(\"circle\")\n            .attr(\"r\", 5)\n            .attr(\"fill\", \"green\");\n        simulation.on(\"tick\", function () {\n            link\n                .attr(\"x1\", function (d) { return d[\"source\"].x; })\n                .attr(\"y1\", function (d) { return d[\"source\"].y; })\n                .attr(\"x2\", function (d) { return d[\"target\"].x; })\n                .attr(\"y2\", function (d) { return d[\"target\"].y; });\n            node\n                .attr(\"cx\", function (d) { return d.x; })\n                .attr(\"cy\", function (d) { return d.y; });\n        });\n    };\n    __decorate([\n        aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"bindable\"],\n        __metadata(\"design:type\", Array)\n    ], GraphPlotCustomElement.prototype, \"data\", void 0);\n    GraphPlotCustomElement = __decorate([\n        Object(aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"inject\"])(Element),\n        Object(aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"noView\"])(),\n        __metadata(\"design:paramtypes\", [Element])\n    ], GraphPlotCustomElement);\n    return GraphPlotCustomElement;\n}());\n\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,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\n//# sourceURL=webpack-internal:///resources/elements/graph-plot\n");

/***/ }),

/***/ "resources/elements/scatter-plot":
/*!************************************************!*\
  !*** ./src/resources/elements/scatter-plot.ts ***!
  \************************************************/
/*! exports provided: ScatterPlotCustomElement */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ScatterPlotCustomElement\", function() { return ScatterPlotCustomElement; });\n/* harmony import */ var d3__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! d3 */ \"./node_modules/d3/index.js\");\n/* harmony import */ var aurelia_framework__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! aurelia-framework */ \"aurelia-framework\");\nvar __decorate = (undefined && undefined.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nvar __metadata = (undefined && undefined.__metadata) || function (k, v) {\n    if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(k, v);\n};\n\n\nvar ScatterPlotCustomElement = /** @class */ (function () {\n    function ScatterPlotCustomElement(element) {\n        this.element = element;\n        // set the dimensions and margins of the graph\n        this.margin = { top: 20, right: 20, bottom: 30, left: 40 };\n        this.width = 600 - this.margin.left - this.margin.right;\n        this.height = 500 - this.margin.top - this.margin.bottom;\n        this.initChart();\n        // https://github.com/wbkd/d3-extended\n        d3__WEBPACK_IMPORTED_MODULE_0__[\"selection\"].prototype.moveToFront = function () {\n            return this.each(function () {\n                this.parentNode.appendChild(this);\n            });\n        };\n        d3__WEBPACK_IMPORTED_MODULE_0__[\"selection\"].prototype.moveToBack = function () {\n            return this.each(function () {\n                var firstChild = this.parentNode.firstChild;\n                if (firstChild) {\n                    this.parentNode.insertBefore(this, firstChild);\n                }\n            });\n        };\n    }\n    ScatterPlotCustomElement.prototype.initChart = function () {\n        // append the svg object to the chart div of the page\n        // append a 'group' element to 'svg'\n        // moves the 'group' element to the top left margin\n        this.svg = d3__WEBPACK_IMPORTED_MODULE_0__[\"select\"](this.element)\n            .append(\"svg\")\n            .attr(\"width\", this.width + this.margin.left + this.margin.right)\n            .attr(\"height\", this.height + this.margin.top + this.margin.bottom)\n            .append(\"g\")\n            .attr(\"transform\", \"translate(\" + this.margin.left + \",\" + this.margin.top + \")\");\n        // set the ranges\n        this.x = d3__WEBPACK_IMPORTED_MODULE_0__[\"scaleLinear\"]()\n            .range([0, this.width]);\n        this.y = d3__WEBPACK_IMPORTED_MODULE_0__[\"scaleLinear\"]()\n            .range([this.height, 0]);\n        // add the x Axis\n        this.svg.append(\"g\")\n            .attr(\"transform\", \"translate(0,\" + this.height + \")\")\n            .attr(\"class\", \"xAxis\");\n        // add the y Axis\n        this.svg.append(\"g\")\n            .attr(\"class\", \"yAxis\");\n    };\n    ScatterPlotCustomElement.prototype.updateChart = function (state) {\n        var self = this;\n        var data = []; //this.store.getProjections();\n        // Update domains\n        // this.x.domain(d3.extent(data, function (d) { return +d[state.selectedProjection][0] }));\n        // this.y.domain(d3.extent(data, function (d) { return +d[state.selectedProjection][1] }));\n        // Select chart\n        var chart = this.svg.selectAll(\".points\")\n            .data(data);\n        // Update axis\n        this.svg.selectAll(\".xAxis\")\n            .call(d3__WEBPACK_IMPORTED_MODULE_0__[\"axisBottom\"](this.x));\n        this.svg.selectAll(\".yAxis\")\n            .call(d3__WEBPACK_IMPORTED_MODULE_0__[\"axisLeft\"](this.y));\n        // Remove points\n        chart.exit().remove();\n        // Add and update points\n        chart.enter()\n            .append(\"circle\")\n            .attr(\"class\", \"point\")\n            .attr('r', 5)\n            .on(\"mouseover\", function (d, i) {\n        })\n            .merge(chart)\n            .transition(1000)\n            // .attr('cx', function (d) { return self.x(d[state.selectedProjection][0]); })\n            // .attr('cy', function (d) { return self.y(d[state.selectedProjection][1]); })\n            .style('opacity', function (d, i) {\n            var opacity;\n            return opacity;\n        });\n        // .style('fill',  function(d, i){\n        //   let color;\n        //   if(self.store.getMetaData(i)[\"type\"] == \"new\") {\n        //     color = \"steelblue\"\n        //     d3.select(this).moveToFront()\n        //   }\n        //   else {\n        //     color = \"lightgrey\"\n        //     d3.select(this).moveToBack()\n        //   }\n        //   return color\n        // });\n    };\n    ScatterPlotCustomElement = __decorate([\n        Object(aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"inject\"])(Element),\n        Object(aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"noView\"])(),\n        __metadata(\"design:paramtypes\", [Element])\n    ], ScatterPlotCustomElement);\n    return ScatterPlotCustomElement;\n}());\n\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoicmVzb3VyY2VzL2VsZW1lbnRzL3NjYXR0ZXItcGxvdC5qcyIsInNvdXJjZXMiOlsid2VicGFjazovLy8uL3NyYy9yZXNvdXJjZXMvZWxlbWVudHMvc2NhdHRlci1wbG90LnRzP2M4OTgiXSwic291cmNlc0NvbnRlbnQiOlsiaW1wb3J0ICogYXMgZDMgZnJvbSBcImQzXCI7XG5pbXBvcnQgeyBpbmplY3QsIG5vVmlldyB9IGZyb20gJ2F1cmVsaWEtZnJhbWV3b3JrJztcbmltcG9ydCAqIGFzIF8gZnJvbSBcImxvZGFzaFwiXG5cblxuQGluamVjdChFbGVtZW50KVxuQG5vVmlldygpXG5leHBvcnQgY2xhc3MgU2NhdHRlclBsb3RDdXN0b21FbGVtZW50IHtcbiAgLy8gRDMgdmFyaWFibGVzXG4gIHByaXZhdGUgc3ZnO1xuICBwcml2YXRlIHg7XG4gIHByaXZhdGUgeTtcblxuICAvLyBzZXQgdGhlIGRpbWVuc2lvbnMgYW5kIG1hcmdpbnMgb2YgdGhlIGdyYXBoXG4gIG1hcmdpbiA9IHsgdG9wOiAyMCwgcmlnaHQ6IDIwLCBib3R0b206IDMwLCBsZWZ0OiA0MCB9O1xuICB3aWR0aCA9IDYwMCAtIHRoaXMubWFyZ2luLmxlZnQgLSB0aGlzLm1hcmdpbi5yaWdodDtcbiAgaGVpZ2h0ID0gNTAwIC0gdGhpcy5tYXJnaW4udG9wIC0gdGhpcy5tYXJnaW4uYm90dG9tO1xuXG4gIGNvbnN0cnVjdG9yKHB1YmxpYyBlbGVtZW50OiBFbGVtZW50KSB7XG4gICAgdGhpcy5pbml0Q2hhcnQoKTtcblxuICAgIC8vIGh0dHBzOi8vZ2l0aHViLmNvbS93YmtkL2QzLWV4dGVuZGVkXG4gICAgZDMuc2VsZWN0aW9uLnByb3RvdHlwZS5tb3ZlVG9Gcm9udCA9IGZ1bmN0aW9uICgpIHtcbiAgICAgIHJldHVybiB0aGlzLmVhY2goZnVuY3Rpb24gKCkge1xuICAgICAgICB0aGlzLnBhcmVudE5vZGUuYXBwZW5kQ2hpbGQodGhpcyk7XG4gICAgICB9KTtcbiAgICB9O1xuXG4gICAgZDMuc2VsZWN0aW9uLnByb3RvdHlwZS5tb3ZlVG9CYWNrID0gZnVuY3Rpb24gKCkge1xuICAgICAgcmV0dXJuIHRoaXMuZWFjaChmdW5jdGlvbiAoKSB7XG4gICAgICAgIHZhciBmaXJzdENoaWxkID0gdGhpcy5wYXJlbnROb2RlLmZpcnN0Q2hpbGQ7XG4gICAgICAgIGlmIChmaXJzdENoaWxkKSB7XG4gICAgICAgICAgdGhpcy5wYXJlbnROb2RlLmluc2VydEJlZm9yZSh0aGlzLCBmaXJzdENoaWxkKTtcbiAgICAgICAgfVxuICAgICAgfSk7XG4gICAgfTtcbiAgfVxuXG4gIGluaXRDaGFydCgpIHtcbiAgICAvLyBhcHBlbmQgdGhlIHN2ZyBvYmplY3QgdG8gdGhlIGNoYXJ0IGRpdiBvZiB0aGUgcGFnZVxuICAgIC8vIGFwcGVuZCBhICdncm91cCcgZWxlbWVudCB0byAnc3ZnJ1xuICAgIC8vIG1vdmVzIHRoZSAnZ3JvdXAnIGVsZW1lbnQgdG8gdGhlIHRvcCBsZWZ0IG1hcmdpblxuICAgIHRoaXMuc3ZnID0gZDMuc2VsZWN0KHRoaXMuZWxlbWVudClcbiAgICAgIC5hcHBlbmQoXCJzdmdcIilcbiAgICAgIC5hdHRyKFwid2lkdGhcIiwgdGhpcy53aWR0aCArIHRoaXMubWFyZ2luLmxlZnQgKyB0aGlzLm1hcmdpbi5yaWdodClcbiAgICAgIC5hdHRyKFwiaGVpZ2h0XCIsIHRoaXMuaGVpZ2h0ICsgdGhpcy5tYXJnaW4udG9wICsgdGhpcy5tYXJnaW4uYm90dG9tKVxuICAgICAgLmFwcGVuZChcImdcIilcbiAgICAgIC5hdHRyKFwidHJhbnNmb3JtXCIsXG4gICAgICAgIFwidHJhbnNsYXRlKFwiICsgdGhpcy5tYXJnaW4ubGVmdCArIFwiLFwiICsgdGhpcy5tYXJnaW4udG9wICsgXCIpXCIpO1xuXG4gICAgLy8gc2V0IHRoZSByYW5nZXNcbiAgICB0aGlzLnggPSBkMy5zY2FsZUxpbmVhcigpXG4gICAgICAucmFuZ2UoWzAsIHRoaXMud2lkdGhdKTtcblxuICAgIHRoaXMueSA9IGQzLnNjYWxlTGluZWFyKClcbiAgICAgIC5yYW5nZShbdGhpcy5oZWlnaHQsIDBdKTtcblxuICAgIC8vIGFkZCB0aGUgeCBBeGlzXG4gICAgdGhpcy5zdmcuYXBwZW5kKFwiZ1wiKVxuICAgICAgLmF0dHIoXCJ0cmFuc2Zvcm1cIiwgXCJ0cmFuc2xhdGUoMCxcIiArIHRoaXMuaGVpZ2h0ICsgXCIpXCIpXG4gICAgICAuYXR0cihcImNsYXNzXCIsIFwieEF4aXNcIik7XG5cbiAgICAvLyBhZGQgdGhlIHkgQXhpc1xuICAgIHRoaXMuc3ZnLmFwcGVuZChcImdcIilcbiAgICAgIC5hdHRyKFwiY2xhc3NcIiwgXCJ5QXhpc1wiKTtcbiAgfVxuXG4gIHVwZGF0ZUNoYXJ0KHN0YXRlKSB7XG4gICAgbGV0IHNlbGYgPSB0aGlzO1xuXG4gICAgbGV0IGRhdGEgPSBbXS8vdGhpcy5zdG9yZS5nZXRQcm9qZWN0aW9ucygpO1xuXG4gICAgLy8gVXBkYXRlIGRvbWFpbnNcbiAgICAvLyB0aGlzLnguZG9tYWluKGQzLmV4dGVudChkYXRhLCBmdW5jdGlvbiAoZCkgeyByZXR1cm4gK2Rbc3RhdGUuc2VsZWN0ZWRQcm9qZWN0aW9uXVswXSB9KSk7XG4gICAgLy8gdGhpcy55LmRvbWFpbihkMy5leHRlbnQoZGF0YSwgZnVuY3Rpb24gKGQpIHsgcmV0dXJuICtkW3N0YXRlLnNlbGVjdGVkUHJvamVjdGlvbl1bMV0gfSkpO1xuXG4gICAgLy8gU2VsZWN0IGNoYXJ0XG4gICAgbGV0IGNoYXJ0ID0gdGhpcy5zdmcuc2VsZWN0QWxsKFwiLnBvaW50c1wiKVxuICAgICAgLmRhdGEoZGF0YSlcblxuICAgIC8vIFVwZGF0ZSBheGlzXG4gICAgdGhpcy5zdmcuc2VsZWN0QWxsKFwiLnhBeGlzXCIpXG4gICAgICAuY2FsbChkMy5heGlzQm90dG9tKHRoaXMueCkpO1xuICAgIHRoaXMuc3ZnLnNlbGVjdEFsbChcIi55QXhpc1wiKVxuICAgICAgLmNhbGwoZDMuYXhpc0xlZnQodGhpcy55KSk7XG5cbiAgICAvLyBSZW1vdmUgcG9pbnRzXG4gICAgY2hhcnQuZXhpdCgpLnJlbW92ZSgpO1xuXG4gICAgLy8gQWRkIGFuZCB1cGRhdGUgcG9pbnRzXG4gICAgY2hhcnQuZW50ZXIoKVxuICAgICAgLmFwcGVuZChcImNpcmNsZVwiKVxuICAgICAgLmF0dHIoXCJjbGFzc1wiLCBcInBvaW50XCIpXG4gICAgICAuYXR0cigncicsIDUpXG4gICAgICAub24oXCJtb3VzZW92ZXJcIiwgZnVuY3Rpb24gKGQsIGkpIHtcbiAgICAgIH0pXG4gICAgICAubWVyZ2UoY2hhcnQpXG4gICAgICAudHJhbnNpdGlvbigxMDAwKVxuICAgICAgLy8gLmF0dHIoJ2N4JywgZnVuY3Rpb24gKGQpIHsgcmV0dXJuIHNlbGYueChkW3N0YXRlLnNlbGVjdGVkUHJvamVjdGlvbl1bMF0pOyB9KVxuICAgICAgLy8gLmF0dHIoJ2N5JywgZnVuY3Rpb24gKGQpIHsgcmV0dXJuIHNlbGYueShkW3N0YXRlLnNlbGVjdGVkUHJvamVjdGlvbl1bMV0pOyB9KVxuICAgICAgLnN0eWxlKCdvcGFjaXR5JywgZnVuY3Rpb24gKGQsIGkpIHtcbiAgICAgICAgbGV0IG9wYWNpdHk7XG4gICAgICAgIHJldHVybiBvcGFjaXR5XG4gICAgICB9KVxuICAgIC8vIC5zdHlsZSgnZmlsbCcsICBmdW5jdGlvbihkLCBpKXtcbiAgICAvLyAgIGxldCBjb2xvcjtcbiAgICAvLyAgIGlmKHNlbGYuc3RvcmUuZ2V0TWV0YURhdGEoaSlbXCJ0eXBlXCJdID09IFwibmV3XCIpIHtcbiAgICAvLyAgICAgY29sb3IgPSBcInN0ZWVsYmx1ZVwiXG4gICAgLy8gICAgIGQzLnNlbGVjdCh0aGlzKS5tb3ZlVG9Gcm9udCgpXG4gICAgLy8gICB9XG4gICAgLy8gICBlbHNlIHtcbiAgICAvLyAgICAgY29sb3IgPSBcImxpZ2h0Z3JleVwiXG4gICAgLy8gICAgIGQzLnNlbGVjdCh0aGlzKS5tb3ZlVG9CYWNrKClcbiAgICAvLyAgIH1cbiAgICAvLyAgIHJldHVybiBjb2xvclxuICAgIC8vIH0pO1xuICB9XG59XG4iXSwibWFwcGluZ3MiOiI7Ozs7Ozs7Ozs7Ozs7QUFBQTtBQUNBO0FBTUE7QUFXQTtBQUFBO0FBTEE7QUFDQTtBQUNBO0FBQ0E7QUFHQTtBQUVBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUVBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUVBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBR0E7QUFDQTtBQUNBO0FBRUE7QUFDQTtBQUVBO0FBQ0E7QUFDQTtBQUNBO0FBRUE7QUFDQTtBQUNBO0FBQ0E7QUFFQTtBQUNBO0FBRUE7QUFFQTtBQUNBO0FBQ0E7QUFFQTtBQUNBO0FBQ0E7QUFFQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBRUE7QUFDQTtBQUVBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBN0dBO0FBRkE7QUFDQTtBQVlBO0FBWEE7QUE4R0E7QUFBQTtBQTlHQTsiLCJzb3VyY2VSb290IjoiIn0=\n//# sourceURL=webpack-internal:///resources/elements/scatter-plot\n");

/***/ }),

/***/ "resources/elements/small-bar":
/*!*********************************************!*\
  !*** ./src/resources/elements/small-bar.ts ***!
  \*********************************************/
/*! exports provided: SmallBarCustomElement */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SmallBarCustomElement\", function() { return SmallBarCustomElement; });\n/* harmony import */ var d3__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! d3 */ \"./node_modules/d3/index.js\");\n/* harmony import */ var aurelia_framework__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! aurelia-framework */ \"aurelia-framework\");\nvar __decorate = (undefined && undefined.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nvar __metadata = (undefined && undefined.__metadata) || function (k, v) {\n    if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(k, v);\n};\n\n\nvar SmallBarCustomElement = /** @class */ (function () {\n    function SmallBarCustomElement(element) {\n        this.element = element;\n        this.isInitialized = false;\n        this.orientation = \"horizontal\";\n        // set the dimensions and margins of the graph\n        this.margin = { top: 0, right: 0, bottom: 0, left: 0 };\n    }\n    SmallBarCustomElement.prototype.attached = function () {\n        this.width = parseInt(this.xsize) - this.margin.left - this.margin.right;\n        this.height = parseInt(this.ysize) - this.margin.top - this.margin.bottom;\n        this.initChart();\n        this.isInitialized = true;\n        this.updateChart();\n    };\n    SmallBarCustomElement.prototype.percentChanged = function (percent) {\n        if (this.isInitialized) {\n            if (typeof percent === \"string\") {\n                this.percent = parseFloat(percent);\n            }\n            this.updateChart();\n        }\n    };\n    SmallBarCustomElement.prototype.initChart = function () {\n        this.svg = d3__WEBPACK_IMPORTED_MODULE_0__[\"select\"](this.element)\n            .append(\"svg\")\n            .attr(\"width\", this.width + this.margin.left + this.margin.right)\n            .attr(\"height\", this.height + this.margin.top + this.margin.bottom)\n            .append(\"g\")\n            .attr(\"transform\", \"translate(\" + this.margin.left + \",\" + this.margin.top + \")\");\n        // set the ranges\n        if (this.orientation == \"horizontal\") {\n            this.x = d3__WEBPACK_IMPORTED_MODULE_0__[\"scaleLinear\"]()\n                .range([0, this.width])\n                .domain([0, 1]);\n        }\n        else {\n            this.x = d3__WEBPACK_IMPORTED_MODULE_0__[\"scaleLinear\"]()\n                .range([this.height, 0])\n                .domain([0, 1]);\n        }\n        // add the x Axis\n        // this.svg.append(\"g\")\n        //   .attr(\"transform\", \"translate(0,\" + this.height + \")\")\n        //   .attr(\"class\", \"xAxis\");\n    };\n    SmallBarCustomElement.prototype.updateChart = function () {\n        var self = this;\n        if (this.orientation == \"horizontal\") {\n            this.svg.append(\"rect\")\n                .style(\"fill\", \"#D8DBDB\")\n                .attr(\"x\", 0)\n                .attr(\"width\", self.x(1))\n                .attr(\"y\", 0)\n                .attr(\"height\", self.height);\n            // Draw bar\n            this.svg\n                .append(\"rect\")\n                .attr(\"class\", \"small-bar\")\n                .attr(\"x\", 0)\n                .attr(\"width\", self.x(self.percent))\n                .attr(\"y\", 0)\n                .attr(\"height\", self.height);\n        }\n        else {\n            this.svg.append(\"rect\")\n                .style(\"fill\", \"#D8DBDB\")\n                .attr(\"x\", 0)\n                .attr(\"y\", 0)\n                .attr(\"height\", self.height)\n                .attr(\"width\", self.width);\n            // Draw bar\n            this.svg\n                .append(\"rect\")\n                .attr(\"class\", \"small-bar\")\n                .attr(\"x\", 0)\n                .attr(\"height\", self.height - self.x(self.percent))\n                .attr(\"y\", self.x(self.percent))\n                .attr(\"width\", self.height);\n        }\n        // this.svg.selectAll(\".xAxis\")\n        //   .call(d3.axisBottom(this.x).ticks(2))\n    };\n    __decorate([\n        aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"bindable\"],\n        __metadata(\"design:type\", Number)\n    ], SmallBarCustomElement.prototype, \"percent\", void 0);\n    __decorate([\n        aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"bindable\"],\n        __metadata(\"design:type\", String)\n    ], SmallBarCustomElement.prototype, \"orientation\", void 0);\n    __decorate([\n        aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"bindable\"],\n        __metadata(\"design:type\", String)\n    ], SmallBarCustomElement.prototype, \"xsize\", void 0);\n    __decorate([\n        aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"bindable\"],\n        __metadata(\"design:type\", String)\n    ], SmallBarCustomElement.prototype, \"ysize\", void 0);\n    SmallBarCustomElement = __decorate([\n        Object(aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"inject\"])(Element),\n        Object(aurelia_framework__WEBPACK_IMPORTED_MODULE_1__[\"noView\"])(),\n        __metadata(\"design:paramtypes\", [Element])\n    ], SmallBarCustomElement);\n    return SmallBarCustomElement;\n}());\n\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,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\n//# sourceURL=webpack-internal:///resources/elements/small-bar\n");

/***/ }),

/***/ "resources/index":
/*!********************************!*\
  !*** ./src/resources/index.ts ***!
  \********************************/
/*! exports provided: configure */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"configure\", function() { return configure; });\n/* harmony import */ var aurelia_pal__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! aurelia-pal */ \"./node_modules/aurelia-pal/dist/native-modules/aurelia-pal.js\");\n\nfunction configure(config) {\n    config.globalResources([\n        './elements/scatter-plot',\n        './elements/graph-plot',\n        './elements/bar-chart',\n        './elements/small-bar',\n        './converters/number-format',\n        './converters/time-format',\n        './converters/custom-sort',\n        './converters/custom-sort-length',\n        './converters/custom-filter-sort-length',\n        './converters/filter',\n        './converters/filter-property',\n    ]);\n}\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoicmVzb3VyY2VzL2luZGV4LmpzIiwic291cmNlcyI6WyJ3ZWJwYWNrOi8vLy4vc3JjL3Jlc291cmNlcy9pbmRleC50cz83NDBmIl0sInNvdXJjZXNDb250ZW50IjpbImltcG9ydCB7IEZyYW1ld29ya0NvbmZpZ3VyYXRpb24gfSBmcm9tICdhdXJlbGlhLWZyYW1ld29yayc7XHJcbmltcG9ydCB7IFBMQVRGT1JNIH0gZnJvbSAnYXVyZWxpYS1wYWwnO1xyXG5cclxuZXhwb3J0IGZ1bmN0aW9uIGNvbmZpZ3VyZShjb25maWc6IEZyYW1ld29ya0NvbmZpZ3VyYXRpb24pIHtcclxuICBjb25maWcuZ2xvYmFsUmVzb3VyY2VzKFtcclxuICAgIFBMQVRGT1JNLm1vZHVsZU5hbWUoXCIuL2VsZW1lbnRzL3NjYXR0ZXItcGxvdFwiKSxcclxuICAgIFBMQVRGT1JNLm1vZHVsZU5hbWUoXCIuL2VsZW1lbnRzL2dyYXBoLXBsb3RcIiksXHJcbiAgICBQTEFURk9STS5tb2R1bGVOYW1lKFwiLi9lbGVtZW50cy9iYXItY2hhcnRcIiksXHJcbiAgICBQTEFURk9STS5tb2R1bGVOYW1lKFwiLi9lbGVtZW50cy9zbWFsbC1iYXJcIiksXHJcbiAgICBQTEFURk9STS5tb2R1bGVOYW1lKFwiLi9jb252ZXJ0ZXJzL251bWJlci1mb3JtYXRcIiksXHJcbiAgICBQTEFURk9STS5tb2R1bGVOYW1lKFwiLi9jb252ZXJ0ZXJzL3RpbWUtZm9ybWF0XCIpLFxyXG4gICAgUExBVEZPUk0ubW9kdWxlTmFtZShcIi4vY29udmVydGVycy9jdXN0b20tc29ydFwiKSxcclxuICAgIFBMQVRGT1JNLm1vZHVsZU5hbWUoXCIuL2NvbnZlcnRlcnMvY3VzdG9tLXNvcnQtbGVuZ3RoXCIpLFxyXG4gICAgUExBVEZPUk0ubW9kdWxlTmFtZShcIi4vY29udmVydGVycy9jdXN0b20tZmlsdGVyLXNvcnQtbGVuZ3RoXCIpLFxyXG4gICAgUExBVEZPUk0ubW9kdWxlTmFtZShcIi4vY29udmVydGVycy9maWx0ZXJcIiksXHJcbiAgICBQTEFURk9STS5tb2R1bGVOYW1lKFwiLi9jb252ZXJ0ZXJzL2ZpbHRlci1wcm9wZXJ0eVwiKSxcclxuICBdKTtcclxufVxyXG4iXSwibWFwcGluZ3MiOiJBQUNBO0FBQUE7QUFBQTtBQUFBO0FBRUE7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBO0FBQ0E7QUFDQTtBQUNBOyIsInNvdXJjZVJvb3QiOiIifQ==\n//# sourceURL=webpack-internal:///resources/index\n");

/***/ })

/******/ });