{"224":{"Abstract":"We present MoleView, a novel technique for interactive exploration of multivariate relational data. Given a spatial embedding of the data, in terms of a scatter plot or graph layout, we propose a semantic lens which selects a specific spatial and attribute-related data range. The lens keeps the selected data in focus unchanged and continuously deforms the data out of the selection range in order to maintain the context around the focus. Specific deformations include distance-based repulsion of scatter plot points, deforming straight-line node-link graph drawings, and as varying the simplification degree of bundled edge graph layouts. Using a brushing-based technique, we further show the applicability of our semantic lens for scenarios requiring a complex selection of the zones of interest. Our technique is simple to implement and provides real-time performance on large datasets. We demonstrate our technique with actual data from air and road traffic control, medical imaging, and software comprehension applications.","Authors":"Hurter, C.;Telea, A.;Ersoy, O.","Clusters":"FilteringTechniques;FocusContextTechniques;GraphNetworkDataAndTechniques;InteractionTechniquesGeneral","DOI":"10.1109\/TVCG.2011.223","Keywords":"graph bundling;attribute filtering;magic lens;semantic lenses","Keywords_Processed":"attribute filtering;magic lens;graph bundling;semantic lense","Title":"MoleView: An Attribute and Structure-Based Semantic Lens for Large Element-Based Plots"},"325":{"Abstract":"Tag clouds have proliferated over the web over the last decade. They provide a visual summary of a collection of texts by visually depicting the tag frequency by font size. In use, tag clouds can evolve as the associated data source changes over time. Interesting discussions around tag clouds often include a series of tag clouds and consider how they evolve over time. However, since tag clouds do not explicitly represent trends or support comparisons, the cognitive demands placed on the person for perceiving trends in multiple tag clouds are high. In this paper, we introduce SparkClouds, which integrate sparklines into a tag cloud to convey trends between multiple tag clouds. We present results from a controlled study that compares SparkClouds with two traditional trend visualizations-multiple line graphs and stacked bar charts-as well as Parallel Tag Clouds. Results show that SparkClouds' ability to show trends compares favourably to the alternative visualizations.","Authors":"Bongshin Lee;Riche, N.H.;Karlson, A.;Carpendale, S.","Clusters":"ChartsDiagramsPlots;EvaluationGeneral;EventsTrendsOutlierDetectionAnalysisAndVisualization;GraphNetworkDataAndTechniques","DOI":"10.1109\/TVCG.2010.194","Keywords":"trend visualization;stacked bar charts;multiple line graphs;tag clouds;evaluation","Keywords_Processed":"trend visualization;stack bar chart;tag cloud;evaluation;multiple line graphs","Title":"SparkClouds: Visualizing Trends in Tag Clouds"},"342":{"Abstract":"High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.","Authors":"Fraedrich, R.;Auer, S.;Westermann, R.","Clusters":"GpuBasedTechniques;ParticleVisualizationAndTechniques;RaytracingRaycasting;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2010.148","Keywords":"gpu resampling;volume rendering;particle visualization;raycasting","Keywords_Processed":"volume render;gpu resampling;raycaste;particle visualization","Title":"Efficient High-Quality Volume Rendering of SPH Data"},"109":{"Abstract":"We report on results of a series of user studies on the perception of four visual variables that are commonly used in the literature to depict uncertainty. To the best of our knowledge, we provide the first formal evaluation of the use of these variables to facilitate an easier reading of uncertainty in visualizations that rely on line graphical primitives. In addition to blur, dashing and grayscale, we investigate the use of `sketchiness' as a visual variable because it conveys visual impreciseness that may be associated with data quality. Inspired by work in non-photorealistic rendering and by the features of hand-drawn lines, we generate line trajectories that resemble hand-drawn strokes of various levels of proficiency-ranging from child to adult strokes-where the amount of perturbations in the line corresponds to the level of uncertainty in the data. Our results show that sketchiness is a viable alternative for the visualization of uncertainty in lines and is as intuitive as blur; although people subjectively prefer dashing style over blur, grayscale and sketchiness. We discuss advantages and limitations of each technique and conclude with design considerations on how to deploy these visual variables to effectively depict various levels of uncertainty for line marks.","Authors":"Boukhelifa, N.;Bezerianos, A.;Isenberg, T.;Fekete, J.","Clusters":"Perception;QualitativeEvaluation;QuantitativeEvaluation;UncertaintyTechniquesAndVisualization","DOI":"10.1109\/TVCG.2012.220","Keywords":"uncertainty visualization;qualitative evaluation;perception;quantitative evaluation","Keywords_Processed":"quantitative evaluation;qualitative evaluation;uncertainty visualization;perception","Title":"Evaluating Sketchiness as a Visual Variable for the Depiction of Qualitative Uncertainty"},"105":{"Abstract":"Storyline visualization is a technique used to depict the temporal dynamics of social interactions. This visualization technique was first introduced as a hand-drawn illustration in XKCD's \u00e2\u20ac\u0153Movie Narrative Charts\u00e2\u20ac\u009d [21]. If properly constructed, the visualization can convey both global trends and local interactions in the data. However, previous methods for automating storyline visualizations are overly simple, failing to achieve some of the essential principles practiced by professional illustrators. This paper presents a set of design considerations for generating aesthetically pleasing and legible storyline visualizations. Our layout algorithm is based on evolutionary computation, allowing us to effectively incorporate multiple objective functions. We show that the resulting visualizations have significantly improved aesthetics and legibility compared to existing techniques.","Authors":"Tanahashi, Y.;Kwan-Liu Ma","Clusters":"DesignStudiesAndCaseStudies;Storytelling;TimeseriesTimeVaryingDataAndTechniques;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2012.212","Keywords":"design study;storyline visualization;timeline visualization;layout algorithm","Keywords_Processed":"design study;layout algorithm;storyline visualization;timeline visualization","Title":"Design Considerations for Optimizing Storyline Visualizations"},"386":{"Abstract":"Diagnosing faults in an operational computer network is a frustrating, time-consuming exercise. Despite advances, automatic diagnostic tools are far from perfect: they occasionally miss the true culprit and are mostly only good at narrowing down the search to a few potential culprits. This uncertainty and the inability to extract useful sense from tool output renders most tools not usable to administrators. To bridge this gap, we present NetClinic, a visual analytics system that couples interactive visualization with an automated diagnostic tool for enterprise networks. It enables administrators to verify the output of the automatic analysis at different levels of detail and to move seamlessly across levels while retaining appropriate context. A qualitative user study shows that NetClinic users can accurately identify the culprit, even when it is not present in the suggestions made by the automated component. We also find that supporting a variety of sensemaking strategies is a key to the success of systems that enhance automated diagnosis.","Authors":"Zhicheng Liu;Bongshin Lee;Kandula, S.;Mahajan, R.","Clusters":"Cognition;ComputerNetworksNetworkSecurity;GraphNetworkDataAndTechniques;","DOI":"10.1109\/VAST.2010.5652910","Keywords":"information visualization;network diagnosis;sensemaking;semantic graph layout;visual analytics","Keywords_Processed":"semantic graph layout;sensemake;information visualization;visual analytic;network diagnosis","Title":"NetClinic: Interactive visualization to enhance automated fault diagnosis in enterprise networks"},"101":{"Abstract":"The importance of interaction to Information Visualization (InfoVis) and, in particular, of the interplay between interactivity and cognition is widely recognized [12, 15, 32, 55, 70]. This interplay, combined with the demands from increasingly large and complex datasets, is driving the increased significance of interaction in InfoVis. In parallel, there have been rapid advances in many facets of interaction technologies. However, InfoVis interactions have yet to take full advantage of these new possibilities in interaction technologies, as they largely still employ the traditional desktop, mouse, and keyboard setup of WIMP (Windows, Icons, Menus, and a Pointer) interfaces. In this paper, we reflect more broadly about the role of more \u00e2\u20ac\u0153natural\u00e2\u20ac\u009d interactions for InfoVis and provide opportunities for future research. We discuss and relate general HCI interaction models to existing InfoVis interaction classifications by looking at interactions from a novel angle, taking into account the entire spectrum of interactions. Our discussion of InfoVis-specific interaction design considerations helps us identify a series of underexplored attributes of interaction that can lead to new, more \u00e2\u20ac\u0153natural,\u00e2\u20ac\u009d interaction techniques for InfoVis.","Authors":"Bongshin Lee;Isenberg, P.;Riche, N.H.;Carpendale, S.","Clusters":"DesignMethodologiesAndInteractionDesign;InteractionTechniquesGeneral;UserInterfacesGeneral;VisualDesignDesignGuidelines","DOI":"10.1109\/TVCG.2012.204","Keywords":"natural user interface;post-wimp;design considerations;interaction","Keywords_Processed":"interaction;natural user interface;design consideration;post wimp","Title":"Beyond Mouse and Keyboard: Expanding Design Considerations for Information Visualization Interactions"},"51":{"Abstract":"Spectral clustering is a powerful and versatile technique, whose broad range of applications includes 3D image analysis. However, its practical use often involves a tedious and time-consuming process of tuning parameters and making application-specific choices. In the absence of training data with labeled clusters, help from a human analyst is required to decide the number of clusters, to determine whether hierarchical clustering is needed, and to define the appropriate distance measures, parameters of the underlying graph, and type of graph Laplacian. We propose to simplify this process via an open-box approach, in which an interactive system visualizes the involved mathematical quantities, suggests parameter values, and provides immediate feedback to support the required decisions. Our framework focuses on applications in 3D image analysis, and links the abstract high-dimensional feature space used in spectral clustering to the three-dimensional data space. This provides a better understanding of the technique, and helps the analyst predict how well specific parameter settings will generalize to similar tasks. In addition, our system supports filtering outliers and labeling the final clusters in such a way that user actions can be recorded and transferred to different data in which the same structures are to be found. Our system supports a wide range of inputs, including triangular meshes, regular grids, and point clouds. We use our system to develop segmentation protocols in chest CT and brain MRI that are then successfully applied to other datasets in an automated manner.","Authors":"Schultz, T.;Kindlmann, G.","Clusters":"DataClusteringAndAggregation;MultidimensionalMultivariateMultifieldDataAndTechniques;MultipleLinkedCoordinatedViews;ProgrammingAlgorithmsAndDataStructures;SegmentationAndClassification","DOI":"10.1109\/TVCG.2013.181","Keywords":"linked views;high-dimensional embeddings;spectral clustering;programming with example;image segmentation","Keywords_Processed":"high dimensional embedding;link view;programming with example;image segmentation;spectral clustering","Title":"Open-Box Spectral Clustering: Applications to Medical Image Analysis"},"326":{"Abstract":"An ongoing challenge for information visualization is how to deal with over-plotting forced by ties or the relatively limited visual field of display devices. A popular solution is to represent local data density with area (bubble plots, treemaps), color(heatmaps), or aggregation (histograms, kernel densities, pixel displays). All of these methods have at least one of three deficiencies:1) magnitude judgments are biased because area and color have convex downward perceptual functions, 2) area, hue, and brightnesshave relatively restricted ranges of perceptual intensity compared to length representations, and\/or 3) it is difficult to brush or link toindividual cases when viewing aggregations. In this paper, we introduce a new technique for visualizing and interacting with datasets that preserves density information by stacking overlapping cases. The overlapping data can be points or lines or other geometric elements, depending on the type of plot. We show real-dataset applications of this stacking paradigm and compare them to other techniques that deal with over-plotting in high-dimensional displays.","Authors":"Tuan Nhon Dang;Wilkinson, L.;Anand, A.","Clusters":"ChartsDiagramsPlots;MultidimensionalMultivariateMultifieldDataAndTechniques;ParallelCoordinates;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2010.197","Keywords":"dot plots;density-based visualization;parallel coordinate plot;multi-dimensional data","Keywords_Processed":"density base visualization;parallel coordinate plot;multi dimensional datum;dot plot","Title":"Stacking Graphic Elements to Avoid Over-Plotting"},"67":{"Abstract":"Electronic Health Records (EHRs) have emerged as a cost-effective data source for conducting medical research. The difficulty in using EHRs for research purposes, however, is that both patient selection and record analysis must be conducted across very large, and typically very noisy datasets. Our previous work introduced EventFlow, a visualization tool that transforms an entire dataset of temporal event records into an aggregated display, allowing researchers to analyze population-level patterns and trends. As datasets become larger and more varied, however, it becomes increasingly difficult to provide a succinct, summarizing display. This paper presents a series of user-driven data simplifications that allow researchers to pare event records down to their core elements. Furthermore, we present a novel metric for measuring visual complexity, and a language for codifying disjoint strategies into an overarching simplification framework. These simplifications were used by real-world researchers to gain new and valuable insights from initially overwhelming datasets.","Authors":"Monroe, M.;Rongjian Lan;Hanseung Lee;Plaisant, C.;Shneiderman, B.","Clusters":"AbstractionSimplificationApproximation;BiomedicalScienceAndMedicine;EventsTrendsOutlierDetectionAnalysisAndVisualization;QueriesAndSearch","DOI":"10.1109\/TVCG.2013.200","Keywords":"electronic health records;temporal query;simplification;event sequences","Keywords_Processed":"electronic health record;temporal query;event sequence;simplification","Title":"Temporal Event Sequence Simplification"},"196":{"Abstract":"Distributed cognition and embodiment provide compelling models for how humans think and interact with the environment. Our examination of the use of large, high-resolution displays from an embodied perspective has lead directly to the development of a new sensemaking environment called Analyst's Workspace (AW). AW leverages the embodied resources made more accessible through the physical nature of the display to create a spatial workspace. By combining spatial layout of documents and other artifacts with an entity-centric, explorative investigative approach, AW aims to allow the analyst to externalize elements of the sensemaking process as a part of the investigation, integrated into the visual representations of the data itself. In this paper, we describe the various capabilities of AW and discuss the key principles and concepts underlying its design, emphasizing unique design principles for designing visual analytic tools for large, high-resolution displays.","Authors":"Andrews, C.;North, C.","Clusters":"Cognition;LargeAndHighResDisplays;SpaceRelatedSpatialDataAndTechniques","DOI":"10.1109\/VAST.2012.6400559","Keywords":"embodiment;sensemaking;distributed cognition;space;large and high-resolution display","Keywords_Processed":"large and high resolution display;sensemake;space;embodiment;distribute cognition","Title":"Analyst's Workspace: An embodied sensemaking environment for large, high-resolution displays"},"119":{"Abstract":"Interactive visualizations can allow science museum visitors to explore new worlds by seeing and interacting with scientific data. However, designing interactive visualizations for informal learning environments, such as museums, presents several challenges. First, visualizations must engage visitors on a personal level. Second, visitors often lack the background to interpret visualizations of scientific data. Third, visitors have very limited time at individual exhibits in museums. This paper examines these design considerations through the iterative development and evaluation of an interactive exhibit as a visualization tool that gives museumgoers access to scientific data generated and used by researchers. The exhibit prototype, Living Liquid, encourages visitors to ask and answer their own questions while exploring the time-varying global distribution of simulated marine microbes using a touchscreen interface. Iterative development proceeded through three rounds of formative evaluations using think-aloud protocols and interviews, each round informing a key visualization design decision: (1) what to visualize to initiate inquiry, (2) how to link data at the microscopic scale to global patterns, and (3) how to include additional data that allows visitors to pursue their own questions. Data from visitor evaluations suggests that, when designing visualizations for public audiences, one should (1) avoid distracting visitors from data that they should explore, (2) incorporate background information into the visualization, (3) favor understandability over scientific accuracy, and (4) layer data accessibility to structure inquiry. Lessons learned from this case study add to our growing understanding of how to use visualizations to actively engage learners with scientific data.","Authors":"Ma, J.;Liao, I.;Kwan-Liu Ma;Frazier, J.","Clusters":"ApplicationsGeneralAndOther;EvaluationGeneral;InteractionTechniquesGeneral;","DOI":"10.1109\/TVCG.2012.244","Keywords":"user interaction;information visualization;informal learning environments;user study;science museums;evaluation","Keywords_Processed":"user interaction;user study;science museum;information visualization;informal learning environment;evaluation","Title":"Living Liquid: Design and Evaluation of an Exploratory Visualization Tool for Museum Visitors"},"80":{"Abstract":"Visual exploration and analysis of multidimensional data becomes increasingly difficult with increasing dimensionality. We want to understand the relationships between dimensions of data, but lack flexible techniques for exploration beyond low-order relationships. Current visual techniques for multidimensional data analysis focus on binary conjunctive relationships between dimensions. Recent techniques, such as cross-filtering on an attribute relationship graph, facilitate the exploration of some higher-order conjunctive relationships, but require a great deal of care and precision to do so effectively. This paper provides a detailed analysis of the expressive power of existing visual querying systems and describes a more flexible approach in which users can explore n-ary conjunctive inter- and intra- dimensional relationships by interactively constructing queries as visual hypergraphs. In a hypergraph query, nodes represent subsets of values and hyperedges represent conjunctive relationships. Analysts can dynamically build and modify the query using sequences of simple interactions. The hypergraph serves not only as a query specification, but also as a compact visual representation of the interactive state. Using examples from several domains, focusing on the digital humanities, we describe the design considerations for developing the querying system and incorporating it into visual analysis tools. We analyze query expressiveness with regard to the kinds of questions it can and cannot pose, and describe how it simultaneously expands the expressiveness of and is complemented by cross-filtering.","Authors":"Shadoan, R.;Weaver, C.","Clusters":"GraphNetworkDataAndTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;QueriesAndSearch;SocialScienceAndHumanities","DOI":"10.1109\/TVCG.2013.220","Keywords":"digital humanities;visual query language;graph search;multivariate data analysis;higher-order conjunctive queries;graph query language;attribute relationship graphs;multi-dimensional data","Keywords_Processed":"visual query language;multi dimensional datum;digital humanity;high order conjunctive query;graph search;multivariate datum analysis;graph query language;attribute relationship graphs","Title":"Visual Analysis of Higher-Order Conjunctive Relationships in Multidimensional Data Using a Hypergraph Query System"},"338":{"Abstract":"Conventional browsing of image collections use mechanisms such as thumbnails arranged on a regular grid or on a line, often mounted over a scrollable panel. However, this approach does not scale well with the size of the datasets (number of images). In this paper, we propose a new thumbnail-based interface to browse large collections of images. Our approach is based on weighted centroidal anisotropic Voronoi diagrams. A dynamically changing subset of images is represented by thumbnails and shown on the screen. Thumbnails are shaped like general polygons, to better cover screen space, while still reflecting the original aspect ratios or orientation of the represented images. During the browsing process, thumbnails are dynamically rearranged, reshaped and rescaled. The objective is to devote more screen space (more numerous and larger thumbnails) to the parts of the dataset closer to the current region of interest, and progressively lesser away from it, while still making the dataset visible as a whole. During the entire process, temporal coherence is always maintained. GPU implementation easily guarantees the frame rates needed for fully smooth interactivity.","Authors":"Brivio, P.;Tarini, M.;Cignoni, P.","Clusters":"LargeScaleDataAndScalability;UserInterfacesGeneral;VisualizationSystemsToolkitsAndEnvironments;ZoomingAndNavigationTechniques","DOI":"10.1109\/TVCG.2010.136","Keywords":"visualization system and toolkit design;zooming and navigation techniques;user interface;scalability issues","Keywords_Processed":"visualization system and toolkit design;zooming and navigation technique;scalability issue;user interface","Title":"Browsing Large Image Datasets through Voronoi Diagrams"},"115":{"Abstract":"In this paper, we explore how the capacity limits of attention influence the effectiveness of information visualizations. We conducted a series of experiments to test how visual feature type (color vs. motion), layout, and variety of visual elements impacted user performance. The experiments tested users' abilities to (1) determine if a specified target is on the screen, (2) detect an odd-ball, deviant target, different from the other visible objects, and (3) gain a qualitative overview by judging the number of unique categories on the screen. Our results show that the severe capacity limits of attention strongly modulate the effectiveness of information visualizations, particularly the ability to detect unexpected information. Keeping in mind these capacity limits, we conclude with a set of design guidelines which depend on a visualization's intended use.","Authors":"Haroz, S.;Whitney, D.","Clusters":"AnimationAndMotion;ChartsDiagramsPlots;Cognition;ColorColorPerception;DesignMethodologiesAndInteractionDesign;EvaluationGeneral;Perception;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2012.233","Keywords":"color;goal-oriented design;user study;perception;layout;nominal axis;attention;motion","Keywords_Processed":"user study;perception;motion;nominal axis;layout;color;goal orient design;attention","Title":"How Capacity Limits of Attention Influence Information Visualization Effectiveness"},"311":{"Abstract":"It remains challenging for information visualization novices to rapidly construct visualizations during exploratory data analysis. We conducted an exploratory laboratory study in which information visualization novices explored fictitious sales data by communicating visualization specifications to a human mediator, who rapidly constructed the visualizations using commercial visualization software. We found that three activities were central to the iterative visualization construction process: data attribute selection, visual template selection, and visual mapping specification. The major barriers faced by the participants were translating questions into data attributes, designing visual mappings, and interpreting the visualizations. Partial specification was common, and the participants used simple heuristics and preferred visualizations they were already familiar with, such as bar, line and pie charts. We derived abstract models from our observations that describe barriers in the data exploration process and uncovered how information visualization novices think about visualization specifications. Our findings support the need for tools that suggest potential visualizations and support iterative refinement, that provide explanations and help with learning, and that are tightly integrated into tool support for the overall visual analytics process.","Authors":"Grammel, L.;Tory, M.;Storey, M.","Clusters":"EvaluationGeneral;HumanComputerInteractionHumanFactors;VisualDesignDesignGuidelines;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2010.164","Keywords":"visual mapping;novices;visualization;visualization construction;visual analytics;empirical study","Keywords_Processed":"visualization;visual mapping;empirical study;visual analytic;visualization construction;novice","Title":"How Information Visualization Novices Construct Visualizations"},"349":{"Abstract":"We investigate the use of a Fourier-domain derivative error kernel to quantify the error incurred while estimating the gradient of a function from scalar point samples on a regular lattice. We use the error kernel to show that gradient reconstruction quality is significantly enhanced merely by shifting the reconstruction kernel to the centers of the principal lattice directions. Additionally, we exploit the algebraic similarities between the scalar and derivative error kernels to design asymptotically optimal gradient estimation filters that can be factored into an infinite impulse response interpolation prefilter and a finite impulse response directional derivative filter. This leads to a significant performance gain both in terms of accuracy and computational efficiency. The interpolation prefilter provides an accurate scalar approximation and can be re-used to cheaply compute directional derivatives on-the-fly without the need to store gradients. We demonstrate the impact of our filters in the context of volume rendering of scalar data sampled on the Cartesian and Body-Centered Cubic lattices. Our results rival those obtained from other competitive gradient estimation methods while incurring no additional computational or storage overhead.","Authors":"Alim, U.;Moller, T.;Condat, L.","Clusters":"AdaptiveProcessingAndRefinement;Interpolation;MachineLearningAndStatistics;MeshesGridsAndLattices;NumericalMethodsMathematics;Sampling","DOI":"10.1109\/TVCG.2010.160","Keywords":"derivative;frequency error kernel;reconstruction;interpolation;sampling;approximation;gradient;lattice","Keywords_Processed":"derivative;gradient;reconstruction;frequency error kernel;lattice;approximation;sample;interpolation","Title":"Gradient Estimation Revitalized"},"50":{"Abstract":"Analysis of multivariate data is of great importance in many scientific disciplines. However, visualization of 3D spatially-fixed multivariate volumetric data is a very challenging task. In this paper we present a method that allows simultaneous real-time visualization of multivariate data. We redistribute the opacity within a voxel to improve the readability of the color defined by a regular transfer function, and to maintain the see-through capabilities of volume rendering. We use predictable procedural noise - random-phase Gabor noise - to generate a high-frequency redistribution pattern and construct an opacity mapping function, which allows to partition the available space among the displayed data attributes. This mapping function is appropriately filtered to avoid aliasing, while maintaining transparent regions. We show the usefulness of our approach on various data sets and with different example applications. Furthermore, we evaluate our method by comparing it to other visualization techniques in a controlled user study. Overall, the results of our study indicate that users are much more accurate in determining exact data values with our novel 3D volume visualization method. Significantly lower error rates for reading data values and high subjective ranking of our method imply that it has a high chance of being adopted for the purpose of visualization of multivariate 3D data.","Authors":"Khlebnikov, R.;Kainz, B.;Steinberger, M.;Schmalstieg, D.","Clusters":"MultidimensionalMultivariateMultifieldDataAndTechniques;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2013.180","Keywords":"scientific visualization;volume rendering;multi-volume rendering;multivariate visualization","Keywords_Processed":"scientific visualization;volume render;multi volume render;multivariate visualization","Title":"Noise-Based Volume Rendering for the Visualization of Multivariate Volumetric Data"},"232":{"Abstract":"Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.","Authors":"Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong","Clusters":"EventsTrendsOutlierDetectionAnalysisAndVisualization;HierarchicalTreeDataAndTechniques;TextDocumentTopicAnalysisDataAndTechniques","DOI":"10.1109\/TVCG.2011.239","Keywords":"text visualization;critical event;hierarchical dirichlet process;topic evolution","Keywords_Processed":"critical event;hierarchical dirichlet process;text visualization;topic evolution","Title":"TextFlow: Towards Better Understanding of Evolving Topics in Text"},"146":{"Abstract":"Cerebral aneurysms are a pathological vessel dilatation that bear a high risk of rupture. For the understanding and evaluation of the risk of rupture, the analysis of hemodynamic information plays an important role. Besides quantitative hemodynamic information, also qualitative flow characteristics, e.g., the inflow jet and impingement zone are correlated with the risk of rupture. However, the assessment of these two characteristics is currently based on an interactive visual investigation of the flow field, obtained by computational fluid dynamics (CFD) or blood flow measurements. We present an automatic and robust detection as well as an expressive visualization of these characteristics. The detection can be used to support a comparison, e.g., of simulation results reflecting different treatment options. Our approach utilizes local streamline properties to formalize the inflow jet and impingement zone. We extract a characteristic seeding curve on the ostium, on which an inflow jet boundary contour is constructed. Based on this boundary contour we identify the impingement zone. Furthermore, we present several visualization techniques to depict both characteristics expressively. Thereby, we consider accuracy and robustness of the extracted characteristics, minimal visual clutter and occlusions. An evaluation with six domain experts confirms that our approach detects both hemodynamic characteristics reasonably.","Authors":"Gasteiger, R.;Lehmann, D.J.;van Pelt, R.;Janiga, G.;Beuing, O.;Vilanova, A.;Theisel, H.;Preim, B.","Clusters":"ApplicationsGeneralAndOther;BiomedicalScienceAndMedicine;Engineering;GlyphsGlyphBasedTechniques;","DOI":"10.1109\/TVCG.2012.202","Keywords":"glyph;cerebral aneurysm;visualization;hemodynamics;inflow jet;impingement zone","Keywords_Processed":"visualization;inflow jet;hemodynamic;glyph;cerebral aneurysm;impingement zone","Title":"Automatic Detection and Visualization of Qualitative Hemodynamic Characteristics in Cerebral Aneurysms"},"313":{"Abstract":"Among the multifarious tag-clouding techniques, Wordle stands out to the community by providing an aesthetic layout, eliciting the emergence of the participatory culture and usage of tag-clouding in the artistic creations. In this paper, we introduce ManiWordle, a Wordle-based visualization tool that revamps interactions with the layout by supporting custom manipulations. ManiWordle allows people to manipulate typography, color, and composition not only for the layout as a whole, but also for the individual words, enabling them to have better control over the layout result. We first describe our design rationale along with the interaction techniques for tweaking the layout. We then present the results both from the preliminary usability study and from the comparative study between ManiWordle and Wordle. The results suggest that ManiWordle provides higher user satisfaction and an efficient method of creating the desired \"art work,\" harnessing the power behind the ever-increasing popularity of Wordle.","Authors":"Koh, K.;Bongshin Lee;Bohyoung Kim;Jinwook Seo","Clusters":"ChartsDiagramsPlots;CollaborativeVisualization;DesignMethodologiesAndInteractionDesign;EvaluationGeneral;HumanComputerInteractionHumanFactors;InteractionTechniquesGeneral","DOI":"10.1109\/TVCG.2010.175","Keywords":"user study;interaction design;flexibility-usability tradeoff;tag clouds;participatory visualization;direct manipulation","Keywords_Processed":"user study;participatory visualization;flexibility usability tradeoff;tag cloud;direct manipulation;interaction design","Title":"ManiWordle: Providing Flexible Control over Wordle"},"328":{"Abstract":"The choices we take when listening to music are expressions of our personal taste and character. Storing and accessing our listening histories is trivial due to services like Last.fm, but learning from them and understanding them is not. Existing solutions operate at a very abstract level and only produce statistics. By applying techniques from information visualization to this problem, we were able to provide average people with a detailed and powerful tool for accessing their own musical past. LastHistory is an interactive visualization for displaying music listening histories, along with contextual information from personal photos and calendar entries. Its two main user tasks are (1) analysis, with an emphasis on temporal patterns and hypotheses related to musical genre and sequences, and (2) reminiscing, where listening histories and context represent part of one's past. In this design study paper we give an overview of the field of music listening histories and explain their unique characteristics as a type of personal data. We then describe the design rationale, data and view transformations of LastHistory and present the results from both a laband a large-scale online study. We also put listening histories in contrast to other lifelogging data. The resonant and enthusiastic feedback that we received from average users shows a need for making their personal data accessible. We hope to stimulate such developments through this research.","Authors":"Baur, D.;Seiffert, F.;Sedlmair, M.;Boring, S.","Clusters":"DesignStudiesAndCaseStudies;MultimediaImageVideoMusic;ProvenanceAndHistory;SocialNetworksAndSocialMedia;TimeseriesTimeVaryingDataAndTechniques;","DOI":"10.1109\/TVCG.2010.206","Keywords":"timeline;information visualization;design study;calendars;photos;lifelogging;music;listening history","Keywords_Processed":"design study;listen history;information visualization;lifelogge;timeline;music;calendar;photo","Title":"The Streams of Our Lives: Visualizing Listening Histories in Context"},"357":{"Abstract":"Numerical weather prediction ensembles are routinely used for operational weather forecasting. The members of these ensembles are individual simulations with either slightly perturbed initial conditions or different model parameterizations, or occasionally both. Multi-member ensemble output is usually large, multivariate, and challenging to interpret interactively. Forecast meteorologists are interested in understanding the uncertainties associated with numerical weather prediction; specifically variability between the ensemble members. Currently, visualization of ensemble members is mostly accomplished through spaghetti plots of a single midtroposphere pressure surface height contour. In order to explore new uncertainty visualization methods, the Weather Research and Forecasting (WRF) model was used to create a 48-hour, 18 member parameterization ensemble of the 13 March 1993 \"Superstorm\". A tool was designed to interactively explore the ensemble uncertainty of three important weather variables: water-vapor mixing ratio, perturbation potential temperature, and perturbation pressure. Uncertainty was quantified using individual ensemble member standard deviation, inter-quartile range, and the width of the 95% confidence interval. Bootstrapping was employed to overcome the dependence on normality in the uncertainty metrics. A coordinated view of ribbon and glyph-based uncertainty visualization, spaghetti plots, iso-pressure colormaps, and data transect plots was provided to two meteorologists for expert evaluation. They found it useful in assessing uncertainty in the data, especially in finding outliers in the ensemble run and therefore avoiding the WRF parameterizations that lead to these outliers. Additionally, the meteorologists could identify spatial regions where the uncertainty was significantly high, allowing for identification of poorly simulated storm environments and physical interpretation of these model issues.","Authors":"Sanyal, J.;Song Zhang;Dyer, J.;Mercer, A.;Amburn, P.;Moorhead, R.J.","Clusters":"EarthSpaceAndEnvironmentalSciences;GeographyGeospatialVisCartographyTerrainVis;GlyphsGlyphBasedTechniques;QualitativeEvaluation;TimeseriesTimeVaryingDataAndTechniques;UncertaintyTechniquesAndVisualization","DOI":"10.1109\/TVCG.2010.181","Keywords":"glyph-based techniques;uncertainty visualization;time-varying data;weather ensemble;qualitative evaluation;geographic\/geospatial visualization","Keywords_Processed":"time vary datum;weather ensemble;glyph base technique;geographic geospatial visualization;qualitative evaluation;uncertainty visualization","Title":"Noodles: A Tool for Visualization of Numerical Weather Model Ensemble Uncertainty"},"286":{"Abstract":"In this paper, we propose a volume visualization system that accepts direct manipulation through a sketch-based What You See Is What You Get (WYSIWYG) approach. Similar to the operations in painting applications for 2D images, in our system, a full set of tools have been developed to enable direct volume rendering manipulation of color, transparency, contrast, brightness, and other optical properties by brushing a few strokes on top of the rendered volume image. To be able to smartly identify the targeted features of the volume, our system matches the sparse sketching input with the clustered features both in image space and volume space. To achieve interactivity, both special algorithms to accelerate the input identification and feature matching have been developed and implemented in our system. Without resorting to tuning transfer function parameters, our proposed system accepts sparse stroke inputs and provides users with intuitive, flexible and effective interaction during volume data exploration and visualization.","Authors":"Hanqi Guo;Ningyu Mao;Xiaoru Yuan","Clusters":"DataFeaturesAndAttributes;HumanComputerInteractionHumanFactors;InteractionTechniquesGeneral;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2011.261","Keywords":"volume rendering;feature space;transfer function;human-computer interaction;sketching input","Keywords_Processed":"volume render;human computer interaction;sketch input;transfer function;feature space","Title":"WYSIWYG (What You See is What You Get) Volume Visualization"},"371":{"Abstract":"Practical volume visualization pipelines are never without compromises and errors. A delicate and often-studied component is the interpolation of off-grid samples, where aliasing can lead to misleading artifacts and blurring, potentially hiding fine details of critical importance. The verifiable visualization framework we describe aims to account for these errors directly in the volume generation stage, and we specifically target volumetric data obtained via computed tomography (CT) reconstruction. In this case the raw data are the X-ray projections obtained from the scanner and the volume data generation process is the CT algorithm. Our framework informs the CT reconstruction process of the specific filter intended for interpolation in the subsequent visualization process, and this in turn ensures an accurate interpolation there at a set tolerance. Here, we focus on fast trilinear interpolation in conjunction with an octree-type mixed resolution volume representation without T-junctions. Efficient rendering is achieved by a space-efficient and locality-optimized representation, which can straightforwardly exploit fast fixed-function pipelines on GPUs.","Authors":"Ziyi Zheng;Wei Xu;Mueller, K.","Clusters":"BiomedicalScienceAndMedicine;DisplaysGeneral;EvaluationGeneral;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2010.211","Keywords":"direct volume rendering;filtered back-projection;computed tomography;verifiable visualization","Keywords_Processed":"filter back projection;verifiable visualization;compute tomography;direct volume render","Title":"VDVR: Verifiable Volume Visualization of Projection-Based Data"},"306":{"Abstract":"Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present FacetAtlas, a multifaceted visualization technique for visually analyzing rich text corpora. FacetAtlas combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of FacetAtlas, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of FacetAtlas through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis.","Authors":"Nan Cao;Jimeng Sun;Yu-Ru Lin;Gotz, D.;Shixia Liu;Huamin Qu","Clusters":"DataFacetsAndTechniques;GraphNetworkDataAndTechniques;QueriesAndSearch;TextDocumentTopicAnalysisDataAndTechniques","DOI":"10.1109\/TVCG.2010.154","Keywords":"search user interface;multi-facet visualization;multi-relational graph;text visualization","Keywords_Processed":"text visualization;search user interface;multi relational graph;multi facet visualization","Title":"FacetAtlas: Multifaceted Visualization for Rich Text Corpora"},"87":{"Abstract":"We introduce Visual Sedimentation, a novel design metaphor for visualizing data streams directly inspired by the physical process of sedimentation. Visualizing data streams (e. g., Tweets, RSS, Emails) is challenging as incoming data arrive at unpredictable rates and have to remain readable. For data streams, clearly expressing chronological order while avoiding clutter, and keeping aging data visible, are important. The metaphor is drawn from the real-world sedimentation processes: objects fall due to gravity, and aggregate into strata over time. Inspired by this metaphor, data is visually depicted as falling objects using a force model to land on a surface, aggregating into strata over time. In this paper, we discuss how this metaphor addresses the specific challenge of smoothing the transition between incoming and aging data. We describe the metaphor's design space, a toolkit developed to facilitate its implementation, and example applications to a range of case studies. We then explore the generative capabilities of the design space through our toolkit. We finally illustrate creative extensions of the metaphor when applied to real streams of data.","Authors":"Huron, S.;Vuillemot, R.;Fekete, J.","Clusters":"DynamicDataAndTechniques;DynamicVisualizationVisualizationOfChange;RealtimeProcessingRenderingAndVisualizationGeneral;StreamingDataAndTechniques;VisualDesignDesignGuidelines;VisualizationTheoryModelsAndMethods","DOI":"10.1109\/TVCG.2013.227","Keywords":"information visualization;dynamic data;realtime;data stream;design;metaphors;dynamic visualization","Keywords_Processed":"realtime;information visualization;dynamic datum;dynamic visualization;datum stream;design;metaphor","Title":"Visual Sedimentation"},"125":{"Abstract":"We present a network visualization design study focused on supporting automotive engineers who need to specify and optimize traffic patterns for in-car communication networks. The task and data abstractions that we derived support actively making changes to an overlay network, where logical communication specifications must be mapped to an underlying physical network. These abstractions are very different from the dominant use case in visual network analysis, namely identifying clusters and central nodes, that stems from the domain of social network analysis. Our visualization tool RelEx was created and iteratively refined through a full user-centered design process that included a full problem characterization phase before tool design began, paper prototyping, iterative refinement in close collaboration with expert users for formative evaluation, deployment in the field with real analysts using their own data, usability testing with non-expert users, and summative evaluation at the end of the deployment. In the summative post-deployment study, which entailed domain experts using the tool over several weeks in their daily practice, we documented many examples where the use of RelEx simplified or sped up their work compared to previous practices.","Authors":"Sedlmair, M.;Frank, A.;Munzner, T.;Butz, A.","Clusters":"DesignStudiesAndCaseStudies;DynamicVisualizationVisualizationOfChange;Engineering;GraphNetworkDataAndTechniques;Traffic","DOI":"10.1109\/TVCG.2012.255","Keywords":"design study;traffic optimization;automotive;change management;traffic routing;network visualization","Keywords_Processed":"design study;automotive;traffic optimization;change management;network visualization;traffic routing","Title":"RelEx: Visualization for Actively Changing Overlay Network Specifications"},"121":{"Abstract":"We propose a method to highlight query hits in hierarchically clustered collections of interrelated items such as digital libraries or knowledge bases. The method is based on the idea that organizing search results similarly to their arrangement on a fixed reference map facilitates orientation and assessment by preserving a user's mental map. Here, the reference map is built from an MDS layout of the items in a Voronoi treemap representing their hierarchical clustering, and we use techniques from dynamic graph layout to align query results with the map. The approach is illustrated on an archive of newspaper articles.","Authors":"Nocaj, A.;Brandes, U.","Clusters":"AbstractionSimplificationApproximation;Cognition;DimensionalityReduction;GraphNetworkDataAndTechniques;QueriesAndSearch;VoronoiBasedTechniques","DOI":"10.1109\/TVCG.2012.250","Keywords":"multi-dimensional scaling;mental map;voronoi treemaps;edge bundling;search results;dynamic graph layout","Keywords_Processed":"edge bundling;mental map;search result;multi dimensional scaling;voronoi treemap;dynamic graph layout","Title":"Organizing Search Results with a Reference Map"},"300":{"Abstract":"While a number of information visualization software frameworks exist, creating new visualizations, especially those that involve novel visualization metaphors, interaction techniques, data analysis strategies, and specialized rendering algorithms, is still often a difficult process. To facilitate the creation of novel visualizations we present a new software framework, behaviorism, which provides a wide range of flexibility when working with dynamic information on visual, temporal, and ontological levels, but at the same time providing appropriate abstractions which allow developers to create prototypes quickly which can then easily be turned into robust systems. The core of the framework is a set of three interconnected graphs, each with associated operators: a scene graph for high-performance 3D rendering, a data graph for different layers of semantically-linked heterogeneous data, and a timing graph for sophisticated control of scheduling, interaction, and animation. In particular, the timing graph provides a unified system to add behaviors to both data and visual elements, as well as to the behaviors themselves. To evaluate the framework we look briefly at three different projects all of which required novel visualizations in different domains, and all of which worked with dynamic data in different ways: an interactive ecological simulation, an information art installation, and an information visualization technique.","Authors":"Forbes, A.;Hollerer, T.;Legrady, G.","Clusters":"ArtAndAestheticsInVisualization;DynamicDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2010.126","Keywords":"dynamic data;information visualization;information art;framework","Keywords_Processed":"dynamic datum;information art;framework;information visualization","Title":"behaviorism: a framework for dynamic data visualization"},"337":{"Abstract":"In the development of magnetic confinement fusion which will potentially be a future source for low cost power, physicists must be able to analyze the magnetic field that confines the burning plasma. While the magnetic field can be described as a vector field, traditional techniques for analyzing the field's topology cannot be used because of its Hamiltonian nature. In this paper we describe a technique developed as a collaboration between physicists and computer scientists that determines the topology of a toroidal magnetic field using fieldlines with near minimal lengths. More specifically, we analyze the Poincare\u2560\u00fc map of the sampled fieldlines in a Poincare\u2560\u00fc section including identifying critical points and other topological features of interest to physicists. The technique has been deployed into an interactiveparallel visualization tool which physicists are using to gain new insight into simulations of magnetically confined burning plasmas.","Authors":"Sanderson, A.;Guoning Chen;Tricoche, X.;Pugmire, D.;Kruger, S.;Breslau, J.","Clusters":"NumericalMethodsMathematics;PhysicsAndPhysicalSciences;VisualPatternFeatureDetectionAndTracking","DOI":"10.1109\/TVCG.2010.133","Keywords":"periodic magnetic fieldlines;magnetic field visualization;confined magnetic fusion;recurrent patterns;poincare map","Keywords_Processed":"poincare map;recurrent pattern;periodic magnetic fieldline;confine magnetic fusion;magnetic field visualization","Title":"Analysis of Recurrent Patterns in Toroidal Magnetic fields"},"226":{"Abstract":"We propose a new framework for visualising tables of counts, proportions and probabilities. We call our framework product plots, alluding to the computation of area as a product of height and width, and the statistical concept of generating a joint distribution from the product of conditional and marginal distributions. The framework, with extensions, is sufficient to encompass over 20 visualisations previously described in fields of statistical graphics and infovis, including bar charts, mosaic plots, treemaps, equal area plots and fluctuation diagrams.","Authors":"Wickham, H.;Hofmann, H.","Clusters":"ChartsDiagramsPlots;HierarchicalTreeDataAndTechniques;MachineLearningAndStatistics","DOI":"10.1109\/TVCG.2011.227","Keywords":"mosaic plots;conditional distribution;bar chart;treemap;joint distribution;statistics","Keywords_Processed":"treemap;conditional distribution;bar chart;statistic;mosaic plot;joint distribution","Title":"Product Plots"},"151":{"Abstract":"Integral flow surfaces constitute a widely used flow visualization tool due to their capability to convey important flow information such as fluid transport, mixing, and domain segmentation. Current flow surface rendering techniques limit their expressiveness, however, by focusing virtually exclusively on displacement visualization, visually neglecting the more complex notion of deformation such as shearing and stretching that is central to the field of continuum mechanics. To incorporate this information into the flow surface visualization and analysis process, we derive a metric tensor field that encodes local surface deformations as induced by the velocity gradient of the underlying flow field. We demonstrate how properties of the resulting metric tensor field are capable of enhancing present surface visualization and generation methods and develop novel surface querying, sampling, and visualization techniques. The provided results show how this step towards unifying classic flow visualization and more advanced concepts from continuum mechanics enables more detailed and improved flow analysis.","Authors":"Obermaier, H.;Joy, K.I.","Clusters":"AnimationAndMotion;Engineering;ManipulationAndDeformation;SurfaceRelatedDataAndTechniques;TensorDataAndTechniques;VectorFieldsDataAndTechniques","DOI":"10.1109\/TVCG.2012.211","Keywords":"integral surfaces;continuum mechanics;vector field;deformation;metric tensor;velocity gradient","Keywords_Processed":"vector field;deformation;metric tensor;integral surface;continuum mechanic;velocity gradient","Title":"Derived Metric Tensors for Flow Surface Visualization"},"339":{"Abstract":"We are interested in 3-dimensional images given as arrays of voxels with intensity values. Extending these values to a continuous function, we study the robustness of homology classes in its level and interlevel sets, that is, the amount of perturbation needed to destroy these classes. The structure of the homology classes and their robustness, over all level and interlevel sets, can be visualized by a triangular diagram of dots obtained by computing the extended persistence of the function. We give a fast hierarchical algorithm using the dual complexes of oct-tree approximations of the function. In addition, we show that for balanced oct-trees, the dual complexes are geometrically realized in R3 and can thus be used to construct level and interlevel sets. We apply these tools to study 3-dimensional images of plant root systems.","Authors":"Bendich, P.;Edelsbrunner, H.;Kerber, M.","Clusters":"AdaptiveProcessingAndRefinement;BiologyAndBioinformatics;EvaluationMetricsAndBenchmarks;NumericalMethodsMathematics;ProgrammingAlgorithmsAndDataStructures;TopologyBasedTechniques;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2010.139","Keywords":"voxel arrays;persistence diagrams;persistent homology;level sets;octree;plant roots;approximation;robustness","Keywords_Processed":"level set;persistent homology;plant root;robustness;octree;approximation;voxel array;persistence diagram","Title":"Computing Robustness and Persistence for Images"},"134":{"Abstract":"This paper presents two linked empirical studies focused on uncertainty visualization. The experiments are framed from two conceptual perspectives. First, a typology of uncertainty is used to delineate kinds of uncertainty matched with space, time, and attribute components of data. Second, concepts from visual semiotics are applied to characterize the kind of visual signification that is appropriate for representing those different categories of uncertainty. This framework guided the two experiments reported here. The first addresses representation intuitiveness, considering both visual variables and iconicity of representation. The second addresses relative performance of the most intuitive abstract and iconic representations of uncertainty on a map reading task. Combined results suggest initial guidelines for representing uncertainty and discussion focuses on practical applicability of results.","Authors":"MacEachren, A.M.;Roth, R.E.;O'Brien, J.;Li, B.;Swingley, D.;Gahegan, M.","Clusters":"SemanticsSemioticsRelatedTechniques;UncertaintyTechniquesAndVisualization;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2012.279","Keywords":"uncertainty categories;semiotics;visual variables;uncertainty visualization","Keywords_Processed":"semiotic;uncertainty visualization;uncertainty category;visual variable","Title":"Visual Semiotics & Uncertainty Visualization: An Empirical Study"},"347":{"Abstract":"Applying certain visualization techniques to datasets described on unstructured grids requires the interpolation of variables of interest at arbitrary locations within the dataset's domain of definition. Typical solutions to the problem of finding the grid element enclosing a given interpolation point make use of a variety of spatial subdivision schemes. However, existing solutions are memory- intensive, do not scale well to large grids, or do not work reliably on grids describing complex geometries. In this paper, we propose a data structure and associated construction algorithm for fast cell location in unstructured grids, and apply it to the interpolation problem. Based on the concept of bounding interval hierarchies, the proposed approach is memory-efficient, fast and numerically robust. We examine the performance characteristics of the proposed approach and compare it to existing approaches using a number of benchmark problems related to vector field visualization. Furthermore, we demonstrate that our approach can successfully accommodate large datasets, and discuss application to visualization on both CPUs and GPUs.","Authors":"Garth, C.;Joy, K.I.","Clusters":"BiologyAndBioinformatics;Interpolation;MeshesGridsAndLattices;VectorFieldsDataAndTechniques","DOI":"10.1109\/TVCG.2010.156","Keywords":"cell location;vector field visualization;unstructured grid;interpolation","Keywords_Processed":"interpolation;unstructured grid;vector field visualization;cell location","Title":"Fast; Memory-Efficient Cell Location in Unstructured Grids for Visualization"},"282":{"Abstract":"Area-preserving maps are found across a wide range of scientific and engineering problems. Their study is made challenging by the significant computational effort typically required for their inspection but more fundamentally by the fractal complexity of salient structures. The visual inspection of these maps reveals a remarkable topological picture consisting of fixed (or periodic) points embedded in so-called island chains, invariant manifolds, and regions of ergodic behavior. This paper is concerned with the effective visualization and precise topological analysis of area-preserving maps with two degrees of freedom from numerical or analytical data. Specifically, a method is presented for the automatic extraction and characterization of fixed points and the computation of their invariant manifolds, also known as separatrices, to yield a complete picture of the structures present within the scale and complexity bounds selected by the user. This general approach offers a significant improvement over the visual representations that are so far available for area-preserving maps. The technique is demonstrated on a numerical simulation of magnetic confinement in a fusion reactor.","Authors":"Tricoche, X.;Garth, C.;Sanderson, A.","Clusters":"DynamicVisualizationVisualizationOfChange;Maps;NumericalMethodsMathematics;TopologyBasedTechniques","DOI":"10.1109\/TVCG.2011.254","Keywords":"invariant manifolds;topology;poincare map;area-preserving maps;chaos;dynamical systems","Keywords_Processed":"dynamical system;invariant manifold;topology;poincare map;chaos;area preserve map","Title":"Visualization of Topological Structures in Area-Preserving Maps"},"48":{"Abstract":"We present MotionExplorer, an exploratory search and analysis system for sequences of human motion in large motion capture data collections. This special type of multivariate time series data is relevant in many research fields including medicine, sports and animation. Key tasks in working with motion data include analysis of motion states and transitions, and synthesis of motion vectors by interpolation and combination. In the practice of research and application of human motion data, challenges exist in providing visual summaries and drill-down functionality for handling large motion data collections. We find that this domain can benefit from appropriate visual retrieval and analysis support to handle these tasks in presence of large motion data. To address this need, we developed MotionExplorer together with domain experts as an exploratory search system based on interactive aggregation and visualization of motion states as a basis for data navigation, exploration, and search. Based on an overview-first type visualization, users are able to search for interesting sub-sequences of motion based on a query-by-example metaphor, and explore search results by details on demand. We developed MotionExplorer in close collaboration with the targeted users who are researchers working on human motion synthesis and analysis, including a summative field study. Additionally, we conducted a laboratory design study to substantially improve MotionExplorer towards an intuitive, usable and robust design. MotionExplorer enables the search in human motion capture data with only a few mouse clicks. The researchers unanimously confirm that the system can efficiently support their work.","Authors":"Bernard, J.;Wilhelm, N.;Kruger, B.;May, T.;Schreck, T.;Kohlhammer, J.","Clusters":"AnalysisProcessGeneral;AnimationAndMotion;DataClusteringAndAggregation;GlyphsGlyphBasedTechniques;TimeseriesTimeVaryingDataAndTechniques;","DOI":"10.1109\/TVCG.2013.178","Keywords":"multivariate time series;data aggregation;exploratory search;visual analytics;cluster glyph;motion capture data","Keywords_Processed":"multivariate time series;exploratory search;visual analytic;cluster glyph;motion capture datum;datum aggregation","Title":"MotionExplorer: Exploratory Search in Human Motion Capture Data Based on Hierarchical Aggregation"},"268":{"Abstract":"Flood disasters are the most common natural risk and tremendous efforts are spent to improve their simulation and management. However, simulation-based investigation of actions that can be taken in case of flood emergencies is rarely done. This is in part due to the lack of a comprehensive framework which integrates and facilitates these efforts. In this paper, we tackle several problems which are related to steering a flood simulation. One issue is related to uncertainty. We need to account for uncertain knowledge about the environment, such as levee-breach locations. Furthermore, the steering process has to reveal how these uncertainties in the boundary conditions affect the confidence in the simulation outcome. Another important problem is that the simulation setup is often hidden in a black-box. We expose system internals and show that simulation steering can be comprehensible at the same time. This is important because the domain expert needs to be able to modify the simulation setup in order to include local knowledge and experience. In the proposed solution, users steer parameter studies through the World Lines interface to account for input uncertainties. The transport of steering information to the underlying data-flow components is handled by a novel meta-flow. The meta-flow is an extension to a standard data-flow network, comprising additional nodes and ropes to abstract parameter control. The meta-flow has a visual representation to inform the user about which control operations happen. Finally, we present the idea to use the data-flow diagram itself for visualizing steering information and simulation results. We discuss a case-study in collaboration with a domain expert who proposes different actions to protect a virtual city from imminent flooding. The key to choosing the best response strategy is the ability to compare different regions of the parameter space while retaining an understanding of what is happening inside the data-flow system.","Authors":"Waser, J.;Ribicic, H.;Fuchs, R.;Hirsch, C.;Schindler, B.;Bloschl, G.;Groller, E.","Clusters":"ApplicationsGeneralAndOther;DataAcquisitionAndManagement;EmergencyDisasterManagement;FlowVisualizationDataAndTechniques;KnowledgeDiscovery;Parameterization;UncertaintyTechniquesAndVisualization;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2011.225","Keywords":"visualization system and toolkit design;parameter study;meta-flow;uncertainty;visual knowledge discovery;emergency\/disaster management;data-flow;visualization of control","Keywords_Processed":"emergency disaster management;datum flow;meta flow;uncertainty;visual knowledge discovery;visualization of control;paramet study;visualization system and toolkit design","Title":"Nodes on Ropes: A Comprehensive Data and Control Flow for Steering Ensemble Simulations"},"253":{"Abstract":"We present a new framework for feature-based statistical analysis of large-scale scientific data and demonstrate its effectiveness by analyzing features from Direct Numerical Simulations (DNS) of turbulent combustion. Turbulent flows are ubiquitous and account for transport and mixing processes in combustion, astrophysics, fusion, and climate modeling among other disciplines. They are also characterized by coherent structure or organized motion, i.e. nonlocal entities whose geometrical features can directly impact molecular mixing and reactive processes. While traditional multi-point statistics provide correlative information, they lack nonlocal structural information, and hence, fail to provide mechanistic causality information between organized fluid motion and mixing and reactive processes. Hence, it is of great interest to capture and track flow features and their statistics together with their correlation with relevant scalar quantities, e.g. temperature or species concentrations. In our approach we encode the set of all possible flow features by pre-computing merge trees augmented with attributes, such as statistical moments of various scalar fields, e.g. temperature, as well as length-scales computed via spectral analysis. The computation is performed in an efficient streaming manner in a pre-processing step and results in a collection of meta-data that is orders of magnitude smaller than the original simulation data. This meta-data is sufficient to support a fully flexible and interactive analysis of the features, allowing for arbitrary thresholds, providing per-feature statistics, and creating various global diagnostics such as Cumulative Density Functions (CDFs), histograms, or time-series. We combine the analysis with a rendering of the features in a linked-view browser that enables scientists to interactively explore, visualize, and analyze the equivalent of one terabyte of simulation data. We highlight the utility of this new framework for combustion s- ience; however, it is applicable to many other science domains.","Authors":"Bennett, J.C.;Krishnamoorthy, V.;Shusen Liu;Grout, R.W.;Hawkes, E.R.;Chen, J.H.;Shepherd, J.;Pascucci, V.;Bremer, P.-T.","Clusters":"AnalysisProcessGeneral;MachineLearningAndStatistics;MultidimensionalMultivariateMultifieldDataAndTechniques;PhysicsAndPhysicalSciences;TopologyBasedTechniques","DOI":"10.1109\/TVCG.2011.199","Keywords":"data exploration;visualization in physical sciences and engineering;data analysis;multivariate data;topology;statistics","Keywords_Processed":"multivariate datum;topology;datum analysis;visualization in physical science and engineering;statistic;datum exploration","Title":"Feature-Based Statistical Analysis of Combustion Simulation Data"},"31":{"Abstract":"Having effective visualizations of filesystem provenance data is valuable for understanding its complex hierarchical structure. The most common visual representation of provenance data is the node-link diagram. While effective for understanding local activity, the node-link diagram fails to offer a high-level summary of activity and inter-relationships within the data. We present a new tool, InProv, which displays filesystem provenance with an interactive radial-based tree layout. The tool also utilizes a new time-based hierarchical node grouping method for filesystem provenance data we developed to match the user's mental model and make data exploration more intuitive. We compared InProv to a conventional node-link based tool, Orbiter, in a quantitative evaluation with real users of filesystem provenance data including provenance data experts, IT professionals, and computational scientists. We also compared in the evaluation our new node grouping method to a conventional method. The results demonstrate that InProv results in higher accuracy in identifying system activity than Orbiter with large complex data sets. The results also show that our new time-based hierarchical node grouping method improves performance in both tools, and participants found both tools significantly easier to use with the new time-based node grouping method. Subjective measures show that participants found InProv to require less mental activity, less physical activity, less work, and is less stressful to use. Our study also reveals one of the first cases of gender differences in visualization; both genders had comparable performance with InProv, but women had a significantly lower average accuracy (56%) compared to men (70%) with Orbiter.","Authors":"Borkin, M.;Yeh, C.S.;Boyd, M.;Macko, P.;Gajos, K.;Seltzer, M.;Pfister, H.","Clusters":"GraphNetworkDataAndTechniques;HierarchicalTreeDataAndTechniques;HumanComputerInteractionHumanFactors;ProvenanceAndHistory;QuantitativeEvaluation","DOI":"10.1109\/TVCG.2013.155","Keywords":"quantitative evaluation;gender differences;graph\/network data;provenance data;hierarchy data","Keywords_Processed":"graph network datum;gender difference;quantitative evaluation;hierarchy datum;provenance datum","Title":"Evaluation of filesystem Provenance Visualization Tools"},"368":{"Abstract":"We present TanGeoMS, a tangible geospatial modeling visualization system that couples a laser scanner, projector, and a flexible physical three-dimensional model with a standard geospatial information system (GIS) to create a tangible user interface for terrain data. TanGeoMS projects an image of real-world data onto a physical terrain model. Users can alter the topography of the model by modifying the clay surface or placing additional objects on the surface. The modified model is captured by an overhead laser scanner then imported into a GIS for analysis and simulation of real-world processes. The results are projected back onto the surface of the model providing feedback on the impact of the modifications on terrain parameters and simulated processes. Interaction with a physical model is highly intuitive, allowing users to base initial design decisions on geospatial data, test the impact of these decisions in GIS simulations, and use the feedback to improve their design. We demonstrate the system on three applications: investigating runoff management within a watershed, assessing the impact of storm surge on barrier islands, and exploring landscape rehabilitation in military training areas.","Authors":"Tateosian, L.;Mitasova, H.;Harmon, B.;Fogleman, B.;Weaver, K.;Harmon, R.","Clusters":"CollaborativeVisualization;GeographyGeospatialVisCartographyTerrainVis;HumanComputerInteractionHumanFactors;UserInterfacesGeneral;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2010.202","Keywords":"terrain visualization;visualization systems;tangible user interface;human-computer interaction;geographic\/geospatial visualization;collaborative visualization","Keywords_Processed":"human computer interaction;visualization system;geographic geospatial visualization;terrain visualization;collaborative visualization;tangible user interface","Title":"TanGeoMS: Tangible Geospatial Modeling System"},"228":{"Abstract":"In this paper, we introduce overview visualization tools for large-scale multiple genome alignment data. Genome alignment visualization and, more generally, sequence alignment visualization are an important tool for understanding genomic sequence data. As sequencing techniques improve and more data become available, greater demand is being placed on visualization tools to scale to the size of these new datasets. When viewing such large data, we necessarily cannot convey details, rather we specifically design overview tools to help elucidate large-scale patterns. Perceptual science, signal processing theory, and generality provide a framework for the design of such visualizations that can scale well beyond current approaches. We present Sequence Surveyor, a prototype that embodies these ideas for scalable multiple whole-genome alignment overview visualization. Sequence Surveyor visualizes sequences in parallel, displaying data using variable color, position, and aggregation encodings. We demonstrate how perceptual science can inform the design of visualization techniques that remain visually manageable at scale and how signal processing concepts can inform aggregation schemes that highlight global trends, outliers, and overall data distributions as the problem scales. These techniques allow us to visualize alignments with over 100 whole bacterial-sized genomes.","Authors":"Albers, D.;Dewey, C.;Gleicher, M.","Clusters":"BiologyAndBioinformatics;LargeScaleDataAndScalability;Perception;VisualDesignDesignGuidelines","DOI":"10.1109\/TVCG.2011.232","Keywords":"perception theory;visual design;bioinformatics visualization;scalability issues","Keywords_Processed":"perception theory;bioinformatic visualization;visual design;scalability issue","Title":"Sequence Surveyor: Leveraging Overview for Scalable Genomic Alignment Visualization"},"308":{"Abstract":"How do we know if what we see is really there? When visualizing data, how do we avoid falling into the trap of apophenia where we see patterns in random noise? Traditionally, infovis has been concerned with discovering new relationships, and statistics with preventing spurious relationships from being reported. We pull these opposing poles closer with two new techniques for rigorous statistical inference of visual discoveries. The \"Rorschach\" helps the analyst calibrate their understanding of uncertainty and \"line-up\" provides a protocol for assessing the significance of visual discoveries, protecting against the discovery of spurious structure.","Authors":"Wickham, H.;Cook, D.;Hofmann, H.;Buja, Andreas","Clusters":"ChartsDiagramsPlots;EvaluationGeneral;MachineLearningAndStatistics;QuantitativeEvaluation","DOI":"10.1109\/TVCG.2010.161","Keywords":"visual testing;permutation tests;data plots;null hypotheses;statistics","Keywords_Processed":"visual testing;null hypothesis;data plot;permutation test;statistic","Title":"Graphical inference for infovis"},"171":{"Abstract":"Despite the ongoing efforts in turbulence research, the universal properties of the turbulence small-scale structure and the relationships between small- and large-scale turbulent motions are not yet fully understood. The visually guided exploration of turbulence features, including the interactive selection and simultaneous visualization of multiple features, can further progress our understanding of turbulence. Accomplishing this task for flow fields in which the full turbulence spectrum is well resolved is challenging on desktop computers. This is due to the extreme resolution of such fields, requiring memory and bandwidth capacities going beyond what is currently available. To overcome these limitations, we present a GPU system for feature-based turbulence visualization that works on a compressed flow field representation. We use a wavelet-based compression scheme including run-length and entropy encoding, which can be decoded on the GPU and embedded into brick-based volume ray-casting. This enables a drastic reduction of the data to be streamed from disk to GPU memory. Our system derives turbulence properties directly from the velocity gradient tensor, and it either renders these properties in turn or generates and renders scalar feature volumes. The quality and efficiency of the system is demonstrated in the visualization of two unsteady turbulence simulations, each comprising a spatio-temporal resolution of 10244. On a desktop computer, the system can visualize each time step in 5 seconds, and it achieves about three times this rate for the visualization of a scalar feature volume.","Authors":"Treib, M.;Burger, K.;Reichl, F.;Meneveau, C.;Szalay, A.;Westermann, R.","Clusters":"CompressionTechniques;StreamingDataAndTechniques;VectorFieldsDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2012.274","Keywords":"volume rendering;data compression;data streaming;vector field;visualization system and toolkit design","Keywords_Processed":"volume render;vector field;data compression;datum stream;visualization system and toolkit design","Title":"Turbulence Visualization at the Terascale on Desktop PCs"},"145":{"Abstract":"One potential solution to reduce the concentration of carbon dioxide in the atmosphere is the geologic storage of captured CO2 in underground rock formations, also known as carbon sequestration. There is ongoing research to guarantee that this process is both efficient and safe. We describe tools that provide measurements of media porosity, and permeability estimates, including visualization of pore structures. Existing standard algorithms make limited use of geometric information in calculating permeability of complex microstructures. This quantity is important for the analysis of biomineralization, a subsurface process that can affect physical properties of porous media. This paper introduces geometric and topological descriptors that enhance the estimation of material permeability. Our analysis framework includes the processing of experimental data, segmentation, and feature extraction and making novel use of multiscale topological analysis to quantify maximum flow through porous networks. We illustrate our results using synchrotron-based X-ray computed microtomography of glass beads during biomineralization. We also benchmark the proposed algorithms using simulated data sets modeling jammed packed bead beds of a monodispersive material.","Authors":"Ushizima, D.;Morozov, D.;Weber, G.H.;Bianchi, A.G.C.;Sethian, J.A.;Bethel, E.W.","Clusters":"GeometricModeling;Microscopy;SegmentationAndClassification;TopologyBasedTechniques","DOI":"10.1109\/TVCG.2012.200","Keywords":"geometric algorithms;persistent homology;segmentation;topological data analysis;reeb graph;microscopy","Keywords_Processed":"persistent homology;reeb graph;microscopy;segmentation;geometric algorithm;topological datum analysis","Title":"Augmented Topological Descriptors of Pore Networks for Material Science"},"315":{"Abstract":"Although previous research has suggested that examining the interplay between internal and external representations can benefit our understanding of the role of information visualization (InfoVis) in human cognitive activities, there has been little work detailing the nature of internal representations, the relationship between internal and external representations and how interaction is related to these representations. In this paper, we identify and illustrate a specific kind of internal representation, mental models, and outline the high-level relationships between mental models and external visualizations. We present a top-down perspective of reasoning as model construction and simulation, and discuss the role of visualization in model based reasoning. From this perspective, interaction can be understood as active modeling for three primary purposes: external anchoring, information foraging, and cognitive offloading. Finally we discuss the implications of our approach for design, evaluation and theory development.","Authors":"Zhicheng Liu;Stasko, J.","Clusters":"Cognition;InteractionTechniquesGeneral;ReasoningProblemSolvingAndDecisionMaking;VisualizationTheoryModelsAndMethods","DOI":"10.1109\/TVCG.2010.177","Keywords":"information visualization;theory;mental model;distributed cognition;model-based reasoning;interaction","Keywords_Processed":"interaction;mental model;information visualization;theory;model base reasoning;distribute cognition","Title":"Mental Models; Visual Reasoning and Interaction in Information Visualization: A Top-down Perspective"},"97":{"Abstract":"In this paper, we investigate the problem of labeling point sites in focus regions of maps or diagrams. This problem occurs, for example, when the user of a mapping service wants to see the names of restaurants or other POIs in a crowded downtown area but keep the overview over a larger area. Our approach is to place the labels at the boundary of the focus region and connect each site with its label by a linear connection, which is called a leader. In this way, we move labels from the focus region to the less valuable context region surrounding it. In order to make the leader layout well readable, we present algorithms that rule out crossings between leaders and optimize other characteristics such as total leader length and distance between labels. This yields a new variant of the boundary labeling problem, which has been studied in the literature. Other than in traditional boundary labeling, where leaders are usually schematized polylines, we focus on leaders that are either straight-line segments or Bezier curves. Further, we present algorithms that, given the sites, find a position of the focus region that optimizes the above characteristics. We also consider a variant of the problem where we have more sites than space for labels. In this situation, we assume that the sites are prioritized by the user. Alternatively, we take a new facility-location perspective which yields a clustering of the sites. We label one representative of each cluster. If the user wishes, we apply our approach to the sites within a cluster, giving details on demand.","Authors":"Fink, M.;Haunert, J.-H.;Schulz, A.;Spoerhase, J.;Wolff, A.","Clusters":"DataClusteringAndAggregation;FocusContextTechniques;GeographyGeospatialVisCartographyTerrainVis;SmallMobileUbiquitousDevicesDisplays","DOI":"10.1109\/TVCG.2012.193","Keywords":"focus+context technique;mobile and ubiquitous visualization;geographic\/geospatial visualization;data clustering","Keywords_Processed":"mobile and ubiquitous visualization;focus context technique;geographic geospatial visualization;datum clustering","Title":"Algorithms for Labeling Focus Regions"}}