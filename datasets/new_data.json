{"0":{"Abstract":"We describe and demonstrate an extensible framework that supports data exploration and provenance in the context of Human Terrain Analysis (HTA). Working closely with defence analysts we extract requirements and a list of features that characterise data analysed at the end of the HTA chain. From these, we select an appropriate non-classified data source with analogous features, and model it as a set of facets. We develop ProveML, an XML-based extension of the Open Provenance Model, using these facets and augment it with the structures necessary to record the provenance of data, analytical process and interpretations. Through an iterative process, we develop and refine a prototype system for Human Terrain Visual Analytics (HTVA), and demonstrate means of storing, browsing and recalling analytical provenance and process through analytic bookmarks in ProveML. We show how these bookmarks can be combined to form narratives that link back to the live data. Throughout the process, we demonstrate that through structured workshops, rapid prototyping and structured communication with intelligence analysts we are able to establish requirements, and design schema, techniques and tools that meet the requirements of the intelligence community. We use the needs and reactions of defence analysts in defining and steering the methods to validate the framework.","Authors":"Walker, R.;Slingsby, A.;Dykes, J.;Kai Xu;Wood, J.;Nguyen, P.H.;Stephens, D.;Wong, B.L.W.;Yongjun Zheng","Clusters":"GeographyGeospatialVisCartographyTerrainVis;InternetWebVisualizationForTheMasses;ProvenanceAndHistory;Storytelling;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2013.132","Keywords":"human terrain analysis;provenance;bookmarks;framework;narrative","Keywords_Processed":"human terrain analysis;framework;narrative;bookmark;provenance","Title":"An Extensible Framework for Provenance in Human Terrain Visual Analytics"},"1":{"Abstract":"We present a novel dynamic graph visualization technique based on node-link diagrams. The graphs are drawn side-byside from left to right as a sequence of narrow stripes that are placed perpendicular to the horizontal time line. The hierarchically organized vertices of the graphs are arranged on vertical, parallel lines that bound the stripes; directed edges connect these vertices from left to right. To address massive overplotting of edges in huge graphs, we employ a splatting approach that transforms the edges to a pixel-based scalar field. This field represents the edge densities in a scalable way and is depicted by non-linear color mapping. The visualization method is complemented by interaction techniques that support data exploration by aggregation, filtering, brushing, and selective data zooming. Furthermore, we formalize graph patterns so that they can be interactively highlighted on demand. A case study on software releases explores the evolution of call graphs extracted from the JUnit open source software project. In a second application, we demonstrate the scalability of our approach by applying it to a bibliography dataset containing more than 1.5 million paper titles from 60 years of research history producing a vast amount of relations between title words.","Authors":"Burch, M.;Vehlow, C.;Beck, F.;Diehl, S.;Weiskopf, D.","Clusters":"GraphNetworkDataAndTechniques;ProgrammingAlgorithmsAndDataStructures;SoftwareVisualization","DOI":"10.1109\/TVCG.2011.226","Keywords":"software visualization;graph splatting;dynamic graph visualization;software evolution","Keywords_Processed":"dynamic graph visualization;software visualization;software evolution;graph splatte","Title":"Parallel Edge Splatting for Scalable Dynamic Graph Visualization"},"2":{"Abstract":"Percutaneous radiofrequency ablation (RFA) is becoming a standard minimally invasive clinical procedure for the treatment of liver tumors. However, planning the applicator placement such that the malignant tissue is completely destroyed, is a demanding task that requires considerable experience. In this work, we present a fast GPU-based real-time approximation of the ablation zone incorporating the cooling effect of liver vessels. Weighted distance fields of varying RF applicator types are derived from complex numerical simulations to allow a fast estimation of the ablation zone. Furthermore, the heat-sink effect of the cooling blood flow close to the applicator's electrode is estimated by means of a preprocessed thermal equilibrium representation of the liver parenchyma and blood vessels. Utilizing the graphics card, the weighted distance field incorporating the cooling blood flow is calculated using a modular shader framework, which facilitates the real-time visualization of the ablation zone in projected slice views and in volume rendering. The proposed methods are integrated in our software assistant prototype for planning RFA therapy. The software allows the physician to interactively place virtual RF applicator models. The real-time visualization of the corresponding approximated ablation zone facilitates interactive evaluation of the tumor coverage in order to optimize the applicator's placement such that all cancer cells are destroyed by the ablation.","Authors":"Rieder, C.;Kroeger, T.;Schumann, C.;Hahn, H.K.","Clusters":"BiomedicalScienceAndMedicine;EarthSpaceAndEnvironmentalSciences;GpuBasedTechniques;InteractionTechniquesGeneral;VisualizationTechniquesAndToolsGeneral;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2011.207","Keywords":"volume rendering;distance field;ablation zone visualization;gpu;radiofrequency ablation;interaction","Keywords_Processed":"interaction;volume render;distance field;radiofrequency ablation;ablation zone visualization;gpu","Title":"GPU-based Real-Time Approximation of the Ablation Zone for Radiofrequency Ablation"},"3":{"Abstract":"We present a novel technique-Compressed Adjacency Matrices-for visualizing gene regulatory networks. These directed networks have strong structural characteristics: out-degrees with a scale-free distribution, in-degrees bound by a low maximum, and few and small cycles. Standard visualization techniques, such as node-link diagrams and adjacency matrices, are impeded by these network characteristics. The scale-free distribution of out-degrees causes a high number of intersecting edges in node-link diagrams. Adjacency matrices become space-inefficient due to the low in-degrees and the resulting sparse network. Compressed adjacency matrices, however, exploit these structural characteristics. By cutting open and rearranging an adjacency matrix, we achieve a compact and neatly-arranged visualization. Compressed adjacency matrices allow for easy detection of subnetworks with a specific structure, so-called motifs, which provide important knowledge about gene regulatory networks to domain experts. We summarize motifs commonly referred to in the literature, and relate them to network analysis tasks common to the visualization domain. We show that a user can easily find the important motifs in compressed adjacency matrices, and that this is hard in standard adjacency matrix and node-link diagrams. We also demonstrate that interaction techniques for standard adjacency matrices can be used for our compressed variant. These techniques include rearrangement clustering, highlighting, and filtering.","Authors":"Dinkla, K.;Westenberg, M.A.;van Wijk, J.J.","Clusters":"Genetics;GraphNetworkDataAndTechniques;MatrixRelatedTechniques","DOI":"10.1109\/TVCG.2012.208","Keywords":"scale-free;adjacency matrix;networks;gene regulation","Keywords_Processed":"network;scale free;gene regulation;adjacency matrix","Title":"Compressed Adjacency Matrices: Untangling Gene Regulatory Networks"},"4":{"Abstract":"The visual analysis of dynamic networks is a challenging task. In this paper, we introduce a new approach supporting the discovery of substructures sharing a similar trend over time by combining computation, visualization and interaction. With existing techniques, their discovery would be a tedious endeavor because of the number of nodes, edges as well as time points to be compared. First, on the basis of the supergraph, we therefore group nodes and edges according to their associated attributes that are changing over time. Second, the supergraph is visualized to provide an overview of the groups of nodes and edges with similar behavior over time in terms of their associated attributes. Third, we provide specific interactions to explore and refine the temporal clustering, allowing the user to further steer the analysis of the dynamic network. We demonstrate our approach by the visual analysis of a large wireless mesh network.","Authors":"Hadlak, S.;Schumann, H.;Cap, C.H.;Wollenberg, T.","Clusters":"DataClusteringAndAggregation;DynamicDataAndTechniques;","DOI":"10.1109\/TVCG.2013.198","Keywords":"visualization;supergraph clustering;dynamic networks","Keywords_Processed":"visualization;dynamic network;supergraph clustering","Title":"Supporting the Visual Analysis of Dynamic Networks by Clustering associated Temporal Attributes"},"5":{"Abstract":"In this paper, we propose a new strategy for graph drawing utilizing layouts of many sub-graphs supplied by a large group of people in a crowd sourcing manner. We developed an algorithm based on Laplacian constrained distance embedding to merge subgraphs submitted by different users, while attempting to maintain the topological information of the individual input layouts. To facilitate collection of layouts from many people, a light-weight interactive system has been designed to enable convenient dynamic viewing, modification and traversing between layouts. Compared with other existing graph layout algorithms, our approach can achieve more aesthetic and meaningful layouts with high user preference.","Authors":"Xiaoru Yuan;Limei Che;Yifan Hu;Xin Zhang","Clusters":"DataEditing;DataRegistrationFusionAndIntegration;Engineering;EvaluationGeneral;GraphNetworkDataAndTechniques;MatrixRelatedTechniques","DOI":"10.1109\/TVCG.2012.236","Keywords":"merging;stress model;graph layout;laplacian matrix;editing;force-directed layout;crowdsourcing","Keywords_Processed":"graph layout;laplacian matrix;stress model;merge;edit;force direct layout;crowdsource","Title":"Intelligent Graph Layout Using Many Users' Input"},"6":{"Abstract":"Sensitivity analysis is a powerful method for discovering the significant factors that contribute to targets and understanding the interaction between variables in multivariate datasets. A number of sensitivity analysis methods fall into the class of local analysis, in which the sensitivity is defined as the partial derivatives of a target variable with respect to a group of independent variables. Incorporating sensitivity analysis in visual analytic tools is essential for multivariate phenomena analysis. However, most current multivariate visualization techniques do not allow users to explore local patterns individually for understanding the sensitivity from a pointwise view. In this paper, we present a novel pointwise local pattern exploration system for visual sensitivity analysis. Using this system, analysts are able to explore local patterns and the sensitivity at individual data points, which reveals the relationships between a focal point and its neighbors. During exploration, users are able to interactively change the derivative coefficients to perform sensitivity analysis based on different requirements as well as their domain knowledge. Each local pattern is assigned an outlier factor, so that users can quickly identify anomalous local patterns that do not conform with the global pattern. Users can also compare the local pattern with the global pattern both visually and statistically. Finally, the local pattern is integrated into the original attribute space using color mapping and jittering, which reveals the distribution of the partial derivatives. Case studies with real datasets are used to investigate the effectiveness of the visualizations and interactions.","Authors":"Zhenyu Guo;Ward, M.O.;Rundensteiner, E.A.;Ruiz, C.","Clusters":"KnowledgeDiscovery;UncertaintyTechniquesAndVisualization;VisualPatternFeatureDetectionAndTracking","DOI":"10.1109\/VAST.2011.6102450","Keywords":"sensitivity analysis;knowledge discovery;local pattern visualizations","Keywords_Processed":"local pattern visualization;knowledge discovery;sensitivity analysis","Title":"Pointwise local pattern exploration for sensitivity analysis"},"7":{"Abstract":"A fundamental characteristic of fluid flow is that it causes mixing: introduce a dye into a flow, and it will disperse. Mixing can be used as a method to visualize and characterize flow. Because mixing is a process that occurs over time, it is a 4D problem that presents a challenge for computation, visualization, and analysis. Motivated by a mixing problem in geophysics, we introduce a combination of methods to analyze, transform, and finally visualize mixing in simulations of convection in a self-gravitating 3D spherical shell representing convection in the Earth's mantle. Geophysicists use tools such as the finite element model CitcomS to simulate convection, and introduce massless, passive tracers to model mixing. The output of geophysical flow simulation is hard to analyze for domain experts because of overall data size and complexity. In addition, information overload and occlusion are problems when visualizing a whole-earth model. To address the large size of the data, we rearrange the simulation data using intelligent indexing for fast file access and efficient caching. To address information overload and interpret mixing, we compute tracer concentration statistics, which are used to characterize mixing in mantle convection models. Our visualization uses a specially tailored version of Direct Volume Rendering. The most important adjustment is the use of constant opacity. Because of this special area of application, i. e. the rendering of a spherical shell, many computations for volume rendering can be optimized. These optimizations are essential to a smooth animation of the time-dependent simulation data. Our results show how our system can be used to quickly assess the simulation output and test hypotheses regarding Earth's mantle convection. The integrated processing pipeline helps geoscientists to focus on their main task of analyzing mantle homogenization.","Authors":"Schroder, S.;Peterson, J.A.;Obermaier, H.;Kellogg, L.H.;Joy, K.I.;Hagen, H.","Clusters":"BiomedicalScienceAndMedicine;EarthSpaceAndEnvironmentalSciences;FlowVisualizationDataAndTechniques;LargeScaleDataAndScalability;PhysicsAndPhysicalSciences","DOI":"10.1109\/TVCG.2012.283","Keywords":"flow visualization;tracer concentration;earth mantle;convection;large data system;geophysics","Keywords_Processed":"earth mantle;large datum system;tracer concentration;geophysic;convection;flow visualization","Title":"Visualization of Flow Behavior in Earth Mantle Convection"},"8":{"Abstract":"In this paper, we present a user study in which we have investigated the influence of seven state-of-the-art volumetric illumination models on the spatial perception of volume rendered images. Within the study, we have compared gradient-based shading with half angle slicing, directional occlusion shading, multidirectional occlusion shading, shadow volume propagation, spherical harmonic lighting as well as dynamic ambient occlusion. To evaluate these models, users had to solve three tasks relying on correct depth as well as size perception. Our motivation for these three tasks was to find relations between the used illumination model, user accuracy and the elapsed time. In an additional task, users had to subjectively judge the output of the tested models. After first reviewing the models and their features, we will introduce the individual tasks and discuss their results. We discovered statistically significant differences in the testing performance of the techniques. Based on these findings, we have analyzed the models and extracted those features which are possibly relevant for the improved spatial comprehension in a relational task. We believe that a combination of these distinctive features could pave the way for a novel illumination model, which would be optimized based on our findings.","Authors":"Lindemann, F.;Ropinski, T.","Clusters":"Cognition;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2011.161","Keywords":"volume illumination;volume rendering;spatial comprehension","Keywords_Processed":"volume render;volume illumination;spatial comprehension","Title":"About the Influence of Illumination Models on Image Comprehension in Direct Volume Rendering"},"9":{"Abstract":"For information visualization researchers, eye tracking has been a useful tool to investigate research participants' underlying cognitive processes by tracking their eye movements while they interact with visual techniques. We used an eye tracker to better understand why participants with a variant of a tabular visualization called `SimulSort' outperformed ones with a conventional table and typical one-column sorting feature (i.e., Typical Sorting). The collected eye-tracking data certainly shed light on the detailed cognitive processes of the participants; SimulSort helped with decision-making tasks by promoting efficient browsing behavior and compensatory decision-making strategies. However, more interestingly, we also found unexpected eye-tracking patterns with Simul- Sort. We investigated the cause of the unexpected patterns through a crowdsourcing-based study (i.e., Experiment 2), which elicited an important limitation of the eye tracking method: incapability of capturing peripheral vision. This particular result would be a caveat for other visualization researchers who plan to use an eye tracker in their studies. In addition, the method to use a testing stimulus (i.e., influential column) in Experiment 2 to verify the existence of such limitations would be useful for researchers who would like to verify their eye tracking results.","Authors":"Sung-Hee Kim;Zhihua Dong;Hanjun Xian;Upatising, B.;Ji Soo Yi","Clusters":"EvaluationGeneral;Perception;QuantitativeEvaluation;ReasoningProblemSolvingAndDecisionMaking;","DOI":"10.1109\/TVCG.2012.215","Keywords":"visualized decision making;limitations;crowdsourcing;peripheral vision;eye tracking;quantitative empirical study","Keywords_Processed":"visualize decision making;limitation;quantitative empirical study;eye tracking;peripheral vision;crowdsource","Title":"Does an Eye Tracker Tell the Truth about Visualizations?: findings while Investigating Visualizations for Decision Making"},"10":{"Abstract":"We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to qua- wing insects.","Authors":"Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.","Clusters":"BiologyAndBioinformatics;FlowVisualizationDataAndTechniques;StreamlinesPathlinesStreaklines","DOI":"10.1109\/TVCG.2011.260","Keywords":"flow visualization;vortex visualization;unsteady flow;streamlines;flowing seed points;streaklines;insect flight","Keywords_Processed":"flow seed point;streamline;unsteady flow;insect flight;vortex visualization;streakline;flow visualization","Title":"Vortex Visualization in Ultra Low Reynolds Number Insect Flight"},"11":{"Abstract":"We introduce Visual Sedimentation, a novel design metaphor for visualizing data streams directly inspired by the physical process of sedimentation. Visualizing data streams (e. g., Tweets, RSS, Emails) is challenging as incoming data arrive at unpredictable rates and have to remain readable. For data streams, clearly expressing chronological order while avoiding clutter, and keeping aging data visible, are important. The metaphor is drawn from the real-world sedimentation processes: objects fall due to gravity, and aggregate into strata over time. Inspired by this metaphor, data is visually depicted as falling objects using a force model to land on a surface, aggregating into strata over time. In this paper, we discuss how this metaphor addresses the specific challenge of smoothing the transition between incoming and aging data. We describe the metaphor's design space, a toolkit developed to facilitate its implementation, and example applications to a range of case studies. We then explore the generative capabilities of the design space through our toolkit. We finally illustrate creative extensions of the metaphor when applied to real streams of data.","Authors":"Huron, S.;Vuillemot, R.;Fekete, J.","Clusters":"DynamicDataAndTechniques;DynamicVisualizationVisualizationOfChange;RealtimeProcessingRenderingAndVisualizationGeneral;StreamingDataAndTechniques;VisualDesignDesignGuidelines;VisualizationTheoryModelsAndMethods","DOI":"10.1109\/TVCG.2013.227","Keywords":"information visualization;dynamic data;realtime;data stream;design;metaphors;dynamic visualization","Keywords_Processed":"realtime;information visualization;dynamic datum;dynamic visualization;datum stream;design;metaphor","Title":"Visual Sedimentation"},"12":{"Abstract":"Biological pathway maps are highly relevant tools for many tasks in molecular biology. They reduce the complexity of the overall biological network by partitioning it into smaller manageable parts. While this reduction of complexity is their biggest strength, it is, at the same time, their biggest weakness. By removing what is deemed not important for the primary function of the pathway, biologists lose the ability to follow and understand cross-talks between pathways. Considering these cross-talks is, however, critical in many analysis scenarios, such as judging effects of drugs. In this paper we introduce Entourage, a novel visualization technique that provides contextual information lost due to the artificial partitioning of the biological network, but at the same time limits the presented information to what is relevant to the analyst's task. We use one pathway map as the focus of an analysis and allow a larger set of contextual pathways. For these context pathways we only show the contextual subsets, i.e., the parts of the graph that are relevant to a selection. Entourage suggests related pathways based on similarities and highlights parts of a pathway that are interesting in terms of mapped experimental data. We visualize interdependencies between pathways using stubs of visual links, which we found effective yet not obtrusive. By combining this approach with visualization of experimental data, we can provide domain experts with a highly valuable tool. We demonstrate the utility of Entourage with case studies conducted with a biochemist who researches the effects of drugs on pathways. We show that the technique is well suited to investigate interdependencies between pathways and to analyze, understand, and predict the effect that drugs have on different cell types.","Authors":"Lex, A.;Partl, C.;Kalkofen, D.;Streit, M.;Gratzl, S.;Wassermann, A.M.;Schmalstieg, D.;Pfister, H.","Clusters":"BiologyAndBioinformatics;GraphNetworkDataAndTechniques;MolecularScienceAndChemistry;SetRelatedDataTechniques","DOI":"10.1109\/TVCG.2013.154","Keywords":"pathway visualization;subsets;biomolecular data;graph;biological networks","Keywords_Processed":"pathway visualization;biological network;graph;subset;biomolecular datum","Title":"Entourage: Visualizing Relationships between Biological Pathways using Contextual Subsets"},"13":{"Abstract":"In Toponomics, the function protein pattern in cells or tissue (the toponome) is imaged and analyzed for applications in toxicology, new drug development and patient-drug-interaction. The most advanced imaging technique is robot-driven multi-parameter fluorescence microscopy. This technique is capable of co-mapping hundreds of proteins and their distribution and assembly in protein clusters across a cell or tissue sample by running cycles of fluorescence tagging with monoclonal antibodies or other affinity reagents, imaging, and bleaching in situ. The imaging results in complex multi-parameter data composed of one slice or a 3D volume per affinity reagent. Biologists are particularly interested in the localization of co-occurring proteins, the frequency of co-occurrence and the distribution of co-occurring proteins across the cell. We present an interactive visual analysis approach for the evaluation of multi-parameter fluorescence microscopy data in toponomics. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The feature specification result is linked to all views establishing a focus+context visualization in 3D. In a new attribute view, we integrate techniques from graph visualization. Each node in the graph represents an affinity reagent while each edge represents two co-occurring affinity reagent bindings. The graph visualization is enhanced by glyphs which encode specific properties of the binding. The graph view is equipped with brushing facilities. By brushing in the spatial and attribute domain, the biologist achieves a better understanding of the function protein patterns of a cell. Furthermore, an interactive table view is integrated which summarizes unique fluorescence patterns. We discuss our approach with respect to a cell probe containing lymphocytes and a prostate tissue section.","Authors":"Oeltze, S.;Freiler, W.;Hillert, R.;Doleisch, H.;Preim, B.;Schubert, W.","Clusters":"BiologyAndBioinformatics;GraphNetworkDataAndTechniques;Microscopy;MolecularScienceAndChemistry;","DOI":"10.1109\/TVCG.2011.217","Keywords":"protein interaction;toponomics;fluorescence microscopy;graph visualization;visual analytics","Keywords_Processed":"fluorescence microscopy;toponomic;visual analytic;protein interaction;graph visualization","Title":"Interactive, Graph-based Visual Analysis of High-dimensional, Multi-parameter Fluorescence Microscopy Data in Toponomics"},"14":{"Abstract":"We present a GPU-based ray-tracing system for the accurate and interactive visualization of cut-surfaces through 3D simulations of physical processes created from spectral\/hp high-order finite element methods. When used by the numerical analyst to debug the solver, the ability for the imagery to precisely reflect the data is critical. In practice, the investigator interactively selects from a palette of visualization tools to construct a scene that can answer a query of the data. This is effective as long as the implicit contract of image quality between the individual and the visualization system is upheld. OpenGL rendering of scientific visualizations has worked remarkably well for exploratory visualization for most solver results. This is due to the consistency between the use of first-order representations in the simulation and the linear assumptions inherent in OpenGL (planar fragments and color-space interpolation). Unfortunately, the contract is broken when the solver discretization is of higher-order. There have been attempts to mitigate this through the use of spatial adaptation and\/or texture mapping. These methods do a better job of approximating what the imagery should be but are not exact and tend to be view-dependent. This paper introduces new rendering mechanisms that specifically deal with the kinds of native data generated by high-order finite element solvers. The exploratory visualization tools are reassessed and cast in this system with the focus on image accuracy. This is accomplished in a GPU setting to ensure interactivity.","Authors":"Nelson, B.;Haimes, R.;Kirby, R.M.","Clusters":"GpuBasedTechniques;IsosurfaceAndSurfaceExtractionTechniques;NumericalMethodsMathematics","DOI":"10.1109\/TVCG.2011.206","Keywords":"gpu raytracing;high-order finite elements;gpu-based root-finding;cut-surface extraction;spectral\/hp elements;cut-plane extraction","Keywords_Processed":"spectral hp element;gpu base root finding;cut plane extraction;high order finite element;gpu raytracing;cut surface extraction","Title":"GPU-Based Interactive Cut-Surface Extraction From High-Order finite Element fields"},"15":{"Abstract":"We present a quasi interpolation framework that attains the optimal approximation-order of Voronoi splines for reconstruction of volumetric data sampled on general lattices. The quasi interpolation framework of Voronoi splines provides an unbiased reconstruction method across various lattices. Therefore this framework allows us to analyze and contrast the sampling-theoretic performance of general lattices, using signal reconstruction, in an unbiased manner. Our quasi interpolation methodology is implemented as an efficient FIR filter that can be applied online or as a preprocessing step. We present visual and numerical experiments that demonstrate the improved accuracy of reconstruction across lattices, using the quasi interpolation framework.","Authors":"Mirzargar, M.;Entezari, A.","Clusters":"CurvesAndCurvature;Interpolation;VolumeRenderingModelingAndVisualization;VoronoiBasedTechniques","DOI":"10.1109\/TVCG.2011.230","Keywords":"quasi interpolation;volume visualization;box spline;voronoi spline","Keywords_Processed":"box spline;voronoi spline;quasi interpolation;volume visualization","Title":"Quasi Interpolation With Voronoi Splines"},"16":{"Abstract":"The aspect ratio of a plot has a dramatic impact on our ability to perceive trends and patterns in the data. Previous approaches for automatically selecting the aspect ratio have been based on adjusting the orientations or angles of the line segments in the plot. In contrast, we recommend a simple, effective method for selecting the aspect ratio: minimize the arc length of the data curve while keeping the area of the plot constant. The approach is parameterization invariant, robust to a wide range of inputs, preserves visual symmetries in the data, and is a compromise between previously proposed techniques. Further, we demonstrate that it can be effectively used to select the aspect ratio of contour plots. We believe arc length should become the default aspect ratio selection method.","Authors":"Talbot, J.;Gerth, J.;Hanrahan, P.","Clusters":"VectorFieldsDataAndTechniques;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2011.167","Keywords":"orientation resolution;aspect ratio selection;banking to 45 degrees","Keywords_Processed":"orientation resolution;banking to 45 degree;aspect ratio selection","Title":"Arc Length-Based Aspect Ratio Selection"},"17":{"Abstract":"We present a visual analytics solution designed to address prevalent issues in the area of Operational Decision Management (ODM). In ODM, which has its roots in Artificial Intelligence (Expert Systems) and Management Science, it is increasingly important to align business decisions with business goals. In our work, we consider decision models (executable models of the business domain) as ontologies that describe the business domain, and production rules that describe the business logic of decisions to be made over this ontology. Executing a decision model produces an accumulation of decisions made over time for individual cases. We are interested, first, to get insight in the decision logic and the accumulated facts by themselves. Secondly and more importantly, we want to see how the accumulated facts reveal potential divergences between the reality as captured by the decision model, and the reality as captured by the executed decisions. We illustrate the motivation, added value for visual analytics, and our proposed solution and tooling through a business case from the car insurance industry.","Authors":"Broeksema, B.;Baudel, T.;Telea, A.;Crisafulli, P.","Clusters":"MachineLearningAndStatistics;SoftwareVisualization;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2013.146","Keywords":"program analysis;decision support systems;model validation and analysis;multivariate statistics","Keywords_Processed":"decision support system;multivariate statistic;model validation and analysis;program analysis","Title":"Decision Exploration Lab: A Visual Analytics Solution for Decision Management"},"18":{"Abstract":"Network data often contain important attributes from various dimensions such as social affiliations and areas of expertise in a social network. If such attributes exhibit a tree structure, visualizing a compound graph consisting of tree and network structures becomes complicated. How to visually reveal patterns of a network over a tree has not been fully studied. In this paper, we propose a compound graph model, TreeNet, to support visualization and analysis of a network at multiple levels of aggregation over a tree. We also present a visualization design, TreeNetViz, to offer the multiscale and cross-scale exploration and interaction of a TreeNet graph. TreeNetViz uses a Radial, Space-Filling (RSF) visualization to represent the tree structure, a circle layout with novel optimization to show aggregated networks derived from TreeNet, and an edge bundling technique to reduce visual complexity. Our circular layout algorithm reduces both total edge-crossings and edge length and also considers hierarchical structure constraints and edge weight in a TreeNet graph. These experiments illustrate that the algorithm can reduce visual cluttering in TreeNet graphs. Our case study also shows that TreeNetViz has the potential to support the analysis of a compound graph by revealing multiscale and cross-scale network patterns.","Authors":"Liang Gou;Xiaolong Zhang","Clusters":"GraphNetworkDataAndTechniques;MultiScaleDataTechniques;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2011.247","Keywords":"network and tree;multi-scale and cross-scale;visualization;treenetviz;compound graphs","Keywords_Processed":"visualization;treenetviz;network and tree;multi scale and cross scale;compound graph","Title":"TreeNetViz: Revealing Patterns of Networks over Tree Structures"},"19":{"Abstract":"For preserving the grotto wall paintings and protecting these historic cultural icons from the damage and deterioration in nature environment, a visual analytics framework and a set of tools are proposed for the discovery of degradation patterns. In comparison with the traditional analysis methods that used restricted scales, our method provides users with multi-scale analytic support to study the problems on site, cave, wall and particular degradation area scales, through the application of multidimensional visualization techniques. Several case studies have been carried out using real-world wall painting data collected from a renowned World Heritage site, to verify the usability and effectiveness of the proposed method. User studies and expert reviews were also conducted through by domain experts ranging from scientists such as microenvironment researchers, archivists, geologists, chemists, to practitioners such as conservators, restorers and curators.","Authors":"Jiawan Zhang;Kai Kang;Dajian Liu;Ye Yuan;Yanli, E.","Clusters":"ApplicationsGeneralAndOther;ArtAndAestheticsInVisualization;SocialScienceAndHumanities;","DOI":"10.1109\/TVCG.2013.219","Keywords":"wall paintings;cultural heritage;visual analytics;degradation","Keywords_Processed":"visual analytic;cultural heritage;wall painting;degradation","Title":"Vis4Heritage: Visual Analytics Approach on Grotto Wall Painting Degradations"},"20":{"Abstract":"As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them.","Authors":"Ferreira, N.;Poco, J.;Vo, H.T.;Freire, J.;Silva, C.T.","Clusters":"AnalysisProcessGeneral;ApplicationsGeneralAndOther;QueriesAndSearch;Traffic","DOI":"10.1109\/TVCG.2013.226","Keywords":"urban data;spatio-temporal queries;visual exploration;taxi movement data","Keywords_Processed":"spatio temporal query;taxi movement datum;urban datum;visual exploration","Title":"Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips"},"21":{"Abstract":"Contingency tables summarize the relations between categorical variables and arise in both scientific and business domains. Asymmetrically large two-way contingency tables pose a problem for common visualization methods. The Contingency Wheel has been recently proposed as an interactive visual method to explore and analyze such tables. However, the scalability and readability of this method are limited when dealing with large and dense tables. In this paper we present Contingency Wheel++, new visual analytics methods that overcome these major shortcomings: (1) regarding automated methods, a measure of association based on Pearson's residuals alleviates the bias of the raw residuals originally used, (2) regarding visualization methods, a frequency-based abstraction of the visual elements eliminates overlapping and makes analyzing both positive and negative associations possible, and (3) regarding the interactive exploration environment, a multi-level overview+detail interface enables exploring individual data items that are aggregated in the visualization or in the table using coordinated views. We illustrate the applicability of these new methods with a use case and show how they enable discovering and analyzing nontrivial patterns and associations in large categorical data.","Authors":"Alsallakh, B.;Aigner, W.;Miksch, S.;Groller, E.","Clusters":"LargeScaleDataAndScalability;TabularDataAndTechniques;UserInterfacesGeneral","DOI":"10.1109\/TVCG.2012.254","Keywords":"information interfaces and presentation;contingency table analysis;large categorical data;visual analytics","Keywords_Processed":"contingency table analysis;visual analytic;information interface and presentation;large categorical datum","Title":"Reinventing the Contingency Wheel: Scalable Visual Analytics of Large Categorical Data"},"22":{"Abstract":"How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.","Authors":"Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu","Clusters":"AnalysisProcessGeneral;DiffusionRelatedTechniques;InformationProcessingAndHandling;SocialNetworksAndSocialMedia;TextDocumentTopicAnalysisDataAndTechniques","DOI":"10.1109\/TVCG.2013.221","Keywords":"information propagation;agenda-setting;topic competition;social media visualization;information diffusion","Keywords_Processed":"information diffusion;social medium visualization;information propagation;agenda setting;topic competition","Title":"Visual Analysis of Topic Competition on Social Media"},"23":{"Abstract":"The study of complex activities such as scientific production and software development often require modeling connections among heterogeneous entities including people, institutions and artifacts. Despite numerous advances in algorithms and visualization techniques for understanding such social networks, the process of constructing network models and performing exploratory analysis remains difficult and time-consuming. In this paper we present Orion, a system for interactive modeling, transformation and visualization of network data. Orion's interface enables the rapid manipulation of large graphs-including the specification of complex linking relationships-using simple drag-and-drop operations with desired node types. Orion maps these user interactions to statements in a declarative workflow language that incorporates both relational operators (e.g., selection, aggregation and joins) and network analytics (e.g., centrality measures). We demonstrate how these features enable analysts to flexibly construct and compare networks in domains such as online health communities, academic collaboration and distributed software development.","Authors":"Heer, J.;Perer, A.","Clusters":"DataAcquisitionAndManagement;DataTransformation;GraphNetworkDataAndTechniques;ProgrammingAlgorithmsAndDataStructures;SocialNetworksAndSocialMedia;","DOI":"10.1109\/VAST.2011.6102441","Keywords":"visualization;social network analysis;graph;data management;data transformation;end-user programming","Keywords_Processed":"visualization;end user programming;datum transformation;graph;social network analysis;data management","Title":"Orion: A system for modeling, transformation and visualization of multidimensional heterogeneous networks"},"24":{"Abstract":"This paper introduces a new feature analysis and visualization method for multifield datasets. Our approach applies a surface-centric model to characterize salient features and form an effective, schematic representation of the data. We propose a simple, geometrically motivated, multifield feature definition. This definition relies on an iterative algorithm that applies existing theory of skeleton derivation to fuse the structures from the constitutive fields into a coherent data description, while addressing noise and spurious details. This paper also presents a new method for non-rigid surface registration between the surfaces of consecutive time steps. This matching is used in conjunction with clustering to discover the interaction patterns between the different fields and their evolution over time. We document the unified visual analysis achieved by our method in the context of several multifield problems from large-scale time-varying simulations.","Authors":"Barakat, S.S.;Rutten, M.;Tricoche, X.","Clusters":"MultidimensionalMultivariateMultifieldDataAndTechniques;SurfaceRelatedDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques","DOI":"10.1109\/TVCG.2012.269","Keywords":"time-varying;surface structures;multi-field","Keywords_Processed":"surface structure;time vary;multi field","Title":"Surface-Based Structure Analysis and Visualization for Multifield Time-Varying Datasets"},"25":{"Abstract":"An alternative form to multidimensional projections for the visual analysis of data represented in multidimensional spaces is the deployment of similarity trees, such as Neighbor Joining trees. They organize data objects on the visual plane emphasizing their levels of similarity with high capability of detecting and separating groups and subgroups of objects. Besides this similarity-based hierarchical data organization, some of their advantages include the ability to decrease point clutter; high precision; and a consistent view of the data set during focusing, offering a very intuitive way to view the general structure of the data set as well as to drill down to groups and subgroups of interest. Disadvantages of similarity trees based on neighbor joining strategies include their computational cost and the presence of virtual nodes that utilize too much of the visual space. This paper presents a highly improved version of the similarity tree technique. The improvements in the technique are given by two procedures. The first is a strategy that replaces virtual nodes by promoting real leaf nodes to their place, saving large portions of space in the display and maintaining the expressiveness and precision of the technique. The second improvement is an implementation that significantly accelerates the algorithm, impacting its use for larger data sets. We also illustrate the applicability of the technique in visual data mining, showing its advantages to support visual classification of data sets, with special attention to the case of image classification. We demonstrate the capabilities of the tree for analysis and iterative manipulation and employ those capabilities to support evolving to a satisfactory data organization and classification.","Authors":"Paiva, J.G.;Florian, L.;Pedrini, H.;Telles, G.P.;Minghim, R.","Clusters":"DimensionalityReduction;HierarchicalTreeDataAndTechniques;SegmentationAndClassification","DOI":"10.1109\/TVCG.2011.212","Keywords":"image classification;multi-dimensional projection;similarity trees","Keywords_Processed":"multi dimensional projection;image classification;similarity tree","Title":"Improved Similarity Trees and their Application to Visual Data Classification"},"26":{"Abstract":"Geoscientific modeling and simulation helps to improve our understanding of the complex Earth system. During the modeling process, validation of the geoscientific model is an essential step. In validation, it is determined whether the model output shows sufficient agreement with observation data. Measures for this agreement are called goodness of fit. In the geosciences, analyzing the goodness of fit is challenging due to its manifold dependencies: 1) The goodness of fit depends on the model parameterization, whose precise values are not known. 2) The goodness of fit varies in space and time due to the spatio-temporal dimension of geoscientific models. 3) The significance of the goodness of fit is affected by resolution and preciseness of available observational data. 4) The correlation between goodness of fit and underlying modeled and observed values is ambiguous. In this paper, we introduce a visual analysis concept that targets these challenges in the validation of geoscientific models - specifically focusing on applications where observation data is sparse, unevenly distributed in space and time, and imprecise, which hinders a rigorous analytical approach. Our concept, developed in close cooperation with Earth system modelers, addresses the four challenges by four tailored visualization components. The tight linking of these components supports a twofold interactive drill-down in model parameter space and in the set of data samples, which facilitates the exploration of the numerous dependencies of the goodness of fit. We exemplify our visualization concept for geoscientific modeling of glacial isostatic adjustments in the last 100,000 years, validated against sea levels indicators - a prominent example for sparse and imprecise observation data. An initial use case and feedback from Earth system modelers indicate that our visualization concept is a valuable complement to the range of validation methods.","Authors":"Unger, A.;Schulte, S.;Klemann, V.;Dransch, D.","Clusters":"EarthSpaceAndEnvironmentalSciences;MachineLearningAndStatistics;MultipleLinkedCoordinatedViews;SpatiotemporalDataAndTechniques","DOI":"10.1109\/TVCG.2012.190","Keywords":"spatio-temporal visualization;earth science visualization;model validation;sea level indicators;coordinated & multiple views","Keywords_Processed":"spatio temporal visualization;earth science visualization;model validation;sea level indicator;coordinate multiple view","Title":"A Visual Analysis Concept for the Validation of Geoscientific Simulation Models"},"27":{"Abstract":"Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop's main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.","Authors":"Lins, L.;Klosowski, J.T.;Scheidegger, C.E.","Clusters":"DataTypesGeneral;InteractionTechniquesGeneral;ProgrammingAlgorithmsAndDataStructures","DOI":"10.1109\/TVCG.2013.179","Keywords":"data cube;interactive exploration;data structures","Keywords_Processed":"interactive exploration;data cube;data structure","Title":"Nanocubes for Real-Time Exploration of Spatiotemporal Datasets"},"28":{"Abstract":"Geographically-grounded situational awareness (SA) is critical to crisis management and is essential in many other decision making domains that range from infectious disease monitoring, through regional planning, to political campaigning. Social media are becoming an important information input to support situational assessment (to produce awareness) in all domains. Here, we present a geovisual analytics approach to supporting SA for crisis events using one source of social media, Twitter. Specifically, we focus on leveraging explicit and implicit geographic information for tweets, on developing place-time-theme indexing schemes that support overview+detail methods and that scale analytical capabilities to relatively large tweet volumes, and on providing visual interface methods to enable understanding of place, time, and theme components of evolving situations. Our approach is user-centered, using scenario-based design methods that include formal scenarios to guide design and validate implementation as well as a systematic claims analysis to justify design choices and provide a framework for future testing. The work is informed by a structured survey of practitioners and the end product of Phase-I development is demonstrated \/ validated through implementation in SensePlace2, a map-based, web application initially focused on tweets but extensible to other media.","Authors":"MacEachren, A.M.;Jaiswal, A.;Robinson, A.;Pezanowski, S.;Savelyev, A.;Mitra, P.;Zhang, X.;Blanford, J.","Clusters":"Cognition;DesignMethodologiesAndInteractionDesign;EmergencyDisasterManagement;GeographyGeospatialVisCartographyTerrainVis;SocialNetworksAndSocialMedia;SpatiotemporalDataAndTechniques;TextDocumentTopicAnalysisDataAndTechniques","DOI":"10.1109\/VAST.2011.6102456","Keywords":"crisis management;text analytics;social media analytics;situation awareness;spatio-temporal analysis;scenario-based design;geovisualization","Keywords_Processed":"scenario base design;spatio temporal analysis;geovisualization;situation awareness;crisis management;text analytic;social medium analytic","Title":"SensePlace2: GeoTwitter analytics support for situational awareness"},"29":{"Abstract":"As the visualization field matures, an increasing number of general toolkits are developed to cover a broad range of applications. However, no general tool can incorporate the latest capabilities for all possible applications, nor can the user interfaces and workflows be easily adjusted to accommodate all user communities. As a result, users will often chose either substandard solutions presented in familiar, customized tools or assemble a patchwork of individual applications glued through ad-hoc scripts and extensive, manual intervention. Instead, we need the ability to easily and rapidly assemble the best-in-task tools into custom interfaces and workflows to optimally serve any given application community. Unfortunately, creating such meta-applications at the API or SDK level is difficult, time consuming, and often infeasible due to the sheer variety of data models, design philosophies, limits in functionality, and the use of closed commercial systems. In this paper, we present the ManyVis framework which enables custom solutions to be built both rapidly and simply by allowing coordination and communication across existing unrelated applications. ManyVis allows users to combine software tools with complementary characteristics into one virtual application driven by a single, custom-designed interface.","Authors":"Rungta, A.;Summa, B.;Demir, D.;Bremer, P.-T.;Pascucci, V.","Clusters":"ApplicationsGeneralAndOther;MultipleLinkedCoordinatedViews;ProgrammingAlgorithmsAndDataStructures;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2013.174","Keywords":"integrated applications;linked views;visualization environment;macros","Keywords_Processed":"macro;link view;integrate application;visualization environment","Title":"ManyVis: Multiple Applications in an Integrated Visualization Environment"},"30":{"Abstract":"Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.","Authors":"Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.;Griffiths, I.W.;Chen, M.","Clusters":"DataClusteringAndAggregation;KnowledgeDiscovery;MachineLearningAndStatistics;MultimediaImageVideoMusic","DOI":"10.1109\/TVCG.2013.207","Keywords":"multimedia visualization;visual knowledge discovery;data clustering;machine learning","Keywords_Processed":"machine learning;multimedia visualization;visual knowledge discovery;datum clustering","Title":"Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop"},"31":{"Abstract":"Traditional layered graph depictions such as flow charts are in wide use. Yet as graphs grow more complex, these depictions can become difficult to understand. Quilts are matrix-based depictions for layered graphs designed to address this problem. In this research, we first improve Quilts by developing three design alternatives, and then compare the best of these alternatives to better-known node-link and matrix depictions. A primary weakness in Quilts is their depiction of skip links, links that do not simply connect to a succeeding layer. Therefore in our first study, we compare Quilts using color-only, text-only, and mixed (color and text) skip link depictions, finding that path finding with the color-only depiction is significantly slower and less accurate, and that in certain cases, the mixed depiction offers an advantage over the text-only depiction. In our second study, we compare Quilts using the mixed depiction to node-link diagrams and centered matrices. Overall results show that users can find paths through graphs significantly faster with Quilts (46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams. This speed advantage is still greater in large graphs (e.g. in 200 node graphs, 55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).","Authors":"Juhee Bae;Watson, B.","Clusters":"GraphNetworkDataAndTechniques;MatrixRelatedTechniques","DOI":"10.1109\/TVCG.2011.187","Keywords":"matrix-based depiction;graph drawing;layered graphs;node-link diagram","Keywords_Processed":"graph drawing;matrix base depiction;layer graph;node link diagram","Title":"Developing and Evaluating Quilts for the Depiction of Large Layered Graphs"},"32":{"Abstract":"Room air flow and air exchange are important aspects for the design of energy-efficient buildings. As a result, simulations are increasingly used prior to construction to achieve an energy-efficient design. We present a visual analysis of air flow generated at building entrances, which uses a combination of revolving doors and air curtains. The resulting flow pattern is challenging because of two interacting flow patterns: On the one hand, the revolving door acts as a pump, on the other hand, the air curtain creates a layer of uniformly moving warm air between the interior of the building and the revolving door. Lagrangian coherent structures (LCS), which by definition are flow barriers, are the method of choice for visualizing the separation and recirculation behavior of warm and cold air flow. The extraction of LCS is based on the finite-time Lyapunov exponent (FTLE) and makes use of a ridge definition which is consistent with the concept of weak LCS. Both FTLE computation and ridge extraction are done in a robust and efficient way by making use of the fast Fourier transform for computing scale-space derivatives.","Authors":"Schindler, B.;Fuchs, R.;Barp, S.;Waser, J.;Pobitzer, A.;Carnecky, R.;Matkovic, K.;Peikert, R.","Clusters":"PhysicsAndPhysicalSciences;TopologyBasedTechniques;VectorFieldsDataAndTechniques","DOI":"10.1109\/TVCG.2012.243","Keywords":"visualization in physical sciences and engineering;topology-based techniques;vector field data","Keywords_Processed":"topology base technique;visualization in physical science and engineering;vector field datum","Title":"Lagrangian Coherent Structures for Design Analysis of Revolving Doors"},"33":{"Abstract":"Analyzing either high-frequency shape detail or any other 2D fields (scalar or vector) embedded over a 3D geometry is a complex task, since detaching the detail from the overall shape can be tricky. An alternative approach is to move to the 2D space, resolving shape reasoning to easier image processing techniques. In this paper we propose a novel framework for the analysis of 2D information distributed over 3D geometry, based on a locally smooth parametrization technique that allows us to treat local 3D data in terms of image content. The proposed approach has been implemented as a sketch-based system that allows to design with a few gestures a set of (possibly overlapping) parameterizations of rectangular portions of the surface. We demonstrate that, due to the locality of the parametrization, the distortion is under an acceptable threshold, while discontinuities can be avoided since the parametrized geometry is always homeomorphic to a disk. We show the effectiveness of the proposed technique to solve specific Cultural Heritage (CH) tasks: the analysis of chisel marks over the surface of a unfinished sculpture and the local comparison of multiple photographs mapped over the surface of an artwork. For this very difficult task, we believe that our framework and the corresponding tool are the first steps toward a computer-based shape reasoning system, able to support CH scholars with a medium they are more used to.","Authors":"Pietroni, N.;Massimiliano, C.;Cignoni, P.;Scopigno, R.","Clusters":"ImageBasedDataImageSignalProcessing;InteractionTechniquesGeneral;Parameterization;SocialScienceAndHumanities;SurfaceRelatedDataAndTechniques","DOI":"10.1109\/TVCG.2011.165","Keywords":"interactive inspection;surface characterization;image processing;cultural heritage;mesh parameterization","Keywords_Processed":"image processing;cultural heritage;surface characterization;mesh parameterization;interactive inspection","Title":"An Interactive Local Flattening Operator to Support Digital Investigations on Artwork Surfaces"},"34":{"Abstract":"This paper presents a visualization approach for detecting and exploring similarity in the temporal variation of field data. We provide an interactive technique for extracting correlations from similarity matrices which capture temporal similarity of univariate functions. We make use of the concept to extract periodic and quasiperiodic behavior at single (spatial) points as well as similarity between different locations within a field and also between different data sets. The obtained correlations are utilized for visual exploration of both temporal and spatial relationships in terms of temporal similarity. Our entire pipeline offers visual interaction and inspection, allowing for the flexibility that in particular time-dependent data analysis techniques require. We demonstrate the utility and versatility of our approach by applying our implementation to data from both simulation and measurement.","Authors":"Frey, S.;Sadlo, F.;Ertl, T.","Clusters":"ComparisonComparativeVisualizationAndSimilarity;TimeseriesTimeVaryingDataAndTechniques","DOI":"10.1109\/TVCG.2012.284","Keywords":"comparative visualization;time-dependent fields;similarity analysis;interactive recurrence analysis","Keywords_Processed":"time dependent field;similarity analysis;comparative visualization;interactive recurrence analysis","Title":"Visualization of Temporal Similarity in field Data"},"35":{"Abstract":"Color mapping and semitransparent layering play an important role in many visualization scenarios, such as information visualization and volume rendering. The combination of color and transparency is still dominated by standard alpha-compositing using the Porter-Duff over operator which can result in false colors with deceiving impact on the visualization. Other more advanced methods have also been proposed, but the problem is still far from being solved. Here we present an alternative to these existing methods specifically devised to avoid false colors and preserve visual depth ordering. Our approach is data driven and follows the recently formulated knowledge-assisted visualization (KAV) paradigm. Preference data, that have been gathered in web-based user surveys, are used to train a support-vector machine model for automatically predicting an optimized hue-preserving blending. We have applied the resulting model to both volume rendering and a specific information visualization technique, illustrative parallel coordinate plots. Comparative renderings show a significant improvement over previous approaches in the sense that false colors are completely removed and important properties such as depth ordering and blending vividness are better preserved. Due to the generality of the defined data-driven blending operator, it can be easily integrated also into other visualization frameworks.","Authors":"Kuhne, L.;Giesen, J.;Zhiyuan Zhang;Sungsoo Ha;Mueller, K.","Clusters":"ColorColorPerception;ParallelCoordinates;VisualizationTechniquesAndToolsGeneral;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2012.186","Keywords":"knowledge-assisted visualization;volume rendering;color blending;hue preservation;parallel coordinates","Keywords_Processed":"volume render;parallel coordinate;knowledge assist visualization;color blending;hue preservation","Title":"A Data-Driven Approach to Hue-Preserving Color-Blending"},"36":{"Abstract":"Presenting and communicating insights to an audience-telling a story-is one of the main goals of data exploration. Even though visualization as a storytelling medium has recently begun to gain attention, storytelling is still underexplored in information visualization and little research has been done to help people tell their stories with data. To create a new, more engaging form of storytelling with data, we leverage and extend the narrative storytelling attributes of whiteboard animation with pen and touch interactions. We present SketchStory, a data-enabled digital whiteboard that facilitates the creation of personalized and expressive data charts quickly and easily. SketchStory recognizes a small set of sketch gestures for chart invocation, and automatically completes charts by synthesizing the visuals from the presenter-provided example icon and binding them to the underlying data. Furthermore, SketchStory allows the presenter to move and resize the completed data charts with touch, and filter the underlying data to facilitate interactive exploration. We conducted a controlled experiment for both audiences and presenters to compare SketchStory with a traditional presentation system, Microsoft PowerPoint. Results show that the audience is more engaged by presentations done with SketchStory than PowerPoint. Eighteen out of 24 audience participants preferred SketchStory to PowerPoint. Four out of five presenter participants also favored SketchStory despite the extra effort required for presentation.","Authors":"Bongshin Lee;Kazi, R.H.;Smith, G.","Clusters":"InteractionTechniquesGeneral;Storytelling;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2013.191","Keywords":"data presentation;sketch;visualization;pen and touch;storytelling;interaction","Keywords_Processed":"visualization;interaction;pen and touch;storytelle;sketch;datum presentation","Title":"SketchStory: Telling More Engaging Stories with Data through Freeform Sketching"},"37":{"Abstract":"We introduce the concept of just-in-time descriptive analytics as a novel application of computational and statistical techniques performed at interaction-time to help users easily understand the structure of data as seen in visualizations. Fundamental to just-intime descriptive analytics is (a) identifying visual features, such as clusters, outliers, and trends, user might observe in visualizations automatically, (b) determining the semantics of such features by performing statistical analysis as the user is interacting, and (c) enriching visualizations with annotations that not only describe semantics of visual features but also facilitate interaction to support high-level understanding of data. In this paper, we demonstrate just-in-time descriptive analytics applied to a point-based multi-dimensional visualization technique to identify and describe clusters, outliers, and trends. We argue that it provides a novel user experience of computational techniques working alongside of users allowing them to build faster qualitative mental models of data by demonstrating its application on a few use-cases. Techniques used to facilitate just-in-time descriptive analytics are described in detail along with their runtime performance characteristics. We believe this is just a starting point and much remains to be researched, as we discuss open issues and opportunities in improving accessibility and collaboration.","Authors":"Kandogan, E.","Clusters":"AlgorithmicPatternFeatureDetectionTracking;AnalysisProcessGeneral;PointBasedDataAndTechniques","DOI":"10.1109\/VAST.2012.6400487","Keywords":"feature identification and characterization;point-based visualization;just-in-time descriptive analytics","Keywords_Processed":"feature identification and characterization;just in time descriptive analytic;point base visualization","Title":"Just-in-time annotation of clusters, outliers, and trends in point-based data visualizations"}}