{"168":{"Abstract":"In a variety of application areas, the use of simulation steering in decision making is limited at best. Research focusing on this problem suggests that most user interfaces are too complex for the end user. Our goal is to let users create and investigate multiple, alternative scenarios without the need for special simulation expertise. To simplify the specification of parameters, we move from a traditional manipulation of numbers to a sketch-based input approach. Users steer both numeric parameters and parameters with a spatial correspondence by sketching a change onto the rendering. Special visualizations provide immediate visual feedback on how the sketches are transformed into boundary conditions of the simulation models. Since uncertainty with respect to many intertwined parameters plays an important role in planning, we also allow the user to intuitively setup complete value ranges, which are then automatically transformed into ensemble simulations. The interface and the underlying system were developed in collaboration with experts in the field of flood management. The real-world data they have provided has allowed us to construct scenarios used to evaluate the system. These were presented to a variety of flood response personnel, and their feedback is discussed in detail in the paper. The interface was found to be intuitive and relevant, although a certain amount of training might be necessary.","Authors":"Ribicic, H.;Waser, J.;Gurbat, R.;Sadransky, B.;Groller, E.","Clusters":"DesignMethodologiesAndInteractionDesign;EmergencyDisasterManagement;InteractionTechniquesGeneral;Simulation;UncertaintyTechniquesAndVisualization;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2012.261","Keywords":"uncertainty visualization;interaction design;sketch-based steering;flood management;emergency\/disaster management;integrated visualization system;ensemble simulation steering","Keywords_Processed":"ensemble simulation steering;emergency disaster management;flood management;integrate visualization system;sketch base steering;interaction design;uncertainty visualization","Title":"Sketching Uncertainty into Simulations"},"137":{"Abstract":"While intuitive time-series visualizations exist for common datasets, student course history data is difficult to represent using traditional visualization techniques due its concurrent nature. A visual composition process is developed and applied to reveal trends across various groupings. By working closely with educators, analytic strategies and techniques are developed to leverage the visualization composition to reveal unknown trends in the data. Furthermore, clustering algorithms are developed to group common course-grade histories for further analysis. Lastly, variations of the composition process are implemented to reveal subtle differences in the underlying data. These analytic tools and techniques enabled educators to confirm expected trends and to discover new ones.","Authors":"Trimm, D.;Rheingans, P.;desJardins, M.","Clusters":"DataClusteringAndAggregation;EvaluationGeneral;VisualDesignDesignGuidelines","DOI":"10.1109\/TVCG.2012.288","Keywords":"student performance analysis;clustering;visualization composition;aggregate visualization","Keywords_Processed":"clustering;aggregate visualization;visualization composition;student performance analysis","Title":"Visualizing Student Histories Using Clustering and Composition"},"61":{"Abstract":"This article presents SoccerStories, a visualization interface to support analysts in exploring soccer data and communicating interesting insights. Currently, most analyses on such data relate to statistics on individual players or teams. However, soccer analysts we collaborated with consider that quantitative analysis alone does not convey the right picture of the game, as context, player positions and phases of player actions are the most relevant aspects. We designed SoccerStories to support the current practice of soccer analysts and to enrich it, both in the analysis and communication stages. Our system provides an overview+detail interface of game phases, and their aggregation into a series of connected visualizations, each visualization being tailored for actions such as a series of passes or a goal attempt. To evaluate our tool, we ran two qualitative user studies on recent games using SoccerStories with data from one of the world's leading live sports data providers. The first study resulted in a series of four articles on soccer tactics, by a tactics analyst, who said he would not have been able to write these otherwise. The second study consisted in an exploratory follow-up to investigate design alternatives for embedding soccer phases into word-sized graphics. For both experiments, we received a very enthusiastic feedback and participants consider further use of SoccerStories to enhance their current workflow.","Authors":"Perin, C.;Vuillemot, R.;Fekete, J.","Clusters":"DataClusteringAndAggregation;KnowledgeDiscovery;SportsVisualization;VisualKnowledgeRepresentationAndExternalization","DOI":"10.1109\/TVCG.2013.192","Keywords":"visual knowledge representation;visual aggregation;sport analytics;visual knowledge discovery","Keywords_Processed":"visual aggregation;visual knowledge discovery;sport analytic;visual knowledge representation","Title":"SoccerStories: A Kick-off for Visual Soccer Analysis"},"367":{"Abstract":"In virtual colonoscopy, CT scans are typically acquired with the patient in both supine (facing up) and prone (facing down) positions. The registration of these two scans is desirable so that the user can clarify situations or confirm polyp findings at a location in one scan with the same location in the other, thereby improving polyp detection rates and reducing false positives. However, this supine-prone registration is challenging because of the substantial distortions in the colon shape due to the patient's change in position. We present an efficient algorithm and framework for performing this registration through the use of conformal geometry to guarantee that the registration is a diffeomorphism (a one-to-one and onto mapping). The taeniae coli and colon flexures are automatically extracted for each supine and prone surface, employing the colon geometry. The two colon surfaces are then divided into several segments using the flexures, and each segment is cut along a taenia coli and conformally flattened to the rectangular domain using holomorphic differentials. The mean curvature is color encoded as texture images, from which feature points are automatically detected using graph cut segmentation, mathematic morphological operations, and principal component analysis. Corresponding feature points are found between supine and prone and are used to adjust the conformal flattening to be quasi-conformal, such that the features become aligned. We present multiple methods of visualizing our results, including 2D flattened rendering, corresponding 3D endoluminal views, and rendering of distortion measurements. We demonstrate the efficiency and efficacy of our registration method by illustrating matched views on both the 2D flattened colon images and in the 3D volume rendered colon endoluminal view. We analytically evaluate the correctness of the results by measuring the distance between features on the registered colons.","Authors":"Wei Zeng;Marino, J.;Chaitanya Gurijala, K.;Xianfeng Gu;Kaufman, A.","Clusters":"BiomedicalScienceAndMedicine;DataRegistrationFusionAndIntegration;GeometryBasedTechniques;NumericalMethodsMathematics","DOI":"10.1109\/TVCG.2010.200","Keywords":"data registration;medical visualization;geometry-based technique;mathematical foundations for visualization","Keywords_Processed":"geometry base technique;mathematical foundation for visualization;medical visualization;datum registration","Title":"Supine and Prone Colon Registration Using Quasi-Conformal Mapping"},"340":{"Abstract":"We extend direct volume rendering with a unified model for generalized isosurfaces, also called interval volumes, allowing a wider spectrum of visual classification. We generalize the concept of scale-invariant opacity-typical for isosurface rendering-to semi-transparent interval volumes. Scale-invariant rendering is independent of physical space dimensions and therefore directly facilitates the analysis of data characteristics. Our model represents sharp isosurfaces as limits of interval volumes and combines them with features of direct volume rendering. Our objective is accurate rendering, guaranteeing that all isosurfaces and interval volumes are visualized in a crack-free way with correct spatial ordering. We achieve simultaneous direct and interval volume rendering by extending preintegration and explicit peak finding with data-driven splitting of ray integration and hybrid computation in physical and data domains. Our algorithm is suitable for efficient parallel processing for interactive applications as demonstrated by our CUDA implementation.","Authors":"Ament, M.;Weiskopf, D.;Carr, H.","Clusters":"ColorColorPerception;DataRegistrationFusionAndIntegration;IsosurfaceAndSurfaceExtractionTechniques;RaytracingRaycasting;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2010.145","Keywords":"direct volume rendering;preintegration;raycasting;isosurface;interval volume;scale-invariant opacity","Keywords_Processed":"preintegration;direct volume render;scale invariant opacity;isosurface;raycaste;interval volume","Title":"Direct Interval Volume Visualization"},"217":{"Abstract":"Multivariate data visualization is a classic topic, for which many solutions have been proposed, each with its own strengths and weaknesses. In standard solutions the structure of the visualization is fixed, we explore how to give the user more freedom to define visualizations. Our new approach is based on the usage of Flexible Linked Axes: The user is enabled to define a visualization by drawing and linking axes on a canvas. Each axis has an associated attribute and range, which can be adapted. Links between pairs of axes are used to show data in either scatter plot- or Parallel Coordinates Plot-style. Flexible Linked Axes enable users to define a wide variety of different visualizations. These include standard methods, such as scatter plot matrices, radar charts, and PCPs [11]; less well known approaches, such as Hyperboxes [1], TimeWheels [17], and many-to-many relational parallel coordinate displays [14]; and also custom visualizations, consisting of combinations of scatter plots and PCPs. Furthermore, our method allows users to define composite visualizations that automatically support brushing and linking. We have discussed our approach with ten prospective users, who found the concept easy to understand and highly promising.","Authors":"Claessen, J.H.T.;van Wijk, J.J.","Clusters":"ChartsDiagramsPlots;MultidimensionalMultivariateMultifieldDataAndTechniques;ParallelCoordinates;","DOI":"10.1109\/TVCG.2011.201","Keywords":"multivariate data;visualization;scatterplot;parallel coordinates plot","Keywords_Processed":"multivariate datum;scatterplot;parallel coordinate plot;visualization","Title":"Flexible Linked Axes for Multivariate Data Visualization"},"246":{"Abstract":"In this paper we present a framework to define transfer functions from a target distribution provided by the user. A target distribution can reflect the data importance, or highly relevant data value interval, or spatial segmentation. Our approach is based on a communication channel between a set of viewpoints and a set of bins of a volume data set, and it supports 1D as well as 2D transfer functions including the gradient information. The transfer functions are obtained by minimizing the informational divergence or Kullback-Leibler distance between the visibility distribution captured by the viewpoints and a target distribution selected by the user. The use of the derivative of the informational divergence allows for a fast optimization process. Different target distributions for 1D and 2D transfer functions are analyzed together with importance-driven and view-based techniques.","Authors":"Ruiz, M.;Bardera, A.;Boada, I.;Viola, I.;Feixas, M.;Sbert, M.","Clusters":"InformationTheory;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2011.173","Keywords":"information theory;transfer function;informational divergence;kullback-leibler distance","Keywords_Processed":"kullback leibler distance;transfer function;informational divergence;information theory","Title":"Automatic Transfer Functions Based on Informational Divergence"},"353":{"Abstract":"We introduce a flexible technique for interactive exploration of vector field data through classification derived from user-specified feature templates. Our method is founded on the observation that, while similar features within the vector field may be spatially disparate, they share similar neighborhood characteristics. Users generate feature-based visualizations by interactively highlighting well-accepted and domain specific representative feature points. Feature exploration begins with the computation of attributes that describe the neighborhood of each sample within the input vector field. Compilation of these attributes forms a representation of the vector field samples in the attribute space. We project the attribute points onto the canonical 2D plane to enable interactive exploration of the vector field using a painting interface. The projection encodes the similarities between vector field points within the distances computed between their associated attribute points. The proposed method is performed at interactive rates for enhanced user experience and is completely flexible as showcased by the simultaneous identification of diverse feature types.","Authors":"Daniels II, J.;Anderson, E.W.;Nonato, L.G.;Silva, C.T.","Clusters":"AlgorithmicPatternFeatureDetectionTracking;DataClusteringAndAggregation;InteractionTechniquesGeneral;MultidimensionalMultivariateMultifieldDataAndTechniques;VectorFieldsDataAndTechniques","DOI":"10.1109\/TVCG.2010.170","Keywords":"user interaction;high-dimensional data;vector field;feature classification;data clustering","Keywords_Processed":"user interaction;vector field;feature classification;high dimensional datum;datum clustering","Title":"Interactive Vector field Feature Identification"},"99":{"Abstract":"In written and spoken communications, figures of speech (e.g., metaphors and synecdoche) are often used as an aid to help convey abstract or less tangible concepts. However, the benefits of using rhetorical illustrations or embellishments in visualization have so far been inconclusive. In this work, we report an empirical study to evaluate hypotheses that visual embellishments may aid memorization, visual search and concept comprehension. One major departure from related experiments in the literature is that we make use of a dual-task methodology in our experiment. This design offers an abstraction of typical situations where viewers do not have their full attention focused on visualization (e.g., in meetings and lectures). The secondary task introduces \u00e2\u20ac\u0153divided attention\u00e2\u20ac\u009d, and makes the effects of visual embellishments more observable. In addition, it also serves as additional masking in memory-based trials. The results of this study show that visual embellishments can help participants better remember the information depicted in visualization. On the other hand, visual embellishments can have a negative impact on the speed of visual search. The results show a complex pattern as to the benefits of visual embellishments in helping participants grasp key concepts from visualization.","Authors":"Borgo, R.;Abdul-Rahman, A.;Mohamed, F.;Grant, P.W.;Reppa, I.;Floridi, L.;Chen, M.","Clusters":"Cognition;EvaluationGeneral;GlyphsGlyphBasedTechniques;QueriesAndSearch;VisualDesignDesignGuidelines;VisualizationTheoryModelsAndMethods","DOI":"10.1109\/TVCG.2012.197","Keywords":"evaluation;icons;cognition;working memory;visual embellishments;visual search;long-term memory;metaphors","Keywords_Processed":"long term memory;icon;visual search;work memory;cognition;metaphor;visual embellishment;evaluation","Title":"An Empirical Study on Using Visual Embellishments in Visualization"},"318":{"Abstract":"Statistical data associated with geographic regions is nowadays globally available in large amounts and hence automated methods to visually display these data are in high demand. There are several well-established thematic map types for quantitative data on the ratio-scale associated with regions: choropleth maps, cartograms, and proportional symbol maps. However, all these maps suffer from limitations, especially if large data values are associated with small regions. To overcome these limitations, we propose a novel type of quantitative thematic map, the necklace map. In a necklace map, the regions of the underlying two-dimensional map are projected onto intervals on a one-dimensional curve (the necklace) that surrounds the map regions. Symbols are scaled such that their area corresponds to the data of their region and placed without overlap inside the corresponding interval on the necklace. Necklace maps appear clear and uncluttered and allow for comparatively large symbol sizes. They visualize data sets well which are not proportional to region sizes. The linear ordering of the symbols along the necklace facilitates an easy comparison of symbol sizes. One map can contain several nested or disjoint necklaces to visualize clustered data. The advantages of necklace maps come at a price: the association between a symbol and its region is weaker than with other types of maps. Interactivity can help to strengthen this association if necessary. We present an automated approach to generate necklace maps which allows the user to interactively control the final symbol placement. We validate our approach with experiments using various data sets and maps.","Authors":"Speckmann, B.;Verbeek, K.","Clusters":"GeographyGeospatialVisCartographyTerrainVis;Maps;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2010.180","Keywords":"necklace maps;automated cartography;geographic visualization;proportional symbol maps","Keywords_Processed":"geographic visualization;necklace map;automate cartography;proportional symbol map","Title":"Necklace Maps"},"37":{"Abstract":"We present the design of a novel framework for the visual integration, comparison, and exploration of correlations in spatial and non-spatial geriatric research data. These data are in general high-dimensional and span both the spatial, volumetric domain - through magnetic resonance imaging volumes - and the non-spatial domain, through variables such as age, gender, or walking speed. The visual analysis framework blends medical imaging, mathematical analysis and interactive visualization techniques, and includes the adaptation of Sparse Partial Least Squares and iterated Tikhonov Regularization algorithms to quantify potential neurologymobility connections. A linked-view design geared specifically at interactive visual comparison integrates spatial and abstract visual representations to enable the users to effectively generate and refine hypotheses in a large, multidimensional, and fragmented space. In addition to the domain analysis and design description, we demonstrate the usefulness of this approach on two case studies. Last, we report the lessons learned through the iterative design and evaluation of our approach, in particular those relevant to the design of comparative visualization of spatial and non-spatial data.","Authors":"Maries, A.;Mays, N.;Hunt, M.O.;Wong, K.F.;Layton, W.;Boudreau, R.;Rosano, C.;Marai, G.E.","Clusters":"ApplicationsGeneralAndOther;ComparisonComparativeVisualizationAndSimilarity;DesignMethodologiesAndInteractionDesign;DesignStudiesAndCaseStudies;IntegratingSpatialAndNonSpatialDataVisualization;MultidimensionalMultivariateMultifieldDataAndTechniques;TasksTaskRequirementsAnalysis","DOI":"10.1109\/TVCG.2013.161","Keywords":"design study;high-dimensional data;applications of visualization;methodology design;task and requirements analysis;visual comparison;integrating spatial and non-spatial visualization","Keywords_Processed":"task and requirement analysis;design study;methodology design;high dimensional datum;application of visualization;integrate spatial and non spatial visualization;visual comparison","Title":"GRACE: A Visual Comparison Framework for Integrated Spatial and Non-Spatial Geriatric Data"},"13":{"Abstract":"We present a novel area-preservation mapping\/flattening method using the optimal mass transport technique, based on the Monge-Brenier theory. Our optimal transport map approach is rigorous and solid in theory, efficient and parallel in computation, yet general for various applications. By comparison with the conventional Monge-Kantorovich approach, our method reduces the number of variables from O(n2) to O(n), and converts the optimal mass transport problem to a convex optimization problem, which can now be efficiently carried out by Newton's method. Furthermore, our framework includes the area weighting strategy that enables users to completely control and adjust the size of areas everywhere in an accurate and quantitative way. Our method significantly reduces the complexity of the problem, and improves the efficiency, flexibility and scalability during visualization. Our framework, by combining conformal mapping and optimal mass transport mapping, serves as a powerful tool for a broad range of applications in visualization and graphics, especially for medical imaging. We provide a variety of experimental results to demonstrate the efficiency, robustness and efficacy of our novel framework.","Authors":"Xin Zhao;Zhengyu Su;Gu, X.;Kaufman, A.;Jian Sun;Jie Gao;Feng Luo","Clusters":"ApplicationsGeneralAndOther;GeometricModeling;Maps;SurfaceRelatedDataAndTechniques","DOI":"10.1109\/TVCG.2013.135","Keywords":"monge-brenier theory;surface flattening;area-preservation mapping;visualization and graphics applications;optimal transport map","Keywords_Processed":"optimal transport map;surface flattening;monge brenier theory;visualization and graphic application;area preservation mapping","Title":"Area-Preservation Mapping using Optimal Mass Transport"},"44":{"Abstract":"With the evolution of graphics hardware, high quality global illumination becomes available for real-time volume rendering. Compared to local illumination, global illumination can produce realistic shading effects which are closer to real world scenes, and has proven useful for enhancing volume data visualization to enable better depth and shape perception. However, setting up optimal lighting could be a nontrivial task for average users. There were lighting design works for volume visualization but they did not consider global light transportation. In this paper, we present a lighting design method for volume visualization employing global illumination. The resulting system takes into account view and transfer-function dependent content of the volume data to automatically generate an optimized three-point lighting environment. Our method fully exploits the back light which is not used by previous volume visualization systems. By also including global shadow and multiple scattering, our lighting system can effectively enhance the depth and shape perception of volumetric features of interest. In addition, we propose an automatic tone mapping operator which recovers visual details from overexposed areas while maintaining sufficient contrast in the dark areas. We show that our method is effective for visualizing volume datasets with complex structures. The structural information is more clearly and correctly presented under the automatically generated light sources.","Authors":"Yubo Zhang;Kwan-Liu Ma","Clusters":"ColorColorPerception;Illumination;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2013.172","Keywords":"lighting design;volume rendering;global illumination;tone mapping","Keywords_Processed":"tone mapping;volume render;lighting design;global illumination","Title":"Lighting Design for Globally Illuminated Volume Rendering"},"127":{"Abstract":"We present and evaluate a framework for constructing sketchy style information visualizations that mimic data graphics drawn by hand. We provide an alternative renderer for the Processing graphics environment that redefines core drawing primitives including line, polygon and ellipse rendering. These primitives allow higher-level graphical features such as bar charts, line charts, treemaps and node-link diagrams to be drawn in a sketchy style with a specified degree of sketchiness. The framework is designed to be easily integrated into existing visualization implementations with minimal programming modification or design effort. We show examples of use for statistical graphics, conveying spatial imprecision and for enhancing aesthetic and narrative qualities of visualization. We evaluate user perception of sketchiness of areal features through a series of stimulus-response tests in order to assess users' ability to place sketchiness on a ratio scale, and to estimate area. Results suggest relative area judgment is compromised by sketchy rendering and that its influence is dependent on the shape being rendered. They show that degree of sketchiness may be judged on an ordinal scale but that its judgement varies strongly between individuals. We evaluate higher-level impacts of sketchiness through user testing of scenarios that encourage user engagement with data visualization and willingness to critique visualization design. Results suggest that where a visualization is clearly sketchy, engagement may be increased and that attitudes to participating in visualization annotation are more positive. The results of our work have implications for effective information visualization design that go beyond the traditional role of sketching as a tool for prototyping or its use for an indication of general uncertainty.","Authors":"Wood, J.;Isenberg, P.;Isenberg, T.;Dykes, J.;Boukhelifa, N.;Slingsby, A.","Clusters":"ArtAndAestheticsInVisualization;IllustrativeVisualization;InteractionTechniquesGeneral;UncertaintyTechniquesAndVisualization;","DOI":"10.1109\/TVCG.2012.262","Keywords":"non-photorealistic rendering;sketch;hand-drawn;uncertainty;visualization","Keywords_Processed":"visualization;non photorealistic rendering;sketch;uncertainty;hand draw","Title":"Sketchy Rendering for Information Visualization"},"298":{"Abstract":"We have observed increasing interest in visual analytics tools and their applications in investigative analysis. Despite the growing interest and substantial studies regarding the topic, understanding the major roadblocks of using such tools from novice users' perspectives is still limited. Therefore, we attempted to identify such \u00e2\u20ac\u0153visual analytic roadblocks\u00e2\u20ac\u009d for novice users in an investigative analysis scenario. To achieve this goal, we reviewed the existing models, theories, and frameworks that could explain the cognitive processes of human-visualization interaction in investigative analysis. Then, we conducted a qualitative experiment with six novice participants, using a slightly modified version of pair analytics, and analyzed the results through the open-coding method. As a result, we came up with four visual analytic roadblocks and explained these roadblocks using existing cognitive models and theories. We also provided design suggestions to overcome these roadblocks.","Authors":"Bum Chul Kwon;Fisher, B.;Ji Soo Yi","Clusters":"AnalysisProcessGeneral;Cognition;QualitativeEvaluation;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/VAST.2011.6102435","Keywords":"qualitative experiment;visual analytics;investigative analysis;cognitive model;roadblock;framework","Keywords_Processed":"investigative analysis;framework;qualitative experiment;visual analytic;cognitive model;roadblock","Title":"Visual analytic roadblocks for novice investigators"},"220":{"Abstract":"Working with three domain specialists we investigate human-centered approaches to geovisualization following an ISO13407 taxonomy covering context of use, requirements and early stages of design. Our case study, undertaken over three years, draws attention to repeating trends: that generic approaches fail to elicit adequate requirements for geovis application design; that the use of real data is key to understanding needs and possibilities; that trust and knowledge must be built and developed with collaborators. These processes take time but modified human-centred approaches can be effective. A scenario developed through contextual inquiry but supplemented with domain data and graphics is useful to geovis designers. Wireframe, paper and digital prototypes enable successful communication between specialist and geovis domains when incorporating real and interesting data, prompting exploratory behaviour and eliciting previously unconsidered requirements. Paper prototypes are particularly successful at eliciting suggestions, especially for novel visualization. Enabling specialists to explore their data freely with a digital prototype is as effective as using a structured task protocol and is easier to administer. Autoethnography has potential for framing the design process. We conclude that a common understanding of context of use, domain data and visualization possibilities are essential to successful geovis design and develop as this progresses. HC approaches can make a significant contribution here. However, modified approaches, applied with flexibility, are most promising. We advise early, collaborative engagement with data - through simple, transient visual artefacts supported by data sketches and existing designs - before moving to successively more sophisticated data wireframes and data prototypes.","Authors":"Lloyd, D.;Dykes, J.","Clusters":"EvaluationGeneral;FieldStudies;GeographyGeospatialVisCartographyTerrainVis;HumanComputerInteractionHumanFactors;InteractionTechniquesGeneral;TasksTaskRequirementsAnalysis;VisualDesignDesignGuidelines","DOI":"10.1109\/TVCG.2011.209","Keywords":"evaluation;sketch;prototypes;requirements;field study;design;geovisualization;context of use","Keywords_Processed":"prototype;sketch;context of use;geovisualization;requirement;design;field study;evaluation","Title":"Human-Centered Approaches in Geovisualization Design: Investigating Multiple Methods Through a Long-Term Case Study"},"124":{"Abstract":"For many applications involving time series data, people are often interested in the changes of item values over time as well as their ranking changes. For example, people search many words via search engines like Google and Bing every day. Analysts are interested in both the absolute searching number for each word as well as their relative rankings. Both sets of statistics may change over time. For very large time series data with thousands of items, how to visually present ranking changes is an interesting challenge. In this paper, we propose RankExplorer, a novel visualization method based on ThemeRiver to reveal the ranking changes. Our method consists of four major components: 1) a segmentation method which partitions a large set of time series curves into a manageable number of ranking categories; 2) an extended ThemeRiver view with embedded color bars and changing glyphs to show the evolution of aggregation values related to each ranking category over time as well as the content changes in each ranking category; 3) a trend curve to show the degree of ranking changes over time; 4) rich user interactions to support interactive exploration of ranking changes. We have applied our method to some real time series data and the case studies demonstrate that our method can reveal the underlying patterns related to ranking changes which might otherwise be obscured in traditional visualizations.","Authors":"Conglei Shi;Weiwei Cui;Shixia Liu;Panpan Xu;Wei Chen;Huamin Qu","Clusters":"InteractionTechniquesGeneral;Ranking;TimeseriesTimeVaryingDataAndTechniques;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2012.253","Keywords":"time-series data;ranking change;themeriver;interaction","Keywords_Processed":"interaction;rank change;time series datum;themeriver","Title":"RankExplorer: Visualization of Ranking Changes in Large Time Series Data"},"131":{"Abstract":"Glyph-based visualization can offer elegant and concise presentation of multivariate information while enhancing speed and ease in visual search experienced by users. As with icon designs, glyphs are usually created based on the designers' experience and intuition, often in a spontaneous manner. Such a process does not scale well with the requirements of applications where a large number of concepts are to be encoded using glyphs. To alleviate such limitations, we propose a new systematic process for glyph design by exploring the parallel between the hierarchy of concept categorization and the ordering of discriminative capacity of visual channels. We examine the feasibility of this approach in an application where there is a pressing need for an efficient and effective means to visualize workflows of biological experiments. By processing thousands of workflow records in a public archive of biological experiments, we demonstrate that a cost-effective glyph design can be obtained by following a process of formulating a taxonomy with the aid of computation, identifying visual channels hierarchically, and defining application-specific abstraction and metaphors.","Authors":"Maguire, E.;Rocca-Serra, P.;Sansone, S.-A.;Davies, J.;Chen, M.","Clusters":"BiologyAndBioinformatics;DesignMethodologiesAndInteractionDesign;GlyphsGlyphBasedTechniques;Taxonomies","DOI":"10.1109\/TVCG.2012.271","Keywords":"taxonomy;design methodologies;bioinformatics visualization;glyph-based techniques","Keywords_Processed":"glyph base technique;taxonomy;bioinformatic visualization;design methodology","Title":"Taxonomy-Based Glyph Design---with a Case Study on Visualizing Workflows of Biological Experiments"},"138":{"Abstract":"When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, \u00e2\u20ac\u0153Whisper\u00e2\u20ac\u009d, for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunflower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efficient flux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identified even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today's information consumption and dispersion in the wild.","Authors":"Nan Cao;Yu-Ru Lin;Xiaohua Sun;Lazer, D.;Shixia Liu;Huamin Qu","Clusters":"DiffusionRelatedTechniques;SocialNetworksAndSocialMedia;SpatiotemporalDataAndTechniques;","DOI":"10.1109\/TVCG.2012.291","Keywords":"information visualization;contagion;social media;spatio-temporal patterns;microblogging;information diffusion","Keywords_Processed":"information diffusion;information visualization;contagion;spatio temporal pattern;microblogge;social medium","Title":"Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time"},"96":{"Abstract":"All major web mapping services use the web Mercator projection. This is a poor choice for maps of the entire globe or areas of the size of continents or larger countries because the Mercator projection shows medium and higher latitudes with extreme areal distortion and provides an erroneous impression of distances and relative areas. The web Mercator projection is also not able to show the entire globe, as polar latitudes cannot be mapped. When selecting an alternative projection for information visualization, rivaling factors have to be taken into account, such as map scale, the geographic area shown, the map's height-to-width ratio, and the type of cartographic visualization. It is impossible for a single map projection to meet the requirements for all these factors. The proposed composite map projection combines several projections that are recommended in cartographic literature and seamlessly morphs map space as the user changes map scale or the geographic region displayed. The composite projection adapts the map's geometry to scale, to the map's height-to-width ratio, and to the central latitude of the displayed area by replacing projections and adjusting their parameters. The composite projection shows the entire globe including poles; it portrays continents or larger countries with less distortion (optionally without areal distortion); and it can morph to the web Mercator projection for maps showing small regions.","Authors":"Jenny, B.","Clusters":"InternetWebVisualizationForTheMasses;Maps;ProgrammingAlgorithmsAndDataStructures","DOI":"10.1109\/TVCG.2012.192","Keywords":"web mapping;web cartography;web mercator;html5 canvas;multi-scale map;web map projection","Keywords_Processed":"html5 canvas;web mapping;web cartography;web mercator;web map projection;multi scale map","Title":"Adaptive Composite Map Projections"},"27":{"Abstract":"We explore the effectiveness of visualizing dense directed graphs by replacing individual edges with edges connected to 'modules'-or groups of nodes-such that the new edges imply aggregate connectivity. We only consider techniques that offer a lossless compression: that is, where the entire graph can still be read from the compressed version. The techniques considered are: a simple grouping of nodes with identical neighbor sets; Modular Decomposition which permits internal structure in modules and allows them to be nested; and Power Graph Analysis which further allows edges to cross module boundaries. These techniques all have the same goal-to compress the set of edges that need to be rendered to fully convey connectivity-but each successive relaxation of the module definition permits fewer edges to be drawn in the rendered graph. Each successive technique also, we hypothesize, requires a higher degree of mental effort to interpret. We test this hypothetical trade-off with two studies involving human participants. For Power Graph Analysis we propose a novel optimal technique based on constraint programming. This enables us to explore the parameter space for the technique more precisely than could be achieved with a heuristic. Although applicable to many domains, we are motivated by-and discuss in particular-the application to software dependency analysis.","Authors":"Dwyer, T.;Riche, N.H.;Marriott, K.;Mears, C.","Clusters":"GraphNetworkDataAndTechniques","DOI":"10.1109\/TVCG.2013.151","Keywords":"networks;modular decomposition;directed graphs;power graph analysis","Keywords_Processed":"modular decomposition;network;direct graph;power graph analysis","Title":"Edge Compression Techniques for Visualization of Dense Directed Graphs"},"172":{"Abstract":"The U.S. Department of Energy's (DOE) Office of Environmental Management (DOE\/EM) currently supports an effort to understand and predict the fate of nuclear contaminants and their transport in natural and engineered systems. Geologists, hydrologists, physicists and computer scientists are working together to create models of existing nuclear waste sites, to simulate their behavior and to extrapolate it into the future. We use visualization as an integral part in each step of this process. In the first step, visualization is used to verify model setup and to estimate critical parameters. High-performance computing simulations of contaminant transport produces massive amounts of data, which is then analyzed using visualization software specifically designed for parallel processing of large amounts of structured and unstructured data. Finally, simulation results are validated by comparing simulation results to measured current and historical field data. We describe in this article how visual analysis is used as an integral part of the decision-making process in the planning of ongoing and future treatment options for the contaminated nuclear waste sites. Lessons learned from visually analyzing our large-scale simulation runs will also have an impact on deciding on treatment measures for other contaminated sites.","Authors":"Meyer, J.;Bethel, E.W.;Horsman, J.L.;Hubbard, S.S.;Krishnan, H.;Romosan, A.;Keating, E.H.;Monroe, L.;Strelitz, R.;Moore, P.;Taylor, G.;Torkian, B.;Johnson, T.C.;Gorton, I.","Clusters":"DataAcquisitionAndManagement;EarthSpaceAndEnvironmentalSciences;HardwareAccellerationAndComputationGeneral;ParallelSystemsAndParallelProcessing;","DOI":"10.1109\/TVCG.2012.278","Keywords":"environmental management;high-performance computing;visual analytics;data management;parallel rendering","Keywords_Processed":"visual analytic;parallel rendering;environmental management;high performance computing;data management","Title":"Visual Data Analysis as an Integral Part of Environmental Management"},"63":{"Abstract":"We introduce a visual analytics method to analyze eye movement data recorded for dynamic stimuli such as video or animated graphics. The focus lies on the analysis of data of several viewers to identify trends in the general viewing behavior, including time sequences of attentional synchrony and objects with strong attentional focus. By using a space-time cube visualization in combination with clustering, the dynamic stimuli and associated eye gazes can be analyzed in a static 3D representation. Shot-based, spatiotemporal clustering of the data generates potential areas of interest that can be filtered interactively. We also facilitate data drill-down: the gaze points are shown with density-based color mapping and individual scan paths as lines in the space-time cube. The analytical process is supported by multiple coordinated views that allow the user to focus on different aspects of spatial and temporal information in eye gaze data. Common eye-tracking visualization techniques are extended to incorporate the spatiotemporal characteristics of the data. For example, heat maps are extended to motion-compensated heat maps and trajectories of scan paths are included in the space-time visualization. Our visual analytics approach is assessed in a qualitative users study with expert users, which showed the usefulness of the approach and uncovered that the experts applied different analysis strategies supported by the system.","Authors":"Kurzhals, K.;Weiskopf, D.","Clusters":"DataClusteringAndAggregation;DesignMethodologiesAndInteractionDesign;EvaluationGeneral;SpatiotemporalDataAndTechniques;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2013.194","Keywords":"spatio-temporal clustering;space-time cube;motion-compensated heatmap;eye tracking;dynamic areas of interest","Keywords_Processed":"space time cube;motion compensate heatmap;eye tracking;dynamic area of interest;spatio temporal clustering","Title":"Space-Time Visual Analytics of Eye-Tracking Data for Dynamic Stimuli"},"68":{"Abstract":"Spatial organization has been proposed as a compelling approach to externalizing the sensemaking process. However, there are two ways in which space can be provided to the user: by creating a physical workspace that the user can interact with directly, such as can be provided by a large, high-resolution display, or through the use of a virtual workspace that the user navigates using virtual navigation techniques such as zoom and pan. In this study we explicitly examined the use of spatial sensemaking techniques within these two environments. The results demonstrate that these two approaches to providing sensemaking space are not equivalent, and that the greater embodiment afforded by the physical workspace changes how the space is perceived and used, leading to increased externalization of the sensemaking process.","Authors":"Andrews, C.;North, C.","Clusters":"Cognition;LargeAndHighResDisplays;ZoomingAndNavigationTechniques","DOI":"10.1109\/TVCG.2013.205","Keywords":"embodiment;sensemaking;physical navigation;visual analytics;large and high-resolution display","Keywords_Processed":"large and high resolution display;sensemake;visual analytic;physical navigation;embodiment","Title":"The Impact of Physical Navigation on Spatial Organization for Sensemaking"},"54":{"Abstract":"In many applications, data tables contain multi-valued attributes that often store the memberships of the table entities to multiple sets such as which languages a person masters, which skills an applicant documents, or which features a product comes with. With a growing number of entities, the resulting element-set membership matrix becomes very rich of information about how these sets overlap. Many analysis tasks targeted at set-typed data are concerned with these overlaps as salient features of such data. This paper presents Radial Sets, a novel visual technique to analyze set memberships for a large number of elements. Our technique uses frequency-based representations to enable quickly finding and analyzing different kinds of overlaps between the sets, and relating these overlaps to other attributes of the table entities. Furthermore, it enables various interactions to select elements of interest, find out if they are over-represented in specific sets or overlaps, and if they exhibit a different distribution for a specific attribute compared to the rest of the elements. These interactions allow formulating highly-expressive visual queries on the elements in terms of their set memberships and attribute values. As we demonstrate via two usage scenarios, Radial Sets enable revealing and analyzing a multitude of overlapping patterns between large sets, beyond the limits of state-of-the-art techniques.","Authors":"Alsallakh, B.;Aigner, W.;Miksch, S.;Hauser, H.","Clusters":"LargeScaleDataAndScalability;MultidimensionalMultivariateMultifieldDataAndTechniques;SetRelatedDataTechniques;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2013.184","Keywords":"overlapping sets;visualization technique;multi-valued attributes;scalability;set-typed data","Keywords_Processed":"multi value attribute;visualization technique;scalability;set type datum;overlap set","Title":"Radial Sets: Interactive Visual Analysis of Large Overlapping Sets"},"8":{"Abstract":"We present a framework for acuity-driven visualization of super-high resolution image data on gigapixel displays. Tiled display walls offer a large workspace that can be navigated physically by the user. Based on head tracking information, the physical characteristics of the tiled display and the formulation of visual acuity, we guide an out-of-core gigapixel rendering scheme by delivering high levels of detail only in places where it is perceivable to the user. We apply this principle to gigapixel image rendering through adaptive level of detail selection. Additionally, we have developed an acuity-driven tessellation scheme for high-quality Focus-and-Context (F+C) lenses that significantly reduces visual artifacts while accurately capturing the underlying lens function. We demonstrate this framework on the Reality Deck, an immersive gigapixel display. We present the results of a user study designed to quantify the impact of our acuity-driven rendering optimizations in the visual exploration process. We discovered no evidence suggesting a difference in search task performance between our framework and naive rendering of gigapixel resolution data, while realizing significant benefits in terms of data transfer overhead. Additionally, we show that our acuity-driven tessellation scheme offers substantially increased frame rates when compared to naive pre-tessellation, while providing indistinguishable image quality.","Authors":"Papadopoulos, C.;Kaufman, A.","Clusters":"FocusContextTechniques;LargeAndHighResDisplays;Perception","DOI":"10.1109\/TVCG.2013.127","Keywords":"gigapixel visualization;focus+context;gigapixel display;visual acuity;reality deck","Keywords_Processed":"visual acuity;gigapixel display;gigapixel visualization;focus context;reality deck","Title":"Acuity-Driven Gigapixel Visualization"},"42":{"Abstract":"Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature.","Authors":"Jian Zhao;Collins, C.;Chevalier, F.;Balakrishnan, R.","Clusters":"GraphNetworkDataAndTechniques;InteractionTechniquesGeneral;QueriesAndSearch;ZoomingAndNavigationTechniques","DOI":"10.1109\/TVCG.2013.167","Keywords":"network exploration;information visualization;faceted browsing;dynamic query;visual analytics;interaction","Keywords_Processed":"interaction;dynamic query;information visualization;visual analytic;facete browsing;network exploration","Title":"Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets"},"205":{"Abstract":"We consider moving objects as multivariate time-series. By visually analyzing the attributes, patterns may appear that explain why certain movements have occurred. Density maps as proposed by Scheepens et al. [25] are a way to reveal these patterns by means of aggregations of filtered subsets of trajectories. Since filtering is often not sufficient for analysts to express their domain knowledge, we propose to use expressions instead. We present a flexible architecture for density maps to enable custom, versatile exploration using multiple density fields. The flexibility comes from a script, depicted in this paper as a block diagram, which defines an advanced computation of a density field. We define six different types of blocks to create, compose, and enhance trajectories or density fields. Blocks are customized by means of expressions that allow the analyst to model domain knowledge. The versatility of our architecture is demonstrated with several maritime use cases developed with domain experts. Our approach is expected to be useful for the analysis of objects in other domains.","Authors":"Scheepens, R.;Willems, N.;van de Wetering, H.;Andrienko, G.;Andrienko, N.;van Wijk, J.J.","Clusters":"AnimationAndMotion;GeographyGeospatialVisCartographyTerrainVis;ImageBasedDataImageSignalProcessing;MachineLearningAndStatistics;MultidimensionalMultivariateMultifieldDataAndTechniques","DOI":"10.1109\/TVCG.2011.181","Keywords":"geographical information systems;kernel density estimation;raster maps;multivariate data;trajectory","Keywords_Processed":"multivariate datum;raster map;geographical information system;trajectory;kernel density estimation","Title":"Composite Density Maps for Multivariate Trajectories"},"362":{"Abstract":"Over the past few years, large human populations around the world have been affected by an increase in significant seismic activities. For both conducting basic scientific research and for setting critical government policies, it is crucial to be able to explore and understand seismic and geographical information obtained through all scientific instruments. In this work, we present a visual analytics system that enables explorative visualization of seismic data together with satellite-based observational data, and introduce a suite of visual analytical tools. Seismic and satellite data are integrated temporally and spatially. Users can select temporal ;and spatial ranges to zoom in on specific seismic events, as well as to inspect changes both during and after the events. Tools for designing high dimensional transfer functions have been developed to enable efficient and intuitive comprehension of the multi-modal data. Spread-sheet style comparisons are used for data drill-down as well as presentation. Comparisons between distinct seismic events are also provided for characterizing event-wise differences. Our system has been designed for scalability in terms of data size, complexity (i.e. number of modalities), and varying form factors of display environments.","Authors":"Xiaoru Yuan;He Xiao;Hanqi Guo;Peihong Guo;Kendall, W.;Huang, J.;Yongxian Zhang","Clusters":"EarthSpaceAndEnvironmentalSciences;LargeScaleDataAndScalability;MultidimensionalMultivariateMultifieldDataAndTechniques","DOI":"10.1109\/TVCG.2010.192","Keywords":"scalable visualization;seismic data;earth science visualization;multivariate visualization","Keywords_Processed":"scalable visualization;earth science visualization;multivariate visualization;seismic datum","Title":"Scalable Multi-variate Analytics of Seismic and Satellite-based Observational Data"},"309":{"Abstract":"Line graphs have been the visualization of choice for temporal data ever since the days of William Playfair (1759-1823), but realistic temporal analysis tasks often include multiple simultaneous time series. In this work, we explore user performance for comparison, slope, and discrimination tasks for different line graph techniques involving multiple time series. Our results show that techniques that create separate charts for each time series--such as small multiples and horizon graphs--are generally more efficient for comparisons across time series with a large visual span. On the other hand, shared-space techniques--like standard line graphs--are typically more efficient for comparisons over smaller visual spans where the impact of overlap and clutter is reduced.","Authors":"Javed, W.;McDonnel, B.;Elmqvist, N.","Clusters":"ChartsDiagramsPlots;EvaluationGeneral;VisualDesignDesignGuidelines;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2010.162","Keywords":"stacked graphs;design guidelines;braided graphs;horizon graphs;line charts;small multiples;evaluation","Keywords_Processed":"braid graph;design guideline;line chart;small multiple;stack graph;horizon graphs;evaluation","Title":"Graphical Perception of Multiple Time Series"},"235":{"Abstract":"While it is still most common for information visualization researchers to develop new visualizations from a data-or taskdriven perspective, there is growing interest in understanding the types of visualizations people create by themselves for personal use. As part of this recent direction, we have studied a large collection of whiteboards in a research institution, where people make active use of combinations of words, diagrams and various types of visuals to help them further their thought processes. Our goal is to arrive at a better understanding of the nature of visuals that are created spontaneously during brainstorming, thinking, communicating, and general problem solving on whiteboards. We use the qualitative approaches of open coding, interviewing, and affinity diagramming to explore the use of recognizable and novel visuals, and the interplay between visualization and diagrammatic elements with words, numbers and labels. We discuss the potential implications of our findings on information visualization design.","Authors":"Walny, J.;Carpendale, S.;Riche, N.H.;Venolia, G.;Fawcett, P.","Clusters":"ChartsDiagramsPlots;HumanComputerInteractionHumanFactors;QualitativeEvaluation;","DOI":"10.1109\/TVCG.2011.251","Keywords":"visualization;whiteboard;diagrams;observational study","Keywords_Processed":"visualization;whiteboard;diagram;observational study","Title":"Visual Thinking In Action: Visualizations As Used On Whiteboards"},"32":{"Abstract":"Conflicting results are reported in the literature on whether dynamic visualizations are more effective than static visualizations for learning and mastering 3-D tasks, and only a few investigations have considered the influence of the spatial abilities of the learners. In a study with 117 participants, we compared the benefit of static vs. dynamic visualization training tools on learners with different spatial abilities performing a typical 3-D task (specifically, creating orthographic projections of a 3-D object). We measured the spatial abilities of the participants using the Mental Rotation Test (MRT) and classified participants into two groups (high and low abilities) to examine how the participants' abilities predicted change in performance after training with static versus dynamic training tools. Our results indicate that: 1) visualization training programs can help learners to improve 3-D task performance, 2) dynamic visualizations provide no advantages over static visualizations that show intermediate steps, 3) training programs are more beneficial for individuals with low spatial abilities than for individuals with high spatial abilities, and 4) training individuals with high spatial abilities using dynamic visualizations provides little benefit.","Authors":"Froese, M.-E.;Tory, M.;Evans, G.-W.;Shrikhande, K.","Clusters":"ApplicationsGeneralAndOther;CamerasCameraViewsAndProjections;Cognition;EvaluationGeneral;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2013.156","Keywords":"orthographic projection;training;cad;3d visualization;spatial ability;evaluation","Keywords_Processed":"evaluation;training;3d visualization;spatial ability;cad;orthographic projection","Title":"Evaluation of Static and Dynamic Visualization Training Approaches for Users with Different Spatial Abilities"},"5":{"Abstract":"The considerable previous work characterizing visualization usage has focused on low-level tasks or interactions and high-level tasks, leaving a gap between them that is not addressed. This gap leads to a lack of distinction between the ends and means of a task, limiting the potential for rigorous analysis. We contribute a multi-level typology of visualization tasks to address this gap, distinguishing why and how a visualization task is performed, as well as what the task inputs and outputs are. Our typology allows complex tasks to be expressed as sequences of interdependent simpler tasks, resulting in concise and flexible descriptions for tasks of varying complexity and scope. It provides abstract rather than domain-specific descriptions of tasks, so that useful comparisons can be made between visualization systems targeted at different application domains. This descriptive power supports a level of analysis required for the generation of new designs, by guiding the translation of domain-specific problems into abstract tasks, and for the qualitative evaluation of visualization usage. We demonstrate the benefits of our approach in a detailed case study, comparing task descriptions from our typology to those derived from related work. We also discuss the similarities and differences between our typology and over two dozen extant classification systems and theoretical frameworks from the literatures of visualization, human-computer interaction, information retrieval, communications, and cartography.","Authors":"Brehmer, M.;Munzner, T.","Clusters":"QualitativeEvaluation;TasksTaskRequirementsAnalysis;VisualizationTheoryModelsAndMethods","DOI":"10.1109\/TVCG.2013.124","Keywords":"qualitative evaluation;typology;task and requirements analysis;visualization models","Keywords_Processed":"task and requirement analysis;qualitative evaluation;visualization model;typology","Title":"A Multi-Level Typology of Abstract Visualization Tasks"},"376":{"Abstract":"In this paper, we introduce a novel application of volume modeling techniques on laser Benign Prostatic Hyperplasia (BPH) therapy simulation. The core technique in our system is an algorithm for simulating the tissue vaporization process by laser heating. Different from classical volume CSG operations, our technique takes experimental data as the guidance to determine the vaporization amount so that only a specified amount of tissue is vaporized in each time. Our algorithm uses a predictor-corrector strategy. First, we apply the classical CSG algorithm on a tetrahedral grid based distance field to estimate the vaporized tissue amount. Then, a volume-correction phase is applied on the distance field. To improve the performance, we further propose optimization approaches for efficient implementation.","Authors":"Zhang, N.;Xiangmin Zhou;Yunhe Shen;Sweet, R.","Clusters":"BiomedicalScienceAndMedicine;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2010.221","Keywords":"volume csg;medical simulation;large benign prostatic hyperplasia simulator;controlled-volume vaporization;volume modeling","Keywords_Processed":"control volume vaporization;medical simulation;large benign prostatic hyperplasia simulator;volume csg;volume model","Title":"Volumetric Modeling in Laser BPH Therapy Simulation"},"288":{"Abstract":"Cellular biology deals with studying the behavior of cells. Current time-lapse imaging microscopes help us capture the progress of experiments at intervals that allow for understanding of the dynamic and kinematic behavior of the cells. On the other hand, these devices generate such massive amounts of data (250GB of data per experiment) that manual sieving of data to identify interesting patterns becomes virtually impossible. In this paper we propose an end-to-end system to analyze time-lapse images of the cultures of human neural stem cells (hNSC), that includes an image processing system to analyze the images to extract all the relevant geometric and statistical features within and between images, a database management system to manage and handle queries on the data, a visual analytic system to navigate through the data, and a visual query system to explore different relationships and correlations between the parameters. In each stage of the pipeline we make novel algorithmic and conceptual contributions, and the entire system design is motivated by many different yet unanswered exploratory questions pursued by our neurobiologist collaborators. With a few examples we show how such abstract biological queries can be analyzed and answered by our system.","Authors":"Kulkarni, I.;Mistry, S.Y.;Cummings, B.;Gopi, M.","Clusters":"AnalysisProcessGeneral;BiologyAndBioinformatics;DataAcquisitionAndManagement;NeurosciencesAndBrainVisualization;QueriesAndSearch;ZoomingAndNavigationTechniques","DOI":"10.1109\/VAST.2011.6102459","Keywords":"navigation;neuroscience;stem cell segmentation;exploration;cell imaging;query processing;visual analytics;data management;tracking","Keywords_Processed":"neuroscience;navigation;query processing;tracking;cell image;visual analytic;exploration;stem cell segmentation;data management","Title":"A visual navigation system for querying neural stem cell imaging data"},"38":{"Abstract":"Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.","Authors":"Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;Ribarsky, W.","Clusters":"BiologyAndBioinformatics;TextDocumentTopicAnalysisDataAndTechniques;","DOI":"10.1109\/TVCG.2013.162","Keywords":"visual analytics;rose tree;hierarchical topic representation;topic modeling","Keywords_Processed":"visual analytic;topic modeling;hierarchical topic representation;rise tree","Title":"HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies"},"324":{"Abstract":"Electronic test and measurement systems are becoming increasingly sophisticated in order to match the increased complexity and ultra-high speed of the devices under test. A key feature in many such instruments is a vastly increased capacity for storage of digital signals. Storage of 109 time points or more is now possible. At the same time, the typical screens on such measurement devices are relatively small. Therefore, these instruments can only render an extremely small fraction of the complete signal at any time. SignalLens uses a Focus+Context approach to provide a means of navigating to and inspecting low-level signal details in the context of the entire signal trace. This approach provides a compact visualization suitable for embedding into the small displays typically provided by electronic measurement instruments. We further augment this display with computed tracks which display time-aligned computed properties of the signal. By combining and filtering these computed tracks it is possible to easily and quickly find computationally detected features in the data which are often obscured by the visual compression required to render the large data sets on a small screen. Further, these tracks can be viewed in the context of the entire signal trace as well as visible high-level signal features. Several examples using real-world electronic measurement data are presented, which demonstrate typical use cases and the effectiveness of the design.","Authors":"Kincaid, R.","Clusters":"EvaluationGeneral;FocusContextTechniques;ImageBasedDataImageSignalProcessing;PhysicsAndPhysicalSciences","DOI":"10.1109\/TVCG.2010.193","Keywords":"lens;electronic signal;test and measurement;focus+context;signal processing","Keywords_Processed":"electronic signal;signal processing;test and measurement;lens;focus context","Title":"SignalLens: Focus+Context Applied to Electronic Time Series"},"375":{"Abstract":"In flow simulations the behavior and properties of particle trajectories often depend on the physical geometry contained in the simulated environment. Understanding the flow in and around the geometry itself is an important part of analyzing the data. Previous work has often utilized focus+context rendering techniques, with an emphasis on showing trajectories while simplifying or illustratively rendering the physical areas. Our research instead emphasizes the local relationship between particle paths and geometry by using a projected multi-field visualization technique. The correlation between a particle path and its surrounding area is calculated on-the-fly and displayed in a non-intrusive manner. In addition, we support visual exploration and comparative analysis through the use of linked information visualization, such as manipulatable curve plots and one-on-one similarity plots. Our technique is demonstrated on particle trajectories from a groundwater simulation and a computer room airflow simulation, where the flow of particles is highly influenced by the dense geometry.","Authors":"Jones, C.;Kwan-Liu Ma","Clusters":"FlowVisualizationDataAndTechniques;FocusContextTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;MultipleLinkedCoordinatedViews","DOI":"10.1109\/TVCG.2010.218","Keywords":"flow visualization;coordinated linked views;focus+context visualization;multi-field visualization","Keywords_Processed":"coordinate link view;focus context visualization;multi field visualization;flow visualization","Title":"Visualizing Flow Trajectories Using Locality-based Rendering and Warped Curve Plots"},"175":{"Abstract":"Metal oxides are important for many technical applications. For example alumina (aluminum oxide) is the most commonly-used ceramic in microelectronic devices thanks to its excellent properties. Experimental studies of these materials are increasingly supplemented with computer simulations. Molecular dynamics (MD) simulations can reproduce the material behavior very well and are now reaching time scales relevant for interesting processes like crack propagation. In this work we focus on the visualization of induced electric dipole moments on oxygen atoms in crack propagation simulations. The straightforward visualization using glyphs for the individual atoms, simple shapes like spheres or arrows, is insufficient for providing information about the data set as a whole. As our contribution we show for the first time that fractional anisotropy values computed from the local neighborhood of individual atoms of MD simulation data depict important information about relevant properties of the field of induced electric dipole moments. Iso surfaces in the field of fractional anisotropy as well as adjustments of the glyph representation allow the user to identify regions of correlated orientation. We present novel and relevant findings for the application domain resulting from these visualizations, like the influence of mechanical forces on the electrostatic properties.","Authors":"Grottel, S.;Beck, P.;Muller, C.;Reina, G.;Roth, J.;Trebin, H.-R.;Ertl, T.","Clusters":"GlyphsGlyphBasedTechniques;PhysicsAndPhysicalSciences;PointBasedDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques","DOI":"10.1109\/TVCG.2012.282","Keywords":"time-varying data;point-based data;visualization in physical sciences and engineering;glyph-based techniques","Keywords_Processed":"point base datum;time vary datum;glyph base technique;visualization in physical science and engineering","Title":"Visualization of Electrostatic Dipoles in Molecular Dynamics of Metal Oxides"},"115":{"Abstract":"In this paper, we explore how the capacity limits of attention influence the effectiveness of information visualizations. We conducted a series of experiments to test how visual feature type (color vs. motion), layout, and variety of visual elements impacted user performance. The experiments tested users' abilities to (1) determine if a specified target is on the screen, (2) detect an odd-ball, deviant target, different from the other visible objects, and (3) gain a qualitative overview by judging the number of unique categories on the screen. Our results show that the severe capacity limits of attention strongly modulate the effectiveness of information visualizations, particularly the ability to detect unexpected information. Keeping in mind these capacity limits, we conclude with a set of design guidelines which depend on a visualization's intended use.","Authors":"Haroz, S.;Whitney, D.","Clusters":"AnimationAndMotion;ChartsDiagramsPlots;Cognition;ColorColorPerception;DesignMethodologiesAndInteractionDesign;EvaluationGeneral;Perception;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2012.233","Keywords":"color;goal-oriented design;user study;perception;layout;nominal axis;attention;motion","Keywords_Processed":"user study;perception;motion;nominal axis;layout;color;goal orient design;attention","Title":"How Capacity Limits of Attention Influence Information Visualization Effectiveness"},"133":{"Abstract":"Current interfaces for common information visualizations such as bar graphs, line graphs, and scatterplots usually make use of the WIMP (Windows, Icons, Menus and a Pointer) interface paradigm with its frequently discussed problems of multiple levels of indirection via cascading menus, dialog boxes, and control panels. Recent advances in interface capabilities such as the availability of pen and touch interaction challenge us to re-think this and investigate more direct access to both the visualizations and the data they portray. We conducted a Wizard of Oz study to explore applying pen and touch interaction to the creation of information visualization interfaces on interactive whiteboards without implementing a plethora of recognizers. Our wizard acted as a robust and flexible pen and touch recognizer, giving participants maximum freedom in how they interacted with the system. Based on our qualitative analysis of the interactions our participants used, we discuss our insights about pen and touch interactions in the context of learnability and the interplay between pen and touch gestures. We conclude with suggestions for designing pen and touch enabled interactive visualization interfaces.","Authors":"Walny, J.;Bongshin Lee;Johns, P.;Riche, N.H.;Carpendale, S.","Clusters":"AnalysisProcessGeneral;EvaluationGeneral;HumanComputerInteractionHumanFactors;InteractionTechniquesGeneral","DOI":"10.1109\/TVCG.2012.275","Keywords":"data exploration;whiteboard;wizard of oz;pen and touch;interaction","Keywords_Processed":"interaction;whiteboard;pen and touch;wizard of oz;datum exploration","Title":"Understanding Pen and Touch Interaction for Data Exploration on Interactive Whiteboards"},"109":{"Abstract":"We report on results of a series of user studies on the perception of four visual variables that are commonly used in the literature to depict uncertainty. To the best of our knowledge, we provide the first formal evaluation of the use of these variables to facilitate an easier reading of uncertainty in visualizations that rely on line graphical primitives. In addition to blur, dashing and grayscale, we investigate the use of `sketchiness' as a visual variable because it conveys visual impreciseness that may be associated with data quality. Inspired by work in non-photorealistic rendering and by the features of hand-drawn lines, we generate line trajectories that resemble hand-drawn strokes of various levels of proficiency-ranging from child to adult strokes-where the amount of perturbations in the line corresponds to the level of uncertainty in the data. Our results show that sketchiness is a viable alternative for the visualization of uncertainty in lines and is as intuitive as blur; although people subjectively prefer dashing style over blur, grayscale and sketchiness. We discuss advantages and limitations of each technique and conclude with design considerations on how to deploy these visual variables to effectively depict various levels of uncertainty for line marks.","Authors":"Boukhelifa, N.;Bezerianos, A.;Isenberg, T.;Fekete, J.","Clusters":"Perception;QualitativeEvaluation;QuantitativeEvaluation;UncertaintyTechniquesAndVisualization","DOI":"10.1109\/TVCG.2012.220","Keywords":"uncertainty visualization;qualitative evaluation;perception;quantitative evaluation","Keywords_Processed":"quantitative evaluation;qualitative evaluation;uncertainty visualization;perception","Title":"Evaluating Sketchiness as a Visual Variable for the Depiction of Qualitative Uncertainty"},"385":{"Abstract":"Journalists increasingly turn to social media sources such as Facebook or Twitter to support their coverage of various news events. For large-scale events such as televised debates and speeches, the amount of content on social media can easily become overwhelming, yet still contain information that may aid and augment reporting via individual content items as well as via aggregate information from the crowd's response. In this work we present a visual analytic tool, Vox Civitas, designed to help journalists and media professionals extract news value from large-scale aggregations of social media content around broadcast events. We discuss the design of the tool, present the text analysis techniques used to enable the presentation, and provide details on the visual and interaction design. We provide an exploratory evaluation based on a user study in which journalists interacted with the system to explore and report on a dataset of over one hundred thousand twitter messages collected during the U.S. State of the Union presidential address in 2010.","Authors":"Diakopoulos, N.;Naaman, M.;Kivran-Swaine, F.","Clusters":"ApplicationsGeneralAndOther;Cognition;SocialNetworksAndSocialMedia","DOI":"10.1109\/VAST.2010.5652922","Keywords":"social media;computer-assisted reporting;sensemaking;computational journalism","Keywords_Processed":"computer assist reporting;sensemake;social medium;computational journalism","Title":"Diamonds in the rough: Social media visual analytics for journalistic inquiry"},"268":{"Abstract":"Flood disasters are the most common natural risk and tremendous efforts are spent to improve their simulation and management. However, simulation-based investigation of actions that can be taken in case of flood emergencies is rarely done. This is in part due to the lack of a comprehensive framework which integrates and facilitates these efforts. In this paper, we tackle several problems which are related to steering a flood simulation. One issue is related to uncertainty. We need to account for uncertain knowledge about the environment, such as levee-breach locations. Furthermore, the steering process has to reveal how these uncertainties in the boundary conditions affect the confidence in the simulation outcome. Another important problem is that the simulation setup is often hidden in a black-box. We expose system internals and show that simulation steering can be comprehensible at the same time. This is important because the domain expert needs to be able to modify the simulation setup in order to include local knowledge and experience. In the proposed solution, users steer parameter studies through the World Lines interface to account for input uncertainties. The transport of steering information to the underlying data-flow components is handled by a novel meta-flow. The meta-flow is an extension to a standard data-flow network, comprising additional nodes and ropes to abstract parameter control. The meta-flow has a visual representation to inform the user about which control operations happen. Finally, we present the idea to use the data-flow diagram itself for visualizing steering information and simulation results. We discuss a case-study in collaboration with a domain expert who proposes different actions to protect a virtual city from imminent flooding. The key to choosing the best response strategy is the ability to compare different regions of the parameter space while retaining an understanding of what is happening inside the data-flow system.","Authors":"Waser, J.;Ribicic, H.;Fuchs, R.;Hirsch, C.;Schindler, B.;Bloschl, G.;Groller, E.","Clusters":"ApplicationsGeneralAndOther;DataAcquisitionAndManagement;EmergencyDisasterManagement;FlowVisualizationDataAndTechniques;KnowledgeDiscovery;Parameterization;UncertaintyTechniquesAndVisualization;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2011.225","Keywords":"visualization system and toolkit design;parameter study;meta-flow;uncertainty;visual knowledge discovery;emergency\/disaster management;data-flow;visualization of control","Keywords_Processed":"emergency disaster management;datum flow;meta flow;uncertainty;visual knowledge discovery;visualization of control;paramet study;visualization system and toolkit design","Title":"Nodes on Ropes: A Comprehensive Data and Control Flow for Steering Ensemble Simulations"},"196":{"Abstract":"Distributed cognition and embodiment provide compelling models for how humans think and interact with the environment. Our examination of the use of large, high-resolution displays from an embodied perspective has lead directly to the development of a new sensemaking environment called Analyst's Workspace (AW). AW leverages the embodied resources made more accessible through the physical nature of the display to create a spatial workspace. By combining spatial layout of documents and other artifacts with an entity-centric, explorative investigative approach, AW aims to allow the analyst to externalize elements of the sensemaking process as a part of the investigation, integrated into the visual representations of the data itself. In this paper, we describe the various capabilities of AW and discuss the key principles and concepts underlying its design, emphasizing unique design principles for designing visual analytic tools for large, high-resolution displays.","Authors":"Andrews, C.;North, C.","Clusters":"Cognition;LargeAndHighResDisplays;SpaceRelatedSpatialDataAndTechniques","DOI":"10.1109\/VAST.2012.6400559","Keywords":"embodiment;sensemaking;distributed cognition;space;large and high-resolution display","Keywords_Processed":"large and high resolution display;sensemake;space;embodiment;distribute cognition","Title":"Analyst's Workspace: An embodied sensemaking environment for large, high-resolution displays"},"142":{"Abstract":"Geoscientific modeling and simulation helps to improve our understanding of the complex Earth system. During the modeling process, validation of the geoscientific model is an essential step. In validation, it is determined whether the model output shows sufficient agreement with observation data. Measures for this agreement are called goodness of fit. In the geosciences, analyzing the goodness of fit is challenging due to its manifold dependencies: 1) The goodness of fit depends on the model parameterization, whose precise values are not known. 2) The goodness of fit varies in space and time due to the spatio-temporal dimension of geoscientific models. 3) The significance of the goodness of fit is affected by resolution and preciseness of available observational data. 4) The correlation between goodness of fit and underlying modeled and observed values is ambiguous. In this paper, we introduce a visual analysis concept that targets these challenges in the validation of geoscientific models - specifically focusing on applications where observation data is sparse, unevenly distributed in space and time, and imprecise, which hinders a rigorous analytical approach. Our concept, developed in close cooperation with Earth system modelers, addresses the four challenges by four tailored visualization components. The tight linking of these components supports a twofold interactive drill-down in model parameter space and in the set of data samples, which facilitates the exploration of the numerous dependencies of the goodness of fit. We exemplify our visualization concept for geoscientific modeling of glacial isostatic adjustments in the last 100,000 years, validated against sea levels indicators - a prominent example for sparse and imprecise observation data. An initial use case and feedback from Earth system modelers indicate that our visualization concept is a valuable complement to the range of validation methods.","Authors":"Unger, A.;Schulte, S.;Klemann, V.;Dransch, D.","Clusters":"EarthSpaceAndEnvironmentalSciences;MachineLearningAndStatistics;MultipleLinkedCoordinatedViews;SpatiotemporalDataAndTechniques","DOI":"10.1109\/TVCG.2012.190","Keywords":"spatio-temporal visualization;earth science visualization;model validation;sea level indicators;coordinated & multiple views","Keywords_Processed":"spatio temporal visualization;earth science visualization;model validation;sea level indicator;coordinate multiple view","Title":"A Visual Analysis Concept for the Validation of Geoscientific Simulation Models"},"292":{"Abstract":"To make informed decisions, an expert has to reason with multi-dimensional, heterogeneous data and analysis results of these. Items in such datasets are typically represented by features. However, as argued in cognitive science, features do not yield an optimal space for human reasoning. In fact, humans tend to organize complex information in terms of prototypes or known cases rather than in absolute terms. When confronted with unknown data items, humans assess them in terms of similarity to these prototypical elements. Interestingly, an analogues similarity-to-prototype approach, where prototypes are taken from the data, has been successfully applied in machine learning. Combining such a machine learning approach with human prototypical reasoning in a Visual Analytics context requires to integrate similarity-based classification with interactive visualizations. To that end, the data prototypes should be visually represented to trigger direct associations to cases familiar to the domain experts. In this paper, we propose a set of highly interactive visualizations to explore data and classification results in terms of dissimilarities to visually represented prototypes. We argue that this approach not only supports human reasoning processes, but is also suitable to enhance understanding of heterogeneous data. The proposed framework is applied to a risk assessment case study in Forensic Psychiatry.","Authors":"Migut, M.;van Gemert, J.C.;Worring, M.","Clusters":"HumanComputerInteractionHumanFactors;InteractionTechniquesGeneral;SegmentationAndClassification;","DOI":"10.1109\/VAST.2011.6102451","Keywords":"interactive visualization;prototypes;dissimilarity-based classification;visual analytics;dissimilarity-based visualization","Keywords_Processed":"prototype;visual analytic;dissimilarity base visualization;dissimilarity base classification;interactive visualization","Title":"Interactive decision making using dissimilarity to visually represented prototypes"},"253":{"Abstract":"We present a new framework for feature-based statistical analysis of large-scale scientific data and demonstrate its effectiveness by analyzing features from Direct Numerical Simulations (DNS) of turbulent combustion. Turbulent flows are ubiquitous and account for transport and mixing processes in combustion, astrophysics, fusion, and climate modeling among other disciplines. They are also characterized by coherent structure or organized motion, i.e. nonlocal entities whose geometrical features can directly impact molecular mixing and reactive processes. While traditional multi-point statistics provide correlative information, they lack nonlocal structural information, and hence, fail to provide mechanistic causality information between organized fluid motion and mixing and reactive processes. Hence, it is of great interest to capture and track flow features and their statistics together with their correlation with relevant scalar quantities, e.g. temperature or species concentrations. In our approach we encode the set of all possible flow features by pre-computing merge trees augmented with attributes, such as statistical moments of various scalar fields, e.g. temperature, as well as length-scales computed via spectral analysis. The computation is performed in an efficient streaming manner in a pre-processing step and results in a collection of meta-data that is orders of magnitude smaller than the original simulation data. This meta-data is sufficient to support a fully flexible and interactive analysis of the features, allowing for arbitrary thresholds, providing per-feature statistics, and creating various global diagnostics such as Cumulative Density Functions (CDFs), histograms, or time-series. We combine the analysis with a rendering of the features in a linked-view browser that enables scientists to interactively explore, visualize, and analyze the equivalent of one terabyte of simulation data. We highlight the utility of this new framework for combustion s- ience; however, it is applicable to many other science domains.","Authors":"Bennett, J.C.;Krishnamoorthy, V.;Shusen Liu;Grout, R.W.;Hawkes, E.R.;Chen, J.H.;Shepherd, J.;Pascucci, V.;Bremer, P.-T.","Clusters":"AnalysisProcessGeneral;MachineLearningAndStatistics;MultidimensionalMultivariateMultifieldDataAndTechniques;PhysicsAndPhysicalSciences;TopologyBasedTechniques","DOI":"10.1109\/TVCG.2011.199","Keywords":"data exploration;visualization in physical sciences and engineering;data analysis;multivariate data;topology;statistics","Keywords_Processed":"multivariate datum;topology;datum analysis;visualization in physical science and engineering;statistic;datum exploration","Title":"Feature-Based Statistical Analysis of Combustion Simulation Data"},"305":{"Abstract":"Pixel-based visualization is a popular method of conveying large amounts of numerical data graphically. Application scenarios include business and finance, bioinformatics and remote sensing. In this work, we examined how the usability of such visual representations varied across different tasks and block resolutions. The main stimuli consisted of temporal pixel-based visualization with a white-red color map, simulating monthly temperature variation over a six-year period. In the first study, we included 5 separate tasks to exert different perceptual loads. We found that performance varied considerably as a function of task, ranging from 75% correct in low-load tasks to below 40% in high-load tasks. There was a small but consistent effect of resolution, with the uniform patch improving performance by around 6% relative to higher block resolution. In the second user study, we focused on a high-load task for evaluating month-to-month changes across different regions of the temperature range. We tested both CIE L*u*v* and RGB color spaces. We found that the nature of the change-evaluation errors related directly to the distance between the compared regions in the mapped color space. We were able to reduce such errors by using multiple color bands for the same data range. In a final study, we examined more fully the influence of block resolution on performance, and found block resolution had a limited impact on the effectiveness of pixel-based visualization.","Authors":"Borgo, R.;Proctor, K.;Chen, M.;J\u00e4nicke, H.;Murray, T.;Thornton, I.M.","Clusters":"DynamicVisualizationVisualizationOfChange;EvaluationGeneral;PixelOrientedEncodings;QueriesAndSearch","DOI":"10.1109\/TVCG.2010.150","Keywords":"user study;change detection;pixel-based visualization;visual search;evaluation","Keywords_Processed":"change detection;user study;visual search;pixel base visualization;evaluation","Title":"Evaluating the impact of task demands and block resolution on the effectiveness of pixel-based visualization"},"70":{"Abstract":"Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.","Authors":"Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.;Griffiths, I.W.;Chen, M.","Clusters":"DataClusteringAndAggregation;KnowledgeDiscovery;MachineLearningAndStatistics;MultimediaImageVideoMusic","DOI":"10.1109\/TVCG.2013.207","Keywords":"multimedia visualization;visual knowledge discovery;data clustering;machine learning","Keywords_Processed":"machine learning;multimedia visualization;visual knowledge discovery;datum clustering","Title":"Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop"},"83":{"Abstract":"Social network analysis (SNA) is becoming increasingly concerned not only with actors and their relations, but also with distinguishing between different types of such entities. For example, social scientists may want to investigate asymmetric relations in organizations with strict chains of command, or incorporate non-actors such as conferences and projects when analyzing coauthorship patterns. Multimodal social networks are those where actors and relations belong to different types, or modes, and multimodal social network analysis (mSNA) is accordingly SNA for such networks. In this paper, we present a design study that we conducted with several social scientist collaborators on how to support mSNA using visual analytics tools. Based on an openended, formative design process, we devised a visual representation called parallel node-link bands (PNLBs) that splits modes into separate bands and renders connections between adjacent ones, similar to the list view in Jigsaw. We then used the tool in a qualitative evaluation involving five social scientists whose feedback informed a second design phase that incorporated additional network metrics. Finally, we conducted a second qualitative evaluation with our social scientist collaborators that provided further insights on the utility of the PNLBs representation and the potential of visual analytics for mSNA.","Authors":"Ghani, S.;Bum Chul Kwon;Seungyoon Lee;Ji Soo Yi;Elmqvist, N.","Clusters":"DesignMethodologiesAndInteractionDesign;DesignStudiesAndCaseStudies;GraphNetworkDataAndTechniques;InteractionTechniquesGeneral;QualitativeEvaluation","DOI":"10.1109\/TVCG.2013.223","Keywords":"multimodal graphs;design study;node-link diagrams;qualitative evaluation;user-centered design;interaction","Keywords_Processed":"interaction;design study;multimodal graph;user center design;qualitative evaluation;node link diagram","Title":"Visual Analytics for Multimodal Social Network Analysis: A Design Study with Social Scientists"},"290":{"Abstract":"We propose a visual analytics procedure for analyzing movement data, i.e., recorded tracks of moving objects. It is oriented to a class of problems where it is required to determine significant places on the basis of certain types of events occurring repeatedly in movement data. The procedure consists of four major steps: (1) event extraction from trajectories; (2) event clustering and extraction of relevant places; (3) spatio-temporal aggregation of events or trajectories; (4) analysis of the aggregated data. All steps are scalable with respect to the amount of the data under analysis. We demonstrate the use of the procedure by example of two real-world problems requiring analysis at different spatial scales.","Authors":"Andrienko, G.;Andrienko, N.;Hurter, C.;Rinzivillo, S.;Wrobel, S.","Clusters":"AnimationAndMotion;DataClusteringAndAggregation;SpaceRelatedSpatialDataAndTechniques;SpatiotemporalDataAndTechniques","DOI":"10.1109\/VAST.2011.6102454","Keywords":"spatio-temporal clustering;spatial clustering;spatio-temporal data;movement;spatial events;trajectory","Keywords_Processed":"spatio temporal datum;spatial event;trajectory;spatial clustering;spatio temporal clustering;movement","Title":"From movement tracks through events to places: Extracting and characterizing significant places from mobility data"},"357":{"Abstract":"Numerical weather prediction ensembles are routinely used for operational weather forecasting. The members of these ensembles are individual simulations with either slightly perturbed initial conditions or different model parameterizations, or occasionally both. Multi-member ensemble output is usually large, multivariate, and challenging to interpret interactively. Forecast meteorologists are interested in understanding the uncertainties associated with numerical weather prediction; specifically variability between the ensemble members. Currently, visualization of ensemble members is mostly accomplished through spaghetti plots of a single midtroposphere pressure surface height contour. In order to explore new uncertainty visualization methods, the Weather Research and Forecasting (WRF) model was used to create a 48-hour, 18 member parameterization ensemble of the 13 March 1993 \"Superstorm\". A tool was designed to interactively explore the ensemble uncertainty of three important weather variables: water-vapor mixing ratio, perturbation potential temperature, and perturbation pressure. Uncertainty was quantified using individual ensemble member standard deviation, inter-quartile range, and the width of the 95% confidence interval. Bootstrapping was employed to overcome the dependence on normality in the uncertainty metrics. A coordinated view of ribbon and glyph-based uncertainty visualization, spaghetti plots, iso-pressure colormaps, and data transect plots was provided to two meteorologists for expert evaluation. They found it useful in assessing uncertainty in the data, especially in finding outliers in the ensemble run and therefore avoiding the WRF parameterizations that lead to these outliers. Additionally, the meteorologists could identify spatial regions where the uncertainty was significantly high, allowing for identification of poorly simulated storm environments and physical interpretation of these model issues.","Authors":"Sanyal, J.;Song Zhang;Dyer, J.;Mercer, A.;Amburn, P.;Moorhead, R.J.","Clusters":"EarthSpaceAndEnvironmentalSciences;GeographyGeospatialVisCartographyTerrainVis;GlyphsGlyphBasedTechniques;QualitativeEvaluation;TimeseriesTimeVaryingDataAndTechniques;UncertaintyTechniquesAndVisualization","DOI":"10.1109\/TVCG.2010.181","Keywords":"glyph-based techniques;uncertainty visualization;time-varying data;weather ensemble;qualitative evaluation;geographic\/geospatial visualization","Keywords_Processed":"time vary datum;weather ensemble;glyph base technique;geographic geospatial visualization;qualitative evaluation;uncertainty visualization","Title":"Noodles: A Tool for Visualization of Numerical Weather Model Ensemble Uncertainty"},"97":{"Abstract":"In this paper, we investigate the problem of labeling point sites in focus regions of maps or diagrams. This problem occurs, for example, when the user of a mapping service wants to see the names of restaurants or other POIs in a crowded downtown area but keep the overview over a larger area. Our approach is to place the labels at the boundary of the focus region and connect each site with its label by a linear connection, which is called a leader. In this way, we move labels from the focus region to the less valuable context region surrounding it. In order to make the leader layout well readable, we present algorithms that rule out crossings between leaders and optimize other characteristics such as total leader length and distance between labels. This yields a new variant of the boundary labeling problem, which has been studied in the literature. Other than in traditional boundary labeling, where leaders are usually schematized polylines, we focus on leaders that are either straight-line segments or Bezier curves. Further, we present algorithms that, given the sites, find a position of the focus region that optimizes the above characteristics. We also consider a variant of the problem where we have more sites than space for labels. In this situation, we assume that the sites are prioritized by the user. Alternatively, we take a new facility-location perspective which yields a clustering of the sites. We label one representative of each cluster. If the user wishes, we apply our approach to the sites within a cluster, giving details on demand.","Authors":"Fink, M.;Haunert, J.-H.;Schulz, A.;Spoerhase, J.;Wolff, A.","Clusters":"DataClusteringAndAggregation;FocusContextTechniques;GeographyGeospatialVisCartographyTerrainVis;SmallMobileUbiquitousDevicesDisplays","DOI":"10.1109\/TVCG.2012.193","Keywords":"focus+context technique;mobile and ubiquitous visualization;geographic\/geospatial visualization;data clustering","Keywords_Processed":"mobile and ubiquitous visualization;focus context technique;geographic geospatial visualization;datum clustering","Title":"Algorithms for Labeling Focus Regions"}}