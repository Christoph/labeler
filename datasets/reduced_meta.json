{"0":{"Abstract":"Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.","Authors":"Hullman, J.;Drucker, S.;Riche, N.H.;Bongshin Lee;Fisher, D.;Adar, E.","Clusters":"Storytelling","DOI":"10.1109\/TVCG.2013.119","Keywords":"data storytelling;narrative visualization;narrative structure","Title":"A Deeper Understanding of Sequence in Narrative Visualization","type":"new","Vector":[0.0011959928,0.0211665537,0.0009809641,0.0,0.0,0.0,0.0,0.0,0.0,0.001692395,0.0,0.0055199746,0.0,0.1172551812,0.0,0.0,0.0,0.0540968332,0.0124931373,0.0539301559]},"1":{"Abstract":"Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it.","Authors":"Schulz, H.;Nocke, T.;Heitzler, M.;Schumann, H.","Clusters":"DesignMethodologiesAndInteractionDesign;EarthSpaceAndEnvironmentalSciences;Taxonomies;VisualDesignDesignGuidelines","DOI":"10.1109\/TVCG.2013.120","Keywords":"design space;visualization recommendation;task taxonomy;climate impact research","Title":"A Design Space of Visualization Tasks","type":"new","Vector":[0.0,0.0,0.0006637523,0.0000199068,0.0,0.0074881633,0.0154659615,0.0033547771,0.0012964036,0.0006369831,0.0,0.0145943756,0.0,0.0620349329,0.0006475789,0.0,0.0193196621,0.0866755961,0.0086649063,0.021028078]},"2":{"Abstract":"We present a prop-based, tangible interface for 3D interactive visualization of thin fiber structures. These data are commonly found in current bioimaging datasets, for example second-harmonic generation microscopy of collagen fibers in tissue. Our approach uses commodity visualization technologies such as a depth sensing camera and low-cost 3D display. Unlike most current uses of these emerging technologies in the games and graphics communities, we employ the depth sensing camera to create a fish-tank sterePoscopic virtual reality system at the scientist's desk that supports tracking of small-scale gestures with objects already found in the work space. We apply the new interface to the problem of interactive exploratory visualization of three-dimensional thin fiber data. A critical task for the visual analysis of these data is understanding patterns in fiber orientation throughout a volume.The interface enables a new, fluid style of data exploration and fiber orientation analysis by using props to provide needed passive-haptic feedback, making 3D interactions with these fiber structures more controlled. We also contribute a low-level algorithm for extracting fiber centerlines from volumetric imaging. The system was designed and evaluated with two biophotonic experts who currently use it in their lab. As compared to typical practice within their field, the new visualization system provides a more effective way to examine and understand the 3D bioimaging datasets they collect.","Authors":"Jackson, B.;Tung Yuen Lau;Schroeder, D.;Toussaint, K.C.;Keefe, D.F.","Clusters":"InteractionTechniquesGeneral;Microscopy","DOI":"10.1109\/TVCG.2013.121","Keywords":"microscopy visualization;tangible interaction;scientific visualization;3d interaction","Title":"A Lightweight Tangible 3D Interface for Interactive Visualization of Thin fiber Structures","type":"new","Vector":[0.0037093269,0.0,0.0,0.0,0.0038954882,0.0,0.0,0.0035109776,0.0068061838,0.0,0.0235283883,0.0018041294,0.0028822908,0.0193025506,0.1940744809,0.0,0.0,0.0082094891,0.0023037406,0.0128643965]},"3":{"Abstract":"Many application domains deal with multi-variate data that consist of both categorical and numerical information. Small-multiple displays are a powerful concept for comparing such data by juxtaposition. For comparison by overlay or by explicit encoding of computed differences, however, a specification of references is necessary. In this paper, we present a formal model for defining semantically meaningful comparisons between many categories in a small-multiple display. Based on pivotized data that are hierarchically partitioned by the categories assigned to the x and y axis of the display, we propose two alternatives for structure-based comparison within this hierarchy. With an absolute reference specification, categories are compared to a fixed reference category. With a relative reference specification, in contrast, a semantic ordering of the categories is considered when comparing them either to the previous or subsequent category each. Both reference specifications can be defined at multiple levels of the hierarchy (including aggregated summaries), enabling a multitude of useful comparisons. We demonstrate the general applicability of our model in several application examples using different visualizations that compare data by overlay or explicit encoding of differences.","Authors":"Kehrer, J.;Piringer, H.;Berger, W.;Groller, E.","Clusters":"CategoricalDataAndTechniques;ComparisonComparativeVisualizationAndSimilarity;VisualEncodingAndLayoutGeneral;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2013.122","Keywords":"trellis displays;categorical data;comparative visualization;small multiples","Title":"A Model for Structure-Based Comparison of Many Categories in Small-Multiple Displays","type":"new","Vector":[0.0,0.0312492554,0.0004008566,0.0009004693,0.0,0.0,0.0085069653,0.0378227503,0.0,0.0045925432,0.0,0.0,0.0085805002,0.0131560829,0.001252888,0.0005206263,0.0026794724,0.0637305505,0.0,0.0207965063]},"4":{"Abstract":"We present an integrated camera motion design and path generation system for building volume data animations. Creating animations is an essential task in presenting complex scientific visualizations. Existing visualization systems use an established animation function based on keyframes selected by the user. This approach is limited in providing the optimal in-between views of the data. Alternatively, computer graphics and virtual reality camera motion planning is frequently focused on collision free movement in a virtual walkthrough. For semi-transparent, fuzzy, or blobby volume data the collision free objective becomes insufficient. Here, we provide a set of essential criteria focused on computing camera paths to establish effective animations of volume data. Our dynamic multi-criteria solver coupled with a force-directed routing algorithm enables rapid generation of camera paths. Once users review the resulting animation and evaluate the camera motion, they are able to determine how each criterion impacts path generation. In this paper, we demonstrate how incorporating this animation approach with an interactive volume visualization system reduces the effort in creating context-aware and coherent animations. This frees the user to focus on visualization tasks with the objective of gaining additional insight from the volume data.","Authors":"Wei-Hsien Hsu;Yubo Zhang;Kwan-Liu Ma","Clusters":"AnimationAndMotion;CamerasCameraViewsAndProjections;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2013.123","Keywords":"animation;visualization;volume rendering;camera motion planning","Title":"A Multi-Criteria Approach to Camera Motion Design for Volume Data Animation","type":"new","Vector":[0.0120615996,0.0428779103,0.0,0.0,0.0,0.0159464702,0.0,0.0,0.0437114379,0.0,0.117166173,0.0,0.0181308268,0.0048310863,0.0030028378,0.0145686373,0.0,0.0,0.0,0.0984751219]},"5":{"Abstract":"The considerable previous work characterizing visualization usage has focused on low-level tasks or interactions and high-level tasks, leaving a gap between them that is not addressed. This gap leads to a lack of distinction between the ends and means of a task, limiting the potential for rigorous analysis. We contribute a multi-level typology of visualization tasks to address this gap, distinguishing why and how a visualization task is performed, as well as what the task inputs and outputs are. Our typology allows complex tasks to be expressed as sequences of interdependent simpler tasks, resulting in concise and flexible descriptions for tasks of varying complexity and scope. It provides abstract rather than domain-specific descriptions of tasks, so that useful comparisons can be made between visualization systems targeted at different application domains. This descriptive power supports a level of analysis required for the generation of new designs, by guiding the translation of domain-specific problems into abstract tasks, and for the qualitative evaluation of visualization usage. We demonstrate the benefits of our approach in a detailed case study, comparing task descriptions from our typology to those derived from related work. We also discuss the similarities and differences between our typology and over two dozen extant classification systems and theoretical frameworks from the literatures of visualization, human-computer interaction, information retrieval, communications, and cartography.","Authors":"Brehmer, M.;Munzner, T.","Clusters":"QualitativeEvaluation;TasksTaskRequirementsAnalysis;VisualizationTheoryModelsAndMethods","DOI":"10.1109\/TVCG.2013.124","Keywords":"qualitative evaluation;typology;task and requirements analysis;visualization models","Title":"A Multi-Level Typology of Abstract Visualization Tasks","type":"new","Vector":[0.0,0.0222453963,0.0,0.0,0.0006463526,0.0,0.0398865231,0.0004960881,0.0050420259,0.01085921,0.0,0.0340619651,0.0,0.0651020139,0.0,0.0,0.0104983374,0.0562090755,0.0096259137,0.0100050336]},"6":{"Abstract":"Regression models play a key role in many application domains for analyzing or predicting a quantitative dependent variable based on one or more independent variables. Automated approaches for building regression models are typically limited with respect to incorporating domain knowledge in the process of selecting input variables (also known as feature subset selection). Other limitations include the identification of local structures, transformations, and interactions between variables. The contribution of this paper is a framework for building regression models addressing these limitations. The framework combines a qualitative analysis of relationship structures by visualization and a quantification of relevance for ranking any number of features and pairs of features which may be categorical or continuous. A central aspect is the local approximation of the conditional target distribution by partitioning 1D and 2D feature domains into disjoint regions. This enables a visual investigation of local patterns and largely avoids structural assumptions for the quantitative ranking. We describe how the framework supports different tasks in model building (e.g., validation and comparison), and we present an interactive workflow for feature subset selection. A real-world case study illustrates the step-wise identification of a five-dimensional model for natural gas consumption. We also report feedback from domain experts after two months of deployment in the energy sector, indicating a significant effort reduction for building and improving regression models.","Authors":"Muhlbacher, T.;Piringer, H.","Clusters":"AlgorithmicPatternFeatureDetectionTracking;KnowledgeDiscovery;MachineLearningAndStatistics;SegmentationAndClassification;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2013.125","Keywords":"regression;data partitioning;guided visualization;feature selection;visual knowledge discovery;model building","Title":"A Partition-Based Framework for Building and Validating Regression Models","type":"new","Vector":[0.0,0.0231517005,0.0071067962,0.0002885109,0.0,0.003823419,0.0227672814,0.0099347921,0.0082753126,0.0355457692,0.0,0.0077601867,0.0,0.0209664225,0.0,0.012984011,0.0,0.0995520992,0.0262351461,0.0]},"7":{"Abstract":"We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.","Authors":"Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.","Clusters":"EvaluationGeneral","DOI":"10.1109\/TVCG.2013.126","Keywords":"validation;information visualization;scientific visualization;visualization;systematic review;evaluation","Title":"A Systematic Review on the Practice of Evaluating Visualization","type":"new","Vector":[0.0,0.0,0.0,0.0073710106,0.0,0.0030105231,0.0039949634,0.0043972358,0.0,0.0068288318,0.0,0.0085398111,0.0002189498,0.1755980815,0.0024149407,0.0062863226,0.0087824327,0.0105374254,0.0138959863,0.0]},"8":{"Abstract":"We present a framework for acuity-driven visualization of super-high resolution image data on gigapixel displays. Tiled display walls offer a large workspace that can be navigated physically by the user. Based on head tracking information, the physical characteristics of the tiled display and the formulation of visual acuity, we guide an out-of-core gigapixel rendering scheme by delivering high levels of detail only in places where it is perceivable to the user. We apply this principle to gigapixel image rendering through adaptive level of detail selection. Additionally, we have developed an acuity-driven tessellation scheme for high-quality Focus-and-Context (F+C) lenses that significantly reduces visual artifacts while accurately capturing the underlying lens function. We demonstrate this framework on the Reality Deck, an immersive gigapixel display. We present the results of a user study designed to quantify the impact of our acuity-driven rendering optimizations in the visual exploration process. We discovered no evidence suggesting a difference in search task performance between our framework and naive rendering of gigapixel resolution data, while realizing significant benefits in terms of data transfer overhead. Additionally, we show that our acuity-driven tessellation scheme offers substantially increased frame rates when compared to naive pre-tessellation, while providing indistinguishable image quality.","Authors":"Papadopoulos, C.;Kaufman, A.","Clusters":"FocusContextTechniques;LargeAndHighResDisplays;Perception","DOI":"10.1109\/TVCG.2013.127","Keywords":"gigapixel visualization;focus+context;gigapixel display;visual acuity;reality deck","Title":"Acuity-Driven Gigapixel Visualization","type":"new","Vector":[0.0046963407,0.0064967139,0.0264134234,0.0,0.0679335733,0.0,0.0020588329,0.0,0.0001303649,0.0,0.0258223537,0.0006028111,0.0231226405,0.0241694545,0.0027557557,0.0028971657,0.0006382951,0.0189803973,0.0168166305,0.0128934969]},"9":{"Abstract":"We present a new efficient and scalable method for the high quality reconstruction of the flow map from sparse samples. The flow map describes the transport of massless particles along the flow. As such, it is a fundamental concept in the analysis of transient flow phenomena and all so-called Lagrangian flow visualization techniques require its approximation. The flow map is generally obtained by integrating a dense 1D, 2D, or 3D set of particles across the domain of definition of the flow. Despite its embarrassingly parallel nature, this computation creates a performance bottleneck in the analysis of large-scale datasets that existing adaptive techniques alleviate only partially. Our iterative approximation method significantly improves upon the state of the art by precisely modeling the flow behavior around automatically detected geometric structures embedded in the flow, thus effectively restricting the sampling effort to interesting regions. Our data reconstruction is based on a modified version of Sibson's scattered data interpolation and allows us at each step to offer an intermediate dense approximation of the flow map and to seamlessly integrate regions that will be further refined in subsequent steps. We present a quantitative and qualitative evaluation of our method on different types of flow datasets and offer a detailed comparison with existing techniques.","Authors":"Barakat, S.S.;Tricoche, X.","Clusters":"AdaptiveProcessingAndRefinement;FlowVisualizationDataAndTechniques;GraphNetworkDataAndTechniques;Interpolation;ParallelSystemsAndParallelProcessing;Sampling","DOI":"10.1109\/TVCG.2013.128","Keywords":"edge features;lagrangian flow visualization;adaptive refinement;parallel reconstruction;sparse sampling;flow map;scattered data interpolation","Title":"Adaptive Refinement of the Flow Map Using Sparse Samples","type":"new","Vector":[0.0,0.0030835507,0.0176935851,0.0061525796,0.0,0.1887351238,0.0050534348,0.0309794984,0.004746909,0.0064929239,0.0,0.006135539,0.0133443541,0.0,0.0,0.08189984,0.0007937386,0.0011344365,0.0103785416,0.0007810339]},"10":{"Abstract":"We present ambient scattering as a preintegration method for scattering on mesoscopic scales in direct volume rendering. Far-range scattering effects usually provide negligible contributions to a given location due to the exponential attenuation with increasing distance. This motivates our approach to preintegrating multiple scattering within a finite spherical region around any given sample point. To this end, we solve the full light transport with a Monte-Carlo simulation within a set of spherical regions, where each region may have different material parameters regarding anisotropy and extinction. This precomputation is independent of the data set and the transfer function, and results in a small preintegration table. During rendering, the look-up table is accessed for each ray sample point with respect to the viewing direction, phase function, and material properties in the spherical neighborhood of the sample. Our rendering technique is efficient and versatile because it readily fits in existing ray marching algorithms and can be combined with local illumination and volumetric ambient occlusion. It provides interactive volumetric scattering and soft shadows, with interactive control of the transfer function, anisotropy parameter of the phase function, lighting conditions, and viewpoint. A GPU implementation demonstrates the benefits of ambient scattering for the visualization of different types of data sets, with respect to spatial perception, high-quality illumination, translucency, and rendering speed.","Authors":"Ament, M.;Sadlo, F.;Weiskopf, D.","Clusters":"Illumination;Rendering;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2013.129","Keywords":"gradient-free shading;volume illumination;direct volume rendering;preintegrated light transport;ambient scattering","Title":"Ambient Volume Scattering","type":"new","Vector":[0.0014070227,0.0,0.0,0.0004640097,0.0030047767,0.0057634175,0.0,0.0,0.0817291723,0.0,0.007585439,0.0,0.0330840757,0.0140043012,0.0,0.0103296017,0.0,0.0,0.0,0.0]},"11":{"Abstract":"Proposals to establish a 'science of interaction' have been forwarded from Information Visualization and Visual Analytics, as well as Cartography, Geovisualization, and GIScience. This paper reports on two studies to contribute to this call for an interaction science, with the goal of developing a functional taxonomy of interaction primitives for map-based visualization. A semi-structured interview study first was conducted with 21 expert interactive map users to understand the way in which map-based visualizations currently are employed. The interviews were transcribed and coded to identify statements representative of either the task the user wished to accomplish (i.e., objective primitives) or the interactive functionality included in the visualization to achieve this task (i.e., operator primitives). A card sorting study then was conducted with 15 expert interactive map designers to organize these example statements into logical structures based on their experience translating client requests into interaction designs. Example statements were supplemented with primitive definitions in the literature and were separated into two sorting exercises: objectives and operators. The objective sort suggested five objectives that increase in cognitive sophistication (identify, compare, rank, associate, & delineate), but exhibited a large amount of variation across participants due to consideration of broader user goals (procure, predict, & prescribe) and interaction operands (space-alone, attributes-in-space, & space-in-time; elementary & general). The operator sort suggested five enabling operators (import, export, save, edit, & annotate) and twelve work operators (reexpress, arrange, sequence, resymbolize, overlay, pan, zoom, reproject, search, filter, retrieve, & calculate). This taxonomy offers an empirically-derived and ecologically-valid structure to inform future research and design on interaction.","Authors":"Roth, R.E.","Clusters":"GeographyGeospatialVisCartographyTerrainVis;InteractionTechniquesGeneral;Maps","DOI":"10.1109\/TVCG.2013.130","Keywords":"interaction primitives;interactive maps;science of interaction;geovisualization;interaction","Title":"An Empirically-Derived Taxonomy of Interaction Primitives for Interactive Cartography and Geovisualization","type":"new","Vector":[0.0,0.0,0.0042686213,0.0,0.0,0.0009396864,0.0449639384,0.0,0.0,0.0,0.0,0.005830246,0.0009102952,0.1416220852,0.0,0.0,0.0003301066,0.0509246104,0.0,0.0]},"12":{"Abstract":"We describe and demonstrate an extensible framework that supports data exploration and provenance in the context of Human Terrain Analysis (HTA). Working closely with defence analysts we extract requirements and a list of features that characterise data analysed at the end of the HTA chain. From these, we select an appropriate non-classified data source with analogous features, and model it as a set of facets. We develop ProveML, an XML-based extension of the Open Provenance Model, using these facets and augment it with the structures necessary to record the provenance of data, analytical process and interpretations. Through an iterative process, we develop and refine a prototype system for Human Terrain Visual Analytics (HTVA), and demonstrate means of storing, browsing and recalling analytical provenance and process through analytic bookmarks in ProveML. We show how these bookmarks can be combined to form narratives that link back to the live data. Throughout the process, we demonstrate that through structured workshops, rapid prototyping and structured communication with intelligence analysts we are able to establish requirements, and design schema, techniques and tools that meet the requirements of the intelligence community. We use the needs and reactions of defence analysts in defining and steering the methods to validate the framework.","Authors":"Walker, R.;Slingsby, A.;Dykes, J.;Kai Xu;Wood, J.;Nguyen, P.H.;Stephens, D.;Wong, B.L.W.;Yongjun Zheng","Clusters":"GeographyGeospatialVisCartographyTerrainVis;InternetWebVisualizationForTheMasses;ProvenanceAndHistory;Storytelling;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2013.132","Keywords":"human terrain analysis;provenance;bookmarks;framework;narrative","Title":"An Extensible Framework for Provenance in Human Terrain Visual Analytics","type":"new","Vector":[0.0,0.0,0.0010134135,0.0,0.0,0.0,0.0,0.0,0.0,0.0774633728,0.0,0.1319787412,0.0,0.0432768442,0.0,0.0,0.0157835581,0.0197675116,0.0,0.0510659223]},"13":{"Abstract":"We present a novel area-preservation mapping\/flattening method using the optimal mass transport technique, based on the Monge-Brenier theory. Our optimal transport map approach is rigorous and solid in theory, efficient and parallel in computation, yet general for various applications. By comparison with the conventional Monge-Kantorovich approach, our method reduces the number of variables from O(n2) to O(n), and converts the optimal mass transport problem to a convex optimization problem, which can now be efficiently carried out by Newton's method. Furthermore, our framework includes the area weighting strategy that enables users to completely control and adjust the size of areas everywhere in an accurate and quantitative way. Our method significantly reduces the complexity of the problem, and improves the efficiency, flexibility and scalability during visualization. Our framework, by combining conformal mapping and optimal mass transport mapping, serves as a powerful tool for a broad range of applications in visualization and graphics, especially for medical imaging. We provide a variety of experimental results to demonstrate the efficiency, robustness and efficacy of our novel framework.","Authors":"Xin Zhao;Zhengyu Su;Gu, X.;Kaufman, A.;Jian Sun;Jie Gao;Feng Luo","Clusters":"ApplicationsGeneralAndOther;GeometricModeling;Maps;SurfaceRelatedDataAndTechniques","DOI":"10.1109\/TVCG.2013.135","Keywords":"monge-brenier theory;surface flattening;area-preservation mapping;visualization and graphics applications;optimal transport map","Title":"Area-Preservation Mapping using Optimal Mass Transport","type":"new","Vector":[0.0007475014,0.0003462855,0.02598872,0.0056880671,0.0169595135,0.0231921305,0.0068219923,0.0200812503,0.0192159032,0.0027692748,0.008102651,0.0017274082,0.0033239741,0.0065600126,0.003266357,0.0226756327,0.0011348793,0.0077182409,0.0020433648,0.0]},"14":{"Abstract":"Domain-specific database applications tend to contain a sizable number of table-, form-, and report-style views that must each be designed and maintained by a software developer. A significant part of this job is the necessary tweaking of low-level presentation details such as label placements, text field dimensions, list or table styles, and so on. In this paper, we present a horizontally constrained layout management algorithm that automates the display of structured hierarchical data using the traditional visual idioms of hand-designed database UIs: tables, multi-column forms, and outline-style indented lists. We compare our system with pure outline and nested table layouts with respect to space efficiency and readability, the latter with an online user study on 27 subjects. Our layouts are 3.9 and 1.6 times more compact on average than outline layouts and horizontally unconstrained table layouts, respectively, and are as readable as table layouts even for large datasets.","Authors":"Bakke, E.;Karger, D.R.;Miller, R.C.","Clusters":"HierarchicalTreeDataAndTechniques;TabularDataAndTechniques;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2013.137","Keywords":"hierarchy data;nested relations;tabular data;layout management","Title":"Automatic Layout of Structured Hierarchical Reports","type":"new","Vector":[0.0,0.1207880089,0.0,0.0,0.0007755087,0.0,0.0042518604,0.002257371,0.0,0.0001930256,0.0,0.026125497,0.002582148,0.0194945632,0.0,0.0,0.0,0.0338039257,0.0,0.0047725251]},"15":{"Abstract":"Numerical ensemble forecasting is a powerful tool that drives many risk analysis efforts and decision making tasks. These ensembles are composed of individual simulations that each uniquely model a possible outcome for a common event of interest: e.g., the direction and force of a hurricane, or the path of travel and mortality rate of a pandemic. This paper presents a new visual strategy to help quantify and characterize a numerical ensemble's predictive uncertainty: i.e., the ability for ensemble constituents to accurately and consistently predict an event of interest based on ground truth observations. Our strategy employs a Bayesian framework to first construct a statistical aggregate from the ensemble. We extend the information obtained from the aggregate with a visualization strategy that characterizes predictive uncertainty at two levels: at a global level, which assesses the ensemble as a whole, as well as a local level, which examines each of the ensemble's constituents. Through this approach, modelers are able to better assess the predictive strengths and weaknesses of the ensemble as a whole, as well as individual models. We apply our method to two datasets to demonstrate its broad applicability.","Authors":"Gosink, L.;Bensema, K.;Pulsipher, T.;Obermaier, H.;Henry, M.;Childs, H.;Joy, K.I.","Clusters":"MachineLearningAndStatistics;Simulation;UncertaintyTechniquesAndVisualization","DOI":"10.1109\/TVCG.2013.138","Keywords":"uncertainty visualization;statistical visualization;numerical ensembles","Title":"Characterizing and Visualizing Predictive Uncertainty in Numerical Ensembles Through Bayesian Model Averaging","type":"new","Vector":[0.0,0.009666871,0.0,0.0,0.0,0.0,0.0006848667,0.0219060797,0.0024480154,0.2574271023,0.0,0.0,0.0,0.0,0.0024526222,0.0076123087,0.0029088411,0.0,0.0042610432,0.0213119703]},"16":{"Abstract":"We propose a new colon flattening algorithm that is efficient, shape-preserving, and robust to topological noise. Unlike previous approaches, which require a mandatory topological denoising to remove fake handles, our algorithm directly flattens the colon surface without any denoising. In our method, we replace the original Euclidean metric of the colon surface with a heat diffusion metric that is insensitive to topological noise. Using this heat diffusion metric, we then solve a Laplacian equation followed by an integration step to compute the final flattening. We demonstrate that our method is shape-preserving and the shape of the polyps are well preserved. The flattened colon also provides an efficient way to enhance the navigation and inspection in virtual colonoscopy. We further show how the existing colon registration pipeline is made more robust by using our colon flattening. We have tested our method on several colon wall surfaces and the experimental results demonstrate the robustness and the efficiency of our method.","Authors":"Gurijala, K.C.;Rui Shi;Wei Zeng;Xianfeng Gu;Kaufman, A.","Clusters":"BiomedicalScienceAndMedicine;PhysicsAndPhysicalSciences;ShapeRelatedTechniques;TopologyBasedTechniques;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2013.139","Keywords":"volume rendering;colon flattening;shape-preserving mapping;virtual colonoscopy;heat diffusion;topological noise","Title":"Colon Flattening Using Heat Diffusion Riemannian Metric","type":"new","Vector":[0.000149058,0.0,0.050540918,0.0136405227,0.0,0.0184806769,0.0029787631,0.0,0.023506018,0.0001662023,0.0033891037,0.0,0.0283462613,0.0,0.0344359198,0.0022425986,0.0006009632,0.0060844271,0.0,0.0]},"17":{"Abstract":"Sets of simulation runs based on parameter and model variation, so-called ensembles, are increasingly used to model physical behaviors whose parameter space is too large or complex to be explored automatically. Visualization plays a key role in conveying important properties in ensembles, such as the degree to which members of the ensemble agree or disagree in their behavior. For ensembles of time-varying vector fields, there are numerous challenges for providing an expressive comparative visualization, among which is the requirement to relate the effect of individual flow divergence to joint transport characteristics of the ensemble. Yet, techniques developed for scalar ensembles are of little use in this context, as the notion of transport induced by a vector field cannot be modeled using such tools. We develop a Lagrangian framework for the comparison of flow fields in an ensemble. Our techniques evaluate individual and joint transport variance and introduce a classification space that facilitates incorporation of these properties into a common ensemble visualization. Variances of Lagrangian neighborhoods are computed using pathline integration and Principal Components Analysis. This allows for an inclusion of uncertainty measurements into the visualization and analysis approach. Our results demonstrate the usefulness and expressiveness of the presented method on several practical examples.","Authors":"Hummel, M.;Obermaier, H.;Garth, C.;Joy, K.I.","Clusters":"ComparisonComparativeVisualizationAndSimilarity;DimensionalityReduction;FlowVisualizationDataAndTechniques;MachineLearningAndStatistics;Simulation;TimeseriesTimeVaryingDataAndTechniques","DOI":"10.1109\/TVCG.2013.141","Keywords":"time-varying;variance;comparison;visualization;flow field;lagrangian;principal component analysis;ensemble","Title":"Comparative Visual Analysis of Lagrangian Transport in CFD Ensembles","type":"new","Vector":[0.0,0.0,0.0,0.014593054,0.0009708013,0.1031761577,0.0127355799,0.0,0.0062909459,0.0701377369,0.0,0.0,0.0,0.0,0.0,0.1093020209,0.0,0.0109179536,0.0,0.0066299147]},"18":{"Abstract":"This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.","Authors":"Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.;Pfister, H.;Hadwiger, M.","Clusters":"KnowledgeDiscovery;LargeScaleDataAndScalability;NeurosciencesAndBrainVisualization;QueriesAndSearch","DOI":"10.1109\/TVCG.2013.142","Keywords":"query algebra;petascale volume analysis;neuroscience;connectomics;visual knowledge discovery","Title":"ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data","type":"new","Vector":[0.0,0.0025047881,0.0,0.0,0.0,0.0,0.0,0.0078987998,0.0226651575,0.0,0.0,0.0016769315,0.0144957469,0.0,0.0169850512,0.0,0.0136563303,0.1128307658,0.0287343285,0.0074201869]},"19":{"Abstract":"Ensembles of numerical simulations are used in a variety of applications, such as meteorology or computational solid mechanics, in order to quantify the uncertainty or possible error in a model or simulation. Deriving robust statistics and visualizing the variability of an ensemble is a challenging task and is usually accomplished through direct visualization of ensemble members or by providing aggregate representations such as an average or pointwise probabilities. In many cases, the interesting quantities in a simulation are not dense fields, but are sets of features that are often represented as thresholds on physical or derived quantities. In this paper, we introduce a generalization of boxplots, called contour boxplots, for visualization and exploration of ensembles of contours or level sets of functions. Conventional boxplots have been widely used as an exploratory or communicative tool for data analysis, and they typically show the median, mean, confidence intervals, and outliers of a population. The proposed contour boxplots are a generalization of functional boxplots, which build on the notion of data depth. Data depth approximates the extent to which a particular sample is centrally located within its density function. This produces a center-outward ordering that gives rise to the statistical quantities that are essential to boxplots. Here we present a generalization of functional data depth to contours and demonstrate methods for displaying the resulting boxplots for two-dimensional simulation data in weather forecasting and computational fluid dynamics.","Authors":"Whitaker, R.T.;Mirzargar, M.;Kirby, R.M.","Clusters":"ChartsDiagramsPlots;MachineLearningAndStatistics;Simulation;UncertaintyTechniquesAndVisualization;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2013.143","Keywords":"uncertainty visualization;order statistics;band depth;boxplots;ensemble visualization","Title":"Contour Boxplots: A Method for Characterizing Uncertainty in Feature Sets from Simulation Ensembles","type":"new","Vector":[0.0007842019,0.0,0.0,0.0,0.0036012204,0.0005922522,0.0069552255,0.0825528784,0.011675675,0.1862360037,0.0,0.0001066838,0.0,0.0074781844,0.0,0.0006234183,0.0,0.0209553015,0.0,0.0014640697]},"20":{"Abstract":"Ensemble run simulations are becoming increasingly widespread. In this work, we couple particle advection with pathline analysis to visualize and reveal the differences among the flow fields of ensemble runs. Our method first constructs a variation field using a Lagrangian-based distance metric. The variation field characterizes the variation between vector fields of the ensemble runs, by extracting and visualizing the variation of pathlines within ensemble. Parallelism in a MapReduce style is leveraged to handle data processing and computing at scale. Using our prototype system, we demonstrate how scientists can effectively explore and investigate differences within ensemble simulations.","Authors":"Hanqi Guo;Xiaoru Yuan;Jian Huang;Xiaomin Zhu","Clusters":"FlowVisualizationDataAndTechniques;ParallelSystemsAndParallelProcessing;Simulation","DOI":"10.1109\/TVCG.2013.144","Keywords":"field line advection;ensemble analysis;parallel processing","Title":"Coupled Ensemble Flow Line Advection and Analysis","type":"new","Vector":[0.0006626575,0.0120565574,0.0,0.0,0.0066423361,0.1091407479,0.0038439387,0.0046719626,0.0,0.1210547903,0.0,0.0003461127,0.0041076313,0.0042788045,0.0,0.0606528932,0.00966516,0.0135238731,0.0269720589,0.0096877118]},"21":{"Abstract":"We enhance a user-centered design process with techniques that deliberately promote creativity to identify opportunities for the visualization of data generated by a major energy supplier. Visualization prototypes developed in this way prove effective in a situation whereby data sets are largely unknown and requirements open - enabling successful exploration of possibilities for visualization in Smart Home data analysis. The process gives rise to novel designs and design metaphors including data sculpting. It suggests: that the deliberate use of creativity techniques with data stakeholders is likely to contribute to successful, novel and effective solutions; that being explicit about creativity may contribute to designers developing creative solutions; that using creativity techniques early in the design process may result in a creative approach persisting throughout the process. The work constitutes the first systematic visualization design for a data rich source that will be increasingly important to energy suppliers and consumers as Smart Meter technology is widely deployed. It is novel in explicitly employing creativity techniques at the requirements stage of visualization design and development, paving the way for further use and study of creativity methods in visualization design.","Authors":"Goodwin, S.;Dykes, J.;Jones, S.;Dillingham, I.;Dove, G.;Duffy, A.;Kachkaev, A.;Slingsby, A.;Wood, J.","Clusters":"ApplicationsGeneralAndOther;DesignMethodologiesAndInteractionDesign;EarthSpaceAndEnvironmentalSciences","DOI":"10.1109\/TVCG.2013.145","Keywords":"smart home;energy consumption;creativity techniques;visualization;user-centered design","Title":"Creative User-Centered Visualization Design for Energy Analysts and Modelers","type":"new","Vector":[0.0,0.0,0.0001997668,0.0,0.0,0.0012922061,0.0002547316,0.0013933878,0.0012228953,0.0042536066,0.0,0.0284342968,0.0011130377,0.1052069087,0.0,0.0067682729,0.0083206099,0.0135169912,0.0015698633,0.0442943706]},"22":{"Abstract":"We present a visual analytics solution designed to address prevalent issues in the area of Operational Decision Management (ODM). In ODM, which has its roots in Artificial Intelligence (Expert Systems) and Management Science, it is increasingly important to align business decisions with business goals. In our work, we consider decision models (executable models of the business domain) as ontologies that describe the business domain, and production rules that describe the business logic of decisions to be made over this ontology. Executing a decision model produces an accumulation of decisions made over time for individual cases. We are interested, first, to get insight in the decision logic and the accumulated facts by themselves. Secondly and more importantly, we want to see how the accumulated facts reveal potential divergences between the reality as captured by the decision model, and the reality as captured by the executed decisions. We illustrate the motivation, added value for visual analytics, and our proposed solution and tooling through a business case from the car insurance industry.","Authors":"Broeksema, B.;Baudel, T.;Telea, A.;Crisafulli, P.","Clusters":"MachineLearningAndStatistics;SoftwareVisualization;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2013.146","Keywords":"program analysis;decision support systems;model validation and analysis;multivariate statistics","Title":"Decision Exploration Lab: A Visual Analytics Solution for Decision Management","type":"new","Vector":[0.0,0.0000950097,0.000752726,0.0,0.0,0.0,0.0018371081,0.0013242742,0.0,0.0096374206,0.0,0.0251657434,0.0,0.0363868157,0.0,0.0,0.0085217195,0.0881773908,0.0,0.0213352131]},"23":{"Abstract":"We present an interface for exploring large design spaces as encountered in simulation-based engineering, design of visual effects, and other tasks that require tuning parameters of computationally-intensive simulations and visually evaluating results. The goal is to enable a style of design with simulations that feels as-direct-as-possible so users can concentrate on creative design tasks. The approach integrates forward design via direct manipulation of simulation inputs (e.g., geometric properties, applied forces) in the same visual space with inverse design via 'tugging' and reshaping simulation outputs (e.g., scalar fields from finite element analysis (FEA) or computational fluid dynamics (CFD)). The interface includes algorithms for interpreting the intent of users' drag operations relative to parameterized models, morphing arbitrary scalar fields output from FEA and CFD simulations, and in-place interactive ensemble visualization. The inverse design strategy can be extended to use multi-touch input in combination with an as-rigid-as-possible shape manipulation to support rich visual queries. The potential of this new design approach is confirmed via two applications: medical device engineering of a vacuum-assisted biopsy device and visual effects design using a physically based flame simulation.","Authors":"Coffey, D.;Chi-Lun Lin;Erdman, A.G.;Keefe, D.F.","Clusters":"InteractionTechniquesGeneral;Simulation;VisualDesignDesignGuidelines","DOI":"10.1109\/TVCG.2013.147","Keywords":"multi-touch;design;simulation;direct manipulation","Title":"Design by Dragging: An Interface for Creative Forward and Inverse Design with Simulation Ensembles","type":"new","Vector":[0.0171857668,0.0050666226,0.0178447909,0.002032313,0.0028300392,0.0198462037,0.0,0.0085542625,0.0109079825,0.0035492843,0.0136748894,0.0,0.0042825637,0.0297470505,0.0,0.0310245756,0.0028857677,0.0365879474,0.0113350597,0.0302794647]},"24":{"Abstract":"Visualizing symmetric patterns in the data often helps the domain scientists make important observations and gain insights about the underlying experiment. Detecting symmetry in scalar fields is a nascent area of research and existing methods that detect symmetry are either not robust in the presence of noise or computationally costly. We propose a data structure called the augmented extremum graph and use it to design a novel symmetry detection method based on robust estimation of distances. The augmented extremum graph captures both topological and geometric information of the scalar field and enables robust and computationally efficient detection of symmetry. We apply the proposed method to detect symmetries in cryo-electron microscopy datasets and the experiments demonstrate that the algorithm is capable of detecting symmetry even in the presence of significant noise. We describe novel applications that use the detected symmetry to enhance visualization of scalar field data and facilitate their exploration.","Authors":"Thomas, D.M.;Natarajan, V.","Clusters":"AnalysisProcessGeneral;GraphNetworkDataAndTechniques;ScalarFieldDataTechniques;TopologyBasedTechniques;VisualPatternFeatureDetectionAndTracking","DOI":"10.1109\/TVCG.2013.148","Keywords":"data exploration;scalar field visualization;extremum graph;morse decomposition;symmetry detection","Title":"Detecting Symmetry in Scalar fields Using Augmented Extremum Graphs","type":"new","Vector":[0.0080217532,0.0,0.0231836522,0.011059962,0.0,0.0310619341,0.0070511869,0.0867166366,0.0233778969,0.0011269177,0.0,0.0,0.0,0.0096880224,0.0,0.0,0.0140589504,0.0005474323,0.0,0.0007632178]},"25":{"Abstract":"Visualization of dynamically changing networks (graphs) is a significant challenge for researchers. Previous work has experimentally compared animation, small multiples, and other techniques, and found trade-offs between these. One potential way to avoid such trade-offs is to combine previous techniques in a hybrid visualization. We present two taxonomies of visualizations of dynamic graphs: one of non-hybrid techniques, and one of hybrid techniques. We also describe a prototype, called DiffAni, that allows a graph to be visualized as a sequence of three kinds of tiles: diff tiles that show difference maps over some time interval, animation tiles that show the evolution of the graph over some time interval, and small multiple tiles that show the graph state at an individual time slice. This sequence of tiles is ordered by time and covers all time slices in the data. An experimental evaluation of DiffAni shows that our hybrid approach has advantages over non-hybrid techniques in certain cases.","Authors":"Rufiange, S.;McGuffin, M.J.","Clusters":"AnimationAndMotion;BiologyAndBioinformatics;ComparisonComparativeVisualizationAndSimilarity;DynamicDataAndTechniques;Taxonomies;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2013.149","Keywords":"dynamic networks;taxonomy;difference map;hybrid visualization;animation;evolution","Title":"DiffAni: Visualizing Dynamic Graphs with a Hybrid of Difference Maps and Animation","type":"new","Vector":[0.0002798914,0.0840301243,0.0,0.0002612307,0.0230077078,0.0,0.0010606256,0.0,0.0,0.0009732862,0.0,0.0,0.0011229318,0.0711633124,0.0,0.0050847392,0.0783295984,0.0,0.0035280691,0.026594858]},"26":{"Abstract":"For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node's dimensions or a subset of the parent node's data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions.","Authors":"Xiaoru Yuan;Donghao Ren;Zuchao Wang;Cong Guo","Clusters":"DimensionalityReduction;HierarchicalTreeDataAndTechniques;InteractionTechniquesGeneral;MatrixRelatedTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques","DOI":"10.1109\/TVCG.2013.150","Keywords":"user interaction;high-dimensional data;hierarchy visualization;matrix;sub-dimensional space;tree;subspace","Title":"Dimension Projection Matrix\/Tree: Interactive Subspace Visual Exploration and Analysis of High Dimensional Data","type":"new","Vector":[0.0,0.1100615438,0.0,0.0,0.0,0.0,0.1389321734,0.0,0.0,0.0,0.0,0.0,0.0047717547,0.0,0.0022296011,0.0,0.0075709049,0.1255898744,0.0,0.0]},"27":{"Abstract":"We explore the effectiveness of visualizing dense directed graphs by replacing individual edges with edges connected to 'modules'-or groups of nodes-such that the new edges imply aggregate connectivity. We only consider techniques that offer a lossless compression: that is, where the entire graph can still be read from the compressed version. The techniques considered are: a simple grouping of nodes with identical neighbor sets; Modular Decomposition which permits internal structure in modules and allows them to be nested; and Power Graph Analysis which further allows edges to cross module boundaries. These techniques all have the same goal-to compress the set of edges that need to be rendered to fully convey connectivity-but each successive relaxation of the module definition permits fewer edges to be drawn in the rendered graph. Each successive technique also, we hypothesize, requires a higher degree of mental effort to interpret. We test this hypothetical trade-off with two studies involving human participants. For Power Graph Analysis we propose a novel optimal technique based on constraint programming. This enables us to explore the parameter space for the technique more precisely than could be achieved with a heuristic. Although applicable to many domains, we are motivated by-and discuss in particular-the application to software dependency analysis.","Authors":"Dwyer, T.;Riche, N.H.;Marriott, K.;Mears, C.","Clusters":"GraphNetworkDataAndTechniques","DOI":"10.1109\/TVCG.2013.151","Keywords":"networks;modular decomposition;directed graphs;power graph analysis","Title":"Edge Compression Techniques for Visualization of Dense Directed Graphs","type":"new","Vector":[0.0,0.0854121356,0.00904135,0.0,0.0,0.0,0.0053708864,0.0,0.0,0.0,0.0,0.0,0.0,0.1198328887,0.0008194629,0.0,0.0398471048,0.0,0.086108867,0.0]},"28":{"Abstract":"Histograms computed from local regions are commonly used in many visualization applications, and allowing the user to query histograms interactively in regions of arbitrary locations and sizes plays an important role in feature identification and tracking. Computing histograms in regions with arbitrary location and size, nevertheless, can be time consuming for large data sets since it involves expensive I\/O and scan of data elements. To achieve both performance- and storage-efficient query of local histograms, we present a new algorithm called WaveletSAT, which utilizes integral histograms, an extension of the summed area tables (SAT), and discrete wavelet transform (DWT). Similar to SAT, an integral histogram is the histogram computed from the area between each grid point and the grid origin, which can be be pre-computed to support fast query. Nevertheless, because one histogram contains multiple bins, it will be very expensive to store one integral histogram at each grid point. To reduce the storage cost for large integral histograms, WaveletSAT treats the integral histograms of all grid points as multiple SATs, each of which can be converted into a sparse representation via DWT, allowing the reconstruction of axis-aligned region histograms of arbitrary sizes from a limited number of wavelet coefficients. Besides, we present an efficient wavelet transform algorithm for SATs that can operate on each grid point separately in logarithmic time complexity, which can be extended to parallel GPU-based implementation. With theoretical and empirical demonstration, we show that WaveletSAT can achieve fast preprocessing and smaller storage overhead than the conventional integral histogram approach with close query performance.","Authors":"Teng-Yok Lee;Han-Wei Shen","Clusters":"ChartsDiagramsPlots;NumericalMethodsMathematics","DOI":"10.1109\/TVCG.2013.152","Keywords":"integral histograms;discrete wavelet transform;waveletsat","Title":"Efficient Local Statistical Analysis via Integral Histograms with Discrete Wavelet Transform","type":"new","Vector":[0.0,0.0,0.0,0.0114326537,0.0,0.0010109343,0.0,0.0059935211,0.0048128339,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0661830974,0.2408928465,0.0]},"29":{"Abstract":"To verify cluster separation in high-dimensional data, analysts often reduce the data with a dimension reduction (DR) technique, and then visualize it with 2D Scatterplots, interactive 3D Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of providing guidance between these visual encoding choices, we conducted an empirical data study in which two human coders manually inspected a broad set of 816 scatterplots derived from 75 datasets, 4 DR techniques, and the 3 previously mentioned scatterplot techniques. Each coder scored all color-coded classes in each scatterplot in terms of their separability from other classes. We analyze the resulting quantitative data with a heatmap approach, and qualitatively discuss interesting scatterplot examples. Our findings reveal that 2D scatterplots are often 'good enough', that is, neither SPLOM nor interactive 3D adds notably more cluster separability with the chosen DR technique. If 2D is not good enough, the most promising approach is to use an alternative DR technique in 2D. Beyond that, SPLOM occasionally adds additional value, and interactive 3D rarely helps but often hurts in terms of poorer class separation and usability. We summarize these results as a workflow model and implications for design. Our results offer guidance to analysts during the DR exploration process.","Authors":"Sedlmair, M.;Munzner, T.;Tory, M.","Clusters":"ChartsDiagramsPlots;DimensionalityReduction;QuantitativeEvaluation","DOI":"10.1109\/TVCG.2013.153","Keywords":"dimension reduction;scatterplot;quantitative study","Title":"Empirical Guidance on Scatterplot and Dimension Reduction Technique Choices","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0261314959,0.0042193075,0.0009256232,0.0006980447,0.0,0.0059385543,0.0,0.0174862455,0.0005534333,0.0,0.0,0.082235699,0.0052142592,0.0]},"30":{"Abstract":"Biological pathway maps are highly relevant tools for many tasks in molecular biology. They reduce the complexity of the overall biological network by partitioning it into smaller manageable parts. While this reduction of complexity is their biggest strength, it is, at the same time, their biggest weakness. By removing what is deemed not important for the primary function of the pathway, biologists lose the ability to follow and understand cross-talks between pathways. Considering these cross-talks is, however, critical in many analysis scenarios, such as judging effects of drugs. In this paper we introduce Entourage, a novel visualization technique that provides contextual information lost due to the artificial partitioning of the biological network, but at the same time limits the presented information to what is relevant to the analyst's task. We use one pathway map as the focus of an analysis and allow a larger set of contextual pathways. For these context pathways we only show the contextual subsets, i.e., the parts of the graph that are relevant to a selection. Entourage suggests related pathways based on similarities and highlights parts of a pathway that are interesting in terms of mapped experimental data. We visualize interdependencies between pathways using stubs of visual links, which we found effective yet not obtrusive. By combining this approach with visualization of experimental data, we can provide domain experts with a highly valuable tool. We demonstrate the utility of Entourage with case studies conducted with a biochemist who researches the effects of drugs on pathways. We show that the technique is well suited to investigate interdependencies between pathways and to analyze, understand, and predict the effect that drugs have on different cell types.","Authors":"Lex, A.;Partl, C.;Kalkofen, D.;Streit, M.;Gratzl, S.;Wassermann, A.M.;Schmalstieg, D.;Pfister, H.","Clusters":"BiologyAndBioinformatics;GraphNetworkDataAndTechniques;MolecularScienceAndChemistry;SetRelatedDataTechniques","DOI":"10.1109\/TVCG.2013.154","Keywords":"pathway visualization;subsets;biomolecular data;graph;biological networks","Title":"Entourage: Visualizing Relationships between Biological Pathways using Contextual Subsets","type":"new","Vector":[0.0209377721,0.0331103321,0.0,0.0,0.0,0.0,0.0,0.0120601504,0.0,0.0008222979,0.0042956164,0.003320709,0.0,0.0036710833,0.045029739,0.0,0.0404103921,0.0130133236,0.0,0.0056609241]},"31":{"Abstract":"Having effective visualizations of filesystem provenance data is valuable for understanding its complex hierarchical structure. The most common visual representation of provenance data is the node-link diagram. While effective for understanding local activity, the node-link diagram fails to offer a high-level summary of activity and inter-relationships within the data. We present a new tool, InProv, which displays filesystem provenance with an interactive radial-based tree layout. The tool also utilizes a new time-based hierarchical node grouping method for filesystem provenance data we developed to match the user's mental model and make data exploration more intuitive. We compared InProv to a conventional node-link based tool, Orbiter, in a quantitative evaluation with real users of filesystem provenance data including provenance data experts, IT professionals, and computational scientists. We also compared in the evaluation our new node grouping method to a conventional method. The results demonstrate that InProv results in higher accuracy in identifying system activity than Orbiter with large complex data sets. The results also show that our new time-based hierarchical node grouping method improves performance in both tools, and participants found both tools significantly easier to use with the new time-based node grouping method. Subjective measures show that participants found InProv to require less mental activity, less physical activity, less work, and is less stressful to use. Our study also reveals one of the first cases of gender differences in visualization; both genders had comparable performance with InProv, but women had a significantly lower average accuracy (56%) compared to men (70%) with Orbiter.","Authors":"Borkin, M.;Yeh, C.S.;Boyd, M.;Macko, P.;Gajos, K.;Seltzer, M.;Pfister, H.","Clusters":"GraphNetworkDataAndTechniques;HierarchicalTreeDataAndTechniques;HumanComputerInteractionHumanFactors;ProvenanceAndHistory;QuantitativeEvaluation","DOI":"10.1109\/TVCG.2013.155","Keywords":"quantitative evaluation;gender differences;graph\/network data;provenance data;hierarchy data","Title":"Evaluation of filesystem Provenance Visualization Tools","type":"new","Vector":[0.0,0.1206709549,0.0,0.0,0.0,0.0,0.0064678727,0.0,0.0,0.0,0.0,0.0,0.0,0.0942939007,0.0,0.0,0.0300967807,0.0,0.0,0.0]},"32":{"Abstract":"Conflicting results are reported in the literature on whether dynamic visualizations are more effective than static visualizations for learning and mastering 3-D tasks, and only a few investigations have considered the influence of the spatial abilities of the learners. In a study with 117 participants, we compared the benefit of static vs. dynamic visualization training tools on learners with different spatial abilities performing a typical 3-D task (specifically, creating orthographic projections of a 3-D object). We measured the spatial abilities of the participants using the Mental Rotation Test (MRT) and classified participants into two groups (high and low abilities) to examine how the participants' abilities predicted change in performance after training with static versus dynamic training tools. Our results indicate that: 1) visualization training programs can help learners to improve 3-D task performance, 2) dynamic visualizations provide no advantages over static visualizations that show intermediate steps, 3) training programs are more beneficial for individuals with low spatial abilities than for individuals with high spatial abilities, and 4) training individuals with high spatial abilities using dynamic visualizations provides little benefit.","Authors":"Froese, M.-E.;Tory, M.;Evans, G.-W.;Shrikhande, K.","Clusters":"ApplicationsGeneralAndOther;CamerasCameraViewsAndProjections;Cognition;EvaluationGeneral;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2013.156","Keywords":"orthographic projection;training;cad;3d visualization;spatial ability;evaluation","Title":"Evaluation of Static and Dynamic Visualization Training Approaches for Users with Different Spatial Abilities","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0003477065,0.2202056329,0.0,0.0,0.0,0.0,0.0,0.0]},"33":{"Abstract":"This paper introduces an approach to exploration and discovery in high-dimensional data that incorporates a user's knowledge and questions to craft sets of projection functions meaningful to them. Unlike most prior work that defines projections based on their statistical properties, our approach creates projection functions that align with user-specified annotations. Therefore, the resulting derived dimensions represent concepts defined by the user's examples. These especially crafted projection functions, or explainers, can help find and explain relationships between the data variables and user-designated concepts. They can organize the data according to these concepts. Sets of explainers can provide multiple perspectives on the data. Our approach considers tradeoffs in choosing these projection functions, including their simplicity, expressive power, alignment with prior knowledge, and diversity. We provide techniques for creating collections of explainers. The methods, based on machine learning optimization frameworks, allow exploring the tradeoffs. We demonstrate our approach on model problems and applications in text analysis.","Authors":"Gleicher, M.","Clusters":"AnalysisProcessGeneral;MachineLearningAndStatistics;SpaceRelatedSpatialDataAndTechniques","DOI":"10.1109\/TVCG.2013.157","Keywords":"high-dimensional spaces;exploration;support vector machine","Title":"Explainers: Expert Explorations with Crafted Projections","type":"new","Vector":[0.0,0.0,0.0034324818,0.0029581398,0.0,0.0,0.0169956261,0.0,0.0003570344,0.0070959023,0.0068258401,0.0259380702,0.0123050793,0.0140730411,0.0,0.0,0.0,0.1040380376,0.0046744443,0.0]},"34":{"Abstract":"Representation of molecular surfaces is a well established way to study the interaction of molecules. The state-of-theart molecular representation is the SES model, which provides a detailed surface visualization. Nevertheless, it is computationally expensive, so the less accurate Gaussian model is traditionally preferred. We introduce a novel surface representation that resembles the SES and approaches the rendering performance of the Gaussian model. Our technique is based on the iterative blending of implicit functions and avoids any pre-computation. Additionally, we propose a GPU-based ray-casting algorithm that efficiently visualize our molecular representation. A qualitative and quantitative comparison of our model with respect to the Gaussian and SES models is presented. As showcased in the paper, our technique is a valid and appealing alternative to the Gaussian representation. This is especially relevant in all the applications where the cost of the SES is prohibitive.","Authors":"Parulek, J.;Brambilla, A.","Clusters":"GeometryBasedTechniques;MolecularScienceAndChemistry;SurfaceRelatedDataAndTechniques","DOI":"10.1109\/TVCG.2013.158","Keywords":"geometry-based technique;molecular visualization;implicit surfaces","Title":"Fast Blending Scheme for Molecular Surface Representation","type":"new","Vector":[0.1259762309,0.0,0.0,0.0010763822,0.0,0.0,0.0003419286,0.0005529577,0.0075734057,0.0010314185,0.0,0.0008493147,0.0872696486,0.0,0.0,0.0050885826,0.0,0.0,0.0,0.0]},"35":{"Abstract":"We propose a novel GPU-based approach to render virtual X-ray projections of deformable tetrahedral meshes. These meshes represent the shape and the internal density distribution of a particular anatomical structure and are derived from statistical shape and intensity models (SSIMs). We apply our method to improve the geometric reconstruction of 3D anatomy (e.g. pelvic bone) from 2D X-ray images. For that purpose, shape and density of a tetrahedral mesh are varied and virtual X-ray projections are generated within an optimization process until the similarity between the computed virtual X-ray and the respective anatomy depicted in a given clinical X-ray is maximized. The OpenGL implementation presented in this work deforms and projects tetrahedral meshes of high resolution (200.000+ tetrahedra) at interactive rates. It generates virtual X-rays that accurately depict the density distribution of an anatomy of interest. Compared to existing methods that accumulate X-ray attenuation in deformable meshes, our novel approach significantly boosts the deformation\/projection performance. The proposed projection algorithm scales better with respect to mesh resolution and complexity of the density distribution, and the combined deformation and projection on the GPU scales better with respect to the number of deformation parameters. The gain in performance allows for a larger number of cycles in the optimization process. Consequently, it reduces the risk of being stuck in a local optimum. We believe that our approach will improve treatments in orthopedics, where 3D anatomical information is essential.","Authors":"Ehlke, M.;Ramm, H.;Lamecker, H.;Hege, H.-C.;Zachow, S.","Clusters":"BiomedicalScienceAndMedicine;DataRegistrationFusionAndIntegration;GpuBasedTechniques;MachineLearningAndStatistics;MeshesGridsAndLattices;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2013.159","Keywords":"statistical shape and intensity models;volume rendering;digitally reconstructed radiographs;gpu acceleration;mesh deformation;image registration","Title":"Fast Generation of Virtual X-ray Images for Reconstruction of 3D Anatomy","type":"new","Vector":[0.0,0.0,0.0875144253,0.0162568722,0.0031626694,0.0,0.0041710527,0.0,0.0018632715,0.001286251,0.0,0.0008916293,0.2364603808,0.0,0.0047287214,0.0035515368,0.0,0.0015205558,0.0,0.0]},"36":{"Abstract":"Scatterplot matrices (SPLOMs), parallel coordinates, and glyphs can all be used to visualize the multiple continuous variables (i.e., dependent variables or measures) in multidimensional multivariate data. However, these techniques are not well suited to visualizing many categorical variables (i.e., independent variables or dimensions). To visualize multiple categorical variables, 'hierarchical axes' that 'stack dimensions' have been used in systems like Polaris and Tableau. However, this approach does not scale well beyond a small number of categorical variables. Emerson et al. [8] extend the matrix paradigm of the SPLOM to simultaneously visualize several categorical and continuous variables, displaying many kinds of charts in the matrix depending on the kinds of variables involved. We propose a variant of their technique, called the Generalized Plot Matrix (GPLOM). The GPLOM restricts Emerson et al.'s technique to only three kinds of charts (scatterplots for pairs of continuous variables, heatmaps for pairs of categorical variables, and barcharts for pairings of categorical and continuous variable), in an effort to make it easier to understand. At the same time, the GPLOM extends Emerson et al.'s work by demonstrating interactive techniques suited to the matrix of charts. We discuss the visual design and interactive features of our GPLOM prototype, including a textual search feature allowing users to quickly locate values or variables by name. We also present a user study that compared performance with Tableau and our GPLOM prototype, that found that GPLOM is significantly faster in certain cases, and not significantly slower in other cases.","Authors":"Im, J.-F.;McGuffin, M.J.;Leung, R.","Clusters":"BusinessFinanceEconomyManufacturing;ChartsDiagramsPlots;DataTypesGeneral;DatabasesAndDataMining;MultidimensionalMultivariateMultifieldDataAndTechniques;ParallelCoordinates;TabularDataAndTechniques;UserInterfacesGeneral","DOI":"10.1109\/TVCG.2013.160","Keywords":"database visualization;tabular data;high-dimensional data;user interface;multi-dimensional multi-variate;database overview;relational data;business intelligence;multi-dimensional data;scatterplot matrix;parallel coordinates","Title":"GPLOM: The Generalized Plot Matrix for Visualizing Multidimensional Multivariate Data","type":"new","Vector":[0.0,0.0,0.0,0.0001037413,0.0,0.0,0.0,0.0,0.0,0.0046388841,0.0,0.0,0.0,0.0401095593,0.0,0.0,0.0,0.114477353,0.0,0.0]},"37":{"Abstract":"We present the design of a novel framework for the visual integration, comparison, and exploration of correlations in spatial and non-spatial geriatric research data. These data are in general high-dimensional and span both the spatial, volumetric domain - through magnetic resonance imaging volumes - and the non-spatial domain, through variables such as age, gender, or walking speed. The visual analysis framework blends medical imaging, mathematical analysis and interactive visualization techniques, and includes the adaptation of Sparse Partial Least Squares and iterated Tikhonov Regularization algorithms to quantify potential neurologymobility connections. A linked-view design geared specifically at interactive visual comparison integrates spatial and abstract visual representations to enable the users to effectively generate and refine hypotheses in a large, multidimensional, and fragmented space. In addition to the domain analysis and design description, we demonstrate the usefulness of this approach on two case studies. Last, we report the lessons learned through the iterative design and evaluation of our approach, in particular those relevant to the design of comparative visualization of spatial and non-spatial data.","Authors":"Maries, A.;Mays, N.;Hunt, M.O.;Wong, K.F.;Layton, W.;Boudreau, R.;Rosano, C.;Marai, G.E.","Clusters":"ApplicationsGeneralAndOther;ComparisonComparativeVisualizationAndSimilarity;DesignMethodologiesAndInteractionDesign;DesignStudiesAndCaseStudies;IntegratingSpatialAndNonSpatialDataVisualization;MultidimensionalMultivariateMultifieldDataAndTechniques;TasksTaskRequirementsAnalysis","DOI":"10.1109\/TVCG.2013.161","Keywords":"design study;high-dimensional data;applications of visualization;methodology design;task and requirements analysis;visual comparison;integrating spatial and non-spatial visualization","Title":"GRACE: A Visual Comparison Framework for Integrated Spatial and Non-Spatial Geriatric Data","type":"new","Vector":[0.0031240744,0.0083347236,0.0,0.0,0.0,0.0,0.0011289705,0.0,0.0140472625,0.0380463715,0.0,0.0,0.0,0.0335791245,0.0517443934,0.0,0.0147897454,0.0894188077,0.0046379954,0.002022782]},"38":{"Abstract":"Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.","Authors":"Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;Ribarsky, W.","Clusters":"BiologyAndBioinformatics;TextDocumentTopicAnalysisDataAndTechniques","DOI":"10.1109\/TVCG.2013.162","Keywords":"visual analytics;rose tree;hierarchical topic representation;topic modeling","Title":"HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies","type":"new","Vector":[0.0,0.0238007938,0.0,0.0,0.0,0.001351124,0.0124938087,0.0004418049,0.0,0.0007938963,0.0,0.1383252902,0.0,0.0239693907,0.0,0.0,0.0,0.0,0.0,0.0425114515]},"39":{"Abstract":"We present a first investigation into hybrid-image visualization for data analysis in large-scale viewing environments. Hybrid-image visualizations blend two different visual representations into a single static view, such that each representation can be perceived at a different viewing distance. Our work is motivated by data analysis scenarios that incorporate one or more displays with sufficiently large size and resolution to be comfortably viewed by different people from various distances. Hybrid-image visualizations can be used, in particular, to enhance overview tasks from a distance and detail-in-context tasks when standing close to the display. By using a perception-based blending approach, hybrid-image visualizations make two full-screen visualizations accessible without tracking viewers in front of a display. We contribute a design space, discuss the perceptual rationale for our work, provide examples, and introduce a set of techniques and tools to aid the design of hybrid-image visualizations.","Authors":"Isenberg, P.;Dragicevic, P.;Willett, W.;Bezerianos, A.;Fekete, J.","Clusters":"CollaborativeVisualization;ImageBasedDataImageSignalProcessing;LargeAndHighResDisplays;MultiScaleDataTechniques","DOI":"10.1109\/TVCG.2013.163","Keywords":"large displays;hybrid images;collaboration;visualization;multi-scale","Title":"Hybrid-Image Visualization for Large Viewing Environments","type":"new","Vector":[0.0015440565,0.0317847582,0.0,0.0022676042,0.0179051965,0.0007287886,0.0058439171,0.0,0.0096218061,0.0053048865,0.0142227867,0.017209095,0.0201218807,0.0781730385,0.0,0.0096260364,0.0205128881,0.0475104016,0.020254723,0.0022854341]},"40":{"Abstract":"We present a system that lets analysts use paid crowd workers to explore data sets and helps analysts interactively examine and build upon workers' insights. We take advantage of the fact that, for many types of data, independent crowd workers can readily perform basic analysis tasks like examining views and generating explanations for trends and patterns. However, workers operating in parallel can often generate redundant explanations. Moreover, because workers have different competencies and domain knowledge, some responses are likely to be more plausible than others. To efficiently utilize the crowd's work, analysts must be able to quickly identify and consolidate redundant responses and determine which explanations are the most plausible. In this paper, we demonstrate several crowd-assisted techniques to help analysts make better use of crowdsourced explanations: (1) We explore crowd-assisted strategies that utilize multiple workers to detect redundant explanations. We introduce color clustering with representative selection-a strategy in which multiple workers cluster explanations and we automatically select the most-representative result-and show that it generates clusterings that are as good as those produced by experts. (2) We capture explanation provenance by introducing highlighting tasks and capturing workers' browsing behavior via an embedded web browser, and refine that provenance information via source-review tasks. We expose this information in an explanation-management interface that allows analysts to interactively filter and sort responses, select the most plausible explanations, and decide which to explore further.","Authors":"Willett, W.;Ginosar, S.;Steinitz, A.;Hartmann, B.;Agrawala, M.","Clusters":"EvaluationGeneral;SocialNetworksAndSocialMedia","DOI":"10.1109\/TVCG.2013.164","Keywords":"crowdsourcing;social data analysis","Title":"Identifying Redundancy and Exposing Provenance in Crowdsourced Data Analysis","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.1126234239,0.0,0.0,0.0030033153,0.0,0.0316077902,0.0,0.0321231684,0.001490894,0.0,0.0141805489,0.0,0.0,0.0176660345]},"41":{"Abstract":"People typically interact with information visualizations using a mouse. Their physical movement, orientation, and distance to visualizations are rarely used as input. We explore how to use such spatial relations among people and visualizations (i.e., proxemics) to drive interaction with visualizations, focusing here on the spatial relations between a single user and visualizations on a large display. We implement interaction techniques that zoom and pan, query and relate, and adapt visualizations based on tracking of users' position in relation to a large high-resolution display. Alternative prototypes are tested in three user studies and compared with baseline conditions that use a mouse. Our aim is to gain empirical data on the usefulness of a range of design possibilities and to generate more ideas. Among other things, the results show promise for changing zoom level or visual representation with the user's physical distance to a large display. We discuss possible benefits and potential issues to avoid when designing information visualizations that use proxemics.","Authors":"Jakobsen, M.R.;Sahlemariam Haile, Y.;Knudsen, S.;Hornbaek, K.","Clusters":"AnimationAndMotion;DataAndAnalysisMetrics;EvaluationGeneral;InteractionTechniquesGeneral;LargeAndHighResDisplays;VectorFieldsDataAndTechniques","DOI":"10.1109\/TVCG.2013.166","Keywords":"information visualization;distance;user study;large displays;orientation;movement;proxemics;user tracking","Title":"Information Visualization and Proxemics: Design Opportunities and Empirical findings","type":"new","Vector":[0.0,0.0025124948,0.0,0.0,0.0,0.0,0.002420734,0.0,0.0,0.0,0.0051091471,0.0,0.0010766118,0.1947944277,0.0,0.0,0.0,0.0360863006,0.0,0.018084722]},"42":{"Abstract":"Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature.","Authors":"Jian Zhao;Collins, C.;Chevalier, F.;Balakrishnan, R.","Clusters":"GraphNetworkDataAndTechniques;InteractionTechniquesGeneral;QueriesAndSearch;ZoomingAndNavigationTechniques","DOI":"10.1109\/TVCG.2013.167","Keywords":"network exploration;information visualization;faceted browsing;dynamic query;visual analytics;interaction","Title":"Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets","type":"new","Vector":[0.0,0.0256124603,0.0,0.0,0.0,0.0,0.0,0.0188064834,0.0,0.0,0.0,0.0283114672,0.0,0.0447335948,0.0,0.0,0.060034964,0.1041593315,0.0,0.0]},"43":{"Abstract":"The precise modeling of vascular structures plays a key role in medical imaging applications, such as diagnosis, therapy planning and blood flow simulations. For the simulation of blood flow in particular, high-precision models are required to produce accurate results. It is thus common practice to perform extensive manual data polishing on vascular segmentations prior to simulation. This usually involves a complex tool chain which is highly impractical for clinical on-site application. To close this gap in current blood flow simulation pipelines, we present a novel technique for interactive vascular modeling which is based on implicit sweep surfaces. Our method is able to generate and correct smooth high-quality models based on geometric centerline descriptions on the fly. It supports complex vascular free-form contours and consequently allows for an accurate and fast modeling of pathological structures such as aneurysms or stenoses. We extend the concept of implicit sweep surfaces to achieve increased robustness and applicability as required in the medical field. We finally compare our method to existing techniques and provide case studies that confirm its contribution to current simulation pipelines.","Authors":"Kretschmer, J.;Godenschwager, C.;Preim, B.;Stamminger, M.","Clusters":"BiomedicalScienceAndMedicine;GeometricModeling;SurfaceRelatedDataAndTechniques","DOI":"10.1109\/TVCG.2013.169","Keywords":"vascular visualization;centerline-based modeling;surface modeling","Title":"Interactive Patient-Specific Vascular Modeling with Sweep Surfaces","type":"new","Vector":[0.0018903964,0.021459499,0.0342423192,0.0008572712,0.0,0.0325050554,0.0,0.0703408704,0.0654362799,0.0013996409,0.0025342026,0.0053200838,0.0056593108,0.0010739171,0.0,0.0051421904,0.0,0.0,0.0,0.0139576014]},"44":{"Abstract":"With the evolution of graphics hardware, high quality global illumination becomes available for real-time volume rendering. Compared to local illumination, global illumination can produce realistic shading effects which are closer to real world scenes, and has proven useful for enhancing volume data visualization to enable better depth and shape perception. However, setting up optimal lighting could be a nontrivial task for average users. There were lighting design works for volume visualization but they did not consider global light transportation. In this paper, we present a lighting design method for volume visualization employing global illumination. The resulting system takes into account view and transfer-function dependent content of the volume data to automatically generate an optimized three-point lighting environment. Our method fully exploits the back light which is not used by previous volume visualization systems. By also including global shadow and multiple scattering, our lighting system can effectively enhance the depth and shape perception of volumetric features of interest. In addition, we propose an automatic tone mapping operator which recovers visual details from overexposed areas while maintaining sufficient contrast in the dark areas. We show that our method is effective for visualizing volume datasets with complex structures. The structural information is more clearly and correctly presented under the automatically generated light sources.","Authors":"Yubo Zhang;Kwan-Liu Ma","Clusters":"ColorColorPerception;Illumination;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2013.172","Keywords":"lighting design;volume rendering;global illumination;tone mapping","Title":"Lighting Design for Globally Illuminated Volume Rendering","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0032688754,0.0,0.0,0.0,0.1084182665,0.0,0.0108898145,0.0,0.0100317749,0.0325915207,0.0,0.0,0.0,0.0,0.0,0.0]},"45":{"Abstract":"Rankings are a popular and universal approach to structuring otherwise unorganized collections of items by computing a rank for each item based on the value of one or more of its attributes. This allows us, for example, to prioritize tasks or to evaluate the performance of products relative to each other. While the visualization of a ranking itself is straightforward, its interpretation is not, because the rank of an item represents only a summary of a potentially complicated relationship between its attributes and those of the other items. It is also common that alternative rankings exist which need to be compared and analyzed to gain insight into how multiple heterogeneous attributes affect the rankings. Advanced visual exploration tools are needed to make this process efficient. In this paper we present a comprehensive analysis of requirements for the visualization of multi-attribute rankings. Based on these considerations, we propose LineUp - a novel and scalable visualization technique that uses bar charts. This interactive technique supports the ranking of items based on multiple heterogeneous attributes with different scales and semantics. It enables users to interactively combine attributes and flexibly refine parameters to explore the effect of changes in the attribute combination. This process can be employed to derive actionable insights as to which attributes of an item need to be modified in order for its rank to change. Additionally, through integration of slope graphs, LineUp can also be used to compare multiple alternative rankings on the same set of items, for example, over time or across different attribute combinations. We evaluate the effectiveness of the proposed multi-attribute visualization technique in a qualitative study. The study shows that users are able to successfully solve complex ranking tasks in a short period of time.","Authors":"Gratzl, S.;Lex, A.;Gehlenborg, N.;Pfister, H.;Streit, M.","Clusters":"ChartsDiagramsPlots;DataFacetsAndTechniques;EvaluationGeneral;InteractionTechniquesGeneral;MultidimensionalMultivariateMultifieldDataAndTechniques;Ranking","DOI":"10.1109\/TVCG.2013.173","Keywords":"ranking;stacked bar charts;scoring;multi-factorial;multi-attribute;multi-faceted;ranking visualization","Title":"LineUp: Visual Analysis of Multi-Attribute Rankings","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0327994697,0.001017845,0.0,0.0011168548,0.1968027391,0.0,0.0]},"46":{"Abstract":"As the visualization field matures, an increasing number of general toolkits are developed to cover a broad range of applications. However, no general tool can incorporate the latest capabilities for all possible applications, nor can the user interfaces and workflows be easily adjusted to accommodate all user communities. As a result, users will often chose either substandard solutions presented in familiar, customized tools or assemble a patchwork of individual applications glued through ad-hoc scripts and extensive, manual intervention. Instead, we need the ability to easily and rapidly assemble the best-in-task tools into custom interfaces and workflows to optimally serve any given application community. Unfortunately, creating such meta-applications at the API or SDK level is difficult, time consuming, and often infeasible due to the sheer variety of data models, design philosophies, limits in functionality, and the use of closed commercial systems. In this paper, we present the ManyVis framework which enables custom solutions to be built both rapidly and simply by allowing coordination and communication across existing unrelated applications. ManyVis allows users to combine software tools with complementary characteristics into one virtual application driven by a single, custom-designed interface.","Authors":"Rungta, A.;Summa, B.;Demir, D.;Bremer, P.-T.;Pascucci, V.","Clusters":"ApplicationsGeneralAndOther;MultipleLinkedCoordinatedViews;ProgrammingAlgorithmsAndDataStructures;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2013.174","Keywords":"integrated applications;linked views;visualization environment;macros","Title":"ManyVis: Multiple Applications in an Integrated Visualization Environment","type":"new","Vector":[0.0020642562,0.0,0.0,0.0,0.0030688999,0.0004521412,0.0,0.0081131596,0.0018750642,0.0001992715,0.0037605642,0.0069583761,0.0011939886,0.0141437935,0.001193471,0.0,0.0064675533,0.0148968409,0.0146340163,0.0817823269]},"47":{"Abstract":"This paper describes an advanced visualization method for the analysis of defects in industrial 3D X-Ray Computed Tomography (XCT) data. We present a novel way to explore a high number of individual objects in a dataset, e.g., pores, inclusions, particles, fibers, and cracks demonstrated on the special application area of pore extraction in carbon fiber reinforced polymers (CFRP). After calculating the individual object properties volume, dimensions and shape factors, all objects are clustered into a mean object (MObject). The resulting MObject parameter space can be explored interactively. To do so, we introduce the visualization of mean object sets (MObject Sets) in a radial and a parallel arrangement. Each MObject may be split up into sub-classes by selecting a specific property, e.g., volume or shape factor, and the desired number of classes. Applying this interactive selection iteratively leads to the intended classifications and visualizations of MObjects along the selected analysis path. Hereby the given different scaling factors of the MObjects down the analysis path are visualized through a visual linking approach. Furthermore the representative MObjects are exported as volumetric datasets to serve as input for successive calculations and simulations. In the field of porosity determination in CFRP non-destructive testing practitioners use representative MObjects to improve ultrasonic calibration curves. Representative pores also serve as input for heat conduction simulations in active thermography. For a fast overview of the pore properties in a dataset we propose a local MObjects visualization in combination with a color-coded homogeneity visualization of cells. The advantages of our novel approach are demonstrated using real world CFRP specimens. The results were evaluated through a questionnaire in order to determine the practicality of the MObjects visualization as a supportive tool for domain specialists.","Authors":"Reh, A.;Gusenbauer, C.;Kastner, J.;Groller, E.;Heinzl, C.","Clusters":"BiomedicalScienceAndMedicine;MaterialScience;Parameterization;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2013.177","Keywords":"porosity;parameter space analysis;mobjects;carbon fiber reinforced polymers;3d x-ray computed tomography","Title":"MObjects--A Novel Method for the Visualization and Interactive Exploration of Defects in Industrial XCT Data","type":"new","Vector":[0.0009807984,0.0017634495,0.0,0.0,0.0,0.0,0.0172593899,0.0068948861,0.0126365711,0.0252990721,0.0,0.0000629836,0.002868126,0.0004484688,0.0114824806,0.0029115694,0.0008020155,0.001497044,0.0002075147,0.0]},"48":{"Abstract":"We present MotionExplorer, an exploratory search and analysis system for sequences of human motion in large motion capture data collections. This special type of multivariate time series data is relevant in many research fields including medicine, sports and animation. Key tasks in working with motion data include analysis of motion states and transitions, and synthesis of motion vectors by interpolation and combination. In the practice of research and application of human motion data, challenges exist in providing visual summaries and drill-down functionality for handling large motion data collections. We find that this domain can benefit from appropriate visual retrieval and analysis support to handle these tasks in presence of large motion data. To address this need, we developed MotionExplorer together with domain experts as an exploratory search system based on interactive aggregation and visualization of motion states as a basis for data navigation, exploration, and search. Based on an overview-first type visualization, users are able to search for interesting sub-sequences of motion based on a query-by-example metaphor, and explore search results by details on demand. We developed MotionExplorer in close collaboration with the targeted users who are researchers working on human motion synthesis and analysis, including a summative field study. Additionally, we conducted a laboratory design study to substantially improve MotionExplorer towards an intuitive, usable and robust design. MotionExplorer enables the search in human motion capture data with only a few mouse clicks. The researchers unanimously confirm that the system can efficiently support their work.","Authors":"Bernard, J.;Wilhelm, N.;Kruger, B.;May, T.;Schreck, T.;Kohlhammer, J.","Clusters":"AnalysisProcessGeneral;AnimationAndMotion;DataClusteringAndAggregation;GlyphsGlyphBasedTechniques;TimeseriesTimeVaryingDataAndTechniques","DOI":"10.1109\/TVCG.2013.178","Keywords":"multivariate time series;data aggregation;exploratory search;visual analytics;cluster glyph;motion capture data","Title":"MotionExplorer: Exploratory Search in Human Motion Capture Data Based on Hierarchical Aggregation","type":"new","Vector":[0.0135347869,0.0237777484,0.0,0.0040746718,0.0,0.0006045449,0.1509914848,0.0,0.0,0.0027418863,0.0035752857,0.0,0.0,0.0419286192,0.0,0.0146895,0.0004996145,0.0206248472,0.0010941796,0.1152544789]},"49":{"Abstract":"Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop's main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.","Authors":"Lins, L.;Klosowski, J.T.;Scheidegger, C.E.","Clusters":"DataTypesGeneral;InteractionTechniquesGeneral;ProgrammingAlgorithmsAndDataStructures","DOI":"10.1109\/TVCG.2013.179","Keywords":"data cube;interactive exploration;data structures","Title":"Nanocubes for Real-Time Exploration of Spatiotemporal Datasets","type":"new","Vector":[0.0,0.0378565279,0.0000394088,0.0,0.0036365382,0.0,0.0,0.0041893309,0.0,0.0,0.0,0.0002046502,0.0026623213,0.0,0.0,0.0,0.0199774741,0.0770171372,0.0214027353,0.0433972309]},"50":{"Abstract":"Analysis of multivariate data is of great importance in many scientific disciplines. However, visualization of 3D spatially-fixed multivariate volumetric data is a very challenging task. In this paper we present a method that allows simultaneous real-time visualization of multivariate data. We redistribute the opacity within a voxel to improve the readability of the color defined by a regular transfer function, and to maintain the see-through capabilities of volume rendering. We use predictable procedural noise - random-phase Gabor noise - to generate a high-frequency redistribution pattern and construct an opacity mapping function, which allows to partition the available space among the displayed data attributes. This mapping function is appropriately filtered to avoid aliasing, while maintaining transparent regions. We show the usefulness of our approach on various data sets and with different example applications. Furthermore, we evaluate our method by comparing it to other visualization techniques in a controlled user study. Overall, the results of our study indicate that users are much more accurate in determining exact data values with our novel 3D volume visualization method. Significantly lower error rates for reading data values and high subjective ranking of our method imply that it has a high chance of being adopted for the purpose of visualization of multivariate 3D data.","Authors":"Khlebnikov, R.;Kainz, B.;Steinberger, M.;Schmalstieg, D.","Clusters":"MultidimensionalMultivariateMultifieldDataAndTechniques;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2013.180","Keywords":"scientific visualization;volume rendering;multi-volume rendering;multivariate visualization","Title":"Noise-Based Volume Rendering for the Visualization of Multivariate Volumetric Data","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0642872158,0.0,0.0,0.0225987123,0.0747044743,0.0563019193,0.0,0.0,0.0225562001,0.0507913025,0.0,0.009890086,0.0,0.0456470838,0.0039609371,0.0]},"51":{"Abstract":"Spectral clustering is a powerful and versatile technique, whose broad range of applications includes 3D image analysis. However, its practical use often involves a tedious and time-consuming process of tuning parameters and making application-specific choices. In the absence of training data with labeled clusters, help from a human analyst is required to decide the number of clusters, to determine whether hierarchical clustering is needed, and to define the appropriate distance measures, parameters of the underlying graph, and type of graph Laplacian. We propose to simplify this process via an open-box approach, in which an interactive system visualizes the involved mathematical quantities, suggests parameter values, and provides immediate feedback to support the required decisions. Our framework focuses on applications in 3D image analysis, and links the abstract high-dimensional feature space used in spectral clustering to the three-dimensional data space. This provides a better understanding of the technique, and helps the analyst predict how well specific parameter settings will generalize to similar tasks. In addition, our system supports filtering outliers and labeling the final clusters in such a way that user actions can be recorded and transferred to different data in which the same structures are to be found. Our system supports a wide range of inputs, including triangular meshes, regular grids, and point clouds. We use our system to develop segmentation protocols in chest CT and brain MRI that are then successfully applied to other datasets in an automated manner.","Authors":"Schultz, T.;Kindlmann, G.","Clusters":"DataClusteringAndAggregation;MultidimensionalMultivariateMultifieldDataAndTechniques;MultipleLinkedCoordinatedViews;ProgrammingAlgorithmsAndDataStructures;SegmentationAndClassification","DOI":"10.1109\/TVCG.2013.181","Keywords":"linked views;high-dimensional embeddings;spectral clustering;programming with example;image segmentation","Title":"Open-Box Spectral Clustering: Applications to Medical Image Analysis","type":"new","Vector":[0.0,0.0,0.042903912,0.0509815035,0.0,0.0,0.1334637304,0.0,0.0636278313,0.0121348205,0.0,0.0114340364,0.0,0.0138014453,0.039112341,0.0220199633,0.0152569072,0.0329626876,0.0,0.0]},"52":{"Abstract":"Star coordinates is a popular projection technique from an nD data space to a 2D\/3D visualization domain. It is defined by setting n coordinate axes in the visualization domain. Since it generally defines an affine projection, strong distortions can occur: an nD sphere can be mapped to an ellipse of arbitrary size and aspect ratio. We propose to restrict star coordinates to orthographic projections which map an nD sphere of radius r to a 2D circle of radius r. We achieve this by formulating conditions for the coordinate axes to define orthographic projections, and by running a repeated non-linear optimization in the background of every modification of the coordinate axes. This way, we define a number of orthographic interaction concepts as well as orthographic data tour sequences: a scatterplot tour, a principle component tour, and a grand tour. All concepts are illustrated and evaluated with synthetic and real data.","Authors":"Lehmann, D.J.;Theisel, H.","Clusters":"ChartsDiagramsPlots;MultidimensionalMultivariateMultifieldDataAndTechniques","DOI":"10.1109\/TVCG.2013.182","Keywords":"multivariate visualization;star plot;visual analytics","Title":"Orthographic Star Coordinates","type":"new","Vector":[0.0012238385,0.0030092393,0.0104339625,0.0063669475,0.0012142104,0.0029644116,0.0175475865,0.0,0.0069031686,0.0027836271,0.0143036603,0.0,0.0147625236,0.0097373552,0.0,0.0082965727,0.0,0.0529475911,0.0,0.0]},"53":{"Abstract":"The visual system can make highly efficient aggregate judgements about a set of objects, with speed roughly independent of the number of objects considered. While there is a rich literature on these mechanisms and their ramifications for visual summarization tasks, this prior work rarely considers more complex tasks requiring multiple judgements over long periods of time, and has not considered certain critical aggregation types, such as the localization of the mean value of a set of points. In this paper, we explore these questions using a common visualization task as a case study: relative mean value judgements within multi-class scatterplots. We describe how the perception literature provides a set of expected constraints on the task, and evaluate these predictions with a large-scale perceptual study with crowd-sourced participants. Judgements are no harder when each set contains more points, redundant and conflicting encodings, as well as additional sets, do not strongly affect performance, and judgements are harder when using less salient encodings. These results have concrete ramifications for the design of scatterplots.","Authors":"Gleicher, M.;Correll, M.;Nothelfer, C.;Franconeri, S.","Clusters":"Perception","DOI":"10.1109\/TVCG.2013.183","Keywords":"perceptual study;information visualization;psychophysics","Title":"Perception of Average Value in Multiclass Scatterplots","type":"new","Vector":[0.0,0.0,0.0,0.0028853507,0.0037077587,0.0,0.0062454801,0.0,0.0,0.0055388944,0.0,0.0,0.0,0.2416384066,0.0,0.0,0.0,0.0414913799,0.0298488294,0.0]},"54":{"Abstract":"In many applications, data tables contain multi-valued attributes that often store the memberships of the table entities to multiple sets such as which languages a person masters, which skills an applicant documents, or which features a product comes with. With a growing number of entities, the resulting element-set membership matrix becomes very rich of information about how these sets overlap. Many analysis tasks targeted at set-typed data are concerned with these overlaps as salient features of such data. This paper presents Radial Sets, a novel visual technique to analyze set memberships for a large number of elements. Our technique uses frequency-based representations to enable quickly finding and analyzing different kinds of overlaps between the sets, and relating these overlaps to other attributes of the table entities. Furthermore, it enables various interactions to select elements of interest, find out if they are over-represented in specific sets or overlaps, and if they exhibit a different distribution for a specific attribute compared to the rest of the elements. These interactions allow formulating highly-expressive visual queries on the elements in terms of their set memberships and attribute values. As we demonstrate via two usage scenarios, Radial Sets enable revealing and analyzing a multitude of overlapping patterns between large sets, beyond the limits of state-of-the-art techniques.","Authors":"Alsallakh, B.;Aigner, W.;Miksch, S.;Hauser, H.","Clusters":"LargeScaleDataAndScalability;MultidimensionalMultivariateMultifieldDataAndTechniques;SetRelatedDataTechniques;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2013.184","Keywords":"overlapping sets;visualization technique;multi-valued attributes;scalability;set-typed data","Title":"Radial Sets: Interactive Visual Analysis of Large Overlapping Sets","type":"new","Vector":[0.0012375161,0.0244941333,0.0021623805,0.0017142605,0.0,0.0,0.0084269243,0.0083858741,0.0073642584,0.0,0.006571166,0.0,0.0,0.0199214303,0.0,0.0005053646,0.0179434396,0.1101448522,0.0,0.0]},"55":{"Abstract":"The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.","Authors":"Bosch, H.;Thom, D.;Heimerl, F.;Puttmann, E.;Koch, S.;Kruger, R.;Worner, M.;Ertl, T.","Clusters":"FilteringTechniques;QueriesAndSearch;SocialNetworksAndSocialMedia;TextDocumentTopicAnalysisDataAndTechniques;TimeCriticalApplications","DOI":"10.1109\/TVCG.2013.186","Keywords":"information visualization;query construction;filter construction;text classification;text analytics;live monitoring;twitter;visual analytics;social media monitoring;microblog analysis","Title":"ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided filtering","type":"new","Vector":[0.0,0.0132071629,0.0,0.0001433285,0.0,0.006440873,0.0084916826,0.0,0.0030513654,0.0072202749,0.0,0.0790927124,0.0,0.006666297,0.0,0.0,0.0224173437,0.0101980171,0.0038475808,0.1199314617]},"56":{"Abstract":"Scatter plots are diagrams that visualize two-dimensional data as sets of points in the plane. They allow users to detect correlations and clusters in the data. Whether or not a user can accomplish these tasks highly depends on the aspect ratio selected for the plot, i.e., the ratio between the horizontal and the vertical extent of the diagram. We argue that an aspect ratio is good if the Delaunay triangulation of the scatter plot at this aspect ratio has some nice geometric property, e.g., a large minimum angle or a small total edge length. More precisely, we consider the following optimization problem. Given a set Q of points in the plane, find a scale factor s such that scaling the x-coordinates of the points in Q by s and the y-coordinates by 1=s yields a point set P(s) that optimizes a property of the Delaunay triangulation of P(s), over all choices of s. We present an algorithm that solves this problem efficiently and demonstrate its usefulness on real-world instances. Moreover, we discuss an empirical test in which we asked 64 participants to choose the aspect ratios of 18 scatter plots. We tested six different quality measures that our algorithm can optimize. In conclusion, minimizing the total edge length and minimizing what we call the 'uncompactness' of the triangles of the Delaunay triangulation yielded the aspect ratios that were most similar to those chosen by the participants in the test.","Authors":"Fink, M.;Haunert, J.-H.;Spoerhase, J.;Wolff, A.","Clusters":"ChartsDiagramsPlots;MeshesGridsAndLattices;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2013.187","Keywords":"aspect ratio;delaunay triangulation;scatterplot","Title":"Selecting the Aspect Ratio of a Scatter Plot Based on Its Delaunay Triangulation","type":"new","Vector":[0.0033531648,0.0,0.0697014674,0.0,0.0,0.0025903246,0.0679652263,0.0163830524,0.0030817345,0.0018284649,0.0,0.0,0.0,0.0408557909,0.0,0.003594052,0.0,0.0451585173,0.0,0.0448422237]},"57":{"Abstract":"When high-dimensional data is visualized in a 2D plane by using parametric projection algorithms, users may wish to manipulate the layout of the data points to better reflect their domain knowledge or to explore alternative structures. However, few users are well-versed in the algorithms behind the visualizations, making parameter tweaking more of a guessing game than a series of decisive interactions. Translating user interactions into algorithmic input is a key component of Visual to Parametric Interaction (V2PI) [13]. Instead of adjusting parameters, users directly move data points on the screen, which then updates the underlying statistical model. However, we have found that some data points that are not moved by the user are just as important in the interactions as the data points that are moved. Users frequently move some data points with respect to some other 'unmoved' data points that they consider as spatially contextual. However, in current V2PI interactions, these points are not explicitly identified when directly manipulating the moved points. We design a richer set of interactions that makes this context more explicit, and a new algorithm and sophisticated weighting scheme that incorporates the importance of these unmoved data points into V2PI.","Authors":"Xinran Hu;Bradel, L.;Maiti, D.;House, L.;North, C.;Leman, S.","Clusters":"InteractionTechniquesGeneral;MachineLearningAndStatistics","DOI":"10.1109\/TVCG.2013.188","Keywords":"statistical models;visual to parametric interaction;visual analytics","Title":"Semantics of Directly Manipulating Spatializations","type":"new","Vector":[0.0066864124,0.0009241273,0.002400527,0.002134229,0.0,0.0,0.0534608287,0.0057563597,0.0036910321,0.0009837752,0.0015548419,0.0333390643,0.0,0.0208013151,0.0041604935,0.0,0.0008486728,0.018429094,0.0,0.0]},"58":{"Abstract":"Cardiovascular diseases (CVD) are the leading cause of death worldwide. Their initiation and evolution depends strongly on the blood flow characteristics. In recent years, advances in 4D PC-MRI acquisition enable reliable and time-resolved 3D flow measuring, which allows a qualitative and quantitative analysis of the patient-specific hemodynamics. Currently, medical researchers investigate the relation between characteristic flow patterns like vortices and different pathologies. The manual extraction and evaluation is tedious and requires expert knowledge. Standardized, (semi-)automatic and reliable techniques are necessary to make the analysis of 4D PC-MRI applicable for the clinical routine. In this work, we present an approach for the extraction of vortex flow in the aorta and pulmonary artery incorporating line predicates. We provide an extensive comparison of existent vortex extraction methods to determine the most suitable vortex criterion for cardiac blood flow and apply our approach to ten datasets with different pathologies like coarctations, Tetralogy of Fallot and aneurysms. For two cases we provide a detailed discussion how our results are capable to complement existent diagnosis information. To ensure real-time feedback for the domain experts we implement our method completely on the GPU.","Authors":"Kohler, B.;Gasteiger, R.;Preim, U.;Theisel, H.;Gutberlet, M.;Preim, B.","Clusters":"ApplicationsGeneralAndOther;BiomedicalScienceAndMedicine;FlowVisualizationDataAndTechniques;LineBasedTechniquesAndApproaches","DOI":"10.1109\/TVCG.2013.189","Keywords":"vortex extraction;line predicates;cardiac blood flow;hemodynamics;4d pc-mri","Title":"Semi-Automatic Vortex Extraction in 4D PC-MRI Cardiac Blood Flow Data using Line Predicates","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.2955714572,0.0,0.0,0.0228992565,0.0,0.0,0.0,0.0,0.0006689017,0.0001985145,0.0,0.0,0.0,0.0,0.0090216305]},"59":{"Abstract":"High-dimensional data visualization has been attracting much attention. To fully test related software and algorithms, researchers require a diverse pool of data with known and desired features. Test data do not always provide this, or only partially. Here we propose the paradigm WYDIWYGS (What You Draw Is What You Get). Its embodiment, SketchPadND, is a tool that allows users to generate high-dimensional data in the same interface they also use for visualization. This provides for an immersive and direct data generation activity, and furthermore it also enables users to interactively edit and clean existing high-dimensional data from possible artifacts. SketchPadND offers two visualization paradigms, one based on parallel coordinates and the other based on a relatively new framework using an N-D polygon to navigate in high-dimensional space. The first interface allows users to draw arbitrary profiles of probability density functions along each dimension axis and sketch shapes for data density and connections between adjacent dimensions. The second interface embraces the idea of sculpting. Users can carve data at arbitrary orientations and refine them wherever necessary. This guarantees that the data generated is truly high-dimensional. We demonstrate our tool's usefulness in real data visualization scenarios.","Authors":"Bing Wang;Ruchikachorn, P.;Mueller, K.","Clusters":"ChartsDiagramsPlots;DataAcquisitionAndManagement;DataEditing;InteractionTechniquesGeneral;MultidimensionalMultivariateMultifieldDataAndTechniques;MultipleLinkedCoordinatedViews;ParallelCoordinates;UserInterfacesGeneral;ZoomingAndNavigationTechniques","DOI":"10.1109\/TVCG.2013.190","Keywords":"data acquisition and management;scatterplot;high-dimensional data;user interface;multiple views;synthetic data generation;data editing;multivariate data;parallel coordinates;n-d navigation;interaction","Title":"SketchPadN-D: WYDIWYG Sculpting and Editing in High-Dimensional Space","type":"new","Vector":[0.001296605,0.0,0.0215902211,0.0003643309,0.0028721174,0.0013565086,0.11441645,0.0,0.0070453657,0.0012762521,0.0078976924,0.0,0.0123531543,0.0085807669,0.0,0.0,0.0,0.1062677332,0.0,0.0]},"60":{"Abstract":"Presenting and communicating insights to an audience-telling a story-is one of the main goals of data exploration. Even though visualization as a storytelling medium has recently begun to gain attention, storytelling is still underexplored in information visualization and little research has been done to help people tell their stories with data. To create a new, more engaging form of storytelling with data, we leverage and extend the narrative storytelling attributes of whiteboard animation with pen and touch interactions. We present SketchStory, a data-enabled digital whiteboard that facilitates the creation of personalized and expressive data charts quickly and easily. SketchStory recognizes a small set of sketch gestures for chart invocation, and automatically completes charts by synthesizing the visuals from the presenter-provided example icon and binding them to the underlying data. Furthermore, SketchStory allows the presenter to move and resize the completed data charts with touch, and filter the underlying data to facilitate interactive exploration. We conducted a controlled experiment for both audiences and presenters to compare SketchStory with a traditional presentation system, Microsoft PowerPoint. Results show that the audience is more engaged by presentations done with SketchStory than PowerPoint. Eighteen out of 24 audience participants preferred SketchStory to PowerPoint. Four out of five presenter participants also favored SketchStory despite the extra effort required for presentation.","Authors":"Bongshin Lee;Kazi, R.H.;Smith, G.","Clusters":"InteractionTechniquesGeneral;Storytelling;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2013.191","Keywords":"data presentation;sketch;visualization;pen and touch;storytelling;interaction","Title":"SketchStory: Telling More Engaging Stories with Data through Freeform Sketching","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0071916891,0.0,0.115525538,0.0,0.0,0.0,0.014193655,0.0,0.015542078]},"61":{"Abstract":"This article presents SoccerStories, a visualization interface to support analysts in exploring soccer data and communicating interesting insights. Currently, most analyses on such data relate to statistics on individual players or teams. However, soccer analysts we collaborated with consider that quantitative analysis alone does not convey the right picture of the game, as context, player positions and phases of player actions are the most relevant aspects. We designed SoccerStories to support the current practice of soccer analysts and to enrich it, both in the analysis and communication stages. Our system provides an overview+detail interface of game phases, and their aggregation into a series of connected visualizations, each visualization being tailored for actions such as a series of passes or a goal attempt. To evaluate our tool, we ran two qualitative user studies on recent games using SoccerStories with data from one of the world's leading live sports data providers. The first study resulted in a series of four articles on soccer tactics, by a tactics analyst, who said he would not have been able to write these otherwise. The second study consisted in an exploratory follow-up to investigate design alternatives for embedding soccer phases into word-sized graphics. For both experiments, we received a very enthusiastic feedback and participants consider further use of SoccerStories to enhance their current workflow.","Authors":"Perin, C.;Vuillemot, R.;Fekete, J.","Clusters":"DataClusteringAndAggregation;KnowledgeDiscovery;SportsVisualization;VisualKnowledgeRepresentationAndExternalization","DOI":"10.1109\/TVCG.2013.192","Keywords":"visual knowledge representation;visual aggregation;sport analytics;visual knowledge discovery","Title":"SoccerStories: A Kick-off for Visual Soccer Analysis","type":"new","Vector":[0.0007289315,0.0195483885,0.0,0.000571848,0.0,0.0005506266,0.0149375944,0.0,0.0,0.0,0.0,0.0128998709,0.0,0.033980649,0.0,0.0,0.0138405799,0.0,0.0,0.1201770839]},"62":{"Abstract":"We suggest a methodology for analyzing movement behaviors of individuals moving in a group. Group movement is analyzed at two levels of granularity: the group as a whole and the individuals it comprises. For analyzing the relative positions and movements of the individuals with respect to the rest of the group, we apply space transformation, in which the trajectories of the individuals are converted from geographical space to an abstract 'group space'. The group space reference system is defined by both the position of the group center, which is taken as the coordinate origin, and the direction of the group's movement. Based on the individuals' positions mapped onto the group space, we can compare the behaviors of different individuals, determine their roles and\/or ranks within the groups, and, possibly, understand how group movement is organized. The utility of the methodology has been evaluated by applying it to a set of real data concerning movements of wild social animals and discussing the results with experts in animal ethology.","Authors":"Andrienko, N.;Andrienko, G.;Barrett, L.;Dostie, M.;Henzi, P.","Clusters":"AnimationAndMotion","DOI":"10.1109\/TVCG.2013.193","Keywords":"movement data;collective movement;visual analytics","Title":"Space Transformation for Understanding Group Movement","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0819592347,0.0048848647,0.0,0.0003982169,0.0,0.0,0.0,0.0077669445,0.0,0.0214209017,0.0,0.0152483041,0.0,0.2576738858]},"63":{"Abstract":"We introduce a visual analytics method to analyze eye movement data recorded for dynamic stimuli such as video or animated graphics. The focus lies on the analysis of data of several viewers to identify trends in the general viewing behavior, including time sequences of attentional synchrony and objects with strong attentional focus. By using a space-time cube visualization in combination with clustering, the dynamic stimuli and associated eye gazes can be analyzed in a static 3D representation. Shot-based, spatiotemporal clustering of the data generates potential areas of interest that can be filtered interactively. We also facilitate data drill-down: the gaze points are shown with density-based color mapping and individual scan paths as lines in the space-time cube. The analytical process is supported by multiple coordinated views that allow the user to focus on different aspects of spatial and temporal information in eye gaze data. Common eye-tracking visualization techniques are extended to incorporate the spatiotemporal characteristics of the data. For example, heat maps are extended to motion-compensated heat maps and trajectories of scan paths are included in the space-time visualization. Our visual analytics approach is assessed in a qualitative users study with expert users, which showed the usefulness of the approach and uncovered that the experts applied different analysis strategies supported by the system.","Authors":"Kurzhals, K.;Weiskopf, D.","Clusters":"DataClusteringAndAggregation;DesignMethodologiesAndInteractionDesign;EvaluationGeneral;SpatiotemporalDataAndTechniques;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2013.194","Keywords":"spatio-temporal clustering;space-time cube;motion-compensated heatmap;eye tracking;dynamic areas of interest","Title":"Space-Time Visual Analytics of Eye-Tracking Data for Dynamic Stimuli","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0064297364,0.137623209,0.0,0.0,0.0,0.0067084489,0.0,0.0015958353,0.0856522542,0.0040995958,0.0,0.0,0.0,0.0,0.1894703518]},"64":{"Abstract":"Storyline visualizations, which are useful in many applications, aim to illustrate the dynamic relationships between entities in a story. However, the growing complexity and scalability of stories pose great challenges for existing approaches. In this paper, we propose an efficient optimization approach to generating an aesthetically appealing storyline visualization, which effectively handles the hierarchical relationships between entities over time. The approach formulates the storyline layout as a novel hybrid optimization approach that combines discrete and continuous optimization. The discrete method generates an initial layout through the ordering and alignment of entities, and the continuous method optimizes the initial layout to produce the optimal one. The efficient approach makes real-time interactions (e.g., bundling and straightening) possible, thus enabling users to better understand and track how the story evolves. Experiments and case studies are conducted to demonstrate the effectiveness and usefulness of the optimization approach.","Authors":"Shixia Liu;Yingcai Wu;Enxun Wei;Mengchen Liu;Yang Liu","Clusters":"InteractionTechniquesGeneral;LevelOfDetail;Optimization;Storytelling","DOI":"10.1109\/TVCG.2013.196","Keywords":"user interaction;optimization;level-of-detail;storytelling;storylines","Title":"StoryFlow: Tracking the Evolution of Stories","type":"new","Vector":[0.0014099258,0.0790535765,0.0031431239,0.000892894,0.0003818629,0.0,0.0076270103,0.0,0.0,0.0044203317,0.0,0.064860368,0.0,0.0071444532,0.0051215155,0.0,0.0,0.0,0.0002267352,0.1007345476]},"65":{"Abstract":"Maintaining an awareness of collaborators' actions is critical during collaborative work, including during collaborative visualization activities. Particularly when collaborators are located at a distance, it is important to know what everyone is working on in order to avoid duplication of effort, share relevant results in a timely manner and build upon each other's results. Can a person's brushing actions provide an indication of their queries and interests in a data set? Can these actions be revealed to a collaborator without substantially disrupting their own independent work? We designed a study to answer these questions in the context of distributed collaborative visualization of tabular data. Participants in our study worked independently to answer questions about a tabular data set, while simultaneously viewing brushing actions of a fictitious collaborator, shown directly within a shared workspace. We compared three methods of presenting the collaborator's actions: brushing & linking (i.e. highlighting exactly what the collaborator would see), selection (i.e. showing only a selected item), and persistent selection (i.e. showing only selected items but having them persist for some time). Our results demonstrated that persistent selection enabled some awareness of the collaborator's activities while causing minimal interference with independent work. Other techniques were less effective at providing awareness, and brushing & linking caused substantial interference. These findings suggest promise for the idea of exploiting natural brushing actions to provide awareness in collaborative work.","Authors":"Hajizadeh, A.H.;Tory, M.;Leung, R.","Clusters":"AmbientVisualization;Cognition;CollaborativeVisualization;EvaluationGeneral;InteractionTechniquesGeneral;MultipleLinkedCoordinatedViews","DOI":"10.1109\/TVCG.2013.197","Keywords":"user study;linked views;awareness;collaboration;attentionally ambient visualization;brushing and linking","Title":"Supporting Awareness through Collaborative Brushing and Linking of Tabular Data","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0117749458,0.0,0.2224100665,0.0,0.0,0.0118054072,0.0289377463,0.0,0.0]},"66":{"Abstract":"The visual analysis of dynamic networks is a challenging task. In this paper, we introduce a new approach supporting the discovery of substructures sharing a similar trend over time by combining computation, visualization and interaction. With existing techniques, their discovery would be a tedious endeavor because of the number of nodes, edges as well as time points to be compared. First, on the basis of the supergraph, we therefore group nodes and edges according to their associated attributes that are changing over time. Second, the supergraph is visualized to provide an overview of the groups of nodes and edges with similar behavior over time in terms of their associated attributes. Third, we provide specific interactions to explore and refine the temporal clustering, allowing the user to further steer the analysis of the dynamic network. We demonstrate our approach by the visual analysis of a large wireless mesh network.","Authors":"Hadlak, S.;Schumann, H.;Cap, C.H.;Wollenberg, T.","Clusters":"DataClusteringAndAggregation;DynamicDataAndTechniques","DOI":"10.1109\/TVCG.2013.198","Keywords":"visualization;supergraph clustering;dynamic networks","Title":"Supporting the Visual Analysis of Dynamic Networks by Clustering associated Temporal Attributes","type":"new","Vector":[0.0,0.0139529533,0.0,0.0,0.0,0.0,0.3057726093,0.0,0.0,0.0000289157,0.0,0.0,0.0,0.0,0.0,0.0,0.2207216994,0.0,0.0,0.0212864817]},"67":{"Abstract":"Electronic Health Records (EHRs) have emerged as a cost-effective data source for conducting medical research. The difficulty in using EHRs for research purposes, however, is that both patient selection and record analysis must be conducted across very large, and typically very noisy datasets. Our previous work introduced EventFlow, a visualization tool that transforms an entire dataset of temporal event records into an aggregated display, allowing researchers to analyze population-level patterns and trends. As datasets become larger and more varied, however, it becomes increasingly difficult to provide a succinct, summarizing display. This paper presents a series of user-driven data simplifications that allow researchers to pare event records down to their core elements. Furthermore, we present a novel metric for measuring visual complexity, and a language for codifying disjoint strategies into an overarching simplification framework. These simplifications were used by real-world researchers to gain new and valuable insights from initially overwhelming datasets.","Authors":"Monroe, M.;Rongjian Lan;Hanseung Lee;Plaisant, C.;Shneiderman, B.","Clusters":"AbstractionSimplificationApproximation;BiomedicalScienceAndMedicine;EventsTrendsOutlierDetectionAnalysisAndVisualization;QueriesAndSearch","DOI":"10.1109\/TVCG.2013.200","Keywords":"electronic health records;temporal query;simplification;event sequences","Title":"Temporal Event Sequence Simplification","type":"new","Vector":[0.0,0.0,0.0175674945,0.0,0.0,0.0,0.0081947792,0.0032427194,0.0,0.0,0.0,0.0,0.0,0.0001065919,0.0,0.0,0.0,0.0202751839,0.0,0.1891565835]},"68":{"Abstract":"Spatial organization has been proposed as a compelling approach to externalizing the sensemaking process. However, there are two ways in which space can be provided to the user: by creating a physical workspace that the user can interact with directly, such as can be provided by a large, high-resolution display, or through the use of a virtual workspace that the user navigates using virtual navigation techniques such as zoom and pan. In this study we explicitly examined the use of spatial sensemaking techniques within these two environments. The results demonstrate that these two approaches to providing sensemaking space are not equivalent, and that the greater embodiment afforded by the physical workspace changes how the space is perceived and used, leading to increased externalization of the sensemaking process.","Authors":"Andrews, C.;North, C.","Clusters":"Cognition;LargeAndHighResDisplays;ZoomingAndNavigationTechniques","DOI":"10.1109\/TVCG.2013.205","Keywords":"embodiment;sensemaking;physical navigation;visual analytics;large and high-resolution display","Title":"The Impact of Physical Navigation on Spatial Organization for Sensemaking","type":"new","Vector":[0.0012035021,0.0,0.0,0.0,0.0,0.0,0.0172327538,0.0,0.0,0.0,0.0077415004,0.2833372645,0.004604352,0.102763632,0.0,0.0,0.0,0.0,0.0,0.0000961263]},"69":{"Abstract":"Time-oriented data play an essential role in many Visual Analytics scenarios such as extracting medical insights from collections of electronic health records or identifying emerging problems and vulnerabilities in network traffic. However, many software libraries for Visual Analytics treat time as a flat numerical data type and insufficiently tackle the complexity of the time domain such as calendar granularities and intervals. Therefore, developers of advanced Visual Analytics designs need to implement temporal foundations in their application code over and over again. We present TimeBench, a software library that provides foundational data structures and algorithms for time-oriented data in Visual Analytics. Its expressiveness and developer accessibility have been evaluated through application examples demonstrating a variety of challenges with time-oriented data and long-term developer studies conducted in the scope of research and student projects.","Authors":"Rind, A.;Lammarsch, T.;Aigner, W.;Alsallakh, B.;Miksch, S.","Clusters":"TimeseriesTimeVaryingDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2013.206","Keywords":"information visualization;toolkits;software infrastructure;time;visual analytics;temporal data","Title":"TimeBench: A Data Model and Software Library for Visual Analytics of Time-Oriented Data","type":"new","Vector":[0.0,0.009548379,0.0,0.0,0.0,0.0,0.000172134,0.0086110724,0.0,0.0035290258,0.0,0.0007545645,0.0005866613,0.00631689,0.0,0.0,0.0024078465,0.0422943267,0.010436833,0.087124342]},"70":{"Abstract":"Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.","Authors":"Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.;Griffiths, I.W.;Chen, M.","Clusters":"DataClusteringAndAggregation;KnowledgeDiscovery;MachineLearningAndStatistics;MultimediaImageVideoMusic","DOI":"10.1109\/TVCG.2013.207","Keywords":"multimedia visualization;visual knowledge discovery;data clustering;machine learning","Title":"Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop","type":"new","Vector":[0.0,0.0,0.0,0.0002044687,0.0,0.0,0.0092198044,0.0,0.0022398239,0.0049526077,0.0,0.0196075881,0.0,0.0221206003,0.0009132948,0.0,0.0,0.0078510958,0.0,0.2912811661]},"71":{"Abstract":"We present a study of linear interpolation when applied to uncertain data. Linear interpolation is a key step for isosurface extraction algorithms, and the uncertainties in the data lead to non-linear variations in the geometry of the extracted isosurface. We present an approach for deriving the probability density function of a random variable modeling the positional uncertainty in the isosurface extraction. When the uncertainty is quantified by a uniform distribution, our approach provides a closed-form characterization of the mentioned random variable. This allows us to derive, in closed form, the expected value as well as the variance of the level-crossing position. While the former quantity is used for constructing a stable isosurface for uncertain data, the latter is used for visualizing the positional uncertainties in the expected isosurface level crossings on the underlying grid.","Authors":"Athawale, T.;Entezari, A.","Clusters":"Interpolation;IsosurfaceAndSurfaceExtractionTechniques;UncertaintyTechniquesAndVisualization","DOI":"10.1109\/TVCG.2013.208","Keywords":"isosurface extraction;uncertainty quantification;linear interpolation;marching cubes","Title":"Uncertainty Quantification in Linear Interpolation for Isosurface Extraction","type":"new","Vector":[0.0,0.0,0.0229557726,0.0,0.0,0.0,0.0009400359,0.1060289084,0.0,0.1713557159,0.0,0.0,0.0,0.0,0.0040254578,0.0031234922,0.0,0.0054875412,0.0,0.0]},"72":{"Abstract":"Business ecosystems are characterized by large, complex, and global networks of firms, often from many different market segments, all collaborating, partnering, and competing to create and deliver new products and services. Given the rapidly increasing scale, complexity, and rate of change of business ecosystems, as well as economic and competitive pressures, analysts are faced with the formidable task of quickly understanding the fundamental characteristics of these interfirm networks. Existing tools, however, are predominantly query- or list-centric with limited interactive, exploratory capabilities. Guided by a field study of corporate analysts, we have designed and implemented dotlink360, an interactive visualization system that provides capabilities to gain systemic insight into the compositional, temporal, and connective characteristics of business ecosystems. dotlink360 consists of novel, multiple connected views enabling the analyst to explore, discover, and understand interfirm networks for a focal firm, specific market segments or countries, and the entire business ecosystem. System evaluation by a small group of prototypical users shows supporting evidence of the benefits of our approach. This design study contributes to the relatively unexplored, but promising area of exploratory information visualization in market research and business strategy.","Authors":"Basole, R.C.;Clear, T.;Mengdie Hu;Mehrotra, H.;Stasko, J.","Clusters":"AnalysisProcessGeneral;BusinessFinanceEconomyManufacturing;DesignStudiesAndCaseStudies;GraphNetworkDataAndTechniques;InteractionTechniquesGeneral","DOI":"10.1109\/TVCG.2013.209","Keywords":"design study;strategic analysis;market research;business ecosystems;network visualization;interaction","Title":"Understanding Interfirm Relationships in Business Ecosystems with Interactive Visualization","type":"new","Vector":[0.0,0.0098706283,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0211096322,0.0,0.100637393,0.0,0.0,0.0863316473,0.0090099067,0.0,0.0265985196]},"73":{"Abstract":"From financial statistics to nutritional values, we are frequently exposed to quantitative information expressed in measures of either extreme magnitudes or unfamiliar units, or both. A common practice used to comprehend such complex measures is to relate, re-express, and compare them through visual depictions using magnitudes and units that are easier to grasp. Through this practice, we create a new graphic composition that we refer to as a concrete scale. To the best of our knowledge, there are no design guidelines that exist for concrete scales despite their common use in communication, educational, and decision-making settings. We attempt to fill this void by introducing a novel framework that would serve as a practical guide for their analysis and design. Informed by a thorough analysis of graphic compositions involving complex measures and an extensive literature review of scale cognition mechanisms, our framework outlines the design space of various measure relations-specifically relations involving the re-expression of complex measures to more familiar concepts-and their visual representations as graphic compositions.","Authors":"Chevalier, F.;Vuillemot, R.;Gali, G.","Clusters":"Cognition;ComparisonComparativeVisualizationAndSimilarity;MultiScaleDataTechniques;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2013.210","Keywords":"visual notation;scale cognition;visual comparison;graphic composition;concrete scale","Title":"Using Concrete Scales: A Practical Framework for Effective Visual Depiction of Complex Measures","type":"new","Vector":[0.0042266302,0.0056569405,0.0024002499,0.0021306147,0.0009542623,0.0051817052,0.001596203,0.0042567322,0.005980965,0.0023626062,0.0019428579,0.0180747517,0.0007747002,0.0481902448,0.0008531874,0.0056347893,0.0019908654,0.0325043441,0.0083074177,0.013713428]},"74":{"Abstract":"This research aims to develop design guidelines for systems that support investigators and analysts in the exploration and assembly of evidence and inferences. We focus here on the problem of identifying candidate 'influencers' within a community of practice. To better understand this problem and its related cognitive and interaction needs, we conducted a user study using a system called INVISQUE (INteractive Visual Search and QUery Environment) loaded with content from the ACM Digital Library. INVISQUE supports search and manipulation of results over a freeform infinite 'canvas'. The study focuses on the representations user create and their reasoning process. It also draws on some pre-established theories and frameworks related to sense-making and cognitive work in general, which we apply as a 'theoretical lenses' to consider findings and articulate solutions. Analysing the user-study data in the light of these provides some understanding of how the high-level problem of identifying key players within a domain can translate into lower-level questions and interactions. This, in turn, has informed our understanding of representation and functionality needs at a level of description which abstracts away from the specifics of the problem at hand to the class of problems of interest. We consider the study outcomes from the perspective of implications for design.","Authors":"Kodagoda, N.;Attfield, S.;Wong, B.L.W.;Rooney, C.;Choudhury, S.","Clusters":"AnalysisProcessGeneral;Cognition;EvaluationGeneral;InteractionTechniquesGeneral;ProgrammingAlgorithmsAndDataStructures;UserInterfacesGeneral","DOI":"10.1109\/TVCG.2013.211","Keywords":"reasoning;interface design;sensemaking;dataframe mode;visual analytics;analysis;evaluation;interaction","Title":"Using Interactive Visual Reasoning to Support Sense-Making: Implications for Design","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0102686075,0.0,0.0,0.0,0.0,0.0679052704,0.0,0.2249215564,0.0,0.0,0.0124617948,0.0,0.0,0.0020487844]},"75":{"Abstract":"Topic modeling has been widely used for analyzing text document collections. Recently, there have been significant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation (LDA) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, LDA cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and flexible visual analytics system for topic modeling called UTOPIAN (User-driven Topic modeling based on Interactive Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, UTOPIAN enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of UTOPIAN via several usage scenarios with real-world document corpuses such as InfoVis\/VAST paper data set and product review data sets.","Authors":"Jaegul Choo;Changhyun Lee;Reddy, C.K.;Haesun Park","Clusters":"DataClusteringAndAggregation;MachineLearningAndStatistics;NumericalMethodsMathematics;TextDocumentTopicAnalysisDataAndTechniques","DOI":"10.1109\/TVCG.2013.212","Keywords":"nonnegative matrix factorization;text analytics;latent dirichlet allocation;interactive clustering;visual analytics;topic modeling","Title":"UTOPIAN: User-Driven Topic Modeling Based on Interactive Nonnegative Matrix Factorization","type":"new","Vector":[0.0,0.0,0.0008800728,0.0002788486,0.0,0.0009217379,0.0740423219,0.0,0.0,0.0,0.0,0.1732867935,0.0,0.0,0.0005078134,0.00062465,0.0,0.0,0.0,0.0]},"76":{"Abstract":"Scientists, engineers, and analysts are confronted with ever larger and more complex sets of data, whose analysis poses special challenges. In many situations it is necessary to compare two or more datasets. Hence there is a need for comparative visualization tools to help analyze differences or similarities among datasets. In this paper an approach for comparative visualization for sets of images is presented. Well-established techniques for comparing images frequently place them side-by-side. A major drawback of such approaches is that they do not scale well. Other image comparison methods encode differences in images by abstract parameters like color. In this case information about the underlying image data gets lost. This paper introduces a new method for visualizing differences and similarities in large sets of images which preserves contextual information, but also allows the detailed analysis of subtle variations. Our approach identifies local changes and applies cluster analysis techniques to embed them in a hierarchy. The results of this process are then presented in an interactive web application which allows users to rapidly explore the space of differences and drill-down on particular features. We demonstrate the flexibility of our approach by applying it to multiple distinct domains.","Authors":"Schmidt, J.;Groller, E.;Bruckner, S.","Clusters":"ComparisonComparativeVisualizationAndSimilarity;FocusContextTechniques","DOI":"10.1109\/TVCG.2013.213","Keywords":"comparative visualization;focus+context visualization;image set comparison","Title":"VAICo: Visual Analysis for Image Comparison","type":"new","Vector":[0.0081180734,0.0028205913,0.0,0.001901942,0.0059049973,0.0,0.1708700805,0.0,0.0111023497,0.0022837669,0.0009892817,0.0012804234,0.0008310368,0.0348237592,0.0051125832,0.0,0.0,0.0029058021,0.0050851402,0.0068598903]},"77":{"Abstract":"Scientists use DNA sequence differences between an individual's genome and a standard reference genome to study the genetic basis of disease. Such differences are called sequence variants, and determining their impact in the cell is difficult because it requires reasoning about both the type and location of the variant across several levels of biological context. In this design study, we worked with four analysts to design a visualization tool supporting variant impact assessment for three different tasks. We contribute data and task abstractions for the problem of variant impact assessment, and the carefully justified design and implementation of the Variant View tool. Variant View features an information-dense visual encoding that provides maximal information at the overview level, in contrast to the extensive navigation required by currently-prevalent genome browsers. We provide initial evidence that the tool simplified and accelerated workflows for these three tasks through three case studies. Finally, we reflect on the lessons learned in creating and refining data and task abstractions that allow for concise overviews of sprawling information spaces that can reduce or remove the need for the memory-intensive use of navigation.","Authors":"Ferstay, J.A.;Nielsen, C.B.;Munzner, T.","Clusters":"BiologyAndBioinformatics;DesignStudiesAndCaseStudies;Genetics","DOI":"10.1109\/TVCG.2013.214","Keywords":"information visualization;design study;genetic variants;bioinformatics","Title":"Variant View: Visualizing Sequence Variants in their Gene Context","type":"new","Vector":[0.0697900284,0.0,0.0,0.0,0.0,0.0,0.0026247503,0.0,0.0,0.0009369617,0.0,0.0118220317,0.0,0.0096732911,0.0,0.0,0.0070571956,0.0346574831,0.002172822,0.0089770721]},"78":{"Abstract":"Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.","Authors":"Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, E.;Bruckner, S.","Clusters":"DimensionalityReduction;SurfaceRelatedDataAndTechniques;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2013.215","Keywords":"surface approximation;volume rendering;reformation","Title":"Vessel Visualization using Curved Surface Reformation","type":"new","Vector":[0.0001028825,0.0096855453,0.0142527193,0.0,0.0,0.0116078568,0.0,0.0,0.0945039375,0.0,0.0,0.0,0.0276291541,0.0090958325,0.0,0.0,0.0,0.0,0.0,0.0011019099]},"79":{"Abstract":"For preserving the grotto wall paintings and protecting these historic cultural icons from the damage and deterioration in nature environment, a visual analytics framework and a set of tools are proposed for the discovery of degradation patterns. In comparison with the traditional analysis methods that used restricted scales, our method provides users with multi-scale analytic support to study the problems on site, cave, wall and particular degradation area scales, through the application of multidimensional visualization techniques. Several case studies have been carried out using real-world wall painting data collected from a renowned World Heritage site, to verify the usability and effectiveness of the proposed method. User studies and expert reviews were also conducted through by domain experts ranging from scientists such as microenvironment researchers, archivists, geologists, chemists, to practitioners such as conservators, restorers and curators.","Authors":"Jiawan Zhang;Kai Kang;Dajian Liu;Ye Yuan;Yanli, E.","Clusters":"ApplicationsGeneralAndOther;ArtAndAestheticsInVisualization;SocialScienceAndHumanities","DOI":"10.1109\/TVCG.2013.219","Keywords":"wall paintings;cultural heritage;visual analytics;degradation","Title":"Vis4Heritage: Visual Analytics Approach on Grotto Wall Painting Degradations","type":"new","Vector":[0.0007516133,0.0077331085,0.0,0.002504325,0.0010620016,0.0019534908,0.0125756041,0.0,0.0020477842,0.004203497,0.0060962025,0.0088024106,0.0,0.0263400771,0.0075948939,0.0016754464,0.0013912197,0.026799457,0.0009643672,0.0194952611]},"80":{"Abstract":"Visual exploration and analysis of multidimensional data becomes increasingly difficult with increasing dimensionality. We want to understand the relationships between dimensions of data, but lack flexible techniques for exploration beyond low-order relationships. Current visual techniques for multidimensional data analysis focus on binary conjunctive relationships between dimensions. Recent techniques, such as cross-filtering on an attribute relationship graph, facilitate the exploration of some higher-order conjunctive relationships, but require a great deal of care and precision to do so effectively. This paper provides a detailed analysis of the expressive power of existing visual querying systems and describes a more flexible approach in which users can explore n-ary conjunctive inter- and intra- dimensional relationships by interactively constructing queries as visual hypergraphs. In a hypergraph query, nodes represent subsets of values and hyperedges represent conjunctive relationships. Analysts can dynamically build and modify the query using sequences of simple interactions. The hypergraph serves not only as a query specification, but also as a compact visual representation of the interactive state. Using examples from several domains, focusing on the digital humanities, we describe the design considerations for developing the querying system and incorporating it into visual analysis tools. We analyze query expressiveness with regard to the kinds of questions it can and cannot pose, and describe how it simultaneously expands the expressiveness of and is complemented by cross-filtering.","Authors":"Shadoan, R.;Weaver, C.","Clusters":"GraphNetworkDataAndTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;QueriesAndSearch;SocialScienceAndHumanities","DOI":"10.1109\/TVCG.2013.220","Keywords":"digital humanities;visual query language;graph search;multivariate data analysis;higher-order conjunctive queries;graph query language;attribute relationship graphs;multi-dimensional data","Title":"Visual Analysis of Higher-Order Conjunctive Relationships in Multidimensional Data Using a Hypergraph Query System","type":"new","Vector":[0.0,0.0464765619,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0054565056,0.0,0.0,0.0,0.0,0.049164568,0.1619032965,0.0,0.0]},"81":{"Abstract":"How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.","Authors":"Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu","Clusters":"AnalysisProcessGeneral;DiffusionRelatedTechniques;InformationProcessingAndHandling;SocialNetworksAndSocialMedia;TextDocumentTopicAnalysisDataAndTechniques","DOI":"10.1109\/TVCG.2013.221","Keywords":"information propagation;agenda-setting;topic competition;social media visualization;information diffusion","Title":"Visual Analysis of Topic Competition on Social Media","type":"new","Vector":[0.0,0.0,0.0,0.0019155427,0.0,0.0050329686,0.0022838911,0.0003339806,0.002541129,0.0055140229,0.0,0.0886205231,0.0,0.0097813344,0.0082948149,0.0002134198,0.0211097183,0.0098477877,0.0,0.0785243202]},"82":{"Abstract":"Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts' feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles.","Authors":"Bogl, M.;Aigner, W.;Filzmoser, P.;Lammarsch, T.;Miksch, S.;Rind, A.","Clusters":"InteractionTechniquesGeneral;MachineLearningAndStatistics;MultipleLinkedCoordinatedViews;TimeseriesTimeVaryingDataAndTechniques","DOI":"10.1109\/TVCG.2013.222","Keywords":"model selection;visual interaction;visual analytics;time-series analysis;coordinated & multiple views","Title":"Visual Analytics for Model Selection in Time Series Analysis","type":"new","Vector":[0.0006430963,0.0003710613,0.0014298235,0.0,0.0,0.0,0.0036440677,0.0,0.0018256447,0.0060914029,0.0,0.0,0.0,0.0233602987,0.0012278229,0.0008506793,0.0,0.0579222427,0.0056335854,0.0380309116]},"83":{"Abstract":"Social network analysis (SNA) is becoming increasingly concerned not only with actors and their relations, but also with distinguishing between different types of such entities. For example, social scientists may want to investigate asymmetric relations in organizations with strict chains of command, or incorporate non-actors such as conferences and projects when analyzing coauthorship patterns. Multimodal social networks are those where actors and relations belong to different types, or modes, and multimodal social network analysis (mSNA) is accordingly SNA for such networks. In this paper, we present a design study that we conducted with several social scientist collaborators on how to support mSNA using visual analytics tools. Based on an openended, formative design process, we devised a visual representation called parallel node-link bands (PNLBs) that splits modes into separate bands and renders connections between adjacent ones, similar to the list view in Jigsaw. We then used the tool in a qualitative evaluation involving five social scientists whose feedback informed a second design phase that incorporated additional network metrics. Finally, we conducted a second qualitative evaluation with our social scientist collaborators that provided further insights on the utility of the PNLBs representation and the potential of visual analytics for mSNA.","Authors":"Ghani, S.;Bum Chul Kwon;Seungyoon Lee;Ji Soo Yi;Elmqvist, N.","Clusters":"DesignMethodologiesAndInteractionDesign;DesignStudiesAndCaseStudies;GraphNetworkDataAndTechniques;InteractionTechniquesGeneral;QualitativeEvaluation","DOI":"10.1109\/TVCG.2013.223","Keywords":"multimodal graphs;design study;node-link diagrams;qualitative evaluation;user-centered design;interaction","Title":"Visual Analytics for Multimodal Social Network Analysis: A Design Study with Social Scientists","type":"new","Vector":[0.0,0.0,0.0037882852,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0812993017,0.0,0.0,0.2907167594,0.0,0.0,0.0]},"84":{"Abstract":"We propose a novel approach of distance-based spatial clustering and contribute a heuristic computation of input parameters for guiding users in the search of interesting cluster constellations. We thereby combine computational geometry with interactive visualization into one coherent framework. Our approach entails displaying the results of the heuristics to users, as shown in Figure 1, providing a setting from which to start the exploration and data analysis. Addition interaction capabilities are available containing visual feedback for exploring further clustering options and is able to cope with noise in the data. We evaluate, and show the benefits of our approach on a sophisticated artificial dataset and demonstrate its usefulness on real-world data.","Authors":"Packer, E.;Bak, P.;Nikkila, M.;Polishchuk, V.;Ship, H.J.","Clusters":"DataClusteringAndAggregation;TopologyBasedTechniques","DOI":"10.1109\/TVCG.2013.224","Keywords":"interactive visual clustering;k-order a-(alpha)-shapes;heuristic-based spatial clustering","Title":"Visual Analytics for Spatial Clustering: Using a Heuristic Approach for Guided Exploration","type":"new","Vector":[0.0,0.0,0.0123725145,0.0,0.0038333964,0.0054284801,0.3753348015,0.008055256,0.0,0.0016391801,0.0,0.0035526356,0.0,0.0140444243,0.0037875826,0.0,0.0092543019,0.0,0.0011492261,0.0238614721]},"85":{"Abstract":"This paper is concerned with the creation of 'macros' in workflow visualization as a support tool to increase the efficiency of data curation tasks. We propose computation of candidate macros based on their usage in large collections of workflows in data repositories. We describe an efficient algorithm for extracting macro motifs from workflow graphs. We discovered that the state transition information, used to identify macro candidates, characterizes the structural pattern of the macro and can be harnessed as part of the visual design of the corresponding macro glyph. This facilitates partial automation and consistency in glyph design applicable to a large set of macro glyphs. We tested this approach against a repository of biological data holding some 9,670 workflows and found that the algorithmically generated candidate macros are in keeping with domain expert expectations.","Authors":"Maguire, E.;Rocca-Serra, P.;Sansone, S.-A.;Davies, J.;Chen, M.","Clusters":"GlyphsGlyphBasedTechniques;StateRelatedDataTechniques;VisualPatternFeatureDetectionAndTracking;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2013.225","Keywords":"motif detection;glyph generation;workflow visualization;glyph-based visualization;state-transition-based algorithm","Title":"Visual Compression of Workflow Visualizations with Automated Detection of Macro Motifs","type":"new","Vector":[0.0072655926,0.0455169974,0.0,0.0030971553,0.0,0.0048529336,0.000021011,0.0,0.0036911677,0.0062733166,0.0,0.0038856489,0.0,0.0060295374,0.0032850964,0.0,0.0399984349,0.0095573173,0.0193681417,0.008308482]},"86":{"Abstract":"As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them.","Authors":"Ferreira, N.;Poco, J.;Vo, H.T.;Freire, J.;Silva, C.T.","Clusters":"AnalysisProcessGeneral;ApplicationsGeneralAndOther;QueriesAndSearch;Traffic","DOI":"10.1109\/TVCG.2013.226","Keywords":"urban data;spatio-temporal queries;visual exploration;taxi movement data","Title":"Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.002872319,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0010091687,0.1089422383,0.0,0.0721095224]},"87":{"Abstract":"We introduce Visual Sedimentation, a novel design metaphor for visualizing data streams directly inspired by the physical process of sedimentation. Visualizing data streams (e. g., Tweets, RSS, Emails) is challenging as incoming data arrive at unpredictable rates and have to remain readable. For data streams, clearly expressing chronological order while avoiding clutter, and keeping aging data visible, are important. The metaphor is drawn from the real-world sedimentation processes: objects fall due to gravity, and aggregate into strata over time. Inspired by this metaphor, data is visually depicted as falling objects using a force model to land on a surface, aggregating into strata over time. In this paper, we discuss how this metaphor addresses the specific challenge of smoothing the transition between incoming and aging data. We describe the metaphor's design space, a toolkit developed to facilitate its implementation, and example applications to a range of case studies. We then explore the generative capabilities of the design space through our toolkit. We finally illustrate creative extensions of the metaphor when applied to real streams of data.","Authors":"Huron, S.;Vuillemot, R.;Fekete, J.","Clusters":"DynamicDataAndTechniques;DynamicVisualizationVisualizationOfChange;RealtimeProcessingRenderingAndVisualizationGeneral;StreamingDataAndTechniques;VisualDesignDesignGuidelines;VisualizationTheoryModelsAndMethods","DOI":"10.1109\/TVCG.2013.227","Keywords":"information visualization;dynamic data;realtime;data stream;design;metaphors;dynamic visualization","Title":"Visual Sedimentation","type":"new","Vector":[0.0005243587,0.0079839752,0.0,0.0000039052,0.002386693,0.011916146,0.0,0.0,0.0,0.0009516391,0.0,0.0069476909,0.0018510907,0.032456688,0.000499847,0.0088628249,0.0003777453,0.0313546148,0.0033816271,0.0193193311]},"88":{"Abstract":"In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.","Authors":"Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;van de Wetering, H.","Clusters":"Traffic","DOI":"10.1109\/TVCG.2013.228","Keywords":"traffic visualization;traffic jam propagation","Title":"Visual Traffic Jam Analysis Based on Trajectory Data","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0060350692,0.017553577,0.007828664,0.0008185513,0.0014306558,0.0,0.0,0.0027946696,0.0,0.0,0.0063004765,0.0415095929,0.0,0.0,0.1648028525]},"89":{"Abstract":"Recent advances in vector field topologymake it possible to compute its multi-scale graph representations for autonomous 2D vector fields in a robust and efficient manner. One of these representations is a Morse Connection Graph (MCG), a directed graph whose nodes correspond to Morse sets, generalizing stationary points and periodic trajectories, and arcs - to trajectories connecting them. While being useful for simple vector fields, the MCG can be hard to comprehend for topologically rich vector fields, containing a large number of features. This paper describes a visual representation of the MCG, inspired by previous work on graph visualization. Our approach aims to preserve the spatial relationships between the MCG arcs and nodes and highlight the coherent behavior of connecting trajectories. Using simulations of ocean flow, we show that it can provide useful information on the flow structure. This paper focuses specifically on MCGs computed for piecewise constant (PC) vector fields. In particular, we describe extensions of the PC framework that make it more flexible and better suited for analysis of data on complex shaped domains with a boundary. We also describe a topology simplification scheme that makes our MCG visualizations less ambiguous. Despite the focus on the PC framework, our approach could also be applied to graph representations or topological skeletons computed using different methods.","Authors":"Szymczak, A.;Sipeki, L.","Clusters":"TopologyBasedTechniques;VectorFieldsDataAndTechniques","DOI":"10.1109\/TVCG.2013.229","Keywords":"vector field topology;morse connection graph","Title":"Visualization of Morse Connection Graphs for Topologically Rich 2D Vector fields","type":"new","Vector":[0.0044268477,0.0136396712,0.0350826372,0.0014218567,0.0,0.0834764987,0.0221421089,0.0347752745,0.0022803034,0.0019551118,0.0004490001,0.0,0.0,0.0039721066,0.0008826744,0.0205031459,0.0033615186,0.0,0.0,0.0452895129]},"90":{"Abstract":"Analysis of dynamic object deformations such as cardiac motion is of great importance, especially when there is a necessity to visualize and compare the deformation behavior across subjects. However, there is a lack of effective techniques for comparative visualization and assessment of a collection of motion data due to its 4-dimensional nature, i.e., timely varying three-dimensional shapes. From the geometric point of view, the motion change can be considered as a function defined on the 2D manifold of the surface. This paper presents a novel classification and visualization method based on a medial surface shape space, in which two novel shape descriptors are defined, for discriminating normal and abnormal human heart deformations as well as localizing the abnormal motion regions. In our medial surface shape space, the geodesic distance connecting two points in the space measures the similarity between their corresponding medial surfaces, which can quantify the similarity and disparity of the 3D heart motions. Furthermore, the novel descriptors can effectively localize the inconsistently deforming myopathic regions on the left ventricle. An easy visualization of heart motion sequences on the projected space allows users to distinguish the deformation differences. Our experimental results on both synthetic and real imaging data show that this method can automatically classify the healthy and myopathic subjects and accurately detect myopathic regions on the left ventricle, which outperforms other conventional cardiac diagnostic methods.","Authors":"Taimouri, V.;Jing Hua","Clusters":"BiomedicalScienceAndMedicine;ComparisonComparativeVisualizationAndSimilarity;ShapeRelatedTechniques;SurfaceRelatedDataAndTechniques","DOI":"10.1109\/TVCG.2013.230","Keywords":"shape space;medial surface;comparative visualization;left ventricle diagnosis","Title":"Visualization of Shape Motions in Shape Space","type":"new","Vector":[0.0257817998,0.0004672852,0.0121776002,0.0096845742,0.0002220344,0.006515968,0.0021799925,0.0026669882,0.0201628179,0.0033281177,0.0069129486,0.0011017759,0.000221179,0.0066600825,0.0160293755,0.0028769066,0.0,0.0078276124,0.0,0.0096042955]},"91":{"Abstract":"To analyze data such as the US Federal Budget or characteristics of the student population of a University it is common to look for changes over time. This task can be made easier and more fruitful if the analysis is performed by grouping by attributes, such as by Agencies, Bureaus and Accounts for the Budget, or Ethnicity, Gender and Major in a University. We present TreeVersity2, a web based interactive data visualization tool that allows users to analyze change in datasets by creating dynamic hierarchies based on the data attributes. TreeVersity2 introduces a novel space filling visualization (StemView) to represent change in trees at multiple levels - not just at the leaf level. With this visualization users can explore absolute and relative changes, created and removed nodes, and each node's actual values, while maintaining the context of the tree. In addition, TreeVersity2 provides overviews of change over the entire time period, and a reporting tool that lists outliers in textual form, which helps users identify the major changes in the data without having to manually setup filters. We validated TreeVersity2 with 12 case studies with organizations as diverse as the National Cancer Institute, Federal Drug Administration, Department of Transportation, Office of the Bursar of the University of Maryland, or eBay. Our case studies demonstrated that TreeVersity2 is flexible enough to be used in different domains and provide useful insights for the data owners. A TreeVersity2 demo can be found at https:\/\/treeversity.cattlab.umd.edu.","Authors":"Guerra-Gomez, J.;Pack, M.L.;Plaisant, C.;Shneiderman, B.","Clusters":"HierarchicalTreeDataAndTechniques","DOI":"10.1109\/TVCG.2013.231","Keywords":"information visualization;tree comparison","Title":"Visualizing Change over Time Using Dynamic Hierarchies: TreeVersity2 and the StemView","type":"new","Vector":[0.0,0.145613132,0.0,0.0,0.0,0.0,0.0,0.0109143321,0.0,0.0061805749,0.0,0.010697381,0.0,0.0083511572,0.0,0.0,0.0000698468,0.0228894391,0.0,0.0180240221]},"92":{"Abstract":"An important feature of networks for many application domains is their community structure. This is because objects within the same community usually have at least one property in common. The investigation of community structure can therefore support the understanding of object attributes from the network topology alone. In real-world systems, objects may belong to several communities at the same time, i.e., communities can overlap. Analyzing fuzzy community memberships is essential to understand to what extent objects contribute to different communities and whether some communities are highly interconnected. We developed a visualization approach that is based on node-link diagrams and supports the investigation of fuzzy communities in weighted undirected graphs at different levels of detail. Starting with the network of communities, the user can continuously drill down to the network of individual nodes and finally analyze the membership distribution of nodes of interest. Our approach uses layout strategies and further visual mappings to graphically encode the fuzzy community memberships. The usefulness of our approach is illustrated by two case studies analyzing networks of different domains: social networking and biological interactions. The case studies showed that our layout and visualization approach helps investigate fuzzy overlapping communities. Fuzzy vertices as well as the different communities to which they belong can be easily identified based on node color and position.","Authors":"Vehlow, C.;Reinhardt, T.;Weiskopf, D.","Clusters":"DataClusteringAndAggregation;GraphNetworkDataAndTechniques;SocialNetworksAndSocialMedia;UncertaintyTechniquesAndVisualization","DOI":"10.1109\/TVCG.2013.232","Keywords":"overlapping community visualization;uncertainty visualization;fuzzy clustering;graph visualization","Title":"Visualizing Fuzzy Overlapping Communities in Networks","type":"new","Vector":[0.0449093196,0.0742010175,0.0640550736,0.0,0.0,0.0,0.0392261257,0.0,0.0,0.0415155379,0.0,0.0,0.0,0.0,0.0,0.0,0.1129901904,0.0,0.0,0.0]},"93":{"Abstract":"Distributed systems are complex to develop and administer, and performance problem diagnosis is particularly challenging. When performance degrades, the problem might be in any of the system's many components or could be a result of poor interactions among them. Recent research efforts have created tools that automatically localize the problem to a small number of potential culprits, but research is needed to understand what visualization techniques work best for helping distributed systems developers understand and explore their results. This paper compares the relative merits of three well-known visualization approaches (side-by-side, diff, and animation) in the context of presenting the results of one proven automated localization technique called request-flow comparison. Via a 26-person user study, which included real distributed systems developers, we identify the unique benefits that each approach provides for different problem types and usage modes.","Authors":"Sambasivan, R.R.;Shafer, I.;Mazurek, M.L.;Ganger, G.R.","Clusters":"DistributedSystemsAndGridEnvironments;HumanComputerInteractionHumanFactors;ReasoningProblemSolvingAndDecisionMaking","DOI":"10.1109\/TVCG.2013.233","Keywords":"visualization;distributed systems;problem diagnosis;human factors","Title":"Visualizing Request-Flow Comparison to Aid Performance Diagnosis in Distributed Systems","type":"new","Vector":[0.0,0.0457352698,0.0,0.0,0.0,0.0304787575,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1935233248,0.0,0.0,0.0372411989,0.0,0.0129622007,0.0215983445]},"94":{"Abstract":"An ongoing debate in the Visualization community concerns the role that visualization types play in data understanding. In human cognition, understanding and memorability are intertwined. As a first step towards being able to ask questions about impact and effectiveness, here we ask: 'What makes a visualization memorable?' We ran the largest scale visualization study to date using 2,070 single-panel visualizations, categorized with visualization type (e.g., bar chart, line graph, etc.), collected from news media sites, government reports, scientific journals, and infographic sources. Each visualization was annotated with additional attributes, including ratings for data-ink ratios and visual densities. Using Amazon's Mechanical Turk, we collected memorability scores for hundreds of these visualizations, and discovered that observers are consistent in which visualizations they find memorable and forgettable. We find intuitive results (e.g., attributes like color and the inclusion of a human recognizable object enhance memorability) and less intuitive results (e.g., common graphs are less memorable than unique visualization types). Altogether our findings suggest that quantifying memorability is a general metric of the utility of information, an essential step towards determining how to design effective visualizations.","Authors":"Borkin, M.;Vo, A.A.;Bylinskii, Z.;Isola, P.;Sunkavalli, S.;Oliva, A.;Pfister, H.","Clusters":"Cognition;Taxonomies","DOI":"10.1109\/TVCG.2013.234","Keywords":"memorability;information visualization;visualization taxonomy","Title":"What Makes a Visualization Memorable?","type":"new","Vector":[0.0000409835,0.0015391896,0.0001733557,0.0,0.0,0.0,0.0005574226,0.0007446381,0.0,0.0008558959,0.0,0.0059647741,0.0,0.0760123034,0.0,0.0,0.0106152682,0.044615565,0.0034001494,0.0100776135]},"95":{"Abstract":"Recently there has been increasing research interest in displaying graphs with curved edges to produce more readable visualizations. While there are several automatic techniques, little has been done to evaluate their effectiveness empirically. In this paper we present two experiments studying the impact of edge curvature on graph readability. The goal is to understand the advantages and disadvantages of using curved edges for common graph tasks compared to straight line segments, which are the conventional choice for showing edges in node-link diagrams. We included several edge variations: straight edges, edges with different curvature levels, and mixed straight and curved edges. During the experiments, participants were asked to complete network tasks including determination of connectivity, shortest path, node degree, and common neighbors. We also asked the participants to provide subjective ratings of the aesthetics of different edge types. The results show significant performance differences between the straight and curved edges and clear distinctions between variations of curved edges.","Authors":"Kai Xu;Rooney, C.;Passmore, P.;Dong-Han Ham;Nguyen, P.H.","Clusters":"CurvesAndCurvature;EvaluationGeneral;GraphNetworkDataAndTechniques","DOI":"10.1109\/TVCG.2012.189","Keywords":"visualization;curved edges;evaluation;graph","Title":"A User Study on Curved Edges in Graph Visualization","type":"new","Vector":[0.0,0.1012936376,0.003165906,0.0,0.0,0.003052965,0.0,0.0,0.001858994,0.0,0.0,0.0,0.0,0.1112369654,0.0057666711,0.003157757,0.0455714997,0.0,0.0,0.0]},"96":{"Abstract":"All major web mapping services use the web Mercator projection. This is a poor choice for maps of the entire globe or areas of the size of continents or larger countries because the Mercator projection shows medium and higher latitudes with extreme areal distortion and provides an erroneous impression of distances and relative areas. The web Mercator projection is also not able to show the entire globe, as polar latitudes cannot be mapped. When selecting an alternative projection for information visualization, rivaling factors have to be taken into account, such as map scale, the geographic area shown, the map's height-to-width ratio, and the type of cartographic visualization. It is impossible for a single map projection to meet the requirements for all these factors. The proposed composite map projection combines several projections that are recommended in cartographic literature and seamlessly morphs map space as the user changes map scale or the geographic region displayed. The composite projection adapts the map's geometry to scale, to the map's height-to-width ratio, and to the central latitude of the displayed area by replacing projections and adjusting their parameters. The composite projection shows the entire globe including poles; it portrays continents or larger countries with less distortion (optionally without areal distortion); and it can morph to the web Mercator projection for maps showing small regions.","Authors":"Jenny, B.","Clusters":"InternetWebVisualizationForTheMasses;Maps;ProgrammingAlgorithmsAndDataStructures","DOI":"10.1109\/TVCG.2012.192","Keywords":"web mapping;web cartography;web mercator;html5 canvas;multi-scale map;web map projection","Title":"Adaptive Composite Map Projections","type":"new","Vector":[0.0,0.0071199524,0.0040968931,0.0027099472,0.0006666501,0.0043730774,0.0070170639,0.0,0.0,0.0,0.0214169449,0.0123976516,0.0409265334,0.0125858279,0.0,0.0,0.0,0.0390490774,0.0,0.0]},"97":{"Abstract":"In this paper, we investigate the problem of labeling point sites in focus regions of maps or diagrams. This problem occurs, for example, when the user of a mapping service wants to see the names of restaurants or other POIs in a crowded downtown area but keep the overview over a larger area. Our approach is to place the labels at the boundary of the focus region and connect each site with its label by a linear connection, which is called a leader. In this way, we move labels from the focus region to the less valuable context region surrounding it. In order to make the leader layout well readable, we present algorithms that rule out crossings between leaders and optimize other characteristics such as total leader length and distance between labels. This yields a new variant of the boundary labeling problem, which has been studied in the literature. Other than in traditional boundary labeling, where leaders are usually schematized polylines, we focus on leaders that are either straight-line segments or Bezier curves. Further, we present algorithms that, given the sites, find a position of the focus region that optimizes the above characteristics. We also consider a variant of the problem where we have more sites than space for labels. In this situation, we assume that the sites are prioritized by the user. Alternatively, we take a new facility-location perspective which yields a clustering of the sites. We label one representative of each cluster. If the user wishes, we apply our approach to the sites within a cluster, giving details on demand.","Authors":"Fink, M.;Haunert, J.-H.;Schulz, A.;Spoerhase, J.;Wolff, A.","Clusters":"DataClusteringAndAggregation;FocusContextTechniques;GeographyGeospatialVisCartographyTerrainVis;SmallMobileUbiquitousDevicesDisplays","DOI":"10.1109\/TVCG.2012.193","Keywords":"focus+context technique;mobile and ubiquitous visualization;geographic\/geospatial visualization;data clustering","Title":"Algorithms for Labeling Focus Regions","type":"new","Vector":[0.0040154803,0.0176151996,0.0120792935,0.0,0.0,0.0075410364,0.0291258608,0.0084740655,0.0062464082,0.0,0.0028749127,0.0266947702,0.0079200462,0.0119815949,0.0003067203,0.0109658508,0.0128749865,0.018871846,0.0011261998,0.0037539753]},"98":{"Abstract":"Comparing slopes is a fundamental graph reading task and the aspect ratio chosen for a plot influences how easy these comparisons are to make. According to Banking to 45\u00c2\u00b0, a classic design guideline first proposed and studied by Cleveland et al., aspect ratios that center slopes around 45\u00c2\u00b0 minimize errors in visual judgments of slope ratios. This paper revisits this earlier work. Through exploratory pilot studies that expand Cleveland et al.'s experimental design, we develop an empirical model of slope ratio estimation that fits more extreme slope ratio judgments and two common slope ratio estimation strategies. We then run two experiments to validate our model. In the first, we show that our model fits more generally than the one proposed by Cleveland et al. and we find that, in general, slope ratio errors are not minimized around 45\u00c2\u00b0. In the second experiment, we explore a novel hypothesis raised by our model: that visible baselines can substantially mitigate errors made in slope judgments. We conclude with an application of our model to aspect ratio selection.","Authors":"Talbot, J.;Gerth, J.;Hanrahan, P.","Clusters":"Perception;VectorFieldsDataAndTechniques;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2012.196","Keywords":"slope perception;orientation resolution;aspect ratio selection;banking to 45 degrees","Title":"An Empirical Model of Slope Ratio Comparisons","type":"new","Vector":[0.0013560015,0.0018378084,0.0133416102,0.0008685327,0.001079498,0.0027638385,0.0,0.0075439492,0.0065513547,0.003789211,0.0046908294,0.0,0.0,0.0736096386,0.0,0.0,0.0,0.0436703343,0.010737348,0.0]},"99":{"Abstract":"In written and spoken communications, figures of speech (e.g., metaphors and synecdoche) are often used as an aid to help convey abstract or less tangible concepts. However, the benefits of using rhetorical illustrations or embellishments in visualization have so far been inconclusive. In this work, we report an empirical study to evaluate hypotheses that visual embellishments may aid memorization, visual search and concept comprehension. One major departure from related experiments in the literature is that we make use of a dual-task methodology in our experiment. This design offers an abstraction of typical situations where viewers do not have their full attention focused on visualization (e.g., in meetings and lectures). The secondary task introduces \u00e2\u20ac\u0153divided attention\u00e2\u20ac\u009d, and makes the effects of visual embellishments more observable. In addition, it also serves as additional masking in memory-based trials. The results of this study show that visual embellishments can help participants better remember the information depicted in visualization. On the other hand, visual embellishments can have a negative impact on the speed of visual search. The results show a complex pattern as to the benefits of visual embellishments in helping participants grasp key concepts from visualization.","Authors":"Borgo, R.;Abdul-Rahman, A.;Mohamed, F.;Grant, P.W.;Reppa, I.;Floridi, L.;Chen, M.","Clusters":"Cognition;EvaluationGeneral;GlyphsGlyphBasedTechniques;QueriesAndSearch;VisualDesignDesignGuidelines;VisualizationTheoryModelsAndMethods","DOI":"10.1109\/TVCG.2012.197","Keywords":"evaluation;icons;cognition;working memory;visual embellishments;visual search;long-term memory;metaphors","Title":"An Empirical Study on Using Visual Embellishments in Visualization","type":"new","Vector":[0.0,0.0,0.0,0.0000845005,0.0,0.0,0.0,0.0018576758,0.0,0.0005240214,0.0,0.0004855957,0.0,0.1605786801,0.0,0.0,0.0,0.000338071,0.012442783,0.0]},"100":{"Abstract":"People have difficulty understanding statistical information and are unaware of their wrong judgments, particularly in Bayesian reasoning. Psychology studies suggest that the way Bayesian problems are represented can impact comprehension, but few visual designs have been evaluated and only populations with a specific background have been involved. In this study, a textual and six visual representations for three classic problems were compared using a diverse subject pool through crowdsourcing. Visualizations included area-proportional Euler diagrams, glyph representations, and hybrid diagrams combining both. Our study failed to replicate previous findings in that subjects' accuracy was remarkably lower and visualizations exhibited no measurable benefit. A second experiment confirmed that simply adding a visualization to a textual Bayesian problem is of little help, even when the text refers to the visualization, but suggests that visualizations are more effective when the text is given without numerical values. We discuss our findings and the need for more such experiments to be carried out on heterogeneous populations of non-experts.","Authors":"Micallef, L.;Dragicevic, P.;Fekete, J.","Clusters":"ChartsDiagramsPlots;Cognition;EvaluationGeneral;GlyphsGlyphBasedTechniques;MachineLearningAndStatistics","DOI":"10.1109\/TVCG.2012.199","Keywords":"glyph;base rate fallacy;probabilistic judgment;bayesian reasoning;euler diagrams;crowdsourcing","Title":"Assessing the Effect of Visualizations on Bayesian Reasoning through Crowdsourcing","type":"new","Vector":[0.0,0.0090740965,0.0079761693,0.0109826519,0.0,0.0,0.0,0.0037739103,0.0028238302,0.020699411,0.0,0.0217051827,0.000212869,0.1420507977,0.0,0.0002400535,0.0024309329,0.0158596731,0.0014856649,0.0]},"101":{"Abstract":"The importance of interaction to Information Visualization (InfoVis) and, in particular, of the interplay between interactivity and cognition is widely recognized [12, 15, 32, 55, 70]. This interplay, combined with the demands from increasingly large and complex datasets, is driving the increased significance of interaction in InfoVis. In parallel, there have been rapid advances in many facets of interaction technologies. However, InfoVis interactions have yet to take full advantage of these new possibilities in interaction technologies, as they largely still employ the traditional desktop, mouse, and keyboard setup of WIMP (Windows, Icons, Menus, and a Pointer) interfaces. In this paper, we reflect more broadly about the role of more \u00e2\u20ac\u0153natural\u00e2\u20ac\u009d interactions for InfoVis and provide opportunities for future research. We discuss and relate general HCI interaction models to existing InfoVis interaction classifications by looking at interactions from a novel angle, taking into account the entire spectrum of interactions. Our discussion of InfoVis-specific interaction design considerations helps us identify a series of underexplored attributes of interaction that can lead to new, more \u00e2\u20ac\u0153natural,\u00e2\u20ac\u009d interaction techniques for InfoVis.","Authors":"Bongshin Lee;Isenberg, P.;Riche, N.H.;Carpendale, S.","Clusters":"DesignMethodologiesAndInteractionDesign;InteractionTechniquesGeneral;UserInterfacesGeneral;VisualDesignDesignGuidelines","DOI":"10.1109\/TVCG.2012.204","Keywords":"natural user interface;post-wimp;design considerations;interaction","Title":"Beyond Mouse and Keyboard: Expanding Design Considerations for Information Visualization Interactions","type":"new","Vector":[0.0048913224,0.0,0.0,0.0,0.0,0.0048997075,0.0,0.0,0.0,0.0,0.0100891742,0.0294262318,0.0043267822,0.1363724593,0.0,0.0,0.0230419745,0.0424184852,0.0009256486,0.0068497745]},"102":{"Abstract":"We characterize the design space of the algorithms that sequentially tile a rectangular area with smaller, fixed-surface, rectangles. This space consist of five independent dimensions: Order, Size, Score, Recurse and Phrase. Each of these dimensions describe a particular aspect of such layout tasks. This class of layouts is interesting, because, beyond encompassing simple grids, tables and trees, it also includes all kinds of treemaps involving the placement of rectangles. For instance, Slice and dice, Squarified, Strip and Pivot layouts are various points in this five dimensional space. Many classic statistics visualizations, such as 100% stacked bar charts, mosaic plots and dimensional stacking, are also instances of this class. A few new and potentially interesting points in this space are introduced, such as spiral treemaps and variations on the strip layout. The core algorithm is implemented as a JavaScript prototype that can be used as a layout component in a variety of InfoViz toolkits.","Authors":"Baudel, T.;Broeksema, B.","Clusters":"ChartsDiagramsPlots;DimensionalityReduction;HierarchicalTreeDataAndTechniques;MeshesGridsAndLattices;VisualEncodingAndLayoutGeneral;VisualizationTheoryModelsAndMethods","DOI":"10.1109\/TVCG.2012.205","Keywords":"mosaic plots;grids;visualization models;layout;treemap;dimensional stacking;tables & tree layouts","Title":"Capturing the Design Space of Sequential Space-filling Layouts","type":"new","Vector":[0.0,0.1006774539,0.0,0.0,0.0003437347,0.0,0.0040144774,0.0,0.0,0.0,0.0,0.0012851423,0.0,0.0,0.0,0.0,0.0,0.0593650167,0.0088254843,0.0]},"103":{"Abstract":"Classifying a set of objects into clusters can be done in numerous ways, producing different results. They can be visually compared using contingency tables [27], mosaicplots [13], fluctuation diagrams [15], tableplots [20] , (modified) parallel coordinates plots [28], Parallel Sets plots [18] or circos diagrams [19]. Unfortunately the interpretability of all these graphical displays decreases rapidly with the numbers of categories and clusterings. In his famous book A Semiology of Graphics [5] Bertin writes \u00e2\u20ac\u0153the discovery of an ordered concept appears as the ultimate point in logical simplification since it permits reducing to a single instant the assimilation of series which previously required many instants of study\u00e2\u20ac\u009d. Or in more everyday language, if you use good orderings you can see results immediately that with other orderings might take a lot of effort. This is also related to the idea of effect ordering [12], that data should be organised to reflect the effect you want to observe. This paper presents an efficient algorithm based on Bertin's idea and concepts related to Kendall's t [17], which finds informative joint orders for two or more nominal classification variables. We also show how these orderings improve the various displays and how groups of corresponding categories can be detected using a top-down partitioning algorithm. Different clusterings based on data on the environmental performance of cars sold in Germany are used for illustration. All presented methods are available in the R package extracat which is used to compute the optimized orderings for the example dataset.","Authors":"Pilhofer, A.;Gribov, A.;Unwin, A.","Clusters":"ChartsDiagramsPlots;Optimization;SegmentationAndClassification;TimeseriesTimeVaryingDataAndTechniques","DOI":"10.1109\/TVCG.2012.207","Keywords":"order optimization;classification;fluctuation diagrams;seriation","Title":"Comparing Clusterings Using Bertin's Idea","type":"new","Vector":[0.0,0.0049756918,0.0030446025,0.0101904115,0.0,0.0,0.1336649941,0.0064810923,0.0023476143,0.0032531986,0.0015346937,0.0,0.0,0.0,0.0,0.0,0.0169637994,0.0979771308,0.0045092641,0.0]},"104":{"Abstract":"We present a novel technique-Compressed Adjacency Matrices-for visualizing gene regulatory networks. These directed networks have strong structural characteristics: out-degrees with a scale-free distribution, in-degrees bound by a low maximum, and few and small cycles. Standard visualization techniques, such as node-link diagrams and adjacency matrices, are impeded by these network characteristics. The scale-free distribution of out-degrees causes a high number of intersecting edges in node-link diagrams. Adjacency matrices become space-inefficient due to the low in-degrees and the resulting sparse network. Compressed adjacency matrices, however, exploit these structural characteristics. By cutting open and rearranging an adjacency matrix, we achieve a compact and neatly-arranged visualization. Compressed adjacency matrices allow for easy detection of subnetworks with a specific structure, so-called motifs, which provide important knowledge about gene regulatory networks to domain experts. We summarize motifs commonly referred to in the literature, and relate them to network analysis tasks common to the visualization domain. We show that a user can easily find the important motifs in compressed adjacency matrices, and that this is hard in standard adjacency matrix and node-link diagrams. We also demonstrate that interaction techniques for standard adjacency matrices can be used for our compressed variant. These techniques include rearrangement clustering, highlighting, and filtering.","Authors":"Dinkla, K.;Westenberg, M.A.;van Wijk, J.J.","Clusters":"Genetics;GraphNetworkDataAndTechniques;MatrixRelatedTechniques","DOI":"10.1109\/TVCG.2012.208","Keywords":"scale-free;adjacency matrix;networks;gene regulation","Title":"Compressed Adjacency Matrices: Untangling Gene Regulatory Networks","type":"new","Vector":[0.0279666566,0.0594100251,0.0599480836,0.0,0.0,0.0,0.0093522865,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0005146752,0.0,0.1791749607,0.0,0.0185499235,0.0]},"105":{"Abstract":"Storyline visualization is a technique used to depict the temporal dynamics of social interactions. This visualization technique was first introduced as a hand-drawn illustration in XKCD's \u00e2\u20ac\u0153Movie Narrative Charts\u00e2\u20ac\u009d [21]. If properly constructed, the visualization can convey both global trends and local interactions in the data. However, previous methods for automating storyline visualizations are overly simple, failing to achieve some of the essential principles practiced by professional illustrators. This paper presents a set of design considerations for generating aesthetically pleasing and legible storyline visualizations. Our layout algorithm is based on evolutionary computation, allowing us to effectively incorporate multiple objective functions. We show that the resulting visualizations have significantly improved aesthetics and legibility compared to existing techniques.","Authors":"Tanahashi, Y.;Kwan-Liu Ma","Clusters":"DesignStudiesAndCaseStudies;Storytelling;TimeseriesTimeVaryingDataAndTechniques;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2012.212","Keywords":"design study;storyline visualization;timeline visualization;layout algorithm","Title":"Design Considerations for Optimizing Storyline Visualizations","type":"new","Vector":[0.0052811396,0.0405958557,0.0017915854,0.0,0.0,0.0069235845,0.0123110572,0.0,0.0059896651,0.0013548548,0.0,0.011058606,0.0,0.02406256,0.0033072267,0.0004519551,0.0198329672,0.0037595603,0.0041256342,0.0402710677]},"106":{"Abstract":"Design studies are an increasingly popular form of problem-driven visualization research, yet there is little guidance available about how to do them effectively. In this paper we reflect on our combined experience of conducting twenty-one design studies, as well as reading and reviewing many more, and on an extensive literature review of other field work methods and methodologies. Based on this foundation we provide definitions, propose a methodological framework, and provide practical guidance for conducting design studies. We define a design study as a project in which visualization researchers analyze a specific real-world problem faced by domain experts, design a visualization system that supports solving this problem, validate the design, and reflect about lessons learned in order to refine visualization design guidelines. We characterize two axes - a task clarity axis from fuzzy to crisp and an information location axis from the domain expert's head to the computer - and use these axes to reason about design study contributions, their suitability, and uniqueness from other approaches. The proposed methodological framework consists of 9 stages: learn, winnow, cast, discover, design, implement, deploy, reflect, and write. For each stage we provide practical guidance and outline potential pitfalls. We also conducted an extensive literature survey of related methodological approaches that involve a significant amount of qualitative field work, and compare design study methodology to that of ethnography, grounded theory, and action research.","Authors":"Sedlmair, M.;Meyer, M.;Munzner, T.","Clusters":"DesignMethodologiesAndInteractionDesign;DesignStudiesAndCaseStudies;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2012.213","Keywords":"methodology;visualization;design study;framework","Title":"Design Study Methodology: Reflections from the Trenches and the Stacks","type":"new","Vector":[0.0020160069,0.0,0.0015828242,0.0,0.0,0.006167792,0.0075211975,0.0003265007,0.0047376702,0.007041252,0.0,0.0212629291,0.0081438042,0.0948514408,0.0025021142,0.0021268375,0.0245387473,0.0254942446,0.0042822197,0.0179707873]},"107":{"Abstract":"We present an ethnographic study of design differences in visual presentations between academic disciplines. Characterizing design conventions between users and data domains is an important step in developing hypotheses, tools, and design guidelines for information visualization. In this paper, disciplines are compared at a coarse scale between four groups of fields: social, natural, and formal sciences; and the humanities. Two commonplace presentation types were analyzed: electronic slideshows and whiteboard \u00e2\u20ac\u0153chalk talks\u00e2\u20ac\u009d. We found design differences in slideshows using two methods - coding and comparing manually-selected features, like charts and diagrams, and an image-based analysis using PCA called eigenslides. In whiteboard talks with controlled topics, we observed design behaviors, including using representations and formalisms from a participant's own discipline, that suggest authors might benefit from novel assistive tools for designing presentations. Based on these findings, we discuss opportunities for visualization ethnography and human-centered authoring tools for visual information.","Authors":"Gomez, S.R.;Jianu, R.;Ziemkiewicz, C.;Hua Guo;Laidlaw, D.H.","Clusters":"AnalysisProcessGeneral;PresentationProductionAndDissemination;VisualDesignDesignGuidelines","DOI":"10.1109\/TVCG.2012.214","Keywords":"presentations;information visualization;design;visual analysis","Title":"Different Strokes for Different Folks: Visual Presentation Design between Disciplines","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0035027123,0.0,0.0,0.0011933053,0.0,0.01781741,0.0,0.1327836358,0.0,0.0,0.0137906492,0.0047647716,0.0029038666,0.004475468]},"108":{"Abstract":"For information visualization researchers, eye tracking has been a useful tool to investigate research participants' underlying cognitive processes by tracking their eye movements while they interact with visual techniques. We used an eye tracker to better understand why participants with a variant of a tabular visualization called `SimulSort' outperformed ones with a conventional table and typical one-column sorting feature (i.e., Typical Sorting). The collected eye-tracking data certainly shed light on the detailed cognitive processes of the participants; SimulSort helped with decision-making tasks by promoting efficient browsing behavior and compensatory decision-making strategies. However, more interestingly, we also found unexpected eye-tracking patterns with Simul- Sort. We investigated the cause of the unexpected patterns through a crowdsourcing-based study (i.e., Experiment 2), which elicited an important limitation of the eye tracking method: incapability of capturing peripheral vision. This particular result would be a caveat for other visualization researchers who plan to use an eye tracker in their studies. In addition, the method to use a testing stimulus (i.e., influential column) in Experiment 2 to verify the existence of such limitations would be useful for researchers who would like to verify their eye tracking results.","Authors":"Sung-Hee Kim;Zhihua Dong;Hanjun Xian;Upatising, B.;Ji Soo Yi","Clusters":"EvaluationGeneral;Perception;QuantitativeEvaluation;ReasoningProblemSolvingAndDecisionMaking","DOI":"10.1109\/TVCG.2012.215","Keywords":"visualized decision making;limitations;crowdsourcing;peripheral vision;eye tracking;quantitative empirical study","Title":"Does an Eye Tracker Tell the Truth about Visualizations?: findings while Investigating Visualizations for Decision Making","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0100528344,0.0,0.0,0.0,0.0,0.0,0.1833384211,0.0,0.0,0.0,0.040214135,0.0,0.0]},"109":{"Abstract":"We report on results of a series of user studies on the perception of four visual variables that are commonly used in the literature to depict uncertainty. To the best of our knowledge, we provide the first formal evaluation of the use of these variables to facilitate an easier reading of uncertainty in visualizations that rely on line graphical primitives. In addition to blur, dashing and grayscale, we investigate the use of `sketchiness' as a visual variable because it conveys visual impreciseness that may be associated with data quality. Inspired by work in non-photorealistic rendering and by the features of hand-drawn lines, we generate line trajectories that resemble hand-drawn strokes of various levels of proficiency-ranging from child to adult strokes-where the amount of perturbations in the line corresponds to the level of uncertainty in the data. Our results show that sketchiness is a viable alternative for the visualization of uncertainty in lines and is as intuitive as blur; although people subjectively prefer dashing style over blur, grayscale and sketchiness. We discuss advantages and limitations of each technique and conclude with design considerations on how to deploy these visual variables to effectively depict various levels of uncertainty for line marks.","Authors":"Boukhelifa, N.;Bezerianos, A.;Isenberg, T.;Fekete, J.","Clusters":"Perception;QualitativeEvaluation;QuantitativeEvaluation;UncertaintyTechniquesAndVisualization","DOI":"10.1109\/TVCG.2012.220","Keywords":"uncertainty visualization;qualitative evaluation;perception;quantitative evaluation","Title":"Evaluating Sketchiness as a Visual Variable for the Depiction of Qualitative Uncertainty","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.001100582,0.0,0.0,0.1864941996,0.0,0.0,0.0,0.1312021849,0.0,0.0,0.0,0.0007584113,0.0,0.0]},"110":{"Abstract":"This paper reports on a between-subject, comparative online study of three information visualization demonstrators that each displayed the same dataset by way of an identical scatterplot technique, yet were different in style in terms of visual and interactive embellishment. We validated stylistic adherence and integrity through a separate experiment in which a small cohort of participants assigned our three demonstrators to predefined groups of stylistic examples, after which they described the styles with their own words. From the online study, we discovered significant differences in how participants execute specific interaction operations, and the types of insights that followed from them. However, in spite of significant differences in apparent usability, enjoyability and usefulness between the style demonstrators, no variation was found on the self-reported depth, expert-rated depth, confidence or difficulty of the resulting insights. Three different methods of insight analysis have been applied, revealing how style impacts the creation of insights, ranging from higher-level pattern seeking to a more reflective and interpretative engagement with content, which is what underlies the patterns. As this study only forms the first step in determining how the impact of style in information visualization could be best evaluated, we propose several guidelines and tips on how to gather, compare and categorize insights through an online evaluation study, particularly in terms of analyzing the concise, yet wide variety of insights and observations in a trustworthy and reproducable manner.","Authors":"Vande Moere, A.;Tomitsch, M.;Wimmer, C.;Christoph, B.;Grechenig, T.","Clusters":"ArtAndAestheticsInVisualization;EvaluationGeneral;IllustrativeVisualization;VisualDesignDesignGuidelines","DOI":"10.1109\/TVCG.2012.221","Keywords":"online study;aesthetics;style;visualization;user experience;design;evaluation","Title":"Evaluating the Effect of Style in Information Visualization","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0155610156,0.0,0.0,0.0,0.0,0.0159314131,0.0,0.1585298693,0.0,0.0,0.0,0.0,0.0,0.0052674268]},"111":{"Abstract":"Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways' corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly.","Authors":"Wongsuphasawat, K.;Gotz, D.","Clusters":"BiomedicalScienceAndMedicine;StateRelatedDataTechniques;TimeseriesTimeVaryingDataAndTechniques","DOI":"10.1109\/TVCG.2012.225","Keywords":"information visualization;temporal event sequences;state diagram;state transitions;outflow","Title":"Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization","type":"new","Vector":[0.0,0.0655309366,0.0,0.0,0.0,0.0151415202,0.0217837787,0.0,0.0,0.0,0.0,0.0,0.0,0.0529663656,0.0056543156,0.0,0.0047101315,0.0,0.0,0.2292310548]},"112":{"Abstract":"A discourse parser is a natural language processing system which can represent the organization of a document based on a rhetorical structure tree-one of the key data structures enabling applications such as text summarization, question answering and dialogue generation. Computational linguistics researchers currently rely on manually exploring and comparing the discourse structures to get intuitions for improving parsing algorithms. In this paper, we present DAViewer, an interactive visualization system for assisting computational linguistics researchers to explore, compare, evaluate and annotate the results of discourse parsers. An iterative user-centered design process with domain experts was conducted in the development of DAViewer. We report the results of an informal formative study of the system to better understand how the proposed visualization and interaction techniques are used in the real research environment.","Authors":"Jian Zhao;Chevalier, F.;Collins, C.;Balakrishnan, R.","Clusters":"HierarchicalTreeDataAndTechniques;InteractionTechniquesGeneral;SocialScienceAndHumanities;TextDocumentTopicAnalysisDataAndTechniques","DOI":"10.1109\/TVCG.2012.226","Keywords":"discourse structure;visual analytics;computational linguisitics;tree comparison;interaction","Title":"Facilitating Discourse Analysis with Interactive Visualization","type":"new","Vector":[0.0,0.1351258102,0.0,0.0,0.0,0.0,0.0076699609,0.0277534709,0.0,0.0043876435,0.0,0.1027130581,0.0,0.0011474864,0.0,0.0,0.0,0.0267136728,0.0,0.0]},"113":{"Abstract":"Reading a visualization can involve a number of tasks such as extracting, comparing or aggregating numerical values. Yet, most of the charts that are published in newspapers, reports, books, and on the Web only support a subset of these tasks. In this paper we introduce graphical overlays-visual elements that are layered onto charts to facilitate a larger set of chart reading tasks. These overlays directly support the lower-level perceptual and cognitive processes that viewers must perform to read a chart. We identify five main types of overlays that support these processes; the overlays can provide (1) reference structures such as gridlines, (2) highlights such as outlines around important marks, (3) redundant encodings such as numerical data labels, (4) summary statistics such as the mean or max and (5) annotations such as descriptive text for context. We then present an automated system that applies user-chosen graphical overlays to existing chart bitmaps. Our approach is based on the insight that generating most of these graphical overlays only requires knowing the properties of the visual marks and axes that encode the data, but does not require access to the underlying data values. Thus, our system analyzes the chart bitmap to extract only the properties necessary to generate the desired overlay. We also discuss techniques for generating interactive overlays that provide additional controls to viewers. We demonstrate several examples of each overlay type for bar, pie and line charts.","Authors":"Kong, N.;Agrawala, M.","Clusters":"Cognition;Perception;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2012.229","Keywords":"graph comprehension;visualization;overlays;graphical perception","Title":"Graphical Overlays: Using Layered Elements to Aid Chart Reading","type":"new","Vector":[0.0,0.0062526506,0.0,0.0,0.0108358189,0.0,0.0,0.0011940851,0.000973303,0.0049538451,0.0,0.0050192165,0.0,0.0676917277,0.0,0.0,0.0,0.0626310858,0.0011980754,0.000393134]},"114":{"Abstract":"Lineups [4, 28] have been established as tools for visual testing similar to standard statistical inference tests, allowing us to evaluate the validity of graphical findings in an objective manner. In simulation studies [12] lineups have been shown as being efficient: the power of visual tests is comparable to classical tests while being much less stringent in terms of distributional assumptions made. This makes lineups versatile, yet powerful, tools in situations where conditions for regular statistical tests are not or cannot be met. In this paper we introduce lineups as a tool for evaluating the power of competing graphical designs. We highlight some of the theoretical properties and then show results from two studies evaluating competing designs: both studies are designed to go to the limits of our perceptual abilities to highlight differences between designs. We use both accuracy and speed of evaluation as measures of a successful design. The first study compares the choice of coordinate system: polar versus cartesian coordinates. The results show strong support in favor of cartesian coordinates in finding fast and accurate answers to spotting patterns. The second study is aimed at finding shift differences between distributions. Both studies are motivated by data problems that we have recently encountered, and explore using simulated data to evaluate the plot designs under controlled conditions. Amazon Mechanical Turk (MTurk) is used to conduct the studies. The lineups provide an effective mechanism for objectively evaluating plot designs.","Authors":"Hofmann, H.;Follett, L.;Majumder, M.;Cook, D.","Clusters":"ComparisonComparativeVisualizationAndSimilarity;HypothesisFormingTestingAndVisualEvidence;VisualEncodingAndLayoutGeneral;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2012.230","Keywords":"efficiency of displays;visual inference;lineups;power comparison","Title":"Graphical Tests for Power Comparison of Competing Designs","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0014171887,0.0,0.0049403915,0.0,0.0060149702,0.0,0.0,0.0,0.0721753028,0.0,0.0040094537,0.0,0.0554731922,0.0055355678,0.0]},"115":{"Abstract":"In this paper, we explore how the capacity limits of attention influence the effectiveness of information visualizations. We conducted a series of experiments to test how visual feature type (color vs. motion), layout, and variety of visual elements impacted user performance. The experiments tested users' abilities to (1) determine if a specified target is on the screen, (2) detect an odd-ball, deviant target, different from the other visible objects, and (3) gain a qualitative overview by judging the number of unique categories on the screen. Our results show that the severe capacity limits of attention strongly modulate the effectiveness of information visualizations, particularly the ability to detect unexpected information. Keeping in mind these capacity limits, we conclude with a set of design guidelines which depend on a visualization's intended use.","Authors":"Haroz, S.;Whitney, D.","Clusters":"AnimationAndMotion;ChartsDiagramsPlots;Cognition;ColorColorPerception;DesignMethodologiesAndInteractionDesign;EvaluationGeneral;Perception;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2012.233","Keywords":"color;goal-oriented design;user study;perception;layout;nominal axis;attention;motion","Title":"How Capacity Limits of Attention Influence Information Visualization Effectiveness","type":"new","Vector":[0.0040443443,0.0414773087,0.0,0.0,0.023068685,0.0,0.0066639139,0.0,0.0,0.0034777883,0.0060583978,0.0,0.0,0.1057647661,0.0,0.0079549588,0.0,0.0238800054,0.0313569856,0.0345344902]},"116":{"Abstract":"In this paper, we propose a new strategy for graph drawing utilizing layouts of many sub-graphs supplied by a large group of people in a crowd sourcing manner. We developed an algorithm based on Laplacian constrained distance embedding to merge subgraphs submitted by different users, while attempting to maintain the topological information of the individual input layouts. To facilitate collection of layouts from many people, a light-weight interactive system has been designed to enable convenient dynamic viewing, modification and traversing between layouts. Compared with other existing graph layout algorithms, our approach can achieve more aesthetic and meaningful layouts with high user preference.","Authors":"Xiaoru Yuan;Limei Che;Yifan Hu;Xin Zhang","Clusters":"DataEditing;DataRegistrationFusionAndIntegration;Engineering;EvaluationGeneral;GraphNetworkDataAndTechniques;MatrixRelatedTechniques","DOI":"10.1109\/TVCG.2012.236","Keywords":"merging;stress model;graph layout;laplacian matrix;editing;force-directed layout;crowdsourcing","Title":"Intelligent Graph Layout Using Many Users' Input","type":"new","Vector":[0.0007452708,0.165324622,0.0024082456,0.0041606537,0.0,0.0,0.0212614719,0.0,0.0,0.0,0.0,0.0009098818,0.0,0.0045598797,0.0021070478,0.0000840799,0.0104468826,0.0,0.0,0.0]},"117":{"Abstract":"Visual comparison is an intrinsic part of interactive data exploration and analysis. The literature provides a large body of existing solutions that help users accomplish comparison tasks. These solutions are mostly of visual nature and custom-made for specific data. We ask the question if a more general support is possible by focusing on the interaction aspect of comparison tasks. As an answer to this question, we propose a novel interaction concept that is inspired by real-world behavior of people comparing information printed on paper. In line with real-world interaction, our approach supports users (1) in interactively specifying pieces of graphical information to be compared, (2) in flexibly arranging these pieces on the screen, and (3) in performing the actual comparison of side-by-side and overlapping arrangements of the graphical information. Complementary visual cues and add-ons further assist users in carrying out comparison tasks. Our concept and the integrated interaction techniques are generally applicable and can be coupled with different visualization techniques. We implemented an interactive prototype and conducted a qualitative user study to assess the concept's usefulness in the context of three different visualization techniques. The obtained feedback indicates that our interaction techniques mimic the natural behavior quite well, can be learned quickly, and are easy to apply to visual comparison tasks.","Authors":"Tominski, C.;Forsell, C.;Johansson, J.","Clusters":"ComparisonComparativeVisualizationAndSimilarity;HumanComputerInteractionHumanFactors;InteractionTechniquesGeneral","DOI":"10.1109\/TVCG.2012.237","Keywords":"natural interaction;visualization;human-computer interaction;visual comparison;interaction","Title":"Interaction Support for Visual Comparison Inspired by Natural Behavior","type":"new","Vector":[0.0066604704,0.0191296908,0.0024662991,0.0008834885,0.0,0.0059025103,0.0137950661,0.0071401649,0.0036476898,0.0,0.0057536403,0.000657439,0.0032829896,0.1965285986,0.0,0.0043607566,0.0167056829,0.0245826201,0.0,0.0]},"118":{"Abstract":"We propose a technique that allows straight-line graph drawings to be rendered interactively with adjustable level of detail. The approach consists of a novel combination of edge cumulation with density-based node aggregation and is designed to exploit common graphics hardware for speed. It operates directly on graph data and does not require precomputed hierarchies or meshes. As proof of concept, we present an implementation that scales to graphs with millions of nodes and edges, and discuss several example applications.","Authors":"Zinsmaier, M.;Brandes, U.;Deussen, O.;Strobelt, H.","Clusters":"ComputerGraphicsTechniquesGeneral;DataClusteringAndAggregation;GraphNetworkDataAndTechniques","DOI":"10.1109\/TVCG.2012.238","Keywords":"opengl;edge aggregation;graph visualization","Title":"Interactive Level-of-Detail Rendering of Large Graphs","type":"new","Vector":[0.0,0.1415649761,0.0,0.0,0.0625094866,0.0051591359,0.0931310143,0.0,0.0,0.0023732547,0.0001405888,0.0,0.0190090875,0.0,0.0134481553,0.0154740641,0.0374308558,0.0375186483,0.0,0.0183290199]},"119":{"Abstract":"Interactive visualizations can allow science museum visitors to explore new worlds by seeing and interacting with scientific data. However, designing interactive visualizations for informal learning environments, such as museums, presents several challenges. First, visualizations must engage visitors on a personal level. Second, visitors often lack the background to interpret visualizations of scientific data. Third, visitors have very limited time at individual exhibits in museums. This paper examines these design considerations through the iterative development and evaluation of an interactive exhibit as a visualization tool that gives museumgoers access to scientific data generated and used by researchers. The exhibit prototype, Living Liquid, encourages visitors to ask and answer their own questions while exploring the time-varying global distribution of simulated marine microbes using a touchscreen interface. Iterative development proceeded through three rounds of formative evaluations using think-aloud protocols and interviews, each round informing a key visualization design decision: (1) what to visualize to initiate inquiry, (2) how to link data at the microscopic scale to global patterns, and (3) how to include additional data that allows visitors to pursue their own questions. Data from visitor evaluations suggests that, when designing visualizations for public audiences, one should (1) avoid distracting visitors from data that they should explore, (2) incorporate background information into the visualization, (3) favor understandability over scientific accuracy, and (4) layer data accessibility to structure inquiry. Lessons learned from this case study add to our growing understanding of how to use visualizations to actively engage learners with scientific data.","Authors":"Ma, J.;Liao, I.;Kwan-Liu Ma;Frazier, J.","Clusters":"ApplicationsGeneralAndOther;EvaluationGeneral;InteractionTechniquesGeneral","DOI":"10.1109\/TVCG.2012.244","Keywords":"user interaction;information visualization;informal learning environments;user study;science museums;evaluation","Title":"Living Liquid: Design and Evaluation of an Exploratory Visualization Tool for Museum Visitors","type":"new","Vector":[0.005181392,0.0022360602,0.0,0.0012103182,0.0,0.0038195493,0.0,0.0,0.0006935658,0.0016633646,0.001297482,0.0073493904,0.0,0.0471955768,0.0,0.0047095464,0.0062815917,0.0169940353,0.0022953492,0.0146074797]},"120":{"Abstract":"We investigate the cognitive impact of various layout features-symmetry, alignment, collinearity, axis alignment and orthogonality - on the recall of network diagrams (graphs). This provides insight into how people internalize these diagrams and what features should or shouldn't be utilised when designing static and interactive network-based visualisations. Participants were asked to study, remember, and draw a series of small network diagrams, each drawn to emphasise a particular visual feature. The visual features were based on existing theories of perception, and the task enabled visual processing at the visceral level only. Our results strongly support the importance of visual features such as symmetry, collinearity and orthogonality, while not showing any significant impact for node-alignment or parallel edges.","Authors":"Marriott, K.;Purchase, H.;Wybrow, M.;Goncu, C.","Clusters":"ChartsDiagramsPlots;DataFeaturesAndAttributes;EvaluationGeneral;GraphNetworkDataAndTechniques;Perception","DOI":"10.1109\/TVCG.2012.245","Keywords":"graph layout;perceptual theories;network diagrams;visual features;experiment;diagram recall","Title":"Memorability of Visual Features in Network Diagrams","type":"new","Vector":[0.0,0.0969035105,0.0,0.0000369459,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2102571876,0.0,0.0,0.0693707729,0.0,0.0,0.0]},"121":{"Abstract":"We propose a method to highlight query hits in hierarchically clustered collections of interrelated items such as digital libraries or knowledge bases. The method is based on the idea that organizing search results similarly to their arrangement on a fixed reference map facilitates orientation and assessment by preserving a user's mental map. Here, the reference map is built from an MDS layout of the items in a Voronoi treemap representing their hierarchical clustering, and we use techniques from dynamic graph layout to align query results with the map. The approach is illustrated on an archive of newspaper articles.","Authors":"Nocaj, A.;Brandes, U.","Clusters":"AbstractionSimplificationApproximation;Cognition;DimensionalityReduction;GraphNetworkDataAndTechniques;QueriesAndSearch;VoronoiBasedTechniques","DOI":"10.1109\/TVCG.2012.250","Keywords":"multi-dimensional scaling;mental map;voronoi treemaps;edge bundling;search results;dynamic graph layout","Title":"Organizing Search Results with a Reference Map","type":"new","Vector":[0.0010013664,0.159598147,0.0053905253,0.0039900624,0.0,0.0,0.0661689966,0.0056318542,0.0,0.0,0.0,0.1747095691,0.0,0.0,0.0011225752,0.0,0.0,0.0182602255,0.0,0.0]},"122":{"Abstract":"We present the results of two user studies on the perception of visual variables on tiled high-resolution wall-sized displays. We contribute an understanding of, and indicators predicting how, large variations in viewing distances and viewing angles affect the accurate perception of angles, areas, and lengths. Our work, thus, helps visualization researchers with design considerations on how to create effective visualizations for these spaces. The first study showed that perception accuracy was impacted most when viewers were close to the wall but differently for each variable (Angle, Area, Length). Our second study examined the effect of perception when participants could move freely compared to when they had a static viewpoint. We found that a far but static viewpoint was as accurate but less time consuming than one that included free motion. Based on our findings, we recommend encouraging viewers to stand further back from the display when conducting perception estimation tasks. If tasks need to be conducted close to the wall display, important information should be placed directly in front of the viewer or above, and viewers should be provided with an estimation of the distortion effects predicted by our work-or encouraged to physically navigate the wall in specific ways to reduce judgement error.","Authors":"Bezerianos, A.;Isenberg, P.","Clusters":"LargeAndHighResDisplays;Perception","DOI":"10.1109\/TVCG.2012.251","Keywords":"information visualization;perception;wall displays","Title":"Perception of Visual Variables on Tiled Wall-Sized Displays for Information Visualization Applications","type":"new","Vector":[0.0,0.0000444457,0.0022976167,0.0,0.0030257054,0.0073714779,0.0002307968,0.0,0.0026711732,0.0041596325,0.0198236495,0.0,0.0035826956,0.1780029761,0.0,0.0001681703,0.0,0.0333402562,0.0018323666,0.0]},"123":{"Abstract":"We present PivotPaths, an interactive visualization for exploring faceted information resources. During both work and leisure, we increasingly interact with information spaces that contain multiple facets and relations, such as authors, keywords, and citations of academic publications, or actors and genres of movies. To navigate these interlinked resources today, one typically selects items from facet lists resulting in abrupt changes from one subset of data to another. While filtering is useful to retrieve results matching specific criteria, it can be difficult to see how facets and items relate and to comprehend the effect of filter operations. In contrast, the PivotPaths interface exposes faceted relations as visual paths in arrangements that invite the viewer to `take a stroll' through an information space. PivotPaths supports pivot operations as lightweight interaction techniques that trigger gradual transitions between views. We designed the interface to allow for casual traversal of large collections in an aesthetically pleasing manner that encourages exploration and serendipitous discoveries. This paper shares the findings from our iterative design-and-evaluation process that included semi-structured interviews and a two-week deployment of PivotPaths applied to a large database of academic publications.","Authors":"Dork, M.;Riche, N.H.;Ramos, G.;Dumais, S.","Clusters":"AnalysisProcessGeneral;AnimationAndMotion;GraphNetworkDataAndTechniques;InteractionTechniquesGeneral","DOI":"10.1109\/TVCG.2012.252","Keywords":"information visualization;node-link diagrams;exploratory search;information seeking;interactivity;animation","Title":"PivotPaths: Strolling through Faceted Information Spaces","type":"new","Vector":[0.0,0.0080486776,0.0033800449,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0564026114,0.0,0.0531009228,0.0,0.0,0.0209330999,0.0242186093,0.0,0.0178023259]},"124":{"Abstract":"For many applications involving time series data, people are often interested in the changes of item values over time as well as their ranking changes. For example, people search many words via search engines like Google and Bing every day. Analysts are interested in both the absolute searching number for each word as well as their relative rankings. Both sets of statistics may change over time. For very large time series data with thousands of items, how to visually present ranking changes is an interesting challenge. In this paper, we propose RankExplorer, a novel visualization method based on ThemeRiver to reveal the ranking changes. Our method consists of four major components: 1) a segmentation method which partitions a large set of time series curves into a manageable number of ranking categories; 2) an extended ThemeRiver view with embedded color bars and changing glyphs to show the evolution of aggregation values related to each ranking category over time as well as the content changes in each ranking category; 3) a trend curve to show the degree of ranking changes over time; 4) rich user interactions to support interactive exploration of ranking changes. We have applied our method to some real time series data and the case studies demonstrate that our method can reveal the underlying patterns related to ranking changes which might otherwise be obscured in traditional visualizations.","Authors":"Conglei Shi;Weiwei Cui;Shixia Liu;Panpan Xu;Wei Chen;Huamin Qu","Clusters":"InteractionTechniquesGeneral;Ranking;TimeseriesTimeVaryingDataAndTechniques;VisualizationTechniquesAndToolsGeneral","DOI":"10.1109\/TVCG.2012.253","Keywords":"time-series data;ranking change;themeriver;interaction","Title":"RankExplorer: Visualization of Ranking Changes in Large Time Series Data","type":"new","Vector":[0.0,0.0021045801,0.0,0.0081942353,0.0007520916,0.0094432317,0.0014993797,0.0106033486,0.0021186512,0.013761449,0.0,0.0,0.0,0.0362397414,0.0,0.0,0.0,0.1421513087,0.0,0.0306257956]},"125":{"Abstract":"We present a network visualization design study focused on supporting automotive engineers who need to specify and optimize traffic patterns for in-car communication networks. The task and data abstractions that we derived support actively making changes to an overlay network, where logical communication specifications must be mapped to an underlying physical network. These abstractions are very different from the dominant use case in visual network analysis, namely identifying clusters and central nodes, that stems from the domain of social network analysis. Our visualization tool RelEx was created and iteratively refined through a full user-centered design process that included a full problem characterization phase before tool design began, paper prototyping, iterative refinement in close collaboration with expert users for formative evaluation, deployment in the field with real analysts using their own data, usability testing with non-expert users, and summative evaluation at the end of the deployment. In the summative post-deployment study, which entailed domain experts using the tool over several weeks in their daily practice, we documented many examples where the use of RelEx simplified or sped up their work compared to previous practices.","Authors":"Sedlmair, M.;Frank, A.;Munzner, T.;Butz, A.","Clusters":"DesignStudiesAndCaseStudies;DynamicVisualizationVisualizationOfChange;Engineering;GraphNetworkDataAndTechniques;Traffic","DOI":"10.1109\/TVCG.2012.255","Keywords":"design study;traffic optimization;automotive;change management;traffic routing;network visualization","Title":"RelEx: Visualization for Actively Changing Overlay Network Specifications","type":"new","Vector":[0.0,0.0,0.0,0.0007348307,0.0,0.0051207016,0.0019023473,0.0,0.0,0.0,0.0000230605,0.0,0.0,0.0403134636,0.0,0.0,0.1551065756,0.0070195929,0.0094466269,0.0]},"126":{"Abstract":"Datasets with a large number of dimensions per data item (hundreds or more) are challenging both for computational and visual analysis. Moreover, these dimensions have different characteristics and relations that result in sub-groups and\/or hierarchies over the set of dimensions. Such structures lead to heterogeneity within the dimensions. Although the consideration of these structures is crucial for the analysis, most of the available analysis methods discard the heterogeneous relations among the dimensions. In this paper, we introduce the construction and utilization of representative factors for the interactive visual analysis of structures in high-dimensional datasets. First, we present a selection of methods to investigate the sub-groups in the dimension set and associate representative factors with those groups of dimensions. Second, we introduce how these factors are included in the interactive visual analysis cycle together with the original dimensions. We then provide the steps of an analytical procedure that iteratively analyzes the datasets through the use of representative factors. We discuss how our methods improve the reliability and interpretability of the analysis process by enabling more informed selections of computational tools. Finally, we demonstrate our techniques on the analysis of brain imaging study results that are performed over a large group of subjects.","Authors":"Turkay, C.;Lundervold, A.;Lundervold, A.;Hauser, H.","Clusters":"InteractionTechniquesGeneral;MultidimensionalMultivariateMultifieldDataAndTechniques","DOI":"10.1109\/TVCG.2012.256","Keywords":"interactive visual analysis;high-dimensional data analysis","Title":"Representative Factor Generation for the Interactive Visual Analysis of High-Dimensional Data","type":"new","Vector":[0.0,0.0,0.0,0.0011238183,0.0,0.0,0.028169882,0.002400535,0.0165390506,0.0078135558,0.0,0.00830995,0.0,0.0487187653,0.0269389186,0.0,0.0,0.1310956726,0.0,0.0]},"127":{"Abstract":"We present and evaluate a framework for constructing sketchy style information visualizations that mimic data graphics drawn by hand. We provide an alternative renderer for the Processing graphics environment that redefines core drawing primitives including line, polygon and ellipse rendering. These primitives allow higher-level graphical features such as bar charts, line charts, treemaps and node-link diagrams to be drawn in a sketchy style with a specified degree of sketchiness. The framework is designed to be easily integrated into existing visualization implementations with minimal programming modification or design effort. We show examples of use for statistical graphics, conveying spatial imprecision and for enhancing aesthetic and narrative qualities of visualization. We evaluate user perception of sketchiness of areal features through a series of stimulus-response tests in order to assess users' ability to place sketchiness on a ratio scale, and to estimate area. Results suggest relative area judgment is compromised by sketchy rendering and that its influence is dependent on the shape being rendered. They show that degree of sketchiness may be judged on an ordinal scale but that its judgement varies strongly between individuals. We evaluate higher-level impacts of sketchiness through user testing of scenarios that encourage user engagement with data visualization and willingness to critique visualization design. Results suggest that where a visualization is clearly sketchy, engagement may be increased and that attitudes to participating in visualization annotation are more positive. The results of our work have implications for effective information visualization design that go beyond the traditional role of sketching as a tool for prototyping or its use for an indication of general uncertainty.","Authors":"Wood, J.;Isenberg, P.;Isenberg, T.;Dykes, J.;Boukhelifa, N.;Slingsby, A.","Clusters":"ArtAndAestheticsInVisualization;IllustrativeVisualization;InteractionTechniquesGeneral;UncertaintyTechniquesAndVisualization","DOI":"10.1109\/TVCG.2012.262","Keywords":"non-photorealistic rendering;sketch;hand-drawn;uncertainty;visualization","Title":"Sketchy Rendering for Information Visualization","type":"new","Vector":[0.0,0.0037062186,0.0051092317,0.0,0.0,0.0,0.0001264676,0.0,0.0,0.0298990733,0.0,0.0,0.0,0.1414507281,0.0,0.0,0.0,0.0,0.0,0.0]},"128":{"Abstract":"Sports analysts live in a world of dynamic games flattened into tables of numbers, divorced from the rinks, pitches, and courts where they were generated. Currently, these professional analysts use R, Stata, SAS, and other statistical software packages for uncovering insights from game data. Quantitative sports consultants seek a competitive advantage both for their clients and for themselves as analytics becomes increasingly valued by teams, clubs, and squads. In order for the information visualization community to support the members of this blossoming industry, it must recognize where and how visualization can enhance the existing analytical workflow. In this paper, we identify three primary stages of today's sports analyst's routine where visualization can be beneficially integrated: 1) exploring a dataspace; 2) sharing hypotheses with internal colleagues; and 3) communicating findings to stakeholders.Working closely with professional ice hockey analysts, we designed and built SnapShot, a system to integrate visualization into the hockey intelligence gathering process. SnapShot employs a variety of information visualization techniques to display shot data, yet given the importance of a specific hockey statistic, shot length, we introduce a technique, the radial heat map. Through a user study, we received encouraging feedback from several professional analysts, both independent consultants and professional team personnel.","Authors":"Pileggi, H.;Stolper, C.D.;Boyle, J.M.;Stasko, J.","Clusters":"HumanComputerInteractionHumanFactors;HypothesisFormingTestingAndVisualEvidence;KnowledgeDiscovery;VisualKnowledgeRepresentationAndExternalization","DOI":"10.1109\/TVCG.2012.263","Keywords":"visual evidence;visual knowledge representation;hypothesis testing;human-computer interaction;visual knowledge discovery","Title":"SnapShot: Visualization to Propel Ice Hockey Analytics","type":"new","Vector":[0.0,0.0,0.0,0.0005291155,0.0,0.0,0.0,0.0,0.0,0.003932388,0.0,0.0305822809,0.0,0.0242525963,0.0,0.0,0.01032761,0.0038712494,0.0,0.1253741465]},"129":{"Abstract":"We present a method for automatically building typographic maps that merge text and spatial data into a visual representation where text alone forms the graphical features. We further show how to use this approach to visualize spatial data such as traffic density, crime rate, or demographic data. The technique accepts a vector representation of a geographic map and spatializes the textual labels in the space onto polylines and polygons based on user-defined visual attributes and constraints. Our sample implementation runs as a Web service, spatializing shape files from the OpenStreetMap project into typographic maps for any region.","Authors":"Afzal, S.;Maciejewski, R.;Yun Jang;Elmqvist, N.;Ebert, D.S.","Clusters":"GeographyGeospatialVisCartographyTerrainVis;Labeling;SpaceRelatedSpatialDataAndTechniques;TextDocumentTopicAnalysisDataAndTechniques","DOI":"10.1109\/TVCG.2012.264","Keywords":"text visualization;spatial data;geovisualization;label placement","Title":"Spatial Text Visualization Using Automatic Typographic Maps","type":"new","Vector":[0.0005004157,0.0207600044,0.0042660091,0.0,0.006940575,0.0058578442,0.0,0.0,0.0080544747,0.0017560777,0.0025190922,0.0870185669,0.0,0.0095448318,0.0002959586,0.0042803719,0.0061612976,0.0290434916,0.0,0.0076068083]},"130":{"Abstract":"Visualizing trajectory attribute data is challenging because it involves showing the trajectories in their spatio-temporal context as well as the attribute values associated with the individual points of trajectories. Previous work on trajectory visualization addresses selected aspects of this problem, but not all of them. We present a novel approach to visualizing trajectory attribute data. Our solution covers space, time, and attribute values. Based on an analysis of relevant visualization tasks, we designed the visualization solution around the principle of stacking trajectory bands. The core of our approach is a hybrid 2D\/3D display. A 2D map serves as a reference for the spatial context, and the trajectories are visualized as stacked 3D trajectory bands along which attribute values are encoded by color. Time is integrated through appropriate ordering of bands and through a dynamic query mechanism that feeds temporally aggregated information to a circular time display. An additional 2D time graph shows temporal information in full detail by stacking 2D trajectory bands. Our solution is equipped with analytical and interactive mechanisms for selecting and ordering of trajectories, and adjusting the color mapping, as well as coordinated highlighting and dedicated 3D navigation. We demonstrate the usefulness of our novel visualization by three examples related to radiation surveillance, traffic analysis, and maritime navigation. User feedback obtained in a small experiment indicates that our hybrid 2D\/3D solution can be operated quite well.","Authors":"Tominski, C.;Schumann, H.;Andrienko, G.;Andrienko, N.","Clusters":"AnalysisProcessGeneral;AnimationAndMotion;InteractionTechniquesGeneral;SpatiotemporalDataAndTechniques","DOI":"10.1109\/TVCG.2012.265","Keywords":"spatio-temporal data;exploratory data analysis;visualization;trajectory attribute data;interaction","Title":"Stacking-Based Visualization of Trajectory Attribute Data","type":"new","Vector":[0.0013712683,0.0,0.0,0.0,0.0,0.0,0.01646407,0.0,0.0,0.0,0.0,0.0,0.0,0.0247473341,0.0,0.0379453622,0.0036844818,0.0438011813,0.0,0.2133830945]},"131":{"Abstract":"Glyph-based visualization can offer elegant and concise presentation of multivariate information while enhancing speed and ease in visual search experienced by users. As with icon designs, glyphs are usually created based on the designers' experience and intuition, often in a spontaneous manner. Such a process does not scale well with the requirements of applications where a large number of concepts are to be encoded using glyphs. To alleviate such limitations, we propose a new systematic process for glyph design by exploring the parallel between the hierarchy of concept categorization and the ordering of discriminative capacity of visual channels. We examine the feasibility of this approach in an application where there is a pressing need for an efficient and effective means to visualize workflows of biological experiments. By processing thousands of workflow records in a public archive of biological experiments, we demonstrate that a cost-effective glyph design can be obtained by following a process of formulating a taxonomy with the aid of computation, identifying visual channels hierarchically, and defining application-specific abstraction and metaphors.","Authors":"Maguire, E.;Rocca-Serra, P.;Sansone, S.-A.;Davies, J.;Chen, M.","Clusters":"BiologyAndBioinformatics;DesignMethodologiesAndInteractionDesign;GlyphsGlyphBasedTechniques;Taxonomies","DOI":"10.1109\/TVCG.2012.271","Keywords":"taxonomy;design methodologies;bioinformatics visualization;glyph-based techniques","Title":"Taxonomy-Based Glyph Design---with a Case Study on Visualizing Workflows of Biological Experiments","type":"new","Vector":[0.0182043981,0.0327044024,0.0,0.0445518235,0.0007517916,0.0,0.0055011439,0.014819197,0.0113314983,0.0361868751,0.0,0.0265103825,0.0,0.0427208176,0.0,0.0,0.0051559156,0.0486806241,0.0045112438,0.0024434342]},"132":{"Abstract":"In this paper, we present the DeepTree exhibit, a multi-user, multi-touch interactive visualization of the Tree of Life. We developed DeepTree to facilitate collaborative learning of evolutionary concepts. We will describe an iterative process in which a team of computer scientists, learning scientists, biologists, and museum curators worked together throughout design, development, and evaluation. We present the importance of designing the interactions and the visualization hand-in-hand in order to facilitate active learning. The outcome of this process is a fractal-based tree layout that reduces visual complexity while being able to capture all life on earth; a custom rendering and navigation engine that prioritizes visual appeal and smooth fly-through; and a multi-user interface that encourages collaborative exploration while offering guided discovery. We present an evaluation showing that the large dataset encouraged free exploration, triggers emotional responses, and facilitates visitor engagement and informal learning.","Authors":"Block, F.;Horn, M.S.;Phillips, B.C.;Diamond, J.;Evans, E.M.;Chia Shen","Clusters":"CollaborativeVisualization;Education;HierarchicalTreeDataAndTechniques;InteractionTechniquesGeneral","DOI":"10.1109\/TVCG.2012.272","Keywords":"multi-touch interaction;large tree visualizations;informal science education;collaborative learning","Title":"The DeepTree Exhibit: Visualizing the Tree of Life to Facilitate Informal Learning","type":"new","Vector":[0.0016127499,0.1313809097,0.0,0.0,0.0007142789,0.0,0.0,0.0262818048,0.0016391993,0.0,0.0021104644,0.0191660488,0.0,0.0571776438,0.0,0.0,0.0,0.0070420186,0.0076633947,0.0127749286]},"133":{"Abstract":"Current interfaces for common information visualizations such as bar graphs, line graphs, and scatterplots usually make use of the WIMP (Windows, Icons, Menus and a Pointer) interface paradigm with its frequently discussed problems of multiple levels of indirection via cascading menus, dialog boxes, and control panels. Recent advances in interface capabilities such as the availability of pen and touch interaction challenge us to re-think this and investigate more direct access to both the visualizations and the data they portray. We conducted a Wizard of Oz study to explore applying pen and touch interaction to the creation of information visualization interfaces on interactive whiteboards without implementing a plethora of recognizers. Our wizard acted as a robust and flexible pen and touch recognizer, giving participants maximum freedom in how they interacted with the system. Based on our qualitative analysis of the interactions our participants used, we discuss our insights about pen and touch interactions in the context of learnability and the interplay between pen and touch gestures. We conclude with suggestions for designing pen and touch enabled interactive visualization interfaces.","Authors":"Walny, J.;Bongshin Lee;Johns, P.;Riche, N.H.;Carpendale, S.","Clusters":"AnalysisProcessGeneral;EvaluationGeneral;HumanComputerInteractionHumanFactors;InteractionTechniquesGeneral","DOI":"10.1109\/TVCG.2012.275","Keywords":"data exploration;whiteboard;wizard of oz;pen and touch;interaction","Title":"Understanding Pen and Touch Interaction for Data Exploration on Interactive Whiteboards","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2372805924,0.0,0.0,0.0,0.0068062622,0.0,0.0]},"134":{"Abstract":"This paper presents two linked empirical studies focused on uncertainty visualization. The experiments are framed from two conceptual perspectives. First, a typology of uncertainty is used to delineate kinds of uncertainty matched with space, time, and attribute components of data. Second, concepts from visual semiotics are applied to characterize the kind of visual signification that is appropriate for representing those different categories of uncertainty. This framework guided the two experiments reported here. The first addresses representation intuitiveness, considering both visual variables and iconicity of representation. The second addresses relative performance of the most intuitive abstract and iconic representations of uncertainty on a map reading task. Combined results suggest initial guidelines for representing uncertainty and discussion focuses on practical applicability of results.","Authors":"MacEachren, A.M.;Roth, R.E.;O'Brien, J.;Li, B.;Swingley, D.;Gahegan, M.","Clusters":"SemanticsSemioticsRelatedTechniques;UncertaintyTechniquesAndVisualization;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2012.279","Keywords":"uncertainty categories;semiotics;visual variables;uncertainty visualization","Title":"Visual Semiotics & Uncertainty Visualization: An Empirical Study","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2594651038,0.0,0.0,0.0,0.0671319612,0.0,0.0,0.0,0.0151091644,0.0068782258,0.0066520381]},"135":{"Abstract":"Uncertainty can arise in any stage of a visual analytics process, especially in data-intensive applications with a sequence of data transformations. Additionally, throughout the process of multidimensional, multivariate data analysis, uncertainty due to data transformation and integration may split, merge, increase, or decrease. This dynamic characteristic along with other features of uncertainty pose a great challenge to effective uncertainty-aware visualization. This paper presents a new framework for modeling uncertainty and characterizing the evolution of the uncertainty information through analytical processes. Based on the framework, we have designed a visual metaphor called uncertainty flow to visually and intuitively summarize how uncertainty information propagates over the whole analysis pipeline. Our system allows analysts to interact with and analyze the uncertainty information at different levels of detail. Three experiments were conducted to demonstrate the effectiveness and intuitiveness of our design.","Authors":"Yingcai Wu;Guo-Xun Yuan;Kwan-Liu Ma","Clusters":"UncertaintyTechniquesAndVisualization","DOI":"10.1109\/TVCG.2012.285","Keywords":"error ellipsoids;uncertainty visualization;uncertainty propagation;uncertainty fusion;uncertainty quantification","Title":"Visualizing Flow of Uncertainty through Analytical Processes","type":"new","Vector":[0.0,0.0134149647,0.0,0.0,0.0,0.0016150035,0.0071239823,0.0,0.0,0.457825624,0.0,0.0011794236,0.0,0.0,0.0,0.0038837657,0.0042712519,0.0,0.0,0.0]},"136":{"Abstract":"The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene\/P system.","Authors":"Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.;Bremer, P.-T.;Pascucci, V.","Clusters":"ComputerNetworksNetworkSecurity;EvaluationGeneral;GraphNetworkDataAndTechniques","DOI":"10.1109\/TVCG.2012.286","Keywords":"performance analysis;projected graph layouts;network traffic visualization","Title":"Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations","type":"new","Vector":[0.0045403961,0.0398859683,0.0,0.0,0.0079814034,0.0108641434,0.0000934605,0.0,0.0011855894,0.0,0.0027039822,0.0,0.011554682,0.0012841899,0.0,0.011616625,0.2259726455,0.0,0.013441973,0.0185656632]},"137":{"Abstract":"While intuitive time-series visualizations exist for common datasets, student course history data is difficult to represent using traditional visualization techniques due its concurrent nature. A visual composition process is developed and applied to reveal trends across various groupings. By working closely with educators, analytic strategies and techniques are developed to leverage the visualization composition to reveal unknown trends in the data. Furthermore, clustering algorithms are developed to group common course-grade histories for further analysis. Lastly, variations of the composition process are implemented to reveal subtle differences in the underlying data. These analytic tools and techniques enabled educators to confirm expected trends and to discover new ones.","Authors":"Trimm, D.;Rheingans, P.;desJardins, M.","Clusters":"DataClusteringAndAggregation;EvaluationGeneral;VisualDesignDesignGuidelines","DOI":"10.1109\/TVCG.2012.288","Keywords":"student performance analysis;clustering;visualization composition;aggregate visualization","Title":"Visualizing Student Histories Using Clustering and Composition","type":"new","Vector":[0.0016679901,0.0,0.0,0.0006438922,0.0048462602,0.0,0.030113332,0.0,0.0023618003,0.0,0.0,0.0,0.0,0.0139796296,0.0,0.023853081,0.0,0.0278758242,0.0,0.1073416285]},"138":{"Abstract":"When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, \u00e2\u20ac\u0153Whisper\u00e2\u20ac\u009d, for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunflower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efficient flux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identified even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today's information consumption and dispersion in the wild.","Authors":"Nan Cao;Yu-Ru Lin;Xiaohua Sun;Lazer, D.;Shixia Liu;Huamin Qu","Clusters":"DiffusionRelatedTechniques;SocialNetworksAndSocialMedia;SpatiotemporalDataAndTechniques","DOI":"10.1109\/TVCG.2012.291","Keywords":"information visualization;contagion;social media;spatio-temporal patterns;microblogging;information diffusion","Title":"Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time","type":"new","Vector":[0.0,0.0086945878,0.0,0.0156309884,0.0,0.0073016173,0.0013154225,0.0,0.0,0.0028341504,0.0,0.0315465736,0.0012109597,0.0111822253,0.0629320336,0.0091280618,0.0311130048,0.0,0.0,0.071627076]},"139":{"Abstract":"Color mapping and semitransparent layering play an important role in many visualization scenarios, such as information visualization and volume rendering. The combination of color and transparency is still dominated by standard alpha-compositing using the Porter-Duff over operator which can result in false colors with deceiving impact on the visualization. Other more advanced methods have also been proposed, but the problem is still far from being solved. Here we present an alternative to these existing methods specifically devised to avoid false colors and preserve visual depth ordering. Our approach is data driven and follows the recently formulated knowledge-assisted visualization (KAV) paradigm. Preference data, that have been gathered in web-based user surveys, are used to train a support-vector machine model for automatically predicting an optimized hue-preserving blending. We have applied the resulting model to both volume rendering and a specific information visualization technique, illustrative parallel coordinate plots. Comparative renderings show a significant improvement over previous approaches in the sense that false colors are completely removed and important properties such as depth ordering and blending vividness are better preserved. Due to the generality of the defined data-driven blending operator, it can be easily integrated also into other visualization frameworks.","Authors":"Kuhne, L.;Giesen, J.;Zhiyuan Zhang;Sungsoo Ha;Mueller, K.","Clusters":"ColorColorPerception;ParallelCoordinates;VisualizationTechniquesAndToolsGeneral;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2012.186","Keywords":"knowledge-assisted visualization;volume rendering;color blending;hue preservation;parallel coordinates","Title":"A Data-Driven Approach to Hue-Preserving Color-Blending","type":"new","Vector":[0.0,0.0015399163,0.0068473322,0.0042903482,0.0242502929,0.0055798027,0.0048583395,0.0006690563,0.0241267586,0.0020103453,0.0095699611,0.0028579813,0.0033300516,0.0818016999,0.0,0.0050772901,0.0,0.0244569458,0.0,0.0]},"140":{"Abstract":"In the last decades cosmological N-body dark matter simulations have enabled ab initio studies of the formation of structure in the Universe. Gravity amplified small density fluctuations generated shortly after the Big Bang, leading to the formation of galaxies in the cosmic web. These calculations have led to a growing demand for methods to analyze time-dependent particle based simulations. Rendering methods for such N-body simulation data usually employ some kind of splatting approach via point based rendering primitives and approximate the spatial distributions of physical quantities using kernel interpolation techniques, common in SPH (Smoothed Particle Hydrodynamics)-codes. This paper proposes three GPU-assisted rendering approaches, based on a new, more accurate method to compute the physical densities of dark matter simulation data. It uses full phase-space information to generate a tetrahedral tessellation of the computational domain, with mesh vertices defined by the simulation's dark matter particle positions. Over time the mesh is deformed by gravitational forces, causing the tetrahedral cells to warp and overlap. The new methods are well suited to visualize the cosmic web. In particular they preserve caustics, regions of high density that emerge, when several streams of dark matter particles share the same location in space, indicating the formation of structures like sheets, filaments and halos. We demonstrate the superior image quality of the new approaches in a comparison with three standard rendering techniques for N-body simulation data.","Authors":"Kaehler, R.;Hahn, O.;Abel, T.","Clusters":"AstronomyAstrophysics;MeshesGridsAndLattices","DOI":"10.1109\/TVCG.2012.187","Keywords":"n-body simulations;tetrahedral grid;dark matter;astrophysics","Title":"A Novel Approach to Visualizing Dark Matter Simulations","type":"new","Vector":[0.0042349702,0.0,0.0584683037,0.0,0.0346683056,0.0,0.0133246352,0.0690713176,0.0,0.0013020705,0.0,0.0,0.0795112208,0.0,0.0023225359,0.2414727418,0.0018063892,0.0019857167,0.0,0.0]},"141":{"Abstract":"The process of surface perception is complex and based on several influencing factors, e.g., shading, silhouettes, occluding contours, and top down cognition. The accuracy of surface perception can be measured and the influencing factors can be modified in order to decrease the error in perception. This paper presents a novel concept of how a perceptual evaluation of a visualization technique can contribute to its redesign with the aim of improving the match between the distal and the proximal stimulus. During analysis of data from previous perceptual studies, we observed that the slant of 3D surfaces visualized on 2D screens is systematically underestimated. The visible trends in the error allowed us to create a statistical model of the perceived surface slant. Based on this statistical model we obtained from user experiments, we derived a new shading model that uses adjusted surface normals and aims to reduce the error in slant perception. The result is a shape-enhancement of visualization which is driven by an experimentally-founded statistical model. To assess the efficiency of the statistical shading model, we repeated the evaluation experiment and confirmed that the error in perception was decreased. Results of both user experiments are publicly-available datasets.","Authors":"Solteszova, V.;Turkay, C.;Price, M.C.;Viola, I.","Clusters":"EvaluationGeneral;MachineLearningAndStatistics;Perception;Rendering;SurfaceRelatedDataAndTechniques","DOI":"10.1109\/TVCG.2012.188","Keywords":"shading;surface slant;perception;evaluation;statistical analysis","Title":"A Perceptual-Statistics Shading Model","type":"new","Vector":[0.0004099783,0.0,0.0006783731,0.0,0.0111034088,0.0,0.0,0.0,0.0278199065,0.0031600792,0.0014218868,0.0,0.0,0.0549678153,0.0,0.002911165,0.0,0.0025835161,0.0,0.0]},"142":{"Abstract":"Geoscientific modeling and simulation helps to improve our understanding of the complex Earth system. During the modeling process, validation of the geoscientific model is an essential step. In validation, it is determined whether the model output shows sufficient agreement with observation data. Measures for this agreement are called goodness of fit. In the geosciences, analyzing the goodness of fit is challenging due to its manifold dependencies: 1) The goodness of fit depends on the model parameterization, whose precise values are not known. 2) The goodness of fit varies in space and time due to the spatio-temporal dimension of geoscientific models. 3) The significance of the goodness of fit is affected by resolution and preciseness of available observational data. 4) The correlation between goodness of fit and underlying modeled and observed values is ambiguous. In this paper, we introduce a visual analysis concept that targets these challenges in the validation of geoscientific models - specifically focusing on applications where observation data is sparse, unevenly distributed in space and time, and imprecise, which hinders a rigorous analytical approach. Our concept, developed in close cooperation with Earth system modelers, addresses the four challenges by four tailored visualization components. The tight linking of these components supports a twofold interactive drill-down in model parameter space and in the set of data samples, which facilitates the exploration of the numerous dependencies of the goodness of fit. We exemplify our visualization concept for geoscientific modeling of glacial isostatic adjustments in the last 100,000 years, validated against sea levels indicators - a prominent example for sparse and imprecise observation data. An initial use case and feedback from Earth system modelers indicate that our visualization concept is a valuable complement to the range of validation methods.","Authors":"Unger, A.;Schulte, S.;Klemann, V.;Dransch, D.","Clusters":"EarthSpaceAndEnvironmentalSciences;MachineLearningAndStatistics;MultipleLinkedCoordinatedViews;SpatiotemporalDataAndTechniques","DOI":"10.1109\/TVCG.2012.190","Keywords":"spatio-temporal visualization;earth science visualization;model validation;sea level indicators;coordinated & multiple views","Title":"A Visual Analysis Concept for the Validation of Geoscientific Simulation Models","type":"new","Vector":[0.0023288667,0.0001028233,0.0045257936,0.0,0.0,0.016136555,0.0029790095,0.0027627254,0.0064822486,0.0239070705,0.0002110923,0.0024935398,0.0,0.0251573994,0.0,0.012395996,0.0018074773,0.0246809821,0.0095525318,0.0292344143]},"143":{"Abstract":"In this work, we address the problem of lossless compression of scientific and medical floating-point volume data. We propose two prediction-based compression methods that share a common framework, which consists of a switched prediction scheme wherein the best predictor out of a preset group of linear predictors is selected. Such a scheme is able to adapt to different datasets as well as to varying statistics within the data. The first method, called APE (Adaptive Polynomial Encoder), uses a family of structured interpolating polynomials for prediction, while the second method, which we refer to as ACE (Adaptive Combined Encoder), combines predictors from previous work with the polynomial predictors to yield a more flexible, powerful encoder that is able to effectively decorrelate a wide range of data. In addition, in order to facilitate efficient visualization of compressed data, our scheme provides an option to partition floating-point values in such a way as to provide a progressive representation. We compare our two compressors to existing state-of-the-art lossless floating-point compressors for scientific data, with our data suite including both computer simulations and observational measurements. The results demonstrate that our polynomial predictor, APE, is comparable to previous approaches in terms of speed but achieves better compression rates on average. ACE, our combined predictor, while somewhat slower, is able to achieve the best compression rate on all datasets, with significantly better rates on most of the datasets.","Authors":"Fout, N.;Kwan-Liu Ma","Clusters":"CompressionTechniques","DOI":"10.1109\/TVCG.2012.194","Keywords":"lossless compression;volume compression;floating-point compression","Title":"An Adaptive Prediction-Based Approach to Lossless Compression of Floating-Point Volume Data","type":"new","Vector":[0.0,0.0,0.0,0.0035102668,0.0,0.0064954524,0.0,0.0,0.0,0.0037389245,0.0,0.0,0.0,0.0037793616,0.0034196629,0.0,0.0,0.0017681253,0.3133483714,0.0]},"144":{"Abstract":"Existing methods for analyzing separation of streamlines are often restricted to a finite time or a local area. In our paper we introduce a new method that complements them by allowing an infinite-time-evaluation of steady planar vector fields. Our algorithm unifies combinatorial and probabilistic methods and introduces the concept of separation in time-discrete Markov-Chains. We compute particle distributions instead of the streamlines of single particles. We encode the flow into a map and then into a transition matrix for each time direction. Finally, we compare the results of our grid-independent algorithm to the popular Finite-Time-Lyapunov-Exponents and discuss the discrepancies.","Authors":"Reich, W.;Scheuermann, G.","Clusters":"AlgorithmicPatternFeatureDetectionTracking;FlowVisualizationDataAndTechniques;UncertaintyTechniquesAndVisualization;VectorFieldsDataAndTechniques","DOI":"10.1109\/TVCG.2012.198","Keywords":"flow visualization;vector field topology;uncertainty;feature extraction","Title":"Analysis of Streamline Separation at Infinity Using Time-Discrete Markov Chains","type":"new","Vector":[0.0,0.0,0.0059116762,0.030967719,0.0,0.1331314672,0.0029031295,0.0872133207,0.0,0.0407184522,0.0,0.0,0.0072833417,0.0,0.0,0.1438392827,0.0206601702,0.0070508054,0.0,0.0]},"145":{"Abstract":"One potential solution to reduce the concentration of carbon dioxide in the atmosphere is the geologic storage of captured CO2 in underground rock formations, also known as carbon sequestration. There is ongoing research to guarantee that this process is both efficient and safe. We describe tools that provide measurements of media porosity, and permeability estimates, including visualization of pore structures. Existing standard algorithms make limited use of geometric information in calculating permeability of complex microstructures. This quantity is important for the analysis of biomineralization, a subsurface process that can affect physical properties of porous media. This paper introduces geometric and topological descriptors that enhance the estimation of material permeability. Our analysis framework includes the processing of experimental data, segmentation, and feature extraction and making novel use of multiscale topological analysis to quantify maximum flow through porous networks. We illustrate our results using synchrotron-based X-ray computed microtomography of glass beads during biomineralization. We also benchmark the proposed algorithms using simulated data sets modeling jammed packed bead beds of a monodispersive material.","Authors":"Ushizima, D.;Morozov, D.;Weber, G.H.;Bianchi, A.G.C.;Sethian, J.A.;Bethel, E.W.","Clusters":"GeometricModeling;Microscopy;SegmentationAndClassification;TopologyBasedTechniques","DOI":"10.1109\/TVCG.2012.200","Keywords":"geometric algorithms;persistent homology;segmentation;topological data analysis;reeb graph;microscopy","Title":"Augmented Topological Descriptors of Pore Networks for Material Science","type":"new","Vector":[0.0123446979,0.0,0.0107788556,0.0017201378,0.0,0.0703358223,0.0,0.0065218967,0.028054991,0.0060013768,0.0005561822,0.0010180896,0.010808281,0.0006895147,0.0,0.0172037627,0.0243102768,0.0015902044,0.0,0.0019293361]},"146":{"Abstract":"Cerebral aneurysms are a pathological vessel dilatation that bear a high risk of rupture. For the understanding and evaluation of the risk of rupture, the analysis of hemodynamic information plays an important role. Besides quantitative hemodynamic information, also qualitative flow characteristics, e.g., the inflow jet and impingement zone are correlated with the risk of rupture. However, the assessment of these two characteristics is currently based on an interactive visual investigation of the flow field, obtained by computational fluid dynamics (CFD) or blood flow measurements. We present an automatic and robust detection as well as an expressive visualization of these characteristics. The detection can be used to support a comparison, e.g., of simulation results reflecting different treatment options. Our approach utilizes local streamline properties to formalize the inflow jet and impingement zone. We extract a characteristic seeding curve on the ostium, on which an inflow jet boundary contour is constructed. Based on this boundary contour we identify the impingement zone. Furthermore, we present several visualization techniques to depict both characteristics expressively. Thereby, we consider accuracy and robustness of the extracted characteristics, minimal visual clutter and occlusions. An evaluation with six domain experts confirms that our approach detects both hemodynamic characteristics reasonably.","Authors":"Gasteiger, R.;Lehmann, D.J.;van Pelt, R.;Janiga, G.;Beuing, O.;Vilanova, A.;Theisel, H.;Preim, B.","Clusters":"ApplicationsGeneralAndOther;BiomedicalScienceAndMedicine;Engineering;GlyphsGlyphBasedTechniques","DOI":"10.1109\/TVCG.2012.202","Keywords":"glyph;cerebral aneurysm;visualization;hemodynamics;inflow jet;impingement zone","Title":"Automatic Detection and Visualization of Qualitative Hemodynamic Characteristics in Cerebral Aneurysms","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.1148160246,0.0,0.0233834431,0.0182043784,0.0007143185,0.0,0.0,0.0,0.0276997617,0.0045581704,0.0,0.0,0.0,0.0,0.0]},"147":{"Abstract":"Computed Tomography Angiography (CTA) is commonly used in clinical routine for diagnosing vascular diseases. The procedure involves the injection of a contrast agent into the blood stream to increase the contrast between the blood vessels and the surrounding tissue in the image data. CTA is often visualized with Direct Volume Rendering (DVR) where the enhanced image contrast is important for the construction of Transfer Functions (TFs). For increased efficiency, clinical routine heavily relies on preset TFs to simplify the creation of such visualizations for a physician. In practice, however, TF presets often do not yield optimal images due to variations in mixture concentration of contrast agent in the blood stream. In this paper we propose an automatic, optimization-based method that shifts TF presets to account for general deviations and local variations of the intensity of contrast enhanced blood vessels. Some of the advantages of this method are the following. It computationally automates large parts of a process that is currently performed manually. It performs the TF shift locally and can thus optimize larger portions of the image than is possible with manual interaction. The method is based on a well known vesselness descriptor in the definition of the optimization criterion. The performance of the method is illustrated by clinically relevant CT angiography datasets displaying both improved structural overviews of vessel trees and improved adaption to local variations of contrast concentration.","Authors":"Lathen, G.;Lindholm, S.;Lenz, R.;Persson, A.;Borga, M.","Clusters":"BiomedicalScienceAndMedicine;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2012.203","Keywords":"direct volume rendering;vessel visualization;transfer function","Title":"Automatic Tuning of Spatially Varying Transfer Functions for Blood Vessel Visualization","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0027639324,0.0,0.0928549367,0.0012999907,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]},"148":{"Abstract":"Finite element (FE) models are frequently used in engineering and life sciences within time-consuming simulations. In contrast with the regular grid structure facilitated by volumetric data sets, as used in medicine or geosciences, FE models are defined over a non-uniform grid. Elements can have curved faces and their interior can be defined through high-order basis functions, which pose additional challenges when visualizing these models. During ray-casting, the uniformly distributed sample points along each viewing ray must be transformed into the material space defined within each element. The computational complexity of this transformation makes a straightforward approach inadequate for interactive data exploration. In this paper, we introduce a novel coherency-based method which supports the interactive exploration of FE models by decoupling the expensive world-to-material space transformation from the rendering stage, thereby allowing it to be performed within a precomputation stage. Therefore, our approach computes view-independent proxy rays in material space, which are clustered to facilitate data reduction. During rendering, these proxy rays are accessed, and it becomes possible to visually analyze high-order FE models at interactive frame rates, even when they are time-varying or consist of multiple modalities. Within this paper, we provide the necessary background about the FE data, describe our decoupling method, and introduce our interactive rendering algorithm. Furthermore, we provide visual results and analyze the error introduced by the presented approach.","Authors":"Bock, A.;Sunden, E.;Bingchen Liu;Wunsche, B.;Ropinski, T.","Clusters":"GpuBasedTechniques;NumericalMethodsMathematics","DOI":"10.1109\/TVCG.2012.206","Keywords":"gpu raycasting;finite element visualization","Title":"Coherency-Based Curve Compression for High-Order finite Element Model Visualization","type":"new","Vector":[0.0,0.0,0.0,0.0078681556,0.0,0.0,0.0612709829,0.0,0.0,0.0,0.0,0.0,0.2816663536,0.0,0.0,0.0,0.0,0.0,0.0,0.0]},"149":{"Abstract":"Topological techniques have proven highly successful in analyzing and visualizing scientific data. As a result, significant efforts have been made to compute structures like the Morse-Smale complex as robustly and efficiently as possible. However, the resulting algorithms, while topologically consistent, often produce incorrect connectivity as well as poor geometry. These problems may compromise or even invalidate any subsequent analysis. Moreover, such techniques may fail to improve even when the resolution of the domain mesh is increased, thus producing potentially incorrect results even for highly resolved functions. To address these problems we introduce two new algorithms: (i) a randomized algorithm to compute the discrete gradient of a scalar field that converges under refinement; and (ii) a deterministic variant which directly computes accurate geometry and thus correct connectivity of the MS complex. The first algorithm converges in the sense that on average it produces the correct result and its standard deviation approaches zero with increasing mesh resolution. The second algorithm uses two ordered traversals of the function to integrate the probabilities of the first to extract correct (near optimal) geometry and connectivity. We present an extensive empirical study using both synthetic and real-world data and demonstrates the advantages of our algorithms in comparison with several popular approaches.","Authors":"Gyulassy, A.;Bremer, P.-T.;Pascucci, V.","Clusters":"TopologyBasedTechniques","DOI":"10.1109\/TVCG.2012.209","Keywords":"topological methods;topology;morse-smale complex","Title":"Computing Morse-Smale Complexes with Accurate Geometry","type":"new","Vector":[0.0073865902,0.0,0.0615731659,0.0070311776,0.0,0.0342607028,0.0018689427,0.1433529436,0.0197905401,0.0024759535,0.0,0.0026210813,0.0078110159,0.0024292457,0.0003835144,0.000440662,0.0098644788,0.0006073506,0.0,0.0]},"150":{"Abstract":"We introduce a simple, yet powerful method called the Cumulative Heat Diffusion for shape-based volume analysis, while drastically reducing the computational cost compared to conventional heat diffusion. Unlike the conventional heat diffusion process, where the diffusion is carried out by considering each node separately as the source, we simultaneously consider all the voxels as sources and carry out the diffusion, hence the term cumulative heat diffusion. In addition, we introduce a new operator that is used in the evaluation of cumulative heat diffusion called the Volume Gradient Operator (VGO). VGO is a combination of the LBO and a data-driven operator which is a function of the half gradient. The half gradient is the absolute value of the difference between the voxel intensities. The VGO by its definition captures the local shape information and is used to assign the initial heat values. Furthermore, VGO is also used as the weighting parameter for the heat diffusion process. We demonstrate that our approach can robustly extract shape-based features and thus forms the basis for an improved classification and exploration of features based on shape.","Authors":"Gurijala, K.C.;Lei Wang;Kaufman, A.","Clusters":"PhysicsAndPhysicalSciences;SegmentationAndClassification;ShapeRelatedTechniques;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2012.210","Keywords":"shape-based volume analysis;transfer function;classification;heat diffusion;volume gradient operator","Title":"Cumulative Heat Diffusion Using Volume Gradient Operator for Volume Analysis","type":"new","Vector":[0.0,0.0,0.0,0.014813602,0.0,0.0060239349,0.0025602979,0.0,0.0608496247,0.0,0.0,0.0,0.0,0.0,0.0750822285,0.0079577579,0.0,0.0115318483,0.0,0.0]},"151":{"Abstract":"Integral flow surfaces constitute a widely used flow visualization tool due to their capability to convey important flow information such as fluid transport, mixing, and domain segmentation. Current flow surface rendering techniques limit their expressiveness, however, by focusing virtually exclusively on displacement visualization, visually neglecting the more complex notion of deformation such as shearing and stretching that is central to the field of continuum mechanics. To incorporate this information into the flow surface visualization and analysis process, we derive a metric tensor field that encodes local surface deformations as induced by the velocity gradient of the underlying flow field. We demonstrate how properties of the resulting metric tensor field are capable of enhancing present surface visualization and generation methods and develop novel surface querying, sampling, and visualization techniques. The provided results show how this step towards unifying classic flow visualization and more advanced concepts from continuum mechanics enables more detailed and improved flow analysis.","Authors":"Obermaier, H.;Joy, K.I.","Clusters":"AnimationAndMotion;Engineering;ManipulationAndDeformation;SurfaceRelatedDataAndTechniques;TensorDataAndTechniques;VectorFieldsDataAndTechniques","DOI":"10.1109\/TVCG.2012.211","Keywords":"integral surfaces;continuum mechanics;vector field;deformation;metric tensor;velocity gradient","Title":"Derived Metric Tensors for Flow Surface Visualization","type":"new","Vector":[0.0,0.0,0.0213551138,0.3365150199,0.0216271345,0.1184035556,0.0,0.0,0.0,0.0080307901,0.0,0.0,0.0,0.0,0.0,0.0775797184,0.0,0.0,0.0,0.0086569695]},"152":{"Abstract":"We report the impact of display characteristics (stereo and size) on task performance in diffusion magnetic resonance imaging (DMRI) in a user study with 12 participants. The hypotheses were that (1) adding stereo and increasing display size would improve task accuracy and reduce completion time, and (2) the greater the complexity of a spatial task, the greater the benefits of an improved display. Thus we expected to see greater performance gains when detailed visual reasoning was required. Participants used dense streamtube visualizations to perform five representative tasks: (1) determine the higher average fractional anisotropy (FA) values between two regions, (2) find the endpoints of fiber tracts, (3) name a bundle, (4) mark a brain lesion, and (5) judge if tracts belong to the same bundle. Contrary to our hypotheses, we found the task completion time was not improved by the use of the larger display and that performance accuracy was hurt rather than helped by the introduction of stereo in our study with dense DMRI data. Bigger was not always better. Thus cautious should be taken when selecting displays for scientific visualization applications. We explored the results further using the body-scale unit and subjective size and stereo experiences.","Authors":"Jian Chen;Haipeng Cai;Auchus, A.P.;Laidlaw, D.H.","Clusters":"DisplaysGeneral;ImmersiveAndVirtualEnvironments;TensorDataAndTechniques","DOI":"10.1109\/TVCG.2012.216","Keywords":"virtual environment;diffusion tensor mri;display characteristics","Title":"Effects of Stereo and Screen Size on the Legibility of Three-Dimensional Streamtube Visualization","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0024421884,0.0,0.0,0.0,0.0,0.0,0.0099006144,0.0,0.0,0.208090293,0.182838016,0.0,0.0,0.0,0.0,0.0]},"153":{"Abstract":"Data selection is a fundamental task in visualization because it serves as a pre-requisite to many follow-up interactions. Efficient spatial selection in 3D point cloud datasets consisting of thousands or millions of particles can be particularly challenging. We present two new techniques, TeddySelection and CloudLasso, that support the selection of subsets in large particle 3D datasets in an interactive and visually intuitive manner. Specifically, we describe how to spatially select a subset of a 3D particle cloud by simply encircling the target particles on screen using either the mouse or direct-touch input. Based on the drawn lasso, our techniques automatically determine a bounding selection surface around the encircled particles based on their density. This kind of selection technique can be applied to particle datasets in several application domains. TeddySelection and CloudLasso reduce, and in some cases even eliminate, the need for complex multi-step selection processes involving Boolean operations. This was confirmed in a formal, controlled user study in which we compared the more flexible CloudLasso technique to the standard cylinder-based selection technique. This study showed that the former is consistently more efficient than the latter - in several cases the CloudLasso selection time was half that of the corresponding cylinder-based selection.","Authors":"Lingyun Yu;Efstathiou, K.;Isenberg, P.;Isenberg, T.","Clusters":"InteractionTechniquesGeneral","DOI":"10.1109\/TVCG.2012.217","Keywords":"3d interaction;direct-touch interaction;spatial selection","Title":"Efficient Structure-Aware Selection Techniques for 3D Point Cloud Visualizations with 2DOF Input","type":"new","Vector":[0.0,0.0034199125,0.0,0.0,0.0,0.0,0.0098867561,0.0,0.0019039086,0.0018725332,0.0007354988,0.0031534544,0.0085640615,0.0647437867,0.0013337948,0.122437142,0.0,0.011440599,0.0,0.0]},"154":{"Abstract":"This paper presents the Element Visualizer (ElVis), a new, open-source scientific visualization system for use with high-order finite element solutions to PDEs in three dimensions. This system is designed to minimize visualization errors of these types of fields by querying the underlying finite element basis functions (e.g., high-order polynomials) directly, leading to pixel-exact representations of solutions and geometry. The system interacts with simulation data through runtime plugins, which only require users to implement a handful of operations fundamental to finite element solvers. The data in turn can be visualized through the use of cut surfaces, contours, isosurfaces, and volume rendering. These visualization algorithms are implemented using NVIDIA's OptiX GPU-based ray-tracing engine, which provides accelerated ray traversal of the high-order geometry, and CUDA, which allows for effective parallel evaluation of the visualization algorithms. The direct interface between ElVis and the underlying data differentiates it from existing visualization tools. Current tools assume the underlying data is composed of linear primitives; high-order data must be interpolated with linear functions as a result. In this work, examples drawn from aerodynamic simulations-high-order discontinuous Galerkin finite element solutions of aerodynamic flows in particular-will demonstrate the superiority of ElVis' pixel-exact approach when compared with traditional linear-interpolation methods. Such methods can introduce a number of inaccuracies in the resulting visualization, making it unclear if visual artifacts are genuine to the solution data or if these artifacts are the result of interpolation errors. Linear methods additionally cannot properly visualize curved geometries (elements or boundaries) which can greatly inhibit developers' debugging efforts. As we will show, pixel-exact visualization exhibits none of these issues, removing the visualization scheme as a source of - ncertainty for engineers using ElVis.","Authors":"Nelson, B.;Liu, E.;Kirby, R.M.;Haimes, R.","Clusters":"ContourCreasesRidgesValleys;FlowVisualizationDataAndTechniques;IsosurfaceAndSurfaceExtractionTechniques;NumericalMethodsMathematics","DOI":"10.1109\/TVCG.2012.218","Keywords":"contours;high-order finite elements;fluid flow simulation;cut-surface extraction;discontinuous galerkin methods;spectral\/hp elements;isosurface","Title":"ElVis: A System for the Accurate and Interactive Visualization of High-Order finite Element Solutions","type":"new","Vector":[0.0,0.0,0.0353137469,0.0031376492,0.0012295317,0.0336132955,0.0,0.0549957752,0.0,0.0025403245,0.0,0.0021094686,0.0385191319,0.006530628,0.0,0.0130420172,0.0008890387,0.0048013903,0.0023468579,0.0]},"155":{"Abstract":"We evaluate and compare video visualization techniques based on fast-forward. A controlled laboratory user study (n = 24) was conducted to determine the trade-off between support of object identification and motion perception, two properties that have to be considered when choosing a particular fast-forward visualization. We compare four different visualizations: two representing the state-of-the-art and two new variants of visualization introduced in this paper. The two state-of-the-art methods we consider are frame-skipping and temporal blending of successive frames. Our object trail visualization leverages a combination of frame-skipping and temporal blending, whereas predictive trajectory visualization supports motion perception by augmenting the video frames with an arrow that indicates the future object trajectory. Our hypothesis was that each of the state-of-the-art methods satisfies just one of the goals: support of object identification or motion perception. Thus, they represent both ends of the visualization design. The key findings of the evaluation are that object trail visualization supports object identification, whereas predictive trajectory visualization is most useful for motion perception. However, frame-skipping surprisingly exhibits reasonable performance for both tasks. Furthermore, we evaluate the subjective performance of three different playback speed visualizations for adaptive fast-forward, a subdomain of video fast-forward.","Authors":"Hoferlin, M.;Kurzhals, K.;Hoferlin, B.;Heidemann, G.;Weiskopf, D.","Clusters":"LaboratoryStudies;MultimediaImageVideoMusic","DOI":"10.1109\/TVCG.2012.222","Keywords":"controlled laboratory user study;adaptive fast-forward;video visualization","Title":"Evaluation of Fast-Forward Video Visualization","type":"new","Vector":[0.0,0.0,0.0005571628,0.0,0.0122496692,0.0,0.0,0.0,0.0,0.0,0.0011333386,0.0,0.007570464,0.1141589712,0.0,0.009431291,0.0,0.0,0.0056873264,0.2061212496]},"156":{"Abstract":"In order to assess the reliability of volume rendering, it is necessary to consider the uncertainty associated with the volume data and how it is propagated through the volume rendering algorithm, as well as the contribution to uncertainty from the rendering algorithm itself. In this work, we show how to apply concepts from the field of reliable computing in order to build a framework for management of uncertainty in volume rendering, with the result being a self-validating computational model to compute a posteriori uncertainty bounds. We begin by adopting a coherent, unifying possibility-based representation of uncertainty that is able to capture the various forms of uncertainty that appear in visualization, including variability, imprecision, and fuzziness. Next, we extend the concept of the fuzzy transform in order to derive rules for accumulation and propagation of uncertainty. This representation and propagation of uncertainty together constitute an automated framework for management of uncertainty in visualization, which we then apply to volume rendering. The result, which we call fuzzy volume rendering, is an uncertainty-aware rendering algorithm able to produce more complete depictions of the volume data, thereby allowing more reliable conclusions and informed decisions. Finally, we compare approaches for self-validated computation in volume rendering, demonstrating that our chosen method has the ability to handle complex uncertainty while maintaining efficiency.","Authors":"Fout, N.;Kwan-Liu Ma","Clusters":"EvaluationGeneral;UncertaintyTechniquesAndVisualization;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2012.227","Keywords":"volume rendering;verifiable visualization;uncertainty visualization","Title":"Fuzzy Volume Rendering","type":"new","Vector":[0.0,0.0,0.0023091241,0.0,0.0,0.0,0.0147906526,0.0008767639,0.0035774985,0.4108521724,0.0,0.0,0.0065430699,0.0,0.0,0.0,0.0,0.0,0.0073449733,0.0]},"157":{"Abstract":"We present a combinatorial algorithm for the general topological simplification of scalar fields on surfaces. Given a scalar field f, our algorithm generates a simplified field g that provably admits only critical points from a constrained subset of the singularities of f, while guaranteeing a small distance ||f - g||\u221e for data-fitting purpose. In contrast to previous algorithms, our approach is oblivious to the strategy used for selecting features of interest and allows critical points to be removed arbitrarily. When topological persistence is used to select the features of interest, our algorithm produces a standard \u03f5-simplification. Our approach is based on a new iterative algorithm for the constrained reconstruction of sub- and sur-level sets. Extensive experiments show that the number of iterations required for our algorithm to converge is rarely greater than 2 and never greater than 5, yielding O(n log(n)) practical time performances. The algorithm handles triangulated surfaces with or without boundary and is robust to the presence of multi-saddles in the input. It is simple to implement, fast in practice and more general than previous techniques. Practically, our approach allows a user to arbitrarily simplify the topology of an input function and robustly generate the corresponding simplified function. An appealing application area of our algorithm is in scalar field design since it enables, without any threshold parameter, the robust pruning of topological noise as selected by the user. This is needed for example to get rid of inaccuracies introduced by numerical solvers, thereby providing topological guarantees needed for certified geometry processing. Experiments show this ability to eliminate numerical noise as well as validate the time efficiency and accuracy of our algorithm. We provide a lightweight C++ implementation as supplemental material that can be used for topological cleaning on surface meshes.","Authors":"Tierny, J.;Pascucci, V.","Clusters":"ScalarFieldDataTechniques;TopologyBasedTechniques","DOI":"10.1109\/TVCG.2012.228","Keywords":"scalar field design;scalar field visualization;topological simplification","Title":"Generalized Topological Simplification of Scalar fields on Surfaces","type":"new","Vector":[0.0057109657,0.0007771817,0.118522368,0.0047118561,0.0,0.0546295121,0.0053639846,0.1097382426,0.001883598,0.0,0.0013439911,0.0030604295,0.0,0.0061792449,0.0,0.0,0.0092496634,0.000491283,0.0,0.0]},"158":{"Abstract":"Visual exploration of volumetric datasets to discover the embedded features and spatial structures is a challenging and tedious task. In this paper we present a semi-automatic approach to this problem that works by visually segmenting the intensity-gradient 2D histogram of a volumetric dataset into an exploration hierarchy. Our approach mimics user exploration behavior by analyzing the histogram with the normalized-cut multilevel segmentation technique. Unlike previous work in this area, our technique segments the histogram into a reasonable set of intuitive components that are mutually exclusive and collectively exhaustive. We use information-theoretic measures of the volumetric data segments to guide the exploration. This provides a data-driven coarse-to-fine hierarchy for a user to interactively navigate the volume in a meaningful manner.","Authors":"Cheuk Yiu Ip;Varshney, A.;JaJa, J.","Clusters":"AnalysisProcessGeneral;ImageBasedDataImageSignalProcessing;SegmentationAndClassification;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2012.231","Keywords":"volume exploration;information-guided exploration;volume classification;normalized cut","Title":"Hierarchical Exploration of Volumes Using Multilevel Segmentation of the Intensity-Gradient Histograms","type":"new","Vector":[0.0,0.0226555901,0.0019202571,0.0,0.0,0.0,0.0091445811,0.0,0.1217195082,0.0106132536,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0355188754,0.0139651917,0.0]},"159":{"Abstract":"In this paper, we enable interactive volumetric global illumination by extending photon mapping techniques to handle interactive transfer function (TF) and material editing in the context of volume rendering. We propose novel algorithms and data structures for finding and evaluating parts of a scene affected by these parameter changes, and thus support efficient updates of the photon map. In direct volume rendering (DVR) the ability to explore volume data using parameter changes, such as editable TFs, is of key importance. Advanced global illumination techniques are in most cases computationally too expensive, as they prevent the desired interactivity. Our technique decreases the amount of computation caused by parameter changes, by introducing Historygrams which allow us to efficiently reuse previously computed photon media interactions. Along the viewing rays, we utilize properties of the light transport equations to subdivide a view-ray into segments and independently update them when invalid. Unlike segments of a view-ray, photon scattering events within the volumetric medium needs to be sequentially updated. Using our Historygram approach, we can identify the first invalid photon interaction caused by a property change, and thus reuse all valid photon interactions. Combining these two novel concepts, supports interactive editing of parameters when using volumetric photon mapping in the context of DVR. As a consequence, we can handle arbitrarily shaped and positioned light sources, arbitrary phase functions, bidirectional reflectance distribution functions and multiple scattering which has previously not been possible in interactive DVR.","Authors":"Jonsson, D.;Kronander, J.;Ropinski, T.;Ynnerman, A.","Clusters":"Illumination;SocialNetworksAndSocialMedia;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2012.232","Keywords":"volume rendering;global illumination;photon mapping;participating media","Title":"Historygrams: Enabling Interactive Global Illumination in Direct Volume Rendering using Photon Mapping","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0377723476,0.0,0.0,0.0,0.0673008857,0.0,0.0,0.0042779303,0.0,0.0036534377,0.0,0.0074695024]},"160":{"Abstract":"Due to the inherent characteristics of the visualization process, most of the problems in this field have strong ties with human cognition and perception. This makes the human brain and sensory system the only truly appropriate evaluation platform for evaluating and fine-tuning a new visualization method or paradigm. However, getting humans to volunteer for these purposes has always been a significant obstacle, and thus this phase of the development process has traditionally formed a bottleneck, slowing down progress in visualization research. We propose to take advantage of the newly emerging field of Human Computation (HC) to overcome these challenges. HC promotes the idea that rather than considering humans as users of the computational system, they can be made part of a hybrid computational loop consisting of traditional computation resources and the human brain and sensory system. This approach is particularly successful in cases where part of the computational problem is considered intractable using known computer algorithms but is trivial to common sense human knowledge. In this paper, we focus on HC from the perspective of solving visualization problems and also outline a framework by which humans can be easily seduced to volunteer their HC resources. We introduce a purpose-driven game titled \u00e2\u20ac\u0153Disguise\u00e2\u20ac\u009d which serves as a prototypical example for how the evaluation of visualization algorithms can be mapped into a fun and addicting activity, allowing this task to be accomplished in an extensive yet cost effective way. Finally, we sketch out a framework that transcends from the pure evaluation of existing visualization methods to the design of a new one.","Authors":"Ahmed, N.;Ziyi Zheng;Mueller, K.","Clusters":"ColorColorPerception;EvaluationGeneral;HumanComputerInteractionHumanFactors;Perception","DOI":"10.1109\/TVCG.2012.234","Keywords":"perception;color blending;evaluation;human computation","Title":"Human Computation in Visualization: Using Purpose Driven Games for Robust Evaluation of Visualization Algorithms","type":"new","Vector":[0.0021864346,0.001689238,0.0008525371,0.0003255135,0.0132732235,0.0008026868,0.0026656345,0.0,0.0118936951,0.0011739123,0.0016701297,0.0068496301,0.00282127,0.0601068139,0.0011144033,0.0004791202,0.0042611921,0.0140861162,0.0029934579,0.0689753999]},"161":{"Abstract":"Planetary topography is the result of complex interactions between geological processes, of which faulting is a prominent component. Surface-rupturing earthquakes cut and move landforms which develop across active faults, producing characteristic surface displacements across the fault. Geometric models of faults and their associated surface displacements are commonly applied to reconstruct these offsets to enable interpretation of the observed topography. However, current 2D techniques are limited in their capability to convey both the three-dimensional kinematics of faulting and the incremental sequence of events required by a given reconstruction. Here we present a real-time system for interactive retro-deformation of faulted topography to enable reconstruction of fault displacement within a high-resolution (sub 1m\/pixel) 3D terrain visualization. We employ geometry shaders on the GPU to intersect the surface mesh with fault-segments interactively specified by the user and transform the resulting surface blocks in realtime according to a kinematic model of fault motion. Our method facilitates a human-in-the-loop approach to reconstruction of fault displacements by providing instant visual feedback while exploring the parameter space. Thus, scientists can evaluate the validity of traditional point-to-point reconstructions by visually examining a smooth interpolation of the displacement in 3D. We show the efficacy of our approach by using it to reconstruct segments of the San Andreas fault, California as well as a graben structure in the Noctis Labyrinthus region on Mars.","Authors":"Westerteiger, R.;Compton, T.;Bernadin, T.;Cowgill, E.;Gwinner, K.;Hamann, B.;Gerndt, A.;Hagen, H.","Clusters":"GeographyGeospatialVisCartographyTerrainVis;InteractionTechniquesGeneral;MeshesGridsAndLattices;Simulation","DOI":"10.1109\/TVCG.2012.239","Keywords":"mesh deformation;terrain rendering;fault simulation;interactive","Title":"Interactive Retro-Deformation of Terrain for Reconstructing 3D Fault Displacements","type":"new","Vector":[0.0041426498,0.0,0.0336937233,0.0157765322,0.0081240389,0.0040593218,0.0,0.0,0.0043148527,0.000810171,0.0053487902,0.0,0.0215645847,0.0105498972,0.0,0.006899513,0.0090592078,0.0000627632,0.0184124698,0.0157347572]},"162":{"Abstract":"This paper presents the first volume visualization system that scales to petascale volumes imaged as a continuous stream of high-resolution electron microscopy images. Our architecture scales to dense, anisotropic petascale volumes because it: (1) decouples construction of the 3D multi-resolution representation required for visualization from data acquisition, and (2) decouples sample access time during ray-casting from the size of the multi-resolution hierarchy. Our system is designed around a scalable multi-resolution virtual memory architecture that handles missing data naturally, does not pre-compute any 3D multi-resolution representation such as an octree, and can accept a constant stream of 2D image tiles from the microscopes. A novelty of our system design is that it is visualization-driven: we restrict most computations to the visible volume data. Leveraging the virtual memory architecture, missing data are detected during volume ray-casting as cache misses, which are propagated backwards for on-demand out-of-core processing. 3D blocks of volume data are only constructed from 2D microscope image tiles when they have actually been accessed during ray-casting. We extensively evaluate our system design choices with respect to scalability and performance, compare to previous best-of-breed systems, and illustrate the effectiveness of our system for real microscopy data from neuroscience.","Authors":"Hadwiger, M.;Beyer, J.;Won-Ki Jeong;Pfister, H.","Clusters":"ApplicationsGeneralAndOther;LargeScaleDataAndScalability;Microscopy;NeurosciencesAndBrainVisualization","DOI":"10.1109\/TVCG.2012.240","Keywords":"high-throughput imaging;high-resolution microscopy;neuroscience;petascale volume exploration","Title":"Interactive Volume Exploration of Petascale Microscopy Data Streams Using a Visualization-Driven Virtual Memory Approach","type":"new","Vector":[0.0008335642,0.0319082699,0.0,0.0,0.0462609797,0.0,0.001858712,0.0,0.0115015327,0.0,0.0002670282,0.0,0.1002407811,0.0,0.0050570269,0.000109486,0.0,0.0,0.2182086347,0.0]},"163":{"Abstract":"We present KnotPad, an interactive paper-like system for visualizing and exploring mathematical knots; we exploit topological drawing and math-aware deformation methods in particular to enable and enrich our interactions with knot diagrams. Whereas most previous efforts typically employ physically based modeling to simulate the 3D dynamics of knots and ropes, our tool offers a Reidemeister move based interactive environment that is much closer to the topological problems being solved in knot theory, yet without interfering with the traditional advantages of paper-based analysis and manipulation of knot diagrams. Drawing knot diagrams with many crossings and producing their equivalent is quite challenging and error-prone. KnotPad can restrict user manipulations to the three types of Reidemeister moves, resulting in a more fluid yet mathematically correct user experience with knots. For our principal test case of mathematical knots, KnotPad permits us to draw and edit their diagrams empowered by a family of interactive techniques. Furthermore, we exploit supplementary interface elements to enrich the user experiences. For example, KnotPad allows one to pull and drag on knot diagrams to produce mathematically valid moves. Navigation enhancements in KnotPad provide still further improvement: by remembering and displaying the sequence of valid moves applied during the entire interaction, KnotPad allows a much cleaner exploratory interface for the user to analyze and study knot equivalence. All these methods combine to reveal the complex spatial relationships of knot diagrams with a mathematically true and rich user experience.","Authors":"Hui Zhang;Jianguang Weng;Lin Jing;Yiwen Zhong","Clusters":"Mathematics;NumericalMethodsMathematics","DOI":"10.1109\/TVCG.2012.242","Keywords":"mathematical visualization;knot theory","Title":"KnotPad: Visualizing and Exploring Knot Theory with Fluid Reidemeister Moves","type":"new","Vector":[0.008598769,0.0102994407,0.0170933702,0.0024191413,0.0,0.0044778498,0.000967677,0.0,0.0041041945,0.0,0.0013781759,0.0,0.0,0.0358705997,0.0,0.0,0.0077284951,0.0,0.0,0.0055339067]},"164":{"Abstract":"Room air flow and air exchange are important aspects for the design of energy-efficient buildings. As a result, simulations are increasingly used prior to construction to achieve an energy-efficient design. We present a visual analysis of air flow generated at building entrances, which uses a combination of revolving doors and air curtains. The resulting flow pattern is challenging because of two interacting flow patterns: On the one hand, the revolving door acts as a pump, on the other hand, the air curtain creates a layer of uniformly moving warm air between the interior of the building and the revolving door. Lagrangian coherent structures (LCS), which by definition are flow barriers, are the method of choice for visualizing the separation and recirculation behavior of warm and cold air flow. The extraction of LCS is based on the finite-time Lyapunov exponent (FTLE) and makes use of a ridge definition which is consistent with the concept of weak LCS. Both FTLE computation and ridge extraction are done in a robust and efficient way by making use of the fast Fourier transform for computing scale-space derivatives.","Authors":"Schindler, B.;Fuchs, R.;Barp, S.;Waser, J.;Pobitzer, A.;Carnecky, R.;Matkovic, K.;Peikert, R.","Clusters":"PhysicsAndPhysicalSciences;TopologyBasedTechniques;VectorFieldsDataAndTechniques","DOI":"10.1109\/TVCG.2012.243","Keywords":"visualization in physical sciences and engineering;topology-based techniques;vector field data","Title":"Lagrangian Coherent Structures for Design Analysis of Revolving Doors","type":"new","Vector":[0.0,0.0047861827,0.0201451225,0.0316973333,0.0,0.1131471633,0.0,0.0192654299,0.0084598399,0.0000601669,0.0,0.0,0.0,0.0012510702,0.0,0.0624696111,0.0018065814,0.0030231441,0.0,0.0002843959]},"165":{"Abstract":"The extraction of significant structures in arbitrary high-dimensional data sets is a challenging task. Moreover, classifying data points as noise in order to reduce a data set bears special relevance for many application domains. Standard methods such as clustering serve to reduce problem complexity by providing the user with classes of similar entities. However, they usually do not highlight relations between different entities and require a stopping criterion, e.g. the number of clusters to be detected. In this paper, we present a visualization pipeline based on recent advancements in algebraic topology. More precisely, we employ methods from persistent homology that enable topological data analysis on high-dimensional data sets. Our pipeline inherently copes with noisy data and data sets of arbitrary dimensions. It extracts central structures of a data set in a hierarchical manner by using a persistence-based filtering algorithm that is theoretically well-founded. We furthermore introduce persistence rings, a novel visualization technique for a class of topological features-the persistence intervals-of large data sets. Persistence rings provide a unique topological signature of a data set, which helps in recognizing similarities. In addition, we provide interactive visualization techniques that assist the user in evaluating the parameter space of our method in order to extract relevant structures. We describe and evaluate our analysis pipeline by means of two very distinct classes of data sets: First, a class of synthetic data sets containing topological objects is employed to highlight the interaction capabilities of our method. Second, in order to affirm the utility of our technique, we analyse a class of high-dimensional real-world data sets arising from current research in cultural heritage.","Authors":"Rieck, B.;Mara, H.;Leitte, H.","Clusters":"DataClusteringAndAggregation;MultidimensionalMultivariateMultifieldDataAndTechniques;TopologyBasedTechniques","DOI":"10.1109\/TVCG.2012.248","Keywords":"multivariate data;topological persistence;clustering","Title":"Multivariate Data Analysis Using Persistence-Based filtering and Topological Signatures","type":"new","Vector":[0.0027111546,0.0,0.0259579727,0.0021660992,0.0,0.0136402416,0.0369688041,0.052303187,0.0022173209,0.0018991602,0.0,0.0004026663,0.0,0.0052534069,0.0,0.0032121129,0.008113065,0.0119585849,0.0,0.0048547384]},"166":{"Abstract":"In many fields of science or engineering, we are confronted with uncertain data. For that reason, the visualization of uncertainty received a lot of attention, especially in recent years. In the majority of cases, Gaussian distributions are used to describe uncertain behavior, because they are able to model many phenomena encountered in science. Therefore, in most applications uncertain data is (or is assumed to be) Gaussian distributed. If such uncertain data is given on fixed positions, the question of interpolation arises for many visualization approaches. In this paper, we analyze the effects of the usual linear interpolation schemes for visualization of Gaussian distributed data. In addition, we demonstrate that methods known in geostatistics and machine learning have favorable properties for visualization purposes in this case.","Authors":"Schlegel, S.;Korn, N.;Scheuermann, G.","Clusters":"Interpolation;MachineLearningAndStatistics;UncertaintyTechniquesAndVisualization","DOI":"10.1109\/TVCG.2012.249","Keywords":"gaussian process;uncertainty;interpolation","Title":"On the Interpolation of Data with Normally Distributed Uncertainty for Visualization","type":"new","Vector":[0.0003199117,0.0,0.0062888215,0.0023088571,0.0,0.0,0.004753711,0.0179775528,0.0117361416,0.1350427292,0.0018727552,0.0027104182,0.0043053786,0.0001916159,0.0,0.0136032239,0.0014252363,0.0084629804,0.0033121426,0.0]},"167":{"Abstract":"The most important resources to fulfill today's energy demands are fossil fuels, such as oil and natural gas. When exploiting hydrocarbon reservoirs, a detailed and credible model of the subsurface structures is crucial in order to minimize economic and ecological risks. Creating such a model is an inverse problem: reconstructing structures from measured reflection seismics. The major challenge here is twofold: First, the structures in highly ambiguous seismic data are interpreted in the time domain. Second, a velocity model has to be built from this interpretation to match the model to depth measurements from wells. If it is not possible to obtain a match at all positions, the interpretation has to be updated, going back to the first step. This results in a lengthy back and forth between the different steps, or in an unphysical velocity model in many cases. This paper presents a novel, integrated approach to interactively creating subsurface models from reflection seismics. It integrates the interpretation of the seismic data using an interactive horizon extraction technique based on piecewise global optimization with velocity modeling. Computing and visualizing the effects of changes to the interpretation and velocity model on the depth-converted model on the fly enables an integrated feedback loop that enables a completely new connection of the seismic data in time domain and well data in depth domain. Using a novel joint time\/depth visualization, depicting side-by-side views of the original and the resulting depth-converted data, domain experts can directly fit their interpretation in time domain to spatial ground truth data. We have conducted a domain expert evaluation, which illustrates that the presented workflow enables the creation of exact subsurface models much more rapidly than previous approaches.","Authors":"Hollt, T.;Freiler, W.;Gschwantner, F.;Doleisch, H.;Heinemann, G.;Hadwiger, M.","Clusters":"EarthSpaceAndEnvironmentalSciences;VisualEncodingAndLayoutGeneral;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2012.259","Keywords":"exploded views;seismic interpretation;seismic visualization;volume deformation","Title":"SeiVis: An Interactive Visual Subsurface Modeling Application","type":"new","Vector":[0.0020260327,0.0058069301,0.0085209536,0.0087939669,0.0603347918,0.0149571915,0.0,0.0,0.0338439367,0.0006458031,0.0,0.0010018795,0.0376676427,0.0151512268,0.0,0.0073845206,0.0016015975,0.0054419883,0.0059026211,0.0163062484]},"168":{"Abstract":"In a variety of application areas, the use of simulation steering in decision making is limited at best. Research focusing on this problem suggests that most user interfaces are too complex for the end user. Our goal is to let users create and investigate multiple, alternative scenarios without the need for special simulation expertise. To simplify the specification of parameters, we move from a traditional manipulation of numbers to a sketch-based input approach. Users steer both numeric parameters and parameters with a spatial correspondence by sketching a change onto the rendering. Special visualizations provide immediate visual feedback on how the sketches are transformed into boundary conditions of the simulation models. Since uncertainty with respect to many intertwined parameters plays an important role in planning, we also allow the user to intuitively setup complete value ranges, which are then automatically transformed into ensemble simulations. The interface and the underlying system were developed in collaboration with experts in the field of flood management. The real-world data they have provided has allowed us to construct scenarios used to evaluate the system. These were presented to a variety of flood response personnel, and their feedback is discussed in detail in the paper. The interface was found to be intuitive and relevant, although a certain amount of training might be necessary.","Authors":"Ribicic, H.;Waser, J.;Gurbat, R.;Sadransky, B.;Groller, E.","Clusters":"DesignMethodologiesAndInteractionDesign;EmergencyDisasterManagement;InteractionTechniquesGeneral;Simulation;UncertaintyTechniquesAndVisualization;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/TVCG.2012.261","Keywords":"uncertainty visualization;interaction design;sketch-based steering;flood management;emergency\/disaster management;integrated visualization system;ensemble simulation steering","Title":"Sketching Uncertainty into Simulations","type":"new","Vector":[0.0018680758,0.0040589713,0.0005708455,0.0,0.0,0.0220233576,0.001628292,0.0,0.0070364373,0.0376611426,0.0,0.0,0.0,0.0251069293,0.0,0.0086356384,0.0,0.0033048244,0.0,0.0490033864]},"169":{"Abstract":"Lighting design is a complex, but fundamental, problem in many fields. In volume visualization, direct volume rendering generates an informative image without external lighting, as each voxel itself emits radiance. However, external lighting further improves the shape and detail perception of features, and it also determines the effectiveness of the communication of feature information. The human visual system is highly effective in extracting structural information from images, and to assist it further, this paper presents an approach to structure-aware automatic lighting design by measuring the structural changes between the images with and without external lighting. Given a transfer function and a viewpoint, the optimal lighting parameters are those that provide the greatest enhancement to structural information - the shape and detail information of features are conveyed most clearly by the optimal lighting parameters. Besides lighting goodness, the proposed metric can also be used to evaluate lighting similarity and stability between two sets of lighting parameters. Lighting similarity can be used to optimize the selection of multiple light sources so that different light sources can reveal distinct structural information. Our experiments with several volume data sets demonstrate the effectiveness of the structure-aware lighting design approach. It is well suited to use by novices as it requires little technical understanding of the rendering parameters associated with direct volume rendering.","Authors":"Yubo Tao;Hai Lin;Feng Dong;Chao Wang;Clapworthy, G.;Hujun Bao","Clusters":"ComparisonComparativeVisualizationAndSimilarity;Illumination;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2012.267","Keywords":"structural dissimilarity;lighting similarity;volume rendering;lighting stability;automatic lighting design","Title":"Structure-Aware Lighting Design for Volume Visualization","type":"new","Vector":[0.0030381754,0.0,0.0,0.0,0.0,0.0,0.0036530547,0.0,0.0734521792,0.0,0.0117768104,0.0,0.0,0.0101958217,0.0,0.0,0.0,0.0,0.0003435171,0.0]},"170":{"Abstract":"This paper introduces a new feature analysis and visualization method for multifield datasets. Our approach applies a surface-centric model to characterize salient features and form an effective, schematic representation of the data. We propose a simple, geometrically motivated, multifield feature definition. This definition relies on an iterative algorithm that applies existing theory of skeleton derivation to fuse the structures from the constitutive fields into a coherent data description, while addressing noise and spurious details. This paper also presents a new method for non-rigid surface registration between the surfaces of consecutive time steps. This matching is used in conjunction with clustering to discover the interaction patterns between the different fields and their evolution over time. We document the unified visual analysis achieved by our method in the context of several multifield problems from large-scale time-varying simulations.","Authors":"Barakat, S.S.;Rutten, M.;Tricoche, X.","Clusters":"MultidimensionalMultivariateMultifieldDataAndTechniques;SurfaceRelatedDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques","DOI":"10.1109\/TVCG.2012.269","Keywords":"time-varying;surface structures;multi-field","Title":"Surface-Based Structure Analysis and Visualization for Multifield Time-Varying Datasets","type":"new","Vector":[0.0,0.0283804782,0.0703272552,0.021457249,0.0,0.0834421955,0.0135955481,0.016058467,0.0136135747,0.0021301338,0.0,0.0057051262,0.0,0.0024629937,0.0,0.0279740732,0.002419167,0.0796541285,0.0230472929,0.0043108568]},"171":{"Abstract":"Despite the ongoing efforts in turbulence research, the universal properties of the turbulence small-scale structure and the relationships between small- and large-scale turbulent motions are not yet fully understood. The visually guided exploration of turbulence features, including the interactive selection and simultaneous visualization of multiple features, can further progress our understanding of turbulence. Accomplishing this task for flow fields in which the full turbulence spectrum is well resolved is challenging on desktop computers. This is due to the extreme resolution of such fields, requiring memory and bandwidth capacities going beyond what is currently available. To overcome these limitations, we present a GPU system for feature-based turbulence visualization that works on a compressed flow field representation. We use a wavelet-based compression scheme including run-length and entropy encoding, which can be decoded on the GPU and embedded into brick-based volume ray-casting. This enables a drastic reduction of the data to be streamed from disk to GPU memory. Our system derives turbulence properties directly from the velocity gradient tensor, and it either renders these properties in turn or generates and renders scalar feature volumes. The quality and efficiency of the system is demonstrated in the visualization of two unsteady turbulence simulations, each comprising a spatio-temporal resolution of 10244. On a desktop computer, the system can visualize each time step in 5 seconds, and it achieves about three times this rate for the visualization of a scalar feature volume.","Authors":"Treib, M.;Burger, K.;Reichl, F.;Meneveau, C.;Szalay, A.;Westermann, R.","Clusters":"CompressionTechniques;StreamingDataAndTechniques;VectorFieldsDataAndTechniques;VisualizationSystemsToolkitsAndEnvironments;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2012.274","Keywords":"volume rendering;data compression;data streaming;vector field;visualization system and toolkit design","Title":"Turbulence Visualization at the Terascale on Desktop PCs","type":"new","Vector":[0.0,0.0,0.0,0.0728691097,0.011344186,0.0638594729,0.0016347058,0.0,0.0,0.0,0.0,0.0,0.0593875662,0.0,0.0,0.023973499,0.0,0.0,0.2962895927,0.0]},"172":{"Abstract":"The U.S. Department of Energy's (DOE) Office of Environmental Management (DOE\/EM) currently supports an effort to understand and predict the fate of nuclear contaminants and their transport in natural and engineered systems. Geologists, hydrologists, physicists and computer scientists are working together to create models of existing nuclear waste sites, to simulate their behavior and to extrapolate it into the future. We use visualization as an integral part in each step of this process. In the first step, visualization is used to verify model setup and to estimate critical parameters. High-performance computing simulations of contaminant transport produces massive amounts of data, which is then analyzed using visualization software specifically designed for parallel processing of large amounts of structured and unstructured data. Finally, simulation results are validated by comparing simulation results to measured current and historical field data. We describe in this article how visual analysis is used as an integral part of the decision-making process in the planning of ongoing and future treatment options for the contaminated nuclear waste sites. Lessons learned from visually analyzing our large-scale simulation runs will also have an impact on deciding on treatment measures for other contaminated sites.","Authors":"Meyer, J.;Bethel, E.W.;Horsman, J.L.;Hubbard, S.S.;Krishnan, H.;Romosan, A.;Keating, E.H.;Monroe, L.;Strelitz, R.;Moore, P.;Taylor, G.;Torkian, B.;Johnson, T.C.;Gorton, I.","Clusters":"DataAcquisitionAndManagement;EarthSpaceAndEnvironmentalSciences;HardwareAccellerationAndComputationGeneral;ParallelSystemsAndParallelProcessing","DOI":"10.1109\/TVCG.2012.278","Keywords":"environmental management;high-performance computing;visual analytics;data management;parallel rendering","Title":"Visual Data Analysis as an Integral Part of Environmental Management","type":"new","Vector":[0.0069404368,0.0,0.0123349137,0.0,0.0068680962,0.0097685326,0.0,0.0061327597,0.0021014771,0.0166351318,0.0037292097,0.0149286974,0.0022068723,0.0135023161,0.0012063746,0.0248051355,0.007919312,0.0331649226,0.0129225284,0.0220237392]},"173":{"Abstract":"The study of aerosol composition for air quality research involves the analysis of high-dimensional single particle mass spectrometry data. We describe, apply, and evaluate a novel interactive visual framework for dimensionality reduction of such data. Our framework is based on non-negative matrix factorization with specifically defined regularization terms that aid in resolving mass spectrum ambiguity. Thereby, visualization assumes a key role in providing insight into and allowing to actively control a heretofore elusive data processing step, and thus enabling rapid analysis meaningful to domain scientists. In extending existing black box schemes, we explore design choices for visualizing, interacting with, and steering the factorization process to produce physically meaningful results. A domain-expert evaluation of our system performed by the air quality research experts involved in this effort has shown that our method and prototype admits the finding of unambiguous and physically correct lower-dimensional basis transformations of mass spectrometry data at significantly increased speed and a higher degree of ease.","Authors":"Engel, D.;Greff, K.;Garth, C.;Bein, K.;Wexler, A.;Hamann, B.;Hagen, H.","Clusters":"DimensionalityReduction;MatrixRelatedTechniques;MultidimensionalMultivariateMultifieldDataAndTechniques;PhysicsAndPhysicalSciences;VisualEncodingAndLayoutGeneral","DOI":"10.1109\/TVCG.2012.280","Keywords":"visual encodings of numerical error metrics;dimension reduction;matrix factorization;multi-dimensional visualization;mass spectrometry data","Title":"Visual Steering and Verification of Mass Spectrometry Data Factorization in Air Quality Research","type":"new","Vector":[0.0030630391,0.0,0.0,0.00441145,0.0,0.0,0.0437829239,0.0,0.0063225128,0.0036607399,0.0027149272,0.0113356597,0.0,0.0115406774,0.0,0.1927548399,0.0074982075,0.033467353,0.0152931921,0.0]},"174":{"Abstract":"The 3D visualization of astronomical nebulae is a challenging problem since only a single 2D projection is observable from our fixed vantage point on Earth. We attempt to generate plausible and realistic looking volumetric visualizations via a tomographic approach that exploits the spherical or axial symmetry prevalent in some relevant types of nebulae. Different types of symmetry can be implemented by using different randomized distributions of virtual cameras. Our approach is based on an iterative compressed sensing reconstruction algorithm that we extend with support for position-dependent volumetric regularization and linear equality constraints. We present a distributed multi-GPU implementation that is capable of reconstructing high-resolution datasets from arbitrary projections. Its robustness and scalability are demonstrated for astronomical imagery from the Hubble Space Telescope. The resulting volumetric data is visualized using direct volume rendering. Compared to previous approaches, our method preserves a much higher amount of detail and visual variety in the 3D visualization, especially for objects with only approximate symmetry.","Authors":"Wenger, S.;Ament, M.;Guthe, S.;Lorenz, D.;Tillmann, A.;Weiskopf, D.;Magnor, M.","Clusters":"AstronomyAstrophysics;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2012.281","Keywords":"direct volume rendering;astronomical visualization;distributed volume reconstruction","Title":"Visualization of Astronomical Nebulae via Distributed Multi-GPU Compressed Sensing Tomography","type":"new","Vector":[0.0,0.0265233807,0.0,0.0122605866,0.0,0.0,0.0220284185,0.0089870626,0.0442378126,0.0018449763,0.02244485,0.0,0.0754429695,0.000509851,0.0000816058,0.0206186418,0.0188352077,0.0040100916,0.0538333271,0.0]},"175":{"Abstract":"Metal oxides are important for many technical applications. For example alumina (aluminum oxide) is the most commonly-used ceramic in microelectronic devices thanks to its excellent properties. Experimental studies of these materials are increasingly supplemented with computer simulations. Molecular dynamics (MD) simulations can reproduce the material behavior very well and are now reaching time scales relevant for interesting processes like crack propagation. In this work we focus on the visualization of induced electric dipole moments on oxygen atoms in crack propagation simulations. The straightforward visualization using glyphs for the individual atoms, simple shapes like spheres or arrows, is insufficient for providing information about the data set as a whole. As our contribution we show for the first time that fractional anisotropy values computed from the local neighborhood of individual atoms of MD simulation data depict important information about relevant properties of the field of induced electric dipole moments. Iso surfaces in the field of fractional anisotropy as well as adjustments of the glyph representation allow the user to identify regions of correlated orientation. We present novel and relevant findings for the application domain resulting from these visualizations, like the influence of mechanical forces on the electrostatic properties.","Authors":"Grottel, S.;Beck, P.;Muller, C.;Reina, G.;Roth, J.;Trebin, H.-R.;Ertl, T.","Clusters":"GlyphsGlyphBasedTechniques;PhysicsAndPhysicalSciences;PointBasedDataAndTechniques;TimeseriesTimeVaryingDataAndTechniques","DOI":"10.1109\/TVCG.2012.282","Keywords":"time-varying data;point-based data;visualization in physical sciences and engineering;glyph-based techniques","Title":"Visualization of Electrostatic Dipoles in Molecular Dynamics of Metal Oxides","type":"new","Vector":[0.0519294919,0.0,0.0,0.0510644645,0.0,0.0007769972,0.0005835073,0.0030004575,0.0088116084,0.0106926855,0.0,0.0,0.0103601952,0.0097553436,0.0159987505,0.0582198756,0.0,0.0033189879,0.0,0.0]},"176":{"Abstract":"A fundamental characteristic of fluid flow is that it causes mixing: introduce a dye into a flow, and it will disperse. Mixing can be used as a method to visualize and characterize flow. Because mixing is a process that occurs over time, it is a 4D problem that presents a challenge for computation, visualization, and analysis. Motivated by a mixing problem in geophysics, we introduce a combination of methods to analyze, transform, and finally visualize mixing in simulations of convection in a self-gravitating 3D spherical shell representing convection in the Earth's mantle. Geophysicists use tools such as the finite element model CitcomS to simulate convection, and introduce massless, passive tracers to model mixing. The output of geophysical flow simulation is hard to analyze for domain experts because of overall data size and complexity. In addition, information overload and occlusion are problems when visualizing a whole-earth model. To address the large size of the data, we rearrange the simulation data using intelligent indexing for fast file access and efficient caching. To address information overload and interpret mixing, we compute tracer concentration statistics, which are used to characterize mixing in mantle convection models. Our visualization uses a specially tailored version of Direct Volume Rendering. The most important adjustment is the use of constant opacity. Because of this special area of application, i. e. the rendering of a spherical shell, many computations for volume rendering can be optimized. These optimizations are essential to a smooth animation of the time-dependent simulation data. Our results show how our system can be used to quickly assess the simulation output and test hypotheses regarding Earth's mantle convection. The integrated processing pipeline helps geoscientists to focus on their main task of analyzing mantle homogenization.","Authors":"Schroder, S.;Peterson, J.A.;Obermaier, H.;Kellogg, L.H.;Joy, K.I.;Hagen, H.","Clusters":"BiomedicalScienceAndMedicine;EarthSpaceAndEnvironmentalSciences;FlowVisualizationDataAndTechniques;LargeScaleDataAndScalability;PhysicsAndPhysicalSciences","DOI":"10.1109\/TVCG.2012.283","Keywords":"flow visualization;tracer concentration;earth mantle;convection;large data system;geophysics","Title":"Visualization of Flow Behavior in Earth Mantle Convection","type":"new","Vector":[0.0030556631,0.0045789069,0.0037778272,0.0,0.0228670289,0.0779876218,0.0018545355,0.0417197831,0.0,0.0030661389,0.0,0.0,0.0069600484,0.002884981,0.0,0.0960311994,0.0005459047,0.0116548471,0.0025095575,0.011216738]},"177":{"Abstract":"This paper presents a visualization approach for detecting and exploring similarity in the temporal variation of field data. We provide an interactive technique for extracting correlations from similarity matrices which capture temporal similarity of univariate functions. We make use of the concept to extract periodic and quasiperiodic behavior at single (spatial) points as well as similarity between different locations within a field and also between different data sets. The obtained correlations are utilized for visual exploration of both temporal and spatial relationships in terms of temporal similarity. Our entire pipeline offers visual interaction and inspection, allowing for the flexibility that in particular time-dependent data analysis techniques require. We demonstrate the utility and versatility of our approach by applying our implementation to data from both simulation and measurement.","Authors":"Frey, S.;Sadlo, F.;Ertl, T.","Clusters":"ComparisonComparativeVisualizationAndSimilarity;TimeseriesTimeVaryingDataAndTechniques","DOI":"10.1109\/TVCG.2012.284","Keywords":"comparative visualization;time-dependent fields;similarity analysis;interactive recurrence analysis","Title":"Visualization of Temporal Similarity in field Data","type":"new","Vector":[0.0015060457,0.004649295,0.0,0.0016897984,0.0,0.0537532021,0.1588477684,0.0282579336,0.0075393013,0.0011802057,0.0,0.0079938718,0.0,0.0,0.0034085125,0.0095666888,0.0112599487,0.0297542407,0.0195229553,0.0442046285]},"178":{"Abstract":"In nuclear science, density functional theory (DFT) is a powerful tool to model the complex interactions within the atomic nucleus, and is the primary theoretical approach used by physicists seeking a better understanding of fission. However DFT simulations result in complex multivariate datasets in which it is difficult to locate the crucial `scission' point at which one nucleus fragments into two, and to identify the precursors to scission. The Joint Contour Net (JCN) has recently been proposed as a new data structure for the topological analysis of multivariate scalar fields, analogous to the contour tree for univariate fields. This paper reports the analysis of DFT simulations using the JCN, the first application of the JCN technique to real data. It makes three contributions to visualization: (i) a set of practical methods for visualizing the JCN, (ii) new insight into the detection of nuclear scission, and (iii) an analysis of aesthetic criteria to drive further work on representing the JCN.","Authors":"Duke, D.;Carr, H.;Knoll, A.;Schunck, N.;Hai Ah Nam;Staszczak, A.","Clusters":"MultidimensionalMultivariateMultifieldDataAndTechniques;ScalarFieldDataTechniques;TopologyBasedTechniques","DOI":"10.1109\/TVCG.2012.287","Keywords":"topology;scalar fields;multi-field","Title":"Visualizing Nuclear Scission through a Multifield Extension of Topological Analysis","type":"new","Vector":[0.0051959633,0.0262558321,0.0039333207,0.005595841,0.0010774338,0.0065213299,0.0017444813,0.070849527,0.0042850465,0.0029159203,0.0,0.0016627447,0.0,0.0036623088,0.0,0.0167793302,0.0019646741,0.0075102533,0.0,0.018878226]},"179":{"Abstract":"Scientists, engineers and physicians are used to analyze 3D data with slice-based visualizations. Radiologists for example are trained to read slices of medical imaging data. Despite the numerous examples of sophisticated 3D rendering techniques, domain experts, who still prefer slice-based visualization do not consider these to be very useful. Since 3D renderings have the advantage of providing an overview at a glance, while 2D depictions better serve detailed analyses, it is of general interest to better combine these methods. Recently there have been attempts to bridge this gap between 2D and 3D renderings. These attempts include specialized techniques for volume picking in medical imaging data that result in repositioning slices. In this paper, we present a new volume picking technique called WYSIWYP (\u00e2\u20ac\u0153what you see is what you pick\u00e2\u20ac\u009d) that, in contrast to previous work, does not require pre-segmented data or metadata and thus is more generally applicable. The positions picked by our method are solely based on the data itself, the transfer function, and the way the volumetric rendering is perceived by the user. To demonstrate the utility of the proposed method, we apply it to automated positioning of slices in volumetric scalar fields from various application areas. Finally, we present results of a user study in which 3D locations selected by users are compared to those resulting from WYSIWYP. The user study confirms our claim that the resulting positions correlate well with those perceived by the user.","Authors":"Wiebel, A.;Vos, F.M.;Foerster, D.;Hege, H.-C.","Clusters":"DesignMethodologiesAndInteractionDesign;InteractionTechniquesGeneral;VolumeRenderingModelingAndVisualization","DOI":"10.1109\/TVCG.2012.292","Keywords":"volume rendering;what-you-see-is-what-you-get;picking","Title":"WYSIWYP: What You See Is What You Pick","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0157108228,0.0,0.0,0.057538807,0.0,0.0,0.0,0.1205777968,0.0470792895,0.0,0.0,0.0,0.0,0.0,0.0055141029]},"180":{"Abstract":"We present a Visual Analytics approach that addresses the detection of interesting patterns in numerical time series, specifically from environmental sciences. Crucial for the detection of interesting temporal patterns are the time scale and the starting points one is looking at. Our approach makes no assumption about time scale and starting position of temporal patterns and consists of three main steps: an algorithm to compute statistical values for all possible time scales and starting positions of intervals, visual identification of potentially interesting patterns in a matrix visualization, and interactive exploration of detected patterns. We demonstrate the utility of this approach in two scientific scenarios and explain how it allowed scientists to gain new insight into the dynamics of environmental systems.","Authors":"Sips, M.;Kothur, P.;Unger, A.;Hege, H.-C.;Dransch, D.","Clusters":"MultiScaleDataTechniques;TimeseriesTimeVaryingDataAndTechniques","DOI":"10.1109\/TVCG.2012.191","Keywords":"time-series analysis;visual analytics;multi-scale visualization","Title":"A Visual Analytics Approach to Multiscale Exploration of Environmental Time Series","type":"new","Vector":[0.0,0.0063756936,0.0,0.0,0.0,0.0064667267,0.0073811533,0.0149350862,0.0083827372,0.0075912986,0.0,0.0,0.0,0.0051414826,0.0,0.0001387745,0.0,0.0727488564,0.0287534837,0.0740061246]},"181":{"Abstract":"Visual Analytics is \u00e2\u20ac\u0153the science of analytical reasoning facilitated by visual interactive interfaces\u00e2\u20ac\u009d [70]. The goal of this field is to develop tools and methodologies for approaching problems whose size and complexity render them intractable without the close coupling of both human and machine analysis. Researchers have explored this coupling in many venues: VAST, Vis, InfoVis, CHI, KDD, IUI, and more. While there have been myriad promising examples of human-computer collaboration, there exists no common language for comparing systems or describing the benefits afforded by designing for such collaboration. We argue that this area would benefit significantly from consensus about the design attributes that define and distinguish existing techniques. In this work, we have reviewed 1,271 papers from many of the top-ranking conferences in visual analytics, human-computer interaction, and visualization. From these, we have identified 49 papers that are representative of the study of human-computer collaborative problem-solving, and provide a thorough overview of the current state-of-the-art. Our analysis has uncovered key patterns of design hinging on humanand machine-intelligence affordances, and also indicates unexplored avenues in the study of this area. The results of this analysis provide a common framework for understanding these seemingly disparate branches of inquiry, which we hope will motivate future work in the field.","Authors":"Crouser, R.J.;Chang, R.","Clusters":"HumanComputerInteractionHumanFactors;VisualizationSystemsToolkitsAndEnvironments;VisualizationTheoryModelsAndMethods","DOI":"10.1109\/TVCG.2012.195","Keywords":"human complexity;human computation;framework;theory","Title":"An Affordance-Based Framework for Human Computation and Human-Computer Collaboration","type":"new","Vector":[0.0069220021,0.0,0.0,0.0,0.0,0.0008299976,0.0057431324,0.0006958655,0.0061884188,0.0042609535,0.0,0.0467593578,0.0011233732,0.0935512586,0.000444304,0.0019169479,0.02911188,0.0133024165,0.0057188132,0.0214313519]},"182":{"Abstract":"While the formal evaluation of systems in visual analytics is still relatively uncommon, particularly rare are case studies of prolonged system use by domain analysts working with their own data. Conducting case studies can be challenging, but it can be a particularly effective way to examine whether visual analytics systems are truly helping expert users to accomplish their goals. We studied the use of a visual analytics system for sensemaking tasks on documents by six analysts from a variety of domains. We describe their application of the system along with the benefits, issues, and problems that we uncovered. Findings from the studies identify features that visual analytics systems should emphasize as well as missing capabilities that should be addressed. These findings inform design implications for future systems.","Authors":"Youn-ah Kang;Stasko, J.","Clusters":"DesignStudiesAndCaseStudies;QualitativeEvaluation","DOI":"10.1109\/TVCG.2012.224","Keywords":"qualitative evaluation;visual analytics;case study","Title":"Examining the Use of a Visual Analytics System for Sensemaking Tasks: Case Studies with Domain Experts","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3001647503,0.0,0.0176755783,0.0,0.0,0.0051145467,0.0,0.0,0.0070577709]},"183":{"Abstract":"Contingency tables summarize the relations between categorical variables and arise in both scientific and business domains. Asymmetrically large two-way contingency tables pose a problem for common visualization methods. The Contingency Wheel has been recently proposed as an interactive visual method to explore and analyze such tables. However, the scalability and readability of this method are limited when dealing with large and dense tables. In this paper we present Contingency Wheel++, new visual analytics methods that overcome these major shortcomings: (1) regarding automated methods, a measure of association based on Pearson's residuals alleviates the bias of the raw residuals originally used, (2) regarding visualization methods, a frequency-based abstraction of the visual elements eliminates overlapping and makes analyzing both positive and negative associations possible, and (3) regarding the interactive exploration environment, a multi-level overview+detail interface enables exploring individual data items that are aggregated in the visualization or in the table using coordinated views. We illustrate the applicability of these new methods with a use case and show how they enable discovering and analyzing nontrivial patterns and associations in large categorical data.","Authors":"Alsallakh, B.;Aigner, W.;Miksch, S.;Groller, E.","Clusters":"LargeScaleDataAndScalability;TabularDataAndTechniques;UserInterfacesGeneral","DOI":"10.1109\/TVCG.2012.254","Keywords":"information interfaces and presentation;contingency table analysis;large categorical data;visual analytics","Title":"Reinventing the Contingency Wheel: Scalable Visual Analytics of Large Categorical Data","type":"new","Vector":[0.0,0.0023588883,0.0,0.0,0.0004103257,0.0,0.0051711285,0.0218745579,0.0003831462,0.0,0.0,0.0054861444,0.0,0.0110674444,0.0004056166,0.0,0.0036822636,0.099877199,0.0,0.0077698992]},"184":{"Abstract":"Significant effort has been devoted to designing clustering algorithms that are responsive to user feedback or that incorporate prior domain knowledge in the form of constraints. However, users desire more expressive forms of interaction to influence clustering outcomes. In our experiences working with diverse application scientists, we have identified an interaction style scatter\/gather clustering that helps users iteratively restructure clustering results to meet their expectations. As the names indicate, scatter and gather are dual primitives that describe whether clusters in a current segmentation should be broken up further or, alternatively, brought back together. By combining scatter and gather operations in a single step, we support very expressive dynamic restructurings of data. Scatter\/gather clustering is implemented using a nonlinear optimization framework that achieves both locality of clusters and satisfaction of user-supplied constraints. We illustrate the use of our scatter\/gather clustering approach in a visual analytic application to study baffle shapes in the bat biosonar (ears and nose) system. We demonstrate how domain experts are adept at supplying scatter\/gather constraints, and how our framework incorporates these constraints effectively without requiring numerous instance-level constraints.","Authors":"Hossain, M.S.;Ojili, P.K.R.;Grimm, C.;Muller, R.;Watson, L.T.;Ramakrishnan, N.","Clusters":"DataClusteringAndAggregation","DOI":"10.1109\/TVCG.2012.258","Keywords":"constrained clustering;scatter\/gather clustering;alternative clustering","Title":"Scatter\/Gather Clustering: Flexibly Incorporating User Feedback to Steer Clustering Results","type":"new","Vector":[0.001246711,0.0,0.0040800087,0.0,0.0,0.0,0.2525701799,0.0001022288,0.0010590278,0.0019643667,0.0001271215,0.0082593579,0.0,0.0050587385,0.0054941745,0.0002218572,0.0100012263,0.0032356211,0.0,0.0]},"185":{"Abstract":"Visual analytic tools aim to support the cognitively demanding task of sensemaking. Their success often depends on the ability to leverage capabilities of mathematical models, visualization, and human intuition through flexible, usable, and expressive interactions. Spatially clustering data is one effective metaphor for users to explore similarity and relationships between information, adjusting the weighting of dimensions or characteristics of the dataset to observe the change in the spatial layout. Semantic interaction is an approach to user interaction in such spatializations that couples these parametric modifications of the clustering model with users' analytic operations on the data (e.g., direct document movement in the spatialization, highlighting text, search, etc.). In this paper, we present results of a user study exploring the ability of semantic interaction in a visual analytic prototype, ForceSPIRE, to support sensemaking. We found that semantic interaction captures the analytical reasoning of the user through keyword weighting, and aids the user in co-creating a spatialization based on the user's reasoning and intuition.","Authors":"Endert, A.;Fiaux, P.;North, C.","Clusters":"Cognition;InteractionTechniquesGeneral","DOI":"10.1109\/TVCG.2012.260","Keywords":"user interaction;sensemaking;visualization;visual analytics;analytic reasoning","Title":"Semantic Interaction for Sensemaking: Inferring Analytical Reasoning for Model Steering","type":"new","Vector":[0.0,0.0065305975,0.0,0.0,0.0,0.0,0.0254285093,0.0,0.0,0.0,0.0,0.2621291409,0.0,0.0099510314,0.0,0.0,0.0,0.0,0.0,0.0061302419]},"186":{"Abstract":"Visual analytics emphasizes the interplay between visualization, analytical procedures performed by computers and human perceptual and cognitive activities. Human reasoning is an important element in this context. There are several theories in psychology and HCI explaining open-ended and exploratory reasoning. Five of these theories (sensemaking theories, gestalt theories, distributed cognition, graph comprehension theories and skill-rule-knowledge models) are described in this paper. We discuss their relevance for visual analytics. In order to do this more systematically, we developed a schema of categories relevant for visual analytics research and evaluation. All these theories have strengths but also weaknesses in explaining interaction with visual analytics systems. A possibility to overcome the weaknesses would be to combine two or more of these theories.","Authors":"Pohl, M.;Smuc, M.;Mayr, E.","Clusters":"Cognition;DesignMethodologiesAndInteractionDesign;KnowledgeDiscovery;ReasoningProblemSolvingAndDecisionMaking","DOI":"10.1109\/TVCG.2012.273","Keywords":"cognitive theory;problem solving;interaction design;visual knowledge discovery;reasoning","Title":"The User Puzzle---Explaining the Interaction with Visual Analytics Systems","type":"new","Vector":[0.0,0.0,0.0023675686,0.0,0.0,0.0086086754,0.0080135392,0.0019187692,0.0026286277,0.0026692869,0.0,0.042790741,0.0004721043,0.142779282,0.0,0.001205947,0.0104605541,0.0092343438,0.0082285681,0.0046054633]},"187":{"Abstract":"Eye movement analysis is gaining popularity as a tool for evaluation of visual displays and interfaces. However, the existing methods and tools for analyzing eye movements and scanpaths are limited in terms of the tasks they can support and effectiveness for large data and data with high variation. We have performed an extensive empirical evaluation of a broad range of visual analytics methods used in analysis of geographic movement data. The methods have been tested for the applicability to eye tracking data and the capability to extract useful knowledge about users' viewing behaviors. This allowed us to select the suitable methods and match them to possible analysis tasks they can support. The paper describes how the methods work in application to eye tracking data and provides guidelines for method selection depending on the analysis tasks.","Authors":"Andrienko, G.;Andrienko, N.;Burch, M.;Weiskopf, D.","Clusters":"AnimationAndMotion;EvaluationGeneral","DOI":"10.1109\/TVCG.2012.276","Keywords":"trajectory analysis;movement data;eye tracking;visual analytics","Title":"Visual Analytics Methodology for Eye Movement Studies","type":"new","Vector":[0.0006710541,0.0427685201,0.0,0.0,0.0,0.0302322492,0.0618132953,0.0096847798,0.0,0.0016581461,0.0,0.0,0.0,0.0261557001,0.0,0.0181681223,0.0,0.0015036755,0.0,0.2043303601]},"188":{"Abstract":"Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.","Authors":"Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.","Clusters":"DatabasesAndDataMining;EvaluationGeneral;HumanComputerInteractionHumanFactors;MachineLearningAndStatistics;SegmentationAndClassification","DOI":"10.1109\/TVCG.2012.277","Keywords":"information retrieval;user evaluation;active learning;classification;human-computer interaction;visual analytics","Title":"Visual Classifier Training for Text Document Retrieval","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0261777367,0.0,0.0031534232,0.0092643752,0.0,0.2400371214,0.0,0.0771836797,0.0,0.0025529008,0.0,0.0021735007,0.0,0.0]},"189":{"Abstract":"The Common N-Gram (CNG) classifier is a text classification algorithm based on the comparison of frequencies of character n-grams (strings of characters of length n) that are the most common in the considered documents and classes of documents. We present a text analytic visualization system that employs the CNG approach for text classification and uses the differences in frequency values of common n-grams in order to visually compare documents at the sub-word level. The visualization method provides both an insight into n-gram characteristics of documents or classes of documents and a visual interpretation of the workings of the CNG classifier.","Authors":"Jankowska, M.;Keselj, V.;Milios, E.","Clusters":"TextDocumentTopicAnalysisDataAndTechniques","DOI":"10.1109\/VAST.2012.6400484","Keywords":"text classification;visual text analysis;visual analytics","Title":"Relative N-gram signatures: Document visualization at the level of character N-grams","type":"new","Vector":[0.0018263138,0.0,0.0,0.0,0.0,0.0,0.0013105462,0.0,0.0014961019,0.0,0.0,0.1541146295,0.0,0.0,0.0,0.0,0.0,0.0016965731,0.0003088039,0.0]},"190":{"Abstract":"We introduce the concept of just-in-time descriptive analytics as a novel application of computational and statistical techniques performed at interaction-time to help users easily understand the structure of data as seen in visualizations. Fundamental to just-intime descriptive analytics is (a) identifying visual features, such as clusters, outliers, and trends, user might observe in visualizations automatically, (b) determining the semantics of such features by performing statistical analysis as the user is interacting, and (c) enriching visualizations with annotations that not only describe semantics of visual features but also facilitate interaction to support high-level understanding of data. In this paper, we demonstrate just-in-time descriptive analytics applied to a point-based multi-dimensional visualization technique to identify and describe clusters, outliers, and trends. We argue that it provides a novel user experience of computational techniques working alongside of users allowing them to build faster qualitative mental models of data by demonstrating its application on a few use-cases. Techniques used to facilitate just-in-time descriptive analytics are described in detail along with their runtime performance characteristics. We believe this is just a starting point and much remains to be researched, as we discuss open issues and opportunities in improving accessibility and collaboration.","Authors":"Kandogan, E.","Clusters":"AlgorithmicPatternFeatureDetectionTracking;AnalysisProcessGeneral;PointBasedDataAndTechniques","DOI":"10.1109\/VAST.2012.6400487","Keywords":"feature identification and characterization;point-based visualization;just-in-time descriptive analytics","Title":"Just-in-time annotation of clusters, outliers, and trends in point-based data visualizations","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0000029666,0.301677646,0.0,0.0,0.0087691167,0.0,0.0260522637,0.0004237198,0.0339426032,0.0,0.0,0.0,0.0566670371,0.0,0.0046987441]},"191":{"Abstract":"An essential element of exploratory data analysis is the use of revealing low-dimensional projections of high-dimensional data. Projection Pursuit has been an effective method for finding interesting low-dimensional projections of multidimensional spaces by optimizing a score function called a projection pursuit index. However, the technique is not scalable to high-dimensional spaces. Here, we introduce a novel method for discovering noteworthy views of high-dimensional data spaces by using binning and random projections. We define score functions, akin to projection pursuit indices, that characterize visual patterns of the low-dimensional projections that constitute feature subspaces. We also describe an analytic, multivariate visualization platform based on this algorithm that is scalable to extremely large problems.","Authors":"Anand, A.;Wilkinson, L.;Tuan Nhon Dang","Clusters":"DimensionalityReduction;MultidimensionalMultivariateMultifieldDataAndTechniques","DOI":"10.1109\/VAST.2012.6400490","Keywords":"random projections;high-dimensional data","Title":"Visual pattern discovery using random projections","type":"new","Vector":[0.0,0.0,0.0052066564,0.0,0.0,0.0,0.0777513414,0.0,0.0,0.0109645852,0.0090143192,0.0078573271,0.0220440384,0.0,0.0,0.0,0.0,0.1431208452,0.0,0.0]},"192":{"Abstract":"Finding patterns and trends in spatial and temporal datasets has been a long studied problem in statistics and different domains of science. This paper presents a visual analytics approach for the interactive exploration and analysis of spatiotemporal correlations among multivariate datasets. Our approach enables users to discover correlations and explore potentially causal or predictive links at different spatiotemporal aggregation levels among the datasets, and allows them to understand the underlying statistical foundations that precede the analysis. Our technique utilizes the Pearson's product-moment correlation coefficient and factors in the lead or lag between different datasets to detect trends and periodic patterns amongst them.","Authors":"Malik, A.;Maciejewski, R.;Elmqvist, N.;Yun Jang;Ebert, D.S.;Huang, W.","Clusters":"MachineLearningAndStatistics","DOI":"10.1109\/VAST.2012.6400491","Keywords":"correlation analysis;visual analytics","Title":"A correlative analysis process in a visual analytics environment","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0039760643,0.0,0.0,0.0105582265,0.0,0.0083741536,0.0,0.0,0.0,0.0,0.0014177436,0.07529234,0.0013175716,0.0942391266]},"193":{"Abstract":"Visualizations embody design choices about data access, data transformation, visual representation, and interaction. To interpret a static visualization, a person must identify the correspondences between the visual representation and the underlying data. These correspondences become moving targets when a visualization is dynamic. Dynamics may be introduced in a visualization at any point in the analysis and visualization process. For example, the data itself may be streaming, shifting subsets may be selected, visual representations may be animated, and interaction may modify presentation. In this paper, we focus on the impact of dynamic data. We present a taxonomy and conceptual framework for understanding how data changes influence the interpretability of visual representations. Visualization techniques are organized into categories at various levels of abstraction. The salient characteristics of each category and task suitability are discussed through examples from the scientific literature and popular practices. Examining the implications of dynamically updating visualizations warrants attention because it directly impacts the interpretability (and thus utility) of visualizations. The taxonomy presented provides a reference point for further exploration of dynamic data visualization techniques.","Authors":"Cottam, J.A.;Lumsdaine, A.;Weaver, C.","Clusters":"Cognition;DynamicDataAndTechniques","DOI":"10.1109\/VAST.2012.6400552","Keywords":"dynamic data;interpretation","Title":"Watch this: A taxonomy for dynamic data visualization","type":"new","Vector":[0.0,0.0090981932,0.0022816694,0.0012997016,0.0054770241,0.0084830132,0.0,0.0050603884,0.0,0.0021022159,0.0,0.0105723653,0.0,0.0431644986,0.0010614526,0.0009519373,0.0068111759,0.0683797316,0.0047840235,0.0238574233]},"194":{"Abstract":"Due to the ever growing volume of acquired data and information, users have to be constantly aware of the methods for their exploration and for interaction. Of these, not each might be applicable to the data at hand or might reveal the desired result. Owing to this, innovations may be used inappropriately and users may become skeptical. In this paper we propose a knowledge-assisted interface for medical visualization, which reduces the necessary effort to use new visualization methods, by providing only the most relevant ones in a smart way. Consequently, we are able to expand such a system with innovations without the users to worry about when, where, and especially how they may or should use them. We present an application of our system in the medical domain and give qualitative feedback from domain experts.","Authors":"Mistelbauer, G.;Bouzari, H.;Schernthaner, R.;Baclija, I.;Kochl, A.;Bruckner, S.;Sramek, M.;Groller, E.","Clusters":"InteractionTechniquesGeneral;NumericalMethodsMathematics","DOI":"10.1109\/VAST.2012.6400555","Keywords":"visualization;fuzzy logic;interaction","Title":"Smart super views---A knowledge-assisted interface for medical visualization","type":"new","Vector":[0.0,0.0144396794,0.0,0.0042601474,0.0,0.0,0.0,0.0,0.0961650609,0.0119667562,0.0,0.0096017563,0.0025868083,0.0069036207,0.0,0.0,0.0059365775,0.0230778329,0.0,0.0101108669]},"195":{"Abstract":"Increasingly, social network datasets contain social attribute information about actors and their relationship. Analyzing such network with social attributes requires making sense of not only its structural features, but also the relationship between social features in attributes and network structures. Existing social network analysis tools are usually weak in supporting complex analytical tasks involving both structural and social features, and often overlook users' needs for sensemaking tools that help to gather, synthesize, and organize information of these features. To address these challenges, we propose a sensemaking framework of social-network visual analytics in this paper. This framework considers both bottom-up processes, which are about constructing new understandings based on collected information, and top-down processes, which concern using prior knowledge to guide information collection, in analyzing social networks from both social and structural perspectives. The framework also emphasizes the externalization of sensemaking processes through interactive visualization. Guided by the framework, we develop a system, SocialNetSense, to support the sensemaking in visual analytics of social networks with social attributes. The example of using our system to analyze a scholar collaboration network shows that our approach can help users gain insight into social networks both structurally and socially, and enhance their process awareness in visual analytics.","Authors":"Liang Gou;Xiaolong Zhang;Airong Luo;Anderson, P.F.","Clusters":"Cognition;SocialNetworksAndSocialMedia;VisualizationSystemsToolkitsAndEnvironments","DOI":"10.1109\/VAST.2012.6400558","Keywords":"socialnetsense;sensemaking;visualization;visual analytics;social networks","Title":"SocialNetSense: Supporting sensemaking of social and structural features in networks with interactive visualization","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0158857292,0.0,0.0238414999,0.0,0.0,0.3300838309,0.0,0.0,0.0]},"196":{"Abstract":"Distributed cognition and embodiment provide compelling models for how humans think and interact with the environment. Our examination of the use of large, high-resolution displays from an embodied perspective has lead directly to the development of a new sensemaking environment called Analyst's Workspace (AW). AW leverages the embodied resources made more accessible through the physical nature of the display to create a spatial workspace. By combining spatial layout of documents and other artifacts with an entity-centric, explorative investigative approach, AW aims to allow the analyst to externalize elements of the sensemaking process as a part of the investigation, integrated into the visual representations of the data itself. In this paper, we describe the various capabilities of AW and discuss the key principles and concepts underlying its design, emphasizing unique design principles for designing visual analytic tools for large, high-resolution displays.","Authors":"Andrews, C.;North, C.","Clusters":"Cognition;LargeAndHighResDisplays;SpaceRelatedSpatialDataAndTechniques","DOI":"10.1109\/VAST.2012.6400559","Keywords":"embodiment;sensemaking;distributed cognition;space;large and high-resolution display","Title":"Analyst's Workspace: An embodied sensemaking environment for large, high-resolution displays","type":"new","Vector":[0.0,0.0,0.0,0.0,0.0010657997,0.0,0.0,0.0,0.0,0.0,0.0,0.2799121958,0.0,0.0283333499,0.0,0.0,0.0176546221,0.0,0.0,0.0283918438]}}